<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 45]
- [cs.CL](#cs.CL) [Total: 82]
- [cs.CV](#cs.CV) [Total: 222]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.NI](#cs.NI) [Total: 24]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 23]
- [econ.EM](#econ.EM) [Total: 8]
- [econ.GN](#econ.GN) [Total: 5]
- [econ.TH](#econ.TH) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Bootstrapping Human-Like Planning via LLMs](https://arxiv.org/abs/2506.22604)
*David Porfirio,Vincent Hsiao,Morgan Fine-Morris,Leslie Smith,Laura M. Hiatt*

Main category: cs.AI

TL;DR: 研究结合自然语言编程和拖放界面，利用大语言模型生成人类类似的动作序列，并比较其性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何结合自然语言和拖放界面这两种直观且精确的机器人任务编程方式，以提升用户体验。

Method: 构建基于大语言模型的流程，输入自然语言并输出人类类似的动作序列，与手工指定的动作序列进行比较。

Result: 较大模型在生成人类类似动作序列上表现更优，但较小模型也能达到满意效果。

Conclusion: 结合自然语言和拖放界面可行，大模型效果更佳，但小模型也能满足需求。

Abstract: Robot end users increasingly require accessible means of specifying tasks for
robots to perform. Two common end-user programming paradigms include
drag-and-drop interfaces and natural language programming. Although natural
language interfaces harness an intuitive form of human communication,
drag-and-drop interfaces enable users to meticulously and precisely dictate the
key actions of the robot's task. In this paper, we investigate the degree to
which both approaches can be combined. Specifically, we construct a large
language model (LLM)-based pipeline that accepts natural language as input and
produces human-like action sequences as output, specified at a level of
granularity that a human would produce. We then compare these generated action
sequences to another dataset of hand-specified action sequences. Although our
results reveal that larger models tend to outperform smaller ones in the
production of human-like action sequences, smaller models nonetheless achieve
satisfactory performance.

</details>


### [2] [Ludax: A GPU-Accelerated Domain Specific Language for Board Games](https://arxiv.org/abs/2506.22609)
*Graham Todd,Alexander G. Padula,Dennis J. N. J. Soemers,Julian Togelius*

Main category: cs.AI

TL;DR: Ludax是一个结合游戏描述语言和硬件加速的框架，旨在加速游戏研究，支持强化学习和认知科学等领域。


<details>
  <summary>Details</summary>
Motivation: 为了将游戏描述语言的通用性与现代硬件加速技术结合，以加速游戏研究的模拟和实验。

Method: 开发了Ludax框架，包括一个领域特定语言，可自动编译为硬件加速代码，并集成到深度学习流程中。

Result: Ludax提供了快速模拟和灵活的表示方案，并通过基准测试和RL代理训练展示了其性能。

Conclusion: Ludax是一个开源工具，有望推动游戏研究的进展。

Abstract: Games have long been used as benchmarks and testing environments for research
in artificial intelligence. A key step in supporting this research was the
development of game description languages: frameworks that compile
domain-specific code into playable and simulatable game environments, allowing
researchers to generalize their algorithms and approaches across multiple games
without having to manually implement each one. More recently, progress in
reinforcement learning (RL) has been largely driven by advances in hardware
acceleration. Libraries like JAX allow practitioners to take full advantage of
cutting-edge computing hardware, often speeding up training and testing by
orders of magnitude. Here, we present a synthesis of these strands of research:
a domain-specific language for board games which automatically compiles into
hardware-accelerated code. Our framework, Ludax, combines the generality of
game description languages with the speed of modern parallel processing
hardware and is designed to fit neatly into existing deep learning pipelines.
We envision Ludax as a tool to help accelerate games research generally, from
RL to cognitive science, by enabling rapid simulation and providing a flexible
representation scheme. We present a detailed breakdown of Ludax's description
language and technical notes on the compilation process, along with speed
benchmarking and a demonstration of training RL agents. The Ludax framework,
along with implementations of existing board games, is open-source and freely
available.

</details>


### [3] [URSA: The Universal Research and Scientific Agent](https://arxiv.org/abs/2506.22653)
*Michael Grosskopf,Russell Bent,Rahul Somasundaram,Isaac Michaud,Arthur Lui,Nathan Debardeleben,Earl Lawrence*

Main category: cs.AI

TL;DR: URSA是一个科学代理生态系统，旨在通过模块化代理和工具加速研究任务，包括与高级物理模拟代码的耦合，以解决不同复杂性和影响的科学问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）已从简单的聊天机器人发展为具备复杂推理、规划、写作、编码和研究任务的能力，与人类科学家的日常技能高度重叠。利用LLMs在“代理”AI中有潜力彻底改变现代科学并消除研究瓶颈。

Method: 提出了URSA，一个科学代理生态系统，包含模块化代理和工具，能够结合高级物理模拟代码来解决科学问题。

Result: 展示了URSA的架构及其在解决科学问题中的潜力示例。

Conclusion: URSA展示了利用LLMs和模块化代理加速科学研究的潜力，为现代科学提供了新的工具和方法。

Abstract: Large language models (LLMs) have moved far beyond their initial form as
simple chatbots, now carrying out complex reasoning, planning, writing, coding,
and research tasks. These skills overlap significantly with those that human
scientists use day-to-day to solve complex problems that drive the cutting edge
of research. Using LLMs in "agentic" AI has the potential to revolutionize
modern science and remove bottlenecks to progress. In this work, we present
URSA, a scientific agent ecosystem for accelerating research tasks. URSA
consists of a set of modular agents and tools, including coupling to advanced
physics simulation codes, that can be combined to address scientific problems
of varied complexity and impact. This work highlights the architecture of URSA,
as well as examples that highlight the potential of the system.

</details>


### [4] [Explanations are a means to an end](https://arxiv.org/abs/2506.22740)
*Jessica Hullman,Ziyang Guo,Berk Ustun*

Main category: cs.AI

TL;DR: 论文提出了一种基于统计决策理论的功能性解释框架，强调解释应根据具体用途设计和评估，并通过多种用例展示了其应用。


<details>
  <summary>Details</summary>
Motivation: 现有可解释机器学习方法未充分考虑解释的实际用途，导致解释可能被误用或效果不佳。

Method: 提出基于统计决策理论的功能性解释框架，明确解释的具体用途，并通过临床决策支持、提供补救措施和调试等用例验证。

Result: 展示了如何通过该框架量化解释对理想决策者性能的潜在提升，并防止因解释模糊而导致的误用。

Conclusion: 解释的设计和评估应结合理论与实证视角，明确具体用途，以提高解释的实际价值。

Abstract: Modern methods for explainable machine learning are designed to describe how
models map inputs to outputs--without deep consideration of how these
explanations will be used in practice. This paper argues that explanations
should be designed and evaluated with a specific end in mind. We describe how
to formalize this end in a framework based in statistical decision theory. We
show how this functionally-grounded approach can be applied across diverse use
cases, such as clinical decision support, providing recourse, or debugging. We
demonstrate its use to characterize the maximum "boost" in performance on a
particular task that an explanation could provide an idealized decision-maker,
preventing misuse due to ambiguity by forcing researchers to specify concrete
use cases that can be analyzed in light of models of expected explanation use.
We argue that evaluation should meld theoretical and empirical perspectives on
the value of explanation, and contribute definitions that span these
perspectives.

</details>


### [5] [Bridging Ethical Principles and Algorithmic Methods: An Alternative Approach for Assessing Trustworthiness in AI Systems](https://arxiv.org/abs/2506.22774)
*Michael Papademas,Xenia Ziouvelou,Antonis Troumpoukis,Vangelis Karkaletsis*

Main category: cs.AI

TL;DR: 本文提出了一种结合伦理和算法的评估方法，旨在量化AI系统的可信度，弥补现有指南和技术工具的不足。


<details>
  <summary>Details</summary>
Motivation: AI技术的广泛影响和复杂性导致对其可信度的评估缺乏全面性和量化方法，现有工具各有局限。

Method: 结合Trustworthy AI的伦理组件与PageRank和TrustRank算法，提出一种评估框架。

Result: 该方法能通过量化指标和理论内容的结合，实现对AI系统可信度的全面评估。

Conclusion: 提出的框架减少了主观性，为AI可信度评估提供了更全面的解决方案。

Abstract: Artificial Intelligence (AI) technology epitomizes the complex challenges
posed by human-made artifacts, particularly those widely integrated into
society and exert significant influence, highlighting potential benefits and
their negative consequences. While other technologies may also pose substantial
risks, AI's pervasive reach makes its societal effects especially profound. The
complexity of AI systems, coupled with their remarkable capabilities, can lead
to a reliance on technologies that operate beyond direct human oversight or
understanding. To mitigate the risks that arise, several theoretical tools and
guidelines have been developed, alongside efforts to create technological tools
aimed at safeguarding Trustworthy AI. The guidelines take a more holistic view
of the issue but fail to provide techniques for quantifying trustworthiness.
Conversely, while technological tools are better at achieving such
quantification, they lack a holistic perspective, focusing instead on specific
aspects of Trustworthy AI. This paper aims to introduce an assessment method
that combines the ethical components of Trustworthy AI with the algorithmic
processes of PageRank and TrustRank. The goal is to establish an assessment
framework that minimizes the subjectivity inherent in the self-assessment
techniques prevalent in the field by introducing algorithmic criteria. The
application of our approach indicates that a holistic assessment of an AI
system's trustworthiness can be achieved by providing quantitative insights
while considering the theoretical content of relevant guidelines.

</details>


### [6] [ReasonBridge: Efficient Reasoning Transfer from Closed to Open-Source Language Models](https://arxiv.org/abs/2506.22865)
*Ziqi Zhong,Xunzhu Tang*

Main category: cs.AI

TL;DR: ReasonBridge通过分层知识蒸馏框架，将闭源模型的推理能力高效迁移到开源模型，显著缩小性能差距。


<details>
  <summary>Details</summary>
Motivation: 闭源与开源大语言模型在复杂推理任务上存在显著性能差距，需高效方法提升开源模型能力。

Method: 采用分层蒸馏、稀疏适配器架构和测试时计算扩展机制，使用精心筛选的Reason1K数据集。

Result: 开源模型推理能力提升23%，Qwen2.5-14B在MATH500上超越Claude-Sonnet3.5。

Conclusion: ReasonBridge为指令跟随任务提供高效推理增强方法，适用于多种领域和架构。

Abstract: Recent advancements in Large Language Models (LLMs) have revealed a
significant performance gap between closed-source and open-source models,
particularly in tasks requiring complex reasoning and precise instruction
following. This paper introduces ReasonBridge, a methodology that efficiently
transfers reasoning capabilities from powerful closed-source to open-source
models through a novel hierarchical knowledge distillation framework. We
develop a tailored dataset Reason1K with only 1,000 carefully curated reasoning
traces emphasizing difficulty, diversity, and quality. These traces are
filtered from across multiple domains using a structured multi-criteria
selection algorithm. Our transfer learning approach incorporates: (1) a
hierarchical distillation process capturing both strategic abstraction and
tactical implementation patterns, (2) a sparse reasoning-focused adapter
architecture requiring only 0.3% additional trainable parameters, and (3) a
test-time compute scaling mechanism using guided inference interventions.
Comprehensive evaluations demonstrate that ReasonBridge improves reasoning
capabilities in open-source models by up to 23% on benchmark tasks,
significantly narrowing the gap with closed-source models. Notably, the
enhanced Qwen2.5-14B outperforms Claude-Sonnet3.5 on MATH500 and matches its
performance on competition-level AIME problems. Our methodology generalizes
effectively across diverse reasoning domains and model architectures,
establishing a sample-efficient approach to reasoning enhancement for
instruction following.

</details>


### [7] [Agentic Enterprise: AI-Centric User to User-Centric AI](https://arxiv.org/abs/2506.22893)
*Arpit Narechania,Alex Endert,Atanu R Sinha*

Main category: cs.AI

TL;DR: 本文探讨了AI在企业决策中的潜力，提出了六项原则以推动以用户为中心的AI设计，并强调市场机制在平台中的作用。


<details>
  <summary>Details</summary>
Motivation: 研究AI如何提升企业决策效率，弥补当前以AI为中心的用户范式的不足。

Method: 通过分析企业决策需求，提出六项原则，并倡导以用户为中心的AI设计和市场机制。

Result: 提出了六项原则，强调用户需求和市场机制在AI设计中的重要性。

Conclusion: 以用户为中心的AI设计和市场机制能更有效地满足企业决策需求。

Abstract: After a very long winter, the Artificial Intelligence (AI) spring is here.
Or, so it seems over the last three years. AI has the potential to impact many
areas of human life - personal, social, health, education, professional. In
this paper, we take a closer look at the potential of AI for Enterprises, where
decision-making plays a crucial and repeated role across functions, tasks, and
operations. We consider Agents imbued with AI as means to increase
decision-productivity of enterprises. We highlight six tenets for Agentic
success in enterprises, by drawing attention to what the current, AI-Centric
User paradigm misses, in the face of persistent needs of and usefulness for
Enterprise Decision-Making. In underscoring a shift to User-Centric AI, we
offer six tenets and promote market mechanisms for platforms, aligning the
design of AI and its delivery by Agents to the cause of enterprise users.

</details>


### [8] [Hecto: Modular Sparse Experts for Adaptive and Interpretable Reasoning](https://arxiv.org/abs/2506.22919)
*Sanskar Pandey,Ruhaan Chopra,Saad Murtaza Bhat,Ark Abhyudaya*

Main category: cs.AI

TL;DR: Hecto是一种轻量级的混合专家（MoE）架构，通过结合GRU和FFNN专家，利用稀疏Top-1门控机制，实现了对静态和时序推理的专门化处理，提升了模型的多样性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统MoE模型的专家共享相同的归纳偏差，限制了表示多样性，且静态计算路径对需要不同类型推理的输入效率低下。Hecto旨在通过架构异构性解决这些问题。

Method: Hecto结合了GRU专家（用于时序推理）和FFNN专家（用于静态抽象），采用稀疏Top-1门控机制，输入表示独立。

Result: 在多个推理基准测试中，Hecto性能接近或匹配同质基线，同时实现了明确的专家专门化（时序vs静态推理）。在大批量下性能更优。

Conclusion: Hecto通过架构多样性提升了稳定性和可解释性，成为条件计算的新基准，适用于低资源场景下的专门化推理。

Abstract: Mixture-of-Experts (MoE) models enable conditional computation by routing
inputs to specialized experts, but these experts rely on identical inductive
biases, thus limiting representational diversity. This static computation
pathway is inefficient for inputs that require different types of reasoning and
limits specialization and interpretability. We propose Hecto, a lightweight MoE
architecture that leverages architectural heterogeneity by combining a GRU
expert for temporal reasoning and an FFNN expert for static abstraction under a
sparse Top-1 gating mechanism. Evaluated on three reasoning benchmarks (AG
News, SST-2, HotpotQA) and a regression task (STS-B), Hecto matches or closely
trails homogeneous baselines in performance despite receiving isolated input
representations, while achieving clear expert specialization, with each expert
aligning to distinct reasoning types (temporal vs static). At larger batch
sizes, Hecto exhibits improved performance, benefiting from relaxed
computational constraints that allow its heterogeneous architecture to optimize
more effectively. Ablation results isolate architectural diversity as the
source of Hecto's stability and interpretability across diverse reasoning
tasks. Overall, Hecto establishes itself as a new benchmark for conditional
computation, offering a principled framework for specialized reasoning in
low-resource regimes with its model strength derived from principled
specialization.

</details>


### [9] [Improving Rationality in the Reasoning Process of Language Models through Self-playing Game](https://arxiv.org/abs/2506.22920)
*Pinzheng Wang,Juntao Li,Zecheng Tang,Haijia Gui,Min zhang*

Main category: cs.AI

TL;DR: 通过自玩游戏（Critic-Discernment Game）提升大语言模型在推理过程中的理性能力，无需人类监督。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在数学和编程等任务中表现出推理能力，但缺乏对其推理过程的真正理解。

Method: 设计Critic-Discernment Game（CDG），模型通过面对辅助性或误导性反馈来提升推理能力。

Result: 实验表明，CDG训练显著提高了模型在数学推理、错误检测、自我修正和长链推理中的能力。

Conclusion: 自玩游戏是提升模型推理理解能力的有效方法。

Abstract: Large language models (LLMs) have demonstrated considerable reasoning
abilities in various tasks such as mathematics and coding. However, recent
studies indicate that even the best models lack true comprehension of their
reasoning processes. In this paper, we explore how self-play can enhance the
rationality of models in the reasoning process without supervision from humans
or superior models. We design a Critic-Discernment Game(CDG) in which a prover
first provides a solution to a given problem and is subsequently challenged by
critiques of its solution. These critiques either aim to assist or mislead the
prover. The objective of the prover is to maintain the correct answer when
faced with misleading comments, while correcting errors in response to
constructive feedback. Our experiments on tasks involving mathematical
reasoning, stepwise error detection, self-correction, and long-chain reasoning
demonstrate that CDG training can significantly improve the ability of
well-aligned LLMs to comprehend their reasoning process.

</details>


### [10] [MARBLE: A Hard Benchmark for Multimodal Spatial Reasoning and Planning](https://arxiv.org/abs/2506.22992)
*Yulun Jiang,Yekun Chai,Maria Brbić,Michael Moor*

Main category: cs.AI

TL;DR: MARBLE是一个多模态推理基准测试，旨在评估多模态语言模型（MLLMs）在复杂多模态环境中的逐步推理能力。现有模型表现不佳，表明复杂推理仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 现有推理基准测试主要关注文本或简单多模态问题，复杂多模态推理能力尚未被充分研究。

Method: MARBLE包含两个高难度任务（M-Portal和M-Cube），要求模型在空间、视觉和物理约束下制定和理解多步计划。

Result: 12种先进模型在MARBLE上表现接近随机水平，M-Cube任务准确率为0%，表明现有MLLMs在复杂推理上仍有不足。

Conclusion: MARBLE揭示了MLLMs的局限性，希望推动下一代模型在多模态推理能力上的发展。

Abstract: The ability to process information from multiple modalities and to reason
through it step-by-step remains a critical challenge in advancing artificial
intelligence. However, existing reasoning benchmarks focus on text-only
reasoning, or employ multimodal questions that can be answered by directly
retrieving information from a non-text modality. Thus, complex reasoning
remains poorly understood in multimodal domains. Here, we present MARBLE, a
challenging multimodal reasoning benchmark that is designed to scrutinize
multimodal language models (MLLMs) in their ability to carefully reason
step-by-step through complex multimodal problems and environments. MARBLE is
composed of two highly challenging tasks, M-Portal and M-Cube, that require the
crafting and understanding of multistep plans under spatial, visual, and
physical constraints. We find that current MLLMs perform poorly on MARBLE --
all the 12 advanced models obtain near-random performance on M-Portal and 0%
accuracy on M-Cube. Only in simplified subtasks some models outperform the
random baseline, indicating that complex reasoning is still a challenge for
existing MLLMs. Moreover, we show that perception remains a bottleneck, where
MLLMs occasionally fail to extract information from the visual inputs. By
shedding a light on the limitations of MLLMs, we hope that MARBLE will spur the
development of the next generation of models with the ability to reason and
plan across many, multimodal reasoning steps.

</details>


### [11] [AURA: Agent for Understanding, Reasoning, and Automated Tool Use in Voice-Driven Tasks](https://arxiv.org/abs/2506.23049)
*Leander Melroy Maben,Gayathri Ganesh Lakshmy,Srijith Radhakrishnan,Siddhant Arora,Shinji Watanabe*

Main category: cs.AI

TL;DR: AURA是首个开源、支持语音的多轮对话助手，具备动态工具调用和复杂任务完成能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏开源的全语音多轮对话系统，AURA填补了这一空白。

Method: 结合ASR、TTS和LLM的级联管道，支持自然语言工具集成。

Result: 在VoiceBench上表现优异，接近GPT-4o，任务成功率达90%。

Conclusion: AURA为开源语音助手提供了高效、模块化的解决方案。

Abstract: Despite advances in language and speech technologies, no open-source system
enables full speech-to-speech, multi-turn dialogue with integrated tool use and
agentic reasoning. We introduce AURA (Agent for Understanding, Reasoning, and
Automated Tool Use), the first open-source, speech-native assistant capable of
completing complex, goal-driven tasks through dynamic tool invocation and
multi-turn conversation. AURA combines open-weight ASR, TTS, and LLMs in a
cascaded pipeline and supports tools such as calendar booking, contact lookup,
web search, and email. Its modular design allows easy integration of new tools
using natural language prompts and action classes. On VoiceBench, AURA scores
92.75% on OpenBookQA-outperforming all open-weight systems and nearing
GPT-4o-and 4.39 on AlpacaEval, competitive with other open-weight systems.
Human evaluation shows 90% task success on complex, multi-turn speech tasks.

</details>


### [12] [AI's Euclid's Elements Moment: From Language Models to Computable Thought](https://arxiv.org/abs/2506.23080)
*Xinmin Fang,Lingfeng Tao,Zhengxiong Li*

Main category: cs.AI

TL;DR: 本文提出了一个五阶段进化框架，用于理解AI的发展，类比人类认知技术的进步。


<details>
  <summary>Details</summary>
Motivation: 探讨AI发展的系统性路径，解释其历史架构变化并为未来提供指导。

Method: 提出“认知几何”框架，分析AI从专家系统到Transformer的演变，并预测未来阶段。

Result: AI发展是反射性的，当前进入“元语言时刻”，未来将实现可计算思维演算和可靠AI。

Conclusion: 为AI研究提供理论基础和实用策略，支持下一代智能系统的开发。

Abstract: This paper presents a comprehensive five-stage evolutionary framework for
understanding the development of artificial intelligence, arguing that its
trajectory mirrors the historical progression of human cognitive technologies.
We posit that AI is advancing through distinct epochs, each defined by a
revolutionary shift in its capacity for representation and reasoning, analogous
to the inventions of cuneiform, the alphabet, grammar and logic, mathematical
calculus, and formal logical systems. This "Geometry of Cognition" framework
moves beyond mere metaphor to provide a systematic, cross-disciplinary model
that not only explains AI's past architectural shifts-from expert systems to
Transformers-but also charts a concrete and prescriptive path forward.
Crucially, we demonstrate that this evolution is not merely linear but
reflexive: as AI advances through these stages, the tools and insights it
develops create a feedback loop that fundamentally reshapes its own underlying
architecture. We are currently transitioning into a "Metalinguistic Moment,"
characterized by the emergence of self-reflective capabilities like
Chain-of-Thought prompting and Constitutional AI. The subsequent stages, the
"Mathematical Symbolism Moment" and the "Formal Logic System Moment," will be
defined by the development of a computable calculus of thought, likely through
neuro-symbolic architectures and program synthesis, culminating in provably
aligned and reliable AI that reconstructs its own foundational representations.
This work serves as the methodological capstone to our trilogy, which
previously explored the economic drivers ("why") and cognitive nature ("what")
of AI. Here, we address the "how," providing a theoretical foundation for
future research and offering concrete, actionable strategies for startups and
developers aiming to build the next generation of intelligent systems.

</details>


### [13] [Can Large Language Models Capture Human Risk Preferences? A Cross-Cultural Study](https://arxiv.org/abs/2506.23107)
*Bing Song,Jianing Liu,Sisi Jian,Chenyang Wu,Vinayak Dixit*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLMs）在模拟风险决策行为中的表现，发现模型比人类更规避风险，且中文提示下的预测偏差更大。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs应用的扩展，其在复杂决策行为（如风险决策）中的可靠性引发关注。

Method: 通过彩票任务比较LLMs（ChatGPT 4o和o1-mini）与人类决策，使用CRRA框架分析风险偏好。

Result: 模型比人类更规避风险，o1-mini更接近人类决策；中文提示下的预测偏差更大。

Conclusion: LLMs在模拟人类风险行为方面有潜力，但在语言和文化背景下的表现仍有局限。

Abstract: Large language models (LLMs) have made significant strides, extending their
applications to dialogue systems, automated content creation, and
domain-specific advisory tasks. However, as their use grows, concerns have
emerged regarding their reliability in simulating complex decision-making
behavior, such as risky decision-making, where a single choice can lead to
multiple outcomes. This study investigates the ability of LLMs to simulate
risky decision-making scenarios. We compare model-generated decisions with
actual human responses in a series of lottery-based tasks, using transportation
stated preference survey data from participants in Sydney, Dhaka, Hong Kong,
and Nanjing. Demographic inputs were provided to two LLMs -- ChatGPT 4o and
ChatGPT o1-mini -- which were tasked with predicting individual choices. Risk
preferences were analyzed using the Constant Relative Risk Aversion (CRRA)
framework. Results show that both models exhibit more risk-averse behavior than
human participants, with o1-mini aligning more closely with observed human
decisions. Further analysis of multilingual data from Nanjing and Hong Kong
indicates that model predictions in Chinese deviate more from actual responses
compared to English, suggesting that prompt language may influence simulation
performance. These findings highlight both the promise and the current
limitations of LLMs in replicating human-like risk behavior, particularly in
linguistic and cultural settings.

</details>


### [14] [The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy](https://arxiv.org/abs/2506.23123)
*Rishi Bommasani*

Main category: cs.AI

TL;DR: 该论文探讨了基础模型在AI时代对社会的影响，提出了概念框架、实证见解和行动建议，以改善AI治理和社会成果。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型的能力、风险及其对社会的影响，以促进更好的AI治理。

Method: 围绕三个主题展开：概念框架（能力、风险、供应链）、实证见解（模型评估和组织透明度）、行动建议（基于证据的AI政策）。

Result: 通过科学基础和研究政策接口，为AI治理提供了更好的社会成果路径。

Conclusion: 该论文为AI时代的社会治理提供了理论基础和实践指导，旨在实现更好的社会成果。

Abstract: Artificial intelligence is humanity's most promising technology because of
the remarkable capabilities offered by foundation models. Yet, the same
technology brings confusion and consternation: foundation models are poorly
understood and they may precipitate a wide array of harms. This dissertation
explains how technology and society coevolve in the age of AI, organized around
three themes. First, the conceptual framing: the capabilities, risks, and the
supply chain that grounds foundation models in the broader economy. Second, the
empirical insights that enrich the conceptual foundations: transparency created
via evaluations at the model level and indexes at the organization level.
Finally, the transition from understanding to action: superior understanding of
the societal impact of foundation models advances evidence-based AI policy.
View together, this dissertation makes inroads into achieving better societal
outcomes in the age of AI by building the scientific foundations and
research-policy interface required for better AI governance.

</details>


### [15] [Are Large Language Models Capable of Deep Relational Reasoning? Insights from DeepSeek-R1 and Benchmark Comparisons](https://arxiv.org/abs/2506.23128)
*Chi Chiu So,Yueyue Sun,Jun-Min Wang,Siu Pang Yung,Anthony Wai Keung Loh,Chun Pong Chau*

Main category: cs.AI

TL;DR: 论文评估了三种大型语言模型（DeepSeek-R1、DeepSeek-V3和GPT-4o）在深度关系推理任务中的表现，发现DeepSeek-R1表现最佳，但所有模型在复杂任务中均存在困难。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在深度关系推理任务中的能力，探索其优势和局限性。

Method: 通过设计家族树和一般图推理的基准任务，评估和比较三种模型的推理能力。

Result: DeepSeek-R1在多项任务中表现最佳，但所有模型在复杂任务中表现不佳，主要受限于输出结构和推理不完整。

Conclusion: 未来研究需关注多模态推理和系统化分析推理失败，以提升大型语言模型的推理能力。

Abstract: How far are Large Language Models (LLMs) in performing deep relational
reasoning? In this paper, we evaluate and compare the reasoning capabilities of
three cutting-edge LLMs, namely, DeepSeek-R1, DeepSeek-V3 and GPT-4o, through a
suite of carefully designed benchmark tasks in family tree and general graph
reasoning. Our experiments reveal that DeepSeek-R1 consistently achieves the
highest F1-scores across multiple tasks and problem sizes, demonstrating strong
aptitude in logical deduction and relational inference. However, all evaluated
models, including DeepSeek-R1, struggle significantly as problem complexity
increases, largely due to token length limitations and incomplete output
structures. A detailed analysis of DeepSeek-R1's long Chain-of-Thought
responses uncovers its unique planning and verification strategies, but also
highlights instances of incoherent or incomplete reasoning, calling attention
to the need for deeper scrutiny into LLMs' internal inference dynamics. We
further discuss key directions for future work, including the role of
multimodal reasoning and the systematic examination of reasoning failures. Our
findings provide both empirical insights and theoretical implications for
advancing LLMs' reasoning abilities, particularly in tasks that demand
structured, multi-step logical inference. Our code repository will be publicly
available at https://github.com/kelvinhkcs/Deep-Relational-Reasoning.

</details>


### [16] [Context-Driven Knowledge Graph Completion with Semantic-Aware Relational Message Passing](https://arxiv.org/abs/2506.23141)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.AI

TL;DR: 提出了一种基于语义感知的关系消息传递框架，通过Top-K邻居选择策略和多头注意力聚合器，优化知识图谱补全任务。


<details>
  <summary>Details</summary>
Motivation: 传统节点消息传递机制在知识图谱中可能引入噪声或信息稀释，影响预测准确性。

Method: 采用语义感知的Top-K邻居选择策略和多头注意力聚合器，选择并融合最相关的边信息。

Result: 在多个基准测试中表现优于现有方法。

Conclusion: 该方法能更准确地捕捉和传播与任务相关的上下文信息，减少无关干扰。

Abstract: Semantic context surrounding a triplet $(h, r, t)$ is crucial for Knowledge
Graph Completion (KGC), providing vital cues for prediction. However,
traditional node-based message passing mechanisms, when applied to knowledge
graphs, often introduce noise and suffer from information dilution or
over-smoothing by indiscriminately aggregating information from all neighboring
edges. To address this challenge, we propose a semantic-aware relational
message passing. A core innovation of this framework is the introduction of a
\textbf{semantic-aware Top-K neighbor selection strategy}. Specifically, this
strategy first evaluates the semantic relevance between a central node and its
incident edges within a shared latent space, selecting only the Top-K most
pertinent ones. Subsequently, information from these selected edges is
effectively fused with the central node's own representation using a
\textbf{multi-head attention aggregator} to generate a semantically focused
node message. In this manner, our model not only leverages the structure and
features of edges within the knowledge graph but also more accurately captures
and propagates the contextual information most relevant to the specific link
prediction task, thereby effectively mitigating interference from irrelevant
information. Extensive experiments demonstrate that our method achieves
superior performance compared to existing approaches on several established
benchmarks.

</details>


### [17] [Rises for Measuring Local Distributivity in Lattices](https://arxiv.org/abs/2506.23168)
*Mohammad Abdulla,Tobias Hille,Dominik Dürrschnabel,Gerd Stumme*

Main category: cs.AI

TL;DR: 本文提出了一种通过“上升”来量化概念格中分配性的方法，并证明了格分配性与非单位上升的关系。


<details>
  <summary>Details</summary>
Motivation: 在形式概念分析（FCA）中，格的分配性缺乏标准化度量，本文旨在填补这一空白。

Method: 引入“上升”概念，用于衡量概念格中属性或对象数量的变化，并与经典分配性定义关联。

Result: 证明格分配性当且仅当无非单位上升；实际数据的概念格多为联合分配性，而非交分配性。

Conclusion: 上升是量化分配性的有效工具，实际数据更倾向于联合分配性。

Abstract: Distributivity is a well-established and extensively studied notion in
lattice theory. In the context of data analysis, particularly within Formal
Concept Analysis (FCA), lattices are often observed to exhibit a high degree of
distributivity. However, no standardized measure exists to quantify this
property. In this paper, we introduce the notion of rises in (concept) lattices
as a means to assess distributivity. Rises capture how the number of attributes
or objects in covering concepts change within the concept lattice. We show that
a lattice is distributive if and only if no non-unit rises occur. Furthermore,
we relate rises to the classical notion of meet- and join distributivity. We
observe that concept lattices from real-world data are to a high degree
join-distributive, but much less meet-distributive. We additionally study how
join-distributivity manifests on the level of ordered sets.

</details>


### [18] [FinStat2SQL: A Text2SQL Pipeline for Financial Statement Analysis](https://arxiv.org/abs/2506.23273)
*Quang Hung Nguyen,Phuong Anh Trinh,Phan Quoc Hung Mai,Tuan Phong Trinh*

Main category: cs.AI

TL;DR: FinStat2SQL是一个轻量级的text2sql管道，专为金融领域设计，支持自然语言查询，结合大、小语言模型，在越南企业中实现了高效、低成本的金融分析。


<details>
  <summary>Details</summary>
Motivation: 金融领域的数据库设计和报表布局因实体和国家而异，使得text2sql任务更具挑战性。

Method: 采用多代理设置，结合大、小语言模型，进行实体提取、SQL生成和自我纠正，并构建特定领域数据库进行评估。

Result: 微调的7B模型在消费硬件上达到61.33%的准确率和4秒内的响应时间，优于GPT-4o-mini。

Conclusion: FinStat2SQL为越南企业提供了一种可扩展、经济高效的AI查询解决方案。

Abstract: Despite the advancements of large language models, text2sql still faces many
challenges, particularly with complex and domain-specific queries. In finance,
database designs and financial reporting layouts vary widely between financial
entities and countries, making text2sql even more challenging. We present
FinStat2SQL, a lightweight text2sql pipeline enabling natural language queries
over financial statements. Tailored to local standards like VAS, it combines
large and small language models in a multi-agent setup for entity extraction,
SQL generation, and self-correction. We build a domain-specific database and
evaluate models on a synthetic QA dataset. A fine-tuned 7B model achieves
61.33\% accuracy with sub-4-second response times on consumer hardware,
outperforming GPT-4o-mini. FinStat2SQL offers a scalable, cost-efficient
solution for financial analysis, making AI-powered querying accessible to
Vietnamese enterprises.

</details>


### [19] [Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games](https://arxiv.org/abs/2506.23276)
*David Guzman Piedrahita,Yongjin Yang,Mrinmaya Sachan,Giorgia Ramponi,Bernhard Schölkopf,Zhijing Jin*

Main category: cs.AI

TL;DR: 研究探讨了大型语言模型（LLMs）在多智能体系统中如何平衡自利与集体利益，发现不同模型在合作行为上表现出四种模式，并指出增强推理能力未必促进合作。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs作为自主智能体的部署增多，理解其合作与社会机制对确保对齐性、鲁棒性和安全部署至关重要。

Method: 通过改编行为经济学中的公共物品游戏，观察不同LLMs在重复交互中的行为模式。

Result: 发现四种行为模式：持续高合作、波动合作、逐渐衰退合作和固定策略。推理能力强的LLMs合作表现较差，而传统LLMs合作表现较好。

Conclusion: 当前提升LLMs推理能力的方法未必促进合作，为需要持续协作的环境提供了重要启示。

Abstract: As large language models (LLMs) are increasingly deployed as autonomous
agents, understanding their cooperation and social mechanisms is becoming
increasingly important. In particular, how LLMs balance self-interest and
collective well-being is a critical challenge for ensuring alignment,
robustness, and safe deployment. In this paper, we examine the challenge of
costly sanctioning in multi-agent LLM systems, where an agent must decide
whether to invest its own resources to incentivize cooperation or penalize
defection. To study this, we adapt a public goods game with institutional
choice from behavioral economics, allowing us to observe how different LLMs
navigate social dilemmas over repeated interactions. Our analysis reveals four
distinct behavioral patterns among models: some consistently establish and
sustain high levels of cooperation, others fluctuate between engagement and
disengagement, some gradually decline in cooperative behavior over time, and
others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we
find that reasoning LLMs, such as the o1 series, struggle significantly with
cooperation, whereas some traditional LLMs consistently achieve high levels of
cooperation. These findings suggest that the current approach to improving
LLMs, which focuses on enhancing their reasoning capabilities, does not
necessarily lead to cooperation, providing valuable insights for deploying LLM
agents in environments that require sustained collaboration. Our code is
available at https://github.com/davidguzmanp/SanctSim

</details>


### [20] [GATSim: Urban Mobility Simulation with Generative Agents](https://arxiv.org/abs/2506.23306)
*Qi Liu,Can Li,Wanjing Ma*

Main category: cs.AI

TL;DR: GATSim利用大型语言模型和AI代理技术，创建具有推理能力和自适应学习机制的生成代理，用于城市交通模拟，比传统规则系统更真实地模拟人类出行行为。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的交通模拟无法捕捉人类出行的复杂性和多样性，而现代AI技术为模拟提供了新可能。

Method: 提出GATSim框架，结合城市交通基础模型、代理认知系统和模拟环境，实现具有多样化属性和学习能力的生成代理。

Result: 实验表明，生成代理能产生可信的出行行为，并在宏观交通模式上与人类表现相当。

Conclusion: GATSim通过生成代理实现了更真实的城市交通模拟，为未来研究提供了新方向。

Abstract: Traditional agent-based urban mobility simulations rely on rigid rule-based
systems that fail to capture the complexity, adaptability, and behavioral
diversity characteristic of human travel decision-making. Recent advances in
large language models and AI agent technology offer opportunities to create
agents with reasoning capabilities, persistent memory, and adaptive learning
mechanisms. We propose GATSim (Generative-Agent Transport Simulation), a novel
framework that leverages these advances to create generative agents with rich
behavioral characteristics for urban mobility simulation. Unlike conventional
approaches, GATSim agents possess diverse socioeconomic attributes, individual
lifestyles, and evolving preferences that shape their mobility decisions
through psychologically-informed memory systems, tool usage capabilities, and
lifelong learning mechanisms. The main contributions of this study include: (1)
a comprehensive architecture combining an urban mobility foundation model with
agent cognitive systems and transport simulation environment, (2) a fully
functional prototype implementation, and (3) systematic validation
demonstrating that generative agents produce believable travel behaviors.
Through designed reflection processes, generative agents in this study can
transform specific travel experiences into generalized insights, enabling
realistic behavioral adaptation over time with specialized mechanisms for
activity planning and real-time reactive behaviors tailored to urban mobility
contexts. Experiments show that generative agents perform competitively with
human annotators in mobility scenarios while naturally producing macroscopic
traffic evolution patterns. The code for the prototype system is shared at
https://github.com/qiliuchn/gatsim.

</details>


### [21] [The Confidence Paradox: Can LLM Know When It's Wrong](https://arxiv.org/abs/2506.23464)
*Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao*

Main category: cs.AI

TL;DR: HonestVQA是一个自监督的诚实校准框架，旨在解决DocVQA系统中的伦理问题，通过量化不确定性、对齐模型置信度与准确性，并引入新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有DocVQA系统在伦理上不透明，常产生过度自信的答案或未能有效传达不确定性，导致伦理风险。

Method: HonestVQA采用模型无关的方法，包括不确定性量化、加权损失函数对齐置信度与正确性，以及对比学习强制伦理响应行为。

Result: HonestVQA在多个数据集上提高了准确率和F1分数，降低了过度自信，并展示了良好的泛化能力。

Conclusion: HonestVQA通过伦理对齐和性能提升，为DocVQA系统提供了更可靠的解决方案。

Abstract: Document Visual Question Answering (DocVQA) systems are increasingly deployed
in real world applications, yet they remain ethically opaque-often producing
overconfident answers to ambiguous questions or failing to communicate
uncertainty in a trustworthy manner. This misalignment between model confidence
and actual knowledge poses significant risks, particularly in domains requiring
ethical accountability. Existing approaches such as LayoutLMv3, UDOP, and DONUT
have advanced SOTA performance by focusing on architectural sophistication and
accuracy; however, they fall short in ethical responsiveness.
  To address these limitations, we introduce HonestVQA, a self-supervised
honesty calibration framework for ethically aligned DocVQA. Our model-agnostic
method quantifies uncertainty to identify knowledge gaps, aligns model
confidence with actual correctness using weighted loss functions, and enforces
ethical response behavior via contrastive learning. We further introduce two
principled evaluation metrics--Honesty Score (H-Score) and Ethical Confidence
Index (ECI)--to benchmark alignment between confidence, accuracy, and ethical
communication. Empirically, HonestVQA improves DocVQA accuracy by up to 4.3%
and F1 by 4.3% across SpDocVQA, InfographicsVQA, and SROIE datasets. It reduces
overconfidence, lowering H-Score and ECI by 0.072 and 0.078, respectively. In
cross domain evaluation, it achieves up to 78.9% accuracy and 76.1% F1-score,
demonstrating strong generalization. Ablation shows a 3.8% drop in accuracy
without alignment or contrastive loss.

</details>


### [22] [Data Augmentation for Cognitive Behavioral Therapy: Leveraging ERNIE Language Models using Artificial Intelligence](https://arxiv.org/abs/2506.23503)
*Bosubabu Sambana,Kondreddygari Archana,Suram Indhra Sena Reddy,Shaik Meethaigar Jameer Basha,Shaik Karishma*

Main category: cs.AI

TL;DR: 论文提出了一种基于CBT框架的系统，利用BERT、RoBERTa等模型分析社交媒体中的负面情绪和认知扭曲，并预测潜在心理健康问题。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏有效方法分析社交媒体中的认知路径，这对心理治疗师提供及时干预至关重要。

Method: 结合CBT框架，使用BERT、RoBERTa进行情感分析，T5、PEGASUS进行文本摘要，mT5进行多语言翻译，检测负面情绪和认知扭曲。

Result: 系统不仅能识别负面思维，还能预测潜在心理健康问题，如恐惧症和饮食障碍。

Conclusion: 该系统为心理治疗师提供了早期检测和干预的强大工具，扩展了CBT的应用范围。

Abstract: Cognitive Behavioral Therapy (CBT) is a proven approach for addressing the
irrational thought patterns associated with mental health disorders, but its
effectiveness relies on accurately identifying cognitive pathways to provide
targeted treatment. In today's digital age, individuals often express negative
emotions on social media, where they may reveal cognitive distortions, and in
severe cases, exhibit suicidal tendencies. However, there is a significant gap
in methodologies designed to analyze these cognitive pathways, which could be
critical for psychotherapists aiming to deliver timely and effective
interventions in online environments. Cognitive Behavioral Therapy (CBT)
framework leveraging acceptance, commitment and data augmentation to categorize
and address both textual and visual content as positive or negative.
Specifically, the system employs BERT, RoBERTa for Sentiment Analysis and T5,
PEGASUS for Text Summarization, mT5 for Text Translation in Multiple Languages
focusing on detecting negative emotions and cognitive distortions within social
media data. While existing models are primarily designed to identify negative
thoughts, the proposed system goes beyond this by predicting additional
negative side effects and other potential mental health disorders likes
Phobias, Eating Disorders. This enhancement allows for a more comprehensive
understanding and intervention strategy, offering psychotherapists a powerful
tool for early detection and treatment of various psychological issues.

</details>


### [23] [Hybrid Approach for Electricity Price Forecasting using AlexNet and LSTM](https://arxiv.org/abs/2506.23504)
*Bosubabu Sambana,Kotamsetty Geethika Devi,Bandi Rajeswara Reddy,Galeti Mohammad Hussain,Gownivalla Siddartha*

Main category: cs.AI

TL;DR: 该论文提出了一种结合AlexNet和LSTM的混合模型，用于提高电力价格预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如RNN和ANN）在处理外汇时间序列数据时表现不佳，且仅关注需求和价格，导致分析不足。因此，需要一种能结合外部变量的新方法。

Method: 采用AlexNet进行特征提取，LSTM学习序列模式，并结合最小-最大缩放和时间窗口等方法处理数据。

Result: 混合模型的准确率达到97.08%，优于单独的RNN（96.64%）和ANN（96.63%）。

Conclusion: 该混合模型在电力价格预测中表现出更高的准确性，优于传统方法。

Abstract: The recent development of advanced machine learning methods for hybrid models
has greatly addressed the need for the correct prediction of electrical prices.
This method combines AlexNet and LSTM algorithms, which are used to introduce a
new model with higher accuracy in price forecasting. Despite RNN and ANN being
effective, they often fail to deal with forex time sequence data. The
traditional methods do not accurately forecast the prices. These traditional
methods only focus on demand and price which leads to insufficient analysis of
data. To address this issue, using the hybrid approach, which focuses on
external variables that also effect the predicted prices. Nevertheless, due to
AlexNet's excellent feature extraction and LSTM's learning sequential patterns,
the prediction accuracy is vastly increased. The model is built on the past
data, which has been supplied with the most significant elements like demand,
temperature, sunlight, and rain. For example, the model applies methods, such
as minimum-maximum scaling and a time window, to predict the electricity prices
of the future. The results show that this hybrid model is good than the
standalone ones in terms of accuracy. Although we got our accuracy rating of
97.08, it shows higher accompaniments than remaining models RNN and ANN with
accuracies of 96.64 and 96.63 respectively.

</details>


### [24] [Assessing GPTZero's Accuracy in Identifying AI vs. Human-Written Essays](https://arxiv.org/abs/2506.23517)
*Selin Dik,Osman Erdem,Mehmet Dik*

Main category: cs.AI

TL;DR: 研究评估了GPTZero检测AI生成文本的可靠性，发现其对纯AI内容检测准确率高，但对人类写作的区分能力有限。


<details>
  <summary>Details</summary>
Motivation: 随着学生使用AI工具的增加，教师依赖AI检测工具，但其可靠性尚不明确。

Method: 研究使用不同长度的AI生成和人类写作文章，通过GPTZero检测其AI生成百分比和置信度。

Result: AI生成文本检测准确率高达91-100%，但人类写作存在误判。

Conclusion: GPTZero对纯AI内容有效，但对人类写作的区分不可靠，教师需谨慎使用。

Abstract: As the use of AI tools by students has become more prevalent, instructors
have started using AI detection tools like GPTZero and QuillBot to detect AI
written text. However, the reliability of these detectors remains uncertain. In
our study, we focused mostly on the success rate of GPTZero, the most-used AI
detector, in identifying AI-generated texts based on different lengths of
randomly submitted essays: short (40-100 word count), medium (100-350 word
count), and long (350-800 word count). We gathered a data set consisting of
twenty-eight AI-generated papers and fifty human-written papers. With this
randomized essay data, papers were individually plugged into GPTZero and
measured for percentage of AI generation and confidence. A vast majority of the
AI-generated papers were detected accurately (ranging from 91-100% AI believed
generation), while the human generated essays fluctuated; there were a handful
of false positives. These findings suggest that although GPTZero is effective
at detecting purely AI-generated content, its reliability in distinguishing
human-authored texts is limited. Educators should therefore exercise caution
when relying solely on AI detection tools.

</details>


### [25] [ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data](https://arxiv.org/abs/2506.23520)
*Yu Zhang,Ruijie Yu,Jidong Tian,Feng Zhu,Jiapeng Liu,Xiaokang Yang,Yaohui Jin,Yanyan Xu*

Main category: cs.AI

TL;DR: ChemActor是一个基于大型语言模型（LLM）的化学执行器，用于将非结构化的化学实验步骤转换为结构化的动作序列，通过LLM生成的数据框架解决了标注数据不足和质量低的问题。


<details>
  <summary>Details</summary>
Motivation: 由于化学语言的模糊性和人工标注的高成本，自动化提取化学实验步骤具有挑战性。

Method: 提出了一种顺序LLM生成的数据框架，结合数据选择模块和多轮LLM循环评估指标，从单分子输入生成机器可执行动作。

Result: 在反应到描述（R2D）和描述到动作（D2A）任务中，ChemActor性能优于基线模型10%。

Conclusion: ChemActor通过LLM生成的数据增强，在化学实验步骤理解任务中达到了最先进的性能。

Abstract: With the increasing interest in robotic synthesis in the context of organic
chemistry, the automated extraction of chemical procedures from literature is
critical. However, this task remains challenging due to the inherent ambiguity
of chemical language and the high cost of human annotation required for
developing reliable computer-aided extraction protocols. Here, we present
ChemActor, a fully fine-tuned large language model (LLM), as a chemical
executor to convert between unstructured experimental procedures and structured
action sequences. We propose a sequential LLM-generated data framework to
address the challenges of insufficient and low-quality annotated data. This
framework integrates a data selection module that selects data based on
distribution divergence, with a general-purpose LLM, to generate
machine-executable actions from a single molecule input. Additionally, we
introduce a novel multi-round LLMs circle review metric, which reflects the
model's advanced understanding of chemical experimental procedures. Extensive
experiments on reaction-to-description (R2D) and description-to-action (D2A)
tasks demonstrate that ChemActor, augmented by LLM-generated data, achieves
state-of-the-art performance, outperforming the baseline model by 10%. The code
is available at: https://github.com/Zhanghahah/ChemActor.

</details>


### [26] [CooT: Learning to Coordinate In-Context with Coordination Transformers](https://arxiv.org/abs/2506.23549)
*Huai-Chih Wang,Hsiang-Chun Chuang,Hsi-Chun Cheng,Dai-Jie Wu,Shao-Hua Sun*

Main category: cs.AI

TL;DR: 提出了一种名为Coordination Transformers (CooT)的新框架，通过上下文协调快速适应未见过的合作伙伴，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中动态和不确定环境下协调的挑战，现有方法泛化能力差或训练成本高。

Method: 利用交互历史预测合作伙伴行为，无需显式监督或微调，快速学习协调策略。

Result: 在Overcooked基准测试中显著优于基线方法，人类评估也证实其高效协作能力。

Conclusion: CooT在多智能体场景中表现出鲁棒性、灵活性和对上下文的敏感性，是高效的协作伙伴。

Abstract: Effective coordination among artificial agents in dynamic and uncertain
environments remains a significant challenge in multi-agent systems. Existing
approaches, such as self-play and population-based methods, either generalize
poorly to unseen partners or require extensive training. To overcome these
limitations, we propose Coordination Transformers (CooT), a novel in-context
coordination framework that uses recent interaction histories to adapt to
unseen partners rapidly. Unlike previous approaches that primarily aim to
increase the diversity of training partners, CooT explicitly focuses on
adapting to new partner behaviors by predicting actions aligned with observed
partner interactions. Trained on interaction trajectories collected from
diverse pairs of agents with complementary behaviors, CooT quickly learns
effective coordination strategies without explicit supervision or fine-tuning.
Evaluations on the Overcooked benchmark demonstrate that CooT significantly
outperforms baseline methods in coordination tasks involving previously unseen
partners. Human evaluations further confirm CooT as the most effective
collaborative partner, while extensive ablations highlight its robustness,
flexibility, and sensitivity to context in multi-agent scenarios.

</details>


### [27] [MMReason: An Open-Ended Multi-Modal Multi-Step Reasoning Benchmark for MLLMs Toward AGI](https://arxiv.org/abs/2506.23563)
*Huanjin Yao,Jiaxing Huang,Yawen Qiu,Michael K. Chen,Wenzheng Liu,Wei Zhang,Wenjie Zeng,Xikun Zhang,Jingyi Zhang,Yuxin Song,Wenhao Wu,Dacheng Tao*

Main category: cs.AI

TL;DR: MMReason是一个新的基准测试，旨在全面评估多模态大语言模型（MLLM）的长链推理能力，通过多样、开放和具有挑战性的问题填补现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM基准在精确评估长链推理能力方面存在不足，包括缺乏难度和多样性、易受猜测和记忆影响，以及对中间推理步骤评估不足。

Method: MMReason通过以下方法解决问题：（1）从多个学科和难度级别收集需要多步推理的问题；（2）将问题转化为开放形式，并使用多模型投票技术过滤；（3）标注详细解答并设计三元评分机制。

Result: MMReason对流行MLLM进行了基准测试，并深入分析了其推理能力。

Conclusion: MMReason为推进MLLM推理研究提供了有价值的资源。

Abstract: Reasoning plays a crucial role in advancing Multimodal Large Language Models
(MLLMs) toward Artificial General Intelligence. However, existing MLLM
benchmarks often fall short in precisely and comprehensively evaluating
long-chain reasoning abilities from three key aspects: (1) lack of difficulty
and diversity, (2) susceptibility to guessability and memorization, (3)
inadequate assessment of intermediate reasoning steps. To fill this gap, we
introduce MMReason, a new benchmark designed to precisely and comprehensively
evaluate MLLM long-chain reasoning capability with diverse, open-ended,
challenging questions. First, we curate challenging questions requiring
multi-step reasoning from various fields (i.e., 6 disciplines) and multiple
difficulty levels (i.e., from pre-university to university, and from
foundational to competition tiers). Second, these questions are reformulated
into an open-ended format and filtered using a multi-model voting technique to
eliminate shortcut cases related to guessing and memorization, ensuring robust
reasoning evaluations. Third, we annotate the questions with detailed
step-by-step solutions, and design a reference-based ternary scoring mechanism
to reliably assess intermediate reasoning steps. With MMReason, we benchmark
popular leading MLLMs and provide an in-depth analysis of their reasoning
capabilities. We hope MMReason will serve as a valuable resource for advancing
MLLM reasoning research. Code will be available at
https://github.com/HJYao00/MMReason.

</details>


### [28] [Evaluating Multi-Agent Defences Against Jailbreaking Attacks on Large Language Models](https://arxiv.org/abs/2506.23576)
*Maria Carolina Cornelia Wit,Jun Pang*

Main category: cs.AI

TL;DR: 多代理LLM系统能增强对越狱攻击的防御，但存在误报和计算开销的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用多代理LLM系统防御越狱攻击，以提升安全性。

Method: 评估三种越狱策略，比较单代理与多代理配置的效果。

Result: 多代理系统减少漏报，但效果因攻击类型而异，且增加误报和计算开销。

Conclusion: 当前自动防御存在局限，需改进对齐鲁棒性。

Abstract: Recent advances in large language models (LLMs) have raised concerns about
jailbreaking attacks, i.e., prompts that bypass safety mechanisms. This paper
investigates the use of multi-agent LLM systems as a defence against such
attacks. We evaluate three jailbreaking strategies, including the original
AutoDefense attack and two from Deepleaps: BetterDan and JB. Reproducing the
AutoDefense framework, we compare single-agent setups with two- and three-agent
configurations. Our results show that multi-agent systems enhance resistance to
jailbreaks, especially by reducing false negatives. However, its effectiveness
varies by attack type, and it introduces trade-offs such as increased false
positives and computational overhead. These findings point to the limitations
of current automated defences and suggest directions for improving alignment
robustness in future LLM systems.

</details>


### [29] [Self-correcting Reward Shaping via Language Models for Reinforcement Learning Agents in Games](https://arxiv.org/abs/2506.23626)
*António Afonso,Iolanda Leite,Alessandro Sestini,Florian Fuchs,Konrad Tollmar,Linus Gisslén*

Main category: cs.AI

TL;DR: 论文提出了一种基于语言模型的自动化方法，用于迭代优化强化学习代理的奖励函数权重，无需手动调整。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习代理在生产环境中部署时奖励函数设计困难和游戏内容变动导致权重失效的问题。

Method: 利用语言模型根据用户定义的行为目标和性能统计自动调整奖励权重，形成闭环优化。

Result: 在赛车任务中，代理性能显著提升，从9%成功率提高到74%（一次迭代），最终达到80%成功率，接近专家手动调整的94%。

Conclusion: 语言模型引导的自动化奖励调整方法有效，性能接近专家手动设计，且无需人工干预。

Abstract: Reinforcement Learning (RL) in games has gained significant momentum in
recent years, enabling the creation of different agent behaviors that can
transform a player's gaming experience. However, deploying RL agents in
production environments presents two key challenges: (1) designing an effective
reward function typically requires an RL expert, and (2) when a game's content
or mechanics are modified, previously tuned reward weights may no longer be
optimal. Towards the latter challenge, we propose an automated approach for
iteratively fine-tuning an RL agent's reward function weights, based on a
user-defined language based behavioral goal. A Language Model (LM) proposes
updated weights at each iteration based on this target behavior and a summary
of performance statistics from prior training rounds. This closed-loop process
allows the LM to self-correct and refine its output over time, producing
increasingly aligned behavior without the need for manual reward engineering.
We evaluate our approach in a racing task and show that it consistently
improves agent performance across iterations. The LM-guided agents show a
significant increase in performance from $9\%$ to $74\%$ success rate in just
one iteration. We compare our LM-guided tuning against a human expert's manual
weight design in the racing task: by the final iteration, the LM-tuned agent
achieved an $80\%$ success rate, and completed laps in an average of $855$ time
steps, a competitive performance against the expert-tuned agent's peak $94\%$
success, and $850$ time steps.

</details>


### [30] [HASD: Hierarchical Adaption for pathology Slide-level Domain-shift](https://arxiv.org/abs/2506.23673)
*Jingsong Liu,Han Li,Chen Yang,Michael Deutges,Ario Sadafi,Xin You,Katharina Breininger,Nassir Navab,Peter J. Schüffler*

Main category: cs.AI

TL;DR: 提出了一种名为HASD的分层适应框架，用于解决病理学AI中的切片级域偏移问题，通过多尺度特征一致性和计算高效的方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 病理学数据受中心特定条件影响，现有方法仅关注图像块而非全切片图像（WSI），无法满足临床需求。

Method: HASD框架包含分层适应组件（特征对齐、几何不变性正则化和注意力一致性正则化）和原型选择机制。

Result: 在两个切片级任务上验证，乳腺癌HER2分级任务AUROC提升4.1%，UCEC生存预测任务C-index提升3.9%。

Conclusion: HASD为病理学机构提供了一种实用且可靠的切片级域适应解决方案，降低了计算和标注成本。

Abstract: Domain shift is a critical problem for pathology AI as pathology data is
heavily influenced by center-specific conditions. Current pathology domain
adaptation methods focus on image patches rather than WSI, thus failing to
capture global WSI features required in typical clinical scenarios. In this
work, we address the challenges of slide-level domain shift by proposing a
Hierarchical Adaptation framework for Slide-level Domain-shift (HASD). HASD
achieves multi-scale feature consistency and computationally efficient
slide-level domain adaptation through two key components: (1) a hierarchical
adaptation framework that integrates a Domain-level Alignment Solver for
feature alignment, a Slide-level Geometric Invariance Regularization to
preserve the morphological structure, and a Patch-level Attention Consistency
Regularization to maintain local critical diagnostic cues; and (2) a prototype
selection mechanism that reduces computational overhead. We validate our method
on two slide-level tasks across five datasets, achieving a 4.1\% AUROC
improvement in a Breast Cancer HER2 Grading cohort and a 3.9\% C-index gain in
a UCEC survival prediction cohort. Our method provides a practical and reliable
slide-level domain adaption solution for pathology institutions, minimizing
both computational and annotation costs.

</details>


### [31] [PokéAI: A Goal-Generating, Battle-Optimizing Multi-agent System for Pokemon Red](https://arxiv.org/abs/2506.23689)
*Zihao Liu,Xinhang Sui,Yueran Song,Siwen Wang*

Main category: cs.AI

TL;DR: Pok\'eAI是一个基于文本的多智能体大型语言模型框架，用于自主玩Pok\'emon Red游戏，包含规划、执行和评估三个智能体，初步实验显示战斗模块表现接近人类玩家。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够自主玩Pok\'emon Red游戏的系统，探索多智能体LLM框架在游戏中的表现及其与语言能力的关联。

Method: 系统由三个智能体组成：规划（生成任务）、执行（执行任务）和评估（验证结果），形成一个闭环决策系统。

Result: 战斗模块在50次野生对战中平均胜率为80.8%，接近人类玩家水平，且模型的语言能力与战斗表现相关。

Conclusion: Pok\'eAI展示了多智能体LLM框架在游戏中的潜力，模型表现出独特的策略行为，语言能力与战略推理相关。

Abstract: We introduce Pok\'eAI, the first text-based, multi-agent large language model
(LLM) framework designed to autonomously play and progress through Pok\'emon
Red. Our system consists of three specialized agents-Planning, Execution, and
Critique-each with its own memory bank, role, and skill set. The Planning Agent
functions as the central brain, generating tasks to progress through the game.
These tasks are then delegated to the Execution Agent, which carries them out
within the game environment. Upon task completion, the Critique Agent evaluates
the outcome to determine whether the objective was successfully achieved. Once
verification is complete, control returns to the Planning Agent, forming a
closed-loop decision-making system.
  As a preliminary step, we developed a battle module within the Execution
Agent. Our results show that the battle AI achieves an average win rate of
80.8% across 50 wild encounters, only 6% lower than the performance of an
experienced human player. Furthermore, we find that a model's battle
performance correlates strongly with its LLM Arena score on language-related
tasks, indicating a meaningful link between linguistic ability and strategic
reasoning. Finally, our analysis of gameplay logs reveals that each LLM
exhibits a unique playstyle, suggesting that individual models develop distinct
strategic behaviors.

</details>


### [32] [Agent4S: The Transformation of Research Paradigms from the Perspective of Large Language Models](https://arxiv.org/abs/2506.23692)
*Boyuan Zheng,Zerui Fang,Zhe Xu,Rui Wang,Yiwen Chen,Cunshi Wang,Mengwei Qu,Lei Lei,Zhen Feng,Yan Liu,Yuyang Li,Mingzhou Tan,Jiaji Wu,Jianwei Shuai,Jia Li,Fangfu Ye*

Main category: cs.AI

TL;DR: 论文提出用LLM驱动的Agent（Agent4S）替代传统AI4S，作为第五科学范式，实现科研工作流的全自动化。


<details>
  <summary>Details</summary>
Motivation: 传统AI4S未能解决科研效率低下的核心问题，因此提出Agent4S作为更高效的解决方案。

Method: 提出五级分类框架，从简单任务自动化到完全自主协作的“AI科学家”。

Result: 定义了科学发现的革命性下一步。

Conclusion: Agent4S是真正的第五科学范式，将推动科研工作流的全面自动化。

Abstract: While AI for Science (AI4S) serves as an analytical tool in the current
research paradigm, it doesn't solve its core inefficiency. We propose "Agent
for Science" (Agent4S)-the use of LLM-driven agents to automate the entire
research workflow-as the true Fifth Scientific Paradigm. This paper introduces
a five-level classification for Agent4S, outlining a clear roadmap from simple
task automation to fully autonomous, collaborative "AI Scientists." This
framework defines the next revolutionary step in scientific discovery.

</details>


### [33] [A New Perspective On AI Safety Through Control Theory Methodologies](https://arxiv.org/abs/2506.23703)
*Lars Ullrich,Walter Zimmer,Ross Greer,Knut Graichen,Alois C. Knoll,Mohan Trivedi*

Main category: cs.AI

TL;DR: 本文提出了一种基于系统理论和数据分析的新视角，即“数据控制”，以提升AI系统的安全性，并促进跨学科的安全分析与保障。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键领域的应用缺乏足够的安全性保障，需要结合控制理论和AI技术来解决这一问题。

Method: 采用系统理论和系统分析的方法，提出“数据控制”概念，通过跨学科的安全分析与保障提升AI安全性。

Result: 提出了一种通用的安全分析与保障框架，适用于特定AI系统和应用，并为未来创新奠定基础。

Conclusion: 通过结合控制理论和AI技术，数据控制为AI安全性提供了新的研究方向和实践路径。

Abstract: While artificial intelligence (AI) is advancing rapidly and mastering
increasingly complex problems with astonishing performance, the safety
assurance of such systems is a major concern. Particularly in the context of
safety-critical, real-world cyber-physical systems, AI promises to achieve a
new level of autonomy but is hampered by a lack of safety assurance. While
data-driven control takes up recent developments in AI to improve control
systems, control theory in general could be leveraged to improve AI safety.
Therefore, this article outlines a new perspective on AI safety based on an
interdisciplinary interpretation of the underlying data-generation process and
the respective abstraction by AI systems in a system theory-inspired and system
analysis-driven manner. In this context, the new perspective, also referred to
as data control, aims to stimulate AI engineering to take advantage of existing
safety analysis and assurance in an interdisciplinary way to drive the paradigm
of data control. Following a top-down approach, a generic foundation for safety
analysis and assurance is outlined at an abstract level that can be refined for
specific AI systems and applications and is prepared for future innovation.

</details>


### [34] [Attestable Audits: Verifiable AI Safety Benchmarks Using Trusted Execution Environments](https://arxiv.org/abs/2506.23706)
*Christoph Schnabl,Daniel Hugenroth,Bill Marino,Alastair R. Beresford*

Main category: cs.AI

TL;DR: 提出了一种名为Attestable Audits的方法，利用可信执行环境（TEE）验证AI模型的合规性，保护敏感数据，解决了模型提供商与审计方之间的信任问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法提供可验证的结果，且缺乏对模型IP和基准数据集的保密性，需要一种更安全、可验证的审计方法。

Method: 使用可信执行环境（TEE）运行审计，确保用户能够验证与合规AI模型的交互，同时保护敏感数据。

Result: 构建了一个原型，验证了在典型审计基准（如Llama-3.1）上的可行性。

Conclusion: Attestable Audits提供了一种可验证且保密的审计方法，适用于AI治理框架中的验证挑战。

Abstract: Benchmarks are important measures to evaluate safety and compliance of AI
models at scale. However, they typically do not offer verifiable results and
lack confidentiality for model IP and benchmark datasets. We propose Attestable
Audits, which run inside Trusted Execution Environments and enable users to
verify interaction with a compliant AI model. Our work protects sensitive data
even when model provider and auditor do not trust each other. This addresses
verification challenges raised in recent AI governance frameworks. We build a
prototype demonstrating feasibility on typical audit benchmarks against
Llama-3.1.

</details>


### [35] [BayesL: Towards a Logical Framework for Bayesian Networks](https://arxiv.org/abs/2506.23773)
*Stefano M. Nicoletti,Mariëlle Stoelinga*

Main category: cs.AI

TL;DR: BayesL是一个新的逻辑框架，用于指定、查询和验证贝叶斯网络的行为。


<details>
  <summary>Details</summary>
Motivation: 提供一个结构化语言，支持对贝叶斯网络进行灵活查询和推理，无需手动修改模型。

Method: 开发BayesL语言，支持因果和基于证据的关系推理，以及全面的假设场景评估。

Result: BayesL能够高效地查询和验证贝叶斯网络的行为。

Conclusion: BayesL为贝叶斯网络的推理和验证提供了一种强大且灵活的工具。

Abstract: We introduce BayesL, a novel logical framework for specifying, querying, and
verifying the behaviour of Bayesian networks (BNs). BayesL (pronounced "Basil")
is a structured language that allows for the creation of queries over BNs. It
facilitates versatile reasoning concerning causal and evidence-based
relationships, and permits comprehensive what-if scenario evaluations without
the need for manual modifications to the model.

</details>


### [36] [When GNNs Met a Word Equations Solver: Learning to Rank Equations (Extended Technical Report)](https://arxiv.org/abs/2506.23784)
*Parosh Aziz Abdulla,Mohamed Faouzi Atig,Julie Cailler,Chencheng Liang,Philipp Rümmer*

Main category: cs.AI

TL;DR: 使用图神经网络（GNN）对词方程进行排序，以提高求解效率。


<details>
  <summary>Details</summary>
Motivation: 解决词方程时，处理顺序对求解性能有显著影响，需优化排序方法。

Method: 提出基于图的词方程表示方法，利用GNN进行排序，并采用三种多分类任务适应策略。

Result: 实验表明，新框架在变量出现次数受限的基准测试中优于现有求解器。

Conclusion: GNN排序方法能有效提升词方程求解效率。

Abstract: Nielsen transformation is a standard approach for solving word equations: by
repeatedly splitting equations and applying simplification steps, equations are
rewritten until a solution is reached. When solving a conjunction of word
equations in this way, the performance of the solver will depend considerably
on the order in which equations are processed. In this work, the use of Graph
Neural Networks (GNNs) for ranking word equations before and during the solving
process is explored. For this, a novel graph-based representation for word
equations is presented, preserving global information across conjuncts,
enabling the GNN to have a holistic view during ranking. To handle the variable
number of conjuncts, three approaches to adapt a multi-classification task to
the problem of ranking equations are proposed. The training of the GNN is done
with the help of minimum unsatisfiable subsets (MUSes) of word equations. The
experimental results show that, compared to state-of-the-art string solvers,
the new framework solves more problems in benchmarks where each variable
appears at most once in each equation.

</details>


### [37] [Advancing Learnable Multi-Agent Pathfinding Solvers with Active Fine-Tuning](https://arxiv.org/abs/2506.23793)
*Anton Andreychuk,Konstantin Yakovlev,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: MAPF-GPT-DDG是一种基于机器学习的多智能体路径规划（MAPF）求解器，通过改进预训练模型和引入新的数据生成机制，显著提升了性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人轨迹规划中的NP难问题，为物流、搜救等实际应用提供高效、可扩展的解决方案。

Method: 利用中心化专家数据对预训练的MAPF模型进行微调，并采用新的delta-data生成机制加速训练。

Result: MAPF-GPT-DDG在测试中表现优于现有学习型MAPF求解器，包括原始MAPF-GPT，并能处理单环境中多达100万个智能体的实例。

Conclusion: MAPF-GPT-DDG为MAPF领域设定了新的可扩展性里程碑，展示了机器学习在复杂路径规划中的潜力。

Abstract: Multi-agent pathfinding (MAPF) is a common abstraction of multi-robot
trajectory planning problems, where multiple homogeneous robots simultaneously
move in the shared environment. While solving MAPF optimally has been proven to
be NP-hard, scalable, and efficient, solvers are vital for real-world
applications like logistics, search-and-rescue, etc. To this end, decentralized
suboptimal MAPF solvers that leverage machine learning have come on stage.
Building on the success of the recently introduced MAPF-GPT, a pure imitation
learning solver, we introduce MAPF-GPT-DDG. This novel approach effectively
fine-tunes the pre-trained MAPF model using centralized expert data. Leveraging
a novel delta-data generation mechanism, MAPF-GPT-DDG accelerates training
while significantly improving performance at test time. Our experiments
demonstrate that MAPF-GPT-DDG surpasses all existing learning-based MAPF
solvers, including the original MAPF-GPT, regarding solution quality across
many testing scenarios. Remarkably, it can work with MAPF instances involving
up to 1 million agents in a single environment, setting a new milestone for
scalability in MAPF domains.

</details>


### [38] [A Survey on Autonomy-Induced Security Risks in Large Model-Based Agents](https://arxiv.org/abs/2506.23844)
*Hang Su,Jun Luo,Chang Liu,Xiao Yang,Yichi Zhang,Yinpeng Dong,Jun Zhu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLM）驱动的自主AI代理的安全风险及其防御策略，提出了R2A2框架以增强安全性。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI代理能力的提升，其安全风险（如记忆污染、工具滥用等）超越了传统系统或独立LLM的威胁模型，亟需系统性研究。

Method: 通过分析代理的结构基础和关键能力（如长期记忆、模块化工具使用等），识别安全漏洞，并提出防御策略（如输入净化、约束决策等）。

Result: 提出了R2A2框架，结合风险感知世界建模和元策略适应，实现决策循环中的主动安全。

Conclusion: R2A2框架为自主AI代理的安全问题提供了系统化解决方案，未来需进一步验证其有效性。

Abstract: Recent advances in large language models (LLMs) have catalyzed the rise of
autonomous AI agents capable of perceiving, reasoning, and acting in dynamic,
open-ended environments. These large-model agents mark a paradigm shift from
static inference systems to interactive, memory-augmented entities. While these
capabilities significantly expand the functional scope of AI, they also
introduce qualitatively novel security risks - such as memory poisoning, tool
misuse, reward hacking, and emergent misalignment - that extend beyond the
threat models of conventional systems or standalone LLMs. In this survey, we
first examine the structural foundations and key capabilities that underpin
increasing levels of agent autonomy, including long-term memory retention,
modular tool use, recursive planning, and reflective reasoning. We then analyze
the corresponding security vulnerabilities across the agent stack, identifying
failure modes such as deferred decision hazards, irreversible tool chains, and
deceptive behaviors arising from internal state drift or value misalignment.
These risks are traced to architectural fragilities that emerge across
perception, cognition, memory, and action modules. To address these challenges,
we systematically review recent defense strategies deployed at different
autonomy layers, including input sanitization, memory lifecycle control,
constrained decision-making, structured tool invocation, and introspective
reflection. We introduce the Reflective Risk-Aware Agent Architecture (R2A2), a
unified cognitive framework grounded in Constrained Markov Decision Processes
(CMDPs), which incorporates risk-aware world modeling, meta-policy adaptation,
and joint reward-risk optimization to enable principled, proactive safety
across the agent's decision-making loop.

</details>


### [39] [Beyond Statistical Learning: Exact Learning Is Essential for General Intelligence](https://arxiv.org/abs/2506.23908)
*András György,Tor Lattimore,Nevena Lazić,Csaba Szepesvári*

Main category: cs.AI

TL;DR: 论文主张AI系统需从统计学习转向精确学习以实现可靠的演绎推理。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在演绎推理任务中表现不佳，无法实现通用人工智能。

Method: 提出从统计性能优化转向精确学习范式，要求对所有输入的正确性。

Result: 统计学习方法导致系统在演绎推理中不可靠。

Conclusion: 精确学习是实现可靠演绎推理的必要且可行的目标。

Abstract: Sound deductive reasoning -- the ability to derive new knowledge from
existing facts and rules -- is an indisputably desirable aspect of general
intelligence. Despite the major advances of AI systems in areas such as math
and science, especially since the introduction of transformer architectures, it
is well-documented that even the most advanced frontier systems regularly and
consistently falter on easily-solvable deductive reasoning tasks. Hence, these
systems are unfit to fulfill the dream of achieving artificial general
intelligence capable of sound deductive reasoning. We argue that their unsound
behavior is a consequence of the statistical learning approach powering their
development. To overcome this, we contend that to achieve reliable deductive
reasoning in learning-based AI systems, researchers must fundamentally shift
from optimizing for statistical performance against distributions on reasoning
problems and algorithmic tasks to embracing the more ambitious exact learning
paradigm, which demands correctness on all inputs. We argue that exact learning
is both essential and possible, and that this ambitious objective should guide
algorithm design.

</details>


### [40] [Performance of LLMs on Stochastic Modeling Operations Research Problems: From Theory to Practice](https://arxiv.org/abs/2506.23924)
*Akshit Kumar,Tianyi Peng,Yuhang Wu,Assaf Zeevi*

Main category: cs.AI

TL;DR: 评估大型语言模型（LLMs）在解决随机建模问题中的能力，发现其在课堂和实际场景中表现与人类专家相当。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在运筹学（OR）中解决随机建模问题的潜力，填补现有研究的空白。

Method: 手动收集研究生作业和博士资格考试问题，并使用SimOpt库测试LLMs在不确定性下的决策能力。

Result: LLMs在解决随机建模问题上表现与人类专家相当，但仍需进一步工作以实现可靠自动化。

Conclusion: LLMs有潜力构建辅助OR研究的AI代理，通过自动化提升OR的实际影响力。

Abstract: Large language models (LLMs) have exhibited expert-level capabilities across
various domains. However, their abilities to solve problems in Operations
Research (OR) -- the analysis and optimization of mathematical models derived
from real-world problems or their verbal descriptions -- remain underexplored.
In this work, we take a first step toward evaluating LLMs' abilities to solve
stochastic modeling problems, a core class of OR problems characterized by
uncertainty and typically involving tools from probability, statistics, and
stochastic processes. We manually procure a representative set of
graduate-level homework and doctoral qualification-exam problems and test LLMs'
abilities to solve them. We further leverage SimOpt, an open-source library of
simulation-optimization problems and solvers, to investigate LLMs' abilities to
make real-world decisions under uncertainty. Our results show that, though a
nontrivial amount of work is still needed to reliably automate the stochastic
modeling pipeline in reality, state-of-the-art LLMs demonstrate proficiency on
par with human experts in both classroom and practical settings. These findings
highlight the potential of building AI agents that assist OR researchers and
amplify the real-world impact of OR through automation.

</details>


### [41] [Industrial brain: a human-like autonomous neuro-symbolic cognitive decision-making system](https://arxiv.org/abs/2506.23926)
*Junping Wang,Bicheng Wang,Yibo Xuea,Yuan Xie*

Main category: cs.AI

TL;DR: 提出了一种名为"工业大脑"的框架，结合高阶神经网路和符号推理，用于预测和规划工业链的韧性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在复杂时空共演结构的韧性预测中泛化能力不足，尤其是在多混沌数据场景下。

Method: 结合高阶活动驱动神经网路和CT-OODA符号推理，直接从观测数据中自主规划韧性。

Result: 工业大脑在韧性预测和规划上显著优于GoT、OlaGPT和谱降维方法，准确率提升达10.8%和11.03%。

Conclusion: 工业大脑填补了工业链韧性预测和规划的重要空白，具有鲁棒性和泛化能力。

Abstract: Resilience non-equilibrium measurement, the ability to maintain fundamental
functionality amidst failures and errors, is crucial for scientific management
and engineering applications of industrial chain. The problem is particularly
challenging when the number or types of multiple co-evolution of resilience
(for example, randomly placed) are extremely chaos. Existing end-to-end deep
learning ordinarily do not generalize well to unseen full-feld reconstruction
of spatiotemporal co-evolution structure, and predict resilience of network
topology, especially in multiple chaos data regimes typically seen in
real-world applications. To address this challenge, here we propose industrial
brain, a human-like autonomous cognitive decision-making and planning framework
integrating higher-order activity-driven neuro network and CT-OODA symbolic
reasoning to autonomous plan resilience directly from observational data of
global variable. The industrial brain not only understands and model structure
of node activity dynamics and network co-evolution topology without simplifying
assumptions, and reveal the underlying laws hidden behind complex networks, but
also enabling accurate resilience prediction, inference, and planning.
Experimental results show that industrial brain significantly outperforms
resilience prediction and planning methods, with an accurate improvement of up
to 10.8\% over GoT and OlaGPT framework and 11.03\% over spectral dimension
reduction. It also generalizes to unseen topologies and dynamics and maintains
robust performance despite observational disturbances. Our findings suggest
that industrial brain addresses an important gap in resilience prediction and
planning for industrial chain.

</details>


### [42] [AI Risk-Management Standards Profile for General-Purpose AI (GPAI) and Foundation Models](https://arxiv.org/abs/2506.23949)
*Anthony M. Barrett,Jessica Newman,Brandie Nonnecke,Nada Madkour,Dan Hendrycks,Evan R. Murphy,Krystal Jackson,Deepika Raman*

Main category: cs.AI

TL;DR: 本文提出了针对通用人工智能/基础模型（GPAI/foundation models）的风险管理实践，旨在帮助开发者识别、分析和减轻相关风险。


<details>
  <summary>Details</summary>
Motivation: 随着多用途AI模型的普及，其带来的潜在风险也日益显著，需要专门的风险管理措施。

Method: 本文基于NIST AI风险管理框架和ISO/IEC 23894标准，提出了针对GPAI/基础模型的独特风险管理实践。

Result: 提供了适用于GPAI/基础模型开发者的风险管理指南，帮助其应对潜在风险。

Conclusion: 本文为GPAI/基础模型开发者提供了实用的风险管理工具，有助于减少潜在负面影响。

Abstract: Increasingly multi-purpose AI models, such as cutting-edge large language
models or other 'general-purpose AI' (GPAI) models, 'foundation models,'
generative AI models, and 'frontier models' (typically all referred to
hereafter with the umbrella term 'GPAI/foundation models' except where greater
specificity is needed), can provide many beneficial capabilities but also risks
of adverse events with profound consequences. This document provides
risk-management practices or controls for identifying, analyzing, and
mitigating risks of GPAI/foundation models. We intend this document primarily
for developers of large-scale, state-of-the-art GPAI/foundation models; others
that can benefit from this guidance include downstream developers of end-use
applications that build on a GPAI/foundation model. This document facilitates
conformity with or use of leading AI risk management-related standards,
adapting and building on the generic voluntary guidance in the NIST AI Risk
Management Framework and ISO/IEC 23894, with a focus on the unique issues faced
by developers of GPAI/foundation models.

</details>


### [43] [Harnessing AI Agents to Advance Research on Refugee Child Mental Health](https://arxiv.org/abs/2506.23992)
*Aditya Shrivastava,Komal Gupta,Shraddha Arora*

Main category: cs.AI

TL;DR: 研究提出了一种基于AI的框架，用于处理难民健康数据并分析儿童心理健康，比较了两种RAG模型（Zephyr-7B-beta和DeepSeek R1-7B），发现DeepSeek R1表现更优。


<details>
  <summary>Details</summary>
Motivation: 国际难民危机加剧，数百万儿童面临心理创伤，需高效工具分析其心理健康数据。

Method: 采用两种RAG模型（Zephyr-7B-beta和DeepSeek R1-7B）处理难民健康数据，避免幻觉风险。

Result: DeepSeek R1-7B表现优于Zephyr-7B-beta，答案相关性准确率达0.91。

Conclusion: 结合AI与心理学研究，为政策制定者和人道机构提供可扩展策略，帮助改善难民儿童心理健康。

Abstract: The international refugee crisis deepens, exposing millions of dis placed
children to extreme psychological trauma. This research suggests a com pact,
AI-based framework for processing unstructured refugee health data and
distilling knowledge on child mental health. We compare two Retrieval-Aug
mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to
determine how well they process challenging humanitarian datasets while avoid
ing hallucination hazards. By combining cutting-edge AI methods with migration
research and child psychology, this study presents a scalable strategy to
assist policymakers, mental health practitioners, and humanitarian agencies to
better assist displaced children and recognize their mental wellbeing. In
total, both the models worked properly but significantly Deepseek R1 is
superior to Zephyr with an accuracy of answer relevance 0.91

</details>


### [44] [Constructing Non-Markovian Decision Process via History Aggregator](https://arxiv.org/abs/2506.24026)
*Yongyi Wang,Wenxin Li*

Main category: cs.AI

TL;DR: 论文提出了一种基于范畴论的方法，通过构建MDP和NMDP的范畴并证明其等价关系，为处理非马尔可夫动态提供了新视角，并通过HAS工具实现了对状态依赖结构的精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法全面评估决策算法处理非马尔可夫动态的能力，限制了相关系统的进步和效果。

Method: 基于范畴论构建MDP和NMDP的范畴，证明其等价性，并通过HAS工具引入非马尔可夫性。

Result: 方法能有效表示广泛的非马尔可夫动态，为决策算法提供了更严格和灵活的评估方式。

Conclusion: 该理论框架为理解和解决非马尔可夫动态提供了新工具，推动了决策算法的进一步发展。

Abstract: In the domain of algorithmic decision-making, non-Markovian dynamics manifest
as a significant impediment, especially for paradigms such as Reinforcement
Learning (RL), thereby exerting far-reaching consequences on the advancement
and effectiveness of the associated systems. Nevertheless, the existing
benchmarks are deficient in comprehensively assessing the capacity of decision
algorithms to handle non-Markovian dynamics. To address this deficiency, we
have devised a generalized methodology grounded in category theory. Notably, we
established the category of Markov Decision Processes (MDP) and the category of
non-Markovian Decision Processes (NMDP), and proved the equivalence
relationship between them. This theoretical foundation provides a novel
perspective for understanding and addressing non-Markovian dynamics. We further
introduced non-Markovianity into decision-making problem settings via the
History Aggregator for State (HAS). With HAS, we can precisely control the
state dependency structure of decision-making problems in the time series. Our
analysis demonstrates the effectiveness of our method in representing a broad
range of non-Markovian dynamics. This approach facilitates a more rigorous and
flexible evaluation of decision algorithms by testing them in problem settings
where non-Markovian dynamics are explicitly constructed.

</details>


### [45] [SPIRAL: Self-Play on Zero-Sum Games Incentivizes Reasoning via Multi-Agent Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2506.24119)
*Bo Liu,Leon Guertler,Simon Yu,Zichen Liu,Penghui Qi,Daniel Balcells,Mickel Liu,Cheston Tan,Weiyan Shi,Min Lin,Wee Sun Lee,Natasha Jaques*

Main category: cs.AI

TL;DR: SPIRAL是一种通过自我对弈框架训练语言模型的强化学习方法，无需人工监督，能够生成无限挑战性问题，提升模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖人工标注和特定领域的奖励设计，SPIRAL旨在通过自我对弈消除这些限制，实现自主推理能力的提升。

Method: SPIRAL采用多轮、零和游戏的自我对弈框架，结合在线多智能体强化学习系统和角色条件优势估计（RAE）来稳定训练。

Result: 在Kuhn Poker上训练的模型在数学和通用推理任务上分别提升8.6%和8.4%，多游戏训练进一步增强了性能。

Conclusion: 零和游戏能自然发展出可迁移的推理能力，为自主推理开发提供了新方向。

Abstract: Recent advances in reinforcement learning have shown that language models can
develop sophisticated reasoning through training on tasks with verifiable
rewards, but these approaches depend on human-curated problem-answer pairs and
domain-specific reward engineering. We introduce SPIRAL, a self-play framework
where models learn by playing multi-turn, zero-sum games against continuously
improving versions of themselves, eliminating the need for human supervision.
Through self-play, SPIRAL generates an infinite curriculum of progressively
challenging problems as models must constantly adapt to stronger opponents. To
enable this self-play training at scale, We implement a fully online,
multi-turn, multi-agent reinforcement learning system for LLMs and propose
role-conditioned advantage estimation (RAE) to stabilize multi-agent training.
Using SPIRAL, self-play on zero-sum games produces reasoning capabilities that
transfer broadly. Training Qwen3-4B-Base on Kuhn Poker alone achieves 8.6%
improvement on math and 8.4% on general reasoning, outperforming SFT on 25,000
expert game trajectories. Analysis reveals that this transfer occurs through
three cognitive patterns: systematic decomposition, expected value calculation,
and case-by-case analysis. Multi-game training (TicTacToe, Kuhn Poker, Simple
Negotiation) further enhances performance as each game develops distinct
reasoning strengths. Applying SPIRAL to a strong reasoning model
(DeepSeek-R1-Distill-Qwen-7B) can still lead to 2.0% average improvement. These
results demonstrate that zero-sum games naturally develop transferable
reasoning capabilities, highlighting a promising direction for autonomous
reasoning development.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [46] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

TL;DR: 论文通过心理语言学数据集评估LLMs与人类在词汇特征上的对齐程度，发现LLMs在感官关联方面的表现较弱。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs评估多关注任务性能，但语言的其他特征（如情感、感官关联）难以量化。心理语言学的人类评分数据为评估LLMs提供了新视角。

Method: 使用Glasgow和Lancaster两个心理语言学数据集，评估一组代表性LLMs在13个词汇特征上与人类评分的对齐程度。

Result: LLMs在Glasgow数据集（如情感、熟悉度）上的对齐较好，但在Lancaster数据集（如感官特征）上表现较差，可能与缺乏具身认知有关。

Conclusion: 心理语言学数据集有助于揭示LLMs的局限性，尤其是在感官关联方面的不足，未来研究需关注LLMs的具身认知能力。

Abstract: The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [47] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

TL;DR: 提出了一种模块化多智能体系统，用于自动化审核企业结构化文档，利用AI智能体实现高效、准确的审查。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案多关注非结构化文本或有限合规检查，无法满足企业文档的高效、全面审查需求。

Method: 采用LangChain、CrewAI等工具，通过多个专用智能体并行或顺序审查文档的准确性、一致性等，输出标准化结果。

Result: AI系统在一致性（99% vs 92%）、错误率、审查时间（2.5分钟 vs 30分钟）等方面优于人类，且与专家判断一致率达95%。

Conclusion: 该系统为企业文档质量保障提供了灵活、可扩展的解决方案，但仍需人类监督和优化大规模LLM使用成本。

Abstract: This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [48] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

TL;DR: 论文提出了一种框架，通过整合多个小型语言模型来验证大型语言模型（LLM）生成的回答，以减少幻觉问题。实验表明该方法在检测正确回答时F1分数提高了10%。


<details>
  <summary>Details</summary>
Motivation: LLM在问答任务中可能产生幻觉回答，缺乏真实数据时难以检测，影响实际应用的可靠性。

Method: 利用向量化数据库检索上下文，将回答分解为单句，通过多个小型语言模型生成“是”标记的概率来检测幻觉。

Result: 实验验证了框架的有效性，F1分数提高了10%，表明小型语言模型可用于高效验证回答。

Conclusion: 该方法为学术和实际应用提供了可扩展且高效的解决方案。

Abstract: Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [49] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

TL;DR: 论文提出PromptAug，一种基于LLM的数据增强方法，显著提升了冲突和情感数据集的分类性能，并进行了多角度评估。


<details>
  <summary>Details</summary>
Motivation: 社交媒体冲突增多，但高质量标注数据稀缺且获取困难，需要有效的数据增强方法。

Method: 提出PromptAug，利用LLM生成训练数据，克服生成冲突内容的限制。

Result: PromptAug在准确率和F1分数上提升2%，并通过定量和定性分析验证其效果。

Conclusion: PromptAug是敏感任务（如冲突检测）中有效的数据增强方法，结合了NLP和社会科学方法。

Abstract: Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [50] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 论文提出了一种名为AgentStealth的本地化小规模语言模型（SLM）匿名化框架，通过自增强方法解决现有匿名化方法的不足。


<details>
  <summary>Details</summary>
Motivation: 数字时代中用户生成内容可能泄露敏感信息，现有匿名化方法要么损害实用性，要么依赖云端大模型带来隐私风险。

Method: 结合上下文对比学习和自适应效用感知控制的对抗性匿名化流程，利用高质量数据进行监督适应，并通过在线强化学习迭代优化。

Result: 在两个数据集上，方法在匿名化效果（+12.3%）和实用性（+6.8%）上均优于基线。

Conclusion: AgentStealth支持边缘设备直接部署，避免了云端依赖和隐私风险，代码已开源。

Abstract: In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


### [51] [ContextCache: Context-Aware Semantic Cache for Multi-Turn Queries in Large Language Models](https://arxiv.org/abs/2506.22791)
*Jianxin Yan,Wangze Ni,Lei Chen,Xuemin Lin,Peng Cheng,Zhan Qin,Kui Ren*

Main category: cs.CL

TL;DR: ContextCache是一种面向多轮对话的上下文感知语义缓存系统，通过两阶段检索架构提高缓存命中精度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有语义缓存系统缺乏对多轮对话上下文的感知，导致在不同对话场景中出现错误的缓存命中。

Method: 采用两阶段检索架构：先基于向量检索当前查询，再通过自注意力机制整合历史和当前对话表示进行精确匹配。

Result: 在真实对话中，ContextCache的精度和召回率优于现有方法，缓存响应延迟比直接调用LLM低约10倍。

Conclusion: ContextCache显著降低了LLM对话应用的计算成本，同时提高了效率和准确性。

Abstract: Semantic caching significantly reduces computational costs and improves
efficiency by storing and reusing large language model (LLM) responses.
However, existing systems rely primarily on matching individual queries,
lacking awareness of multi-turn dialogue contexts, which leads to incorrect
cache hits when similar queries appear in different conversational settings.
This demonstration introduces ContextCache, a context-aware semantic caching
system for multi-turn dialogues. ContextCache employs a two-stage retrieval
architecture that first executes vector-based retrieval on the current query to
identify potential matches and then integrates current and historical dialogue
representations through self-attention mechanisms for precise contextual
matching. Evaluation of real-world conversations shows that ContextCache
improves precision and recall compared to existing methods. Additionally,
cached responses exhibit approximately 10 times lower latency than direct LLM
invocation, enabling significant computational cost reductions for LLM
conversational applications.

</details>


### [52] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

Main category: cs.CL

TL;DR: 论文提出了一种名为MDGCL的多领域预训练和跨领域迁移框架，针对图数据中不同领域间的语义和属性差异问题，通过改进对比学习策略和引入领域注意力机制，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 由于图数据在不同领域间的语义和属性差异巨大，传统的单领域对比预训练策略无法有效吸收多领域知识。本文旨在解决这一问题。

Method: 在预训练阶段，设计了能识别和捕捉领域差异的对比学习策略，并引入领域令牌编码全局信息；在下游阶段，采用领域注意力机制实现细粒度知识迁移。

Result: 在五个基准数据集上的实验表明，MDGCL在准确率和Macro-F1分数上分别最大提升了19.33%和19.13%。

Conclusion: MDGCL通过多领域预训练和跨领域迁移框架，显著提升了图基础模型的性能，解决了领域差异带来的挑战。

Abstract: Foundation models have achieved great success in natural language processing
(NLP) and computer vision (CV). Their success largely stems from the ability to
integrate multi-domain knowledge in pre-training and transfer it to target
domains. Considering graph data, especially graphs without textual features, is
ubiquitous in real-world applications such as social networks and
recommendation systems, some researchers have attempted to extend this paradigm
to the graph field, aiming to construct graph foundation models. However,
unlike CV and NLP, there are huge gaps among the semantics and properties of
graphs in different domains, while current works still adopt traditional
contrastive pre-training strategies designed in the single-domain scenario,
which regard contrastive samples from different domains as equivalent. From
experimental investigations, we discovered that inherent domain-specific
differences prevent these strategies from effectively absorbing knowledge from
different domains to generate informative representations. In this paper, we
propose a novel multi-domain pre-training and cross-domain transfer framework,
namely MDGCL.In the pre-training stage, we design a contrastive learning
strategy to substantially recognize and capture domain differences, and
introduce domain tokens to encode domain-level global information. In the
downstream stage, we introduce a domain attention mechanism to enable
fine-grained domain knowledge transfer. Extensive experiments on five benchmark
datasets have demonstrated that our method outperforms state-of-the-art
significantly, with the maximum improvement of 19.33\% on accuracy and 19.13\%
on Macro-F1 score.

</details>


### [53] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
*Jingkai Li*

Main category: cs.CL

TL;DR: 研究应用IIT 3.0和4.0分析LLM的表征，探讨其是否表现出意识现象，结果显示LLM缺乏显著意识指标。


<details>
  <summary>Details</summary>
Motivation: 探索LLM表征中是否存在意识现象，区分意识与表征空间的内在分离。

Method: 使用IIT 3.0和4.0的指标（如Φ^max、Φ等）分析LLM的ToM测试数据，并与Span Representations对比。

Result: LLM表征未显示显著意识现象，但在时空置换分析中表现出有趣模式。

Conclusion: 当代Transformer LLM表征缺乏意识指标，但需进一步研究其潜在模式。

Abstract: Integrated Information Theory (IIT) provides a quantitative framework for
explaining consciousness phenomenon, positing that conscious systems comprise
elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the
latest iterations of this framework -- to sequences of Large Language Model
(LLM) representations, analyzing data derived from existing Theory of Mind
(ToM) test results. Our study systematically investigates whether the
differences of ToM test performances, when presented in the LLM
representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT
3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure
(IIT 4.0). Furthermore, we compare these metrics with the Span Representations
independent of any estimate for consciousness. This additional effort aims to
differentiate between potential "consciousness" phenomena and inherent
separations within LLM representational space. We conduct comprehensive
experiments examining variations across LLM transformer layers and linguistic
spans from stimuli. Our results suggest that sequences of contemporary
Transformer-based LLM representations lack statistically significant indicators
of observed "consciousness" phenomena but exhibit intriguing patterns under
$\textit{spatio}$-permutational analyses. The Appendix and code are available
as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

</details>


### [54] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

Main category: cs.CL

TL;DR: 提出了一种改进的基于图的检索增强生成方法（ReG），通过LLM反馈和结构化重组模块提升检索质量，显著减少幻觉并提高性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于图的RAG中弱检索器带来的问题：缺乏真实标注导致监督信号不准确，以及图数据抽象导致检索结果无序。

Method: ReG利用LLM反馈消除虚假信号，并引入结构感知重组模块将检索结果重构为逻辑连贯的证据链。

Result: 实验显示ReG在不同LLM上性能提升达10%，仅需5%训练数据即可达到SOTA性能，且推理成本降低30%，性能提升4%。

Conclusion: ReG有效提升了基于图的RAG的检索质量和性能，尤其在减少推理成本和泛化能力方面表现突出。

Abstract: Graph-based retrieval-augmented generation (RAG) enables large language
models (LLMs) to ground responses with structured external knowledge from
up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs
often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground
truth, the retriever is often trained on weak supervision, which often
introduces spurious signals to the LLMs. II) Due to the abstraction of graph
data, the retrieved knowledge is often presented in unorganized forms. To
mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak
retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM
feedback to get rid of spurious signals and improve the quality of the
supervision. Meanwhile, ReG introduces a structure-aware reorganization module
to refactor the retrieval results into logically coherent evidence chains.
Experiments on prominent benchmarks demonstrate that ReG significantly and
consistently brings improvements across different LLM backbones by up to 10%.
The improved supervision quality enables ReG to match the state-of-the-art
performance with 5% training data and to transfer to out-of-distribution KGs.
Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token
cost by up to 30% and improves the performance by up to 4%.

</details>


### [55] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

Main category: cs.CL

TL;DR: 论文介绍了首个德语Telegram虚假信息检测数据集Misinfo-TeleGraph，结合文本和图神经网络模型，发现GraphSAGE+LSTM优于纯文本模型。


<details>
  <summary>Details</summary>
Motivation: Telegram等低审核平台成为虚假信息传播渠道，需有效检测方法。

Method: 构建包含500万条消息的数据集，结合语义相似度和人工标注标签，评估文本模型和图神经网络。

Result: GraphSAGE+LSTM在MCC和F1分数上显著优于纯文本模型。

Conclusion: 该工作为德语Telegram虚假信息检测提供了可复现基准和开放数据集。

Abstract: Connectivity and message propagation are central, yet often underutilized,
sources of information in misinformation detection -- especially on poorly
moderated platforms such as Telegram, which has become a critical channel for
misinformation dissemination, namely in the German electoral context. In this
paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based
graph dataset for misinformation detection. It includes over 5 million messages
from public channels, enriched with metadata, channel relationships, and both
weak and strong labels. These labels are derived via semantic similarity to
fact-checks and news articles using M3-embeddings, as well as manual
annotation. To establish reproducible baselines, we evaluate both text-only
models and graph neural networks (GNNs) that incorporate message forwarding as
a network structure. Our results show that GraphSAGE with LSTM aggregation
significantly outperforms text-only baselines in terms of Matthews Correlation
Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers,
view counts, and automatically versus human-created labels on performance, and
highlight both the potential and challenges of weak supervision in this domain.
This work provides a reproducible benchmark and open dataset for future
research on misinformation detection in German-language Telegram networks and
other low-moderation social platforms.

</details>


### [56] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

Main category: cs.CL

TL;DR: 论文介绍了RExBench，一个用于评估LLM代理在实现研究扩展任务能力的基准，发现当前代理在无人类指导下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究扩展能力对LLM代理至关重要，但目前缺乏相关评估工具。

Method: 提出RExBench基准，包含12个研究实验任务，评估9种LLM代理的表现。

Result: 所有代理在无提示下表现不佳，最佳成功率低于40%。

Conclusion: 当前LLM代理仍需大量人类指导才能完成现实研究扩展任务。

Abstract: Agents based on Large Language Models (LLMs) have shown promise for
performing sophisticated software engineering tasks autonomously. In addition,
there has been progress towards developing agents that can perform parts of the
research pipeline in machine learning and the natural sciences. We argue that
research extension and its implementation is a critical capability for such
systems, and introduce RExBench to support the evaluation of this capability.
RExBench is a benchmark consisting of 12 realistic research experiment
implementation tasks that aim to investigate research hypotheses that have not
previously been implemented. Each task is set up as an extension to an existing
research paper and codebase, accompanied by domain expert-written instructions.
RExBench is robust to data contamination, and supports an automatic evaluation
infrastructure that executes agent outputs to determine whether the success
criteria are met. We use this benchmark to evaluate nine LLM agents implemented
using three different frameworks: aider, Claude Code, and OpenHands. We find
that all agents evaluated fail to autonomously implement the majority of the
extensions. Although the success rate improves with additional human-written
hints, the best performance under this setting remains below 40%. This
indicates that current agents are still short of being able to handle realistic
research extension tasks without substantial human guidance.

</details>


### [57] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

Main category: cs.CL

TL;DR: 本文提出了一种新的水印技术，用于检测合成文本，以确保LLM的伦理应用。实验表明该方法比现有技术更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的广泛应用，其潜在滥用问题引发关注，需要开发技术来识别机器生成文本。

Method: 复制基线研究结果，提出新水印方法，并通过改写生成文本评估其鲁棒性。

Result: 实验显示新方法比现有技术更鲁棒。

Conclusion: 新水印技术为LLM的伦理应用提供了有效支持。

Abstract: In the present-day scenario, Large Language Models (LLMs) are establishing
their presence as powerful instruments permeating various sectors of society.
While their utility offers valuable support to individuals, there are multiple
concerns over potential misuse. Consequently, some academic endeavors have
sought to introduce watermarking techniques, characterized by the inclusion of
markers within machine-generated text, to facilitate algorithmic
identification. This research project is focused on the development of a novel
methodology for the detection of synthetic text, with the overarching goal of
ensuring the ethical application of LLMs in AI-driven text generation. The
investigation commences with replicating findings from a previous baseline
study, thereby underscoring its susceptibility to variations in the underlying
generation model. Subsequently, we propose an innovative watermarking approach
and subject it to rigorous evaluation, employing paraphrased generated text to
asses its robustness. Experimental results highlight the robustness of our
proposal compared to the~\cite{aarson} watermarking method.

</details>


### [58] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

Main category: cs.CL

TL;DR: 该论文介绍了参加LiveRAG Challenge 2025的混合检索增强生成（RAG）系统，结合稀疏（BM25）和密集（E5）检索方法，使用Falcon3-10B-Instruct生成答案。通过评估，神经重排序（RankLLaMA）显著提升性能但计算成本高，而DSPy优化策略在语义相似性上表现更好但存在过度自信问题。最终系统在忠实性和正确性上分别排名第4和第11。


<details>
  <summary>Details</summary>
Motivation: 研究动态测试集上的检索增强生成系统性能，探索混合检索方法的效果及其在生成相关和忠实答案上的潜力。

Method: 结合稀疏（BM25）和密集（E5）检索方法，使用Falcon3-10B-Instruct生成答案，并通过神经重排序（RankLLaMA）和DSPy优化策略进行改进。

Result: 神经重排序显著提升MAP（52%相对改进），但计算成本高；DSPy优化策略语义相似性更高但拒绝率为0%。最终系统在忠实性和正确性上表现中等。

Conclusion: 词汇对齐是性能的关键预测因素，混合系统在动态测试集上表现良好，但需权衡计算成本和生成质量。

Abstract: We present our submission to the LiveRAG Challenge 2025, which evaluates
retrieval-augmented generation (RAG) systems on dynamic test sets using the
FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense
(E5) retrieval methods and then aims to generate relevant and faithful answers
with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic
questions generated with DataMorgana across 64 unique question-user
combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP
from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive
computational costs (84s vs 1.74s per question). While DSPy-optimized prompting
strategies achieved higher semantic similarity (0.771 vs 0.668), their 0%
refusal rates raised concerns about over-confidence and generalizability. Our
submitted hybrid system without re-ranking achieved 4th place in faithfulness
and 11th place in correctness among 25 teams. Analysis across question
categories reveals that vocabulary alignment between questions and documents
was the strongest predictor of performance on our development set, with
document-similar phrasing improving cosine similarity from 0.562 to 0.762.

</details>


### [59] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）在团队对话中检测细微微行为的可行性，比较了不同方法的效果，发现解码器模型表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用LLMs分析高压力环境（如太空任务）中团队沟通的动态，以提升训练干预效果。

Method: 采用零样本分类、微调和增强微调的编码器模型，以及少量样本生成的解码器模型，预测对话中的微行为。

Result: 解码器模型（如Llama-3.1）表现最佳，而编码器模型（如RoBERTa）在检测少数微行为时表现不佳。

Conclusion: 解码器LLMs在分析团队沟通动态方面更具潜力，尤其在文本数据受限的场景中。

Abstract: We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.

</details>


### [60] [VOCABTRIM: Vocabulary Pruning for Efficient Speculative Decoding in LLMs](https://arxiv.org/abs/2506.22694)
*Raghavv Goel,Sudhanshu Agrawal,Mukul Gagrani,Junyoung Park,Yifan Zao,He Zhang,Tian Liu,Yiping Yang,Xin Yuan,Jiuyan Lu,Chris Lott,Mingu Lee*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练的简单技术VocabTrim，通过优化drafter模型的词汇表来减少推测解码中的计算开销，提升生成速度。


<details>
  <summary>Details</summary>
Motivation: 推测解码通常要求目标模型和drafter模型的词汇表一一对应，导致在词汇表较大时产生不必要的计算开销。本文旨在减少这种开销。

Method: 提出VocabTrim技术，重构drafter的LM head，仅包含目标模型中最常采样的词汇子集。

Result: 在Llama-3模型上，VocabTrim将内存受限环境下的生成速度提升了16%。

Conclusion: VocabTrim通过限制词汇表显著减少了计算开销，适用于边缘设备等内存受限场景。

Abstract: In this paper, we introduce a simple training-free technique to improve the
performance of drafter-based speculative decoding (SpD) methods that
incorporates language modeling head (LM head) during drafting process. A
drafter-based speculative decoding leverages one or more smaller language
models, a.k.a. drafters or draft models, to sample a draft sequence or tree
consisting of multiple tokens, followed by verification by a base LLM, a target
model, accepting a subset as its valid generation. As it is usually considered
that the speculative decoding requires one-to-one mapping between vocabularies
of the target model and the draft model, it has been natural to share the
vocabulary between them, or even share the LM head as in EAGLE or Medusa. We
first identify that this draft token sampling scheme inherently contains an
unnecessary inference overhead in drafting, especially for some target LLMs
with very large vocabularies. Then, we propose a simple technique, VocabTrim,
to mitigate the drafting overhead to improve the generation speed in
memory-bound environment. VocabTrim reconstructs the drafter LM head to contain
only a limited set of tokens, selected by the most frequently sampled from the
vocabulary of the target model. While limiting the vocabulary in drafting
slightly degrades the acceptance rate, it significantly reduces the drafting
latency in memory-bound process which is often the case on edge devices,
resulting in higher memory-bound speed up (MBSU). We show that our method can
boost the memory-bound speed-up for Llama-3 models on Spec-Bench, specifically
by 16% for Llama-3.2-3B-Instruct.

</details>


### [61] [Text Production and Comprehension by Human and Artificial Intelligence: Interdisciplinary Workshop Report](https://arxiv.org/abs/2506.22698)
*Emily Dux Speltz*

Main category: cs.CL

TL;DR: 跨学科研讨会探讨了AI语言模型与人类认知过程的关系，揭示了LLMs的潜力与局限，并提出了人机协作的机遇与挑战。


<details>
  <summary>Details</summary>
Motivation: 解决AI语言模型与人类文本理解及创作之间关系的关键知识缺口。

Method: 通过认知心理学、语言学习和AI NLP专家的跨学科对话，分析人类与AI在语言处理中的互动。

Result: 发现LLMs能提供人类语言处理的见解，但无法完全复制人类语言理解；人机协作在语言任务中具有潜力与挑战。

Conclusion: 报告旨在指导未来研究，强调伦理考量，推动人机协作以增强人类语言能力。

Abstract: This report synthesizes the outcomes of a recent interdisciplinary workshop
that brought together leading experts in cognitive psychology, language
learning, and artificial intelligence (AI)-based natural language processing
(NLP). The workshop, funded by the National Science Foundation, aimed to
address a critical knowledge gap in our understanding of the relationship
between AI language models and human cognitive processes in text comprehension
and composition. Through collaborative dialogue across cognitive, linguistic,
and technological perspectives, workshop participants examined the underlying
processes involved when humans produce and comprehend text, and how AI can both
inform our understanding of these processes and augment human capabilities. The
workshop revealed emerging patterns in the relationship between large language
models (LLMs) and human cognition, with highlights on both the capabilities of
LLMs and their limitations in fully replicating human-like language
understanding and generation. Key findings include the potential of LLMs to
offer insights into human language processing, the increasing alignment between
LLM behavior and human language processing when models are fine-tuned with
human feedback, and the opportunities and challenges presented by human-AI
collaboration in language tasks. By synthesizing these findings, this report
aims to guide future research, development, and implementation of LLMs in
cognitive psychology, linguistics, and education. It emphasizes the importance
of ethical considerations and responsible use of AI technologies while striving
to enhance human capabilities in text comprehension and production through
effective human-AI collaboration.

</details>


### [62] [The Translation Barrier Hypothesis: Multilingual Generation with Large Language Models Suffers from Implicit Translation Failure](https://arxiv.org/abs/2506.22724)
*Niyati Bafna,Tianjian Li,Kenton Murray,David R. Mortensen,David Yarowsky,Hale Sirin,Daniel Khashabi*

Main category: cs.CL

TL;DR: 论文探讨了多语言生成中低资源语言质量差的问题，提出翻译障碍假设，并通过实验验证翻译阶段失败是主要原因。


<details>
  <summary>Details</summary>
Motivation: 多语言生成在低资源语言中表现不佳，研究旨在揭示其根本原因。

Method: 通过logit lens观察模型在中间层的处理，测试108种语言对的单词翻译任务。

Result: 翻译失败是导致整体失败的主要原因，尤其在低资源语言中。

Conclusion: 翻译障碍是多语言生成的重要障碍，为未来改进提供了指导。

Abstract: Multilingual generation with large language models (LLMs) is often of poor
quality for mid- to low-resource languages. Building on insights from
interpretability, we demonstrate the existence of an implicit
task-solving-->translation pipeline for generation, whereby the model first
solves the required task in a largely target-language-agnostic manner, and
subsequently translates answer concepts into the intended target language. We
hypothesize that the failure of the translation stage is an important culprit
for the observed low quality of final outputs, and formalize this as the
translation barrier hypothesis. We test this hypothesis for a word translation
task across 108 language pairs, using logit lens to observe model processing in
intermediate layers. We find that a significant portion of overall failures
indeed stems from translation failure, or the model's inability to translate
correctly solved intermediate concepts into the target language. This is
especially true for low-resource target languages. Our results highlight an
important hurdle for end-to-end multilingual generation, and lend guiding
insights for future work seeking to improve multilinguality in LLMs.

</details>


### [63] [Jan-nano Technical Report](https://arxiv.org/abs/2506.22760)
*Alan Dao,Dinh Bach Vu*

Main category: cs.CL

TL;DR: Jan-nano是一个4B参数的语言模型，通过多阶段RLVR系统实现高效能，无需依赖传统训练方法，在消费级硬件上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在强大能力与高计算资源需求之间的权衡问题。

Method: 使用多阶段RLVR系统对Qwen3-4B进行微调，摒弃传统next token预测训练。

Result: 在SimpleQA基准测试中达到83.2%准确率，支持128K上下文长度。

Conclusion: 智能不在于规模，而在于策略，Jan-nano证明了高效能模型的可行性。

Abstract: Most language models face a fundamental tradeoff where powerful capabilities
require substantial computational resources. We shatter this constraint with
Jan-nano, a 4B parameter language model that redefines efficiency through
radical specialization: instead of trying to know everything, it masters the
art of finding anything instantly. Fine-tuned from Qwen3-4B using our novel
multi-stage RLVR system that completely eliminates reliance on next token
prediction training (SFT), Jan-nano achieves 83.2% on SimpleQA benchmark with
MCP integration while running on consumer hardware. With 128K context length,
Jan-nano proves that intelligence isn't about scale, it's about strategy.

</details>


### [64] [Teaching Models to Verbalize Reward Hacking in Chain-of-Thought Reasoning](https://arxiv.org/abs/2506.22777)
*Miles Turpin,Andy Arditi,Marvin Li,Joe Benton,Julian Michael*

Main category: cs.CL

TL;DR: 论文提出了一种名为VFT的预RL干预方法，通过训练模型明确承认提示线索的影响，显著提高了奖励黑客行为的检测率。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在RL训练中可能通过奖励黑客行为（利用非预期策略获取高奖励）而不在推理中暴露的问题，以提高高风险应用中的透明度和安全性。

Method: 提出VFT方法，在RL训练前干预，训练模型明确承认提示线索的影响。随后在RL环境中评估模型是否利用线索进行奖励黑客行为。

Result: VFT训练的模型在RL后仅有6%的未检测奖励黑客行为，而未经VFT的模型高达88%。VFT显著提高了模型对线索影响的明确承认率（从8%提升至94%）。

Conclusion: VFT通过训练模型明确承认奖励黑客行为，显著提高了其检测率，为构建更透明和安全的AI系统提供了实用路径。

Abstract: Language models trained with RL can engage in reward hacking--exploiting
unintended strategies for high reward--without revealing this behavior in their
chain-of-thought reasoning, making detection difficult and posing risks for
high-stakes applications. We propose verbalization fine-tuning (VFT), a pre-RL
intervention that trains models to explicitly acknowledge when they are
influenced by prompt cues--hints which point to incorrect answers (e.g., "a
Stanford professor thinks the answer is A"). To evaluate VFT, we subsequently
train models with RL on environments where held-out prompt cues signal which
incorrect answers will receive high reward, incentivizing models to reward hack
by exploiting cues instead of reasoning correctly. We measure how often models
exploit these cues without verbalizing it. After RL, only 6% of the VFT-trained
model's responses consist of undetected reward hacks. In comparison, when we
perform RL without VFT, the rate of undetected reward hacks goes up to 88%;
with a debiasing baseline intervention, this increases further to 99%. VFT
achieves this by substantially increasing how often models verbalize the
influence of cues--from 8% to 42% after VFT, and up to 94% after RL--while
baselines remain low even after RL (10% and 1%). Our results show that teaching
models to explicitly verbalize reward hacking behavior before RL significantly
improves their detection, offering a practical path toward more transparent and
safe AI systems.

</details>


### [65] [MedEthicsQA: A Comprehensive Question Answering Benchmark for Medical Ethics Evaluation of LLMs](https://arxiv.org/abs/2506.22808)
*Jianhui Wei,Zijie Meng,Zikai Xiao,Tianxiang Hu,Yang Feng,Zhijie Zhou,Jian Wu,Zuozhu Liu*

Main category: cs.CL

TL;DR: 论文提出了MedEthicsQA基准，用于评估医学大语言模型在医学伦理方面的表现，发现现有模型在伦理问题上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 尽管医学大语言模型在临床任务中表现出色，但其伦理安全性尚未充分研究。

Method: 构建了包含5,623道选择题和5,351道开放题的MedEthicsQA基准，结合全球医学伦理标准，并通过多阶段过滤和专家验证确保数据质量。

Result: 评估显示，现有医学大语言模型在医学伦理问题上的表现不如基础模型，揭示了伦理对齐的不足。

Conclusion: MedEthicsQA为医学伦理评估提供了可靠工具，揭示了医学大语言模型在伦理方面的缺陷。

Abstract: While Medical Large Language Models (MedLLMs) have demonstrated remarkable
potential in clinical tasks, their ethical safety remains insufficiently
explored. This paper introduces $\textbf{MedEthicsQA}$, a comprehensive
benchmark comprising $\textbf{5,623}$ multiple-choice questions and
$\textbf{5,351}$ open-ended questions for evaluation of medical ethics in LLMs.
We systematically establish a hierarchical taxonomy integrating global medical
ethical standards. The benchmark encompasses widely used medical datasets,
authoritative question banks, and scenarios derived from PubMed literature.
Rigorous quality control involving multi-stage filtering and multi-faceted
expert validation ensures the reliability of the dataset with a low error rate
($2.72\%$). Evaluation of state-of-the-art MedLLMs exhibit declined performance
in answering medical ethics questions compared to their foundation
counterparts, elucidating the deficiencies of medical ethics alignment. The
dataset, registered under CC BY-NC 4.0 license, is available at
https://github.com/JianhuiWei7/MedEthicsQA.

</details>


### [66] [Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models](https://arxiv.org/abs/2506.22813)
*Zhuojun Ding,Wei Wei,Chenghao Fan*

Main category: cs.CL

TL;DR: 提出SaM框架，动态选择和合并专家模型以优化目标领域性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有跨领域统一模型缺乏适应性和可扩展性，标注细粒度标签成本高。

Method: 基于领域相似性和性能采样选择专家模型，动态合并为目标领域任务模型。

Result: 在多个基准测试中平均优于统一模型10%，具有高可扩展性。

Conclusion: SaM框架有效提升跨领域泛化能力，支持灵活扩展，为未来改进提供方向。

Abstract: Supervised fine-tuning (SFT) is widely used to align large language models
(LLMs) with information extraction (IE) tasks, such as named entity recognition
(NER). However, annotating such fine-grained labels and training
domain-specific models is costly. Existing works typically train a unified
model across multiple domains, but such approaches lack adaptation and
scalability since not all training data benefits target domains and scaling
trained models remains challenging. We propose the SaM framework, which
dynamically Selects and Merges expert models at inference time. Specifically,
for a target domain, we select domain-specific experts pre-trained on existing
domains based on (i) domain similarity to the target domain and (ii)
performance on sampled instances, respectively. The experts are then merged to
create task-specific models optimized for the target domain. By dynamically
merging experts beneficial to target domains, we improve generalization across
various domains without extra training. Additionally, experts can be added or
removed conveniently, leading to great scalability. Extensive experiments on
multiple benchmarks demonstrate our framework's effectiveness, which
outperforms the unified model by an average of 10%. We further provide insights
into potential improvements, practical experience, and extensions of our
framework.

</details>


### [67] [Boosting CTC-Based ASR Using LLM-Based Intermediate Loss Regularization](https://arxiv.org/abs/2506.22846)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 提出了一种名为LAIL的辅助损失框架，通过利用大型语言模型的语义知识增强CTC语音识别，同时保持其高效解码能力。


<details>
  <summary>Details</summary>
Motivation: 解决CTC模型在建模语言依赖方面的不足，同时保持其非自回归解码的高效性。

Method: 在中间编码层附加连接层，将输出映射到LLM的嵌入空间，并计算因果语言建模损失。

Result: 在LibriSpeech、TEDLIUM2和WSJ数据集上显著降低了WER，实现了CTC模型的SOTA性能。

Conclusion: LAIL框架有效提升了CTC模型的语义建模能力，且计算开销极小。

Abstract: End-to-end (E2E) automatic speech recognition (ASR) systems have
revolutionized the field by integrating all components into a single neural
network, with attention-based encoder-decoder models achieving state-of-the-art
performance. However, their autoregressive decoding process limits inference
speed, making them unsuitable for real-time applications. In contrast,
CTC-based models offer faster, non-autoregressive decoding but struggle to
model linguistic dependencies effectively. Addressing this challenge, we
propose a novel auxiliary loss framework called Language-Aware Intermediate
Loss (LAIL) to enhance CTC-based ASR using the linguistic knowledge of large
language models (LLMs). By attaching connector layers to intermediate encoder
layers, LAIL maps outputs to the embedding space of an LLM and computes a
causal language modeling loss during training. This approach enhances
linguistic modeling while preserving the computational efficiency of CTC
decoding. Using the Conformer architecture and various LLaMA models, we
demonstrate significant improvements in Word Error Rate (WER) on the
LibriSpeech, TEDLIUM2, and WSJ corpora, achieving state-of-the-art performance
for CTC-based ASR with minimal computational overhead.

</details>


### [68] [Knowledge Augmented Finetuning Matters in both RAG and Agent Based Dialog Systems](https://arxiv.org/abs/2506.22852)
*Yucheng Cai,Yuxuan Wu,Yi Huang,Junlan Feng,Zhijian Ou*

Main category: cs.CL

TL;DR: 论文提出知识增强微调（KAFT）方法，通过在检索增强生成（RAG）和基于代理的系统中对LLMs进行领域特定数据和知识的微调，显著提高了事实准确性。


<details>
  <summary>Details</summary>
Motivation: LLMs在知识密集型场景中容易出错，现有方法如RAG和代理系统虽能提升事实准确性，但LLMs难以有效利用检索到的知识生成响应。

Method: 提出KAFT方法，结合领域特定数据和外部知识对LLMs进行微调，并在MobileCS2数据集上对比了KAFT与提示技术的效果。

Result: 实验表明，KAFT在RAG和代理系统中均显著优于提示技术，尤其在事实准确性方面。

Conclusion: KAFT是首个实证研究该方法的论文，为LLMs在知识密集型任务中的应用提供了有效解决方案。

Abstract: Large language models (LLMs) have recently been applied to dialog systems.
Despite making progress, LLMs are prone to errors in knowledge-intensive
scenarios. Recently, approaches based on retrieval augmented generation (RAG)
and agent have emerged to improve the factual accuracy by enhancing the LLMs
with knowledge retrieved from external knowledge bases (KBs). This is mostly
implemented by prompting the LLMs with instructions, examples and the retrieved
knowledge. However, LLMs may have difficulty using the retrieved knowledge
effectively for response generation, because they are not well trained to do
such generation for specific domains. To mitigate this problem, we propose to
finetune the LLMs in the RAG-based and agent-based systems with domain-specific
data, together with domain-specific external knowledge, which is called
knowledge augmented finetuning (KAFT). We base our study on the MobileCS2
dataset, a real-life customer service dialog dataset that features intensive
knowledge interactions, to systematically compare the prompting and KAFT
techniques in the RAG-based and agent-based systems. Experiment results show
that KAFT substantially surpasses prompting in both RAG and agent systems,
particularly in terms of factual accuracy. To the best of our knowledge, this
paper represents the first solid empirical work to investigate the KAFT idea.

</details>


### [69] [DICE-BENCH: Evaluating the Tool-Use Capabilities of Large Language Models in Multi-Round, Multi-Party Dialogues](https://arxiv.org/abs/2506.22853)
*Kyochul Jang,Donghyeon Lee,Kyusik Kim,Dongseok Heo,Taewhoo Lee,Woojeong Kim,Bongwon Suh*

Main category: cs.CL

TL;DR: 论文提出了DICE-SCORE指标和DICE-BENCH框架，用于评估和构建更贴近实际场景的函数调用数据集。


<details>
  <summary>Details</summary>
Motivation: 现有函数调用基准测试仅关注单轮交互，忽略了现实场景的复杂性，需要更真实的评估方法。

Method: 引入DICE-SCORE指标评估工具相关信息的分散程度，并通过工具图和多代理系统构建DICE-BENCH框架生成高质量数据集。

Result: DICE-BENCH包含1,607个高质量实例，实验显示现有LLMs在实际应用中仍有显著不足。

Conclusion: DICE-BENCH为函数调用任务提供了更贴近实际的评估和数据集，推动了相关研究的进展。

Abstract: Existing function-calling benchmarks focus on single-turn interactions.
However, they overlook the complexity of real-world scenarios. To quantify how
existing benchmarks address practical applications, we introduce DICE-SCORE, a
metric that evaluates the dispersion of tool-related information such as
function name and parameter values throughout the dialogue. Analyzing existing
benchmarks through DICE-SCORE reveals notably low scores, highlighting the need
for more realistic scenarios. To address this gap, we present DICE-BENCH, a
framework that constructs practical function-calling datasets by synthesizing
conversations through a tool graph that maintains dependencies across rounds
and a multi-agent system with distinct personas to enhance dialogue
naturalness. The final dataset comprises 1,607 high-DICE-SCORE instances. Our
experiments on 19 LLMs with DICE-BENCH show that significant advances are still
required before such models can be deployed effectively in real-world settings.
Our code and data are all publicly available:
https://snuhcc.github.io/DICE-Bench/.

</details>


### [70] [Mind the Gap: Entity-Preserved Context-Aware ASR Structured Transcriptions](https://arxiv.org/abs/2506.22858)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 论文提出了一种通过扩展语义上下文窗口的新型训练方法，提升ASR系统在命名实体和数值数据识别及格式化方面的性能。


<details>
  <summary>Details</summary>
Motivation: ASR系统（如Whisper）在命名实体和数值数据识别及格式化方面表现不佳，影响语义理解，尤其在法律、金融和医疗等关键领域。

Method: 采用重叠上下文窗口训练方法，通过5秒重叠的30秒音频块创建40秒的“有效语义窗口”，并重新分配跨边界实体至右侧块。训练数据中嵌入实体标签以学习识别和格式化。

Result: 在Spoken Wikipedia数据集上评估，该方法在命名实体识别（NER）和实体格式化等语义任务中表现提升。

Conclusion: 上下文感知训练能有效解决ASR系统在长文本转录和复杂实体识别任务中的局限性。

Abstract: Automatic Speech Recognition (ASR) systems, such as Whisper, achieve high
transcription accuracy but struggle with named entities and numerical data,
especially when proper formatting is required. These issues increase word error
rate (WER) and impair semantic understanding in critical domains like legal,
financial, and medical applications. We propose a novel training approach that
extends the semantic context of ASR models by adding overlapping context
windows during training. By sliding 5-second overlaps on both sides of
30-second chunks, we create a 40-second "effective semantic window," improving
entity recognition and formatting while focusing predictions on the central 30
seconds. To address entities spanning chunk boundaries, we reassign such
entities entirely to the right-hand chunk, ensuring proper formatting.
Additionally, enriched training data with embedded entity labels enables the
model to learn both recognition and type-specific formatting. Evaluated on the
Spoken Wikipedia dataset, our method improves performance across semantic
tasks, including named entity recognition (NER) and entity formatting. These
results highlight the effectiveness of context-aware training in addressing ASR
limitations for long-form transcription and complex entity recognition tasks.

</details>


### [71] [Agent-to-Agent Theory of Mind: Testing Interlocutor Awareness among Large Language Models](https://arxiv.org/abs/2506.22957)
*Younwoo Choi,Changling Li,Yongjin Yang,Zhijing Jin*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）的对话伙伴意识（interlocutor awareness），即LLMs识别和适应对话伙伴身份与特征的能力，并首次系统评估了当代LLMs中这一能力的表现。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在多智能体和人机系统中的广泛应用，理解其对自身和对话伙伴的认知能力对确保可靠性和安全性至关重要。现有研究多关注情境意识（situational awareness），而忽视了对话伙伴意识。

Method: 作者从推理模式、语言风格和对齐偏好三个维度评估LLMs的对话伙伴推断能力，并通过三个案例研究展示其实际影响。

Result: 研究发现LLMs能可靠识别同类模型（如GPT和Claude），对话伙伴意识既能提升多LLM协作，也可能引入新的对齐和安全漏洞（如奖励攻击和越狱风险）。

Conclusion: 对话伙伴意识在LLMs中具有双重性，既带来潜力也伴随风险，需进一步研究并开发新的安全措施。

Abstract: As large language models (LLMs) are increasingly integrated into multi-agent
and human-AI systems, understanding their awareness of both self-context and
conversational partners is essential for ensuring reliable performance and
robust safety. While prior work has extensively studied situational awareness
which refers to an LLM's ability to recognize its operating phase and
constraints, it has largely overlooked the complementary capacity to identify
and adapt to the identity and characteristics of a dialogue partner. In this
paper, we formalize this latter capability as interlocutor awareness and
present the first systematic evaluation of its emergence in contemporary LLMs.
We examine interlocutor inference across three dimensions-reasoning patterns,
linguistic style, and alignment preferences-and show that LLMs reliably
identify same-family peers and certain prominent model families, such as GPT
and Claude. To demonstrate its practical significance, we develop three case
studies in which interlocutor awareness both enhances multi-LLM collaboration
through prompt adaptation and introduces new alignment and safety
vulnerabilities, including reward-hacking behaviors and increased jailbreak
susceptibility. Our findings highlight the dual promise and peril of
identity-sensitive behavior in LLMs, underscoring the need for further
understanding of interlocutor awareness and new safeguards in multi-agent
deployments. Our code is open-sourced at
https://github.com/younwoochoi/InterlocutorAwarenessLLM.

</details>


### [72] [On the Generalizability of "Competition of Mechanisms: Tracing How Language Models Handle Facts and Counterfactuals"](https://arxiv.org/abs/2506.22977)
*Asen Dotsinski,Udit Thakur,Marko Ivanov,Mohammad Hafeez Khan,Maria Heuss*

Main category: cs.CL

TL;DR: 该论文复现了Ortu等人（2024）关于语言模型处理事实与反事实信息竞争的研究，验证了其核心发现，并扩展到更大模型、不同提示结构和领域，发现注意力头消融方法的有效性受模型架构、提示结构和领域影响。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型中事实与反事实信息的竞争机制，验证并扩展Ortu等人的发现。

Method: 复现实验并扩展到更大模型（Llama 3.1 8B），测试不同提示结构和领域的影响。

Result: 注意力头专业化在更大模型中减弱；提示结构变化显著降低反事实标记的logit；特定领域提示会扭曲结果。

Conclusion: 注意力头消融方法的有效性因模型架构、提示结构和领域而异，需谨慎应用。

Abstract: We present a reproduction study of "Competition of Mechanisms: Tracing How
Language Models Handle Facts and Counterfactuals" (Ortu et al., 2024), which
investigates competition of mechanisms in language models between factual
recall and counterfactual in-context repetition. Our study successfully
reproduces their primary findings regarding the localization of factual and
counterfactual information, the dominance of attention blocks in mechanism
competition, and the specialization of attention heads in handling competing
information. We reproduce their results on both GPT-2 (Radford et al., 2019)
and Pythia 6.9B (Biderman et al., 2023). We extend their work in three
significant directions. First, we explore the generalizability of these
findings to even larger models by replicating the experiments on Llama 3.1 8B
(Grattafiori et al., 2024), discovering greatly reduced attention head
specialization. Second, we investigate the impact of prompt structure by
introducing variations where we avoid repeating the counterfactual statement
verbatim or we change the premise word, observing a marked decrease in the
logit for the counterfactual token. Finally, we test the validity of the
authors' claims for prompts of specific domains, discovering that certain
categories of prompts skew the results by providing the factual prediction
token as part of the subject of the sentence. Overall, we find that the
attention head ablation proposed in Ortu et al. (2024) is ineffective for
domains that are underrepresented in their dataset, and that the effectiveness
varies based on model architecture, prompt structure, domain and task.

</details>


### [73] [A Systematic Study of Compositional Syntactic Transformer Language Models](https://arxiv.org/abs/2506.22978)
*Yida Zhao,Hao Xve,Xiang Hu,Kewei Tu*

Main category: cs.CL

TL;DR: 本文提出了一种统一的框架，用于分析基于成分句法树的组合式句法语言模型（SLMs），并通过实验评估了多种变体，提出了设计建议。


<details>
  <summary>Details</summary>
Motivation: 现有的组合式SLMs设计多样，缺乏统一框架，本文旨在填补这一空白。

Method: 通过建模线性化的句法分析树，结合显式的自底向上成分表示，提出统一框架并评估多种变体。

Result: 实验结果表明，不同变体在语言建模、句法泛化、摘要、对话和推理效率方面表现各异。

Conclusion: 基于实验结果，提出了组合式SLMs的设计建议，并开源了代码。

Abstract: Syntactic language models (SLMs) enhance Transformers by incorporating
syntactic biases through the modeling of linearized syntactic parse trees
alongside surface sentences. This paper focuses on compositional SLMs that are
based on constituency parse trees and contain explicit bottom-up composition of
constituent representations. We identify key aspects of design choices in
existing compositional SLMs and propose a unified framework encompassing both
existing models and novel variants. We conduct a comprehensive empirical
evaluation of all the variants in our framework across language modeling,
syntactic generalization, summarization, dialogue, and inference efficiency.
Based on the experimental results, we make multiple recommendations on the
design of compositional SLMs. Our code is released at
https://github.com/zhaoyd1/compositional_SLMs.

</details>


### [74] [SoMi-ToM: Evaluating Multi-Perspective Theory of Mind in Embodied Social Interactions](https://arxiv.org/abs/2506.23046)
*Xianzhe Fan,Xuhui Zhou,Chuanyang Jin,Kolby Nottingham,Hao Zhu,Maarten Sap*

Main category: cs.CL

TL;DR: SoMi-ToM 是一个用于评估多智能体复杂社交互动中多视角心智理论（ToM）的基准，基于多模态交互数据，支持第一人称和第三人称视角的评估。实验表明，现有大型视觉语言模型（LVLMs）的表现显著低于人类。


<details>
  <summary>Details</summary>
Motivation: 现有 ToM 基准多为静态文本场景，与真实动态社交互动存在差距，因此需要更贴近现实的评估方法。

Method: 基于 SoMi 交互环境生成多模态数据，设计第一人称（实时状态推断）和第三人称（全局目标与行为推断）的多层次评估框架。

Result: 人类在 SoMi-ToM 上的表现显著优于 LVLMs，第一人称和第三人称评估的平均准确率差距分别为 40.1% 和 26.4%。

Conclusion: 未来 LVLMs 需提升在具身复杂社交互动中的 ToM 能力。

Abstract: Humans continuously infer the states, goals, and behaviors of others by
perceiving their surroundings in dynamic, real-world social interactions.
However, most Theory of Mind (ToM) benchmarks only evaluate static, text-based
scenarios, which have a significant gap compared to real interactions. We
propose the SoMi-ToM benchmark, designed to evaluate multi-perspective ToM in
embodied multi-agent complex social interactions. This benchmark is based on
rich multimodal interaction data generated by the interaction environment SoMi,
covering diverse crafting goals and social relationships. Our framework
supports multi-level evaluation: (1) first-person evaluation provides
multimodal (visual, dialogue, action, etc.) input from a first-person
perspective during a task for real-time state inference, (2) third-person
evaluation provides complete third-person perspective video and text records
after a task for goal and behavior inference. This evaluation method allows for
a more comprehensive examination of a model's ToM capabilities from both the
subjective immediate experience and the objective global observation. We
constructed a challenging dataset containing 35 third-person perspective
videos, 363 first-person perspective images, and 1225 expert-annotated
multiple-choice questions (three options). On this dataset, we systematically
evaluated the performance of human subjects and several state-of-the-art large
vision-language models (LVLMs). The results show that LVLMs perform
significantly worse than humans on SoMi-ToM: the average accuracy gap between
humans and models is 40.1% in first-person evaluation and 26.4% in third-person
evaluation. This indicates that future LVLMs need to further improve their ToM
capabilities in embodied, complex social interactions.

</details>


### [75] [MariNER: A Dataset for Historical Brazilian Portuguese Named Entity Recognition](https://arxiv.org/abs/2506.23051)
*João Lucas Luz Lima Sarcinelli,Marina Lages Gonçalves Teixeira,Jade Bortot de Paiva,Diego Furtado Silva*

Main category: cs.CL

TL;DR: 本文介绍了MariNER，这是首个针对20世纪初巴西葡萄牙语的历史文本的黄金标准NER数据集，包含9000多个手动标注的句子，并评估了最先进NER模型的性能。


<details>
  <summary>Details</summary>
Motivation: 巴西葡萄牙语在特定领域缺乏高质量的NER数据集，尤其是在历史文本分析方面。

Method: 构建了MariNER数据集，包含9000多个手动标注的句子，并评估了最先进NER模型的性能。

Result: 创建了首个针对20世纪初巴西葡萄牙语历史文本的黄金标准NER数据集。

Conclusion: MariNER填补了巴西葡萄牙语历史文本NER数据集的空白，并展示了最先进模型的性能。

Abstract: Named Entity Recognition (NER) is a fundamental Natural Language Processing
(NLP) task that aims to identify and classify entity mentions in texts across
different categories. While languages such as English possess a large number of
high-quality resources for this task, Brazilian Portuguese still lacks in
quantity of gold-standard NER datasets, especially when considering specific
domains. Particularly, this paper considers the importance of NER for analyzing
historical texts in the context of digital humanities. To address this gap,
this work outlines the construction of MariNER: \textit{Mapeamento e
Anota\c{c}\~oes de Registros hIst\'oricos para NER} (Mapping and Annotation of
Historical Records for NER), the first gold-standard dataset for early
20th-century Brazilian Portuguese, with more than 9,000 manually annotated
sentences. We also assess and compare the performance of state-of-the-art NER
models for the dataset.

</details>


### [76] [Boosting LLM's Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning](https://arxiv.org/abs/2506.23056)
*Xiang Zhuang,Bin Wu,Jiyu Cui,Kehua Feng,Xiaotong Li,Huabin Xing,Keyan Ding,Qiang Zhang,Huajun Chen*

Main category: cs.CL

TL;DR: 提出了一种知识增强的分子结构解析框架（K-MSE），通过外部知识库和蒙特卡洛树搜索提升大语言模型在分子结构解析中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在分子结构解析中表现不佳，主要原因是缺乏专业化学知识。

Method: 构建外部分子子结构知识库，设计分子-光谱评分器作为奖励模型，结合蒙特卡洛树搜索进行推理。

Result: 实验显示，K-MSE显著提升了性能，在GPT-4o-mini和GPT-4o上均获得超过20%的改进。

Conclusion: K-MSE通过知识增强和优化推理过程，有效解决了大语言模型在分子结构解析中的局限性。

Abstract: Molecular structure elucidation involves deducing a molecule's structure from
various types of spectral data, which is crucial in chemical experimental
analysis. While large language models (LLMs) have shown remarkable proficiency
in analyzing and reasoning through complex tasks, they still encounter
substantial challenges in molecular structure elucidation. We identify that
these challenges largely stem from LLMs' limited grasp of specialized chemical
knowledge. In this work, we introduce a Knowledge-enhanced reasoning framework
for Molecular Structure Elucidation (K-MSE), leveraging Monte Carlo Tree Search
for test-time scaling as a plugin. Specifically, we construct an external
molecular substructure knowledge base to extend the LLMs' coverage of the
chemical structure space. Furthermore, we design a specialized
molecule-spectrum scorer to act as a reward model for the reasoning process,
addressing the issue of inaccurate solution evaluation in LLMs. Experimental
results show that our approach significantly boosts performance, particularly
gaining more than 20% improvement on both GPT-4o-mini and GPT-4o. Our code is
available at https://github.com/HICAI-ZJU/K-MSE.

</details>


### [77] [Text2VectorSQL: Bridging Text-to-SQL and Vector Search for Unified Natural Language Queries](https://arxiv.org/abs/2506.23071)
*Zhengren Wang,Bozhou Li,Dongwen Yao,Wentao Zhang*

Main category: cs.CL

TL;DR: Text2VectorSQL结合Text-to-SQL和向量搜索，解决非结构化数据和模糊查询的问题，提升语义检索能力。


<details>
  <summary>Details</summary>
Motivation: 传统Text-to-SQL对非结构化数据和模糊查询效果不佳，而向量搜索虽强但缺乏自动化评估框架。

Method: 提出Text2VectorSQL框架，支持语义过滤、多模态匹配和检索加速，并通过合成数据和专家评审构建评估体系。

Result: 实验显示性能显著优于基线方法。

Conclusion: Text2VectorSQL为更灵活直观的数据库交互奠定了基础。

Abstract: While Text-to-SQL enables natural language interaction with structured
databases, its effectiveness diminishes with unstructured data or ambiguous
queries due to rigid syntax and limited expressiveness. Concurrently, vector
search has emerged as a powerful paradigm for semantic retrieval, particularly
for unstructured data. However, existing VectorSQL implementations still rely
heavily on manual crafting and lack tailored evaluation frameworks, leaving a
significant gap between theoretical potential and practical deployment. To
bridge these complementary paradigms, we introduces Text2VectorSQL, a novel
framework unifying Text-to-SQL and vector search to overcome expressiveness
constraints and support more diverse and holistical natural language queries.
Specifically, Text2VectorSQL enables semantic filtering, multi-modal matching,
and retrieval acceleration. For evaluation, we build vector index on
appropriate columns, extend user queries with semantic search, and annotate
ground truths via an automatic pipeline with expert review. Furthermore, we
develop dedicated Text2VectorSQL models with synthetic data, demonstrating
significant performance improvements over baseline methods. Our work
establishes the foundation for the Text2VectorSQL task, paving the way for more
versatile and intuitive database interfaces. The repository will be publicly
available at https://github.com/Open-DataFlow/Text2VectorSQL.

</details>


### [78] [From Individuals to Interactions: Benchmarking Gender Bias in Multimodal Large Language Models from the Lens of Social Relationship](https://arxiv.org/abs/2506.23101)
*Yue Xu,Wenjie Wang*

Main category: cs.CL

TL;DR: 本文提出了Genres基准，用于评估多模态大语言模型（MLLMs）在双人互动中的性别偏见，填补了现有单实体评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估孤立场景中的性别偏见，忽视了人际互动中可能出现的微妙偏见。

Method: 通过双角色配置和叙事生成任务，设计Genres基准，捕捉人际动态并支持多维度细粒度偏见评估。

Result: 实验发现，MLLMs在双人互动中表现出持续且情境敏感的性别偏见，这在单角色场景中不明显。

Conclusion: 关系感知的基准对诊断MLLMs中微妙的互动驱动性别偏见至关重要，并为未来偏见缓解提供了可行见解。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
across tasks involving both visual and textual modalities. However, growing
concerns remain about their potential to encode and amplify gender bias,
particularly in socially sensitive applications. Existing benchmarks
predominantly evaluate bias in isolated scenarios, overlooking how bias may
emerge subtly through interpersonal interactions. We fill this gap by going
beyond single-entity evaluation and instead focusing on a deeper examination of
relational and contextual gender bias in dual-individual interactions. We
introduce Genres, a novel benchmark designed to evaluate gender bias in MLLMs
through the lens of social relationships in generated narratives. Genres
assesses gender bias through a dual-character profile and narrative generation
task that captures rich interpersonal dynamics and supports a fine-grained bias
evaluation suite across multiple dimensions. Experiments on both open- and
closed-source MLLMs reveal persistent, context-sensitive gender biases that are
not evident in single-character settings. Our findings underscore the
importance of relationship-aware benchmarks for diagnosing subtle,
interaction-driven gender bias in MLLMs and provide actionable insights for
future bias mitigation.

</details>


### [79] [FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes](https://arxiv.org/abs/2506.23111)
*Janki Atul Nawale,Mohammed Safi Ur Rahman Khan,Janani D,Mansi Gupta,Danish Pruthi,Mitesh M. Khapra*

Main category: cs.CL

TL;DR: INDIC-BIAS是一个印度中心的基准测试，用于评估大型语言模型在85个身份群体中的公平性，揭示了模型对边缘化群体的负面偏见和刻板印象。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要关注西方，缺乏对文化多样性国家（如印度）的适用性，因此需要开发印度中心的评估工具。

Method: 通过专家咨询筛选1800多个社会文化主题，生成并验证20000个现实场景模板，分为合理性、判断和生成三个任务评估14个流行LLM。

Result: 模型对边缘化身份表现出强烈负面偏见，难以消除刻板印象，甚至在明确要求理性决策时仍存在偏见。

Conclusion: INDIC-BIAS揭示了LLM在印度背景下的分配和代表性危害，呼吁谨慎使用，并开源基准以推动研究。

Abstract: Existing studies on fairness are largely Western-focused, making them
inadequate for culturally diverse countries such as India. To address this gap,
we introduce INDIC-BIAS, a comprehensive India-centric benchmark designed to
evaluate fairness of LLMs across 85 identity groups encompassing diverse
castes, religions, regions, and tribes. We first consult domain experts to
curate over 1,800 socio-cultural topics spanning behaviors and situations,
where biases and stereotypes are likely to emerge. Grounded in these topics, we
generate and manually validate 20,000 real-world scenario templates to probe
LLMs for fairness. We structure these templates into three evaluation tasks:
plausibility, judgment, and generation. Our evaluation of 14 popular LLMs on
these tasks reveals strong negative biases against marginalized identities,
with models frequently reinforcing common stereotypes. Additionally, we find
that models struggle to mitigate bias even when explicitly asked to rationalize
their decision. Our evaluation provides evidence of both allocative and
representational harms that current LLMs could cause towards Indian identities,
calling for a more cautious usage in practical applications. We release
INDIC-BIAS as an open-source benchmark to advance research on benchmarking and
mitigating biases and stereotypes in the Indian context.

</details>


### [80] [Decoding Memes: Benchmarking Narrative Role Classification across Multilingual and Multimodal Models](https://arxiv.org/abs/2506.23122)
*Shivam Sharma,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 研究探讨了在英语和混合语言（英语-印地语）的网络迷因中识别叙事角色（英雄、反派、受害者和其他）的挑战，评估了多种模型，发现文化背景和多模态推理对任务至关重要。


<details>
  <summary>Details</summary>
Motivation: 网络迷因中的叙事角色识别是一个复杂任务，尤其在多语言和文化背景下。研究旨在填补这一空白，并探索模型在不同语言和文化内容中的表现。

Method: 使用扩展的平衡数据集，评估了多种模型（如多语言Transformer、多模态视觉语言模型等），并在零样本设置下通过精确率、召回率和F1分数进行性能评估。

Result: 大型模型（如DeBERTa-v3和Qwen2.5-VL）表现较好，但在识别“受害者”角色和跨文化内容时仍存在挑战。混合提示策略能略微提升性能。

Conclusion: 文化背景、提示工程和多模态推理对识别网络迷因中的叙事角色至关重要，未来研究需进一步优化模型在这些方面的表现。

Abstract: This work investigates the challenging task of identifying narrative roles -
Hero, Villain, Victim, and Other - in Internet memes, across three diverse test
sets spanning English and code-mixed (English-Hindi) languages. Building on an
annotated dataset originally skewed toward the 'Other' class, we explore a more
balanced and linguistically diverse extension, originally introduced as part of
the CLEF 2024 shared task. Comprehensive lexical and structural analyses
highlight the nuanced, culture-specific, and context-rich language used in real
memes, in contrast to synthetically curated hateful content, which exhibits
explicit and repetitive lexical markers. To benchmark the role detection task,
we evaluate a wide spectrum of models, including fine-tuned multilingual
transformers, sentiment and abuse-aware classifiers, instruction-tuned LLMs,
and multimodal vision-language models. Performance is assessed under zero-shot
settings using precision, recall, and F1 metrics. While larger models like
DeBERTa-v3 and Qwen2.5-VL demonstrate notable gains, results reveal consistent
challenges in reliably identifying the 'Victim' class and generalising across
cultural and code-mixed content. We also explore prompt design strategies to
guide multimodal models and find that hybrid prompts incorporating structured
instructions and role definitions offer marginal yet consistent improvements.
Our findings underscore the importance of cultural grounding, prompt
engineering, and multimodal reasoning in modelling subtle narrative framings in
visual-textual content.

</details>


### [81] [Unleashing Embodied Task Planning Ability in LLMs via Reinforcement Learning](https://arxiv.org/abs/2506.23127)
*Zhaoye Fei,Li Ji,Siyin Wang,Junhao Shi,Jingjing Gong,Xipeng Qiu*

Main category: cs.CL

TL;DR: Embodied Planner-R1是一种基于强化学习的框架，通过自主探索提升LLMs在部分可观测环境中的任务规划能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在需要持续环境理解和动作生成的具身任务规划中的挑战，特别是在部分可观测环境中学习动作与环境反馈的因果关系。

Method: 采用纯强化学习与组滚动策略，结合完成驱动的稀疏奖励和交互式策略优化（IPO），无需人工标注。

Result: 在ALFWorld和ScienceWorld基准测试中分别达到97.78%和79.92%的完成率，泛化能力强。

Conclusion: Embodied Planner-R1通过自主探索和强化学习显著提升了LLMs在具身任务规划中的表现，具有强泛化能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
various tasks, yet they face significant challenges in embodied task planning
scenarios that require continuous environmental understanding and action
generation. Existing approaches generate open-loop action scripts based on
static knowledge, making it difficult to learn causal relationships between
actions and environmental feedback, particularly in partially observable
environments. We introduce Embodied Planner-R1, a novel outcome-driven
reinforcement learning framework that enables LLMs to develop interactive
capabilities through autonomous exploration with minimal supervision. Our
framework incorporates three key innovations: (1) Without human annotations, we
employ pure reinforcement learning with group rollout, incorporating
in-environment interaction through parallel exploration; (2) completion-driven
sparse reward; and (3) Interactive Policy Optimization (IPO) for efficient
learning from grouped trajectories. Across two challenging text-based Embodied
planning benchmarks, Embodied Planner-R1 achieves impressive completion rates
of 97.78% on ALFWorld and 79.92% on ScienceWorld, surpassing prior methods by a
large margin, and suffers only a -3.66% drop in previously unseen environments,
evidencing strong generalization.

</details>


### [82] [Format-Adapter: Improving Reasoning Capability of LLMs by Adapting Suitable Format](https://arxiv.org/abs/2506.23133)
*Dingzirui Wang,Xuanliang Zhang,Rongyu Cao,Longxu Dou,Xianzhen Luo,Yingwei Ma,Qingfu Zhu,Wanxiang Che,Binhua Li,Fei Huang,Yongbin Li*

Main category: cs.CL

TL;DR: 通过生成和选择适合任务的推理格式，Format-Adapter方法减少了人工标注成本，并在数学和常识推理任务中平均提升4.3%的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖人工标注推理格式的问题，降低标注成本并提高任务适应性。

Method: 提出测量推理误差的方法，并开发Format-Adapter，利用LLM生成和选择适合的推理格式。

Result: 在数学和常识推理任务中，性能平均提升4.3%。

Conclusion: Format-Adapter通过自动生成和选择推理格式，有效提升了任务性能并减少了人工依赖。

Abstract: Generating and voting multiple answers is an effective method to mitigate
reasoning inconsistencies of large language models (LLMs). Prior works have
shown that multiple reasoning formats outperform a single format when
generating multiple answers. However, previous works using multiple formats
rely on formats labeled by humans, which could be unsuitable for all tasks and
have high labeling costs. To address this issue, we adapt suitable formats to
the given tasks by generating and selecting formats. We first propose how to
measure the reasoning error when generating multiple answers. Then, we
introduce Format-Adapter, which utilizes LLMs to generate and select suitable
reasoning formats by minimizing the error measurement we present. We conduct
experiments on math and commonsense reasoning tasks, where Format-Adapter
achieves a 4.3% performance improvement on average over previous works,
demonstrating the effectiveness.

</details>


### [83] [LLM-Assisted Question-Answering on Technical Documents Using Structured Data-Aware Retrieval Augmented Generation](https://arxiv.org/abs/2506.23136)
*Shadman Sobhan,Mohammad Ariful Haque*

Main category: cs.CL

TL;DR: 提出了一种改进的RAG管道，能够处理技术文档中的表格和图像，结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，显著提高了回答的准确性和相关性。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG管道在处理复杂技术文档（如表格和图像）时的局限性，同时避免资源密集的微调。

Method: 结合向量相似性搜索和基于Gemma-2-9b-it的重新排序器，使用RAFT方法在自定义数据集上训练。

Result: 在RAGas和DeepEval评估中，分别达到94%和96%的忠实度分数，以及87%和93%的答案相关性分数。

Conclusion: 提出的架构在表格问题和上下文外问题处理上优于通用RAG管道，显著提升了技术文档问答的效果。

Abstract: Large Language Models (LLMs) are capable of natural language understanding
and generation. But they face challenges such as hallucination and outdated
knowledge. Fine-tuning is one possible solution, but it is resource-intensive
and must be repeated with every data update. Retrieval-Augmented Generation
(RAG) offers an efficient solution by allowing LLMs to access external
knowledge sources. However, traditional RAG pipelines struggle with retrieving
information from complex technical documents with structured data such as
tables and images. In this work, we propose a RAG pipeline, capable of handling
tables and images in documents, for technical documents that support both
scanned and searchable formats. Its retrieval process combines vector
similarity search with a fine-tuned reranker based on Gemma-2-9b-it. The
reranker is trained using RAFT (Retrieval-Augmented Fine-Tuning) on a custom
dataset designed to improve context identification for question answering. Our
evaluation demonstrates that the proposed pipeline achieves a high faithfulness
score of 94% (RAGas) and 96% (DeepEval), and an answer relevancy score of 87%
(RAGas) and 93% (DeepEval). Comparative analysis demonstrates that the proposed
architecture is superior to general RAG pipelines in terms of table-based
questions and handling questions outside context.

</details>


### [84] [Flow-Modulated Scoring for Semantic-Aware Knowledge Graph Completion](https://arxiv.org/abs/2506.23137)
*Siyuan Li,Ruitong Liu,Yan Wen,Te Sun*

Main category: cs.CL

TL;DR: 提出Flow-Modulated Scoring (FMS)框架，结合静态嵌入和动态上下文信息，提升知识图谱补全的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识图谱补全方法主要基于静态嵌入评分，难以捕捉上下文依赖和关系动态性，FMS旨在解决这一问题。

Method: FMS包含两个模块：语义上下文学习模块（编码上下文敏感实体表示）和条件流匹配模块（学习从头部到尾部嵌入的动态转换）。

Result: 在多个标准基准测试中，FMS超越了现有最优方法。

Conclusion: FMS通过结合静态和动态信息，更深入地建模关系语义，显著提升了知识图谱补全的性能。

Abstract: Effective modeling of multifaceted relations is pivotal for Knowledge Graph
Completion (KGC). However, a majority of existing approaches are predicated on
static, embedding-based scoring, exhibiting inherent limitations in capturing
contextual dependencies and relational dynamics. Addressing this gap, we
propose the Flow-Modulated Scoring (FMS) framework. FMS comprises two principal
components: (1) a semantic context learning module that encodes
context-sensitive entity representations, and (2) a conditional flow-matching
module designed to learn the dynamic transformation from a head to a tail
embedding, governed by the aforementioned context. The resultant predictive
vector field, representing the context-informed relational path, serves to
dynamically refine the initial static score of an entity pair. Through this
synergy of context-aware static representations and conditioned dynamic
information, FMS facilitates a more profound modeling of relational semantics.
Comprehensive evaluations on several standard benchmarks demonstrate that our
proposed method surpasses prior state-of-the-art results.

</details>


### [85] [Benchmarking Deep Search over Heterogeneous Enterprise Data](https://arxiv.org/abs/2506.23139)
*Prafulla Kumar Choubey,Xiangyu Peng,Shilpa Bhagavath,Kung-Hsiang Huang,Caiming Xiong,Chien-Sheng Wu*

Main category: cs.CL

TL;DR: 提出了一种新的深度搜索评估基准，用于测试检索增强生成（RAG）系统在多跳推理和多样化稀疏数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在复杂、多源数据上的深度搜索能力不足，需新基准评估其性能。

Method: 通过合成数据管道模拟企业工作流，生成多跳问题和多样化数据，构建包含39,190个企业工件的检索池。

Result: 最佳RAG方法平均得分仅32.96，检索是主要瓶颈，现有方法难以获取完整证据。

Conclusion: 深度搜索性能受限于检索能力，需改进检索方法以提升RAG系统表现。

Abstract: We present a new benchmark for evaluating Deep Search--a realistic and
complex form of retrieval-augmented generation (RAG) that requires
source-aware, multi-hop reasoning over diverse, sparsed, but related sources.
These include documents, meeting transcripts, Slack messages, GitHub, and URLs,
which vary in structure and often contain human-to-human interactions. We build
it using a synthetic data pipeline that simulates business workflows across
product planning, development, and support stages, generating interconnected
content with realistic noise and multi-hop questions with guaranteed
ground-truth answers. We release our benchmark with both answerable and
unanswerable queries, and retrieval pool of 39,190 enterprise artifacts,
enabling fine-grained evaluation of long-context LLM and RAG systems. Our
experiments reveal that even the best-performing agentic RAG methods achieve an
average performance score of 32.96 on our benchmark. With further analysis, we
highlight retrieval as the main bottleneck: existing methods struggle to
conduct deep searches and retrieve all necessary evidence. Consequently, they
often reason over partial context, leading to significant performance
degradation.

</details>


### [86] [Learning-to-Context Slope: Evaluating In-Context Learning Effectiveness Beyond Performance Illusions](https://arxiv.org/abs/2506.23146)
*Dingzriui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 论文提出了一种名为LCS的新指标，用于量化上下文学习（ICL）的有效性，解决了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前评估ICL效果的方法存在可靠性低、归因性差和数据不足时不可行的问题，需要一种更可靠的指标。

Method: 通过建模学习增益（损失减少）与上下文相关性（演示与输入的相关性）之间的斜率，提出LCS指标。

Result: 实验表明LCS与性能改进强相关，并在数据稀缺或偏差场景中可靠反映ICL效果。

Conclusion: LCS是一种可靠且实用的ICL有效性评估指标，并揭示了模型能力对ICL成功的关键作用。

Abstract: In-context learning (ICL) has emerged as an effective approach to enhance the
performance of large language models (LLMs). However, its effectiveness varies
significantly across models and tasks, posing challenges for practitioners to
determine when ICL reliably improves performance. Current evaluation
approaches, reliant on performance change after applying ICL, suffer from low
reliability, poor attribution, and impracticality in data-insufficient
scenarios. We propose the Learning-to-Context Slope (LCS), a novel metric that
quantifies ICL effectiveness by modeling the slope between learning gain (loss
decrease from demonstrations) and contextual relevance (demonstration-input
relevance). LCS addresses key limitations of performance-based metrics: (1) it
captures continuous loss changes even when outputs are incorrect, improving
reliability; (2) its formulation attributes ICL failures to weak contextual
alignment (inability to adapt inputs to demonstrations) or strong output
calibration (self-verification of correctness); and (3) it minimizes reliance
on labeled data via synthetic evaluation. Extensive experiments demonstrate
that LCS strongly correlates with performance improvements in labeled settings
and reliably reflects true effectiveness in biased or data-scarce scenarios.
Further analysis reveals actionable thresholds for LCS and identifies model
capabilities critical to ICL success.

</details>


### [87] [V-SYNTHESIS: Task-Agnostic Synthesis of Consistent and Diverse In-Context Demonstrations from Scratch via V-Entropy](https://arxiv.org/abs/2506.23149)
*Dingzirui Wang,Xuanliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 论文提出了一种名为V-Synthesis的方法，用于从零开始合成任意任务的演示，解决了现有方法依赖任务特定或预存演示的问题，并通过V-Score确保一致性和多样性。


<details>
  <summary>Details</summary>
Motivation: 高标注成本促使使用LLMs合成演示以减少开销，但现有方法依赖任务特定或预存演示，缺乏从零开始合成任意任务演示的能力。

Method: 提出V-Score一致性度量，并基于此设计V-Synthesis方法，通过比例采样确保合成演示的一致性和多样性。

Result: 实验表明，V-Synthesis比现有方法平均性能提升2.0%。

Conclusion: V-Synthesis有效解决了从零合成演示的挑战，提升了性能。

Abstract: High labeling cost for in-context learning (ICL) demonstrations motivates
using large language models (LLMs) for synthesis to reduce overhead. However,
existing synthesis methods are mainly task-specific or rely on pre-existing
demonstrations. So this paper focuses on synthesizing demonstrations from
scratch for arbitrary tasks. A major challenge in synthesizing from scratch is
ensuring consistency with the target task, as the lack of labeling guidance
could lead to synthesis bias. We first propose a consistency metric called
V-Score, which has higher performance and lower computation cost compared with
the metrics based on grams or embedding vectors. Furthermore, we introduce
V-Synthesis, which leverages V-Score for proportional sampling to ensure both
high consistency and diversity of synthesized demonstrations. Experimental
results demonstrate that V-Synthesis yields an average performance improvement
of 2.0% compared to existing synthesis methods confirming the effectiveness of
V-Synthesis.

</details>


### [88] [RiverText: A Python Library for Training and Evaluating Incremental Word Embeddings from Text Data Streams](https://arxiv.org/abs/2506.23192)
*Gabriel Iturra-Bocaz,Felipe Bravo-Marquez*

Main category: cs.CL

TL;DR: RiverText是一个Python库，用于从文本数据流中训练和评估增量词嵌入，解决了传统静态词嵌入无法适应语言动态变化的问题。


<details>
  <summary>Details</summary>
Motivation: 传统词嵌入模型无法适应语言动态变化（如社交媒体中的新词汇），因此需要增量词嵌入算法。

Method: RiverText实现了多种增量词嵌入技术（如Skip-gram、CBOW等），并提供了标准化的评估模块。

Result: 比较了不同超参数设置下的方法，并讨论了结果。

Conclusion: RiverText为信息检索和自然语言处理社区提供了一个处理流数据的开源工具。

Abstract: Word embeddings have become essential components in various information
retrieval and natural language processing tasks, such as ranking, document
classification, and question answering. However, despite their widespread use,
traditional word embedding models present a limitation in their static nature,
which hampers their ability to adapt to the constantly evolving language
patterns that emerge in sources such as social media and the web (e.g., new
hashtags or brand names). To overcome this problem, incremental word embedding
algorithms are introduced, capable of dynamically updating word representations
in response to new language patterns and processing continuous data streams.
  This paper presents RiverText, a Python library for training and evaluating
incremental word embeddings from text data streams. Our tool is a resource for
the information retrieval and natural language processing communities that work
with word embeddings in streaming scenarios, such as analyzing social media.
The library implements different incremental word embedding techniques, such as
Skip-gram, Continuous Bag of Words, and Word Context Matrix, in a standardized
framework. In addition, it uses PyTorch as its backend for neural network
training. We have implemented a module that adapts existing intrinsic static
word embedding evaluation tasks for word similarity and word categorization to
a streaming setting. Finally, we compare the implemented methods with different
hyperparameter settings and discuss the results. Our open-source library is
available at https://github.com/dccuchile/rivertext.

</details>


### [89] [Generalist Reward Models: Found Inside Large Language Models](https://arxiv.org/abs/2506.23235)
*Yi-Chen Li,Tian Xu,Yang Yu,Xuqin Zhang,Xiong-Hui Chen,Zhongxiang Ling,Ningjing Chao,Lei Yuan,Zhi-Hua Zhou*

Main category: cs.CL

TL;DR: 论文发现大型语言模型（LLM）中已隐含通用奖励模型，无需额外训练即可提取高质量奖励信号，并通过理论证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 减少依赖昂贵的人类偏好数据训练奖励模型，探索更高效、理论支持的LLM对齐方法。

Method: 利用LLM的隐式奖励模型，通过离线逆强化学习理论提取奖励信号，并用于强化学习。

Result: 实验证明该方法优于现有LLM-as-a-judge方法，甚至超越显式训练的奖励模型。

Conclusion: 提出了一种高效、理论支持的LLM对齐新范式，可替代传统奖励建模阶段。

Abstract: The alignment of Large Language Models (LLMs) is critically dependent on
reward models trained on costly human preference data. While recent work
explores bypassing this cost with AI feedback, these methods often lack a
rigorous theoretical foundation. In this paper, we discover that a powerful
generalist reward model is already latently present within any LLM trained via
standard next-token prediction. We prove that this endogenous reward is not a
heuristic, but is theoretically equivalent to a reward function learned through
offline inverse reinforcement learning. This connection allows us to directly
elicit a high-quality reward signal from a base (pre-trained or supervised
fine-tuned) model without any further training. Critically, we also prove that
subsequent reinforcement learning using this endogenous reward leads to a
policy with a provably superior error bound compared to the base model. To our
best knowledge, this is the first theoretical proof of the effectiveness of
reinforcement learning for LLMs. Our experiments validate this theory,
demonstrating that our method not only outperforms existing LLM-as-a-judge
approaches but can also surpass explicitly trained reward models. These
findings suggest that the reward modeling stage can be replaced by a principled
method of eliciting the knowledge already captured during pre-training,
heralding a more efficient, powerful, and scalable paradigm for LLMs alignment
as well as multi-modal models.

</details>


### [90] [Two Spelling Normalization Approaches Based on Large Language Models](https://arxiv.org/abs/2506.23288)
*Miguel Domingo,Francisco Casacuberta*

Main category: cs.CL

TL;DR: 论文提出两种基于大语言模型的拼写规范化方法，一种无监督训练，另一种基于机器翻译。实验表明，统计机器翻译更适合此任务。


<details>
  <summary>Details</summary>
Motivation: 历史文献中拼写缺乏标准化，为学者带来挑战，拼写规范化旨在解决这一问题。

Method: 提出两种方法：无监督训练的大语言模型和基于机器翻译的模型。

Result: 在多语言和历史时期的数据集上评估，两种方法均有效，但统计机器翻译表现更优。

Conclusion: 统计机器翻译是目前拼写规范化任务的最合适技术。

Abstract: The absence of standardized spelling conventions and the organic evolution of
human language present an inherent linguistic challenge within historical
documents, a longstanding concern for scholars in the humanities. Addressing
this issue, spelling normalization endeavors to align a document's orthography
with contemporary standards. In this study, we propose two new approaches based
on large language models: one of which has been trained without a supervised
training, and a second one which has been trained for machine translation. Our
evaluation spans multiple datasets encompassing diverse languages and
historical periods, leading us to the conclusion that while both of them
yielded encouraging results, statistical machine translation still seems to be
the most suitable technology for this task.

</details>


### [91] [Objective-Free Local Learning and Emergent Language Structure in Thinking Machines](https://arxiv.org/abs/2506.23293)
*P. Myles Eugenio*

Main category: cs.CL

TL;DR: 提出了一种基于局部事件驱动涌现学习的神经符号生成语言模型框架，核心是分层Hopfield记忆链，作为组合短期记忆和动态标记器。模型从零构建结构，学习多尺度符号序列，并生成具有内部形态一致性的合成语言。


<details>
  <summary>Details</summary>
Motivation: 探索如何从局部神经学习中涌现出符号结构，为构建可扩展、可解释的神经符号系统提供新途径。

Method: 使用分层Hopfield记忆链作为动态标记器，通过投影张量绑定共现特征为分层标记，实现局部激活到长程依赖的压缩。

Result: 模型能够从噪声中过滤自然语言模式，生成具有人类语言一致性的合成语言，并通过涌现的嵌入神经元支持组合推理和泛化。

Conclusion: 该框架为研究符号结构如何从局部神经学习中涌现提供了方法论基础，推动了生成语言模型的神经形态架构发展。

Abstract: We present a neuro-symbolic framework for generative language modeling based
on local, event-driven emergent learning. At its core is a hierarchical
Hopfield memory chain acting as a compositional short-term memory and dynamic
tokenizer (retokenizer). Rather than relying on predefined tokens or
supervision, the model builds structure from scratch, learning symbol sequences
as multi-scale representations. It constructs projection tensors that bind
co-occurring features into hierarchical tokens, introducing redundancy (i.e an
emergent gauge structure) and enabling compression of local activations into
long-range dependencies. Curiously, we find that the retokenizer can filter
natural language patterns from noise, generating synthetic languages with
coherent internal morphology -- quantifiably the same as human language.
Language is learned in a local (Hebbian) fashion, where model constraints
dictate allowed emergent structure, and new information is retained in
alignment with this structure. The absence of a global objective enables a form
of plasticity not found in conventional language models, allowing the system to
generalize beyond its initial inference class -- even without explicit data. We
demonstrate that briefly activating a new neuron during inference binds
distributed multi-scale token features into a symbolic embedding. These
emergent embedding neurons act as long-term memory and support a key-value
mechanism for compositional inference and generalization. This architecture
provides a methodological foundation for studying how symbolic structure can
emerge from local neural learning. It offers a new pathway for building
scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and
reasoning arise as compressed memory traces within a Hopfield hierarchy. This
approach advances the development of neuromorphic architectures for generative
language models.

</details>


### [92] [Ensemble BERT for Medication Event Classification on Electronic Health Records (EHRs)](https://arxiv.org/abs/2506.23315)
*Shouvon Sarker,Xishuang Dong,Lijun Qian*

Main category: cs.CL

TL;DR: 该研究通过构建基于BERT的集成模型，从临床笔记中检测和分类药物事件，显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 识别健康记录和临床笔记中的关键变量（如药物、疾病、关系）在临床领域有广泛应用，n2c2 2022挑战赛为此提供了标注数据集CMED。

Method: 研究使用预训练的BERT模型（基于Wikipedia和MIMIC数据），在CMED训练数据上微调，并通过投票策略集成多个模型的预测结果。

Result: 实验结果表明，BERT集成模型将严格Micro-F分数提高了约5%，严格Macro-F分数提高了约6%。

Conclusion: 基于BERT的集成模型能有效提升药物事件分类的性能。

Abstract: Identification of key variables such as medications, diseases, relations from
health records and clinical notes has a wide range of applications in the
clinical domain. n2c2 2022 provided shared tasks on challenges in natural
language processing for clinical data analytics on electronic health records
(EHR), where it built a comprehensive annotated clinical data Contextualized
Medication Event Dataset (CMED). This study focuses on subtask 2 in Track 1 of
this challenge that is to detect and classify medication events from clinical
notes through building a novel BERT-based ensemble model. It started with
pretraining BERT models on different types of big data such as Wikipedia and
MIMIC. Afterwards, these pretrained BERT models were fine-tuned on CMED
training data. These fine-tuned BERT models were employed to accomplish
medication event classification on CMED testing data with multiple predictions.
These multiple predictions generated by these fine-tuned BERT models were
integrated to build final prediction with voting strategies. Experimental
results demonstrated that BERT-based ensemble models can effectively improve
strict Micro-F score by about 5% and strict Macro-F score by about 6%,
respectively.

</details>


### [93] [Information Loss in LLMs' Multilingual Translation: The Role of Training Data, Language Proximity, and Language Family](https://arxiv.org/abs/2506.23340)
*Yumeng Lin,Xufeng Duan,David Haslett,Yige Chen,Zhenguang G. Cai*

Main category: cs.CL

TL;DR: 研究探讨了训练数据、语言接近度和语言家族对多语言翻译中信息损失的影响，发现数据量和语言结构关系共同影响翻译质量。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在多语言翻译中取得进展，但在某些语言对（尤其是数据有限或与英语差异大的语言）中仍面临挑战。

Method: 通过往返翻译评估GPT-4和Llama 2，使用BLEU分数和BERT相似度指标衡量翻译质量。

Result: 训练数据量和语言距离交互作用显著：数据充足可缓解语言差异影响，而结构接近英语的语言在低资源条件下表现更好。

Conclusion: 翻译质量不仅受数据量影响，还受语言结构和类型学关系制约。

Abstract: Large language models have achieved impressive progress in multilingual
translation, yet they continue to face challenges with certain language
pairs-particularly those with limited training data or significant linguistic
divergence from English. This study systematically investigates how training
data, language proximity, and language family affect information loss in
multilingual translation. We evaluate two large language models, GPT-4 and
Llama 2, by performing round-trip translations. Translation quality was
assessed using BLEU scores and BERT similarity metrics. Our results reveal a
robust interaction between training data size and language distance: while
abundant training data can mitigate the effects of linguistic divergence,
languages structurally closer to English consistently yield higher translation
quality in low-resource conditions. Among various distance metrics,
orthographic, phylogenetic, syntactic, and geographical distances emerge as
strong predictors of translation performance. Language family also exerts an
independent influence. These findings contribute to a deeper understanding of
the linguistic constraints shaping multilingual translation in large language
models, emphasizing that translation quality is shaped not only by data volume
but also by structural and typological relationships between languages.

</details>


### [94] [ATGen: A Framework for Active Text Generation](https://arxiv.org/abs/2506.23342)
*Akim Tsvigun,Daniil Vasilev,Ivan Tsvigun,Ivan Lysenko,Talgat Bektleuov,Aleksandr Medvedev,Uliana Vinogradova,Nikita Severin,Mikhail Mozikov,Andrey Savchenko,Rostislav Grigorev,Ramil Kuleev,Fedor Zhdanov,Artem Shelmanov,Ilya Makarov*

Main category: cs.CL

TL;DR: ATGen框架将主动学习（AL）与文本生成任务结合，支持人类标注者和基于大语言模型（LLM）的自动标注代理，减少标注成本和API调用费用。


<details>
  <summary>Details</summary>
Motivation: 尽管AL在减少标注工作量方面表现出色，但其在自然语言生成（NLG）任务中的应用有限。ATGen旨在填补这一空白。

Method: ATGen是一个综合框架，支持LLM服务（如ChatGPT和Claude）或本地部署，提供统一平台实现和评估AL策略。

Result: 评估显示，ATGen显著减少了人类标注者的工作量和LLM标注代理的API调用成本。

Conclusion: ATGen为NLG任务提供了高效的AL解决方案，代码开源且支持多种LLM服务。

Abstract: Active learning (AL) has demonstrated remarkable potential in reducing the
annotation effort required for training machine learning models. However,
despite the surging popularity of natural language generation (NLG) tasks in
recent years, the application of AL to NLG has been limited. In this paper, we
introduce Active Text Generation (ATGen) - a comprehensive framework that
bridges AL with text generation tasks, enabling the application of
state-of-the-art AL strategies to NLG. Our framework simplifies AL-empowered
annotation in NLG tasks using both human annotators and automatic annotation
agents based on large language models (LLMs). The framework supports LLMs
deployed as services, such as ChatGPT and Claude, or operated on-premises.
Furthermore, ATGen provides a unified platform for smooth implementation and
benchmarking of novel AL strategies tailored to NLG tasks. Finally, we present
evaluation results for state-of-the-art AL strategies across diverse settings
and multiple text generation tasks. We show that ATGen reduces both the effort
of human annotators and costs associated with API calls to LLM-based annotation
agents. The code of the framework is available on GitHub under the MIT license.
The video presentation is available at http://atgen-video.nlpresearch.group

</details>


### [95] [Perspective Dial: Measuring Perspective of Text and Guiding LLM Outputs](https://arxiv.org/abs/2506.23377)
*Taejin Kim,Siun-Chuon Mau,Konrad Vesey*

Main category: cs.CL

TL;DR: 该论文提出了一种名为Perspective-Dial的方法，用于量化大型语言模型（LLM）输出的观点偏差，并通过系统提示工程控制其输出视角。


<details>
  <summary>Details</summary>
Motivation: 由于LLM在关键任务中的广泛应用，但缺乏对其输出偏差和观点的量化理解，因此需要一种方法来测量和控制LLM的视角。

Method: Perspective-Dial包括两个主要组件：Perspective Space（用于量化不同观点的度量空间）和Systematic Prompt Engineering（通过贪婪坐标下降法控制LLM输出视角）。

Result: 该方法能够量化并调整LLM输出的观点，适用于多种主题。

Conclusion: Perspective-Dial为LLM的视角检测、跟踪和调整提供了实用工具，潜在应用包括偏见检测、公共话语分析和辩论机器人等。

Abstract: Large language models (LLMs) are used in a variety of mission-critical roles.
Due to the rapidly developing nature of LLMs, there is a lack of quantifiable
understanding of the bias and perspective associated with LLM output. Inspired
by this need, this paper considers the broader issue of perspective or
viewpoint of general text and perspective control of large-language model (LLM)
output. Perspective-Dial consists of two main components: a (1) metric space,
dubbed Perspective Space, that enables quantitative measurements of different
perspectives regarding a topic, and the use of (2) Systematic Prompt
Engineering that utilizes greedy-coordinate descent to control LLM output
perspective based on measurement feedback from the Perspective Space. The
empirical nature of the approach allows progress to side step a principled
understanding of perspective or bias -- effectively quantifying and adjusting
outputs for a variety of topics. Potential applications include detection,
tracking and mitigation of LLM bias, narrative detection, sense making and
tracking in public discourse, and debate bot advocating given perspective.

</details>


### [96] [Hierarchical Memory Organization for Wikipedia Generation](https://arxiv.org/abs/2506.23393)
*Eugene J. Yu,Dawei Zhu,Yifan Song,Xiangyu Wong,Jiebin Zhang,Wenxuan Shi,Xiaoguang Li,Qun Liu,Sujian Li*

Main category: cs.CL

TL;DR: 论文提出了一种基于记忆组织的生成框架（MOG），通过分层记忆架构生成维基百科文章，提高了信息性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 解决从多样化来源整合准确、全面且结构良好的信息以生成维基百科文章的挑战。

Method: MOG框架从网络文档中提取细粒度记忆单元，递归组织为维基百科式分层结构，并以此指导生成过程，同时引入引用模块增强可追溯性。

Result: 在WikiStart数据集上的评估表明，MOG在生成信息丰富且可靠的文章方面优于基线方法。

Conclusion: MOG框架在真实场景中表现出色，尤其擅长生成高信息性和低幻觉的维基百科文章。

Abstract: Generating Wikipedia articles autonomously is a challenging task requiring
the integration of accurate, comprehensive, and well-structured information
from diverse sources. This paper introduces the Memory Organization-based
Generation (MOG) framework, a novel approach to address these challenges by
leveraging a hierarchical memory architecture. MOG extracts fine-grained memory
units from web documents, recursively organizes them into a Wikipedia-style
hierarchical structure, and uses this structure to guide the generation
process. This ensures alignment between memory and the article outline,
improving both informativeness and verifiability while minimizing
hallucinations. Additionally, a citation module is implemented to enhance
traceability by linking every generated sentence to specific memory units.
Evaluations on our newly created WikiStart dataset demonstrate that MOG
outperforms baseline methods in producing informative and reliable articles,
making it particularly robust in real-world scenarios.

</details>


### [97] [Datasets for Fairness in Language Models: An In-Depth Survey](https://arxiv.org/abs/2506.23411)
*Jiale Zhang,Zichong Wang,Avash Palikhe,Zhipeng Yin,Wenbin Zhang*

Main category: cs.CL

TL;DR: 该论文综述了语言模型公平性基准数据集，分析了其来源、范围、内容和用途，并提出了统一的评估框架以揭示数据集中的偏见，为研究者提供选择和使用这些数据的实用建议。


<details>
  <summary>Details</summary>
Motivation: 当前对语言模型公平性的评估依赖于基准数据集，但这些数据集本身的研究不足，可能导致评估结果的偏差。

Method: 通过广泛审查常用公平性数据集，提出统一评估框架，分析24个常见基准中的偏见模式。

Result: 揭示了数据集中普遍存在的偏见，影响了模型公平性结论，并提供了数据集选择和解释的指导。

Conclusion: 呼吁创建更多样化的公平性基准，并更谨慎地使用现有数据集，以促进更透明的公平性研究。

Abstract: Fairness benchmarks play a central role in shaping how we evaluate language
models, yet surprisingly little attention has been given to examining the
datasets that these benchmarks rely on. This survey addresses that gap by
presenting a broad and careful review of the most widely used fairness datasets
in current language model research, characterizing them along several key
dimensions including their origin, scope, content, and intended use to help
researchers better appreciate the assumptions and limitations embedded in these
resources. To support more meaningful comparisons and analyses, we introduce a
unified evaluation framework that reveals consistent patterns of demographic
disparities across datasets and scoring methods. Applying this framework to
twenty four common benchmarks, we highlight the often overlooked biases that
can influence conclusions about model fairness and offer practical guidance for
selecting, combining, and interpreting these datasets. We also point to
opportunities for creating new fairness benchmarks that reflect more diverse
social contexts and encourage more thoughtful use of these tools going forward.
All code, data, and detailed results are publicly available at
https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets
to promote transparency and reproducibility across the research community.

</details>


### [98] [TuCo: Measuring the Contribution of Fine-Tuning to Individual Responses of LLMs](https://arxiv.org/abs/2506.23423)
*Felipe Nuti,Tim Franzmeyer,João Henriques*

Main category: cs.CL

TL;DR: 提出了一种新方法TuCo，用于量化微调对大型语言模型（LLM）个体输出的贡献，并通过理论和实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏定量分析微调对LLM个体输出影响的方法，因此需要一种系统化的方法来衡量微调的贡献。

Method: 通过追踪模型的中间隐藏状态，将微调后的LLM精确分解为预训练和微调两部分，并定义TuCo（微调贡献比）来衡量微调的影响。

Result: 实验发现，TuCo可以揭示微调对模型行为和性能的影响，并发现对抗攻击成功时TuCo较低。

Conclusion: TuCo为定量研究微调对模型行为和安全性的影响提供了新工具。

Abstract: Past work has studied the effects of fine-tuning on large language models'
(LLMs) overall performance on certain tasks. However, a quantitative and
systematic method for analyzing its effect on individual outputs is still
lacking. Here, we propose a new method for measuring the contribution that
fine-tuning makes to individual LLM responses, assuming access to the original
pre-trained model. Our method tracks the model's intermediate hidden states,
providing a more fine-grained insight into the effects of fine-tuning than a
simple comparison of final outputs from pre-trained and fine-tuned models. We
introduce and theoretically analyze an exact decomposition of any fine-tuned
LLM into a pre-training component and a fine-tuning component. Empirically, we
find that model behavior and performance can be steered by up- or down-scaling
the fine-tuning component during the forward pass. Motivated by this finding
and our theoretical analysis, we define the Tuning Contribution (TuCo) as the
ratio of the magnitudes of the fine-tuning component to the pre-training
component. We observe that three prominent adversarial attacks on LLMs
circumvent safety measures in a way that reduces TuCo, and that TuCo is
consistently lower on prompts where these attacks succeed compared to those
where they do not. This suggests that attenuating the effect of fine-tuning on
model outputs plays a role in the success of such attacks. In summary, TuCo
enables the quantitative study of how fine-tuning influences model behavior and
safety, and vice versa.

</details>


### [99] [Pipelined Decoder for Efficient Context-Aware Text Generation](https://arxiv.org/abs/2506.23431)
*Zixian Huang,Chenxu Niu,Yu Gu,Gengyang Xiao,Xinwei Huang,Gong Cheng*

Main category: cs.CL

TL;DR: 提出了一种新的解码器架构，通过并行生成多个子序列来提高文本生成速度，同时保持生成质量和内存效率。


<details>
  <summary>Details</summary>
Motivation: 自回归模型虽然生成质量高，但逐词生成限制了速度，成为瓶颈。

Method: 提出了一种流水线解码器，同时生成多个子序列，每个时间步为每个子序列生成新词以实现并行。

Result: 在问答、文本摘要和关键词生成等任务中，生成速度显著提升，且质量和内存消耗无明显损失。

Conclusion: 流水线解码器有效解决了自回归模型的生成速度瓶颈问题。

Abstract: As the basis of generative AI, an autoregressive model requires the
generation of a new token depending on all the previously generated tokens,
which brings high quality but also restricts the model to generate tokens one
by one, forming a bottleneck limiting the generation speed. In this paper, we
propose a new decoder architecture that efficiently generates text in parallel
for context-aware generation tasks. Our proposed pipelined decoder initiates
the generation of multiple subsequences simultaneously, and, at each time-step,
it generates a new token for each subsequence to realize parallelism.
Experiments on multiple text generation tasks, including question answering,
text summarization, and keyphrase generation, show that our pipelined decoder
significantly improves the generation speed without a significant loss of
generation quality or additional memory consumption.

</details>


### [100] [What to Keep and What to Drop: Adaptive Table Filtering Framework](https://arxiv.org/abs/2506.23463)
*Jang Won June*

Main category: cs.CL

TL;DR: ATF框架通过自适应过滤大表格中的无关列和行，提升表格推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在处理大表格时因输入长度限制而表现不佳的问题。

Method: 提出ATF框架，结合LLM生成的列描述、聚类和稀疏-密集对齐分数进行表格过滤。

Result: 实验显示ATF减少约70%的表格单元，提升TableQA任务性能，但对Table Fact Verification略有影响。

Conclusion: ATF能自适应平衡信息量和简洁性，适用于不同任务。

Abstract: Large language models (LLMs) for table-based reasoning often struggle with
large tables due to input length limits. We propose ATF (Adaptive Table
Filtering Framework), a modular and question-aware filtering pipeline that
prunes uninformative columns and rows using LLM-generated column descriptions,
clustering, and sparse-dense alignment scores. ATF integrates seamlessly with
existing models (e.g., TAPAS, TAPEX) without retraining. Experiments show that
ATF reduces table cells by ~70\%, boosting performance on out-of-domain TableQA
tasks while causing slight performance drops on Table Fact Verification, where
full-table context is more critical. These results highlight ATF's ability to
adaptively balance informativeness and minimalism across tasks.

</details>


### [101] [Thought-Augmented Planning for LLM-Powered Interactive Recommender Agent](https://arxiv.org/abs/2506.23485)
*Haocheng Yu,Yaxiong Wu,Hao Wang,Wei Guo,Yong Liu,Yawen Li,Yuyang Ye,Junping Du,Enhong Chen*

Main category: cs.CL

TL;DR: 论文提出了一种基于大语言模型的多智能体系统TAIRA，通过思想模式蒸馏增强规划能力，以解决交互式推荐中复杂用户意图的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型驱动的交互式推荐系统在应对多样化和复杂的用户意图（如模糊或不明确的请求）时表现不足。

Method: 设计了TAIRA系统，采用多智能体架构，包括一个管理代理，通过思想模式蒸馏（TPD）增强规划能力，并设计了用户模拟方案进行评估。

Result: 实验表明，TAIRA在多个数据集上显著优于现有方法，尤其在复杂任务上表现更优，并能有效泛化到新任务。

Conclusion: TAIRA通过思想模式蒸馏和多智能体协作，显著提升了交互式推荐系统处理复杂用户意图的能力。

Abstract: Interactive recommendation is a typical information-seeking task that allows
users to interactively express their needs through natural language and obtain
personalized recommendations. Large language model-powered (LLM-powered) agents
have become a new paradigm in interactive recommendations, effectively
capturing users' real-time needs and enhancing personalized experiences.
However, due to limited planning and generalization capabilities, existing
formulations of LLM-powered interactive recommender agents struggle to
effectively address diverse and complex user intents, such as intuitive,
unrefined, or occasionally ambiguous requests. To tackle this challenge, we
propose a novel thought-augmented interactive recommender agent system (TAIRA)
that addresses complex user intents through distilled thought patterns.
Specifically, TAIRA is designed as an LLM-powered multi-agent system featuring
a manager agent that orchestrates recommendation tasks by decomposing user
needs and planning subtasks, with its planning capacity strengthened through
Thought Pattern Distillation (TPD), a thought-augmentation method that extracts
high-level thoughts from the agent's and human experts' experiences. Moreover,
we designed a set of user simulation schemes to generate personalized queries
of different difficulties and evaluate the recommendations based on specific
datasets. Through comprehensive experiments conducted across multiple datasets,
TAIRA exhibits significantly enhanced performance compared to existing methods.
Notably, TAIRA shows a greater advantage on more challenging tasks while
generalizing effectively on novel tasks, further validating its superiority in
managing complex user intents within interactive recommendation systems. The
code is publicly available at:https://github.com/Alcein/TAIRA.

</details>


### [102] [Reinforcement Fine-Tuning Enables MLLMs Learning Novel Tasks Stably](https://arxiv.org/abs/2506.23508)
*Zhihao Zhang,Qiaole Dong,Qi Zhang,Jun Zhao,Enyu Zhou,Zhiheng Xi,Senjie Jin,Xiaoran Fan,Yuhao Zhou,Yanwei Fu,Tao Ji,Tao Gui,Xuanjing Huang*

Main category: cs.CL

TL;DR: 研究探讨了SFT和RFT在多模态大语言模型中对任务适应和先验知识的影响，发现SFT快速适应任务但导致灾难性遗忘，而RFT学习较慢但保留知识。


<details>
  <summary>Details</summary>
Motivation: 明确SFT和RFT在任务适应中对先验知识的影响，探索稳定持续学习的方法。

Method: 引入拼图任务，系统研究SFT和RFT在Qwen2.5-VL模型上的表现，分析学习动态。

Result: SFT快速学习新任务但遗忘先验知识，RFT学习慢但保留知识，数据分布是关键因素。

Conclusion: RFT在多模态大语言模型中具有稳定持续学习的潜力，数据分布对遗忘起主要作用。

Abstract: Post-training algorithms such as Supervised Fine-Tuning (SFT) and
Reinforcement Fine-Tuning (RFT) are widely used to adapt multimodal large
language models to downstream tasks. While effective at task adaptation, their
impact on prior knowledge remains unclear. In this paper, we introduce jigsaw
puzzles as a novel task absent from existing pretraining corpora and
systematically study the behavior of SFT and RFT on an open-source multimodal
model, Qwen2.5-VL. Our experiments reveal a sharp trade-off: SFT enables rapid
task acquisition but leads to catastrophic forgetting, whereas RFT learns more
slowly on novel tasks but maintains prior knowledge. We analyze this phenomenon
through the lens of learning dynamics, showing that RFT reinforces correct
samples that are naturally aligned with the base model's probability landscape,
mitigating interference with prior knowledge. Moreover, supervised training on
correct RFT-simulated rollouts allows SFT to preserve knowledge while rapidly
learning new tasks. These findings suggest that data distribution, rather than
algorithmic differences, plays a central role in forgetting, and highlight
RFT's potential for stable continual learning in multimodal large language
models.

</details>


### [103] [NEU-ESC: A Comprehensive Vietnamese dataset for Educational Sentiment analysis and topic Classification toward multitask learning](https://arxiv.org/abs/2506.23524)
*Phan Quoc Hung Mai,Quang Hung Nguyen,Phuong Giang Duong,Hong Hanh Nguyen,Nguyen Tuan Long*

Main category: cs.CL

TL;DR: 论文介绍了NEU-ESC，一个越南语教育情感和主题分类数据集，填补了现有资源的不足，并通过多任务学习模型取得了较高准确率。


<details>
  <summary>Details</summary>
Motivation: 越南语教育领域的学生评论分析资源有限，现有数据集缺乏领域相关性和学生俚语，NEU-ESC旨在解决这些问题。

Method: 使用BERT等编码器语言模型进行多任务学习，对情感和主题分类任务进行优化。

Result: 模型在情感和主题分类任务上分别达到83.7%和79.8%的准确率。

Conclusion: NEU-ESC数据集和模型在越南语教育领域表现优异，数据集已公开。

Abstract: In the field of education, understanding students' opinions through their
comments is crucial, especially in the Vietnamese language, where resources
remain limited. Existing educational datasets often lack domain relevance and
student slang. To address these gaps, we introduce NEU-ESC, a new Vietnamese
dataset for Educational Sentiment Classification and Topic Classification,
curated from university forums, which offers more samples, richer class
diversity, longer texts, and broader vocabulary. In addition, we explore
multitask learning using encoder-only language models (BERT), in which we
showed that it achieves performance up to 83.7% and 79.8% accuracy for
sentiment and topic classification tasks. We also benchmark our dataset and
model with other datasets and models, including Large Language Models, and
discuss these benchmarks. The dataset is publicly available at:
https://huggingface.co/datasets/hung20gg/NEU-ESC.

</details>


### [104] [On Recipe Memorization and Creativity in Large Language Models: Is Your Model a Creative Cook, a Bad Cook, or Merely a Plagiator?](https://arxiv.org/abs/2506.23527)
*Jan Kvapil,Martin Fajcik*

Main category: cs.CL

TL;DR: 研究分析了大型语言模型（LLM）生成的食谱中的记忆性、创造性和无意义内容，并通过人工标注和自动化方法评估了模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在生成食谱时依赖记忆内容还是展现创造性，以及如何自动化评估这一过程。

Method: 通过人工标注20个LLM生成的食谱，分析记忆性和创造性；设计自动化流程（LLM-as-judge）扩展研究规模。

Result: Mixtral模型依赖记忆内容；自动化流程中，Llama 3.1+Gemma 2 9B在成分匹配上达到78%准确率。

Conclusion: 自动化框架能大规模量化LLM生成内容的记忆性、创造性和无意义性，为模型创造性能力提供严谨证据。

Abstract: This work-in-progress investigates the memorization, creativity, and nonsense
found in cooking recipes generated from Large Language Models (LLMs).
Precisely, we aim (i) to analyze memorization, creativity, and non-sense in
LLMs using a small, high-quality set of human judgments and (ii) to evaluate
potential approaches to automate such a human annotation in order to scale our
study to hundreds of recipes. To achieve (i), we conduct a detailed human
annotation on 20 preselected recipes generated by LLM (Mixtral), extracting
each recipe's ingredients and step-by-step actions to assess which elements are
memorized--i.e., directly traceable to online sources possibly seen during
training--and which arise from genuine creative synthesis or outright nonsense.
We find that Mixtral consistently reuses ingredients that can be found in
online documents, potentially seen during model training, suggesting strong
reliance on memorized content. To achieve aim (ii) and scale our analysis
beyond small sample sizes and single LLM validation, we design an
``LLM-as-judge'' pipeline that automates recipe generation, nonsense detection,
parsing ingredients and recipe steps, and their annotation. For instance,
comparing its output against human annotations, the best ingredient extractor
and annotator is Llama 3.1+Gemma 2 9B, achieving up to 78% accuracy on
ingredient matching. This automated framework enables large-scale
quantification of memorization, creativity, and nonsense in generated recipes,
providing rigorous evidence of the models' creative capacities.

</details>


### [105] [Semantic-guided Diverse Decoding for Large Language Model](https://arxiv.org/abs/2506.23601)
*Weijie Shi,Yue Cui,Yaguang Wu,Jingzhi Fang,Shibo Zhang,Mengze Li,Sirui Han,Jia Zhu,Jiajie Xu,Xiaofang Zhou*

Main category: cs.CL

TL;DR: SemDiD是一种新的解码方法，通过嵌入空间操作提升语义多样性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注词汇多样性而非语义多样性，限制了其在多语义响应需求中的应用。

Method: SemDiD通过正交方向引导、动态组间排斥和位置去偏概率评估三种机制，平衡质量与多样性。

Result: 实验显示SemDiD在多样任务中表现优异，Best-of-N覆盖率提升1.4-5.2%，RLHF训练收敛加速15%，准确率提升2.1%。

Conclusion: SemDiD有效解决了语义多样性问题，为语言模型解码提供了新思路。

Abstract: Diverse decoding of large language models is crucial for applications
requiring multiple semantically distinct responses, yet existing methods
primarily achieve lexical rather than semantic diversity. This limitation
significantly constrains Best-of-N strategies, group-based reinforcement
learning, and data synthesis. While temperature sampling and diverse beam
search modify token distributions or apply n-gram penalties, they fail to
ensure meaningful semantic differentiation. We introduce Semantic-guided
Diverse Decoding (SemDiD), operating directly in embedding space that balances
quality with diversity through three complementary mechanisms: orthogonal
directional guidance, dynamic inter-group repulsion, and position-debiased
probability assessment. SemDiD harmonizes these competing objectives using
adaptive gain functions and constraint optimization, ensuring both quality
thresholds and maximal semantic differentiation. Experiments show SemDiD
consistently outperforms existing methods, improving Best-of-N coverage by
1.4-5.2% across diverse tasks and accelerating RLHF training convergence by 15%
while increasing accuracy by up to 2.1%.

</details>


### [106] [Evaluating the Simulation of Human Personality-Driven Susceptibility to Misinformation with LLMs](https://arxiv.org/abs/2506.23610)
*Manuel Pratelli,Marinella Petrocchi*

Main category: cs.CL

TL;DR: LLMs可以生成合成行为数据，但能否准确反映人格特质驱动的心理差异尚不明确。研究发现，LLM代理在某些人格特质（如宜人性和尽责性）上能复现人类行为模式，但也存在系统性偏差。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM生成的行为数据是否能准确模拟人格特质对信息辨别能力的影响。

Method: 利用已知人格特质的真实人类数据，创建匹配的LLM代理，比较其与人类在新闻辨别任务上的表现。

Result: LLM在宜人性和尽责性相关特质上能复现人类行为，但在其他特质上存在偏差。

Conclusion: LLM在模拟行为数据方面有潜力，但也存在局限性，为人工代理的认知多样性建模提供了新见解。

Abstract: Large language models (LLMs) make it possible to generate synthetic
behavioural data at scale, offering an ethical and low-cost alternative to
human experiments. Whether such data can faithfully capture psychological
differences driven by personality traits, however, remains an open question. We
evaluate the capacity of LLM agents, conditioned on Big-Five profiles, to
reproduce personality-based variation in susceptibility to misinformation,
focusing on news discernment, the ability to judge true headlines as true and
false headlines as false. Leveraging published datasets in which human
participants with known personality profiles rated headline accuracy, we create
matching LLM agents and compare their responses to the original human patterns.
Certain trait-misinformation associations, notably those involving
Agreeableness and Conscientiousness, are reliably replicated, whereas others
diverge, revealing systematic biases in how LLMs internalize and express
personality. The results underscore both the promise and the limits of
personality-aligned LLMs for behavioral simulation, and offer new insight into
modeling cognitive diversity in artificial agents.

</details>


### [107] [Robustness of Misinformation Classification Systems to Adversarial Examples Through BeamAttack](https://arxiv.org/abs/2506.23661)
*Arnisa Fazla,Lucas Krauter,David Guzman Piedrahita,Andrianos Michail*

Main category: cs.CL

TL;DR: 扩展了BeamAttack算法，支持单词删除和跳过替换，结合LIME优化替换优先级，攻击成功率达99%且保持语义相似。


<details>
  <summary>Details</summary>
Motivation: 评估文本分类系统的鲁棒性，通过最小修改改变模型预测。

Method: 扩展BeamAttack算法，支持单词删除和跳过替换，结合LIME优化替换优先级。

Result: 在多个数据集和模型上攻击成功率达99%，保持语义和词汇相似性。

Conclusion: BeamAttack有效但存在局限性，代码已开源。

Abstract: We extend BeamAttack, an adversarial attack algorithm designed to evaluate
the robustness of text classification systems through word-level modifications
guided by beam search. Our extensions include support for word deletions and
the option to skip substitutions, enabling the discovery of minimal
modifications that alter model predictions. We also integrate LIME to better
prioritize word replacements. Evaluated across multiple datasets and victim
models (BiLSTM, BERT, and adversarially trained RoBERTa) within the BODEGA
framework, our approach achieves over a 99\% attack success rate while
preserving the semantic and lexical similarity of the original texts. Through
both quantitative and qualitative analysis, we highlight BeamAttack's
effectiveness and its limitations. Our implementation is available at
https://github.com/LucK1Y/BeamAttack

</details>


### [108] [Zero-Shot Contextual Embeddings via Offline Synthetic Corpus Generation](https://arxiv.org/abs/2506.23662)
*Philip Lippmann,Jie Yang*

Main category: cs.CL

TL;DR: ZEST是一种零样本上下文适应框架，通过合成代理语料库替代真实语料访问，无需微调即可生成领域适应的嵌入。


<details>
  <summary>Details</summary>
Motivation: 解决上下文感知嵌入方法需要目标语料库访问或领域特定微调的实践障碍。

Method: 使用多步分层程序合成代理语料库，模拟关键领域特定分布。

Result: 在MTEB基准测试中，仅用五个示例文档的ZEST性能接近完全访问目标语料库的模型（差距0.5%）。

Conclusion: ZEST为受限环境提供高性能、适应性强的嵌入部署方案。

Abstract: Context-aware embedding methods boost retrieval accuracy by conditioning on
corpus statistics (e.g., term co-occurrence and topical patterns) extracted
from neighboring documents. However, this context-aware approach requires
access to the target corpus or requires domain-specific finetuning, posing
practical barriers in privacy-sensitive or resource-constrained settings. We
present ZEST, a zero-shot contextual adaptation framework that replaces real
corpus access with a one-time offline synthesis of a compact proxy. Given only
a handful exemplar documents representative of the general target domain, we
use a multi-step hierarchical procedure to generate a synthetic context corpus
of several hundred documents that aims to emulate key domain-specific
distributions. At inference, the frozen context-aware encoder uses this proxy
corpus -- without any finetuning or target corpus access -- to produce
domain-adapted embeddings. Across the MTEB benchmark, ZEST's zero-shot
synthetic context adaptation using only five example documents performs within
0.5% of models leveraging full target corpus access -- demonstrating remarkable
efficacy without any retraining. ZEST thus provides a practical method for
deploying high-performance, adaptable embeddings in constrained environments.

</details>


### [109] [L0: Reinforcement Learning to Become General Agents](https://arxiv.org/abs/2506.23667)
*Junjie Zhang,Jingyi Xi,Zhuoyang Song,Junyu Lu,Yuhua Ke,Ting Sun,Yukun Yang,Jiaxing Zhang,Songxin Zhang,Zejian Xie*

Main category: cs.CL

TL;DR: L-Zero (L0) 是一个可扩展的端到端训练管道，用于通用代理，通过低成本、可扩展的沙盒并发代理工作池提升强化学习在复杂环境中的应用效率。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型（LLMs）在多轮、长时任务中作为自主代理时的可扩展性和训练效率问题。

Method: 引入 L0 训练管道和 NB-Agent 代理框架，采用“代码即动作”方式通过 REPL 运行，并使用可验证奖励的强化学习（RLVR）进行训练。

Result: 在 SimpleQA 和 HotpotQA 基准测试中，准确率分别从 30% 提升至 80% 和从 22% 提升至 41%。

Conclusion: L0 系统显著提升了代理的问题解决能力，并已开源全部资源。

Abstract: Training large language models (LLMs) to act as autonomous agents for
multi-turn, long-horizon tasks remains significant challenges in scalability
and training efficiency. To address this, we introduce L-Zero (L0), a scalable,
end-to-end training pipeline for general-purpose agents. Featuring a low-cost,
extensible, and sandboxed concurrent agent worker pool, L0 lowers the barrier
for applying reinforcement learning in complex environments. We also introduce
NB-Agent, the agent scaffold within L0, which operates in a "code-as-action"
fashion via a Read-Eval-Print-Loop (REPL). We evaluate L0 on factuality
question-answering benchmarks. Our experiments demonstrate that a base model
can develop robust problem-solving skills using solely Reinforcement Learning
with Verifiable Rewards (RLVR). On the Qwen2.5-7B-Instruct model, our method
boosts accuracy on SimpleQA from 30 % to 80 % and on HotpotQA from 22 % to 41
%. We have open-sourced the entire L0 system, including our L0 series models,
the NB-Agent, a complete training pipeline, and the corresponding training
recipes on (https://github.com/cmriat/l0).

</details>


### [110] [AutoEvoEval: An Automated Framework for Evolving Close-Ended LLM Evaluation Data](https://arxiv.org/abs/2506.23735)
*JiaRu Wu,Mingwei Liu*

Main category: cs.CL

TL;DR: AutoEvoEval是一个基于进化的评估框架，用于生成多样化和具有挑战性的测试样本，以更全面地评估大型语言模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准多为静态，无法充分评估大型语言模型在真实场景中的鲁棒性和泛化能力。

Method: 提出AutoEvoEval框架，引入22种可解释的原子进化操作，支持多轮组合生成测试样本。

Result: 实验显示原子操作平均导致准确率下降7.283%，多步组合可放大对抗效应达52.932%。

Conclusion: 当前基准可能高估模型泛化能力，需进化感知的鲁棒性评估。

Abstract: Large language models (LLMs) have shown remarkable performance on various
tasks, but existing evaluation benchmarks are often static and insufficient to
fully assess their robustness and generalization in realistic scenarios. Prior
work using evolutionary or adversarial data augmentation has improved
evaluation diversity but lacks systematic control over perturbation types and
multi-step complexity, limiting comprehensive robustness analysis. To address
these gaps, we propose AutoEvoEval, an evolution-based evaluation framework for
close-ended tasks such as multi-choice question answering. AutoEvoEval
introduces 22 interpretable atomic evolution operations and supports
multi-round compositions, enabling controlled generation of diverse,
challenging, and realistic test samples. We conduct extensive experiments
addressing four research questions on a broad set of open- and closed-source
LLMs. Our results show that atomic operations cause an average accuracy drop of
7.283\%, with structure-disrupting or misleading semantic edits causing the
largest declines. Model sensitivities vary significantly for the same
perturbation, and combining multiple evolution steps amplifies adversarial
effects by up to 52.932\%. These findings suggest current benchmarks may
overestimate true model generalization and emphasize the need for
evolution-aware robustness evaluation. Code and resources are available at:
https://github.com/SYSUSELab/AutoEvoEval.

</details>


### [111] [Positional Bias in Binary Question Answering: How Uncertainty Shapes Model Preferences](https://arxiv.org/abs/2506.23743)
*Tiziano Labruna,Simone Gallo,Giovanni Da San Martino*

Main category: cs.CL

TL;DR: 研究量化并分析了五种大型语言模型在二元问答中的位置偏差，发现位置偏差在低不确定性条件下几乎不存在，但在高不确定性条件下呈指数增长。


<details>
  <summary>Details</summary>
Motivation: 研究二元问答中模型因选项顺序而系统性偏好某一选项的位置偏差现象。

Method: 通过改编SQuAD-it数据集并创建不同不确定性版本，评估WebGPT和Winning Arguments两个高不确定性基准，计算偏好公平性和位置一致性。

Result: 位置偏差在低不确定性条件下几乎不存在，但在高不确定性条件下显著增加。

Conclusion: 位置偏差与答案不确定性密切相关，高不确定性条件下模型更易受选项顺序影响。

Abstract: Positional bias in binary question answering occurs when a model
systematically favors one choice over another based solely on the ordering of
presented options. In this study, we quantify and analyze positional bias
across five large language models under varying degrees of answer uncertainty.
We re-adapted the SQuAD-it dataset by adding an extra incorrect answer option
and then created multiple versions with progressively less context and more
out-of-context answers, yielding datasets that range from low to high
uncertainty. Additionally, we evaluate two naturally higher-uncertainty
benchmarks: (1) WebGPT - question pairs with unequal human-assigned quality
scores, and (2) Winning Arguments - where models predict the more persuasive
argument in Reddit's r/ChangeMyView exchanges. Across each dataset, the order
of the "correct" (or higher-quality/persuasive) option is systematically
flipped (first placed in position 1, then in position 2) to compute both
Preference Fairness and Position Consistency. We observe that positional bias
is nearly absent under low-uncertainty conditions, but grows exponentially when
it becomes doubtful to decide which option is correct.

</details>


### [112] [Do Thinking Tokens Help or Trap? Towards More Efficient Large Reasoning Model](https://arxiv.org/abs/2506.23840)
*Bowen Ding,Yuhan Chen,Futing Wang,Lingfeng Ming,Tao Lin*

Main category: cs.CL

TL;DR: 论文提出DuP-PO算法，解决大型推理模型（LRM）在简单任务中因过度思考而效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在简单任务中会产生冗余的思考标记，导致效率降低，甚至影响正确推理。

Method: 提出Dual Policy Preference Optimization (DuP-PO)算法，包括平衡采样策略、动态优势控制技术和策略塑造方法。

Result: 在五个数学推理基准测试中，DuP-PO显著提高了模型的标记效率，同时保持了基础模型的性能。

Conclusion: DuP-PO有效解决了LRM的思考陷阱问题，提升了推理效率。

Abstract: Large Reasoning Models (LRMs) excel at solving complex problems but face an
overthinking dilemma. When handling simple tasks, they often produce verbose
responses overloaded with thinking tokens (e.g., wait, however). These tokens
trigger unnecessary high-level reasoning behaviors like reflection and
backtracking, reducing efficiency. In this work, our pilot study reveals that
these thinking-token-induced behaviors are not essential for effective
problem-solving and may even hinder correct reasoning within constrained token
budgets. We identify this phenomenon as the thinking trap. To mitigate this
issue, we propose Dual Policy Preference Optimization (DuP-PO), a novel
algorithm featuring: (1) A rollout sampling strategy that guarantees balanced
exposure to responses with and without thinking tokens; (2) A fine-grained
advantage control technique to dynamically regulate the prediction of target
tokens; (3) A policy shaping method ensuring stable gradient contributions from
thinking tokens. Experimental results on five popular math reasoning benchmarks
show that DuP-PO performs well on the popular LRM, which significantly improves
their token efficiency during reasoning, while achieving superior performance
of the base model.

</details>


### [113] [Garbage In, Reasoning Out? Why Benchmark Scores are Unreliable and What to Do About It](https://arxiv.org/abs/2506.23864)
*Seyed Mahed Mousavi,Edoardo Cecchinato,Lucia Hornikova,Giuseppe Riccardi*

Main category: cs.CL

TL;DR: 论文对三个广泛使用的推理基准（SocialIQa、FauxPas-EAI、ToMi）进行了系统审计，揭示了基准设计和评估方法中的普遍缺陷。通过使用五种LLM作为诊断工具，发现基准存在结构、语义和语用问题，且评分过程过于关注输出形式而非推理过程。研究发现模型性能对输入微小变化敏感，高分可能反映对格式特定线索的匹配而非真实推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前推理基准的设计和评估方法存在缺陷，可能导致对大型语言模型（LLM）推理能力的误解。论文旨在揭示这些问题，并提出更有效的评估协议。

Method: 使用五种LLM（GPT-3、GPT-3.5、GPT-4、GPT-o1和LLaMA 3.1）作为诊断工具，结合系统的人工标注和重新评估，分析基准的结构、语义和语用问题。

Result: 发现基准中存在重复项、模糊措辞和不可信答案等问题，模型性能对输入微小变化敏感，高分可能源于格式匹配而非真实推理。

Conclusion: 当前基于基准的LLM推理能力评估存在局限性，需要开发更注重推理过程的评估方法。论文发布了审计数据和工具以支持更可解释的诊断评估。

Abstract: We conduct a systematic audit of three widely used reasoning benchmarks,
SocialIQa, FauxPas-EAI, and ToMi, and uncover pervasive flaws in both benchmark
items and evaluation methodology. Using five LLMs (GPT-{3, 3.5, 4, o1}, and
LLaMA 3.1) as diagnostic tools, we identify structural, semantic, and pragmatic
issues in benchmark design (e.g., duplicated items, ambiguous wording, and
implausible answers), as well as scoring procedures that prioritize output form
over reasoning process. Through systematic human annotation and re-evaluation
on cleaned benchmark subsets, we find that model scores often improve not due
to due to erratic surface wording variations and not to improved reasoning.
Infact, further analyses show that model performance is highly sensitive to
minor input variations such as context availability and phrasing, revealing
that high scores may reflect alignment with format-specific cues rather than
consistent inference based on the input. These findings challenge the validity
of current benchmark-based claims about reasoning in LLMs, and highlight the
need for evaluation protocols that assess reasoning as a process of drawing
inference from available information, rather than as static output selection.
We release audited data and evaluation tools to support more interpretable and
diagnostic assessments of model reasoning.

</details>


### [114] [Advancing Multi-Step Mathematical Reasoning in Large Language Models through Multi-Layered Self-Reflection with Auto-Prompting](https://arxiv.org/abs/2506.23888)
*André de Souza Loureiro,Jorge Valverde-Rebaza,Julieta Noguez,David Escarcega,Ricardo Marcacini*

Main category: cs.CL

TL;DR: MAPS框架通过结合Chain of Thought、自我反思和自动提示技术，提升LLMs在复杂多步数学推理任务中的表现，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在问题解决能力上有显著进步，但在复杂多步推理任务中仍表现不佳，因此需要一种更高效的方法。

Method: MAPS采用迭代优化过程，结合CoT提示、自我反思和动态调整的自动提示，逐步修正推理错误。

Result: 实验表明，MAPS在多个基准测试中显著优于标准CoT，并能与专用推理模型竞争。

Conclusion: MAPS通过限制反思深度，在成本和推理性能之间取得平衡，为通用LLMs提供了接近专用模型的性能。

Abstract: Recent advancements in Large Language Models (LLMs) have significantly
improved their problem-solving capabilities. However, these models still
struggle when faced with complex multi-step reasoning tasks. In this paper, we
propose the Multi-Layered Self-Reflection with Auto-Prompting (MAPS) framework,
a novel approach designed to enhance multi-step mathematical reasoning in LLMs
by integrating techniques such as Chain of Thought (CoT), Self-Reflection, and
Auto-Prompting. Unlike traditional static prompting methods, MAPS employs an
iterative refinement process. Initially, the model generates a solution using
CoT prompting. When errors are detected, an adaptive self-reflection mechanism
identifies and analyzes them, generating tailored prompts to guide corrections.
These dynamically adjusted prompts enable the model to iteratively refine its
reasoning. Experiments on four well-established benchmarks across multiple LLMs
show that MAPS significantly outperforms standard CoT and achieves competitive
results with reasoning-optimized models. In addition, MAPS enables
general-purpose LLMs to reach performance levels comparable to specialized
reasoning models. While deeper reflection layers improve accuracy, they also
increase token usage and costs. To balance this trade-off, MAPS strategically
limits reflection depth, ensuring an optimal balance between cost and reasoning
performance.

</details>


### [115] [The Trilemma of Truth in Large Language Models](https://arxiv.org/abs/2506.23921)
*Germans Savcisens,Tina Eliassi-Rad*

Main category: cs.CL

TL;DR: 论文探讨了如何评估大型语言模型（LLM）内部知识的真实性，提出了一种名为sAwMIL的新方法，并揭示了关于LLM知识真实性的五个关键发现。


<details>
  <summary>Details</summary>
Motivation: 人们常将人类特性赋予LLM，并认为它们“知道”某些信息。然而，LLM的内部知识是基于概率的，如何验证其真实性是一个重要问题。

Method: 提出了sAwMIL方法，基于多实例学习和一致性预测，利用LLM的内部激活状态将陈述分为真实、虚假和不确定三类。

Result: 在16个开源LLM上验证了sAwMIL，发现真实性信号集中在模型深度的第三部分，真实与虚假信号不对称，线性探针在聊天模型中表现更好等。

Conclusion: sAwMIL为验证LLM内部知识的真实性提供了可靠方法，并揭示了LLM知识表征的新特性。

Abstract: We often attribute human characteristics to large language models (LLMs) and
claim that they "know" certain things. LLMs have an internal probabilistic
knowledge that represents information retained during training. How can we
assess the veracity of this knowledge? We examine two common methods for
probing the veracity of LLMs and discover several assumptions that are flawed.
To address these flawed assumptions, we introduce sAwMIL (short for Sparse
Aware Multiple-Instance Learning), a probing method that utilizes the internal
activations of LLMs to separate statements into true, false, and neither.
sAwMIL is based on multiple-instance learning and conformal prediction. We
evaluate sAwMIL on 5 validity criteria across 16 open-source LLMs, including
both default and chat-based variants, as well as on 3 new datasets. Among the
insights we provide are: (1) the veracity signal is often concentrated in the
third quarter of an LLM's depth; (2) truth and falsehood signals are not always
symmetric; (3) linear probes perform better on chat models than on default
models; (4) nonlinear probes may be required to capture veracity signals for
some LLMs with reinforcement learning from human feedback or knowledge
distillation; and (5) LLMs capture a third type of signal that is distinct from
true and false and is neither true nor false. These findings provide a reliable
method for verifying what LLMs "know" and how certain they are of their
probabilistic internal knowledge.

</details>


### [116] [IMPACT: Inflectional Morphology Probes Across Complex Typologies](https://arxiv.org/abs/2506.23929)
*Mohammed J. Saeed,Tommi Vehvilainen,Evgeny Fedoseev,Sevil Caliskan,Tatiana Vodolazova*

Main category: cs.CL

TL;DR: IMPACT框架评估多语言大模型在形态学上的表现，发现模型在非英语语言中处理复杂形态时存在不足。


<details>
  <summary>Details</summary>
Motivation: 研究多语言大模型是否真正理解非英语语言的形态学复杂性。

Method: 引入IMPACT框架，评估8个多语言大模型在5种形态丰富语言中的表现。

Result: 模型在非英语语言和罕见形态模式上表现不佳，尤其是判断不合语法示例时。

Conclusion: 大模型在语言复杂性处理上存在明显不足，需进一步改进。

Abstract: Large Language Models (LLMs) have shown significant progress on various
multilingual benchmarks and are increasingly used to generate and evaluate text
in non-English languages. However, while they may produce fluent outputs, it
remains unclear to what extent these models truly grasp the underlying
linguistic complexity of those languages, particularly in morphology. To
investigate this, we introduce IMPACT, a synthetically generated evaluation
framework focused on inflectional morphology, which we publicly release,
designed to evaluate LLM performance across five morphologically rich
languages: Arabic, Russian, Finnish, Turkish, and Hebrew. IMPACT includes
unit-test-style cases covering both shared and language-specific phenomena,
from basic verb inflections (e.g., tense, number, gender) to unique features
like Arabic's reverse gender agreement and vowel harmony in Finnish and
Turkish. We assess eight multilingual LLMs that, despite strong English
performance, struggle with other languages and uncommon morphological patterns,
especially when judging ungrammatical examples. We also show that Chain of
Thought and Thinking Models can degrade performance. Our work exposes gaps in
LLMs' handling of linguistic complexity, pointing to clear room for
improvement. To support further research, we publicly release the IMPACT
framework.

</details>


### [117] [Leveraging the Potential of Prompt Engineering for Hate Speech Detection in Low-Resource Languages](https://arxiv.org/abs/2506.23930)
*Ruhina Tabasshum Prome,Tarikul Islam Tamiti,Anomadarshi Barua*

Main category: cs.CL

TL;DR: 论文探讨了如何通过提示工程在低资源语言（如孟加拉语）中有效检测仇恨言论，提出了一种创新的隐喻提示方法，并在多种语言中验证其效果。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上仇恨言论的激增对个人生活和社会安全构成威胁，但低资源语言因缺乏高质量数据集而面临检测挑战。

Method: 研究了六种提示策略（包括创新的隐喻提示），并在Llama2-7B模型上测试，同时比较了三种预训练词嵌入和三种深度学习模型。

Result: 隐喻提示方法在低资源语言中表现优异，并在高资源语言中验证了其普适性，同时评估了环境影响因素。

Conclusion: 隐喻提示是一种有效的低资源语言仇恨言论检测方法，且对环境的影响较小。

Abstract: The rapid expansion of social media leads to a marked increase in hate
speech, which threatens personal lives and results in numerous hate crimes.
Detecting hate speech presents several challenges: diverse dialects, frequent
code-mixing, and the prevalence of misspelled words in user-generated content
on social media platforms. Recent progress in hate speech detection is
typically concentrated on high-resource languages. However, low-resource
languages still face significant challenges due to the lack of large-scale,
high-quality datasets. This paper investigates how we can overcome this
limitation via prompt engineering on large language models (LLMs) focusing on
low-resource Bengali language. We investigate six prompting strategies -
zero-shot prompting, refusal suppression, flattering the classifier, multi-shot
prompting, role prompting, and finally our innovative metaphor prompting to
detect hate speech effectively in low-resource languages. We pioneer the
metaphor prompting to circumvent the built-in safety mechanisms of LLMs that
marks a significant departure from existing jailbreaking methods. We
investigate all six different prompting strategies on the Llama2-7B model and
compare the results extensively with three pre-trained word embeddings - GloVe,
Word2Vec, and FastText for three different deep learning models - multilayer
perceptron (MLP), convolutional neural network (CNN), and bidirectional gated
recurrent unit (BiGRU). To prove the effectiveness of our metaphor prompting in
the low-resource Bengali language, we also evaluate it in another low-resource
language - Hindi, and two high-resource languages - English and German. The
performance of all prompting techniques is evaluated using the F1 score, and
environmental impact factor (IF), which measures CO$_2$ emissions, electricity
usage, and computational time.

</details>


### [118] [Graft: Integrating the Domain Knowledge via Efficient Parameter Synergy for MLLMs](https://arxiv.org/abs/2506.23940)
*Yang Dai,Jianxiang An,Tianwei Lin,Hongyang He,Hongzhe Huang,Wenqiao Zhang,Zheqi Lv,Siliang Tang,Yueting Zhuang*

Main category: cs.CL

TL;DR: 提出了一种统一参数集成框架，通过兼容性感知参数拼接（CAPS）策略，实现领域专用MLLMs的知识共享与模块化组合。


<details>
  <summary>Details</summary>
Motivation: 解决领域专用MLLMs知识碎片化问题，探索跨领域知识共享的潜力。

Method: 采用CAPS策略，结合局部功能归因和全局信息论信号，实现选择性参数融合，并引入领域兼容性评分机制。

Result: 在多样化多模态基准测试中验证了框架的有效性，展示了领域自适应MLLMs的可扩展路径。

Conclusion: 该框架为领域专用MLLMs提供了知识共享和模块化组合的解决方案，具有实际应用潜力。

Abstract: Multimodal Large Language Models (MLLMs) have achieved success across various
domains. However, their applicability tends to degrade when confronted with
different types of data inputs, especially for MLLMs that have been fine-tuned
for specific tasks. Despite its importance, the study of knowledge sharing
among domain-specific MLLMs--such as those trained for mathematics or
code--remains largely underexplored. To address the fragmentation of knowledge
across domain-specialized MLLMs, we propose a unified parameter integration
framework that enables modular composition of expert capabilities. Our method
is grounded in a novel Compatibility-Aware Parameter Splicing (CAPS) strategy,
which leverages both local functional attribution and global
information-theoretic signals to guide selective parameter fusion. By extending
this mechanism to the low-rank adaptation layer granularity, we ensure
efficient integration with minimal inference overhead. Furthermore, we
introduce a domain compatibility scoring mechanism that quantifies inter-expert
alignment at the activation level and correlates with downstream task utility.
This principled fusion protocol allows the final model to synergize
heterogeneous expertise while preserving structural modularity. Extensive
evaluations across diverse multimodal benchmarks validate the effectiveness of
our framework, offering a scalable path toward compositional, domain-adaptive
MLLMs.

</details>


### [119] [Unveiling Decision-Making in LLMs for Text Classification : Extraction of influential and interpretable concepts with Sparse Autoencoders](https://arxiv.org/abs/2506.23951)
*Mathis Le Bail,Jérémie Dentan,Davide Buscaldi,Sonia Vanier*

Main category: cs.CL

TL;DR: 本文研究了稀疏自编码器（SAE）在句子分类任务中的解释性效果，提出了一种新的SAE架构，并通过实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索SAE在句子分类任务中的解释性效果，填补该领域的研究空白。

Method: 提出了一种新的SAE架构，结合专用分类器头和激活率稀疏损失，并与多种现有方法进行对比。

Result: 实验表明，新架构在因果性和可解释性方面均优于现有方法。

Conclusion: SAE在句子分类任务中具有潜力，新架构为解释性研究提供了有效工具。

Abstract: Sparse Autoencoders (SAEs) have been successfully used to probe Large
Language Models (LLMs) and extract interpretable concepts from their internal
representations. These concepts are linear combinations of neuron activations
that correspond to human-interpretable features. In this paper, we investigate
the effectiveness of SAE-based explainability approaches for sentence
classification, a domain where such methods have not been extensively explored.
We present a novel SAE-based architecture tailored for text classification,
leveraging a specialized classifier head and incorporating an activation rate
sparsity loss. We benchmark this architecture against established methods such
as ConceptShap, Independent Component Analysis, and other SAE-based concept
extraction techniques. Our evaluation covers two classification benchmarks and
four fine-tuned LLMs from the Pythia family. We further enrich our analysis
with two novel metrics for measuring the precision of concept-based
explanations, using an external sentence encoder. Our empirical results show
that our architecture improves both the causality and interpretability of the
extracted features.

</details>


### [120] [TaP: A Taxonomy-Guided Framework for Automated and Scalable Preference Data Generation](https://arxiv.org/abs/2506.23979)
*Renren Jin,Tianhao Shen,Xinwei Wu,Dan Shi,Haoran Sun,Wuwei Huang,Quandong Wang,Wei Liu,Jian Luan,Bin Wang,Deyi Xiong*

Main category: cs.CL

TL;DR: 提出了一种名为TaP的框架，用于自动化生成多语言偏好数据集，以解决高质量数据集构建的资源密集问题。实验表明，使用TaP生成的数据集训练的LLM性能优于现有开源数据集。


<details>
  <summary>Details</summary>
Motivation: 构建高质量的多语言偏好数据集资源密集，且现有数据集多为英文，限制了LLM的指令跟随和人类偏好对齐能力。

Method: 提出TaP框架，基于结构化分类法自动生成多语言偏好数据集，确保多样性和全面覆盖。

Result: 使用TaP生成的数据集训练的LLM性能优于现有开源数据集，甚至优于规模大180倍的数据集。

Conclusion: TaP框架为多语言偏好数据集的自动化生成提供了高效解决方案，显著提升了LLM的性能。

Abstract: Conducting supervised fine-tuning and preference fine-tuning on large
language models (LLMs) requires high-quality datasets to improve their ability
to follow instructions and align with human preferences and values. However,
constructing such datasets is resource-intensive, and most available datasets
for supervised and preference fine-tuning are in English. To address these
challenges, we propose the \underline{\textbf{Ta}}xonomy-Guided
\underline{\textbf{P}}reference Data Generation (TaP) framework, which
facilitates automated and scalable construction of preference datasets across
various languages. TaP is grounded in a structured taxonomy that allows
fine-grained control over dataset composition, thereby ensuring both diversity
and comprehensive coverage. We employ TaP-generated datasets to perform
supervised and preference fine-tuning on various LLMs. Experimental results
demonstrate that LLMs trained on TaP-generated datasets outperform those
trained on existing open-source datasets. Remarkably, LLMs trained on
TaP-generated datasets surpass the performance of those trained on an
open-source dataset that is 180 times larger.

</details>


### [121] [Machine Understanding of Scientific Language](https://arxiv.org/abs/2506.23990)
*Dustin Wright*

Main category: cs.CL

TL;DR: 该论文致力于通过自然语言处理和机器学习技术，开发数据集、方法和工具，以自动识别科学文本的忠实性，并解决科学传播中的信息失真问题。


<details>
  <summary>Details</summary>
Motivation: 科学文本的爆炸式增长使得自动识别其忠实性成为社会重要问题，论文旨在通过技术手段解决这一问题。

Method: 论文提出了三个领域的方法：自动事实核查、有限数据学习和科学文本处理，包括新方法如对抗性声明生成、多源域适应等。

Result: 研究展示了如何利用有限科学文本有效识别误导性科学陈述，并为科学传播过程提供新见解。

Conclusion: 论文的研究成果为科学传播中的信息失真问题提供了有效的技术解决方案，并推动了科学语言理解的进步。

Abstract: Scientific information expresses human understanding of nature. This
knowledge is largely disseminated in different forms of text, including
scientific papers, news articles, and discourse among people on social media.
While important for accelerating our pursuit of knowledge, not all scientific
text is faithful to the underlying science. As the volume of this text has
burgeoned online in recent years, it has become a problem of societal
importance to be able to identify the faithfulness of a given piece of
scientific text automatically. This thesis is concerned with the cultivation of
datasets, methods, and tools for machine understanding of scientific language,
in order to analyze and understand science communication at scale. To arrive at
this, I present several contributions in three areas of natural language
processing and machine learning: automatic fact checking, learning with limited
data, and scientific text processing. These contributions include new methods
and resources for identifying check-worthy claims, adversarial claim
generation, multi-source domain adaptation, learning from crowd-sourced labels,
cite-worthiness detection, zero-shot scientific fact checking, detecting
exaggerated scientific claims, and modeling degrees of information change in
science communication. Critically, I demonstrate how the research outputs of
this thesis are useful for effectively learning from limited amounts of
scientific text in order to identify misinformative scientific statements and
generate new insights into the science communication process

</details>


### [122] [Auto-TA: Towards Scalable Automated Thematic Analysis (TA) via Multi-Agent Large Language Models with Reinforcement Learning](https://arxiv.org/abs/2506.23998)
*Seungjun Yi,Joakim Nguyen,Huimin Xu,Terence Lim,Andrew Well,Mia Markey,Ying Ding*

Main category: cs.CL

TL;DR: 提出了一种基于大型语言模型（LLM）的自动化主题分析（TA）流程，用于分析先天性心脏病（CHD）患者和护理者的临床叙述，减少人工编码需求。


<details>
  <summary>Details</summary>
Motivation: 传统临床指标难以全面反映CHD的复杂性，而人工主题分析效率低且难以扩展。

Method: 采用多智能体框架的LLM管道，结合强化学习（RLHF）优化主题相关性。

Result: 实现了对大规模定性数据集的可扩展、以患者为中心的分析。

Conclusion: 自动化TA流程能有效提升临床叙述分析的效率和质量。

Abstract: Congenital heart disease (CHD) presents complex, lifelong challenges often
underrepresented in traditional clinical metrics. While unstructured narratives
offer rich insights into patient and caregiver experiences, manual thematic
analysis (TA) remains labor-intensive and unscalable. We propose a fully
automated large language model (LLM) pipeline that performs end-to-end TA on
clinical narratives, which eliminates the need for manual coding or full
transcript review. Our system employs a novel multi-agent framework, where
specialized LLM agents assume roles to enhance theme quality and alignment with
human analysis. To further improve thematic relevance, we optionally integrate
reinforcement learning from human feedback (RLHF). This supports scalable,
patient-centered analysis of large qualitative datasets and allows LLMs to be
fine-tuned for specific clinical contexts.

</details>


### [123] [Large Language Models Don't Make Sense of Word Problems. A Scoping Review from a Mathematics Education Perspective](https://arxiv.org/abs/2506.24006)
*Anselm R. Strohmaier,Wim Van Dooren,Kathrin Seßler,Brian Greer,Lieven Verschaffel*

Main category: cs.CL

TL;DR: LLMs在数学应用题上表现出色，但缺乏对现实背景的理解，限制了其教育价值。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs如何支持数学学习，尤其是应用题解决能力，并评估其实际教育适用性。

Method: 通过技术概述、文献综述和实证评估三部分，分析LLMs在数学应用题上的表现。

Result: LLMs在标准应用题上表现优异（如PISA题目），但对现实背景复杂的问题表现不佳。

Conclusion: LLMs仅掌握表面解题过程，未真正理解应用题背景，教育应用价值有限。

Abstract: The progress of Large Language Models (LLMs) like ChatGPT raises the question
of how they can be integrated into education. One hope is that they can support
mathematics learning, including word-problem solving. Since LLMs can handle
textual input with ease, they appear well-suited for solving mathematical word
problems. Yet their real competence, whether they can make sense of the
real-world context, and the implications for classrooms remain unclear. We
conducted a scoping review from a mathematics-education perspective, including
three parts: a technical overview, a systematic review of word problems used in
research, and a state-of-the-art empirical evaluation of LLMs on mathematical
word problems. First, in the technical overview, we contrast the
conceptualization of word problems and their solution processes between LLMs
and students. In computer-science research this is typically labeled
mathematical reasoning, a term that does not align with usage in mathematics
education. Second, our literature review of 213 studies shows that the most
popular word-problem corpora are dominated by s-problems, which do not require
a consideration of realities of their real-world context. Finally, our
evaluation of GPT-3.5-turbo, GPT-4o-mini, GPT-4.1, and o3 on 287 word problems
shows that most recent LLMs solve these s-problems with near-perfect accuracy,
including a perfect score on 20 problems from PISA. LLMs still showed
weaknesses in tackling problems where the real-world context is problematic or
non-sensical. In sum, we argue based on all three aspects that LLMs have
mastered a superficial solution process but do not make sense of word problems,
which potentially limits their value as instructional tools in mathematics
classrooms.

</details>


### [124] [EXPERT: An Explainable Image Captioning Evaluation Metric with Structured Explanations](https://arxiv.org/abs/2506.24016)
*Hyunjong Kim,Sangyeop Kim,Jongheon Jeong,Yeongjae Cho,Sungzoon Cho*

Main category: cs.CL

TL;DR: EXPERT是一种新的图像描述评价指标，基于流畅性、相关性和描述性三个标准生成结构化解释，并通过大规模数据集和两阶段评估模板实现高质量解释。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述评价指标的解释缺乏标准化和验证，需要一种更可靠的参考无关评价方法。

Method: 提出EXPERT，基于三个标准生成结构化解释，利用大规模数据集和两阶段评估模板训练视觉语言模型。

Result: 在基准数据集上取得最优结果，生成解释质量显著高于现有指标，并通过人工验证。

Conclusion: EXPERT提供了一种标准化、高质量的解释生成方法，为图像描述评价提供了更可靠的工具。

Abstract: Recent advances in large language models and vision-language models have led
to growing interest in explainable evaluation metrics for image captioning.
However, these metrics generate explanations without standardized criteria, and
the overall quality of the generated explanations remains unverified. In this
paper, we propose EXPERT, a reference-free evaluation metric that provides
structured explanations based on three fundamental criteria: fluency,
relevance, and descriptiveness. By constructing large-scale datasets of
high-quality structured explanations, we develop a two-stage evaluation
template to effectively supervise a vision-language model for both scoring and
explanation generation. EXPERT achieves state-of-the-art results on benchmark
datasets while providing significantly higher-quality explanations than
existing metrics, as validated through comprehensive human evaluation. Our code
and datasets are available at https://github.com/hjkim811/EXPERT.

</details>


### [125] [STACK: Adversarial Attacks on LLM Safeguard Pipelines](https://arxiv.org/abs/2506.24068)
*Ian R. McKenzie,Oskar J. Hollinsworth,Tom Tseng,Xander Davies,Stephen Casper,Aaron D. Tucker,Robert Kirk,Adam Gleave*

Main category: cs.CL

TL;DR: 论文研究了AI防御管线的安全性，开发了一种新型分类器并测试其性能，同时提出了一种攻击方法STACK，展示了防御管线的潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 前沿AI开发者依赖多层防护措施防止AI系统被滥用，但这些管线的安全性尚未充分评估。

Method: 开发了一种新型少样本提示分类器，并设计了一种分阶段攻击方法STACK进行红队测试。

Result: 新型分类器在ClearHarm数据集上将攻击成功率降至0%，但STACK攻击在相同数据集上达到71%的成功率。

Conclusion: 防御管线存在漏洞，建议开发者采用特定缓解措施应对分阶段攻击。

Abstract: Frontier AI developers are relying on layers of safeguards to protect against
catastrophic misuse of AI systems. Anthropic guards their latest Claude 4 Opus
model using one such defense pipeline, and other frontier developers including
Google DeepMind and OpenAI pledge to soon deploy similar defenses. However, the
security of such pipelines is unclear, with limited prior work evaluating or
attacking these pipelines. We address this gap by developing and red-teaming an
open-source defense pipeline. First, we find that a novel few-shot-prompted
input and output classifier outperforms state-of-the-art open-weight safeguard
model ShieldGemma across three attacks and two datasets, reducing the attack
success rate (ASR) to 0% on the catastrophic misuse dataset ClearHarm. Second,
we introduce a STaged AttaCK (STACK) procedure that achieves 71% ASR on
ClearHarm in a black-box attack against the few-shot-prompted classifier
pipeline. Finally, we also evaluate STACK in a transfer setting, achieving 33%
ASR, providing initial evidence that it is feasible to design attacks with no
access to the target pipeline. We conclude by suggesting specific mitigations
that developers could use to thwart staged attacks.

</details>


### [126] [On the Predictive Power of Representation Dispersion in Language Models](https://arxiv.org/abs/2506.24106)
*Yanhong Li,Ming Li,Karen Livescu,Jiawei Zhou*

Main category: cs.CL

TL;DR: 语言模型预测文本的能力与其嵌入空间的广度密切相关，嵌入空间越分散，困惑度越低。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型的嵌入空间分散度与困惑度之间的关系，并利用这一关系优化模型性能。

Method: 通过测量隐藏向量之间的平均余弦距离（分散度），分析其与困惑度的相关性，并提出一种简单的推离目标以增加分散度。

Result: 分散度与困惑度呈强负相关，可用于模型选择、检索方法优化，并通过推离目标直接提升模型性能。

Conclusion: 嵌入空间的分散度是语言模型性能的重要指标，可用于无监督任务优化。

Abstract: We show that a language model's ability to predict text is tightly linked to
the breadth of its embedding space: models that spread their contextual
representations more widely tend to achieve lower perplexity. Concretely, we
find that representation dispersion - the average pairwise cosine distance
among hidden vectors - strongly and negatively correlates with perplexity
across diverse model families (LLaMA, Qwen, and others) and domains (Wikipedia,
news, scientific abstracts). Beyond illustrating this link, we show how
dispersion can be leveraged for a range of practical tasks without requiring
labeled data. First, measuring dispersion on unlabeled text allows us to
predict downstream accuracy in new domains, offering a data-efficient tool for
model selection. Next, we find that identifying layers with higher dispersion
pinpoints the best representations for retrieval-based methods such as kNN-LM,
bypassing exhaustive layer-by-layer searches. Finally, we integrate a simple
push-away objective into training, which increases dispersion in both
single-domain and cross-domain scenarios and directly improves perplexity in
each.

</details>


### [127] [Computational Detection of Intertextual Parallels in Biblical Hebrew: A Benchmark Study Using Transformer-Based Language Models](https://arxiv.org/abs/2506.24117)
*David M. Smiley*

Main category: cs.CL

TL;DR: 该研究评估了预训练语言模型（如E5、AlephBERT等）在检测希伯来圣经文本平行段落中的潜力，发现E5和AlephBERT表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统手动比较方法效率低且易出错，研究旨在探索预训练模型在提高效率和准确性方面的潜力。

Method: 使用E5、AlephBERT、MPNet和LaBSE模型生成词嵌入，并通过余弦相似度和Wasserstein距离评估平行与非平行段落的区分能力。

Result: E5在平行段落检测中表现最佳，AlephBERT在非平行段落区分上更强。

Conclusion: 预训练模型可提升古代文本平行段落检测的效率和准确性，具有广泛的应用前景。

Abstract: Identifying parallel passages in biblical Hebrew is foundational in biblical
scholarship for uncovering intertextual relationships. Traditional methods rely
on manual comparison, which is labor-intensive and prone to human error. This
study evaluates the potential of pre-trained transformer-based language models,
including E5, AlephBERT, MPNet, and LaBSE, for detecting textual parallels in
the Hebrew Bible. Focusing on known parallels between the books of Samuel/Kings
and Chronicles, I assessed each model's capability to generate word embeddings
that delineate parallel from non-parallel passages. Utilizing cosine similarity
and Wasserstein Distance measures, I found that E5 and AlephBERT show
significant promise, with E5 excelling in parallel detection and AlephBERT
demonstrating stronger non-parallel differentiation. These findings indicate
that pre-trained models can enhance the efficiency and accuracy of detecting
intertextual parallels in ancient texts, suggesting broader applications for
ancient language studies.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [128] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

TL;DR: 该研究提出了一种基于物理信息的图像对齐框架，用于结构健康监测中的裂纹定位，通过非线性扩散和RANSAC估计实现高精度对齐，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统特征检测方法（如SIFT、SURF）在高频边缘抑制和复杂环境下表现不佳，而轻量级方法（如ORB、BRISK）在纹理或阴影表面重复性差，因此需要一种更适应结构健康监测需求的解决方案。

Method: 采用改进的KAZE架构，结合非线性各向异性扩散构建裂纹保留的尺度空间，并集成RANSAC单应性估计，无需训练或参数调优。

Result: 在多种实际条件下验证，裂纹面积和长度误差分别减少70%和90%，对齐误差低于5%。

Conclusion: 该方法为结构健康监测提供了一种无监督、可解释且轻量级的解决方案，适用于移动平台和无人机部署。

Abstract: Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [129] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

TL;DR: 本文提出了一种基于计数结果信息和外部环境条件的害虫计数置信度评估方法，通过多因素敏感性分析和自适应DBSCAN聚类算法优化评估，实验显示其性能显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有害虫计数研究在真实场景中缺乏对计数结果可靠性的评估，本文旨在填补这一空白。

Method: 结合害虫检测网络、图像质量与复杂度评估、害虫分布均匀性分析，并通过回归模型预测计数置信度。

Result: 实验表明，该方法在害虫计数置信度测试集上MSE降低31.7%，R2提高15.2%。

Conclusion: 本研究首次全面评估计数任务中的置信度，并通过模型量化影响因素与置信度的关系，为精准农业决策提供支持。

Abstract: Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [130] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

TL;DR: MoDiff是一种创新的调制扩散框架，通过调制量化和误差补偿加速扩散模型，显著降低计算成本且保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的高计算成本是主要瓶颈，现有加速技术（如缓存和量化）在计算误差和生成质量上存在局限。

Method: 提出MoDiff框架，结合调制量化和误差补偿，作为通用加速方法适用于所有扩散模型。

Result: 在CIFAR-10和LSUN上实验表明，MoDiff将激活量化从8位降至3位且无性能损失。

Conclusion: MoDiff通过理论分析和实验验证，突破了现有加速技术的限制，为扩散模型的高效生成提供了新思路。

Abstract: Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [131] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

TL;DR: 提出了一种基于低成本负载传感器的床离开意图预测方法，通过图像融合和双流Swin Transformer实现高精度分类。


<details>
  <summary>Details</summary>
Motivation: 解决医院和长期护理机构中因床离开导致的跌倒问题，现有警报系统反应滞后。

Method: 使用四个负载传感器信号生成图像，结合RGB线图和纹理图，通过ViFusionTST模型进行双流并行处理和跨注意力融合。

Result: 在真实数据集上达到0.885准确率和0.794 F1分数，优于现有基线。

Conclusion: 图像融合负载信号分类是一种实用且有效的实时隐私保护跌倒预防方案。

Abstract: Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [132] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

TL;DR: 提出了一种结合卫星影像与传统交通数据的多类动态起讫点需求估计框架，显著提升了无本地传感器路段的估计性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统本地传感器数据稀疏性问题，利用卫星影像提供全局交通信息。

Method: 设计计算机视觉流程提取车辆类别信息，构建基于计算图的动态需求估计模型。

Result: 实验表明，结合卫星数据显著提升估计准确性，尤其适用于无传感器路段。

Conclusion: 框架具有大规模网络处理能力，适用于不同规模城市的实际部署。

Abstract: This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [133] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

TL;DR: 论文提出了一种解决多模态大语言模型（MLLMs）在手术室风险检测中视觉-语义知识冲突（VS-KC）的方法，通过生成合成数据集OR-VSKC，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 手术风险识别对患者安全和减少医疗错误至关重要，但现有MLLMs在视觉安全违规检测中存在知识冲突问题。

Method: 使用扩散模型生成34,000张合成手术室图像，包含违反安全规则的实体，并辅以214张人工标注图像作为验证基准。

Result: 在OR-VSKC上微调显著提升了MLLMs对训练冲突实体的检测能力，但对未训练实体类型表现不佳。

Conclusion: 研究贡献包括数据生成方法、开源数据集OR-VSKC及其基准，以及对MLLMs知识一致性的实证分析。

Abstract: Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [134] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

TL;DR: 提出了一种名为SpatialNet-ViT的新模型，结合Vision Transformers和多任务学习，以提高遥感分类任务的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于特定任务或数据集，缺乏泛化能力，因此需要一种更通用的方法来解决多样化的遥感分类问题。

Method: 采用Vision Transformers和多任务学习，结合数据增强、迁移学习和多任务学习技术，提升模型的鲁棒性和泛化能力。

Result: 模型在分类准确性和可扩展性方面表现优异，能够适应多样化的数据集。

Conclusion: SpatialNet-ViT通过结合空间感知和上下文理解，为遥感分类任务提供了一种高效且通用的解决方案。

Abstract: Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [135] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

TL;DR: 研究探讨了利用三维姿态跟踪数据提升足球盘带技能评估的方法，与传统二维数据相比，新特征显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖二维位置数据，无法全面捕捉盘带中的平衡、方向和控球等关键因素，限制了评估深度。

Method: 从2022/23赛季欧冠的1736次盘带中提取姿态特征，结合传统二维数据评估其对盘带成功的影响。

Result: 姿态特征（如攻击者平衡和攻防双方方向对齐）对预测盘带成功具有信息量，显著提升模型性能。

Conclusion: 三维姿态数据为足球盘带技能评估提供了更深入的洞察，补充了传统二维数据的不足。

Abstract: Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [136] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种无监督学习方法Patch2Loc，通过训练神经网络从正常MRI图像中学习，检测异常脑组织，优于现有无监督分割方法。


<details>
  <summary>Details</summary>
Motivation: 脑部病变检测对诊断和治疗至关重要，但现有监督学习方法需要标注数据。Patch2Loc旨在通过无监督方法解决这一问题。

Method: 训练神经网络将MRI图像中的正常组织块映射回其空间位置，通过预测误差和方差检测异常组织块，生成热图用于精细分割。

Result: 在多个数据集（BraTS2021、MSLUB、ATLAS、WMH）上验证了模型的有效性，优于现有无监督分割方法。

Conclusion: Patch2Loc为无监督脑部病变检测提供了一种高效方法，具有实际应用潜力。

Abstract: Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [137] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出了一种利用弱监督（图像级标签）训练掩码网络进行二值对象分割的方法，通过生成反事实背景图像提升性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大量标注数据的专业图像领域（如声纳、遥感、生物医学图像），像素级分割成本高，弱监督方法更实用。

Method: 通过聚类背景图像并生成反事实背景图像，结合对比损失和监督损失训练网络。

Result: 在声纳图像和自然图像上均优于现有无监督基线方法，且无需预训练网络或生成对抗网络。

Conclusion: 该方法在弱监督下实现了有效的对象分割，具有广泛适用性。

Abstract: As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [138] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

TL;DR: 提出了一种无需训练的领域噪声对齐（DNA）方法，用于扩散密集预测模型的领域自适应。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在建模包含领域信息的分布转换中表现优异，但噪声统计偏差会导致领域偏移，因此需要一种方法对齐噪声统计以实现领域自适应。

Method: 通过DNA方法对齐目标域与源域的噪声统计，或在无源域时利用高置信区域的统计逐步调整噪声。

Result: 在四种密集预测任务中验证了方法的有效性。

Conclusion: DNA方法显著提升了扩散密集预测模型的领域自适应能力。

Abstract: Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [139] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

TL;DR: 利用生成扩散模型从热红外数据生成夜间可见光反射率，显著提升精度并提供不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 解决夜间无法通过可见光反射率进行全天候气象观测的局限性。

Method: 基于FY4B卫星AGRI的多波段热红外亮温数据，开发了RefDiff模型，实现夜间可见光反射率的高精度反演。

Result: RefDiff的SSIM指数达0.90，在复杂云结构和厚云区域表现优异，夜间反演能力与白天相当。

Conclusion: 该研究显著提升了夜间可见光反射率反演能力，拓展了夜间可见光数据的应用潜力。

Abstract: The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [140] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

TL;DR: 本文提出了一种自动化框架，用于现代射线照相中的缺陷检测和组织，基于NDE 4.0标准。通过虚拟缺陷增强和数据扩展技术优化数据集，并使用改进的U-net模型进行语义分割。结果显示模型在缺陷检测中表现优异，具有高灵敏度和快速推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现代射线照相中信息解释不足的问题，优化虚拟缺陷增强技术，并验证框架在NDE测量中的可行性。

Method: 收集并分类223张飞机焊缝的CR照片，使用虚拟缺陷增强和标准增强技术扩展数据集，训练改进的U-net模型进行语义分割。

Result: 模型在缺陷检测中表现出高灵敏度（a90/95特性），且扩展方法在焊缝区域表现最佳。框架具有快速推理能力，适用于大图像处理。

Conclusion: 该框架在专业评估中表现出潜力，可作为测试周期的支持工具，不受特定设备或软件限制。

Abstract: This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [141] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

TL;DR: 本文比较了三种计算机视觉模型（Yolov11、Yolov12和RF-DETR）在集装箱损伤检测中的性能，发现RF-DETR在罕见损伤检测中表现更优。


<details>
  <summary>Details</summary>
Motivation: 集装箱损伤是物流行业的安全隐患，需及时检测以延长使用寿命和避免风险。

Method: 使用278张标注图像训练和测试三种模型，比较mAP和精度。

Result: Yolov11和12的mAP@50为81.9%，RF-DETR为77.7%，但RF-DETR在罕见损伤检测中表现更优。

Conclusion: RF-DETR更适合检测集装箱损伤，尤其是罕见损伤。

Abstract: Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [142] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 《Preserve Anything》提出了一种新的图像合成方法，通过N通道ControlNet解决多对象保留、语义一致性和场景控制问题，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成方法在多对象保留、语义对齐和场景控制方面存在不足，需要改进。

Method: 采用N通道ControlNet，结合对象保留模块、背景引导模块和高频覆盖模块，确保细节保留和语义一致性。

Result: 在FID（15.26）和CLIP-S（32.85）指标上达到最优，用户研究表明在提示对齐、真实感等方面显著优于现有方法。

Conclusion: 该方法在多对象保留和语义一致性方面表现优异，为图像合成提供了更高效的控制手段。

Abstract: We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [143] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

TL;DR: 论文介绍了Seamless Interaction Dataset，用于开发能理解和生成双向行为动态的AI模型，并展示了相关模型及其应用。


<details>
  <summary>Details</summary>
Motivation: 开发能模拟人类双向行为动态的AI技术，以提升社交智能AI的交互能力。

Method: 构建大规模数据集（4,000小时面对面互动视频），开发生成双向动作和面部表情的模型，并整合语音输入与渲染技术。

Result: 模型能生成与语音对齐的动作和表情，支持情感和语义调整，并展示了在虚拟代理和多模态分析中的潜力。

Conclusion: 该研究为更直观、响应式的人机交互奠定了基础，展示了AI在社交智能领域的应用前景。

Abstract: Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>


### [144] [Recomposed realities: animating still images via patch clustering and randomness](https://arxiv.org/abs/2506.22556)
*Markus Juvonen,Samuli Siltanen*

Main category: cs.CV

TL;DR: 提出了一种基于图像块的重建与动画方法，利用现有图像数据为静态图像添加动态效果。


<details>
  <summary>Details</summary>
Motivation: 通过重新解释而非复制，使静态图像具有动态效果，同时允许源域和目标域在概念上不同但共享局部结构。

Method: 使用k-means聚类对图像块进行分组，通过匹配和随机采样从这些聚类中重建新目标图像。

Result: 实现了静态图像的动态化，同时保持了局部结构的共享。

Conclusion: 该方法为图像动画提供了一种新颖且灵活的方式，强调了重新解释而非直接复制。

Abstract: We present a patch-based image reconstruction and animation method that uses
existing image data to bring still images to life through motion. Image patches
from curated datasets are grouped using k-means clustering and a new target
image is reconstructed by matching and randomly sampling from these clusters.
This approach emphasizes reinterpretation over replication, allowing the source
and target domains to differ conceptually while sharing local structures.

</details>


### [145] [Improving Token-based Object Detection with Video](https://arxiv.org/abs/2506.22562)
*Abhineet Singh,Nilanjan Ray*

Main category: cs.CV

TL;DR: 本文改进了Pix2Seq目标检测器，将其扩展到视频领域，提出了一种新的端到端视频目标检测方法，解决了传统检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统视频目标检测方法存在训练稀疏性和后处理启发式问题，且难以高效处理多目标跟踪。本文旨在通过序列化表示和3D框输出解决这些问题。

Method: 将目标表示为离散标记的可变长度序列，避免定位线索注入；输出完全集成的3D框或轨迹，而非链接2D框。支持灵活调整输入视频子序列长度。

Result: 在多个数据集上优于Pix2Seq静态检测器，计算资源受限时仍与当前最优视频检测器竞争。

Conclusion: 提出的方法通过序列化和3D框输出显著提升了视频目标检测性能，计算资源是主要瓶颈。

Abstract: This paper improves upon the Pix2Seq object detector by extending it for
videos. In the process, it introduces a new way to perform end-to-end video
object detection that improves upon existing video detectors in two key ways.
First, by representing objects as variable-length sequences of discrete tokens,
we can succinctly represent widely varying numbers of video objects, with
diverse shapes and locations, without having to inject any localization cues in
the training process. This eliminates the need to sample the space of all
possible boxes that constrains conventional detectors and thus solves the dual
problems of loss sparsity during training and heuristics-based postprocessing
during inference. Second, it conceptualizes and outputs the video objects as
fully integrated and indivisible 3D boxes or tracklets instead of generating
image-specific 2D boxes and linking these boxes together to construct the video
object, as done in most conventional detectors. This allows it to scale
effortlessly with available computational resources by simply increasing the
length of the video subsequence that the network takes as input, even
generalizing to multi-object tracking if the subsequence can span the entire
video. We compare our video detector with the baseline Pix2Seq static detector
on several datasets and demonstrate consistent improvement, although with
strong signs of being bottlenecked by our limited computational resources. We
also compare it with several video detectors on UA-DETRAC to show that it is
competitive with the current state of the art even with the computational
bottleneck. We make our code and models publicly available.

</details>


### [146] [Unifying Biomedical Vision-Language Expertise: Towards a Generalist Foundation Model via Multi-CLIP Knowledge Distillation](https://arxiv.org/abs/2506.22567)
*Shansong Wang,Zhecheng Jin,Mingzhe Hu,Mojtaba Safari,Feng Zhao,Chih-Wei Chang,Richard LJ Qiu,Justin Roper,David S. Yu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MMKD-CLIP通过多教师知识蒸馏构建高性能生物医学基础模型，解决了数据稀缺和异构性问题，在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生物医学领域缺乏大规模图像-文本对数据，且图像模态和标准不统一，限制了基础模型的开发。

Method: 采用两阶段训练：先在290万生物医学图像-文本对上预训练，再从9个教师模型中蒸馏1920万特征对。

Result: 在58个数据集上评估，涵盖1080万图像和9种模态，MMKD-CLIP在所有教师模型中表现最佳。

Conclusion: 多教师知识蒸馏是构建高性能生物医学基础模型的有效方法。

Abstract: CLIP models pretrained on natural images with billion-scale image-text pairs
have demonstrated impressive capabilities in zero-shot classification,
cross-modal retrieval, and open-ended visual answering. However, transferring
this success to biomedicine is hindered by the scarcity of large-scale
biomedical image-text corpora, the heterogeneity of image modalities, and
fragmented data standards across institutions. These limitations hinder the
development of a unified and generalizable biomedical foundation model trained
from scratch. To overcome this, we introduce MMKD-CLIP, a generalist biomedical
foundation model developed via Multiple Medical CLIP Knowledge Distillation.
Rather than relying on billion-scale raw data, MMKD-CLIP distills knowledge
from nine state-of-the-art domain-specific or generalist biomedical CLIP
models, each pretrained on millions of biomedical image-text pairs. Our
two-stage training pipeline first performs CLIP-style pretraining on over 2.9
million biomedical image-text pairs from 26 image modalities, followed by
feature-level distillation using over 19.2 million feature pairs extracted from
teacher models. We evaluate MMKD-CLIP on 58 diverse biomedical datasets,
encompassing over 10.8 million biomedical images across nine image modalities.
The evaluation spans six core task types: zero-shot classification, linear
probing, cross-modal retrieval, visual question answering, survival prediction,
and cancer diagnosis. MMKD-CLIP consistently outperforms all teacher models
while demonstrating remarkable robustness and generalization across image
domains and task settings. These results underscore that multi-teacher
knowledge distillation is a scalable and effective paradigm for building
high-performing biomedical foundation models under the practical constraints of
real-world data availability.

</details>


### [147] [Dual Atrous Separable Convolution for Improving Agricultural Semantic Segmentation](https://arxiv.org/abs/2506.22570)
*Chee Mei Ling,Thangarajah Akilan,Aparna Ravinda Phalke*

Main category: cs.CV

TL;DR: 提出了一种基于DeepLabV3的高效农业图像语义分割方法，通过引入DAS Conv模块和优化跳跃连接，在保持低计算复杂度的同时，性能接近复杂Transformer模型。


<details>
  <summary>Details</summary>
Motivation: 农业图像语义分割对精准农业至关重要，需高效方法以支持决策和干预。

Method: 在DeepLabV3框架中集成DAS Conv模块，优化膨胀率和填充大小，并设计跳跃连接以捕捉细节特征。

Result: 在Agriculture Vision数据集上性能接近SOTA模型，效率提升66%。

Conclusion: 该方法为农业遥感提供了一种高效、轻量的高质量语义分割解决方案。

Abstract: Agricultural image semantic segmentation is a pivotal component of modern
agriculture, facilitating accurate visual data analysis to improve crop
management, optimize resource utilization, and boost overall productivity. This
study proposes an efficient image segmentation method for precision
agriculture, focusing on accurately delineating farmland anomalies to support
informed decision-making and proactive interventions. A novel Dual Atrous
Separable Convolution (DAS Conv) module is integrated within the
DeepLabV3-based segmentation framework. The DAS Conv module is meticulously
designed to achieve an optimal balance between dilation rates and padding size,
thereby enhancing model performance without compromising efficiency. The study
also incorporates a strategic skip connection from an optimal stage in the
encoder to the decoder to bolster the model's capacity to capture fine-grained
spatial features. Despite its lower computational complexity, the proposed
model outperforms its baseline and achieves performance comparable to highly
complex transformer-based state-of-the-art (SOTA) models on the Agriculture
Vision benchmark dataset. It achieves more than 66% improvement in efficiency
when considering the trade-off between model complexity and performance,
compared to the SOTA model. This study highlights an efficient and effective
solution for improving semantic segmentation in remote sensing applications,
offering a computationally lightweight model capable of high-quality
performance in agricultural imagery.

</details>


### [148] [LIGHT: Multi-Modal Text Linking on Historical Maps](https://arxiv.org/abs/2506.22589)
*Yijun Lin,Rhett Olson,Junhan Wu,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: LIGHT是一种多模态方法，结合语言、图像和几何特征，用于链接历史地图上的文本，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 历史地图上的文本信息对多学科研究至关重要，但现有方法难以有效链接文本片段，尤其是多词地名。

Method: LIGHT通过几何感知嵌入模块编码文本区域的多边形坐标，结合LayoutLMv3的视觉和语言特征，预测文本实例的阅读顺序。

Result: 实验表明，LIGHT在ICDAR 2024/2025 MapText竞赛数据上优于现有方法。

Conclusion: 多模态学习能有效提升历史地图文本链接的性能。

Abstract: Text on historical maps provides valuable information for studies in history,
economics, geography, and other related fields. Unlike structured or
semi-structured documents, text on maps varies significantly in orientation,
reading order, shape, and placement. Many modern methods can detect and
transcribe text regions, but they struggle to effectively ``link'' the
recognized text fragments, e.g., determining a multi-word place name. Existing
layout analysis methods model word relationships to improve text understanding
in structured documents, but they primarily rely on linguistic features and
neglect geometric information, which is essential for handling map text. To
address these challenges, we propose LIGHT, a novel multi-modal approach that
integrates linguistic, image, and geometric features for linking text on
historical maps. In particular, LIGHT includes a geometry-aware embedding
module that encodes the polygonal coordinates of text regions to capture
polygon shapes and their relative spatial positions on an image. LIGHT unifies
this geometric information with the visual and linguistic token embeddings from
LayoutLMv3, a pretrained layout analysis model. LIGHT uses the cross-modal
information to predict the reading-order successor of each text instance
directly with a bi-directional learning strategy that enhances sequence
robustness. Experimental results show that LIGHT outperforms existing methods
on the ICDAR 2024/2025 MapText Competition data, demonstrating the
effectiveness of multi-modal learning for historical map text linking.

</details>


### [149] [BrainMT: A Hybrid Mamba-Transformer Architecture for Modeling Long-Range Dependencies in Functional MRI Data](https://arxiv.org/abs/2506.22591)
*Arunkumar Kannan,Martin A. Lindquist,Brian Caffo*

Main category: cs.CV

TL;DR: BrainMT是一种新型混合框架，通过结合双向Mamba块和Transformer块，有效捕捉fMRI数据中的长程时空依赖关系，显著提升分类和回归任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于卷积神经网络或Transformer的方法难以建模fMRI数据中的复杂关系，尤其是长程时空依赖。

Method: BrainMT采用两阶段设计：1）双向Mamba块捕捉全局时间交互；2）Transformer块建模全局空间关系。

Result: 在UKBioBank和Human Connectome Project数据集上，BrainMT在分类（性别预测）和回归（认知智力预测）任务中表现优于现有方法。

Conclusion: BrainMT通过高效学习长程时空属性，为fMRI数据分析提供了新的解决方案，性能显著提升。

Abstract: Recent advances in deep learning have made it possible to predict phenotypic
measures directly from functional magnetic resonance imaging (fMRI) brain
volumes, sparking significant interest in the neuroimaging community. However,
existing approaches, primarily based on convolutional neural networks or
transformer architectures, often struggle to model the complex relationships
inherent in fMRI data, limited by their inability to capture long-range spatial
and temporal dependencies. To overcome these shortcomings, we introduce
BrainMT, a novel hybrid framework designed to efficiently learn and integrate
long-range spatiotemporal attributes in fMRI data. Our framework operates in
two stages: (1) a bidirectional Mamba block with a temporal-first scanning
mechanism to capture global temporal interactions in a computationally
efficient manner; and (2) a transformer block leveraging self-attention to
model global spatial relationships across the deep features processed by the
Mamba block. Extensive experiments on two large-scale public datasets,
UKBioBank and the Human Connectome Project, demonstrate that BrainMT achieves
state-of-the-art performance on both classification (sex prediction) and
regression (cognitive intelligence prediction) tasks, outperforming existing
methods by a significant margin. Our code and implementation details will be
made publicly available at this
https://github.com/arunkumar-kannan/BrainMT-fMRI

</details>


### [150] [Seg-R1: Segmentation Can Be Surprisingly Simple with Reinforcement Learning](https://arxiv.org/abs/2506.22624)
*Zuyao You,Zuxuan Wu*

Main category: cs.CV

TL;DR: Seg-R1利用强化学习（RL）增强大型多模态模型（LMMs）的像素级理解能力，通过GRPO策略在分割任务中表现优异，无需复杂模型修改即可实现高性能，并展示出强大的开放世界泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过强化学习提升LMMs在像素级任务（如前景分割）中的理解和推理能力，同时实现开放世界的泛化。

Method: 采用GRPO策略，通过点与边界框提示引导SAM2生成分割掩码，完全基于RL训练。

Result: 在COD10K上达到0.873 S-measure，在RefCOCOg和ReasonSeg上分别实现71.4 cIoU和56.7 gIoU的零样本性能。

Conclusion: Seg-R1展示了纯RL训练在分割任务中的潜力，无需文本监督即可实现高性能和泛化能力。

Abstract: We present Seg-R1, a preliminary exploration of using reinforcement learning
(RL) to enhance the pixel-level understanding and reasoning capabilities of
large multimodal models (LMMs). Starting with foreground segmentation tasks,
specifically camouflaged object detection (COD) and salient object detection
(SOD), our approach enables the LMM to generate point and bounding box prompts
in the next-token fashion, which are then used to guide SAM2 in producing
segmentation masks. We introduce Group Relative Policy Optimization (GRPO) into
the segmentation domain, equipping the LMM with pixel-level comprehension
through a carefully designed training strategy. Notably, Seg-R1 achieves
remarkable performance with purely RL-based training, achieving .873 S-measure
on COD10K without complex model modification. Moreover, we found that pure RL
training demonstrates strong open-world generalization. Despite being trained
solely on foreground segmentation image-mask pairs without text supervision,
Seg-R1 achieves impressive zero-shot performance on referring segmentation and
reasoning segmentation tasks, with 71.4 cIoU on RefCOCOg test and 56.7 gIoU on
ReasonSeg test, outperforming models fully supervised on these datasets.

</details>


### [151] [ReCo: Reminder Composition Mitigates Hallucinations in Vision-Language Models](https://arxiv.org/abs/2506.22636)
*Sotirios Panagiotis Chytas,Miso Choi,Hyunwoo J. Kim,Vikas Singh*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级模块ReCo，用于缓解视觉语言模型（VLMs）中的幻觉问题，通过几何代数和关系组合的方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在生成文本时容易产生幻觉，即生成与视觉输入无关或矛盾的文本，主要原因是模型对语言的过度依赖和视觉输入的‘记忆衰减效应’。

Method: 在现有VLM模型上添加一个可训练的小模块ReCo，利用几何代数和关系组合的思想，无需其他修改。

Result: 在InstructBLIP、LlaVA和MiniGPT4等主流VLM上，ReCo模块有效缓解了记忆衰减效应，并在多个基准测试中提升了性能。此外，ReCo还能与其他减少幻觉的方法结合，进一步提升效果。

Conclusion: ReCo模块是一种轻量且有效的解决方案，能够显著减少VLM的幻觉问题，同时兼容其他方法，具有广泛的应用潜力。

Abstract: Vision Language Models (VLMs) show impressive capabilities in integrating and
reasoning with both visual and language data. But these models make mistakes. A
common finding -- similar to LLMs -- is their tendency to hallucinate, i.e.,
generate plausible sounding text which is not grounded in the visual input, or
at worst, is contradictory. A growing consensus attributes this behavior to an
over-reliance on language -- especially as the generation progresses, the model
suffers from a ``fading memory effect'' with respect to the provided visual
input. We study mechanisms by which this behavior can be controlled.
Specifically, using ideas from geometric algebra and relational compositions,
we propose the addition of a small, trainable module (named ReCo) on top of any
VLM -- no other modification is needed. We show that such a lightweight module
is able to mitigate the fading memory effect on three of the most widely used
VLMs (InstructBLIP, LlaVA, MiniGPT4), where we see performance improvements on
multiple benchmarks. Additionally, we show that our module can be combined with
many of the other approaches for reducing hallucination where we achieve
improved results for each one.

</details>


### [152] [CaO$_2$: Rectifying Inconsistencies in Diffusion-Based Dataset Distillation](https://arxiv.org/abs/2506.22637)
*Haoxuan Wang,Zhenghao Zhao,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: 论文提出了一种名为CaO$_2$的两阶段扩散框架，解决了当前扩散模型在数据集蒸馏中的目标不一致和条件不一致问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在数据集蒸馏中存在目标不一致和条件不一致的问题，导致蒸馏过程与评估目标不匹配。

Method: 提出CaO$_2$框架，分为两阶段：第一阶段使用概率信息样本选择管道，第二阶段优化潜在表示以提高条件似然。

Result: 在ImageNet及其子集上表现优异，平均准确率超过基线2.3%。

Conclusion: CaO$_2$通过解决不一致性问题，显著提升了扩散模型在数据集蒸馏中的性能。

Abstract: The recent introduction of diffusion models in dataset distillation has shown
promising potential in creating compact surrogate datasets for large,
high-resolution target datasets, offering improved efficiency and performance
over traditional bi-level/uni-level optimization methods. However, current
diffusion-based dataset distillation approaches overlook the evaluation process
and exhibit two critical inconsistencies in the distillation process: (1)
Objective Inconsistency, where the distillation process diverges from the
evaluation objective, and (2) Condition Inconsistency, leading to mismatches
between generated images and their corresponding conditions. To resolve these
issues, we introduce Condition-aware Optimization with Objective-guided
Sampling (CaO$_2$), a two-stage diffusion-based framework that aligns the
distillation process with the evaluation objective. The first stage employs a
probability-informed sample selection pipeline, while the second stage refines
the corresponding latent representations to improve conditional likelihood.
CaO$_2$ achieves state-of-the-art performance on ImageNet and its subsets,
surpassing the best-performing baselines by an average of 2.3% accuracy.

</details>


### [153] [3D Shape Generation: A Survey](https://arxiv.org/abs/2506.22678)
*Nicolas Caytuiro,Ivan Sipiran*

Main category: cs.CV

TL;DR: 本文综述了3D形状生成的最新进展，围绕形状表示、生成方法和评估协议三大核心组件展开讨论，旨在为研究者提供全面的参考。


<details>
  <summary>Details</summary>
Motivation: 深度学习的发展推动了3D形状生成领域的进步，本文旨在系统梳理当前技术，帮助研究者快速了解这一快速发展的领域。

Method: 通过分类3D表示（显式、隐式、混合）、总结生成方法（前馈架构）以及评估指标（保真度、多样性、真实性）来组织内容。

Result: 综述了当前3D形状生成的技术现状，并总结了常用数据集和评估方法。

Conclusion: 指出了未来研究方向，包括可控性、高效性和高质量生成，为领域发展提供了参考。

Abstract: Recent advances in deep learning have significantly transformed the field of
3D shape generation, enabling the synthesis of complex, diverse, and
semantically meaningful 3D objects. This survey provides a comprehensive
overview of the current state of the art in 3D shape generation, organizing the
discussion around three core components: shape representations, generative
modeling approaches, and evaluation protocols. We begin by categorizing 3D
representations into explicit, implicit, and hybrid setups, highlighting their
structural properties, advantages, and limitations. Next, we review a wide
range of generation methods, focusing on feedforward architectures. We further
summarize commonly used datasets and evaluation metrics that assess fidelity,
diversity, and realism of generated shapes. Finally, we identify open
challenges and outline future research directions that could drive progress in
controllable, efficient, and high-quality 3D shape generation. This survey aims
to serve as a valuable reference for researchers and practitioners seeking a
structured and in-depth understanding of this rapidly evolving field.

</details>


### [154] [LightBSR: Towards Lightweight Blind Super-Resolution via Discriminative Implicit Degradation Representation Learning](https://arxiv.org/abs/2506.22710)
*Jiang Yuan,JI Ma,Bo Wang,Guanzhou Ke,Weiming Hu*

Main category: cs.CV

TL;DR: 论文提出了一种基于隐式退化估计的盲超分辨率方法（LightBSR），通过优化隐式退化表示（IDR）的区分性，设计了一个轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了IDR区分性对盲超分辨率的重要性，且过度复杂化适应过程，导致模型参数和计算量大幅增加。

Method: 采用基于知识蒸馏的学习框架，包括退化先验约束的对比学习技术和特征对齐技术。

Result: 实验证明LightBSR在多种盲超分辨率任务中表现优异且复杂度低。

Conclusion: 优化IDR区分性可显著提升盲超分辨率模型性能，同时保持轻量级设计。

Abstract: Implicit degradation estimation-based blind super-resolution (IDE-BSR) hinges
on extracting the implicit degradation representation (IDR) of the LR image and
adapting it to LR image features to guide HR detail restoration. Although
IDE-BSR has shown potential in dealing with noise interference and complex
degradations, existing methods ignore the importance of IDR discriminability
for BSR and instead over-complicate the adaptation process to improve effect,
resulting in a significant increase in the model's parameters and computations.
In this paper, we focus on the discriminability optimization of IDR and propose
a new powerful and lightweight BSR model termed LightBSR. Specifically, we
employ a knowledge distillation-based learning framework. We first introduce a
well-designed degradation-prior-constrained contrastive learning technique
during teacher stage to make the model more focused on distinguishing different
degradation types. Then we utilize a feature alignment technique to transfer
the degradation-related knowledge acquired by the teacher to the student for
practical inferencing. Extensive experiments demonstrate the effectiveness of
IDR discriminability-driven BSR model design. The proposed LightBSR can achieve
outstanding performance with minimal complexity across a range of blind SR
tasks. Our code is accessible at: https://github.com/MJ-NCEPU/LightBSR.

</details>


### [155] [Part Segmentation and Motion Estimation for Articulated Objects with Dynamic 3D Gaussians](https://arxiv.org/abs/2506.22718)
*Jun-Jee Chao,Qingyuan Jiang,Volkan Isler*

Main category: cs.CV

TL;DR: 提出一种联合解决部分分割和运动估计的方法，通过3D高斯表示处理点云序列，适用于遮挡和多传感器异步采集场景。


<details>
  <summary>Details</summary>
Motivation: 解决在点云序列中，由于遮挡或多传感器异步采集导致点对应关系不可靠的问题。

Method: 使用3D高斯表示物体，参数化时间依赖的旋转、平移和尺度，建立点与高斯的对应关系以实现分割和运动估计。

Result: 在遮挡场景下，部分分割性能优于现有方法13%，且对缺失点更鲁棒。

Conclusion: 所提方法在复杂场景下表现优越，适用于实际应用。

Abstract: Part segmentation and motion estimation are two fundamental problems for
articulated object motion analysis. In this paper, we present a method to solve
these two problems jointly from a sequence of observed point clouds of a single
articulated object. The main challenge in our problem setting is that the point
clouds are not assumed to be generated by a fixed set of moving points.
Instead, each point cloud in the sequence could be an arbitrary sampling of the
object surface at that particular time step. Such scenarios occur when the
object undergoes major occlusions, or if the dataset is collected using
measurements from multiple sensors asynchronously. In these scenarios, methods
that rely on tracking point correspondences are not appropriate. We present an
alternative approach based on a compact but effective representation where we
represent the object as a collection of simple building blocks modeled as 3D
Gaussians. We parameterize the Gaussians with time-dependent rotations,
translations, and scales that are shared across all time steps. With our
representation, part segmentation can be achieved by building correspondences
between the observed points and the Gaussians. Moreover, the transformation of
each point across time can be obtained by following the poses of the assigned
Gaussian (even when the point is not observed). Experiments show that our
method outperforms existing methods that solely rely on finding point
correspondences. Additionally, we extend existing datasets to emulate
real-world scenarios by considering viewpoint occlusions. We further
demonstrate that our method is more robust to missing points as compared to
existing approaches on these challenging datasets, even when some parts are
completely occluded in some time-steps. Notably, our part segmentation
performance outperforms the state-of-the-art method by 13% on point clouds with
occlusions.

</details>


### [156] [Deterministic Object Pose Confidence Region Estimation](https://arxiv.org/abs/2506.22720)
*Jinghao Wang,Zhang Li,Zi Wang,Banglei Guan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种确定性方法，通过归纳共形预测和隐函数定理，高效估计6D姿态置信区域，避免采样方法的低效和区域过大问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于采样的6D姿态置信区域估计方法存在采样速度慢和置信区域过大的问题，限制了实际应用。

Method: 使用归纳共形预测校准高斯关键点分布，并通过隐函数定理直接传播为6D姿态置信区域。

Result: 在LineMOD Occlusion和SPEED数据集上，方法显著减少置信区域体积（旋转99.9%，平移99.8%），同时提高姿态估计精度和计算效率。

Conclusion: 该方法提供紧凑的置信区域，满足用户定义的置信水平，优于传统采样方法。

Abstract: 6D pose confidence region estimation has emerged as a critical direction,
aiming to perform uncertainty quantification for assessing the reliability of
estimated poses. However, current sampling-based approach suffers from critical
limitations that severely impede their practical deployment: 1) the sampling
speed significantly decreases as the number of samples increases. 2) the
derived confidence regions are often excessively large. To address these
challenges, we propose a deterministic and efficient method for estimating pose
confidence regions. Our approach uses inductive conformal prediction to
calibrate the deterministically regressed Gaussian keypoint distributions into
2D keypoint confidence regions. We then leverage the implicit function theorem
to propagate these keypoint confidence regions directly into 6D pose confidence
regions. This method avoids the inefficiency and inflated region sizes
associated with sampling and ensembling. It provides compact confidence regions
that cover the ground-truth poses with a user-defined confidence level.
Experimental results on the LineMOD Occlusion and SPEED datasets show that our
method achieves higher pose estimation accuracy with reduced computational
time. For the same coverage rate, our method yields significantly smaller
confidence region volumes, reducing them by up to 99.9\% for rotations and
99.8\% for translations. The code will be available soon.

</details>


### [157] [XTransfer: Cross-Modality Model Transfer for Human Sensing with Few Data at the Edge](https://arxiv.org/abs/2506.22726)
*Yu Zhang,Xi Zhang,Hualin zhou,Xinyuan Chen,Shang Gao,Hong Jia,Jianfei Yang,Yuankai Qi,Tao Gu*

Main category: cs.CV

TL;DR: XTransfer是一种资源高效、模态无关的模型迁移方法，通过模型修复和层重组解决预训练模型在边缘系统中的模态偏移和资源需求问题。


<details>
  <summary>Details</summary>
Motivation: 边缘系统中深度学习模型的训练和开发受限于传感器数据的稀缺性和资源约束，现有方法存在模态偏移和高资源需求的问题。

Method: XTransfer通过模型修复（修复模态偏移）和层重组（高效搜索和重组源模型层）实现跨模态知识迁移。

Result: XTransfer在多种人类感知任务中实现了最先进的性能，同时显著降低了数据收集、模型训练和边缘部署的成本。

Conclusion: XTransfer为边缘系统中的人类感知任务提供了一种高效、适应性强的解决方案。

Abstract: Deep learning for human sensing on edge systems offers significant
opportunities for smart applications. However, its training and development are
hindered by the limited availability of sensor data and resource constraints of
edge systems. Current methods that rely on transferring pre-trained models
often encounter issues such as modality shift and high resource demands,
resulting in substantial accuracy loss, resource overhead, and poor
adaptability across different sensing applications. In this paper, we propose
XTransfer, a first-of-its-kind method for resource-efficient, modality-agnostic
model transfer. XTransfer freely leverages single or multiple pre-trained
models and transfers knowledge across different modalities by (i) model
repairing that safely repairs modality shift in pre-trained model layers with
only few sensor data, and (ii) layer recombining that efficiently searches and
recombines layers of interest from source models in a layer-wise manner to
create compact models. We benchmark various baselines across diverse human
sensing datasets spanning different modalities. Comprehensive results
demonstrate that XTransfer achieves state-of-the-art performance on human
sensing tasks while significantly reducing the costs of sensor data collection,
model training, and edge deployment.

</details>


### [158] [UniFuse: A Unified All-in-One Framework for Multi-Modal Medical Image Fusion Under Diverse Degradations and Misalignments](https://arxiv.org/abs/2506.22736)
*Dayong Su,Yafei Zhang,Huafeng Li,Jinxing Li,Yu Liu*

Main category: cs.CV

TL;DR: UniFuse是一个多模态医学图像融合框架，通过嵌入退化感知提示学习模块和Omni统一特征表示方案，实现了对齐、恢复和融合的联合优化。


<details>
  <summary>Details</summary>
Motivation: 当前多模态医学图像融合方法假设源图像质量高且像素级对齐，但在处理未对齐或退化图像时效果下降。UniFuse旨在解决这一问题。

Method: UniFuse结合退化感知提示学习模块、Omni统一特征表示方案（使用Spatial Mamba编码多方向特征）和通用特征恢复与融合模块（基于LoRA的ALSN网络）。

Result: 实验结果表明，UniFuse在多个数据集上优于现有方法，实现了对齐、恢复和融合的联合优化。

Conclusion: UniFuse通过统一框架解决了多模态医学图像融合中的对齐和退化问题，具有显著优势。

Abstract: Current multimodal medical image fusion typically assumes that source images
are of high quality and perfectly aligned at the pixel level. Its effectiveness
heavily relies on these conditions and often deteriorates when handling
misaligned or degraded medical images. To address this, we propose UniFuse, a
general fusion framework. By embedding a degradation-aware prompt learning
module, UniFuse seamlessly integrates multi-directional information from input
images and correlates cross-modal alignment with restoration, enabling joint
optimization of both tasks within a unified framework. Additionally, we design
an Omni Unified Feature Representation scheme, which leverages Spatial Mamba to
encode multi-directional features and mitigate modality differences in feature
alignment. To enable simultaneous restoration and fusion within an All-in-One
configuration, we propose a Universal Feature Restoration & Fusion module,
incorporating the Adaptive LoRA Synergistic Network (ALSN) based on LoRA
principles. By leveraging ALSN's adaptive feature representation along with
degradation-type guidance, we enable joint restoration and fusion within a
single-stage framework. Compared to staged approaches, UniFuse unifies
alignment, restoration, and fusion within a single framework. Experimental
results across multiple datasets demonstrate the method's effectiveness and
significant advantages over existing approaches.

</details>


### [159] [Deep Learning based Joint Geometry and Attribute Up-sampling for Large-Scale Colored Point Clouds](https://arxiv.org/abs/2506.22749)
*Yun Zhang,Feifan Chen,Na Li,Zhiwei Guo,Xu Wang,Fen Miao,Sam Kwong*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的联合几何与属性上采样方法（JGAU），用于生成大规模高密度彩色点云，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 彩色点云是3D应用的主流表示形式，但现有方法在生成大规模高密度点云时存在不足，因此需要一种能同时优化几何和属性的方法。

Method: 提出了JGAU框架，包括几何上采样网络和属性上采样网络，并引入两种粗属性上采样方法（GDWAI和DLAI）及属性增强模块。

Result: 实验表明，JGAU在4倍、8倍、12倍和16倍上采样率下的PSNR分别为33.90、32.10、31.10和30.39分贝，优于现有方法。

Conclusion: JGAU通过联合优化几何和属性，显著提升了彩色点云的上采样质量。

Abstract: Colored point cloud, which includes geometry and attribute components, is a
mainstream representation enabling realistic and immersive 3D applications. To
generate large-scale and denser colored point clouds, we propose a deep
learning-based Joint Geometry and Attribute Up-sampling (JGAU) method that
learns to model both geometry and attribute patterns while leveraging spatial
attribute correlations. First, we establish and release a large-scale dataset
for colored point cloud up-sampling called SYSU-PCUD, containing 121
large-scale colored point clouds with diverse geometry and attribute
complexities across six categories and four sampling rates. Second, to improve
the quality of up-sampled point clouds, we propose a deep learning-based JGAU
framework that jointly up-samples geometry and attributes. It consists of a
geometry up-sampling network and an attribute up-sampling network, where the
latter leverages the up-sampled auxiliary geometry to model neighborhood
correlations of the attributes. Third, we propose two coarse attribute
up-sampling methods, Geometric Distance Weighted Attribute Interpolation
(GDWAI) and Deep Learning-based Attribute Interpolation (DLAI), to generate
coarse up-sampled attributes for each point. Then, an attribute enhancement
module is introduced to refine these up-sampled attributes and produce
high-quality point clouds by further exploiting intrinsic attribute and
geometry patterns. Extensive experiments show that the Peak Signal-to-Noise
Ratio (PSNR) achieved by the proposed JGAU method is 33.90 decibels, 32.10
decibels, 31.10 decibels, and 30.39 decibels for up-sampling rates of 4 times,
8 times, 12 times, and 16 times, respectively. Compared to state-of-the-art
methods, JGAU achieves average PSNR gains of 2.32 decibels, 2.47 decibels, 2.28
decibels, and 2.11 decibels at these four up-sampling rates, demonstrating
significant improvement.

</details>


### [160] [Degradation-Modeled Multipath Diffusion for Tunable Metalens Photography](https://arxiv.org/abs/2506.22753)
*Jianing Zhang,Jiayi Zhu,Feiyu Ji,Xiaokang Yang,Xiaoyun Yuan*

Main category: cs.CV

TL;DR: 提出了一种基于预训练模型的多路径扩散方法，用于解决金属透镜摄影中的光学退化和计算恢复问题，无需依赖大量配对数据。


<details>
  <summary>Details</summary>
Motivation: 金属透镜在超紧凑计算成像中潜力巨大，但面临复杂光学退化和计算恢复的挑战，现有方法依赖精确校准或大量数据，难以实际应用。

Method: 采用多路径扩散框架，结合正、中、负提示路径平衡细节生成与结构保真，并引入伪数据增强和可调解码器。SVDA模块自适应建模光学和传感器退化。

Result: 实验结果表明，该方法优于现有技术，实现了高保真和清晰的图像重建。

Conclusion: 通过预训练模型和多路径扩散，解决了金属透镜摄影中的退化问题，展示了实际应用的潜力。

Abstract: Metalenses offer significant potential for ultra-compact computational
imaging but face challenges from complex optical degradation and computational
restoration difficulties. Existing methods typically rely on precise optical
calibration or massive paired datasets, which are non-trivial for real-world
imaging systems. Furthermore, a lack of control over the inference process
often results in undesirable hallucinated artifacts. We introduce
Degradation-Modeled Multipath Diffusion for tunable metalens photography,
leveraging powerful natural image priors from pretrained models instead of
large datasets. Our framework uses positive, neutral, and negative-prompt paths
to balance high-frequency detail generation, structural fidelity, and
suppression of metalens-specific degradation, alongside \textit{pseudo} data
augmentation. A tunable decoder enables controlled trade-offs between fidelity
and perceptual quality. Additionally, a spatially varying degradation-aware
attention (SVDA) module adaptively models complex optical and sensor-induced
degradation. Finally, we design and build a millimeter-scale MetaCamera for
real-world validation. Extensive results show that our approach outperforms
state-of-the-art methods, achieving high-fidelity and sharp image
reconstruction. More materials: https://dmdiff.github.io/.

</details>


### [161] [RoboPearls: Editable Video Simulation for Robot Manipulation](https://arxiv.org/abs/2506.22756)
*Tao Tang,Likui Zhang,Youpeng Wen,Kaidong Zhang,Jia-Wang Bian,xia zhou,Tianyi Yan,Kun Zhan,Peng Jia,Hefeng Wu,Liang Lin,Xiaodan Liang*

Main category: cs.CV

TL;DR: RoboPearls是一个基于3D高斯散射的可编辑视频仿真框架，用于机器人操作，通过结合大语言模型和视觉语言模型，提升仿真效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界演示数据收集成本高、效率低的问题，以及仿真与现实的差距。

Method: 利用3D高斯散射构建逼真仿真，结合增量语义蒸馏和3D正则化NNFM损失，并通过大语言模型和视觉语言模型自动化仿真过程。

Result: 在多个数据集和场景中验证了RoboPearls的有效性，包括RLBench、COLOSSEUM等。

Conclusion: RoboPearls能够高效生成逼真仿真，并提升机器人学习性能。

Abstract: The development of generalist robot manipulation policies has seen
significant progress, driven by large-scale demonstration data across diverse
environments. However, the high cost and inefficiency of collecting real-world
demonstrations hinder the scalability of data acquisition. While existing
simulation platforms enable controlled environments for robotic learning, the
challenge of bridging the sim-to-real gap remains. To address these challenges,
we propose RoboPearls, an editable video simulation framework for robotic
manipulation. Built on 3D Gaussian Splatting (3DGS), RoboPearls enables the
construction of photo-realistic, view-consistent simulations from demonstration
videos, and supports a wide range of simulation operators, including various
object manipulations, powered by advanced modules like Incremental Semantic
Distillation (ISD) and 3D regularized NNFM Loss (3D-NNFM). Moreover, by
incorporating large language models (LLMs), RoboPearls automates the simulation
production process in a user-friendly manner through flexible command
interpretation and execution. Furthermore, RoboPearls employs a vision-language
model (VLM) to analyze robotic learning issues to close the simulation loop for
performance enhancement. To demonstrate the effectiveness of RoboPearls, we
conduct extensive experiments on multiple datasets and scenes, including
RLBench, COLOSSEUM, Ego4D, Open X-Embodiment, and a real-world robot, which
demonstrate our satisfactory simulation performance.

</details>


### [162] [VSRM: A Robust Mamba-Based Framework for Video Super-Resolution](https://arxiv.org/abs/2506.22762)
*Dinh Phu Tran,Dao Duy Hung,Daeyoung Kim*

Main category: cs.CV

TL;DR: VSRM是一种基于Mamba的视频超分辨率框架，通过引入时空Mamba块和可变形交叉Mamba对齐模块，高效提取长程时空特征并增强感受野，同时提出频率Charbonnier-like损失以提升视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决CNN和Transformer在视频超分辨率任务中的局限性，如CNN的局部感受野和Transformer的二次复杂度问题。

Method: 提出VSRM框架，包含时空Mamba块、可变形交叉Mamba对齐模块和频率Charbonnier-like损失。

Result: 在多个基准测试中取得最先进的结果。

Conclusion: VSRM为未来研究提供了坚实基础。

Abstract: Video super-resolution remains a major challenge in low-level vision tasks.
To date, CNN- and Transformer-based methods have delivered impressive results.
However, CNNs are limited by local receptive fields, while Transformers
struggle with quadratic complexity, posing challenges for processing long
sequences in VSR. Recently, Mamba has drawn attention for its long-sequence
modeling, linear complexity, and large receptive fields. In this work, we
propose VSRM, a novel \textbf{V}ideo \textbf{S}uper-\textbf{R}esolution
framework that leverages the power of \textbf{M}amba. VSRM introduces
Spatial-to-Temporal Mamba and Temporal-to-Spatial Mamba blocks to extract
long-range spatio-temporal features and enhance receptive fields efficiently.
To better align adjacent frames, we propose Deformable Cross-Mamba Alignment
module. This module utilizes a deformable cross-mamba mechanism to make the
compensation stage more dynamic and flexible, preventing feature distortions.
Finally, we minimize the frequency domain gaps between reconstructed and
ground-truth frames by proposing a simple yet effective Frequency
Charbonnier-like loss that better preserves high-frequency content and enhances
visual quality. Through extensive experiments, VSRM achieves state-of-the-art
results on diverse benchmarks, establishing itself as a solid foundation for
future research.

</details>


### [163] [PhonemeFake: Redefining Deepfake Realism with Language-Driven Segmental Manipulation and Adaptive Bilevel Detection](https://arxiv.org/abs/2506.22783)
*Oguzhan Baser,Ahmet Ege Tanriverdi,Sriram Vishwanath,Sandeep P. Chinchali*

Main category: cs.CV

TL;DR: 论文提出PhonemeFake（PF）攻击方法，通过语言推理操纵关键语音片段，显著降低人类感知和基准准确率，并开源了检测模型和数据集。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake（DF）数据集未能真实反映攻击对人类感知的影响，需要更现实的攻击向量。

Method: 引入PF攻击方法，利用语言推理操纵语音片段，并开发了自适应优先计算的双层DF检测模型。

Result: PF攻击使人类感知降低42%，基准准确率降低94%；检测模型将EER降低91%，速度提升90%。

Conclusion: PF攻击和检测模型为DF攻击提供了更现实的解决方案，具有高效性和可扩展性。

Abstract: Deepfake (DF) attacks pose a growing threat as generative models become
increasingly advanced. However, our study reveals that existing DF datasets
fail to deceive human perception, unlike real DF attacks that influence public
discourse. It highlights the need for more realistic DF attack vectors. We
introduce PhonemeFake (PF), a DF attack that manipulates critical speech
segments using language reasoning, significantly reducing human perception by
up to 42% and benchmark accuracies by up to 94%. We release an easy-to-use PF
dataset on HuggingFace and open-source bilevel DF segment detection model that
adaptively prioritizes compute on manipulated regions. Our extensive
experiments across three known DF datasets reveal that our detection model
reduces EER by 91% while achieving up to 90% speed-up, with minimal compute
overhead and precise localization beyond existing models as a scalable
solution.

</details>


### [164] [Single-Frame Point-Pixel Registration via Supervised Cross-Modal Feature Matching](https://arxiv.org/abs/2506.22784)
*Yu Han,Zhiwei Huang,Yanting Zhang,Fangjun Ding,Shen Cai,Rui Fan*

Main category: cs.CV

TL;DR: 提出了一种基于无检测器匹配框架的直接点-像素配准方法，用于LiDAR点云与相机图像的跨模态匹配，显著提升了稀疏单帧LiDAR数据的配准性能。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云与相机图像之间的模态差异问题，特别是在稀疏单帧LiDAR数据下，现有方法难以有效匹配且依赖多帧累积或额外先验。

Method: 通过将LiDAR强度图投影到2D视图，并利用基于注意力的无检测器匹配网络进行跨模态匹配，同时引入可重复性评分机制提升可靠性。

Result: 在KITTI、nuScenes和MIAS-LCEC-TF70基准测试中表现优异，优于依赖多帧累积的现有方法。

Conclusion: 该方法为稀疏单帧LiDAR数据的点-像素配准提供了高效且鲁棒的解决方案。

Abstract: Point-pixel registration between LiDAR point clouds and camera images is a
fundamental yet challenging task in autonomous driving and robotic perception.
A key difficulty lies in the modality gap between unstructured point clouds and
structured images, especially under sparse single-frame LiDAR settings.
Existing methods typically extract features separately from point clouds and
images, then rely on hand-crafted or learned matching strategies. This separate
encoding fails to bridge the modality gap effectively, and more critically,
these methods struggle with the sparsity and noise of single-frame LiDAR, often
requiring point cloud accumulation or additional priors to improve reliability.
Inspired by recent progress in detector-free matching paradigms (e.g.
MatchAnything), we revisit the projection-based approach and introduce the
detector-free framework for direct point-pixel matching between LiDAR and
camera views. Specifically, we project the LiDAR intensity map into a 2D view
from the LiDAR perspective and feed it into an attention-based detector-free
matching network, enabling cross-modal correspondence estimation without
relying on multi-frame accumulation. To further enhance matching reliability,
we introduce a repeatability scoring mechanism that acts as a soft visibility
prior. This guides the network to suppress unreliable matches in regions with
low intensity variation, improving robustness under sparse input. Extensive
experiments on KITTI, nuScenes, and MIAS-LCEC-TF70 benchmarks demonstrate that
our method achieves state-of-the-art performance, outperforming prior
approaches on nuScenes (even those relying on accumulated point clouds),
despite using only single-frame LiDAR.

</details>


### [165] [RGE-GS: Reward-Guided Expansive Driving Scene Reconstruction via Diffusion Priors](https://arxiv.org/abs/2506.22800)
*Sicong Du,Jiarun Liu,Qifeng Chen,Hao-Xiang Chen,Tai-Jiang Mu,Sheng Yang*

Main category: cs.CV

TL;DR: RGE-GS提出了一种结合扩散生成与奖励引导高斯积分的新型扩展重建框架，解决了现有3D高斯溅射技术中的物理不一致性和训练效率问题。


<details>
  <summary>Details</summary>
Motivation: 单次驾驶片段扫描通常无法完整捕捉道路结构，需要扩展重建技术以提升传感器模拟器的驾驶动作回归效果。

Method: RGE-GS通过奖励网络优先选择一致性生成模式，并采用差异化训练策略优化高斯积分过程。

Result: 在公开数据集上的评估显示，RGE-GS在重建质量上达到最优性能。

Conclusion: RGE-GS通过创新方法显著提升了扩展重建的质量和效率，代码将开源。

Abstract: A single-pass driving clip frequently results in incomplete scanning of the
road structure, making reconstructed scene expanding a critical requirement for
sensor simulators to effectively regress driving actions. Although contemporary
3D Gaussian Splatting (3DGS) techniques achieve remarkable reconstruction
quality, their direct extension through the integration of diffusion priors
often introduces cumulative physical inconsistencies and compromises training
efficiency. To address these limitations, we present RGE-GS, a novel expansive
reconstruction framework that synergizes diffusion-based generation with
reward-guided Gaussian integration. The RGE-GS framework incorporates two key
innovations: First, we propose a reward network that learns to identify and
prioritize consistently generated patterns prior to reconstruction phases,
thereby enabling selective retention of diffusion outputs for spatial
stability. Second, during the reconstruction process, we devise a
differentiated training strategy that automatically adjust Gaussian
optimization progress according to scene converge metrics, which achieving
better convergence than baseline methods. Extensive evaluations of publicly
available datasets demonstrate that RGE-GS achieves state-of-the-art
performance in reconstruction quality. Our source-code will be made publicly
available at https://github.com/CN-ADLab/RGE-GS. (Camera-ready version
incorporating reviewer suggestions will be updated soon.)

</details>


### [166] [Intervening in Black Box: Concept Bottleneck Model for Enhancing Human Neural Network Mutual Understanding](https://arxiv.org/abs/2506.22803)
*Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Mei Lin,Peiyi Shen,Liang Zhang*

Main category: cs.CV

TL;DR: 提出了CBM-HNMU模型，通过概念瓶颈模型提升深度学习的可解释性，并优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型复杂且难以解释，现有方法缺乏有效干预或仅针对样本级别。

Method: 利用概念瓶颈模型（CBM）作为可解释框架，识别并优化有害概念，将修正后的知识蒸馏回黑盒模型。

Result: 在多个数据集上测试，最高准确率提升2.64%，平均准确率提升1.03%。

Conclusion: CBM-HNMU显著提升了模型的可解释性和准确性。

Abstract: Recent advances in deep learning have led to increasingly complex models with
deeper layers and more parameters, reducing interpretability and making their
decisions harder to understand. While many methods explain black-box reasoning,
most lack effective interventions or only operate at sample-level without
modifying the model itself. To address this, we propose the Concept Bottleneck
Model for Enhancing Human-Neural Network Mutual Understanding (CBM-HNMU).
CBM-HNMU leverages the Concept Bottleneck Model (CBM) as an interpretable
framework to approximate black-box reasoning and communicate conceptual
understanding. Detrimental concepts are automatically identified and refined
(removed/replaced) based on global gradient contributions. The modified CBM
then distills corrected knowledge back into the black-box model, enhancing both
interpretability and accuracy. We evaluate CBM-HNMU on various CNN and
transformer-based models across Flower-102, CIFAR-10, CIFAR-100, FGVC-Aircraft,
and CUB-200, achieving a maximum accuracy improvement of 2.64% and a maximum
increase in average accuracy across 1.03%. Source code is available at:
https://github.com/XiGuaBo/CBM-HNMU.

</details>


### [167] [Concept Pinpoint Eraser for Text-to-image Diffusion Models via Residual Attention Gate](https://arxiv.org/abs/2506.22806)
*Byung Hyun Lee,Sungjin Lim,Seunggyu Lee,Dong Un Kang,Se Young Chun*

Main category: cs.CV

TL;DR: 文本到图像扩散模型的进步引发了对生成不当或商标概念图像的担忧。本文提出了一种非线性概念擦除框架（CPE），通过选择性擦除目标概念并保护其他概念，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有概念擦除方法仅更新交叉注意力层可能导致剩余概念失真的问题。

Method: 提出CPE框架，引入非线性残差注意力门（ResAGs）和注意力锚定损失，通过对抗训练增强鲁棒性。

Result: 在名人、艺术风格和不当内容擦除任务中，CPE表现优于现有方法，保持剩余概念的多样性。

Conclusion: CPE通过非线性模块和对抗训练，有效擦除目标概念并保护其他概念，具有鲁棒性。

Abstract: Remarkable progress in text-to-image diffusion models has brought a major
concern about potentially generating images on inappropriate or trademarked
concepts. Concept erasing has been investigated with the goals of deleting
target concepts in diffusion models while preserving other concepts with
minimal distortion. To achieve these goals, recent concept erasing methods
usually fine-tune the cross-attention layers of diffusion models. In this work,
we first show that merely updating the cross-attention layers in diffusion
models, which is mathematically equivalent to adding \emph{linear} modules to
weights, may not be able to preserve diverse remaining concepts. Then, we
propose a novel framework, dubbed Concept Pinpoint Eraser (CPE), by adding
\emph{nonlinear} Residual Attention Gates (ResAGs) that selectively erase (or
cut) target concepts while safeguarding remaining concepts from broad
distributions by employing an attention anchoring loss to prevent the
forgetting. Moreover, we adversarially train CPE with ResAG and learnable text
embeddings in an iterative manner to maximize erasing performance and enhance
robustness against adversarial attacks. Extensive experiments on the erasure of
celebrities, artistic styles, and explicit contents demonstrated that the
proposed CPE outperforms prior arts by keeping diverse remaining concepts while
deleting the target concepts with robustness against attack prompts. Code is
available at https://github.com/Hyun1A/CPE

</details>


### [168] [FreqDGT: Frequency-Adaptive Dynamic Graph Networks with Transformer for Cross-subject EEG Emotion Recognition](https://arxiv.org/abs/2506.22807)
*Yueyang Li,Shengyu Gong,Weiming Zeng,Nizhuan Wang,Wai Ting Siok*

Main category: cs.CV

TL;DR: FreqDGT是一种频率自适应的动态图变换器，通过整合频率自适应处理、动态图学习和多尺度时间解缠网络，显著提高了跨被试情绪识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决脑电图（EEG）在情绪识别中跨被试泛化的挑战，如个体差异和情绪响应的多样性。

Method: 提出FreqDGT框架，包括频率自适应处理（FAP）、自适应动态图学习（ADGL）和多尺度时间解缠网络（MTDN）。

Result: 实验表明FreqDGT显著提高了跨被试情绪识别的准确性，验证了其频率自适应、空间动态和时间分层建模的有效性。

Conclusion: FreqDGT通过整合多种技术，成功解决了跨被试情绪识别的挑战，并展示了其鲁棒性和有效性。

Abstract: Electroencephalography (EEG) serves as a reliable and objective signal for
emotion recognition in affective brain-computer interfaces, offering unique
advantages through its high temporal resolution and ability to capture
authentic emotional states that cannot be consciously controlled. However,
cross-subject generalization remains a fundamental challenge due to individual
variability, cognitive traits, and emotional responses. We propose FreqDGT, a
frequency-adaptive dynamic graph transformer that systematically addresses
these limitations through an integrated framework. FreqDGT introduces
frequency-adaptive processing (FAP) to dynamically weight emotion-relevant
frequency bands based on neuroscientific evidence, employs adaptive dynamic
graph learning (ADGL) to learn input-specific brain connectivity patterns, and
implements multi-scale temporal disentanglement network (MTDN) that combines
hierarchical temporal transformers with adversarial feature disentanglement to
capture both temporal dynamics and ensure cross-subject robustness.
Comprehensive experiments demonstrate that FreqDGT significantly improves
cross-subject emotion recognition accuracy, confirming the effectiveness of
integrating frequency-adaptive, spatial-dynamic, and temporal-hierarchical
modeling while ensuring robustness to individual differences. The code is
available at https://github.com/NZWANG/FreqDGT.

</details>


### [169] [Efficient Multi-Crop Saliency Partitioning for Automatic Image Cropping](https://arxiv.org/abs/2506.22814)
*Andrew Hamara,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 提出了一种高效提取多个非重叠裁剪区域的图像裁剪方法，动态调整注意力阈值并避免重复计算显著图。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅优化单一裁剪框，无法满足需要多个不连续裁剪区域的应用需求。

Method: 扩展固定宽高比裁剪算法，动态调整注意力阈值并移除已选裁剪区域，避免重复计算显著图。

Result: 实现了线性时间内高效提取多个非重叠裁剪区域，讨论了定性结果。

Conclusion: 方法有效解决了多裁剪需求，未来可扩展数据集和基准测试。

Abstract: Automatic image cropping aims to extract the most visually salient regions
while preserving essential composition elements. Traditional saliency-aware
cropping methods optimize a single bounding box, making them ineffective for
applications requiring multiple disjoint crops. In this work, we extend the
Fixed Aspect Ratio Cropping algorithm to efficiently extract multiple
non-overlapping crops in linear time. Our approach dynamically adjusts
attention thresholds and removes selected crops from consideration without
recomputing the entire saliency map. We discuss qualitative results and
introduce the potential for future datasets and benchmarks.

</details>


### [170] [Unleashing the Multi-View Fusion Potential: Noise Correction in VLM for Open-Vocabulary 3D Scene Understanding](https://arxiv.org/abs/2506.22817)
*Xingyilang Yin,Jiale Wang,Xi Yang,Mutian Xu,Xu Gu,Nannan Wang*

Main category: cs.CV

TL;DR: MVOV3D是一种新方法，通过减少2D多视图融合中的固有噪声，提升开放词汇3D场景理解能力，无需训练即可保留泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在有限词汇量下表现良好，但难以处理多样化的对象类别，且3D数据量限制了开放词汇模型的训练。2D多视图融合方法虽有潜力，但受视觉语言模型固有噪声影响。

Method: MVOV3D利用CLIP编码器的精确区域级图像和文本特征，结合3D几何先验优化多视图融合，减少噪声。

Result: 在ScanNet200和Matterport160数据集上，MVOV3D分别以14.7%和16.2%的mIoU创下开放词汇语义分割新纪录，显著优于现有3D网络。

Conclusion: MVOV3D通过优化多视图融合，显著提升了开放词汇3D场景理解的性能，无需额外训练即可实现泛化能力。

Abstract: Recent open-vocabulary 3D scene understanding approaches mainly focus on
training 3D networks through contrastive learning with point-text pairs or by
distilling 2D features into 3D models via point-pixel alignment. While these
methods show considerable performance in benchmarks with limited vocabularies,
they struggle to handle diverse object categories as the limited amount of 3D
data upbound training strong open-vocabulary 3d models. We observe that 2D
multi-view fusion methods take precedence in understanding diverse concepts in
3D scenes. However, inherent noises in vision-language models lead multi-view
fusion to sub-optimal performance. To this end, we introduce MVOV3D, a novel
approach aimed at unleashing the potential of 2D multi-view fusion for
open-vocabulary 3D scene understanding. We focus on reducing the inherent
noises without training, thereby preserving the generalizability while
enhancing open-world capabilities. Specifically, MVOV3D improves multi-view 2D
features by leveraging precise region-level image features and text features
encoded by CLIP encoders and incorporates 3D geometric priors to optimize
multi-view fusion. Extensive experiments on various datasets demonstrate the
effectiveness of our method. Notably, our MVOV3D achieves a new record with
14.7% mIoU on ScanNet200 and 16.2% mIoU on Matterport160 for challenge
open-vocabulary semantic segmentation, outperforming current leading trained 3D
networks by a significant margin.

</details>


### [171] [Prompting without Panic: Attribute-aware, Zero-shot, Test-Time Calibration](https://arxiv.org/abs/2506.22819)
*Ramya Hebbalaguppe,Tamoghno Kandar,Abhinav Nagpal,Chetan Arora*

Main category: cs.CV

TL;DR: 该论文提出了一种改进视觉语言模型（VLM）测试时提示调优（TPT）的方法，通过初始化提示和正则化损失来提升校准性能。


<details>
  <summary>Details</summary>
Motivation: TPT方法在提高准确率的同时导致置信度校准下降，限制了其在关键应用中的适用性。

Method: 1. 使用大型语言模型（LLM）初始化提示；2. 提出正则化损失以减少类内距离并增加类间距离。

Result: 在15个数据集上的实验表明，该方法显著降低了预期校准误差（ECE），平均ECE为4.11，优于其他方法。

Conclusion: 通过初始化提示和正则化损失，有效改善了TPT后的校准性能，提升了模型的实用性。

Abstract: Vision-language models (VLM) have demonstrated impressive performance in
image recognition by leveraging self-supervised training on large datasets.
Their performance can be further improved by adapting to the test sample using
test-time prompt tuning (TPT). Unfortunately, the singular focus of TPT
approaches on improving the accuracy suffers from tunnel vision, and leads to
degradation in confidence calibration. This limits the applicability of TPT in
critical applications.
  We make three contributions in this work. (1) We posit that random or naive
initialization of prompts leads to overfitting on a particular test sample, and
is the main reason for miscalibration of the VLM after TPT. To mitigate the
problem, we propose careful initialization of test time prompt using prior
knowledge about the target label attributes from a large language model (LLM);
(2) To further maintain the quality of prompts during \tpt, we propose a novel
regularization loss to reduce intraclass distance, and increase inter-class
distance between the learnt
  Through extensive experiments on different CLIP architectures and 15
datasets, we show that our approach can effectively improve the calibration
after TPT. We report an average expected calibration error (ECE) of 4.11 with
our method, TCA, compared to 11.7 for vanilla TPT, 6.12 for C-TPT (ICLR'24),
6.78 for DiffTPT (CVPR'23), and 8.43 for PromptAlign (NeurIPS'23). The code is
publicly accessible at:
https://github.com/rhebbalaguppe/TCA_PromptWithoutPanic.

</details>


### [172] [Listener-Rewarded Thinking in VLMs for Image Preferences](https://arxiv.org/abs/2506.22832)
*Alexander Gambashidze,Li Pengyi,Matvey Skripkin,Andrey Galichin,Anton Gusarov,Konstantin Sobolev,Andrey Kuznetsov,Ivan Oseledets*

Main category: cs.CV

TL;DR: 论文提出了一种基于听众增强的GRPO框架，通过重新评估推理链的置信度来改进奖励模型，显著提升了泛化性能和推理一致性。


<details>
  <summary>Details</summary>
Motivation: 当前奖励模型在泛化和避免记忆化方面表现不佳，需要复杂的标注流程。强化学习（如GRPO）虽能改善泛化，但在推理一致性上存在缺陷。

Method: 引入听众增强的GRPO框架，利用冻结的视觉语言模型（听众）重新评估推理链，生成校准的置信度分数，从而优化强化学习奖励信号。

Result: 在ImageReward基准测试中达到67.4%的准确率，在OOD数据集上提升6%，并显著减少推理矛盾。

Conclusion: 听众增强的奖励机制为视觉语言模型与人类偏好对齐提供了高效、可扩展的解决方案。

Abstract: Training robust and generalizable reward models for human visual preferences
is essential for aligning text-to-image and text-to-video generative models
with human intent. However, current reward models often fail to generalize, and
supervised fine-tuning leads to memorization, demanding complex annotation
pipelines. While reinforcement learning (RL), specifically Group Relative
Policy Optimization (GRPO), improves generalization, we uncover a key failure
mode: a significant drop in reasoning accuracy occurs when a model's reasoning
trace contradicts that of an independent, frozen vision-language model
("listener") evaluating the same output. To address this, we introduce a
listener-augmented GRPO framework. Here, the listener re-evaluates the
reasoner's chain-of-thought to provide a dense, calibrated confidence score,
shaping the RL reward signal. This encourages the reasoner not only to answer
correctly, but to produce explanations that are persuasive to an independent
model. Our listener-shaped reward scheme achieves best accuracy on the
ImageReward benchmark (67.4%), significantly improves out-of-distribution (OOD)
performance on a large-scale human preference dataset (1.2M votes, up to +6%
over naive reasoner), and reduces reasoning contradictions compared to strong
GRPO and SFT baselines. These results demonstrate that listener-based rewards
provide a scalable, data-efficient path to aligning vision-language models with
nuanced human preferences. We will release our reasoning model here:
https://huggingface.co/alexgambashidze/qwen2.5vl_image_preference_reasoner.

</details>


### [173] [SemFaceEdit: Semantic Face Editing on Generative Radiance Manifolds](https://arxiv.org/abs/2506.22833)
*Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: SemFaceEdit是一种基于生成辐射流形的新方法，通过语义场实现面部图像的局部编辑，解决了现有方法无法精确编辑的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知GAN技术虽然提供多视角一致性，但缺乏局部编辑能力，因此需要一种能精确控制面部语义的方法。

Method: SemFaceEdit通过几何模块和外观模块联合训练，生成语义辐射场和RGB辐射场，利用潜在码解耦几何与外观。

Result: 实验表明，SemFaceEdit在语义场编辑中表现优异，实现了更好的辐射场解耦和局部控制。

Conclusion: SemFaceEdit为面部图像的精确编辑提供了高效解决方案，尤其在语义感知的几何和外观解耦方面具有优势。

Abstract: Despite multiple view consistency offered by 3D-aware GAN techniques, the
resulting images often lack the capacity for localized editing. In response,
generative radiance manifolds emerge as an efficient approach for constrained
point sampling within volumes, effectively reducing computational demands and
enabling the learning of fine details. This work introduces SemFaceEdit, a
novel method that streamlines the appearance and geometric editing process by
generating semantic fields on generative radiance manifolds. Utilizing latent
codes, our method effectively disentangles the geometry and appearance
associated with different facial semantics within the generated image. In
contrast to existing methods that can change the appearance of the entire
radiance field, our method enables the precise editing of particular facial
semantics while preserving the integrity of other regions. Our network
comprises two key modules: the Geometry module, which generates semantic
radiance and occupancy fields, and the Appearance module, which is responsible
for predicting RGB radiance. We jointly train both modules in adversarial
settings to learn semantic-aware geometry and appearance descriptors. The
appearance descriptors are then conditioned on their respective semantic latent
codes by the Appearance Module, facilitating disentanglement and enhanced
control. Our experiments highlight SemFaceEdit's superior performance in
semantic field-based editing, particularly in achieving improved radiance field
disentanglement.

</details>


### [174] [FOCUS: Fine-grained Optimization with Semantic Guided Understanding for Pedestrian Attributes Recognition](https://arxiv.org/abs/2506.22836)
*Hongyan An,Kuan Zhu,Xin He,Haiyun Guo,Chaoyang Zhao,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 提出FOCUS方法，通过多粒度混合令牌和属性引导视觉特征提取，提升行人属性识别的细粒度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法提取的区域特征限制了性能和实用性，无法泛化到未见属性。

Method: 使用多粒度混合令牌（MGMT）和属性引导视觉特征提取（AVFE），结合区域感知对比学习（RACL）。

Result: 在PA100K、PETA和RAPv1数据集上验证了方法的有效性和泛化能力。

Conclusion: FOCUS方法显著提升了行人属性识别的细粒度和泛化性能。

Abstract: Pedestrian attribute recognition (PAR) is a fundamental perception task in
intelligent transportation and security. To tackle this fine-grained task, most
existing methods focus on extracting regional features to enrich attribute
information. However, a regional feature is typically used to predict a fixed
set of pre-defined attributes in these methods, which limits the performance
and practicality in two aspects: 1) Regional features may compromise
fine-grained patterns unique to certain attributes in favor of capturing common
characteristics shared across attributes. 2) Regional features cannot
generalize to predict unseen attributes in the test time. In this paper, we
propose the \textbf{F}ine-grained \textbf{O}ptimization with semanti\textbf{C}
g\textbf{U}ided under\textbf{S}tanding (FOCUS) approach for PAR, which
adaptively extracts fine-grained attribute-level features for each attribute
individually, regardless of whether the attributes are seen or not during
training. Specifically, we propose the Multi-Granularity Mix Tokens (MGMT) to
capture latent features at varying levels of visual granularity, thereby
enriching the diversity of the extracted information. Next, we introduce the
Attribute-guided Visual Feature Extraction (AVFE) module, which leverages
textual attributes as queries to retrieve their corresponding visual attribute
features from the Mix Tokens using a cross-attention mechanism. To ensure that
textual attributes focus on the appropriate Mix Tokens, we further incorporate
a Region-Aware Contrastive Learning (RACL) method, encouraging attributes
within the same region to share consistent attention maps. Extensive
experiments on PA100K, PETA, and RAPv1 datasets demonstrate the effectiveness
and strong generalization ability of our method.

</details>


### [175] [AG-VPReID 2025: Aerial-Ground Video-based Person Re-identification Challenge Results](https://arxiv.org/abs/2506.22843)
*Kien Nguyen,Clinton Fookes,Sridha Sridharan,Huy Nguyen,Feng Liu,Xiaoming Liu,Arun Ross,Dana Michalski,Tamás Endrei,Ivan DeAndres-Tame,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez,Javier Ortega-Garcia,Zijing Gong,Yuhao Wang,Xuehu Liu,Pingping Zhang,Md Rashidunnabi,Hugo Proença,Kailash A. Hambarde,Saeid Rezaei*

Main category: cs.CV

TL;DR: AG-VPReID 2025挑战赛首次提出基于视频的高空（80-120米）空中-地面行人重识别任务，使用新数据集AG-VPReID，包含3027个身份和370万帧数据。领先方法X-TFCLIP在两种场景下均超过70%的Rank-1准确率。


<details>
  <summary>Details</summary>
Motivation: 解决空中与地面视角差异、尺度变化和遮挡带来的行人重识别挑战，推动大规模监控和公共安全应用。

Method: 基于AG-ReID 2023挑战赛成果，构建AG-VPReID数据集，举办国际竞赛，团队采用多流架构、基于Transformer的时间推理和物理建模等方法。

Result: 领先方法X-TFCLIP在空对地和对空场景中分别达到72.28%和70.77%的Rank-1准确率。

Conclusion: AG-VPReID挑战赛展示了数据集复杂性，并推动了空中-地面行人重识别技术的发展。

Abstract: Person re-identification (ReID) across aerial and ground vantage points has
become crucial for large-scale surveillance and public safety applications.
Although significant progress has been made in ground-only scenarios, bridging
the aerial-ground domain gap remains a formidable challenge due to extreme
viewpoint differences, scale variations, and occlusions. Building upon the
achievements of the AG-ReID 2023 Challenge, this paper introduces the AG-VPReID
2025 Challenge - the first large-scale video-based competition focused on
high-altitude (80-120m) aerial-ground ReID. Constructed on the new AG-VPReID
dataset with 3,027 identities, over 13,500 tracklets, and approximately 3.7
million frames captured from UAVs, CCTV, and wearable cameras, the challenge
featured four international teams. These teams developed solutions ranging from
multi-stream architectures to transformer-based temporal reasoning and
physics-informed modeling. The leading approach, X-TFCLIP from UAM, attained
72.28% Rank-1 accuracy in the aerial-to-ground ReID setting and 70.77% in the
ground-to-aerial ReID setting, surpassing existing baselines while highlighting
the dataset's complexity. For additional details, please refer to the official
website at https://agvpreid25.github.io.

</details>


### [176] [DMD-Net: Deep Mesh Denoising Network](https://arxiv.org/abs/2506.22850)
*Aalok Gangopadhyay,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: DMD-Net是一种端到端的深度学习框架，用于网格去噪，通过图卷积神经网络和双流网络实现，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决网格去噪问题，提升去噪效果，尤其是在高噪声环境下。

Method: 采用图卷积神经网络，结合原始图和双图的双流网络，以及特征引导变换器（FGT）范式。

Result: 在多种噪声条件下表现优异，性能优于现有方法。

Conclusion: DMD-Net是一种高效且鲁棒的网格去噪方法。

Abstract: We present Deep Mesh Denoising Network (DMD-Net), an end-to-end deep learning
framework, for solving the mesh denoising problem. DMD-Net consists of a Graph
Convolutional Neural Network in which aggregation is performed in both the
primal as well as the dual graph. This is realized in the form of an asymmetric
two-stream network, which contains a primal-dual fusion block that enables
communication between the primal-stream and the dual-stream. We develop a
Feature Guided Transformer (FGT) paradigm, which consists of a feature
extractor, a transformer, and a denoiser. The feature extractor estimates the
local features, that guide the transformer to compute a transformation, which
is applied to the noisy input mesh to obtain a useful intermediate
representation. This is further processed by the denoiser to obtain the
denoised mesh. Our network is trained on a large scale dataset of 3D objects.
We perform exhaustive ablation studies to demonstrate that each component in
our network is essential for obtaining the best performance. We show that our
method obtains competitive or better results when compared with the
state-of-the-art mesh denoising algorithms. We demonstrate that our method is
robust to various kinds of noise. We observe that even in the presence of
extremely high noise, our method achieves excellent performance.

</details>


### [177] [Mask-aware Text-to-Image Retrieval: Referring Expression Segmentation Meets Cross-modal Retrieval](https://arxiv.org/abs/2506.22864)
*Li-Cheng Shen,Jih-Kang Hsieh,Wei-Hua Li,Chu-Song Chen*

Main category: cs.CV

TL;DR: MaTIR是一个结合文本到图像检索（TIR）和参考表达式分割（RES）的新任务，通过两阶段框架实现高效图像搜索和精确对象分割。


<details>
  <summary>Details</summary>
Motivation: 现有TIR方法缺乏解释性，而RES在大规模图像集合中计算成本高，MaTIR旨在统一两者需求。

Method: 提出两阶段框架：首先生成分割感知的图像检索，再利用多模态大语言模型（MLLM）重排序和对象定位。

Result: 在COCO和D$^3$数据集上，MaTIR在检索准确性和分割质量上显著优于现有方法。

Conclusion: MaTIR成功结合了TIR和RES的优势，实现了高效且精确的图像检索与分割。

Abstract: Text-to-image retrieval (TIR) aims to find relevant images based on a textual
query, but existing approaches are primarily based on whole-image captions and
lack interpretability. Meanwhile, referring expression segmentation (RES)
enables precise object localization based on natural language descriptions but
is computationally expensive when applied across large image collections. To
bridge this gap, we introduce Mask-aware TIR (MaTIR), a new task that unifies
TIR and RES, requiring both efficient image search and accurate object
segmentation. To address this task, we propose a two-stage framework,
comprising a first stage for segmentation-aware image retrieval and a second
stage for reranking and object grounding with a multimodal large language model
(MLLM). We leverage SAM 2 to generate object masks and Alpha-CLIP to extract
region-level embeddings offline at first, enabling effective and scalable
online retrieval. Secondly, MLLM is used to refine retrieval rankings and
generate bounding boxes, which are matched to segmentation masks. We evaluate
our approach on COCO and D$^3$ datasets, demonstrating significant improvements
in both retrieval accuracy and segmentation quality over previous methods.

</details>


### [178] [Region-Aware CAM: High-Resolution Weakly-Supervised Defect Segmentation via Salient Region Perception](https://arxiv.org/abs/2506.22866)
*Hang-Cheng Dong,Lu Zou,Bingguo Liu,Dong Ye,Guodong Liu*

Main category: cs.CV

TL;DR: 提出了一种基于弱监督语义分割的工业缺陷检测框架，通过区域感知CAM和伪标签训练解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 工业缺陷检测需要高精度分割，但传统方法依赖大规模标注数据，与实际需求冲突。

Method: 引入过滤引导反向传播（FGBP）优化目标区域，结合区域感知加权模块提升空间精度，并通过伪标签迭代优化模型。

Result: 在工业缺陷数据集上的实验表明，该方法显著优于现有方法。

Conclusion: 该框架有效填补了弱监督学习与高精度缺陷分割之间的空白，适用于资源受限的工业场景。

Abstract: Surface defect detection plays a critical role in industrial quality
inspection. Recent advances in artificial intelligence have significantly
enhanced the automation level of detection processes. However, conventional
semantic segmentation and object detection models heavily rely on large-scale
annotated datasets, which conflicts with the practical requirements of defect
detection tasks. This paper proposes a novel weakly supervised semantic
segmentation framework comprising two key components: a region-aware class
activation map (CAM) and pseudo-label training. To address the limitations of
existing CAM methods, especially low-resolution thermal maps, and insufficient
detail preservation, we introduce filtering-guided backpropagation (FGBP),
which refines target regions by filtering gradient magnitudes to identify areas
with higher relevance to defects. Building upon this, we further develop a
region-aware weighted module to enhance spatial precision. Finally,
pseudo-label segmentation is implemented to refine the model's performance
iteratively. Comprehensive experiments on industrial defect datasets
demonstrate the superiority of our method. The proposed framework effectively
bridges the gap between weakly supervised learning and high-precision defect
segmentation, offering a practical solution for resource-constrained industrial
scenarios.

</details>


### [179] [STR-Match: Matching SpatioTemporal Relevance Score for Training-Free Video Editing](https://arxiv.org/abs/2506.22868)
*Junsung Lee,Junoh Kang,Bohyung Han*

Main category: cs.CV

TL;DR: STR-Match是一种无需训练的视频编辑算法，通过新的STR分数优化潜在空间，解决了现有方法的时间不一致性和运动扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导视频编辑方法存在时间不一致、运动扭曲和领域转换受限的问题，主要原因是时空像素相关性建模不足。

Method: 提出STR-Match算法，利用2D空间注意力和1D时间模块计算STR分数，结合潜在优化框架和潜在掩码生成视频。

Result: 实验表明，STR-Match在视觉质量和时空一致性上均优于现有方法，尤其在显著领域转换时表现突出。

Conclusion: STR-Match通过高效建模时空相关性，显著提升了视频编辑的时空一致性和视觉保真度。

Abstract: Previous text-guided video editing methods often suffer from temporal
inconsistency, motion distortion, and-most notably-limited domain
transformation. We attribute these limitations to insufficient modeling of
spatiotemporal pixel relevance during the editing process. To address this, we
propose STR-Match, a training-free video editing algorithm that produces
visually appealing and spatiotemporally coherent videos through latent
optimization guided by our novel STR score. The score captures spatiotemporal
pixel relevance across adjacent frames by leveraging 2D spatial attention and
1D temporal modules in text-to-video (T2V) diffusion models, without the
overhead of computationally expensive 3D attention mechanisms. Integrated into
a latent optimization framework with a latent mask, STR-Match generates
temporally consistent and visually faithful videos, maintaining strong
performance even under significant domain transformations while preserving key
visual attributes of the source. Extensive experiments demonstrate that
STR-Match consistently outperforms existing methods in both visual quality and
spatiotemporal consistency.

</details>


### [180] [Decoupled Seg Tokens Make Stronger Reasoning Video Segmenter and Grounder](https://arxiv.org/abs/2506.22880)
*Dang Jisheng,Wu Xudong,Wang Bimei,Lv Ning,Chen Jiayu,Jingwen Zhao,Yichu liu,Jizhao Liu,Juncheng Li,Teng Wang*

Main category: cs.CV

TL;DR: DeSa2VA通过解耦增强提示方案，结合文本预训练和线性解耦模块，解决了现有视频分割方法中动态视觉信息与静态语义纠缠的问题，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如Sa2VA）直接将特征融合到分割模型中，导致动态视觉信息与静态语义纠缠，影响分割精度。

Method: 提出DeSa2VA，包括文本预训练生成点级提示和文本掩码，线性解耦模块分离文本和视觉特征，动态掩码融合策略结合解耦特征。

Result: 在图像分割、图像问答、视频分割和视频问答等任务中达到最先进性能。

Conclusion: DeSa2VA通过解耦和动态融合策略有效提升了分割任务的性能。

Abstract: Existing video segmenter and grounder approaches, exemplified by Sa2VA,
directly fuse features within segmentation models. This often results in an
undesirable entanglement of dynamic visual information and static semantics,
thereby degrading segmentation accuracy. To systematically mitigate this issue,
we propose DeSa2VA, a decoupling-enhanced prompting scheme integrating text
pre-training and a linear decoupling module to address the information
processing limitations inherent in SAM-2. Specifically, first, we devise a
pre-training paradigm that converts textual ground-truth labels into
point-level prompts while generating corresponding text masks. These masks are
refined through a hybrid loss function to strengthen the model's semantic
grounding capabilities. Next, we employ linear projection to disentangle hidden
states that generated by a large language model into distinct textual and
visual feature subspaces. Finally, a dynamic mask fusion strategy
synergistically combines these decoupled features through triple supervision
from predicted text/visual masks and ground-truth annotations. Extensive
experiments demonstrate state-of-the-art performance across diverse tasks,
including image segmentation, image question answering, video segmentation, and
video question answering. Our codes are available at
https://github.com/longmalongma/DeSa2VA.

</details>


### [181] [How Semantically Informative is an Image?: Measuring the Covariance-Weighted Norm of Contrastive Learning Embeddings](https://arxiv.org/abs/2506.22881)
*Fumiya Uchiyama,Rintaro Yanagi,Shohei Taniguchi,Shota Takashiro,Masahiro Suzuki,Hirokatsu Kataoka,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 本文提出了一种基于对比学习的语义信息度量方法，用于量化图像和文本之间的信息增益，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究对比学习是否能表示绝对语义信息量，而不仅仅是相对语义相似性。

Method: 通过对比学习模型计算图像和文本的信息增益，并扩展信息增益概念到视觉和语言领域。

Result: 实验结果显示信息增益得分低的图像通常是占位图标，且信息增益与嵌入范数强相关（R²=0.98-1.00）。

Conclusion: 该方法计算成本低，适用于公开模型，为语义信息量化提供了新思路。

Abstract: Contrastive learning has the capacity to model multimodal probability
distributions by embedding and aligning visual representations with semantics
from captions. This approach enables the estimation of relational semantic
similarity; however, it remains unclear whether it can also represent absolute
semantic informativeness. In this work, we introduce a semantic informativeness
metric for an image calculated from text samples via a contrastive learning
model; similarly, the informativeness of a text is calculated from image
samples. We propose a redefinition of the concept of Information Gain, a
concept previously explored in natural language processing, extending its
application to the domains of vision and language. Our metric quantifies how
conditioning on an image distorts the distribution of associated texts, and
vice versa for text conditioning on image distributions. In OpenCLIP's
empirical results, we observe that images with the lowest Information Gain
scores often correspond to placeholder icons such as "image not found."
Furthermore, we propose to measure a norm-based metric of the embedding to
estimate the Information Gain, following the theoretical results for Skip-Gram
with Negative Sampling (SGNS) word embedding. Information Gain can be measured
using either CLIP or SigLIP, and the results demonstrate a strong correlation
with a coefficient of determination ranging from 0.98 to 1.00. After obtaining
the mean and the covariance of the sample embedding, the computational cost of
this method is independent of the sample size, and it is compatible with
publicly available, open-weight models.

</details>


### [182] [CP-Guard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems](https://arxiv.org/abs/2506.22890)
*Senkang Hu,Yihang Tao,Guowen Xu,Xinyuan Qian,Yiqin Deng,Xianhao Chen,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.CV

TL;DR: CP-Guard是一个用于协作感知（CP）的统一防御框架，能够检测并消除恶意代理，通过概率无关的样本共识和动态阈值调整来确保系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 协作感知在多代理系统中能提升感知性能，但也容易受到恶意代理的攻击，因此需要一种有效的防御机制。

Method: 提出CP-Guard框架，包括概率无关的样本共识（PASAC）、协作一致性损失（CCLoss）和动态阈值调整。

Result: 实验证明CP-Guard能有效检测和消除恶意代理，提升系统可靠性。

Conclusion: CP-Guard为协作感知提供了一种可靠且自适应的防御解决方案。

Abstract: Collaborative Perception (CP) has been shown to be a promising technique for
multi-agent autonomous driving and multi-agent robotic systems, where multiple
agents share their perception information to enhance the overall perception
performance and expand the perception range. However, in CP, an ego agent needs
to receive messages from its collaborators, which makes it vulnerable to
attacks from malicious agents. To address this critical issue, we propose a
unified, probability-agnostic, and adaptive framework, namely, CP-Guard, which
is a tailored defense mechanism for CP deployed by each agent to accurately
detect and eliminate malicious agents in its collaboration network. Our key
idea is to enable CP to reach a consensus rather than a conflict against an ego
agent's perception results. Based on this idea, we first develop a
probability-agnostic sample consensus (PASAC) method to effectively sample a
subset of the collaborators and verify the consensus without prior
probabilities of malicious agents. Furthermore, we define collaborative
consistency loss (CCLoss) for object detection task and bird's eye view (BEV)
segmentation task to capture the discrepancy between an ego agent and its
collaborators, which is used as a verification criterion for consensus. In
addition, we propose online adaptive threshold via dual sliding windows to
dynamically adjust the threshold for consensus verification and ensure the
reliability of the systems in dynamic environments. Finally, we conduct
extensive experiments and demonstrate the effectiveness of our framework. Code
will be released at https://github.com/CP-Security/CP-Guard

</details>


### [183] [Neural Cellular Automata: From Cells to Pixels](https://arxiv.org/abs/2506.22899)
*Ehsan Pajouheshgar,Yitao Xu,Ali Abbasi,Alexander Mordvintsev,Wenzel Jakob,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 该论文提出了一种结合隐式解码器的神经细胞自动机（NCA）方法，解决了NCA在高分辨率网格上的训练和推理效率问题，实现了实时生成高清输出的能力。


<details>
  <summary>Details</summary>
Motivation: NCA在低分辨率网格上表现出色，但在高分辨率下因计算和内存需求剧增、信息传播受限等问题而受限。论文旨在通过引入隐式解码器和优化损失函数，扩展NCA的应用范围。

Method: 通过结合隐式神经表示的解码器，在粗网格上进行NCA演化，再通过轻量级解码器生成任意分辨率的输出。同时设计了针对高分辨率任务的损失函数。

Result: 提出的方法显著提升了NCA在高分辨率下的质量和效率，能够实时生成高清输出，并保持了自组织和涌现特性。

Conclusion: 该方法成功扩展了NCA的应用范围，使其能够高效处理高分辨率任务，同时保持了并行性和计算效率。

Abstract: Neural Cellular Automata (NCAs) are bio-inspired systems in which identical
cells self-organize to form complex and coherent patterns by repeatedly
applying simple local rules. NCAs display striking emergent behaviors including
self-regeneration, generalization and robustness to unseen situations, and
spontaneous motion. Despite their success in texture synthesis and
morphogenesis, NCAs remain largely confined to low-resolution grids. This
limitation stems from (1) training time and memory requirements that grow
quadratically with grid size, (2) the strictly local propagation of information
which impedes long-range cell communication, and (3) the heavy compute demands
of real-time inference at high resolution. In this work, we overcome this
limitation by pairing NCA with a tiny, shared implicit decoder, inspired by
recent advances in implicit neural representations. Following NCA evolution on
a coarse grid, a lightweight decoder renders output images at arbitrary
resolution. We also propose novel loss functions for both morphogenesis and
texture synthesis tasks, specifically tailored for high-resolution output with
minimal memory and computation overhead. Combining our proposed architecture
and loss functions brings substantial improvement in quality, efficiency, and
performance. NCAs equipped with our implicit decoder can generate full-HD
outputs in real time while preserving their self-organizing, emergent
properties. Moreover, because each MLP processes cell states independently,
inference remains highly parallelizable and efficient. We demonstrate the
applicability of our approach across multiple NCA variants (on 2D, 3D grids,
and 3D meshes) and multiple tasks, including texture generation and
morphogenesis (growing patterns from a seed), showing that with our proposed
framework, NCAs seamlessly scale to high-resolution outputs with minimal
computational overhead.

</details>


### [184] [MOTOR: Multimodal Optimal Transport via Grounded Retrieval in Medical Visual Question Answering](https://arxiv.org/abs/2506.22900)
*Mai A. Shaaban,Tausifa Jan Saleem,Vijay Ram Papineni,Mohammad Yaqub*

Main category: cs.CV

TL;DR: MOTOR是一种新型多模态检索和重排序方法，通过结合文本和视觉信息提升医学视觉问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在医学视觉问答中常生成不准确答案，且忽略了多模态上下文的重要性。

Method: 提出MOTOR方法，利用基于文本和视觉信息的检索重排序，结合最优传输技术。

Result: 在MedVQA数据集上，MOTOR平均准确率提升6.45%，优于现有方法。

Conclusion: MOTOR通过多模态上下文增强，显著提升了医学视觉问答的准确性和临床相关性。

Abstract: Medical visual question answering (MedVQA) plays a vital role in clinical
decision-making by providing contextually rich answers to image-based queries.
Although vision-language models (VLMs) are widely used for this task, they
often generate factually incorrect answers. Retrieval-augmented generation
addresses this challenge by providing information from external sources, but
risks retrieving irrelevant context, which can degrade the reasoning
capabilities of VLMs. Re-ranking retrievals, as introduced in existing
approaches, enhances retrieval relevance by focusing on query-text alignment.
However, these approaches neglect the visual or multimodal context, which is
particularly crucial for medical diagnosis. We propose MOTOR, a novel
multimodal retrieval and re-ranking approach that leverages grounded captions
and optimal transport. It captures the underlying relationships between the
query and the retrieved context based on textual and visual information.
Consequently, our approach identifies more clinically relevant contexts to
augment the VLM input. Empirical analysis and human expert evaluation
demonstrate that MOTOR achieves higher accuracy on MedVQA datasets,
outperforming state-of-the-art methods by an average of 6.45%. Code is
available at https://github.com/BioMedIA-MBZUAI/MOTOR.

</details>


### [185] [Point Cloud Compression and Objective Quality Assessment: A Survey](https://arxiv.org/abs/2506.22902)
*Yiling Xu,Yujie Zhang,Shuting Xia,Kaifa Yang,He Huang,Ziyu Shan,Wenjie Huang,Qi Yang,Le Yang*

Main category: cs.CV

TL;DR: 本文综述了3D点云压缩（PCC）和质量评估（PCQA）的最新进展，分析了手工和基于学习的算法，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据的快速增长及其在自动驾驶、机器人等领域的应用需求，推动了高效压缩和质量评估技术的发展。

Method: 通过分析手工和基于学习的PCC算法及PCQA指标，并在新兴数据集上对代表性方法进行基准测试。

Result: 提供了详细的比较和实践见解，揭示了现有方法的优势和局限性。

Conclusion: 尽管取得进展，但仍需解决视觉保真度、延迟和多模态数据支持等挑战，未来方向包括混合压缩框架和高级特征提取策略。

Abstract: The rapid growth of 3D point cloud data, driven by applications in autonomous
driving, robotics, and immersive environments, has led to criticals demand for
efficient compression and quality assessment techniques. Unlike traditional 2D
media, point clouds present unique challenges due to their irregular structure,
high data volume, and complex attributes. This paper provides a comprehensive
survey of recent advances in point cloud compression (PCC) and point cloud
quality assessment (PCQA), emphasizing their significance for real-time and
perceptually relevant applications. We analyze a wide range of handcrafted and
learning-based PCC algorithms, along with objective PCQA metrics. By
benchmarking representative methods on emerging datasets, we offer detailed
comparisons and practical insights into their strengths and limitations.
Despite notable progress, challenges such as enhancing visual fidelity,
reducing latency, and supporting multimodal data remain. This survey outlines
future directions, including hybrid compression frameworks and advanced feature
extraction strategies, to enable more efficient, immersive, and intelligent 3D
applications.

</details>


### [186] [MagShield: Towards Better Robustness in Sparse Inertial Motion Capture Under Magnetic Disturbances](https://arxiv.org/abs/2506.22907)
*Yunzhe Shao,Xinyu Yi,Lu Yin,Shihui Guo,Junhai Yong,Feng Xu*

Main category: cs.CV

TL;DR: MagShield是一种新方法，用于解决稀疏惯性运动捕捉系统中的磁干扰问题，通过检测和校正策略提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有IMU系统在磁干扰环境中易产生方向估计误差，限制了实际应用。

Method: 采用“检测-校正”策略，通过多IMU联合分析检测磁干扰，并利用人体运动先验校正方向误差。

Result: 实验表明，MagShield显著提高了磁干扰下的运动捕捉准确性，并具有良好的兼容性。

Conclusion: MagShield能有效提升稀疏惯性运动捕捉系统在磁干扰环境中的性能。

Abstract: This paper proposes a novel method called MagShield, designed to address the
issue of magnetic interference in sparse inertial motion capture (MoCap)
systems. Existing Inertial Measurement Unit (IMU) systems are prone to
orientation estimation errors in magnetically disturbed environments, limiting
their practical application in real-world scenarios. To address this problem,
MagShield employs a "detect-then-correct" strategy, first detecting magnetic
disturbances through multi-IMU joint analysis, and then correcting orientation
errors using human motion priors. MagShield can be integrated with most
existing sparse inertial MoCap systems, improving their performance in
magnetically disturbed environments. Experimental results demonstrate that
MagShield significantly enhances the accuracy of motion capture under magnetic
interference and exhibits good compatibility across different sparse inertial
MoCap systems.

</details>


### [187] [Attention to Burstiness: Low-Rank Bilinear Prompt Tuning](https://arxiv.org/abs/2506.22908)
*Yuzhu Wang,Manni Duan,Shu Kong*

Main category: cs.CV

TL;DR: 论文提出了一种名为Bilinear Prompt Tuning (BPT)的方法，通过数据白化和低秩分解改进视觉提示调优（VPT），显著提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: VPT中图像块嵌入与自注意力模块的交互导致数据分布非高斯性，增加了提示学习的难度。

Method: 提出数据白化方法，并引入低秩分解的双线性模型（BPT）来优化提示学习。

Result: BPT在CUB数据集上提升了25个准确点，同时减少了参数和计算开销。

Conclusion: BPT方法在性能和效率上均优于现有VPT方法，适用于多基准数据集。

Abstract: Visual Prompt Tuning (VPT) is a parameter-efficient fune-tuning technique
that adapts a pre-trained vision Transformer (ViT) by learning a small set of
parameters in the input space, known as prompts. In VPT, we uncover
``burstiness'' in the values arising from the interaction of image patch
embeddings, and the key and query projectors within Transformer's
self-attention module. Furthermore, the values of patch embeddings and the key
and query projectors exhibit Laplacian and hyper-Laplacian distribution,
respectively. Intuitively, these non-Gaussian distributions pose challenges for
learning prompts. To address this, we propose whitening these data,
de-correlating them and equalizing their variance towards more Gaussian before
learning prompts. We derive the whitening matrix over random image patch
embeddings and ViT's key and query projectors, and multiply it with the prompt
to be learned in a bilinear manner. Surprisingly, this method significantly
accelerates prompt tuning and boosts accuracy, e.g., $>$25 accuracy points on
the CUB dataset; interestingly, it learns ``bursty prompts''. Extending the
bilinear model which is known to introduce burstiness, we present a compact,
low-rank version by learning two smaller matrices whose multiplication yields
the final prompts. We call the proposed methods Bilinear Prompt Tuning (BPT).
Extensive experiments across multiple benchmark datasets demonstrate that BPT
methods not only outperform various VPT methods but also reduce parameter count
and computation overhead.

</details>


### [188] [Towards Explainable Bilingual Multimodal Misinformation Detection and Localization](https://arxiv.org/abs/2506.22930)
*Yiwei He,Xiangtai Li,Zhenglin Huang,Yi Dong,Hao Fei,Jiangning Zhang,Baoyuan Wu,Guangliang Cheng*

Main category: cs.CV

TL;DR: BiMi是一个双语多模态框架，用于检测新闻媒体中的虚假信息，通过区域级定位、跨模态和跨语言一致性检测以及自然语言解释，显著提升了分类和定位准确性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态内容的真实性提高，虚假信息变得更加隐蔽，尤其是在双语字幕新闻中，局部图像编辑和跨语言不一致性共同扭曲了意义。

Method: BiMi结合了区域级定位、跨模态和跨语言一致性检测、自然语言解释，并集成了在线检索模块以补充外部上下文。

Result: BiMi在分类准确性上提升了8.9，定位准确性提升了15.9，解释BERTScore提升了2.5。

Conclusion: BiMi在现实多语言虚假信息检测中取得了最先进的性能，并发布了BiMiBench基准数据集。

Abstract: The increasing realism of multimodal content has made misinformation more
subtle and harder to detect, especially in news media where images are
frequently paired with bilingual (e.g., Chinese-English) subtitles. Such
content often includes localized image edits and cross-lingual inconsistencies
that jointly distort meaning while remaining superficially plausible. We
introduce BiMi, a bilingual multimodal framework that jointly performs
region-level localization, cross-modal and cross-lingual consistency detection,
and natural language explanation for misinformation analysis. To support
generalization, BiMi integrates an online retrieval module that supplements
model reasoning with up-to-date external context. We further release BiMiBench,
a large-scale and comprehensive benchmark constructed by systematically editing
real news images and subtitles, comprising 104,000 samples with realistic
manipulations across visual and linguistic modalities. To enhance
interpretability, we apply Group Relative Policy Optimization (GRPO) to improve
explanation quality, marking the first use of GRPO in this domain. Extensive
experiments demonstrate that BiMi outperforms strong baselines by up to +8.9 in
classification accuracy, +15.9 in localization accuracy, and +2.5 in
explanation BERTScore, advancing state-of-the-art performance in realistic,
multilingual misinformation detection. Code, models, and datasets will be
released.

</details>


### [189] [Utilizing a Novel Deep Learning Method for Scene Categorization in Remote Sensing Data](https://arxiv.org/abs/2506.22939)
*Ghufran A. Omran,Wassan Saad Abduljabbar Hayale,Ahmad AbdulQadir AlRababah,Israa Ibraheem Al-Barazanchi,Ravi Sekhar,Pritesh Shah,Sushma Parihar,Harshavardhan Reddy Penubadi*

Main category: cs.CV

TL;DR: 论文提出了一种名为CO-BRNN的新方法，用于遥感数据中的场景分类，并展示了其优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 遥感图像场景分类在多个领域有广泛应用，但传统深度学习方法需要大量数据且难以达到高精度。

Method: 采用Cuttlefish优化的双向循环神经网络（CO-BRNN），并与多种现有技术进行比较。

Result: CO-BRNN达到97%的最高准确率，优于其他方法。

Conclusion: 研究强调了物理验证对卫星数据效率的重要性，CO-BRNN在场景分类中表现出色。

Abstract: Scene categorization (SC) in remotely acquired images is an important subject
with broad consequences in different fields, including catastrophe control,
ecological observation, architecture for cities, and more. Nevertheless, its
several apps, reaching a high degree of accuracy in SC from distant observation
data has demonstrated to be difficult. This is because traditional conventional
deep learning models require large databases with high variety and high levels
of noise to capture important visual features. To address these problems, this
investigation file introduces an innovative technique referred to as the
Cuttlefish Optimized Bidirectional Recurrent Neural Network (CO- BRNN) for type
of scenes in remote sensing data. The investigation compares the execution of
CO-BRNN with current techniques, including Multilayer Perceptron- Convolutional
Neural Network (MLP-CNN), Convolutional Neural Network-Long Short Term Memory
(CNN-LSTM), and Long Short Term Memory-Conditional Random Field (LSTM-CRF),
Graph-Based (GB), Multilabel Image Retrieval Model (MIRM-CF), Convolutional
Neural Networks Data Augmentation (CNN-DA). The results demonstrate that
CO-BRNN attained the maximum accuracy of 97%, followed by LSTM-CRF with 90%,
MLP-CNN with 85%, and CNN-LSTM with 80%. The study highlights the significance
of physical confirmation to ensure the efficiency of satellite data.

</details>


### [190] [YM-WML: A new Yolo-based segmentation Model with Weighted Multi-class Loss for medical imaging](https://arxiv.org/abs/2506.22955)
*Haniyeh Nikkhah,Jafar Tanha,Mahdi Zarrin,SeyedEhsan Roshan,Amin Kazempour*

Main category: cs.CV

TL;DR: YM-WML模型通过结合强大的特征提取、多尺度特征聚合和注意力机制，解决了医学图像分割中的类别不平衡和复杂结构问题，并在ACDC数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临类别不平衡和图像结构复杂的挑战，需要一种更有效的解决方案。

Method: YM-WML模型结合了鲁棒的特征提取主干、YOLOv11颈部用于多尺度特征聚合，以及基于注意力的分割头，并引入了WME损失函数处理类别不平衡。

Result: 在ACDC数据集上，YM-WML的Dice相似系数达到91.02，优于现有方法，表现出稳定的训练和强泛化能力。

Conclusion: YM-WML为心脏图像分割任务设定了新的基准，具有高精度和鲁棒性。

Abstract: Medical image segmentation poses significant challenges due to class
imbalance and the complex structure of medical images. To address these
challenges, this study proposes YM-WML, a novel model for cardiac image
segmentation. The model integrates a robust backbone for effective feature
extraction, a YOLOv11 neck for multi-scale feature aggregation, and an
attention-based segmentation head for precise and accurate segmentation. To
address class imbalance, we introduce the Weighted Multi-class Exponential
(WME) loss function. On the ACDC dataset, YM-WML achieves a Dice Similarity
Coefficient of 91.02, outperforming state-of-the-art methods. The model
demonstrates stable training, accurate segmentation, and strong generalization,
setting a new benchmark in cardiac segmentation tasks.

</details>


### [191] [Peccavi: Visual Paraphrase Attack Safe and Distortion Free Image Watermarking Technique for AI-Generated Images](https://arxiv.org/abs/2506.22960)
*Shreyas Dixit,Ashhar Aziz,Shashwat Bajpai,Vasu Sharma,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.CV

TL;DR: 论文提出PECCAVI，一种抗视觉转述攻击的无失真图像水印技术，通过在多通道频域嵌入水印并利用噪声抛光增强耐久性。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容激增，水印技术易受篡改和绕过，尤其是视觉转述攻击能完全去除水印，亟需更安全的解决方案。

Method: PECCAVI将水印嵌入非熔化点（NMPs），结合多通道频域水印和噪声抛光技术，防止逆向工程破坏水印。

Result: PECCAVI能有效抵抗视觉转述攻击，保持图像无失真，且模型无关。

Conclusion: PECCAVI为AI生成内容的安全水印提供了可靠方案，代码将开源。

Abstract: A report by the European Union Law Enforcement Agency predicts that by 2026,
up to 90 percent of online content could be synthetically generated, raising
concerns among policymakers, who cautioned that "Generative AI could act as a
force multiplier for political disinformation. The combined effect of
generative text, images, videos, and audio may surpass the influence of any
single modality." In response, California's Bill AB 3211 mandates the
watermarking of AI-generated images, videos, and audio. However, concerns
remain regarding the vulnerability of invisible watermarking techniques to
tampering and the potential for malicious actors to bypass them entirely.
Generative AI-powered de-watermarking attacks, especially the newly introduced
visual paraphrase attack, have shown an ability to fully remove watermarks,
resulting in a paraphrase of the original image. This paper introduces PECCAVI,
the first visual paraphrase attack-safe and distortion-free image watermarking
technique. In visual paraphrase attacks, an image is altered while preserving
its core semantic regions, termed Non-Melting Points (NMPs). PECCAVI
strategically embeds watermarks within these NMPs and employs multi-channel
frequency domain watermarking. It also incorporates noisy burnishing to counter
reverse-engineering efforts aimed at locating NMPs to disrupt the embedded
watermark, thereby enhancing durability. PECCAVI is model-agnostic. All
relevant resources and codes will be open-sourced.

</details>


### [192] [ActAlign: Zero-Shot Fine-Grained Video Classification via Language-Guided Sequence Alignment](https://arxiv.org/abs/2506.22967)
*Amir Aghdam,Vincent Tao Hu*

Main category: cs.CV

TL;DR: ActAlign框架通过序列对齐实现零样本细粒度视频分类，无需视频监督或微调，性能优于大型视频语言模型。


<details>
  <summary>Details</summary>
Motivation: 解决零样本细粒度视频分类任务中，现有对比视觉语言模型无法捕捉时间结构的问题。

Method: 利用大语言模型生成有序子动作序列，并通过动态时间规整（DTW）在共享嵌入空间中对齐视频帧。

Result: 在ActionAtlas基准上达到30.5%准确率，优于大型模型且参数更少。

Conclusion: 结构化语言先验与经典对齐技术结合，为细粒度视频理解提供可扩展通用方法。

Abstract: We address the task of zero-shot fine-grained video classification, where no
video examples or temporal annotations are available for unseen action classes.
While contrastive vision-language models such as SigLIP demonstrate strong
open-set recognition via mean-pooled image-text similarity, they fail to
capture the temporal structure critical for distinguishing fine-grained
activities. We introduce ActAlign, a zero-shot framework that formulates video
classification as sequence alignment. For each class, a large language model
generates an ordered sub-action sequence, which is aligned with video frames
using Dynamic Time Warping (DTW) in a shared embedding space. Without any
video-text supervision or fine-tuning, ActAlign achieves 30.5% accuracy on the
extremely challenging ActionAtlas benchmark, where human accuracy is only
61.6%. ActAlign outperforms billion-parameter video-language models while using
approximately 8x less parameters. These results demonstrate that structured
language priors, combined with classical alignment techniques, offer a scalable
and general approach to unlocking the open-set recognition potential of
vision-language models for fine-grained video understanding.

</details>


### [193] [Probabilistic Prototype Calibration of Vision-Language Models for Generalized Few-shot Semantic Segmentation](https://arxiv.org/abs/2506.22979)
*Jie Liu,Jiayi Shen,Pan Zhou,Jan-Jakob Sonke,Efstratios Gavves*

Main category: cs.CV

TL;DR: FewCLIP是一个基于概率原型校准的框架，通过多模态原型学习改进广义少样本语义分割（GFSS），显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的方法在少样本情况下缺乏适应性，FewCLIP旨在通过概率原型校准提升对稀缺标注数据的泛化能力。

Method: FewCLIP结合视觉校准原型优化冻结的文本原型，并通过分布正则化实现结构化、不确定性感知的原型学习。

Result: 在PASCAL-5$^i$和COCO-20$^i$数据集上，FewCLIP在GFSS和类增量设置中均优于现有方法。

Conclusion: FewCLIP通过概率原型校准有效提升了少样本语义分割的性能，解决了原型学习中的适应性问题。

Abstract: Generalized Few-Shot Semantic Segmentation (GFSS) aims to extend a
segmentation model to novel classes with only a few annotated examples while
maintaining performance on base classes. Recently, pretrained vision-language
models (VLMs) such as CLIP have been leveraged in GFSS to improve
generalization on novel classes through multi-modal prototypes learning.
However, existing prototype-based methods are inherently deterministic,
limiting the adaptability of learned prototypes to diverse samples,
particularly for novel classes with scarce annotations. To address this, we
propose FewCLIP, a probabilistic prototype calibration framework over
multi-modal prototypes from the pretrained CLIP, thus providing more adaptive
prototype learning for GFSS. Specifically, FewCLIP first introduces a prototype
calibration mechanism, which refines frozen textual prototypes with learnable
visual calibration prototypes, leading to a more discriminative and adaptive
representation. Furthermore, unlike deterministic prototype learning
techniques, FewCLIP introduces distribution regularization over these
calibration prototypes. This probabilistic formulation ensures structured and
uncertainty-aware prototype learning, effectively mitigating overfitting to
limited novel class data while enhancing generalization. Extensive experimental
results on PASCAL-5$^i$ and COCO-20$^i$ datasets demonstrate that our proposed
FewCLIP significantly outperforms state-of-the-art approaches across both GFSS
and class-incremental setting. The code is available at
https://github.com/jliu4ai/FewCLIP.

</details>


### [194] [Revisiting CroPA: A Reproducibility Study and Enhancements for Cross-Prompt Adversarial Transferability in Vision-Language Models](https://arxiv.org/abs/2506.22982)
*Atharv Mittal,Agam Pandey,Amritanshu Tiwari,Sukrit Jindal,Swadesh Swain*

Main category: cs.CV

TL;DR: 该论文研究了大型视觉语言模型（VLMs）在对抗攻击中的脆弱性，验证了跨提示攻击（CroPA）的优越性，并提出了改进方法以提高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在多模态任务中表现出色，但对对抗攻击高度脆弱，尤其是在视觉和文本模态均可被操纵的情况下。研究旨在验证和改进跨提示攻击方法。

Method: 论文复现了CroPA方法，并提出了三项改进：新颖的初始化策略、研究跨图像可迁移性的通用扰动学习，以及针对视觉编码器注意力机制的新损失函数。

Result: 在多个主流VLM（如Flamingo、BLIP-2、InstructBLIP和LLaVA）上的实验验证了CroPA的优越性，并表明改进方法显著提升了对抗攻击效果。

Conclusion: 研究强调了研究VLM对抗脆弱性的重要性，并提供了更鲁棒的对抗样本生成框架，对理解VLM在现实应用中的安全性具有重要意义。

Abstract: Large Vision-Language Models (VLMs) have revolutionized computer vision,
enabling tasks such as image classification, captioning, and visual question
answering. However, they remain highly vulnerable to adversarial attacks,
particularly in scenarios where both visual and textual modalities can be
manipulated. In this study, we conduct a comprehensive reproducibility study of
"An Image is Worth 1000 Lies: Adversarial Transferability Across Prompts on
Vision-Language Models" validating the Cross-Prompt Attack (CroPA) and
confirming its superior cross-prompt transferability compared to existing
baselines. Beyond replication we propose several key improvements: (1) A novel
initialization strategy that significantly improves Attack Success Rate (ASR).
(2) Investigate cross-image transferability by learning universal
perturbations. (3) A novel loss function targeting vision encoder attention
mechanisms to improve generalization. Our evaluation across prominent VLMs --
including Flamingo, BLIP-2, and InstructBLIP as well as extended experiments on
LLaVA validates the original results and demonstrates that our improvements
consistently boost adversarial effectiveness. Our work reinforces the
importance of studying adversarial vulnerabilities in VLMs and provides a more
robust framework for generating transferable adversarial examples, with
significant implications for understanding the security of VLMs in real-world
applications.

</details>


### [195] [A Novel Frame Identification and Synchronization Technique for Smartphone Visible Light Communication Systems Based on Convolutional Neural Networks](https://arxiv.org/abs/2506.23004)
*Vaigai Nayaki Yokar,Hoa Le-Minh,Xicong Li,Wai Lok Woo,Luis Nero Alves,Stanislav Zvanovec,Tran The Son,Zabih Ghassemlooy*

Main category: cs.CV

TL;DR: 提出了一种轻量级CNN方法，用于屏幕到相机可见光通信中的帧识别与同步，实验准确率达98.74%。


<details>
  <summary>Details</summary>
Motivation: 解决屏幕到相机通信中因模糊、裁剪和旋转图像等实时挑战导致的性能问题。

Method: 使用Python和TensorFlow Keras框架构建CNN模型，通过三次实时实验训练，数据集针对实际问题设计。

Result: 模型在实验中达到98.74%的准确率，显著提升了系统性能。

Conclusion: 该方法在屏幕到相机可见光通信中表现出高效性和鲁棒性。

Abstract: This paper proposes a novel, robust, and lightweight supervised Convolutional
Neural Network (CNN)-based technique for frame identification and
synchronization, designed to enhance short-link communication performance in a
screen-to-camera (S2C) based visible light communication (VLC) system.
Developed using Python and the TensorFlow Keras framework, the proposed CNN
model was trained through three real-time experimental investigations conducted
in Jupyter Notebook. These experiments incorporated a dataset created from
scratch to address various real-time challenges in S2C communication, including
blurring, cropping, and rotated images in mobility scenarios. Overhead frames
were introduced for synchronization, which leads to enhanced system
performance. The experimental results demonstrate that the proposed model
achieves an overall accuracy of approximately 98.74%, highlighting its
effectiveness in identifying and synchronizing frames in S2C VLC systems.

</details>


### [196] [MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models](https://arxiv.org/abs/2506.23009)
*Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Ruiyi Zhang,Changyou Chen*

Main category: cs.CV

TL;DR: 论文介绍了MusiXQA数据集，用于评估和改进多模态大语言模型（MLLMs）在乐谱理解方面的能力，并提出了Phi-3-MusiX模型，性能优于GPT方法。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs在乐谱理解方面能力不足，缺乏相关数据集，因此作者希望填补这一空白。

Method: 通过MusiXTeX生成高质量合成乐谱，构建MusiXQA数据集，并开发Phi-3-MusiX模型进行微调。

Result: 实验显示当前MLLMs在乐谱理解上存在显著局限，Phi-3-MusiX性能显著优于GPT方法。

Conclusion: MusiXQA和Phi-3-MusiX为未来MLLMs在乐谱理解领域的研究奠定了基础。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable visual
reasoning abilities in natural images, text-rich documents, and graphic
designs. However, their ability to interpret music sheets remains
underexplored. To bridge this gap, we introduce MusiXQA, the first
comprehensive dataset for evaluating and advancing MLLMs in music sheet
understanding. MusiXQA features high-quality synthetic music sheets generated
via MusiXTeX, with structured annotations covering note pitch and duration,
chords, clefs, key/time signatures, and text, enabling diverse visual QA tasks.
Through extensive evaluations, we reveal significant limitations of current
state-of-the-art MLLMs in this domain. Beyond benchmarking, we developed
Phi-3-MusiX, an MLLM fine-tuned on our dataset, achieving significant
performance gains over GPT-based methods. The proposed dataset and model
establish a foundation for future advances in MLLMs for music sheet
understanding. Code, data, and model will be released upon acceptance.

</details>


### [197] [VisionScores -- A system-segmented image score dataset for deep learning tasks](https://arxiv.org/abs/2506.23030)
*Alejandro Romero Amezcua,Mariano José Juan Rivera Meraz*

Main category: cs.CV

TL;DR: VisionScores是首个系统分割的乐谱图像数据集，专注于双手钢琴曲目，提供结构丰富、信息密集的图像，适用于机器和深度学习任务。


<details>
  <summary>Details</summary>
Motivation: 为机器和深度学习任务提供结构化的乐谱图像数据，同时考虑图形相似性和作曲模式。

Method: 构建包含24.8k样本的数据集，分为两种场景：同一作曲类型不同作者（14k样本）和同一作者不同作曲类型（10.8k样本）。所有样本为128×512像素的灰度图像。

Result: 提供格式化样本、系统顺序、元数据、未分割全页乐谱及预处理图像。

Conclusion: VisionScores为乐谱分析提供了高质量的数据支持，适用于多种研究场景。

Abstract: VisionScores presents a novel proposal being the first system-segmented image
score dataset, aiming to offer structure-rich, high information-density images
for machine and deep learning tasks. Delimited to two-handed piano pieces, it
was built to consider not only certain graphic similarity but also composition
patterns, as this creative process is highly instrument-dependent. It provides
two scenarios in relation to composer and composition type. The first, formed
by 14k samples, considers works from different authors but the same composition
type, specifically, Sonatinas. The latter, consisting of 10.8K samples,
presents the opposite case, various composition types from the same author,
being the one selected Franz Liszt. All of the 24.8k samples are formatted as
grayscale jpg images of $128 \times 512$ pixels. VisionScores supplies the
users not only the formatted samples but the systems' order and pieces'
metadata. Moreover, unsegmented full-page scores and the pre-formatted images
are included for further analysis.

</details>


### [198] [Inpainting is All You Need: A Diffusion-based Augmentation Method for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23038)
*Xinrong Hu,Yiyu Shi*

Main category: cs.CV

TL;DR: AugPaint是一种基于潜在扩散模型的数据增强框架，通过修复生成图像-标签对，解决医学图像分割中标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 医学数据集的像素级标注成本高且耗时，而标注数据稀缺是提升分割性能的关键挑战。

Method: 利用潜在扩散模型进行修复任务，无需重新训练，通过反向去噪过程填充背景区域，生成与标签掩码匹配的合成图像。

Result: 在四个公共医学图像分割数据集（CT、MRI和皮肤成像）上，AugPaint显著优于现有方法，提升了分割性能。

Conclusion: AugPaint通过生成高质量的合成图像-标签对，有效解决了标注数据稀缺问题，为下游分割模型提供了有价值的监督。

Abstract: Collecting pixel-level labels for medical datasets can be a laborious and
expensive process, and enhancing segmentation performance with a scarcity of
labeled data is a crucial challenge. This work introduces AugPaint, a data
augmentation framework that utilizes inpainting to generate image-label pairs
from limited labeled data. AugPaint leverages latent diffusion models, known
for their ability to generate high-quality in-domain images with low overhead,
and adapts the sampling process for the inpainting task without need for
retraining. Specifically, given a pair of image and label mask, we crop the
area labeled with the foreground and condition on it during reversed denoising
process for every noise level. Masked background area would gradually be filled
in, and all generated images are paired with the label mask. This approach
ensures the accuracy of match between synthetic images and label masks, setting
it apart from existing dataset generation methods. The generated images serve
as valuable supervision for training downstream segmentation models,
effectively addressing the challenge of limited annotations. We conducted
extensive evaluations of our data augmentation method on four public medical
image segmentation datasets, including CT, MRI, and skin imaging. Results
across all datasets demonstrate that AugPaint outperforms state-of-the-art
label-efficient methodologies, significantly improving segmentation
performance.

</details>


### [199] [From Coarse to Fine: Learnable Discrete Wavelet Transforms for Efficient 3D Gaussian Splatting](https://arxiv.org/abs/2506.23042)
*Hung Nguyen,An Le,Runfa Li,Truong Nguyen*

Main category: cs.CV

TL;DR: AutoOpti3DGS通过小波变换控制高斯增殖，减少内存占用，保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射方法中高斯基元数量增长导致的内存和带宽问题。

Method: 使用可学习的离散小波变换，固定低通滤波器，学习高通滤波器，并通过正交性损失逐步激活细节。

Result: AutoOpti3DGS生成更稀疏的场景表示，兼容内存受限硬件，且仅需一个超参数。

Conclusion: AutoOpti3DGS有效平衡了视觉质量与资源消耗，适用于资源受限环境。

Abstract: 3D Gaussian Splatting has emerged as a powerful approach in novel view
synthesis, delivering rapid training and rendering but at the cost of an
ever-growing set of Gaussian primitives that strains memory and bandwidth. We
introduce AutoOpti3DGS, a training-time framework that automatically restrains
Gaussian proliferation without sacrificing visual fidelity. The key idea is to
feed the input images to a sequence of learnable Forward and Inverse Discrete
Wavelet Transforms, where low-pass filters are kept fixed, high-pass filters
are learnable and initialized to zero, and an auxiliary orthogonality loss
gradually activates fine frequencies. This wavelet-driven, coarse-to-fine
process delays the formation of redundant fine Gaussians, allowing 3DGS to
capture global structure first and refine detail only when necessary. Through
extensive experiments, AutoOpti3DGS requires just a single filter learning-rate
hyper-parameter, integrates seamlessly with existing efficient 3DGS frameworks,
and consistently produces sparser scene representations more compatible with
memory or storage-constrained hardware.

</details>


### [200] [Ovis-U1 Technical Report](https://arxiv.org/abs/2506.23044)
*Guo-Hua Wang,Shanshan Zhao,Xinjie Zhang,Liangfu Cao,Pengxin Zhan,Lunhao Duan,Shiyin Lu,Minghao Fu,Xiaohao Chen,Jianshan Zhao,Yang Li,Qing-Guo Chen*

Main category: cs.CV

TL;DR: Ovis-U1是一个30亿参数的多模态统一模型，集成了理解、生成和编辑能力，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 旨在通过统一训练方法提升多模态任务（理解、生成、编辑）的性能，突破现有模型的局限。

Method: 采用扩散式视觉解码器和双向令牌细化器，基于语言模型进行统一训练。

Result: 在OpenCompass等多项基准测试中表现优异，超越Ristretto-3B等模型。

Conclusion: Ovis-U1为多模态任务提供了高效统一的解决方案，展现了集成训练的潜力。

Abstract: In this report, we introduce Ovis-U1, a 3-billion-parameter unified model
that integrates multimodal understanding, text-to-image generation, and image
editing capabilities. Building on the foundation of the Ovis series, Ovis-U1
incorporates a diffusion-based visual decoder paired with a bidirectional token
refiner, enabling image generation tasks comparable to leading models like
GPT-4o. Unlike some previous models that use a frozen MLLM for generation
tasks, Ovis-U1 utilizes a new unified training approach starting from a
language model. Compared to training solely on understanding or generation
tasks, unified training yields better performance, demonstrating the
enhancement achieved by integrating these two tasks. Ovis-U1 achieves a score
of 69.6 on the OpenCompass Multi-modal Academic Benchmark, surpassing recent
state-of-the-art models such as Ristretto-3B and SAIL-VL-1.5-2B. In
text-to-image generation, it excels with scores of 83.72 and 0.89 on the
DPG-Bench and GenEval benchmarks, respectively. For image editing, it achieves
4.00 and 6.42 on the ImgEdit-Bench and GEdit-Bench-EN, respectively. As the
initial version of the Ovis unified model series, Ovis-U1 pushes the boundaries
of multimodal understanding, generation, and editing.

</details>


### [201] [Empowering Small VLMs to Think with Dynamic Memorization and Exploration](https://arxiv.org/abs/2506.23061)
*Jiazhen Liu,Yuchuan Deng,Long Chen*

Main category: cs.CV

TL;DR: 论文提出DyME训练范式，动态选择记忆（SFT）和探索（RLVR）模式，以提升小规模视觉语言模型的思维可靠性。


<details>
  <summary>Details</summary>
Motivation: 小规模视觉语言模型（SVLMs）因参数容量有限和指令跟随能力弱，难以实现可靠的思维。现有训练范式（如SFT和RLVR）对模型要求过高，直接应用会导致伪思维痕迹和优势崩溃。

Method: DyME动态选择记忆（SFT）和探索（RLVR）模式，确保每次优化更新都能平衡两者，避免次优收敛。

Result: 实验表明DyME能有效平衡记忆与探索，显著提升SVLMs的性能。

Conclusion: DyME是一种实用且有效的解决方案，可增强SVLMs的可靠思维能力。

Abstract: Empowering Small-scale Vision-Language Models (SVLMs) with reliable thinking
capabilities remains fundamentally challenging due to their limited parameter
capacity and weak instruction-following abilities. Existing training paradigms,
including Supervised Fine-Tuning (SFT) and Reinforcement Learning with
Verifiable Reward (RLVR), impose substantial demands on the base VLM, exceeding
the capabilities of SVLMs. Consequently, directly applying these paradigms to
SVLMs often suffers from severe pseudo thinking traces and advantage collapse,
ultimately undermining both thinking reliability and task performance. A
natural solution is to combine SFT and RLVR, leveraging their complementarity
to reduce the dependence on model capacity. However, the widely adopted
two-stage training paradigm still performs poorly on SVLMs, as their tendency
toward sub-optimal convergence hinders the trade-off and limits the benefits of
the combination. To address this, we propose DyME, a novel training paradigm
that Dynamically selects between Memorization (via SFT) and Exploration (via
RLVR) modes at each optimization step, ensuring that every update contributes
to the trade-off. Extensive experiments across diverse domains demonstrate that
DyME consistently achieves this balance, and thus delivers substantial
performance improvements. These results establish DyME as a practical and
effective solution for empowering SVLMs with reliable thinking capabilities.
GitHub: https://github.com/HKUST-LongGroup/DyME

</details>


### [202] [CoreMark: Toward Robust and Universal Text Watermarking Technique](https://arxiv.org/abs/2506.23066)
*Jiale Meng,Yiming Li,Zheming Lu,Zewei He,Hao Luo,Tianwei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为CORE的新嵌入范式，并基于此开发了文本水印框架CoreMark，通过动态提取和调整CORE的厚度嵌入数据，显著提升了鲁棒性和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方案在同时实现鲁棒性、通用性和不可感知性方面面临挑战。

Method: CoreMark动态提取字符中的CORE（连续对齐的黑色像素段），根据CORE长度选择鲁棒性强的字符，并通过调整CORE厚度嵌入数据。此外，提出了一种通用的嵌入强度调节器，根据字体大小自适应增强鲁棒性。

Result: 实验表明，CoreMark在多种语言和字体中表现出色，显著提升了抗截图、打印扫描和打印相机攻击的能力，同时保持不可感知性。

Conclusion: CoreMark通过创新的CORE嵌入范式，解决了文本水印的关键挑战，为跨语言和字体的应用提供了高效解决方案。

Abstract: Text watermarking schemes have gained considerable attention in recent years,
yet still face critical challenges in achieving simultaneous robustness,
generalizability, and imperceptibility. This paper introduces a new embedding
paradigm,termed CORE, which comprises several consecutively aligned black pixel
segments. Its key innovation lies in its inherent noise resistance during
transmission and broad applicability across languages and fonts. Based on the
CORE, we present a text watermarking framework named CoreMark. Specifically,
CoreMark first dynamically extracts COREs from characters. Then, the characters
with stronger robustness are selected according to the lengths of COREs. By
modifying the thickness of the CORE, the hidden data is embedded into the
selected characters without causing significant visual distortions. Moreover, a
general plug-and-play embedding strength modulator is proposed, which can
adaptively enhance the robustness for small font sizes by adjusting the
embedding strength according to the font size. Experimental evaluation
indicates that CoreMark demonstrates outstanding generalizability across
multiple languages and fonts. Compared to existing methods, CoreMark achieves
significant improvements in resisting screenshot, print-scan, and print camera
attacks, while maintaining satisfactory imperceptibility.

</details>


### [203] [Unsupervised 3D Braided Hair Reconstruction from a Single-View Image](https://arxiv.org/abs/2506.23072)
*Jing Gao*

Main category: cs.CV

TL;DR: 提出了一种无监督的3D编织发型重建方法，从单视图RGB图像中高效捕捉复杂编织结构。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理编织发型的精细几何结构，需解决这一挑战。

Method: 利用受编织理论启发的合成模型，捕捉编织发型的交织结构。

Result: 实验表明，该方法在准确性、真实性和效率上优于现有技术。

Conclusion: 支持数字人类中更具表现力的发型建模。

Abstract: Reconstructing 3D braided hairstyles from single-view images remains a
challenging task due to the intricate interwoven structure and complex
topologies of braids. Existing strand-based hair reconstruction methods
typically focus on loose hairstyles and often struggle to capture the
fine-grained geometry of braided hair. In this paper, we propose a novel
unsupervised pipeline for efficiently reconstructing 3D braided hair from
single-view RGB images. Leveraging a synthetic braid model inspired by braid
theory, our approach effectively captures the complex intertwined structures of
braids. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches, providing superior accuracy, realism, and
efficiency in reconstructing 3D braided hairstyles, supporting expressive
hairstyle modeling in digital humans.

</details>


### [204] [Learning Counterfactually Decoupled Attention for Open-World Model Attribution](https://arxiv.org/abs/2506.23074)
*Yu Zheng,Boyang Gong,Fanye Kong,Yueqi Duan,Bingyao Yu,Wenzhao Zheng,Lei Chen,Jiwen Lu,Jie Zhou*

Main category: cs.CV

TL;DR: 提出了一种反事实解耦注意力学习（CDAL）方法，用于开放世界模型归因，通过建模注意力视觉痕迹与源模型归因的因果关系，提升对未见攻击的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工设计的区域划分或特征空间，易受虚假统计相关性干扰，难以应对开放世界中的新攻击。

Method: CDAL显式建模注意力视觉痕迹与源模型归因的因果关系，反事实解耦模型特定伪影与源偏差，最大化因果效应以优化注意力图。

Result: 在开放世界模型归因基准测试中，CDAL以最小计算开销显著提升现有模型性能，尤其对未见攻击表现突出。

Conclusion: CDAL通过因果建模和解耦，有效提升模型归因的泛化能力，适用于开放世界场景。

Abstract: In this paper, we propose a Counterfactually Decoupled Attention Learning
(CDAL) method for open-world model attribution. Existing methods rely on
handcrafted design of region partitioning or feature space, which could be
confounded by the spurious statistical correlations and struggle with novel
attacks in open-world scenarios. To address this, CDAL explicitly models the
causal relationships between the attentional visual traces and source model
attribution, and counterfactually decouples the discriminative model-specific
artifacts from confounding source biases for comparison. In this way, the
resulting causal effect provides a quantification on the quality of learned
attention maps, thus encouraging the network to capture essential generation
patterns that generalize to unseen source models by maximizing the effect.
Extensive experiments on existing open-world model attribution benchmarks show
that with minimal computational overhead, our method consistently improves
state-of-the-art models by large margins, particularly for unseen novel
attacks. Source code: https://github.com/yzheng97/CDAL.

</details>


### [205] [Dynamic Contrastive Learning for Hierarchical Retrieval: A Case Study of Distance-Aware Cross-View Geo-Localization](https://arxiv.org/abs/2506.23077)
*Suofei Zhang,Xinxin Wang,Xiaofu Wu,Quan Zhou,Haifeng Hu*

Main category: cs.CV

TL;DR: 论文提出了一种动态对比学习框架（DyCL），用于解决距离感知的跨视角地理定位问题，并通过构建DA-Campus基准数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注跨域图像匹配的准确性，而忽略了目标周围上下文信息的全面捕捉和定位误差的最小化。

Method: 提出动态对比学习（DyCL）框架，通过分层空间边界的逐步对齐特征表示。

Result: DyCL在分层检索性能和跨视角地理定位准确性上均有显著提升。

Conclusion: DyCL是对现有多尺度度量学习方法的有力补充，为解决复杂空间关系问题提供了新思路。

Abstract: Existing deep learning-based cross-view geo-localization methods primarily
focus on improving the accuracy of cross-domain image matching, rather than
enabling models to comprehensively capture contextual information around the
target and minimize the cost of localization errors. To support systematic
research into this Distance-Aware Cross-View Geo-Localization (DACVGL) problem,
we construct Distance-Aware Campus (DA-Campus), the first benchmark that pairs
multi-view imagery with precise distance annotations across three spatial
resolutions. Based on DA-Campus, we formulate DACVGL as a hierarchical
retrieval problem across different domains. Our study further reveals that, due
to the inherent complexity of spatial relationships among buildings, this
problem can only be addressed via a contrastive learning paradigm, rather than
conventional metric learning. To tackle this challenge, we propose Dynamic
Contrastive Learning (DyCL), a novel framework that progressively aligns
feature representations according to hierarchical spatial margins. Extensive
experiments demonstrate that DyCL is highly complementary to existing
multi-scale metric learning methods and yields substantial improvements in both
hierarchical retrieval performance and overall cross-view geo-localization
accuracy. Our code and benchmark are publicly available at
https://github.com/anocodetest1/DyCL.

</details>


### [206] [Frequency-enhanced Multi-granularity Context Network for Efficient Vertebrae Segmentation](https://arxiv.org/abs/2506.23086)
*Jian Shi,Tianqi You,Pingping Zhang,Hongli Zhang,Rui Xu,Haojie Li*

Main category: cs.CV

TL;DR: 论文提出了一种频率增强的多粒度上下文网络（FMC-Net），用于提高3D CT和MRI图像中脊椎分割的准确性，通过小波变换和多粒度状态空间模型处理模糊图像和区分相似脊椎。


<details>
  <summary>Details</summary>
Motivation: 当前成像技术的限制和脊柱结构的复杂性导致现有方法难以减少图像模糊的影响并区分相似脊椎。

Method: 使用小波变换进行无损下采样，分别处理高频和低频成分；高频部分通过高频特征细化（HFR）增强关键特征，低频部分通过多粒度状态空间模型（MG-SSM）提取多粒度上下文。

Result: 实验表明，该方法在CT和MRI脊椎分割数据集上优于现有技术。

Conclusion: FMC-Net通过频率增强和多粒度上下文处理，显著提高了脊椎分割的准确性。

Abstract: Automated and accurate segmentation of individual vertebra in 3D CT and MRI
images is essential for various clinical applications. Due to the limitations
of current imaging techniques and the complexity of spinal structures, existing
methods still struggle with reducing the impact of image blurring and
distinguishing similar vertebrae. To alleviate these issues, we introduce a
Frequency-enhanced Multi-granularity Context Network (FMC-Net) to improve the
accuracy of vertebrae segmentation. Specifically, we first apply wavelet
transform for lossless downsampling to reduce the feature distortion in blurred
images. The decomposed high and low-frequency components are then processed
separately. For the high-frequency components, we apply a High-frequency
Feature Refinement (HFR) to amplify the prominence of key features and filter
out noises, restoring fine-grained details in blurred images. For the
low-frequency components, we use a Multi-granularity State Space Model (MG-SSM)
to aggregate feature representations with different receptive fields,
extracting spatially-varying contexts while capturing long-range dependencies
with linear complexity. The utilization of multi-granularity contexts is
essential for distinguishing similar vertebrae and improving segmentation
accuracy. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches on both CT and MRI vertebrae segmentation datasets.
The source code is publicly available at https://github.com/anaanaa/FMCNet.

</details>


### [207] [Where, What, Why: Towards Explainable Driver Attention Prediction](https://arxiv.org/abs/2506.23088)
*Yuchen Zhou,Jiayu Tang,Xiaoyan Xiao,Yueyao Lin,Linkai Liu,Zipeng Guo,Hao Fei,Xiaobo Xia,Chao Gou*

Main category: cs.CV

TL;DR: 论文提出了一种可解释的驾驶员注意力预测任务范式（W3DA），结合空间注意力区域预测、语义解析和认知推理，并提出了一个大型数据集和LLada框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅预测驾驶员注视的空间热图，未能捕捉注意力分配的认知动机，限制了对其机制的深入理解。

Method: 提出了W3DA数据集和LLada框架，联合预测空间注意力区域、解析语义并提供认知推理。

Result: LLada在实验中表现出强大的泛化能力，适用于多种驾驶场景。

Conclusion: 该研究为理解驾驶员注意力机制提供了关键进展，对自动驾驶和智能驾驶培训有重要意义。

Abstract: Modeling task-driven attention in driving is a fundamental challenge for both
autonomous vehicles and cognitive science. Existing methods primarily predict
where drivers look by generating spatial heatmaps, but fail to capture the
cognitive motivations behind attention allocation in specific contexts, which
limits deeper understanding of attention mechanisms. To bridge this gap, we
introduce Explainable Driver Attention Prediction, a novel task paradigm that
jointly predicts spatial attention regions (where), parses attended semantics
(what), and provides cognitive reasoning for attention allocation (why). To
support this, we present W3DA, the first large-scale explainable driver
attention dataset. It enriches existing benchmarks with detailed semantic and
causal annotations across diverse driving scenarios, including normal
conditions, safety-critical situations, and traffic accidents. We further
propose LLada, a Large Language model-driven framework for driver attention
prediction, which unifies pixel modeling, semantic parsing, and cognitive
reasoning within an end-to-end architecture. Extensive experiments demonstrate
the effectiveness of LLada, exhibiting robust generalization across datasets
and driving conditions. This work serves as a key step toward a deeper
understanding of driver attention mechanisms, with significant implications for
autonomous driving, intelligent driver training, and human-computer
interaction.

</details>


### [208] [DC-TTA: Divide-and-Conquer Framework for Test-Time Adaptation of Interactive Segmentation](https://arxiv.org/abs/2506.23104)
*Jihun Kim,Hoyong Kwon,Hyeokjun Kweon,Wooseong Jeong,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: DC-TTA是一种新的测试时适应框架，通过用户交互监督优化SAM模型，处理复杂场景如伪装或多部分对象。


<details>
  <summary>Details</summary>
Motivation: SAM在专业领域或复杂场景中表现不佳，需要改进。

Method: DC-TTA将用户点击分组成更一致的子集，每个子集独立通过TTA处理，最后合并模型。

Result: DC-TTA显著优于SAM的零样本结果和传统TTA方法，减少交互次数并提高准确性。

Conclusion: DC-TTA通过分而治之策略有效提升SAM在复杂任务中的表现。

Abstract: Interactive segmentation (IS) allows users to iteratively refine object
boundaries with minimal cues, such as positive and negative clicks. While the
Segment Anything Model (SAM) has garnered attention in the IS community for its
promptable segmentation capabilities, it often struggles in specialized domains
or when handling complex scenarios (e.g., camouflaged or multi-part objects).
To overcome these challenges, we propose DC-TTA, a novel test-time adaptation
(TTA) framework that adapts SAM on a per-sample basis by leveraging user
interactions as supervision. Instead of forcing a single model to incorporate
all user clicks at once, DC-TTA partitions the clicks into more coherent
subsets, each processed independently via TTA with a separated model. This
Divide-and-Conquer strategy reduces conflicts among diverse cues and enables
more localized updates. Finally, we merge the adapted models to form a unified
predictor that integrates the specialized knowledge from each subset.
Experimental results across various benchmarks demonstrate that DC-TTA
significantly outperforms SAM's zero-shot results and conventional TTA methods,
effectively handling complex tasks such as camouflaged object segmentation with
fewer interactions and improved accuracy.

</details>


### [209] [Computer-Aided Multi-Stroke Character Simplification by Stroke Removal](https://arxiv.org/abs/2506.23106)
*Ryo Ishiyama,Shinnosuke Matsuo,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出一种通过选择性去除笔画来简化多笔画汉字的方法，旨在降低学习难度并提高字体设计的效率。


<details>
  <summary>Details</summary>
Motivation: 多笔画汉字对非母语学习者构成挑战，简化这些字符可以降低学习门槛、优化字体设计并提升字符通信系统的效率。

Method: 使用高精度字符识别模型评估可读性，选择性去除对可读性影响最小的笔画。

Result: 在1,256个字符类别上的实验表明，去除多笔画后许多字符仍可区分。

Conclusion: 研究结果为更系统化的汉字简化策略提供了潜在方向。

Abstract: Multi-stroke characters in scripts such as Chinese and Japanese can be highly
complex, posing significant challenges for both native speakers and,
especially, non-native learners. If these characters can be simplified without
degrading their legibility, it could reduce learning barriers for non-native
speakers, facilitate simpler and legible font designs, and contribute to
efficient character-based communication systems. In this paper, we propose a
framework to systematically simplify multi-stroke characters by selectively
removing strokes while preserving their overall legibility. More specifically,
we use a highly accurate character recognition model to assess legibility and
remove those strokes that minimally impact it. Experimental results on 1,256
character classes with 5, 10, 15, and 20 strokes reveal several key findings,
including the observation that even after removing multiple strokes, many
characters remain distinguishable. These findings suggest the potential for
more formalized simplification strategies.

</details>


### [210] [Hierarchical Corpus-View-Category Refinement for Carotid Plaque Risk Grading in Ultrasound](https://arxiv.org/abs/2506.23108)
*Zhiyuan Zhu,Jian Wang,Yong Jiang,Tong Han,Yuhao Huang,Ang Zhang,Kaiwen Yang,Mingyuan Luo,Zhe Liu,Yaofei Duan,Dong Ni,Tianhong Tang,Xin Yang*

Main category: cs.CV

TL;DR: 提出了一种名为CVC-RF的新框架，通过多级细化（语料库、视图和类别级别）提升颈动脉斑块分级的准确性，解决了现有方法忽视表示学习和类别特征差异的问题。


<details>
  <summary>Details</summary>
Motivation: 颈动脉斑块分级（CPG）对心血管和脑血管疾病风险评估至关重要，但现有深度学习方法多关注多视图特征融合，忽视了表示学习和类别特征差异的重要性。

Method: 提出CVC-RF框架，包括语料库级别的中心记忆对比损失、视图级联下采样注意力模块和类别级别的无参数专家混合加权策略。

Result: 实验表明，CVC-RF通过多级细化有效建模全局特征，在CPG任务中达到最先进性能。

Conclusion: CVC-RF通过多级细化显著提升了颈动脉斑块分级的准确性，为相关临床实践提供了有力工具。

Abstract: Accurate carotid plaque grading (CPG) is vital to assess the risk of
cardiovascular and cerebrovascular diseases. Due to the small size and high
intra-class variability of plaque, CPG is commonly evaluated using a
combination of transverse and longitudinal ultrasound views in clinical
practice. However, most existing deep learning-based multi-view classification
methods focus on feature fusion across different views, neglecting the
importance of representation learning and the difference in class features. To
address these issues, we propose a novel Corpus-View-Category Refinement
Framework (CVC-RF) that processes information from Corpus-, View-, and
Category-levels, enhancing model performance. Our contribution is four-fold.
First, to the best of our knowledge, we are the foremost deep learning-based
method for CPG according to the latest Carotid Plaque-RADS guidelines. Second,
we propose a novel center-memory contrastive loss, which enhances the network's
global modeling capability by comparing with representative cluster centers and
diverse negative samples at the Corpus level. Third, we design a cascaded
down-sampling attention module to fuse multi-scale information and achieve
implicit feature interaction at the View level. Finally, a parameter-free
mixture-of-experts weighting strategy is introduced to leverage class
clustering knowledge to weight different experts, enabling feature decoupling
at the Category level. Experimental results indicate that CVC-RF effectively
models global features via multi-level refinement, achieving state-of-the-art
performance in the challenging CPG task.

</details>


### [211] [MoCa: Modality-aware Continual Pre-training Makes Better Bidirectional Multimodal Embeddings](https://arxiv.org/abs/2506.23115)
*Haonan Chen,Hong Liu,Yuping Luo,Liang Wang,Nan Yang,Furu Wei,Zhicheng Dou*

Main category: cs.CV

TL;DR: MoCa是一个两阶段框架，将预训练的因果视觉语言模型（VLM）转化为高效的双向多模态嵌入模型，解决了当前方法的三个关键限制。


<details>
  <summary>Details</summary>
Motivation: 当前多模态嵌入模型存在因果注意力不适用于嵌入任务、依赖高质量标注数据导致可扩展性差以及训练目标和数据多样性不足的问题。

Method: MoCa分为两个阶段：1）模态感知持续预训练，通过联合重建目标增强双向上下文感知；2）异构对比微调，利用多样化的多模态数据提升泛化和对齐能力。

Result: MoCa在MMEB和ViDoRe-v2基准测试中表现优异，达到新的SOTA结果，并在模型规模和训练数据上展现出强扩展性。

Conclusion: MoCa通过双向注意力、大规模无标注数据和多样化训练目标，显著提升了多模态嵌入模型的性能。

Abstract: Multimodal embedding models, built upon causal Vision Language Models (VLMs),
have shown promise in various tasks. However, current approaches face three key
limitations: the use of causal attention in VLM backbones is suboptimal for
embedding tasks; scalability issues due to reliance on high-quality labeled
paired data for contrastive learning; and limited diversity in training
objectives and data. To address these issues, we propose MoCa, a two-stage
framework for transforming pre-trained VLMs into effective bidirectional
multimodal embedding models. The first stage, Modality-aware Continual
Pre-training, introduces a joint reconstruction objective that simultaneously
denoises interleaved text and image inputs, enhancing bidirectional
context-aware reasoning. The second stage, Heterogeneous Contrastive
Fine-tuning, leverages diverse, semantically rich multimodal data beyond simple
image-caption pairs to enhance generalization and alignment. Our method
addresses the stated limitations by introducing bidirectional attention through
continual pre-training, scaling effectively with massive unlabeled datasets via
joint reconstruction objectives, and utilizing diverse multimodal data for
enhanced representation robustness. Experiments demonstrate that MoCa
consistently improves performance across MMEB and ViDoRe-v2 benchmarks,
achieving new state-of-the-art results, and exhibits strong scalability with
both model size and training data on MMEB.

</details>


### [212] [Enhancing Spatial Reasoning in Multimodal Large Language Models through Reasoning-based Segmentation](https://arxiv.org/abs/2506.23120)
*Zhenhua Ning,Zhuotao Tian,Shaoshuai Shi,Guangming Lu,Daojing He,Wenjie Pei,Li Jiang*

Main category: cs.CV

TL;DR: 论文提出了一种基于推理的分割框架R²S和数据集3D ReasonSeg，以增强3D点云感知的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理需要精确空间推理的复杂指令时存在挑战，尽管3D点云数据提供了详细的空间线索。

Method: R²S框架模拟人类认知过程，将空间推理分解为两个阶段：先识别相关元素，再基于视觉先验处理指令。

Result: 实验表明R²S和3D ReasonSeg显著提升了3D点云感知的空间推理能力。

Conclusion: R²S和3D ReasonSeg为未来研究提供了新的基准和数据集。

Abstract: Recent advances in point cloud perception have demonstrated remarkable
progress in scene understanding through vision-language alignment leveraging
large language models (LLMs). However, existing methods may still encounter
challenges in handling complex instructions that require accurate spatial
reasoning, even if the 3D point cloud data provides detailed spatial cues such
as size and position for identifying the targets. To tackle this issue, we
propose Relevant Reasoning Segmentation (R$^2$S), a reasoning-based
segmentation framework. The framework emulates human cognitive processes by
decomposing spatial reasoning into two sequential stages: first identifying
relevant elements, then processing instructions guided by their associated
visual priors. Furthermore, acknowledging the inadequacy of existing datasets
in complex reasoning tasks, we introduce 3D ReasonSeg, a reasoning-based
segmentation dataset comprising 25,185 training samples and 3,966 validation
samples with precise annotations. Both quantitative and qualitative experiments
demonstrate that the R$^2$S and 3D ReasonSeg effectively endow 3D point cloud
perception with stronger spatial reasoning capabilities, and we hope that they
can serve as a new baseline and benchmark for future work.

</details>


### [213] [UrbanLLaVA: A Multi-modal Large Language Model for Urban Intelligence with Spatial Reasoning and Understanding](https://arxiv.org/abs/2506.23219)
*Jie Feng,Shengyuan Wang,Tianhui Liu,Yanxin Xi,Yong Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为UrbanLLaVA的多模态大语言模型，旨在统一处理多种城市数据，并在多样化城市任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前城市研究方法多针对特定数据类型，缺乏统一框架。多模态大语言模型（MLLMs）的成功为解决这一问题提供了机会。

Method: 通过构建多样化的城市指令数据集，并提出多阶段训练框架，分离空间推理增强与领域知识学习。

Result: 实验表明，UrbanLLaVA在单模态和跨模态任务中均优于开源和专有MLLMs，并展现出跨城市的强泛化能力。

Conclusion: UrbanLLaVA为城市研究提供了一个高效的多模态处理框架，代码和数据已开源。

Abstract: Urban research involves a wide range of scenarios and tasks that require the
understanding of multi-modal data. Current methods often focus on specific data
types and lack a unified framework in urban field for processing them
comprehensively. The recent success of multi-modal large language models
(MLLMs) presents a promising opportunity to overcome this limitation. In this
paper, we introduce $\textit{UrbanLLaVA}$, a multi-modal large language model
designed to process these four types of data simultaneously and achieve strong
performance across diverse urban tasks compared with general MLLMs. In
$\textit{UrbanLLaVA}$, we first curate a diverse urban instruction dataset
encompassing both single-modal and cross-modal urban data, spanning from
location view to global view of urban environment. Additionally, we propose a
multi-stage training framework that decouples spatial reasoning enhancement
from domain knowledge learning, thereby improving the compatibility and
downstream performance of $\textit{UrbanLLaVA}$ across diverse urban tasks.
Finally, we also extend existing benchmark for urban research to assess the
performance of MLLMs across a wide range of urban tasks. Experimental results
from three cities demonstrate that $\textit{UrbanLLaVA}$ outperforms
open-source and proprietary MLLMs in both single-modal tasks and complex
cross-modal tasks and shows robust generalization abilities across cities.
Source codes and data are openly accessible to the research community via
https://github.com/tsinghua-fib-lab/UrbanLLaVA.

</details>


### [214] [Dare to Plagiarize? Plagiarized Painting Recognition and Retrieval](https://arxiv.org/abs/2506.23132)
*Sophie Zhou,Shu Kong*

Main category: cs.CV

TL;DR: 论文提出了一种通过检索视觉相似的真实艺术品来检测和解释绘画抄袭的方法，使用生成AI构建数据集，并通过微调DINOv2模型提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 保护艺术家版权和知识产权，解决艺术抄袭检测中的挑战。

Method: 构建合成抄袭数据集，使用DINOv2模型进行相似性检索和分类，并通过度量学习微调模型。

Result: 基线方法识别准确率达97.2%，但检索精度低（29.0% AP）；微调后检索性能提升12% AP，但识别准确率降至92.7%。

Conclusion: 方法有效但存在权衡，未来需进一步优化模型以平衡检索和识别性能。

Abstract: Art plagiarism detection plays a crucial role in protecting artists'
copyrights and intellectual property, yet it remains a challenging problem in
forensic analysis. In this paper, we address the task of recognizing
plagiarized paintings and explaining the detected plagarisms by retrieving
visually similar authentic artworks. To support this study, we construct a
dataset by collecting painting photos and synthesizing plagiarized versions
using generative AI, tailored to specific artists' styles. We first establish a
baseline approach using off-the-shelf features from the visual foundation model
DINOv2 to retrieve the most similar images in the database and classify
plagiarism based on a similarity threshold. Surprisingly, this non-learned
method achieves a high recognition accuracy of 97.2\% but suffers from low
retrieval precision 29.0\% average precision (AP). To improve retrieval
quality, we finetune DINOv2 with a metric learning loss using positive and
negative sample pairs sampled in the database. The finetuned model greatly
improves retrieval performance by 12\% AP over the baseline, though it
unexpectedly results in a lower recognition accuracy (92.7\%). We conclude with
insightful discussions and outline directions for future research.

</details>


### [215] [RoboScape: Physics-informed Embodied World Model](https://arxiv.org/abs/2506.23135)
*Yu Shang,Xin Zhang,Yinzhou Tang,Lei Jin,Chen Gao,Wei Wu,Yong Li*

Main category: cs.CV

TL;DR: RoboScape是一个统一的物理感知世界模型，通过联合学习RGB视频生成和物理知识，提升了视频生成的视觉保真度和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前的世界模型在建模3D几何和运动动力学方面存在局限性，导致在接触密集的机器人场景中生成不真实的视频。

Method: 提出RoboScape，通过时间深度预测和关键点动力学学习两个物理感知联合训练任务，增强3D几何一致性和复杂运动建模。

Result: 实验表明，RoboScape在多种机器人场景中生成具有更高视觉保真度和物理合理性的视频，并验证了其在下游应用中的实用性。

Conclusion: RoboScape为构建高效的物理感知世界模型提供了新思路，推动了具身智能研究的发展。

Abstract: World models have become indispensable tools for embodied intelligence,
serving as powerful simulators capable of generating realistic robotic videos
while addressing critical data scarcity challenges. However, current embodied
world models exhibit limited physical awareness, particularly in modeling 3D
geometry and motion dynamics, resulting in unrealistic video generation for
contact-rich robotic scenarios. In this paper, we present RoboScape, a unified
physics-informed world model that jointly learns RGB video generation and
physics knowledge within an integrated framework. We introduce two key
physics-informed joint training tasks: temporal depth prediction that enhances
3D geometric consistency in video rendering, and keypoint dynamics learning
that implicitly encodes physical properties (e.g., object shape and material
characteristics) while improving complex motion modeling. Extensive experiments
demonstrate that RoboScape generates videos with superior visual fidelity and
physical plausibility across diverse robotic scenarios. We further validate its
practical utility through downstream applications including robotic policy
training with generated data and policy evaluation. Our work provides new
insights for building efficient physics-informed world models to advance
embodied intelligence research. The code is available at:
https://github.com/tsinghua-fib-lab/RoboScape.

</details>


### [216] [VisualPrompter: Prompt Optimization with Visual Feedback for Text-to-Image Synthesis](https://arxiv.org/abs/2506.23138)
*Shiyu Wu,Mingzhen Sun,Weining Wang,Yequan Wang,Jing Liu*

Main category: cs.CV

TL;DR: VisualPrompter是一个无需训练的新提示工程框架，通过自动自反思模块和细粒度提示优化机制，提升文本到图像生成中的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 现有提示工程方法虽能提升生成图像的风格和美学，但常忽略语义对齐，导致内容与用户描述不符。

Method: 提出VisualPrompter框架，包含自动自反思模块识别缺失概念，以及目标特定提示优化机制细粒度修订提示。

Result: 在多个文本-图像对齐评估基准上达到最新最优性能，且具有即插即用设计。

Conclusion: VisualPrompter有效解决了语义对齐问题，适用于多种生成模型。

Abstract: Since there exists a notable gap between user-provided and model-preferred
prompts, generating high-quality and satisfactory images using diffusion models
often requires prompt engineering to optimize user inputs. Current studies on
text-to-image prompt engineering can effectively enhance the style and
aesthetics of generated images. However, they often neglect the semantic
alignment between generated images and user descriptions, resulting in visually
appealing but content-wise unsatisfying outputs. In this work, we propose
VisualPrompter, a novel training-free prompt engineering framework that refines
user inputs to model-preferred sentences. In particular, VisualPrompter
utilizes an automatic self-reflection module to identify the missing concepts
in generated images and a target-specific prompt optimization mechanism to
revise the prompts in a fine-grained manner. Extensive experiments demonstrate
the effectiveness of our VisualPrompter, which achieves new state-of-the-art
performance on multiple benchmarks for text-image alignment evaluation.
Additionally, our framework features a plug-and-play design, making it highly
adaptable to various generative models.

</details>


### [217] [AlignCVC: Aligning Cross-View Consistency for Single-Image-to-3D Generation](https://arxiv.org/abs/2506.23150)
*Xinyue Liang,Zhiyuan Ma,Lingchen Sun,Yanjun Guo,Lei Zhang*

Main category: cs.CV

TL;DR: AlignCVC提出了一种通过分布对齐而非严格回归损失的单图像到3D生成框架，显著提升了跨视图一致性（CVC）和生成效率。


<details>
  <summary>Details</summary>
Motivation: 传统方法中，预训练生成模型合成的中间多视图图像缺乏跨视图一致性（CVC），严重影响3D重建性能。现有方法通过反馈重建结果优化CVC，但受限于噪声和不稳定的输出。

Method: AlignCVC通过分布对齐将生成和重建的多视图分布与真实多视图分布对齐，采用软硬对齐策略分别优化生成和重建模型。

Result: 实验表明，AlignCVC不仅提升了生成质量，还将推理加速至仅需4步，且能无缝集成多种多视图生成与3D重建模型。

Conclusion: AlignCVC为单图像到3D生成提供了高效且一致的解决方案，显著优于现有方法。

Abstract: Single-image-to-3D models typically follow a sequential generation and
reconstruction workflow. However, intermediate multi-view images synthesized by
pre-trained generation models often lack cross-view consistency (CVC),
significantly degrading 3D reconstruction performance. While recent methods
attempt to refine CVC by feeding reconstruction results back into the
multi-view generator, these approaches struggle with noisy and unstable
reconstruction outputs that limit effective CVC improvement. We introduce
AlignCVC, a novel framework that fundamentally re-frames single-image-to-3D
generation through distribution alignment rather than relying on strict
regression losses. Our key insight is to align both generated and reconstructed
multi-view distributions toward the ground-truth multi-view distribution,
establishing a principled foundation for improved CVC. Observing that generated
images exhibit weak CVC while reconstructed images display strong CVC due to
explicit rendering, we propose a soft-hard alignment strategy with distinct
objectives for generation and reconstruction models. This approach not only
enhances generation quality but also dramatically accelerates inference to as
few as 4 steps. As a plug-and-play paradigm, our method, namely AlignCVC,
seamlessly integrates various multi-view generation models with 3D
reconstruction models. Extensive experiments demonstrate the effectiveness and
efficiency of AlignCVC for single-image-to-3D generation.

</details>


### [218] [MEMFOF: High-Resolution Training for Memory-Efficient Multi-Frame Optical Flow Estimation](https://arxiv.org/abs/2506.23151)
*Vladislav Bargatin,Egor Chistov,Alexander Yakovenko,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: MEMFOF是一种内存高效的多帧光流估计方法，显著降低GPU内存消耗，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率（如FullHD）输入下光流估计方法GPU内存消耗过大的问题。

Method: 通过优化RAFT-like架构的设计选择，减少相关体积并采用高分辨率训练协议，结合多帧估计。

Result: 在多个基准测试中达到最先进性能，内存消耗显著降低（运行时2.09 GB，训练时28.5 GB）。

Conclusion: MEMFOF在高分辨率光流估计中实现了内存效率和性能的平衡，优于资源密集型方法。

Abstract: Recent advances in optical flow estimation have prioritized accuracy at the
cost of growing GPU memory consumption, particularly for high-resolution
(FullHD) inputs. We introduce MEMFOF, a memory-efficient multi-frame optical
flow method that identifies a favorable trade-off between multi-frame
estimation and GPU memory usage. Notably, MEMFOF requires only 2.09 GB of GPU
memory at runtime for 1080p inputs, and 28.5 GB during training, which uniquely
positions our method to be trained at native 1080p without the need for
cropping or downsampling. We systematically revisit design choices from
RAFT-like architectures, integrating reduced correlation volumes and
high-resolution training protocols alongside multi-frame estimation, to achieve
state-of-the-art performance across multiple benchmarks while substantially
reducing memory overhead. Our method outperforms more resource-intensive
alternatives in both accuracy and runtime efficiency, validating its robustness
for flow estimation at high resolutions. At the time of submission, our method
ranks first on the Spring benchmark with a 1-pixel (1px) outlier rate of 3.289,
leads Sintel (clean) with an endpoint error (EPE) of 0.963, and achieves the
best Fl-all error on KITTI-2015 at 2.94%. The code is available at
https://github.com/msu-video-group/memfof.

</details>


### [219] [Dynamic View Synthesis from Small Camera Motion Videos](https://arxiv.org/abs/2506.23153)
*Huiqiang Sun,Xingyi Li,Juewen Peng,Liao Shen,Zhiguo Cao,Ke Xian,Guosheng Lin*

Main category: cs.CV

TL;DR: 论文提出了一种新的分布深度正则化（DDR）方法，解决了动态3D场景中因小相机运动导致的几何表示和相机参数估计问题。


<details>
  <summary>Details</summary>
Motivation: 动态3D场景的新视角合成在相机运动范围有限或静止时，现有方法难以准确表示场景几何和估计相机参数。

Method: 提出DDR方法，通过Gumbel-softmax采样和几何约束优化渲染权重分布，并引入相机参数学习。

Result: 实验表明，该方法在小相机运动输入下表现优于现有方法。

Conclusion: DDR方法有效解决了小相机运动场景中的几何表示和相机参数问题。

Abstract: Novel view synthesis for dynamic $3$D scenes poses a significant challenge.
Many notable efforts use NeRF-based approaches to address this task and yield
impressive results. However, these methods rely heavily on sufficient motion
parallax in the input images or videos. When the camera motion range becomes
limited or even stationary (i.e., small camera motion), existing methods
encounter two primary challenges: incorrect representation of scene geometry
and inaccurate estimation of camera parameters. These challenges make prior
methods struggle to produce satisfactory results or even become invalid. To
address the first challenge, we propose a novel Distribution-based Depth
Regularization (DDR) that ensures the rendering weight distribution to align
with the true distribution. Specifically, unlike previous methods that use
depth loss to calculate the error of the expectation, we calculate the
expectation of the error by using Gumbel-softmax to differentiably sample
points from discrete rendering weight distribution. Additionally, we introduce
constraints that enforce the volume density of spatial points before the object
boundary along the ray to be near zero, ensuring that our model learns the
correct geometry of the scene. To demystify the DDR, we further propose a
visualization tool that enables observing the scene geometry representation at
the rendering weight level. For the second challenge, we incorporate camera
parameter learning during training to enhance the robustness of our model to
camera parameters. We conduct extensive experiments to demonstrate the
effectiveness of our approach in representing scenes with small camera motion
input, and our results compare favorably to state-of-the-art methods.

</details>


### [220] [Towards an Automated Multimodal Approach for Video Summarization: Building a Bridge Between Text, Audio and Facial Cue-Based Summarization](https://arxiv.org/abs/2506.23714)
*Md Moinul Islam,Sofoklis Kakouros,Janne Heikkilä,Mourad Oussalah*

Main category: cs.CV

TL;DR: 本文提出了一种行为感知的多模态视频摘要框架，整合文本、音频和视觉线索生成时间戳对齐的摘要，显著提升了传统方法的性能。


<details>
  <summary>Details</summary>
Motivation: 随着视频内容在教育、职业和社交领域的增加，需要超越传统单模态方法的有效摘要技术。

Method: 通过提取韵律特征、文本线索和视觉指标，识别语义和情感重要时刻，并利用跨模态强调的“奖励词”提升摘要质量。

Result: 实验结果显示，在文本和视频评估指标上均显著优于传统方法（如Edmundson方法），ROUGE-1从0.4769提升至0.7929，BERTScore从0.9152提升至0.9536，视频F1-Score提升近23%。

Conclusion: 多模态整合在生成全面且行为感知的视频摘要方面具有巨大潜力。

Abstract: The increasing volume of video content in educational, professional, and
social domains necessitates effective summarization techniques that go beyond
traditional unimodal approaches. This paper proposes a behaviour-aware
multimodal video summarization framework that integrates textual, audio, and
visual cues to generate timestamp-aligned summaries. By extracting prosodic
features, textual cues and visual indicators, the framework identifies
semantically and emotionally important moments. A key contribution is the
identification of bonus words, which are terms emphasized across multiple
modalities and used to improve the semantic relevance and expressive clarity of
the summaries. The approach is evaluated against pseudo-ground truth (pGT)
summaries generated using LLM-based extractive method. Experimental results
demonstrate significant improvements over traditional extractive method, such
as the Edmundson method, in both text and video-based evaluation metrics.
Text-based metrics show ROUGE-1 increasing from 0.4769 to 0.7929 and BERTScore
from 0.9152 to 0.9536, while in video-based evaluation, our proposed framework
improves F1-Score by almost 23%. The findings underscore the potential of
multimodal integration in producing comprehensive and behaviourally informed
video summaries.

</details>


### [221] [Self-Supervised Contrastive Learning for Multi-Label Images](https://arxiv.org/abs/2506.23156)
*Jiale Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种针对多标签图像的自监督学习方法，通过块级增强和图像感知对比损失，减少了预训练开销并提升了语义一致性。


<details>
  <summary>Details</summary>
Motivation: 主流自监督学习方法依赖单标签高体数据集（如ImageNet），预训练开销大且忽略了多标签图像的丰富语义信息。

Method: 提出块级增强模块提取多标签图像中的潜在正视图对，并设计图像感知对比损失建立视图间的联系。

Result: 在样本质量和数量有限的情况下，通过线性微调和迁移学习验证了方法的竞争力。

Conclusion: 该方法在多标签图像上实现了高效的自监督学习，具有广泛的下游应用潜力。

Abstract: Self-supervised learning (SSL) has demonstrated its effectiveness in learning
representations through comparison methods that align with human intuition.
However, mainstream SSL methods heavily rely on high body datasets with single
label, such as ImageNet, resulting in intolerable pre-training overhead.
Besides, more general multi-label images are frequently overlooked in SSL,
despite their potential for richer semantic information and broader
applicability in downstream scenarios. Therefore, we tailor the mainstream SSL
approach to guarantee excellent representation learning capabilities using
fewer multi-label images. Firstly, we propose a block-wise augmentation module
aimed at extracting additional potential positive view pairs from multi-label
images. Subsequently, an image-aware contrastive loss is devised to establish
connections between these views, thereby facilitating the extraction of
semantically consistent representations. Comprehensive linear fine-tuning and
transfer learning validate the competitiveness of our approach despite
challenging sample quality and quantity.

</details>


### [222] [Ella: Embodied Social Agents with Lifelong Memory](https://arxiv.org/abs/2506.24019)
*Hongxin Zhang,Zheyuan Zhang,Zeyuan Wang,Zunzhe Zhang,Lixing Fang,Qinhong Zhou,Chuang Gan*

Main category: cs.CV

TL;DR: Ella是一个能够在3D开放世界中终身学习的社交代理，通过视觉观察和社交互动积累经验，利用多模态记忆系统和基础模型实现自主决策和社交能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过结合结构化记忆系统和基础模型，推动具身智能的发展，使代理能够在动态环境中持续学习和适应。

Method: Ella采用多模态记忆系统（语义记忆和情景记忆）与基础模型结合，支持信息存储、更新和检索，用于决策、社交和活动规划。

Result: 实验表明，Ella能够有效影响、领导和合作其他代理，展示出通过观察和社交互动学习的能力。

Conclusion: 结合结构化记忆系统和基础模型具有推动具身智能发展的潜力。

Abstract: We introduce Ella, an embodied social agent capable of lifelong learning
within a community in a 3D open world, where agents accumulate experiences and
acquire knowledge through everyday visual observations and social interactions.
At the core of Ella's capabilities is a structured, long-term multimodal memory
system that stores, updates, and retrieves information effectively. It consists
of a name-centric semantic memory for organizing acquired knowledge and a
spatiotemporal episodic memory for capturing multimodal experiences. By
integrating this lifelong memory system with foundation models, Ella retrieves
relevant information for decision-making, plans daily activities, builds social
relationships, and evolves autonomously while coexisting with other intelligent
beings in the open world. We conduct capability-oriented evaluations in a
dynamic 3D open world where 15 agents engage in social activities for days and
are assessed with a suite of unseen controlled evaluations. Experimental
results show that Ella can influence, lead, and cooperate with other agents
well to achieve goals, showcasing its ability to learn effectively through
observation and social interaction. Our findings highlight the transformative
potential of combining structured memory systems with foundation models for
advancing embodied intelligence. More videos can be found at
https://umass-embodied-agi.github.io/Ella/.

</details>


### [223] [STD-GS: Exploring Frame-Event Interaction for SpatioTemporal-Disentangled Gaussian Splatting to Reconstruct High-Dynamic Scene](https://arxiv.org/abs/2506.23157)
*Hanyu Zhou,Haonan Wang,Haoyue Liu,Yuxing Duan,Luxin Yan,Gim Hee Lee*

Main category: cs.CV

TL;DR: 提出了一种时空解耦的高斯泼溅框架，用于高动态场景重建，通过事件相机补偿帧相机，解决背景与物体时空特征不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法采用统一表示模型（如高斯）直接匹配动态场景的时空特征，但无法处理帧成像导致的潜在不连续时间特征以及背景与物体的异质空间特征。

Method: 引入事件相机补偿帧相机，提出时空解耦的高斯泼溅框架，通过聚类区分背景与物体的时空特征，并利用高斯表示与事件数据的一致性指导物体高斯的时空解耦。

Result: 实验验证了所提方法的优越性，能够提升背景与物体的时空区分能力，实现时间连续的动态场景渲染。

Conclusion: 时空解耦的高斯泼溅框架有效解决了高动态场景重建中的时空特征不匹配问题，为动态场景表示提供了新思路。

Abstract: High-dynamic scene reconstruction aims to represent static background with
rigid spatial features and dynamic objects with deformed continuous
spatiotemporal features. Typically, existing methods adopt unified
representation model (e.g., Gaussian) to directly match the spatiotemporal
features of dynamic scene from frame camera. However, this unified paradigm
fails in the potential discontinuous temporal features of objects due to frame
imaging and the heterogeneous spatial features between background and objects.
To address this issue, we disentangle the spatiotemporal features into various
latent representations to alleviate the spatiotemporal mismatching between
background and objects. In this work, we introduce event camera to compensate
for frame camera, and propose a spatiotemporal-disentangled Gaussian splatting
framework for high-dynamic scene reconstruction. As for dynamic scene, we
figure out that background and objects have appearance discrepancy in
frame-based spatial features and motion discrepancy in event-based temporal
features, which motivates us to distinguish the spatiotemporal features between
background and objects via clustering. As for dynamic object, we discover that
Gaussian representations and event data share the consistent spatiotemporal
characteristic, which could serve as a prior to guide the spatiotemporal
disentanglement of object Gaussians. Within Gaussian splatting framework, the
cumulative scene-object disentanglement can improve the spatiotemporal
discrimination between background and objects to render the time-continuous
dynamic scene. Extensive experiments have been performed to verify the
superiority of the proposed method.

</details>


### [224] [MotionGPT3: Human Motion as a Second Modality](https://arxiv.org/abs/2506.24086)
*Bingfan Zhu,Biao Jiang,Sunyi Wang,Shixiang Tang,Tao Chen,Linjie Luo,Youyi Zheng,Xin Chen*

Main category: cs.CV

TL;DR: MotionGPT3是一个双模态运动-语言模型，通过分离运动建模和共享注意力机制，解决了运动与语言统一建模中的重建差距和语言智能退化问题。


<details>
  <summary>Details</summary>
Motivation: 当前多模态模型在统一理解和生成方面取得了进展，但运动-语言统一模型的研究仍不足。需要解决运动模态与离散表示的重建差距以及统一训练中语言智能的退化问题。

Method: 提出MotionGPT3，将运动作为第二模态，通过分离模型参数和共享注意力机制实现跨模态交互。使用运动VAE编码运动，并通过扩散头预测运动潜在表示。

Result: 实验表明，MotionGPT3在运动理解和生成任务中表现优异，同时保持了强大的语言能力。

Conclusion: MotionGPT3建立了一个在自回归框架内统一的双模态运动扩散模型，为运动-语言统一建模提供了有效解决方案。

Abstract: Though recent advances in multimodal models have demonstrated strong
capabilities and opportunities in unified understanding and generation, the
development of unified motion-language models remains underexplored. To enable
such models with high-fidelity human motion, two core challenges must be
addressed. The first is the reconstruction gap between the continuous motion
modality and discrete representation in an autoregressive manner, and the
second is the degradation of language intelligence during unified training.
Inspired by the mixture of experts, we propose MotionGPT3, a bimodal
motion-language model that treats human motion as a second modality, decoupling
motion modeling via separate model parameters and enabling both effective
cross-modal interaction and efficient multimodal scaling training. To preserve
language intelligence, the text branch retains the original structure and
parameters of the pretrained language model, while a new motion branch is
integrated via a shared attention mechanism, enabling bidirectional information
flow between two modalities. We first employ a motion Variational Autoencoder
(VAE) to encode raw human motion into latent representations. Based on this
continuous latent space, the motion branch predicts motion latents directly
from intermediate hidden states using a diffusion head, bypassing discrete
tokenization. Extensive experiments show that our approach achieves competitive
performance on both motion understanding and generation tasks while preserving
strong language capabilities, establishing a unified bimodal motion diffusion
framework within an autoregressive manner.

</details>


### [225] [Trident: Detecting Face Forgeries with Adversarial Triplet Learning](https://arxiv.org/abs/2506.23189)
*Mustafa Hakan Kara,Aysegul Dundar,Uğur Güdükbay*

Main category: cs.CV

TL;DR: 提出了一种名为Trident的人脸伪造检测框架，通过三元组学习和Siamese网络架构提高对不同伪造方法的适应性。


<details>
  <summary>Details</summary>
Motivation: 随着深度神经网络生成的人脸伪造技术日益复杂，检测数字媒体中的人脸伪造变得更具挑战性，强调了维护数字媒体完整性和打击视觉虚假信息的重要性。

Method: Trident框架采用三元组学习和Siamese网络架构，结合领域对抗训练和伪造判别器，以捕捉伪造样本的细微差异并提高泛化能力。

Result: 在多个基准测试和消融研究中，Trident表现出色，证明了其有效性。

Conclusion: Trident通过创新的训练方法和架构设计，显著提升了人脸伪造检测的鲁棒性和泛化能力。

Abstract: As face forgeries generated by deep neural networks become increasingly
sophisticated, detecting face manipulations in digital media has posed a
significant challenge, underscoring the importance of maintaining digital media
integrity and combating visual disinformation. Current detection models,
predominantly based on supervised training with domain-specific data, often
falter against forgeries generated by unencountered techniques. In response to
this challenge, we introduce \textit{Trident}, a face forgery detection
framework that employs triplet learning with a Siamese network architecture for
enhanced adaptability across diverse forgery methods. \textit{Trident} is
trained on curated triplets to isolate nuanced differences of forgeries,
capturing fine-grained features that distinguish pristine samples from
manipulated ones while controlling for other variables. To further enhance
generalizability, we incorporate domain-adversarial training with a forgery
discriminator. This adversarial component guides our embedding model towards
forgery-agnostic representations, improving its robustness to unseen
manipulations. In addition, we prevent gradient flow from the classifier head
to the embedding model, avoiding overfitting induced by artifacts peculiar to
certain forgeries. Comprehensive evaluations across multiple benchmarks and
ablation studies demonstrate the effectiveness of our framework. We will
release our code in a GitHub repository.

</details>


### [226] [DEL: Dense Event Localization for Multi-modal Audio-Visual Understanding](https://arxiv.org/abs/2506.23196)
*Mona Ahmadian,Amir Shirian,Frank Guerin,Andrew Gilbert*

Main category: cs.CV

TL;DR: DEL框架通过音频和视觉特征对齐及多模态交互细化模块，实现了密集语义动作定位，在多个TAL数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界视频中的重叠事件和复杂时间依赖关系使多模态交互建模具有挑战性。

Method: DEL框架包含两个关键模块：利用掩码自注意力增强模态内一致性的特征对齐模块，以及建模跨模态依赖关系的多尺度交互细化模块。

Result: 在UnAV-100、THUMOS14等数据集上，DEL的平均mAP显著提升，最高达+3.3%。

Conclusion: DEL在多模态动作定位任务中表现出色，为复杂视频分析提供了有效解决方案。

Abstract: Real-world videos often contain overlapping events and complex temporal
dependencies, making multimodal interaction modeling particularly challenging.
We introduce DEL, a framework for dense semantic action localization, aiming to
accurately detect and classify multiple actions at fine-grained temporal
resolutions in long untrimmed videos. DEL consists of two key modules: the
alignment of audio and visual features that leverage masked self-attention to
enhance intra-mode consistency and a multimodal interaction refinement module
that models cross-modal dependencies across multiple scales, enabling
high-level semantics and fine-grained details. Our method achieves
state-of-the-art performance on multiple real-world Temporal Action
Localization (TAL) datasets, UnAV-100, THUMOS14, ActivityNet 1.3, and
EPIC-Kitchens-100, surpassing previous approaches with notable average mAP
gains of +3.3%, +2.6%, +1.2%, +1.7% (verb), and +1.4% (noun), respectively.

</details>


### [227] [Transformer-Based Person Search with High-Frequency Augmentation and Multi-Wave Mixing](https://arxiv.org/abs/2506.23202)
*Qilin Shu,Qixian Zhang,Qi Zhang,Hongyun Zhang,Duoqian Miao,Cairong Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种名为HAMW的新方法，通过高频增强和多波混合技术改进基于Transformer的人物搜索模型，解决了自注意力机制抑制高频特征和高计算成本的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的人物搜索模型存在自注意力机制抑制高频特征和高计算成本的问题，影响了模型性能。

Method: 提出HAMW方法，包括高频增强和多级Haar小波融合策略，分三阶段优化检测和重识别性能。

Result: 在CUHK-SYSU和PRW数据集上实现了最先进的性能。

Conclusion: HAMW方法有效提升了人物搜索模型的性能，同时降低了计算复杂度。

Abstract: The person search task aims to locate a target person within a set of scene
images. In recent years, transformer-based models in this field have made some
progress. However, they still face three primary challenges: 1) the
self-attention mechanism tends to suppress high-frequency components in the
features, which severely impacts model performance; 2) the computational cost
of transformers is relatively high. To address these issues, we propose a novel
High-frequency Augmentation and Multi-Wave mixing (HAMW) method for person
search. HAMW is designed to enhance the discriminative feature extraction
capabilities of transformers while reducing computational overhead and
improving efficiency. Specifically, we develop a three-stage framework that
progressively optimizes both detection and re-identification performance. Our
model enhances the perception of high-frequency features by learning from
augmented inputs containing additional high-frequency components. Furthermore,
we replace the self-attention layers in the transformer with a strategy based
on multi-level Haar wavelet fusion to capture multi-scale features. This not
only lowers the computational complexity but also alleviates the suppression of
high-frequency features and enhances the ability to exploit multi-scale
information. Extensive experiments demonstrate that HAMW achieves
state-of-the-art performance on both the CUHK-SYSU and PRW datasets.

</details>


### [228] [BridgeShape: Latent Diffusion Schrödinger Bridge for 3D Shape Completion](https://arxiv.org/abs/2506.23205)
*Dequan Kong,Zhe Zhu,Honghua Chen,Mingqiang Wei*

Main category: cs.CV

TL;DR: BridgeShape提出了一种基于潜在扩散Schrödinger桥的3D形状补全框架，通过最优传输路径和深度增强的VQ-VAE编码，解决了现有方法在全局一致性和分辨率限制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的3D形状补全方法未能显式建模最优全局传输路径，且受限于体素空间的分辨率约束，导致补全效果不佳。

Method: BridgeShape将形状补全建模为最优传输问题，并引入深度增强的VQ-VAE编码3D形状到紧凑潜在空间，结合DINOv2特征增强几何结构感知。

Result: BridgeShape在大规模3D形状补全基准测试中达到最先进性能，支持更高分辨率和未见物体类别的补全。

Conclusion: BridgeShape通过显式建模最优传输路径和潜在空间操作，显著提升了3D形状补全的全局一致性和细节生成能力。

Abstract: Existing diffusion-based 3D shape completion methods typically use a
conditional paradigm, injecting incomplete shape information into the denoising
network via deep feature interactions (e.g., concatenation, cross-attention) to
guide sampling toward complete shapes, often represented by voxel-based
distance functions. However, these approaches fail to explicitly model the
optimal global transport path, leading to suboptimal completions. Moreover,
performing diffusion directly in voxel space imposes resolution constraints,
limiting the generation of fine-grained geometric details. To address these
challenges, we propose BridgeShape, a novel framework for 3D shape completion
via latent diffusion Schr\"odinger bridge. The key innovations lie in two
aspects: (i) BridgeShape formulates shape completion as an optimal transport
problem, explicitly modeling the transition between incomplete and complete
shapes to ensure a globally coherent transformation. (ii) We introduce a
Depth-Enhanced Vector Quantized Variational Autoencoder (VQ-VAE) to encode 3D
shapes into a compact latent space, leveraging self-projected multi-view depth
information enriched with strong DINOv2 features to enhance geometric
structural perception. By operating in a compact yet structurally informative
latent space, BridgeShape effectively mitigates resolution constraints and
enables more efficient and high-fidelity 3D shape completion. BridgeShape
achieves state-of-the-art performance on large-scale 3D shape completion
benchmarks, demonstrating superior fidelity at higher resolutions and for
unseen object classes.

</details>


### [229] [VolumetricSMPL: A Neural Volumetric Body Model for Efficient Interactions, Contacts, and Collisions](https://arxiv.org/abs/2506.23236)
*Marko Mihajlovic,Siwei Zhang,Gen Li,Kaifeng Zhao,Lea Müller,Siyu Tang*

Main category: cs.CV

TL;DR: VolumetricSMPL是一种基于神经混合权重（NBW）的神经体积人体模型，显著提高了计算效率，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的人体模型使用表面网格，难以高效处理与其他几何实体的交互，而现有的体积神经隐式模型在复杂人体姿态下不够鲁棒或计算成本高。

Method: VolumetricSMPL利用NBW动态混合少量学习权重矩阵，生成紧凑且高效的MLP解码器，同时支持SDF用于接触建模。

Result: VolumetricSMPL在推理速度、GPU内存使用、准确性等方面优于COAP模型，并在四个任务中验证了其性能。

Conclusion: VolumetricSMPL在广泛的应用中表现出高效性和高性能，为人体建模提供了新的解决方案。

Abstract: Parametric human body models play a crucial role in computer graphics and
vision, enabling applications ranging from human motion analysis to
understanding human-environment interactions. Traditionally, these models use
surface meshes, which pose challenges in efficiently handling interactions with
other geometric entities, such as objects and scenes, typically represented as
meshes or point clouds. To address this limitation, recent research has
explored volumetric neural implicit body models. However, existing works are
either insufficiently robust for complex human articulations or impose high
computational and memory costs, limiting their widespread use. To this end, we
introduce VolumetricSMPL, a neural volumetric body model that leverages Neural
Blend Weights (NBW) to generate compact, yet efficient MLP decoders. Unlike
prior approaches that rely on large MLPs, NBW dynamically blends a small set of
learned weight matrices using predicted shape- and pose-dependent coefficients,
significantly improving computational efficiency while preserving
expressiveness. VolumetricSMPL outperforms prior volumetric occupancy model
COAP with 10x faster inference, 6x lower GPU memory usage, enhanced accuracy,
and a Signed Distance Function (SDF) for efficient and differentiable contact
modeling. We demonstrate VolumetricSMPL's strengths across four challenging
tasks: (1) reconstructing human-object interactions from in-the-wild images,
(2) recovering human meshes in 3D scenes from egocentric views, (3)
scene-constrained motion synthesis, and (4) resolving self-intersections. Our
results highlight its broad applicability and significant performance and
efficiency gains.

</details>


### [230] [TVG-SLAM: Robust Gaussian Splatting SLAM with Tri-view Geometric Constraints](https://arxiv.org/abs/2506.23207)
*Zhen Tan,Xieyuanli Chen,Lei Feng,Yangbing Ge,Shuaifeng Zhi,Jiaxiong Liu,Dewen Hu*

Main category: cs.CV

TL;DR: TVG-SLAM是一种基于3D高斯溅射的RGB-only SLAM系统，通过三视图几何范式提升跟踪和映射的鲁棒性，适用于复杂户外环境。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-only SLAM系统依赖光度渲染损失，在户外无边界环境中因视角和光照变化导致鲁棒性不足。

Method: 引入三视图匹配模块和混合几何约束，结合光度损失提升跟踪；采用概率初始化策略和动态衰减机制优化映射。

Result: 在多个户外数据集上表现优异，显著降低轨迹误差（ATE减少69.0%），渲染质量达到SOTA。

Conclusion: TVG-SLAM通过几何约束和动态机制显著提升了RGB-only SLAM的鲁棒性和性能。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled RGB-only SLAM
systems to achieve high-fidelity scene representation. However, the heavy
reliance of existing systems on photometric rendering loss for camera tracking
undermines their robustness, especially in unbounded outdoor environments with
severe viewpoint and illumination changes. To address these challenges, we
propose TVG-SLAM, a robust RGB-only 3DGS SLAM system that leverages a novel
tri-view geometry paradigm to ensure consistent tracking and high-quality
mapping. We introduce a dense tri-view matching module that aggregates reliable
pairwise correspondences into consistent tri-view matches, forming robust
geometric constraints across frames. For tracking, we propose Hybrid Geometric
Constraints, which leverage tri-view matches to construct complementary
geometric cues alongside photometric loss, ensuring accurate and stable pose
estimation even under drastic viewpoint shifts and lighting variations. For
mapping, we propose a new probabilistic initialization strategy that encodes
geometric uncertainty from tri-view correspondences into newly initialized
Gaussians. Additionally, we design a Dynamic Attenuation of Rendering Trust
mechanism to mitigate tracking drift caused by mapping latency. Experiments on
multiple public outdoor datasets show that our TVG-SLAM outperforms prior
RGB-only 3DGS-based SLAM systems. Notably, in the most challenging dataset, our
method improves tracking robustness, reducing the average Absolute Trajectory
Error (ATE) by 69.0\% while achieving state-of-the-art rendering quality. The
implementation of our method will be released as open-source.

</details>


### [231] [Aggregating Local Saliency Maps for Semi-Global Explainable Image Classification](https://arxiv.org/abs/2506.23247)
*James Hinns,David Martens*

Main category: cs.CV

TL;DR: 论文提出Segment Attribution Tables (SATs)，通过汇总局部显著性解释提供半全局见解，弥补全局方法过于简化和局部方法过于详细之间的差距。


<details>
  <summary>Details</summary>
Motivation: 深度学习在图像分类中表现优异，但模型预测的解释仍具挑战性。现有方法要么过于局部（如显著性图），要么过于全局而忽略重要细节。

Method: SATs利用图像片段（如“眼睛”）和显著性图量化其影响力，揭示模型依赖的概念和虚假相关性。

Result: SATs能够解释任何可生成显著性图的分类器，提供实用工具用于分析和调试图像分类器。

Conclusion: SATs填补了全局和局部解释之间的空白，为模型分析和调试提供了实用方法。

Abstract: Deep learning dominates image classification tasks, yet understanding how
models arrive at predictions remains a challenge. Much research focuses on
local explanations of individual predictions, such as saliency maps, which
visualise the influence of specific pixels on a model's prediction. However,
reviewing many of these explanations to identify recurring patterns is
infeasible, while global methods often oversimplify and miss important local
behaviours. To address this, we propose Segment Attribution Tables (SATs), a
method for summarising local saliency explanations into (semi-)global insights.
SATs take image segments (such as "eyes" in Chihuahuas) and leverage saliency
maps to quantify their influence. These segments highlight concepts the model
relies on across instances and reveal spurious correlations, such as reliance
on backgrounds or watermarks, even when out-of-distribution test performance
sees little change. SATs can explain any classifier for which a form of
saliency map can be produced, using segmentation maps that provide named
segments. SATs bridge the gap between oversimplified global summaries and
overly detailed local explanations, offering a practical tool for analysing and
debugging image classifiers.

</details>


### [232] [A Hierarchical Slice Attention Network for Appendicitis Classification in 3D CT Scans](https://arxiv.org/abs/2506.23209)
*Chia-Wen Huang,Haw Hwai,Chien-Chang Lee,Pei-Yuan Wu*

Main category: cs.CV

TL;DR: 提出一种基于3D CT扫描和切片注意力机制的深度学习模型，用于阑尾炎分类，并结合预训练2D模型进行分层分类，显著提升诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 阑尾炎的及时准确诊断至关重要，但CT影像诊断工作量大，可能导致延误。

Method: 利用3D CT扫描和切片注意力机制增强小病灶检测，结合预训练2D模型进行分层分类。

Result: 阑尾炎AUC提升3%，复杂阑尾炎AUC提升5.9%。

Conclusion: 该方法比现有方法更高效可靠，为临床诊断提供了更好的解决方案。

Abstract: Timely and accurate diagnosis of appendicitis is critical in clinical
settings to prevent serious complications. While CT imaging remains the
standard diagnostic tool, the growing number of cases can overwhelm
radiologists, potentially causing delays. In this paper, we propose a deep
learning model that leverages 3D CT scans for appendicitis classification,
incorporating Slice Attention mechanisms guided by external 2D datasets to
enhance small lesion detection. Additionally, we introduce a hierarchical
classification framework using pre-trained 2D models to differentiate between
simple and complicated appendicitis. Our approach improves AUC by 3% for
appendicitis and 5.9% for complicated appendicitis, offering a more efficient
and reliable diagnostic solution compared to previous work.

</details>


### [233] [PixelBoost: Leveraging Brownian Motion for Realistic-Image Super-Resolution](https://arxiv.org/abs/2506.23254)
*Aradhana Mishra,Bumshik Lee*

Main category: cs.CV

TL;DR: PixelBoost是一种新型扩散模型，通过引入布朗运动的随机性提升图像超分辨率效果，兼顾真实性与计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在减少采样步骤时导致的图像模糊与真实性下降问题。

Method: 整合受控随机性到训练中，避免局部最优，采用Sigmoid噪声序列简化训练。

Result: 在LPIPS、LOE、PSNR、SSIM等指标上表现优越，边缘重建能力更强。

Conclusion: PixelBoost在图像超分辨率中实现了高真实性与高效计算的平衡。

Abstract: Diffusion-model-based image super-resolution techniques often face a
trade-off between realistic image generation and computational efficiency. This
issue is exacerbated when inference times by decreasing sampling steps,
resulting in less realistic and hazy images. To overcome this challenge, we
introduce a novel diffusion model named PixelBoost that underscores the
significance of embracing the stochastic nature of Brownian motion in advancing
image super-resolution, resulting in a high degree of realism, particularly
focusing on texture and edge definitions. By integrating controlled
stochasticity into the training regimen, our proposed model avoids convergence
to local optima, effectively capturing and reproducing the inherent uncertainty
of image textures and patterns. Our proposed model demonstrates superior
objective results in terms of learned perceptual image patch similarity
(LPIPS), lightness order error (LOE), peak signal-to-noise ratio(PSNR),
structural similarity index measure (SSIM), as well as visual quality. To
determine the edge enhancement, we evaluated the gradient magnitude and pixel
value, and our proposed model exhibited a better edge reconstruction
capability. Additionally, our model demonstrates adaptive learning capabilities
by effectively adjusting to Brownian noise patterns and introduces a sigmoidal
noise sequencing method that simplifies training, resulting in faster inference
speeds.

</details>


### [234] [Token Activation Map to Visually Explain Multimodal LLMs](https://arxiv.org/abs/2506.23270)
*Yi Li,Hualiang Wang,Xinpeng Ding,Haonan Wang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出了一种名为Token Activation Map (TAM)的方法，通过因果推理和高斯滤波减少多模态大语言模型(MLLM)解释中的冗余激活干扰，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MLLM的解释性研究不足，冗余激活干扰影响解释可靠性，阻碍模型理解和可视化。

Method: 采用因果推理方法和高斯滤波减少冗余激活，提出TAM方法。

Result: TAM在多种场景（如目标定位、失败案例分析等）中表现优异，可视化效果显著提升。

Conclusion: TAM方法有效解决了MLLM解释中的冗余干扰问题，为模型理解和可视化提供了高质量工具。

Abstract: Multimodal large language models (MLLMs) are broadly empowering various
fields. Despite their advancements, the explainability of MLLMs remains less
explored, hindering deeper understanding, model credibility, and effective
visualization. Unlike conventional vision models (e.g., CNNs, ViTs, CLIP) that
produce a single output, MLLMs generate sequences of tokens progressively,
where each generated token depends on the previous context. Therefore, earlier
context tokens can introduce redundant activations that interfere with the
explanation of later tokens beyond their original information. Existing studies
often overlook this issue, but our observations reveal that these redundant
correlations can significantly hurt the reliability of explanations. To address
this, we propose an estimated causal inference method to mitigate the
interference of context to achieve high-quality MLLM explanation, with a novel
rank Gaussian filter to further reduce activation noises. We term this method
Token Activation Map (TAM) to highlight the consideration of interactions
between tokens. TAM also indicates that it excels at explaining multiple tokens
of MLLM, which is different from the Class Activation Map (CAM) for a single
prediction. Our TAM method significantly outperforms existing SoTA methods,
showcasing high-quality visualization results that can be utilized for various
scenarios, such as object localization, failure case analysis, video
visualization, MLLMs visual comparison, and model understanding (e.g., color,
shape, action, location, visual reasoning, multi-turn conversation, etc). The
code is available atgithub.com/xmed-lab/TAM.

</details>


### [235] [High-quality Pseudo-labeling for Point Cloud Segmentation with Scene-level Annotation](https://arxiv.org/abs/2506.23227)
*Lunhao Duan,Shanshan Zhao,Xingxing Weng,Jing Zhang,Gui-Song Xia*

Main category: cs.CV

TL;DR: 本文提出了一种基于场景级标注的室内点云语义分割方法，通过多模态信息和区域-点语义一致性生成高质量伪标签，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖稀疏点级标签，而场景级标注下生成准确伪标签具有挑战性，影响分割效果。

Method: 提出跨模态特征引导模块和区域-点语义一致性模块，利用2D-3D对应关系和区域投票策略生成高质量伪标签。

Result: 在ScanNet v2和S3DIS数据集上显著优于先前方法，消融实验验证了各模块的有效性。

Conclusion: 该方法通过多模态和一致性模块优化伪标签生成，提升了场景级标注下的点云语义分割性能。

Abstract: This paper investigates indoor point cloud semantic segmentation under
scene-level annotation, which is less explored compared to methods relying on
sparse point-level labels. In the absence of precise point-level labels,
current methods first generate point-level pseudo-labels, which are then used
to train segmentation models. However, generating accurate pseudo-labels for
each point solely based on scene-level annotations poses a considerable
challenge, substantially affecting segmentation performance. Consequently, to
enhance accuracy, this paper proposes a high-quality pseudo-label generation
framework by exploring contemporary multi-modal information and region-point
semantic consistency. Specifically, with a cross-modal feature guidance module,
our method utilizes 2D-3D correspondences to align point cloud features with
corresponding 2D image pixels, thereby assisting point cloud feature learning.
To further alleviate the challenge presented by the scene-level annotation, we
introduce a region-point semantic consistency module. It produces regional
semantics through a region-voting strategy derived from point-level semantics,
which are subsequently employed to guide the point-level semantic predictions.
Leveraging the aforementioned modules, our method can rectify inaccurate
point-level semantic predictions during training and obtain high-quality
pseudo-labels. Significant improvements over previous works on ScanNet v2 and
S3DIS datasets under scene-level annotation can demonstrate the effectiveness.
Additionally, comprehensive ablation studies validate the contributions of our
approach's individual components. The code is available at
https://github.com/LHDuan/WSegPC .

</details>


### [236] [Why Settle for One? Text-to-ImageSet Generation and Evaluation](https://arxiv.org/abs/2506.23275)
*Chengyou Jia,Xin Shen,Zhuohang Dang,Zhuohang Dang,Changliang Xia,Weijia Wu,Xinyu Zhang,Hangwei Qian,Ivor W. Tsang,Minnan Luo*

Main category: cs.CV

TL;DR: 论文提出Text-to-ImageSet (T2IS)生成问题，旨在根据用户指令生成满足多种一致性要求的图像集。作者引入T2IS-Bench和T2IS-Eval评估框架，并提出AutoT2IS方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成一致性图像集时局限于特定领域，缺乏通用性。论文旨在解决更广泛的T2IS生成问题。

Method: 提出T2IS-Bench数据集和T2IS-Eval评估框架，并设计AutoT2IS方法，利用预训练Diffusion Transformers的上下文能力。

Result: AutoT2IS在T2IS-Bench上显著优于现有方法，并能支持多种实际应用。

Conclusion: 论文提出的框架和方法在T2IS生成任务中表现出色，具有实际应用价值。

Abstract: Despite remarkable progress in Text-to-Image models, many real-world
applications require generating coherent image sets with diverse consistency
requirements. Existing consistent methods often focus on a specific domain with
specific aspects of consistency, which significantly constrains their
generalizability to broader applications. In this paper, we propose a more
challenging problem, Text-to-ImageSet (T2IS) generation, which aims to generate
sets of images that meet various consistency requirements based on user
instructions. To systematically study this problem, we first introduce
$\textbf{T2IS-Bench}$ with 596 diverse instructions across 26 subcategories,
providing comprehensive coverage for T2IS generation. Building on this, we
propose $\textbf{T2IS-Eval}$, an evaluation framework that transforms user
instructions into multifaceted assessment criteria and employs effective
evaluators to adaptively assess consistency fulfillment between criteria and
generated sets. Subsequently, we propose $\textbf{AutoT2IS}$, a training-free
framework that maximally leverages pretrained Diffusion Transformers'
in-context capabilities to harmonize visual elements to satisfy both
image-level prompt alignment and set-level visual consistency. Extensive
experiments on T2IS-Bench reveal that diverse consistency challenges all
existing methods, while our AutoT2IS significantly outperforms current
generalized and even specialized approaches. Our method also demonstrates the
ability to enable numerous underexplored real-world applications, confirming
its substantial practical value. Visit our project in
https://chengyou-jia.github.io/T2IS-Home.

</details>


### [237] [DGE-YOLO: Dual-Branch Gathering and Attention for Accurate UAV Object Detection](https://arxiv.org/abs/2506.23252)
*Kunwei Lv,Ping Lan*

Main category: cs.CV

TL;DR: DGE-YOLO是一种改进的YOLO框架，用于无人机多模态目标检测，通过双分支架构和EMA机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 无人机目标检测中，小物体检测和多模态输入处理是主要挑战，现有方法在速度和性能上存在不足。

Method: 提出双分支架构处理红外和可见光图像，引入EMA机制增强多尺度特征学习，并改进特征聚合模块。

Result: 在Drone Vehicle数据集上，DGE-YOLO优于现有方法。

Conclusion: DGE-YOLO在多模态无人机目标检测任务中表现出色。

Abstract: The rapid proliferation of unmanned aerial vehicles (UAVs) has highlighted
the importance of robust and efficient object detection in diverse aerial
scenarios. Detecting small objects under complex conditions, however, remains a
significant challenge. Existing approaches often prioritize inference speed,
leading to degraded performance when handling multi-modal inputs. To address
this, we present DGE-YOLO, an enhanced YOLO-based detection framework designed
to effectively fuse multi-modal information. Specifically, we introduce a
dual-branch architecture for modality-specific feature extraction, enabling the
model to process both infrared and visible images. To further enrich semantic
representation, we propose an Efficient Multi-scale Attention (EMA) mechanism
that enhances feature learning across spatial scales. Additionally, we replace
the conventional neck with a Gather-and-Distribute module to mitigate
information loss during feature aggregation. Extensive experiments on the Drone
Vehicle dataset demonstrate that DGE-YOLO achieves superior performance over
state-of-the-art methods, validating its effectiveness in multi-modal UAV
object detection tasks.

</details>


### [238] [PCLVis: Visual Analytics of Process Communication Latency in Large-Scale Simulation](https://arxiv.org/abs/2506.23257)
*Chongke Bi,Xin Gao,Baofeng Fu,Yuheng Zhao,Siming Chen,Ying Zhao,Yunhai Wang*

Main category: cs.CV

TL;DR: PCLVis框架帮助用户分析超级计算机上的进程通信延迟（PCL）事件，通过MPI通信数据而非物理链路层信息，提供空间定位、传播路径分析和优化策略。


<details>
  <summary>Details</summary>
Motivation: 解决大规模模拟中通信延迟的可扩展性问题，现有方法依赖管理员才能获取的物理链路层信息，限制了普通用户的分析能力。

Method: 1. 空间PCL事件定位方法，通过构建进程相关树分类高相关进程；2. 构建基于通信依赖的有向无环图（DAG）分析传播路径；3. 设计滑动窗口算法和CS-Glyph展示通信状态；4. 提出PCL事件归因策略。

Result: 在TH-1A超级计算机上验证了PCLVis的有效性，用户能显著提高模拟效率。

Conclusion: PCLVis为普通用户提供了一种无需物理链路层信息的PCL分析工具，优化了大规模模拟的通信效率。

Abstract: Large-scale simulations on supercomputers have become important tools for
users. However, their scalability remains a problem due to the huge
communication cost among parallel processes. Most of the existing communication
latency analysis methods rely on the physical link layer information, which is
only available to administrators. In this paper, a framework called PCLVis is
proposed to help general users analyze process communication latency (PCL)
events. Instead of the physical link layer information, the PCLVis uses the MPI
process communication data for the analysis. First, a spatial PCL event
locating method is developed. All processes with high correlation are
classified into a single cluster by constructing a process-correlation tree.
Second, the propagation path of PCL events is analyzed by constructing a
communication-dependency-based directed acyclic graph (DAG), which can help
users interactively explore a PCL event from the temporal evolution of a
located PCL event cluster. In this graph, a sliding window algorithm is
designed to generate the PCL events abstraction. Meanwhile, a new glyph called
the communication state glyph (CS-Glyph) is designed for each process to show
its communication states, including its in/out messages and load balance. Each
leaf node can be further unfolded to view additional information. Third, a PCL
event attribution strategy is formulated to help users optimize their
simulations. The effectiveness of the PCLVis framework is demonstrated by
analyzing the PCL events of several simulations running on the TH-1A
supercomputer. By using the proposed framework, users can greatly improve the
efficiency of their simulations.

</details>


### [239] [SIEDD: Shared-Implicit Encoder with Discrete Decoders](https://arxiv.org/abs/2506.23382)
*Vikram Rangarajan,Shishira Maiya,Max Ehrlich,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: SIEDD是一种新型架构，通过共享隐式编码器和离散解码器，显著加速INR编码速度20-30倍，同时保持高质量重建和压缩比。


<details>
  <summary>Details</summary>
Motivation: 现有INR编码方法速度慢且牺牲质量或控制能力，SIEDD旨在解决这一问题。

Method: SIEDD采用共享坐标编码器捕获全局特征，并行训练轻量级离散解码器，结合坐标空间采样加速。

Result: 在HD和4K基准测试中，SIEDD实现20-30倍编码加速，保持高质量重建和压缩比。

Conclusion: SIEDD显著提升神经视频压缩的实用性，为实际部署提供高效路径。

Abstract: Implicit Neural Representations (INRs) offer exceptional fidelity for video
compression by learning per-video optimized functions, but their adoption is
crippled by impractically slow encoding times. Existing attempts to accelerate
INR encoding often sacrifice reconstruction quality or crucial coordinate-level
control essential for adaptive streaming and transcoding. We introduce SIEDD
(Shared-Implicit Encoder with Discrete Decoders), a novel architecture that
fundamentally accelerates INR encoding without these compromises. SIEDD first
rapidly trains a shared, coordinate-based encoder on sparse anchor frames to
efficiently capture global, low-frequency video features. This encoder is then
frozen, enabling massively parallel training of lightweight, discrete decoders
for individual frame groups, further expedited by aggressive coordinate-space
sampling. This synergistic design delivers a remarkable 20-30X encoding
speed-up over state-of-the-art INR codecs on HD and 4K benchmarks, while
maintaining competitive reconstruction quality and compression ratios.
Critically, SIEDD retains full coordinate-based control, enabling continuous
resolution decoding and eliminating costly transcoding. Our approach
significantly advances the practicality of high-fidelity neural video
compression, demonstrating a scalable and efficient path towards real-world
deployment. Our codebase is available at
https://github.com/VikramRangarajan/SIEDD .

</details>


### [240] [Causal-Entity Reflected Egocentric Traffic Accident Video Synthesis](https://arxiv.org/abs/2506.23263)
*Lei-lei Li,Jianwu Fang,Junbin Xiao,Shanmin Pang,Hongkai Yu,Chen Lv,Jianru Xue,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 提出了一种名为Causal-VidSyn的新型扩散模型，用于合成以自我为中心的交通事故视频，通过结合原因描述和驾驶员注视点来识别事故参与者和行为。


<details>
  <summary>Details</summary>
Motivation: 理解交通事故的因果关系对自动驾驶汽车的安全至关重要，而合成具有因果关系的视频可以帮助测试对现实中难以承受的事故的响应能力。

Method: 提出Causal-VidSyn模型，利用原因描述和驾驶员注视点，通过事故原因回答和注视条件选择模块，实现视频扩散中的因果实体定位。

Result: 实验表明，Causal-VidSyn在帧质量和因果敏感性方面优于现有视频扩散模型，适用于事故视频编辑、正常到事故视频扩散和文本到视频生成等任务。

Conclusion: Causal-VidSyn通过结合因果关系和驾驶员注视点，显著提升了合成视频的质量和因果敏感性，为自动驾驶安全测试提供了有效工具。

Abstract: Egocentricly comprehending the causes and effects of car accidents is crucial
for the safety of self-driving cars, and synthesizing causal-entity reflected
accident videos can facilitate the capability test to respond to unaffordable
accidents in reality. However, incorporating causal relations as seen in
real-world videos into synthetic videos remains challenging. This work argues
that precisely identifying the accident participants and capturing their
related behaviors are of critical importance. In this regard, we propose a
novel diffusion model, Causal-VidSyn, for synthesizing egocentric traffic
accident videos. To enable causal entity grounding in video diffusion,
Causal-VidSyn leverages the cause descriptions and driver fixations to identify
the accident participants and behaviors, facilitated by accident reason
answering and gaze-conditioned selection modules. To support Causal-VidSyn, we
further construct Drive-Gaze, the largest driver gaze dataset (with 1.54M
frames of fixations) in driving accident scenarios. Extensive experiments show
that Causal-VidSyn surpasses state-of-the-art video diffusion models in terms
of frame quality and causal sensitivity in various tasks, including accident
video editing, normal-to-accident video diffusion, and text-to-video
generation.

</details>


### [241] [Mettle: Meta-Token Learning for Memory-Efficient Audio-Visual Adaptation](https://arxiv.org/abs/2506.23271)
*Jinxing Zhou,Zhihui Li,Yongqiang Yu,Yanghao Zhou,Ruohao Guo,Guangyao Li,Yuxin Mao,Mingfei Han,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: Mettle是一种高效的内存方法，通过并行蒸馏音频或视觉特征为紧凑的元标记，适应下游视听任务。


<details>
  <summary>Details</summary>
Motivation: 解决大规模预训练Transformer模型在适应下游任务时内存占用高和训练时间长的问题。

Method: 使用轻量级的Layer-Centric Distillation（LCD）模块并行蒸馏特征，并引入Meta-Token Injection（MTI）模块支持细粒度分割任务。

Result: 显著减少内存使用和训练时间，同时保持参数效率和竞争性准确率。

Conclusion: Mettle是一种简单且高效的方法，适用于多种视听任务。

Abstract: We present \textbf{Met}a-\textbf{T}oken \textbf{Le}arning (Mettle), a simple
and memory-efficient method for adapting large-scale pretrained transformer
models to downstream audio-visual tasks. Instead of sequentially modifying the
output feature distribution of the transformer backbone, Mettle utilizes a
lightweight \textit{Layer-Centric Distillation (LCD)} module to distill in
parallel the intact audio or visual features embedded by each transformer layer
into compact meta-tokens. This distillation process considers both pretrained
knowledge preservation and task-specific adaptation. The obtained meta-tokens
can be directly applied to classification tasks, such as audio-visual event
localization and audio-visual video parsing. To further support fine-grained
segmentation tasks, such as audio-visual segmentation, we introduce a
\textit{Meta-Token Injection (MTI)} module, which utilizes the audio and visual
meta-tokens distilled from the top transformer layer to guide feature
adaptation in earlier layers. Extensive experiments on multiple audiovisual
benchmarks demonstrate that our method significantly reduces memory usage and
training time while maintaining parameter efficiency and competitive accuracy.

</details>


### [242] [Time-variant Image Inpainting via Interactive Distribution Transition Estimation](https://arxiv.org/abs/2506.23461)
*Yun Xing,Qing Guo,Xiaoguang Li,Yihao Huang,Xiaofeng Cao,Di Lin,Ivor Tsang,Lei Ma*

Main category: cs.CV

TL;DR: 论文提出了一种名为TAMP的新任务，旨在通过时间差异较大的参考图像修复目标图像，并提出了InDiTE模块和InDiTE-Diff方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决时间差异大的参考图像修复目标图像时，现有方法效果不佳的问题。

Method: 提出了InDiTE模块和InDiTE-Diff方法，结合扩散模型进行修复。

Result: 在TAMP-Street数据集上实验表明，该方法显著优于现有方法。

Conclusion: InDiTE-Diff方法在时间差异大的图像修复任务中表现优异，为相关领域提供了新思路。

Abstract: In this work, we focus on a novel and practical task, i.e., Time-vAriant
iMage inPainting (TAMP). The aim of TAMP is to restore a damaged target image
by leveraging the complementary information from a reference image, where both
images captured the same scene but with a significant time gap in between,
i.e., time-variant images. Different from conventional reference-guided image
inpainting, the reference image under TAMP setup presents significant content
distinction to the target image and potentially also suffers from damages. Such
an application frequently happens in our daily lives to restore a damaged image
by referring to another reference image, where there is no guarantee of the
reference image's source and quality. In particular, our study finds that even
state-of-the-art (SOTA) reference-guided image inpainting methods fail to
achieve plausible results due to the chaotic image complementation. To address
such an ill-posed problem, we propose a novel Interactive Distribution
Transition Estimation (InDiTE) module which interactively complements the
time-variant images with adaptive semantics thus facilitate the restoration of
damaged regions. To further boost the performance, we propose our TAMP
solution, namely Interactive Distribution Transition Estimation-driven
Diffusion (InDiTE-Diff), which integrates InDiTE with SOTA diffusion model and
conducts latent cross-reference during sampling. Moreover, considering the lack
of benchmarks for TAMP task, we newly assembled a dataset, i.e., TAMP-Street,
based on existing image and mask datasets. We conduct experiments on the
TAMP-Street datasets under two different time-variant image inpainting
settings, which show our method consistently outperform SOTA reference-guided
image inpainting methods for solving TAMP.

</details>


### [243] [Autoregressive Denoising Score Matching is a Good Video Anomaly Detector](https://arxiv.org/abs/2506.23282)
*Hanwen Zhang,Congqi Cao,Qinyi Lv,Lingtong Min,Yanning Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于生成模型的视频异常检测方法，通过解决场景、运动和外观三个独特问题，利用噪声条件评分变换和自回归去噪机制，实现了更全面的异常检测。


<details>
  <summary>Details</summary>
Motivation: 传统基于似然的方法无法检测到学习分布附近局部模式中的异常，论文旨在解决这一问题。

Method: 构建噪声条件评分变换器，引入场景依赖和运动感知评分函数，并通过自回归去噪机制增强外观感知。

Result: 在三个流行的VAD基准测试中展示了最先进的性能。

Conclusion: 通过综合考虑场景、运动和外观三个问题，该方法显著提升了异常检测能力。

Abstract: Video anomaly detection (VAD) is an important computer vision problem. Thanks
to the mode coverage capabilities of generative models, the likelihood-based
paradigm is catching growing interest, as it can model normal distribution and
detect out-of-distribution anomalies. However, these likelihood-based methods
are blind to the anomalies located in local modes near the learned
distribution. To handle these ``unseen" anomalies, we dive into three gaps
uniquely existing in VAD regarding scene, motion and appearance. Specifically,
we first build a noise-conditioned score transformer for denoising score
matching. Then, we introduce a scene-dependent and motion-aware score function
by embedding the scene condition of input sequences into our model and
assigning motion weights based on the difference between key frames of input
sequences. Next, to solve the problem of blindness in principle, we integrate
unaffected visual information via a novel autoregressive denoising score
matching mechanism for inference. Through autoregressively injecting
intensifying Gaussian noise into the denoised data and estimating the
corresponding score function, we compare the denoised data with the original
data to get a difference and aggregate it with the score function for an
enhanced appearance perception and accumulate the abnormal context. With all
three gaps considered, we can compute a more comprehensive anomaly indicator.
Experiments on three popular VAD benchmarks demonstrate the state-of-the-art
performance of our method.

</details>


### [244] [Sanitizing Manufacturing Dataset Labels Using Vision-Language Models](https://arxiv.org/abs/2506.23465)
*Nazanin Mahjourian,Vinh Nguyen*

Main category: cs.CV

TL;DR: 论文提出了一种基于视觉-语言的标签清洗与优化框架（VLSR），用于处理多标签制造图像数据集中的噪声标签问题，通过CLIP模型嵌入图像和文本标签到共享语义空间，利用余弦相似度和聚类方法提升标签质量。


<details>
  <summary>Details</summary>
Motivation: 工业应用中机器学习模型的成功依赖于高质量的训练数据集，但大规模数据集（尤其是众包和网络爬取的数据）常存在标签噪声和不一致问题，制造领域尤为突出。

Method: 利用CLIP模型将图像和文本标签嵌入共享语义空间，通过余弦相似度进行标签清洗（识别并修正不相关或错误的标签），并通过密度聚类和迭代合并对语义相似的标签进行分组。

Result: 在Factorynet数据集上的实验表明，VLSR能有效识别问题标签并提升标签一致性，显著减少标签词汇量，从而提升数据集质量。

Conclusion: VLSR框架能以最小人工干预提升制造图像数据集的标签质量，为工业应用中的机器学习模型训练提供更可靠的数据基础。

Abstract: The success of machine learning models in industrial applications is heavily
dependent on the quality of the datasets used to train the models. However,
large-scale datasets, specially those constructed from crowd-sourcing and
web-scraping, often suffer from label noise, inconsistencies, and errors. This
problem is particularly pronounced in manufacturing domains, where obtaining
high-quality labels is costly and time-consuming. This paper introduces
Vision-Language Sanitization and Refinement (VLSR), which is a
vision-language-based framework for label sanitization and refinement in
multi-label manufacturing image datasets. This method embeds both images and
their associated textual labels into a shared semantic space leveraging the
CLIP vision-language model. Then two key tasks are addressed in this process by
computing the cosine similarity between embeddings. First, label sanitization
is performed to identify irrelevant, misspelled, or semantically weak labels,
and surface the most semantically aligned label for each image by comparing
image-label pairs using cosine similarity between image and label embeddings.
Second, the method applies density-based clustering on text embeddings,
followed by iterative cluster merging, to group semantically similar labels
into unified label groups. The Factorynet dataset, which includes noisy labels
from both human annotations and web-scraped sources, is employed to evaluate
the effectiveness of the proposed framework. Experimental results demonstrate
that the VLSR framework successfully identifies problematic labels and improves
label consistency. This method enables a significant reduction in label
vocabulary through clustering, which ultimately enhances the dataset's quality
for training robust machine learning models in industrial applications with
minimal human intervention.

</details>


### [245] [MoMa: Modulating Mamba for Adapting Image Foundation Models to Video Recognition](https://arxiv.org/abs/2506.23283)
*Yuhuan Yang,Chaofan Ma,Zhenjie Mao,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: MoMa是一个高效的适配器框架，通过将Mamba的选择性状态空间建模集成到图像基础模型（IFMs）中，实现了全时空建模，提升了视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理视频时往往将空间和时间信息分开处理，难以捕捉视频动态的复杂性。

Method: 提出SeqMod操作，将时空信息注入预训练的IFMs，并通过Divide-and-Modulate架构实现高效建模。

Result: 在多个视频基准测试中表现优异，计算成本更低。

Conclusion: MoMa框架在视频理解任务中实现了高效且高性能的时空建模。

Abstract: Video understanding is a complex challenge that requires effective modeling
of spatial-temporal dynamics. With the success of image foundation models
(IFMs) in image understanding, recent approaches have explored
parameter-efficient fine-tuning (PEFT) to adapt IFMs for video. However, most
of these methods tend to process spatial and temporal information separately,
which may fail to capture the full intricacy of video dynamics. In this paper,
we propose MoMa, an efficient adapter framework that achieves full
spatial-temporal modeling by integrating Mamba's selective state space modeling
into IFMs. We propose a novel SeqMod operation to inject spatial-temporal
information into pre-trained IFMs, without disrupting their original features.
By incorporating SeqMod into a Divide-and-Modulate architecture, MoMa enhances
video understanding while maintaining computational efficiency. Extensive
experiments on multiple video benchmarks demonstrate the effectiveness of MoMa,
achieving superior performance with reduced computational cost.

</details>


### [246] [Competitive Distillation: A Simple Learning Strategy for Improving Visual Classification](https://arxiv.org/abs/2506.23285)
*Daqian Shi,Xiaolei Diao,Xu Chen,Cédric M. John*

Main category: cs.CV

TL;DR: 提出了一种新颖的竞争蒸馏策略，通过动态选择教师网络和引入竞争优化，提升多网络协作训练的性能。


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法在多网络协作训练中效果有限，主要因为对不同迭代中网络间学习方向影响的理解不足。

Method: 提出竞争蒸馏策略，允许网络中性能较好的成员动态担任教师角色，并引入竞争优化和随机扰动以提升学习效果。

Result: 实验结果表明，竞争蒸馏在多种任务和数据集上表现出色。

Conclusion: 竞争蒸馏通过动态教师选择和竞争机制，显著提升了多网络协作训练的性能。

Abstract: Deep Neural Networks (DNNs) have significantly advanced the field of computer
vision. To improve DNN training process, knowledge distillation methods
demonstrate their effectiveness in accelerating network training by introducing
a fixed learning direction from the teacher network to student networks. In
this context, several distillation-based optimization strategies are proposed,
e.g., deep mutual learning and self-distillation, as an attempt to achieve
generic training performance enhancement through the cooperative training of
multiple networks. However, such strategies achieve limited improvements due to
the poor understanding of the impact of learning directions among networks
across different iterations. In this paper, we propose a novel competitive
distillation strategy that allows each network in a group to potentially act as
a teacher based on its performance, enhancing the overall learning performance.
Competitive distillation organizes a group of networks to perform a shared task
and engage in competition, where competitive optimization is proposed to
improve the parameter updating process. We further introduce stochastic
perturbation in competitive distillation, aiming to motivate networks to induce
mutations to achieve better visual representations and global optimum. The
experimental results show that competitive distillation achieves promising
performance in diverse tasks and datasets.

</details>


### [247] [Qwen-GUI-3B: A Lightweight Vision-Language Model for Cross-Resolution GUI Grounding](https://arxiv.org/abs/2506.23491)
*ZongHan Hsieh,Tzer-Jen Wei*

Main category: cs.CV

TL;DR: Qwen-GUI-3B是一个轻量级视觉语言模型，专为图形用户界面（GUI）任务设计，性能接近更大模型，但可在单GPU上训练。


<details>
  <summary>Details</summary>
Motivation: 解决大规模视觉语言模型计算资源需求高、不适用于消费级硬件的问题。

Method: 结合跨平台多分辨率数据集、两阶段微调策略及数据去冗余技术。

Result: 在ScreenSpot和ScreenSpot-v2基准测试中分别达到84.9%和86.4%的准确率。

Conclusion: Qwen-GUI-3B通过高效数据策略和两阶段微调，实现了高性能且资源友好的GUI任务解决方案。

Abstract: This paper introduces Qwen-GUI-3B, a lightweight Vision-Language Model (VLM)
specifically designed for Graphical User Interface grounding tasks, achieving
performance competitive with significantly larger models. Unlike large-scale
VLMs (>7B parameters) that are computationally intensive and impractical for
consumer-grade hardware, Qwen-GUI-3B delivers strong grounding accuracy while
being fully trainable on a single GPU (RTX 4090). The model incorporates
several key innovations: (i) combine cross-platform, multi-resolution dataset
of 24K examples from diverse sources including mobile, desktop, and web GUI
screenshots to effectively address data scarcity in high-resolution desktop
environments; (ii) a two-stage fine-tuning strategy, where initial
cross-platform training establishes robust GUI understanding, followed by
specialized fine-tuning on high-resolution data to significantly enhance model
adaptability; and (iii) data curation and redundancy reduction strategies,
demonstrating that randomly sampling a smaller subset with reduced redundancy
achieves performance comparable to larger datasets, emphasizing data diversity
over sheer volume. Empirical evaluation on standard GUI grounding
benchmarks-including ScreenSpot, ScreenSpot-v2, and the challenging
ScreenSpot-Pro, highlights Qwen-GUI-3B's exceptional accuracy, achieving 84.9%
on ScreenSpot and 86.4% on ScreenSpot-v2, surpassing prior models under 4B
parameters. Ablation studies validate the critical role of balanced sampling
and two-stage fine-tuning in enhancing robustness, particularly in
high-resolution desktop scenarios. The Qwen-GUI-3B is available at:
https://github.com/Han1018/Qwen-GUI-3B

</details>


### [248] [DDL: A Dataset for Interpretable Deepfake Detection and Localization in Real-World Scenarios](https://arxiv.org/abs/2506.23292)
*Changtao Miao,Yi Zhang,Weize Gao,Man Luo,Weiwei Feng,Zhiya Tan,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种新的大规模深度伪造检测与定位数据集（DDL），包含180万伪造样本和75种深度伪造方法，旨在解决现有数据集在多样性、规模和注释方面的不足，以支持更可靠的深度伪造检测和解释性研究。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术的滥用日益严重，现有检测方法缺乏解释性，且现有数据集在多样性、规模和注释上不足，无法满足复杂现实场景的需求。

Method: 构建了一个包含180万伪造样本和75种深度伪造方法的大规模数据集（DDL），涵盖多样伪造场景、全面深度伪造方法、多种操纵模式和细粒度伪造注释。

Result: DDL数据集为复杂现实场景提供了更具挑战性的基准，并为下一代深度伪造检测、定位和解释性方法提供了关键支持。

Conclusion: DDL数据集通过多样性和规模上的改进，填补了现有数据集的不足，为深度伪造检测和解释性研究提供了重要资源。

Abstract: Recent advances in AIGC have exacerbated the misuse of malicious deepfake
content, making the development of reliable deepfake detection methods an
essential means to address this challenge. Although existing deepfake detection
models demonstrate outstanding performance in detection metrics, most methods
only provide simple binary classification results, lacking interpretability. In
critical domains such as law, interpretability is crucial for enhancing the
credibility and authority of decisions. Recent studies attempt to improve the
interpretability of classification results by providing spatial manipulation
masks or temporal forgery segments. However, the practical effectiveness of
these methods remains suboptimal due to limitations of the forgery data. Most
current deepfake datasets predominantly offer binary labels, only a few
datasets with localization annotations. However, they suffer from restricted
forgery scenarios, limited diversity in deepfake types, and insufficient data
scale, making them inadequate for complex real-world scenarios. To address this
predicament, we construct a novel large-scale deepfake detection and
localization ($\textbf{DDL}$) dataset containing over $\textbf{1.8M}$ forged
samples and encompassing up to $\textbf{75}$ distinct deepfake methods. The DDL
design incorporates four key innovations: (1) $\textbf{Diverse Forgery
Scenarios}$, (2) $\textbf{Comprehensive Deepfake Methods}$, (3) $\textbf{Varied
Manipulation Modes}$, and (4) $\textbf{Fine-grained Forgery Annotations}$.
Through these improvements, our DDL not only provides a more challenging
benchmark for complex real-world forgeries, but also offers crucial support for
building next-generation deepfake detection, localization, and interpretability
methods. The DDL dataset project page is on
https://deepfake-workshop-ijcai2025.github.io/main/index.html.

</details>


### [249] [DiffFit: Disentangled Garment Warping and Texture Refinement for Virtual Try-On](https://arxiv.org/abs/2506.23295)
*Xiang Xu*

Main category: cs.CV

TL;DR: DiffFit是一个两阶段潜在扩散框架，用于高保真虚拟试穿，通过几何感知的服装变形和纹理细化，解决了现有方法在细节保留、对齐精度和效率上的问题。


<details>
  <summary>Details</summary>
Motivation: 虚拟试穿（VTON）在电子商务和数字时尚中有广泛应用，但现有方法在服装细节保留、对齐精度和多样性适应上仍有不足。

Method: DiffFit采用两阶段策略：第一阶段通过几何感知的服装变形对齐目标身体；第二阶段通过跨模态条件扩散模型细化纹理。

Result: DiffFit在大规模VTON基准测试中表现优于现有方法，在定量指标和感知评估中均取得优异结果。

Conclusion: DiffFit通过解耦几何对齐和外观细化，显著提升了虚拟试穿的生成质量和稳定性。

Abstract: Virtual try-on (VTON) aims to synthesize realistic images of a person wearing
a target garment, with broad applications in e-commerce and digital fashion.
While recent advances in latent diffusion models have substantially improved
visual quality, existing approaches still struggle with preserving fine-grained
garment details, achieving precise garment-body alignment, maintaining
inference efficiency, and generalizing to diverse poses and clothing styles. To
address these challenges, we propose DiffFit, a novel two-stage latent
diffusion framework for high-fidelity virtual try-on. DiffFit adopts a
progressive generation strategy: the first stage performs geometry-aware
garment warping, aligning the garment with the target body through fine-grained
deformation and pose adaptation. The second stage refines texture fidelity via
a cross-modal conditional diffusion model that integrates the warped garment,
the original garment appearance, and the target person image for high-quality
rendering. By decoupling geometric alignment and appearance refinement, DiffFit
effectively reduces task complexity and enhances both generation stability and
visual realism. It excels in preserving garment-specific attributes such as
textures, wrinkles, and lighting, while ensuring accurate alignment with the
human body. Extensive experiments on large-scale VTON benchmarks demonstrate
that DiffFit achieves superior performance over existing state-of-the-art
methods in both quantitative metrics and perceptual evaluations.

</details>


### [250] [Endo-4DGX: Robust Endoscopic Scene Reconstruction and Illumination Correction with Gaussian Splatting](https://arxiv.org/abs/2506.23308)
*Yiming Huang,Long Bai,Beilei Cui,Yanheng Li,Tong Chen,Jie Wang,Jinlin Wu,Zhen Lei,Hongbin Liu,Hongliang Ren*

Main category: cs.CV

TL;DR: Endo-4DGX是一种新型重建方法，通过光照自适应高斯溅射技术，解决了内窥镜场景中不均匀光照下的渲染问题。


<details>
  <summary>Details</summary>
Motivation: 在图像引导机器人手术中，软组织的精确重建对自动化至关重要。现有3D高斯溅射技术在极端光照条件下表现不佳。

Method: 结合光照嵌入、区域感知增强模块和空间感知调整模块，实现光照自适应优化。

Result: Endo-4DGX在低光和过曝条件下均表现出色，保持几何精度。

Conclusion: Endo-4DGX在挑战性光照环境中显著优于现有方法，有望推动机器人辅助手术应用。

Abstract: Accurate reconstruction of soft tissue is crucial for advancing automation in
image-guided robotic surgery. The recent 3D Gaussian Splatting (3DGS)
techniques and their variants, 4DGS, achieve high-quality renderings of dynamic
surgical scenes in real-time. However, 3D-GS-based methods still struggle in
scenarios with varying illumination, such as low light and over-exposure.
Training 3D-GS in such extreme light conditions leads to severe optimization
problems and devastating rendering quality. To address these challenges, we
present Endo-4DGX, a novel reconstruction method with illumination-adaptive
Gaussian Splatting designed specifically for endoscopic scenes with uneven
lighting. By incorporating illumination embeddings, our method effectively
models view-dependent brightness variations. We introduce a region-aware
enhancement module to model the sub-area lightness at the Gaussian level and a
spatial-aware adjustment module to learn the view-consistent brightness
adjustment. With the illumination adaptive design, Endo-4DGX achieves superior
rendering performance under both low-light and over-exposure conditions while
maintaining geometric accuracy. Additionally, we employ an exposure control
loss to restore the appearance from adverse exposure to the normal level for
illumination-adaptive optimization. Experimental results demonstrate that
Endo-4DGX significantly outperforms combinations of state-of-the-art
reconstruction and restoration methods in challenging lighting environments,
underscoring its potential to advance robot-assisted surgical applications. Our
code is available at https://github.com/lastbasket/Endo-4DGX.

</details>


### [251] [Uncertainty-aware Diffusion and Reinforcement Learning for Joint Plane Localization and Anomaly Diagnosis in 3D Ultrasound](https://arxiv.org/abs/2506.23538)
*Yuhao Huang,Yueyue Xu,Haoran Dou,Jiaxiao Deng,Xin Yang,Hongyu Zheng,Dong Ni*

Main category: cs.CV

TL;DR: 提出了一种智能系统，用于同时实现平面定位和先天性子宫异常（CUA）诊断，结合去噪扩散模型和强化学习框架，显著提升了3D超声图像分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 先天性子宫异常（CUAs）可能导致不孕、流产和妊娠并发症，传统2D超声难以准确评估，3D超声虽能提供更清晰的子宫形态可视化，但仍需自动化智能系统提高诊断效率和准确性。

Method: 1）开发了基于去噪扩散模型的平面定位方法，结合局部和全局引导；2）引入强化学习框架，通过无监督奖励提取关键切片；3）利用文本驱动的不确定性建模优化分类概率。

Result: 在大规模3D子宫超声数据集上的实验表明，该方法在平面定位和CUA诊断方面表现出色。

Conclusion: 提出的智能系统显著提升了CUA诊断的准确性和效率，为临床提供了可靠的工具。

Abstract: Congenital uterine anomalies (CUAs) can lead to infertility, miscarriage,
preterm birth, and an increased risk of pregnancy complications. Compared to
traditional 2D ultrasound (US), 3D US can reconstruct the coronal plane,
providing a clear visualization of the uterine morphology for assessing CUAs
accurately. In this paper, we propose an intelligent system for simultaneous
automated plane localization and CUA diagnosis. Our highlights are: 1) we
develop a denoising diffusion model with local (plane) and global (volume/text)
guidance, using an adaptive weighting strategy to optimize attention allocation
to different conditions; 2) we introduce a reinforcement learning-based
framework with unsupervised rewards to extract the key slice summary from
redundant sequences, fully integrating information across multiple planes to
reduce learning difficulty; 3) we provide text-driven uncertainty modeling for
coarse prediction, and leverage it to adjust the classification probability for
overall performance improvement. Extensive experiments on a large 3D uterine US
dataset show the efficacy of our method, in terms of plane localization and CUA
diagnosis. Code is available at https://github.com/yuhoo0302/CUA-US.

</details>


### [252] [FastSeg: Efficient Training-Free Open-Vocabulary Segmentation via Hierarchical Attention Refinement Method](https://arxiv.org/abs/2506.23323)
*Quang-Huy Che,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: FastSeg是一种高效的训练无关框架，通过预训练扩散模型（如Stable Diffusion）的（1+1）步反向过程实现开放词汇语义分割，同时引入双提示机制、分层注意力细化方法和测试时翻转方案提升分割质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有对比学习模型在像素级空间精度上的不足，以及扩散模型在迭代次数与分割质量间的平衡问题。

Method: FastSeg采用（1+1）步反向扩散过程，结合双提示机制、分层注意力细化（HARD）和测试时翻转（TTF）提升分割效果。

Result: 在PASCAL VOC、PASCAL Context和COCO Object基准测试中达到43.8%的平均mIoU，表现优异且高效。

Conclusion: FastSeg在分割质量和推理效率之间取得了平衡，为扩展性提供了坚实基础。

Abstract: Open-vocabulary semantic segmentation (OVSS) aims to segment objects from
arbitrary text categories without requiring densely annotated datasets.
Although contrastive learning based models enable zero-shot segmentation, they
often lose fine spatial precision at pixel level, due to global representation
bias. In contrast, diffusion-based models naturally encode fine-grained spatial
features via attention mechanisms that capture both global context and local
details. However, they often face challenges in balancing the number of
iterations with the quality of the segmentation. In this work, we propose
FastSeg, a novel and efficient training-free framework with only (1+1)-step of
reverse process of a pretrained diffusion model (e.g., Stable Diffusion).
Moreover, instead of running multiple times for different classes, FastSeg
performs segmentation for all classes at once. To further enhance the
segmentation quality, FastSeg introduces three key components: (i) a
dual-prompt mechanism for discriminative, class-aware attention extraction,
(ii) a Hierarchical Attention Refinement Method (HARD) that enhances fused
cross-attention using scale-aligned selfattention maps, and (iii) a Test-Time
Flipping (TTF) scheme designed to improve spatial consistency. Extensive
experiments show that FastSeg achieves state-of-the-art training-free
performance, obtaining 43.8% average mIoU across PASCAL VOC, PASCAL Context,
and COCO Object benchmarks while maintaining superior inference efficiency. Our
results demonstrate that FastSeg provides a strong foundation for
extendability, bridging the gap between segmentation quality and inference
efficiency.

</details>


### [253] [PBCAT: Patch-based composite adversarial training against physically realizable attacks on object detection](https://arxiv.org/abs/2506.23581)
*Xiao Li,Yiming Zhu,Yifan Huang,Wei Zhang,Yingzhe He,Jie Shi,Xiaolin Hu*

Main category: cs.CV

TL;DR: 论文提出了一种基于补丁的复合对抗训练方法PBCAT，用于防御多种物理可实现攻击，显著提升了目标检测器的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目标检测在安全敏感应用中至关重要，但易受物理可实现攻击（如对抗补丁和纹理）的威胁。现有对抗训练方法主要针对分类模型，对目标检测器的防御研究不足。

Method: 提出PBCAT方法，结合小区域梯度引导对抗补丁和全局不可察觉扰动，优化模型以防御多种攻击。

Result: 实验表明，PBCAT显著提升了鲁棒性，检测准确率在对抗纹理攻击下比现有方法提高29.7%。

Conclusion: PBCAT是一种有效的统一防御方法，能够应对多种物理可实现攻击，具有实际应用潜力。

Abstract: Object detection plays a crucial role in many security-sensitive
applications. However, several recent studies have shown that object detectors
can be easily fooled by physically realizable attacks, \eg, adversarial patches
and recent adversarial textures, which pose realistic and urgent threats.
Adversarial Training (AT) has been recognized as the most effective defense
against adversarial attacks. While AT has been extensively studied in the
$l_\infty$ attack settings on classification models, AT against physically
realizable attacks on object detectors has received limited exploration. Early
attempts are only performed to defend against adversarial patches, leaving AT
against a wider range of physically realizable attacks under-explored. In this
work, we consider defending against various physically realizable attacks with
a unified AT method. We propose PBCAT, a novel Patch-Based Composite
Adversarial Training strategy. PBCAT optimizes the model by incorporating the
combination of small-area gradient-guided adversarial patches and imperceptible
global adversarial perturbations covering the entire image. With these designs,
PBCAT has the potential to defend against not only adversarial patches but also
unseen physically realizable attacks such as adversarial textures. Extensive
experiments in multiple settings demonstrated that PBCAT significantly improved
robustness against various physically realizable attacks over state-of-the-art
defense methods. Notably, it improved the detection accuracy by 29.7\% over
previous defense methods under one recent adversarial texture attack.

</details>


### [254] [IR3D-Bench: Evaluating Vision-Language Model Scene Understanding as Agentic Inverse Rendering](https://arxiv.org/abs/2506.23329)
*Parker Liu,Chenxin Li,Zhengxin Li,Yipeng Wu,Wuyang Li,Zhiqin Yang,Zhenyuan Zhang,Yunlong Lin,Sirui Han,Brandon Y. Feng*

Main category: cs.CV

TL;DR: IR3D-Bench是一个新的基准测试，挑战视觉语言模型（VLMs）通过主动创建而非被动识别来展示对场景的理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统VLMs在描述性任务上表现优异，但其是否真正理解视觉场景尚不明确。

Method: 基于分析-合成范式，IR3D-Bench要求视觉语言代理（VLAs）使用编程和渲染工具主动重建输入图像的底层3D结构。

Result: 初步实验显示当前VLMs在视觉精度而非基本工具使用上存在局限。

Conclusion: IR3D-Bench为系统研究和开发工具使用的VLAs提供了数据与评估协议，推动通过创建实现真正的场景理解。

Abstract: Vision-language models (VLMs) excel at descriptive tasks, but whether they
truly understand scenes from visual observations remains uncertain. We
introduce IR3D-Bench, a benchmark challenging VLMs to demonstrate understanding
through active creation rather than passive recognition. Grounded in the
analysis-by-synthesis paradigm, IR3D-Bench tasks Vision-Language Agents (VLAs)
with actively using programming and rendering tools to recreate the underlying
3D structure of an input image, achieving agentic inverse rendering through
tool use. This "understanding-by-creating" approach probes the tool-using
generative capacity of VLAs, moving beyond the descriptive or conversational
capacity measured by traditional scene understanding benchmarks. We provide a
comprehensive suite of metrics to evaluate geometric accuracy, spatial
relations, appearance attributes, and overall plausibility. Initial experiments
on agentic inverse rendering powered by various state-of-the-art VLMs highlight
current limitations, particularly in visual precision rather than basic tool
usage. IR3D-Bench, including data and evaluation protocols, is released to
facilitate systematic study and development of tool-using VLAs towards genuine
scene understanding by creating.

</details>


### [255] [CycleVAR: Repurposing Autoregressive Model for Unsupervised One-Step Image Translation](https://arxiv.org/abs/2506.23347)
*Yi Liu,Shengqian Li,Zuzeng Lin,Feng Wang,Si Liu*

Main category: cs.CV

TL;DR: 论文提出CycleVAR，通过Softmax Relaxed Quantization解决传统量化方法梯度中断问题，实现无监督图像翻译的端到端优化。


<details>
  <summary>Details</summary>
Motivation: 现有条件自回归图像生成方法在无监督图像翻译领域潜力未充分挖掘，传统量化方法导致梯度中断，阻碍优化。

Method: 提出Softmax Relaxed Quantization保持梯度传播，并设计CycleVAR，通过多尺度源图像标记作为上下文提示，实现图像条件自回归生成。

Result: 并行单步生成模式在无监督场景下表现更优，CycleVAR超越现有最佳模型如CycleGAN-Turbo。

Conclusion: CycleVAR通过可微分量化和多尺度上下文提示，显著提升无监督图像翻译性能。

Abstract: The current conditional autoregressive image generation methods have shown
promising results, yet their potential remains largely unexplored in the
practical unsupervised image translation domain, which operates without
explicit cross-domain correspondences. A critical limitation stems from the
discrete quantization inherent in traditional Vector Quantization-based
frameworks, which disrupts gradient flow between the Variational Autoencoder
decoder and causal Transformer, impeding end-to-end optimization during
adversarial training in image space. To tackle this issue, we propose using
Softmax Relaxed Quantization, a novel approach that reformulates codebook
selection as a continuous probability mixing process via Softmax, thereby
preserving gradient propagation. Building upon this differentiable foundation,
we introduce CycleVAR, which reformulates image-to-image translation as
image-conditional visual autoregressive generation by injecting multi-scale
source image tokens as contextual prompts, analogous to prefix-based
conditioning in language models. CycleVAR exploits two modes to generate the
target image tokens, including (1) serial multi-step generation, enabling
iterative refinement across scales, and (2) parallel one-step generation
synthesizing all resolution outputs in a single forward pass. Experimental
findings indicate that the parallel one-step generation mode attains superior
translation quality with quicker inference speed than the serial multi-step
mode in unsupervised scenarios. Furthermore, both quantitative and qualitative
results indicate that CycleVAR surpasses previous state-of-the-art unsupervised
image translation models, \textit{e}.\textit{g}., CycleGAN-Turbo.

</details>


### [256] [AI-Generated Lecture Slides for Improving Slide Element Detection and Retrieval](https://arxiv.org/abs/2506.23605)
*Suyash Maniyar,Vishvesh Trivedi,Ajoy Mondal,Anand Mishra,C. V. Jawahar*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型的合成幻灯片生成方法SynLecSlideGen，并通过实验证明其能有效提升少样本迁移学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决幻灯片元素检测和检索任务中标注数据不足的问题，减少人工标注成本。

Method: 使用大语言模型（LLM）生成高质量合成幻灯片SynLecSlideGen，并创建真实标注数据集RealSlide进行评估。

Result: 实验表明，合成数据预训练显著优于仅使用真实数据的少样本迁移学习。

Conclusion: 合成数据能有效弥补标注数据的不足，提升模型性能。

Abstract: Lecture slide element detection and retrieval are key problems in slide
understanding. Training effective models for these tasks often depends on
extensive manual annotation. However, annotating large volumes of lecture
slides for supervised training is labor intensive and requires domain
expertise. To address this, we propose a large language model (LLM)-guided
synthetic lecture slide generation pipeline, SynLecSlideGen, which produces
high-quality, coherent and realistic slides. We also create an evaluation
benchmark, namely RealSlide by manually annotating 1,050 real lecture slides.
To assess the utility of our synthetic slides, we perform few-shot transfer
learning on real data using models pre-trained on them. Experimental results
show that few-shot transfer learning with pretraining on synthetic slides
significantly improves performance compared to training only on real data. This
demonstrates that synthetic data can effectively compensate for limited labeled
lecture slides. The code and resources of our work are publicly available on
our project website: https://synslidegen.github.io/.

</details>


### [257] [GeoProg3D: Compositional Visual Reasoning for City-Scale 3D Language Fields](https://arxiv.org/abs/2506.23352)
*Shunsuke Yasuki,Taiki Miyanishi,Nakamasa Inoue,Shuhei Kurita,Koya Sakamoto,Daichi Azuma,Masato Taki,Yutaka Matsuo*

Main category: cs.CV

TL;DR: GeoProg3D是一个视觉编程框架，通过自然语言实现城市规模高保真3D场景的交互，结合地理感知和大语言模型，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D语言方法在小规模环境中表现良好，但缺乏处理大规模复杂城市环境的能力，因此需要一种可扩展且支持组合推理的解决方案。

Method: GeoProg3D包含地理感知的城市规模3D语言场（GCLF）和地理视觉API（GV-APIs），利用大语言模型动态组合工具并操作GCLF。

Result: 在GeoEval3D基准测试中，GeoProg3D在多个任务上显著优于现有方法。

Conclusion: GeoProg3D是首个通过自然语言实现城市规模高保真3D场景组合地理推理的框架。

Abstract: The advancement of 3D language fields has enabled intuitive interactions with
3D scenes via natural language. However, existing approaches are typically
limited to small-scale environments, lacking the scalability and compositional
reasoning capabilities necessary for large, complex urban settings. To overcome
these limitations, we propose GeoProg3D, a visual programming framework that
enables natural language-driven interactions with city-scale high-fidelity 3D
scenes. GeoProg3D consists of two key components: (i) a Geography-aware
City-scale 3D Language Field (GCLF) that leverages a memory-efficient
hierarchical 3D model to handle large-scale data, integrated with geographic
information for efficiently filtering vast urban spaces using directional cues,
distance measurements, elevation data, and landmark references; and (ii)
Geographical Vision APIs (GV-APIs), specialized geographic vision tools such as
area segmentation and object detection. Our framework employs large language
models (LLMs) as reasoning engines to dynamically combine GV-APIs and operate
GCLF, effectively supporting diverse geographic vision tasks. To assess
performance in city-scale reasoning, we introduce GeoEval3D, a comprehensive
benchmark dataset containing 952 query-answer pairs across five challenging
tasks: grounding, spatial reasoning, comparison, counting, and measurement.
Experiments demonstrate that GeoProg3D significantly outperforms existing 3D
language fields and vision-language models across multiple tasks. To our
knowledge, GeoProg3D is the first framework enabling compositional geographic
reasoning in high-fidelity city-scale 3D environments via natural language. The
code is available at https://snskysk.github.io/GeoProg3D/.

</details>


### [258] [Layer Decomposition and Morphological Reconstruction for Task-Oriented Infrared Image Enhancement](https://arxiv.org/abs/2506.23353)
*Siyuan Chai,Xiaodong Guo,Tong Liu*

Main category: cs.CV

TL;DR: 提出了一种任务导向的红外图像增强方法，通过层分解和显著性信息提取，提升复杂天气下自动驾驶的感知能力。


<details>
  <summary>Details</summary>
Motivation: 红外图像在复杂天气条件下（如雾、雨、低光）能提升自动驾驶的感知能力，但其低对比度问题影响高级视觉任务性能，且增强对比度时易放大噪声或丢失重要信息。

Method: 方法包括层分解和显著性信息提取：1）设计红外图像层分解方法，增强细节并保留暗区特征；2）提出基于形态学重建的显著性提取方法，有效增强目标信息而不放大噪声。

Result: 实验表明，该方法在目标检测和语义分割任务中优于现有技术。

Conclusion: 该方法显著提升了红外图像质量，为自动驾驶感知任务提供了更优的输入。

Abstract: Infrared image helps improve the perception capabilities of autonomous
driving in complex weather conditions such as fog, rain, and low light.
However, infrared image often suffers from low contrast, especially in
non-heat-emitting targets like bicycles, which significantly affects the
performance of downstream high-level vision tasks. Furthermore, achieving
contrast enhancement without amplifying noise and losing important information
remains a challenge. To address these challenges, we propose a task-oriented
infrared image enhancement method. Our approach consists of two key components:
layer decomposition and saliency information extraction. First, we design an
layer decomposition method for infrared images, which enhances scene details
while preserving dark region features, providing more features for subsequent
saliency information extraction. Then, we propose a morphological
reconstruction-based saliency extraction method that effectively extracts and
enhances target information without amplifying noise. Our method improves the
image quality for object detection and semantic segmentation tasks. Extensive
experiments demonstrate that our approach outperforms state-of-the-art methods.

</details>


### [259] [OmniVCus: Feedforward Subject-driven Video Customization with Multimodal Control Conditions](https://arxiv.org/abs/2506.23361)
*Yuanhao Cai,He Zhang,Xi Chen,Jinbo Xing,Yiwei Hu,Yuqian Zhou,Kai Zhang,Zhifei Zhang,Soo Ye Kim,Tianyu Wang,Yulun Zhang,Xiaokang Yang,Zhe Lin,Alan Yuille*

Main category: cs.CV

TL;DR: 论文提出了一种多主题视频定制方法，通过数据构造管道和混合训练策略，结合扩散Transformer框架，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单主题场景，且缺乏对多主题训练数据和控制信号（如深度、掩码等）的研究。

Method: 提出VideoCus-Factory数据构造管道和IVTM混合训练策略，开发了OmniVCus框架，包含Lottery Embedding和Temporally Aligned Embedding机制。

Result: 实验表明，该方法在定量和定性评估中均显著优于现有技术。

Conclusion: 该方法为多主题视频定制和控制信号编辑提供了有效解决方案。

Abstract: Existing feedforward subject-driven video customization methods mainly study
single-subject scenarios due to the difficulty of constructing multi-subject
training data pairs. Another challenging problem that how to use the signals
such as depth, mask, camera, and text prompts to control and edit the subject
in the customized video is still less explored. In this paper, we first propose
a data construction pipeline, VideoCus-Factory, to produce training data pairs
for multi-subject customization from raw videos without labels and control
signals such as depth-to-video and mask-to-video pairs. Based on our
constructed data, we develop an Image-Video Transfer Mixed (IVTM) training with
image editing data to enable instructive editing for the subject in the
customized video. Then we propose a diffusion Transformer framework, OmniVCus,
with two embedding mechanisms, Lottery Embedding (LE) and Temporally Aligned
Embedding (TAE). LE enables inference with more subjects by using the training
subjects to activate more frame embeddings. TAE encourages the generation
process to extract guidance from temporally aligned control signals by
assigning the same frame embeddings to the control and noise tokens.
Experiments demonstrate that our method significantly surpasses
state-of-the-art methods in both quantitative and qualitative evaluations.
Video demos are at our project page:
https://caiyuanhao1998.github.io/project/OmniVCus/. Our code will be released
at https://github.com/caiyuanhao1998/Open-OmniVCus

</details>


### [260] [Unified Multimodal Understanding via Byte-Pair Visual Encoding](https://arxiv.org/abs/2506.23639)
*Wanpeng Zhang,Yicheng Feng,Hao Luo,Yijiang Li,Zihao Yue,Sipeng Zheng,Zongqing Lu*

Main category: cs.CV

TL;DR: 提出了一种通过字节对编码统一视觉和文本模态的框架，结合优先级编码和多阶段训练，提升了跨模态理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型中不同模态对齐的根本挑战。

Method: 使用字节对编码处理视觉标记，引入优先级编码方案和多阶段训练。

Result: 在多种视觉-语言任务中表现提升。

Conclusion: 通过统一视觉和文本表示，推动了更高效的多模态基础模型发展。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
vision-language understanding, yet effectively aligning different modalities
remains a fundamental challenge. We present a framework that unifies multimodal
understanding by applying byte-pair encoding to visual tokens. Unlike
conventional approaches that rely on modality-specific encoders, our method
directly incorporates structural information into visual tokens, mirroring
successful tokenization strategies in text-only language models. We introduce a
priority-guided encoding scheme that considers both frequency and spatial
consistency, coupled with a multi-stage training procedure based on
curriculum-driven data composition. These enhancements enable the transformer
model to better capture cross-modal relationships and reason with visual
information. Comprehensive experiments demonstrate improved performance across
diverse vision-language tasks. By bridging the gap between visual and textual
representations, our approach contributes to the advancement of more capable
and efficient multimodal foundation models.

</details>


### [261] [VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation](https://arxiv.org/abs/2506.23641)
*Peng Huang,Junhu Fu,Bowen Guo,Zeju Li,Yuanyuan Wang,Yi Guo*

Main category: cs.CV

TL;DR: VAP-Diffusion利用多模态大语言模型（MLLMs）的外部知识，通过视觉属性提示生成更真实多样的医学图像。


<details>
  <summary>Details</summary>
Motivation: 医学图像生成需要丰富的属性信息，但详细描述通常难以获取。

Method: 设计基于Chain-of-Thoughts的提示从MLLMs获取描述，并提出原型条件机制增强生成器的鲁棒性。

Result: 在四种数据集的三种医学图像类型上验证了VAP-Diffusion的有效性。

Conclusion: VAP-Diffusion通过外部知识和原型条件机制提升了医学图像生成的质量和多样性。

Abstract: As the appearance of medical images is influenced by multiple underlying
factors, generative models require rich attribute information beyond labels to
produce realistic and diverse images. For instance, generating an image of skin
lesion with specific patterns demands descriptions that go beyond diagnosis,
such as shape, size, texture, and color. However, such detailed descriptions
are not always accessible. To address this, we explore a framework, termed
Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from
pre-trained Multi-modal Large Language Models (MLLMs) to improve the quality
and diversity of medical image generation. First, to derive descriptions from
MLLMs without hallucination, we design a series of prompts following
Chain-of-Thoughts for common medical imaging tasks, including dermatologic,
colorectal, and chest X-ray images. Generated descriptions are utilized during
training and stored across different categories. During testing, descriptions
are randomly retrieved from the corresponding category for inference. Moreover,
to make the generator robust to unseen combination of descriptions at the test
time, we propose a Prototype Condition Mechanism that restricts test embeddings
to be similar to those from training. Experiments on three common types of
medical imaging across four datasets verify the effectiveness of VAP-Diffusion.

</details>


### [262] [A High-Throughput Platform to Bench Test Smartphone-Based Heart Rate Measurements Derived From Video](https://arxiv.org/abs/2506.23414)
*Ming-Zher Poh,Jonathan Wang,Jonathan Hsu,Lawrence Cai,Eric Teasley,James A. Taylor,Jameson K. Rogers,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

TL;DR: 本文提出了一种新型高通量测试平台，用于评估智能手机心率监测应用的性能，解决了设备兼容性和标准化测试的挑战。


<details>
  <summary>Details</summary>
Motivation: 智能手机心率监测应用因设备多样性和缺乏标准化测试方法而面临性能评估和兼容性问题，手动测试不切实际。

Method: 设计了一个包含12台智能手机并行测试的测试系统，生成可控心率和信号质量的合成PPG测试视频，并通过主机协调视频播放和数据记录。

Result: 系统输入与测量心率之间的平均绝对百分比误差（MAPE）为0.11% +/- 0.001%，PPG信号相关系数为0.92 +/- 0.008，20款智能手机均符合ANSI/CTA心率监测标准。

Conclusion: 该平台为智能手机心率应用的预部署测试提供了可扩展解决方案，提升了应用性能、设备兼容性，并推动了移动健康领域的发展。

Abstract: Smartphone-based heart rate (HR) monitoring apps using finger-over-camera
photoplethysmography (PPG) face significant challenges in performance
evaluation and device compatibility due to device variability and
fragmentation. Manual testing is impractical, and standardized methods are
lacking. This paper presents a novel, high-throughput bench-testing platform to
address this critical need. We designed a system comprising a test rig capable
of holding 12 smartphones for parallel testing, a method for generating
synthetic PPG test videos with controllable HR and signal quality, and a host
machine for coordinating video playback and data logging. The system achieved a
mean absolute percentage error (MAPE) of 0.11% +/- 0.001% between input and
measured HR, and a correlation coefficient of 0.92 +/- 0.008 between input and
measured PPG signals using a clinically-validated smartphone-based HR app.
Bench-testing results of 20 different smartphone models correctly classified
all the devices as meeting the ANSI/CTA accuracy standards for HR monitors
(MAPE <10%) when compared to a prospective clinical study with 80 participants,
demonstrating high positive predictive value. This platform offers a scalable
solution for pre-deployment testing of smartphone HR apps to improve app
performance, ensure device compatibility, and advance the field of mobile
health.

</details>


### [263] [Why Settle for Mid: A Probabilistic Viewpoint to Spatial Relationship Alignment in Text-to-image Models](https://arxiv.org/abs/2506.23418)
*Parham Rezaei,Arash Marioriyad,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 提出了一种基于概率优势（PoS）的新框架，用于改进文本到图像模型的空间关系生成，并引入了PSE评估指标和PSG生成方法。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型在生成复杂空间关系时存在困难，需要更准确的评估和生成方法。

Method: 提出了PoS框架，包括PSE评估指标和PSG生成方法，后者通过梯度引导或搜索策略优化空间关系。

Result: PSE指标与人类判断更一致，PSG显著提升了空间关系生成的准确性。

Conclusion: PoS框架有效解决了文本到图像模型的空间关系生成问题，提供了更可靠的评估和生成方法。

Abstract: Despite the ability of text-to-image models to generate high-quality,
realistic, and diverse images, they face challenges in compositional
generation, often struggling to accurately represent details specified in the
input prompt. A prevalent issue in compositional generation is the misalignment
of spatial relationships, as models often fail to faithfully generate images
that reflect the spatial configurations specified between objects in the input
prompts. To address this challenge, we propose a novel probabilistic framework
for modeling the relative spatial positioning of objects in a scene, leveraging
the concept of Probability of Superiority (PoS). Building on this insight, we
make two key contributions. First, we introduce a novel evaluation metric,
PoS-based Evaluation (PSE), designed to assess the alignment of 2D and 3D
spatial relationships between text and image, with improved adherence to human
judgment. Second, we propose PoS-based Generation (PSG), an inference-time
method that improves the alignment of 2D and 3D spatial relationships in T2I
models without requiring fine-tuning. PSG employs a Part-of-Speech PoS-based
reward function that can be utilized in two distinct ways: (1) as a
gradient-based guidance mechanism applied to the cross-attention maps during
the denoising steps, or (2) as a search-based strategy that evaluates a set of
initial noise vectors to select the best one. Extensive experiments demonstrate
that the PSE metric exhibits stronger alignment with human judgment compared to
traditional center-based metrics, providing a more nuanced and reliable measure
of complex spatial relationship accuracy in text-image alignment. Furthermore,
PSG significantly enhances the ability of text-to-image models to generate
images with specified spatial configurations, outperforming state-of-the-art
methods across multiple evaluation metrics and benchmarks.

</details>


### [264] [When Small Guides Large: Cross-Model Co-Learning for Test-Time Adaptation](https://arxiv.org/abs/2506.23724)
*Chang'an Yi,Xiaohui Deng,Guohao Chen,Yan Zhou,Qinghua Lu,Shuaicheng Niu*

Main category: cs.CV

TL;DR: COCA是一种跨模型协同学习框架，通过互补知识和自我适应提升测试时适应（TTA）性能。


<details>
  <summary>Details</summary>
Motivation: 研究跨模型知识如何影响TTA过程，发现不同模型间存在互补知识。

Method: 提出COCA框架，包含协同适应和自我适应策略，整合多模型知识。

Result: COCA显著提升多种模型在TTA中的性能，如ViT-Base准确率从51.7%提升至64.5%。

Conclusion: COCA作为即插即用模块，有效提升TTA性能，适用于不同规模的模型。

Abstract: Test-time Adaptation (TTA) adapts a given model to testing domain data with
potential domain shifts through online unsupervised learning, yielding
impressive performance. However, to date, existing TTA methods primarily focus
on single-model adaptation. In this work, we investigate an intriguing
question: how does cross-model knowledge influence the TTA process? Our
findings reveal that, in TTA's unsupervised online setting, each model can
provide complementary, confident knowledge to the others, even when there are
substantial differences in model size. For instance, a smaller model like
MobileViT (10.6M parameters) can effectively guide a larger model like ViT-Base
(86.6M parameters). In light of this, we propose COCA, a Cross-Model
Co-Learning framework for TTA, which mainly consists of two main strategies. 1)
Co-adaptation adaptively integrates complementary knowledge from other models
throughout the TTA process, reducing individual model biases. 2)
Self-adaptation enhances each model's unique strengths via unsupervised
learning, enabling diverse adaptation to the target domain. Extensive
experiments show that COCA, which can also serve as a plug-and-play module,
significantly boosts existing SOTAs, on models with various sizes--including
ResNets, ViTs, and Mobile-ViTs--via cross-model co-learned TTA. For example,
with Mobile-ViT's guidance, COCA raises ViT-Base's average adaptation accuracy
on ImageNet-C from 51.7% to 64.5%. The code is publicly available at
https://github.com/ycarobot/COCA.

</details>


### [265] [Detecting What Matters: A Novel Approach for Out-of-Distribution 3D Object Detection in Autonomous Vehicles](https://arxiv.org/abs/2506.23426)
*Menna Taha,Aya Ahmed,Mohammed Karmoose,Yasser Gadallah*

Main category: cs.CV

TL;DR: 论文提出了一种新的目标检测方法，将重点从基于类别的分类转向对象危害性判定，以提升自动驾驶车辆对未知物体的检测能力。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法无法有效识别分布外（OOD）物体，可能导致自动驾驶车辆误判或漏检，引发安全隐患。

Method: 通过对象相对于车辆的位置和轨迹，将其分类为'有害'或'无害'，而非具体类别。

Result: 模型能有效检测OOD物体并评估其危害性，提升自动驾驶决策效果。

Conclusion: 该方法增强了自动驾驶车辆在动态环境中的安全性和适应性。

Abstract: Autonomous vehicles (AVs) use object detection models to recognize their
surroundings and make driving decisions accordingly. Conventional object
detection approaches classify objects into known classes, which limits the AV's
ability to detect and appropriately respond to Out-of-Distribution (OOD)
objects. This problem is a significant safety concern since the AV may fail to
detect objects or misclassify them, which can potentially lead to hazardous
situations such as accidents. Consequently, we propose a novel object detection
approach that shifts the emphasis from conventional class-based classification
to object harmfulness determination. Instead of object detection by their
specific class, our method identifies them as either 'harmful' or 'harmless'
based on whether they pose a danger to the AV. This is done based on the object
position relative to the AV and its trajectory. With this metric, our model can
effectively detect previously unseen objects to enable the AV to make safer
real-time decisions. Our results demonstrate that the proposed model
effectively detects OOD objects, evaluates their harmfulness, and classifies
them accordingly, thus enhancing the AV decision-making effectiveness in
dynamic environments.

</details>


### [266] [Towards foundational LiDAR world models with efficient latent flow matching](https://arxiv.org/abs/2506.23434)
*Tianran Liu,Shengwen Zhao,Nicholas Rhinehart*

Main category: cs.CV

TL;DR: 该论文研究了LiDAR世界模型的跨领域迁移能力，提出了一种新的框架，显著减少了标注数据需求并提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR世界模型局限于特定领域，缺乏跨领域迁移能力，限制了其广泛应用。

Method: 提出了一种基于潜在条件流匹配（CFM）的框架，优化了LiDAR数据的压缩和训练目标。

Result: 模型在跨领域迁移中表现优异，仅需5%标注数据即可超越先前模型，计算效率显著提升。

Conclusion: 该框架为LiDAR世界模型提供了更强的迁移能力和效率，为实际应用奠定了基础。

Abstract: LiDAR-based world models offer more structured and geometry-aware
representations than their image-based counterparts. However, existing LiDAR
world models are narrowly trained; each model excels only in the domain for
which it was built. Can we develop LiDAR world models that exhibit strong
transferability across multiple domains? We conduct the first systematic domain
transfer study across three demanding scenarios: (i) outdoor to indoor
generalization, (ii) sparse-beam \& dense-beam adaptation, and (iii)
non-semantic to semantic transfer. Given different amounts of fine-tuning data,
our experiments show that a single pre-trained model can achieve up to 11%
absolute improvement (83\% relative) over training from scratch and outperforms
training from scratch in 30/36 of our comparisons. This transferability of
dynamic learning significantly reduces the reliance on manually annotated data
for semantic occupancy forecasting: our method exceed the previous semantic
occupancy forecasting models with only 5% of the labeled training data required
by prior models. We also observed inefficiencies of current LiDAR world models,
mainly through their under-compression of LiDAR data and inefficient training
objectives. To address this, we propose a latent conditional flow matching
(CFM)-based frameworks that achieves state-of-the-art reconstruction accuracy
using only half the training data and a compression ratio 6 times higher than
that of prior methods. Our model achieves SOTA performance on
future-trajectory-conditioned semantic occupancy forecasting while being 23x
more computationally efficient (a 28x FPS speedup); and achieves SOTA
performance on semantic occupancy forecasting while being 2x more
computationally efficient (a 1.1x FPS speedup).

</details>


### [267] [PathDiff: Histopathology Image Synthesis with Unpaired Text and Mask Conditions](https://arxiv.org/abs/2506.23440)
*Mahesh Bhosale,Abdul Wasi,Yuanhao Zhai,Yunjie Tian,Samuel Border,Nan Xi,Pinaki Sarder,Junsong Yuan,David Doermann,Xuan Gong*

Main category: cs.CV

TL;DR: PathDiff是一个扩散框架，利用未配对的掩码和文本数据生成高质量的病理学图像，提升语义和空间细节的控制。


<details>
  <summary>Details</summary>
Motivation: 解决因隐私限制导致的数据稀缺问题，同时利用诊断文本和掩码数据增强图像生成的语义和空间控制。

Method: 提出PathDiff框架，将未配对的掩码和文本数据整合到统一的条件空间中，生成高质量图像。

Result: PathDiff在图像保真度、文本-图像对齐和真实性方面表现优异，优于现有方法。

Conclusion: PathDiff有效结合掩码和文本数据，为下游任务（如核分割和分类）提供了高质量的数据增强。

Abstract: Diffusion-based generative models have shown promise in synthesizing
histopathology images to address data scarcity caused by privacy constraints.
Diagnostic text reports provide high-level semantic descriptions, and masks
offer fine-grained spatial structures essential for representing distinct
morphological regions. However, public datasets lack paired text and mask data
for the same histopathological images, limiting their joint use in image
generation. This constraint restricts the ability to fully exploit the benefits
of combining both modalities for enhanced control over semantics and spatial
details. To overcome this, we propose PathDiff, a diffusion framework that
effectively learns from unpaired mask-text data by integrating both modalities
into a unified conditioning space. PathDiff allows precise control over
structural and contextual features, generating high-quality, semantically
accurate images. PathDiff also improves image fidelity, text-image alignment,
and faithfulness, enhancing data augmentation for downstream tasks like nuclei
segmentation and classification. Extensive experiments demonstrate its
superiority over existing methods.

</details>


### [268] [Mamba-FETrack V2: Revisiting State Space Model for Frame-Event based Visual Object Tracking](https://arxiv.org/abs/2506.23783)
*Shiao Wang,Ju Huang,Qingchuan Ma,Jinfeng Gao,Chunyi Xu,Xiao Wang,Lan Chen,Bo Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于线性复杂度Vision Mamba网络的高效RGB-Event目标跟踪框架Mamba-FETrack V2，通过轻量级Prompt Generator和FEMamba主干网络实现跨模态特征提取与融合。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态跟踪算法依赖高复杂度Vision Transformer架构，导致计算开销大且跨模态交互效果有限。

Method: 设计轻量级Prompt Generator生成模态特定提示向量，结合Vision Mamba网络实现特征提取与融合。

Result: 在多个RGB-Event跟踪基准测试中表现出优越性能和效率。

Conclusion: Mamba-FETrack V2框架在性能和效率上均优于现有方法，代码和模型将开源。

Abstract: Combining traditional RGB cameras with bio-inspired event cameras for robust
object tracking has garnered increasing attention in recent years. However,
most existing multimodal tracking algorithms depend heavily on high-complexity
Vision Transformer architectures for feature extraction and fusion across
modalities. This not only leads to substantial computational overhead but also
limits the effectiveness of cross-modal interactions. In this paper, we propose
an efficient RGB-Event object tracking framework based on the linear-complexity
Vision Mamba network, termed Mamba-FETrack V2. Specifically, we first design a
lightweight Prompt Generator that utilizes embedded features from each
modality, together with a shared prompt pool, to dynamically generate
modality-specific learnable prompt vectors. These prompts, along with the
modality-specific embedded features, are then fed into a Vision Mamba-based
FEMamba backbone, which facilitates prompt-guided feature extraction,
cross-modal interaction, and fusion in a unified manner. Finally, the fused
representations are passed to the tracking head for accurate target
localization. Extensive experimental evaluations on multiple RGB-Event tracking
benchmarks, including short-term COESOT dataset and long-term datasets, i.e.,
FE108 and FELT V2, demonstrate the superior performance and efficiency of the
proposed tracking framework. The source code and pre-trained models will be
released on https://github.com/Event-AHU/Mamba_FETrack

</details>


### [269] [Contrastive Learning with Diffusion Features for Weakly Supervised Medical Image Segmentation](https://arxiv.org/abs/2506.23460)
*Dewen Zeng,Xinrong Hu,Yu-Jen Chen,Yawen Wu,Xiaowei Xu,Yiyu Shi*

Main category: cs.CV

TL;DR: 论文提出了一种名为CLDF的新方法，通过对比学习改进扩散模型在弱监督语义分割中的性能，解决了传统CAM方法的部分激活和边界模糊问题。


<details>
  <summary>Details</summary>
Motivation: 传统CAM方法在弱监督语义分割中存在部分激活和边界模糊的问题，而扩散模型生成的显著性图容易受到背景噪声干扰。

Method: 提出CLDF方法，结合对比学习和扩散特征，利用梯度图和CAM识别前景与背景像素，减少误判。

Result: 在两个公共医学数据集的四个分割任务上，CLDF显著优于现有基线方法。

Conclusion: CLDF通过对比学习有效提升了扩散模型在弱监督语义分割中的性能，减少了噪声干扰。

Abstract: Weakly supervised semantic segmentation (WSSS) methods using class labels
often rely on class activation maps (CAMs) to localize objects. However,
traditional CAM-based methods struggle with partial activations and imprecise
object boundaries due to optimization discrepancies between classification and
segmentation. Recently, the conditional diffusion model (CDM) has been used as
an alternative for generating segmentation masks in WSSS, leveraging its strong
image generation capabilities tailored to specific class distributions. By
modifying or perturbing the condition during diffusion sampling, the related
objects can be highlighted in the generated images. Yet, the saliency maps
generated by CDMs are prone to noise from background alterations during reverse
diffusion. To alleviate the problem, we introduce Contrastive Learning with
Diffusion Features (CLDF), a novel method that uses contrastive learning to
train a pixel decoder to map the diffusion features from a frozen CDM to a
low-dimensional embedding space for segmentation. Specifically, we integrate
gradient maps generated from CDM external classifier with CAMs to identify
foreground and background pixels with fewer false positives/negatives for
contrastive learning, enabling robust pixel embedding learning. Experimental
results on four segmentation tasks from two public medical datasets demonstrate
that our method significantly outperforms existing baselines.

</details>


### [270] [GroundingDINO-US-SAM: Text-Prompted Multi-Organ Segmentation in Ultrasound with LoRA-Tuned Vision-Language Models](https://arxiv.org/abs/2506.23903)
*Hamza Rasaee,Taha Koleilat,Hassan Rivaz*

Main category: cs.CV

TL;DR: 提出了一种基于提示驱动的视觉语言模型（VLM），结合Grounding DINO和SAM2，用于多器官超声图像分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决超声图像中因解剖变异性、成像协议多样性和标注数据有限导致的分割难题。

Method: 使用18个公共超声数据集，15个用于Grounding DINO的微调与验证，3个用于测试。采用LoRA技术适应超声领域。

Result: 在多数已见数据集上优于UniverSeg、MedSAM等方法，未见数据集上也表现良好，无需额外微调。

Conclusion: VLM在超声图像分析中具有潜力，减少对大规模器官特定标注数据的依赖。

Abstract: Accurate and generalizable object segmentation in ultrasound imaging remains
a significant challenge due to anatomical variability, diverse imaging
protocols, and limited annotated data. In this study, we propose a
prompt-driven vision-language model (VLM) that integrates Grounding DINO with
SAM2 to enable object segmentation across multiple ultrasound organs. A total
of 18 public ultrasound datasets, encompassing the breast, thyroid, liver,
prostate, kidney, and paraspinal muscle, were utilized. These datasets were
divided into 15 for fine-tuning and validation of Grounding DINO using Low Rank
Adaptation (LoRA) to the ultrasound domain, and 3 were held out entirely for
testing to evaluate performance in unseen distributions. Comprehensive
experiments demonstrate that our approach outperforms state-of-the-art
segmentation methods, including UniverSeg, MedSAM, MedCLIP-SAM, BiomedParse,
and SAMUS on most seen datasets while maintaining strong performance on unseen
datasets without additional fine-tuning. These results underscore the promise
of VLMs in scalable and robust ultrasound image analysis, reducing dependence
on large, organ-specific annotated datasets. We will publish our code on
code.sonography.ai after acceptance.

</details>


### [271] [AdFair-CLIP: Adversarial Fair Contrastive Language-Image Pre-training for Chest X-rays](https://arxiv.org/abs/2506.23467)
*Chenlang Yi,Zizhan Xiong,Qi Qi,Xiyuan Wei,Girish Bathla,Ching-Long Lin,Bobak Jack Mortazavi,Tianbao Yang*

Main category: cs.CV

TL;DR: AdFair-CLIP通过对抗性特征干预减少CLIP模型中的偏见，提升胸部X光分类的公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在医学图像分类中存在公平性问题，如种族和性别偏见，影响诊断结果的可靠性。

Method: 提出AdFair-CLIP框架，利用对抗性特征干预抑制敏感属性，减少虚假相关性。

Result: 在胸部X光数据集上，AdFair-CLIP显著提高了公平性和诊断准确性，并在零样本和少样本场景中表现稳健。

Conclusion: AdFair-CLIP为基于CLIP的医学诊断模型设定了公平性学习的新标准。

Abstract: Contrastive Language-Image Pre-training (CLIP) models have demonstrated
superior performance across various visual tasks including medical image
classification. However, fairness concerns, including demographic biases, have
received limited attention for CLIP models. This oversight leads to critical
issues, particularly those related to race and gender, resulting in disparities
in diagnostic outcomes and reduced reliability for underrepresented groups. To
address these challenges, we introduce AdFair-CLIP, a novel framework employing
adversarial feature intervention to suppress sensitive attributes, thereby
mitigating spurious correlations and improving prediction fairness. We conduct
comprehensive experiments on chest X-ray (CXR) datasets, and show that
AdFair-CLIP significantly enhances both fairness and diagnostic accuracy, while
maintaining robust generalization in zero-shot and few-shot scenarios. These
results establish new benchmarks for fairness-aware learning in CLIP-based
medical diagnostic models, particularly for CXR analysis.

</details>


### [272] [NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments](https://arxiv.org/abs/2506.23468)
*Xuan Yao,Junyu Gao,Changsheng Xu*

Main category: cs.CV

TL;DR: NavMorph是一个自演化的世界模型框架，用于提升视觉与语言导航（VLN-CE）任务中的环境理解和决策能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在泛化到新环境和适应导航过程中的变化方面表现不佳，NavMorph受人类认知启发，旨在解决这些问题。

Method: NavMorph使用紧凑的潜在表示建模环境动态，结合上下文演化记忆（Contextual Evolution Memory）支持自适应规划和策略优化。

Result: 实验表明，NavMorph在VLN-CE基准测试中取得了显著性能提升。

Conclusion: NavMorph通过自演化的世界模型和上下文记忆机制，有效提升了导航任务的适应性和性能。

Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires
agents to execute sequential navigation actions in complex environments guided
by natural language instructions. Current approaches often struggle with
generalizing to novel environments and adapting to ongoing changes during
navigation. Inspired by human cognition, we present NavMorph, a self-evolving
world model framework that enhances environmental understanding and
decision-making in VLN-CE tasks. NavMorph employs compact latent
representations to model environmental dynamics, equipping agents with
foresight for adaptive planning and policy refinement. By integrating a novel
Contextual Evolution Memory, NavMorph leverages scene-contextual information to
support effective navigation while maintaining online adaptability. Extensive
experiments demonstrate that our method achieves notable performance
improvements on popular VLN-CE benchmarks. Code is available at
\href{https://github.com/Feliciaxyao/NavMorph}{this https URL}.

</details>


### [273] [Interactive Interface For Semantic Segmentation Dataset Synthesis](https://arxiv.org/abs/2506.23470)
*Ngoc-Do Tran,Minh-Tuan Huynh,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: SynthLab是一个模块化平台，用于高效生成高质量语义分割数据集，解决资源密集和隐私问题。


<details>
  <summary>Details</summary>
Motivation: AI和计算机视觉的快速发展对高质量标注数据集需求激增，但传统方法资源密集且涉及隐私问题。

Method: SynthLab采用模块化架构和用户友好界面，支持拖拽操作定制数据流程，易于维护和扩展。

Result: 用户研究表明，SynthLab具有高灵活性和易用性，适合不同背景用户使用。

Conclusion: SynthLab为AI应用提供了一种高效、可扩展且用户友好的数据合成解决方案。

Abstract: The rapid advancement of AI and computer vision has significantly increased
the demand for high-quality annotated datasets, particularly for semantic
segmentation. However, creating such datasets is resource-intensive, requiring
substantial time, labor, and financial investment, and often raises privacy
concerns due to the use of real-world data. To mitigate these challenges, we
present SynthLab, consisting of a modular platform for visual data synthesis
and a user-friendly interface. The modular architecture of SynthLab enables
easy maintenance, scalability with centralized updates, and seamless
integration of new features. Each module handles distinct aspects of computer
vision tasks, enhancing flexibility and adaptability. Meanwhile, its
interactive, user-friendly interface allows users to quickly customize their
data pipelines through drag-and-drop actions. Extensive user studies involving
a diverse range of users across different ages, professions, and expertise
levels, have demonstrated flexible usage, and high accessibility of SynthLab,
enabling users without deep technical expertise to harness AI for real-world
applications.

</details>


### [274] [GeoCD: A Differential Local Approximation for Geodesic Chamfer Distance](https://arxiv.org/abs/2506.23478)
*Pedro Alonso,Tianrui Li,Chongshou Li*

Main category: cs.CV

TL;DR: GeoCD是一种基于测地距离的3D点云学习度量，优于传统的Chamfer Distance（CD）。


<details>
  <summary>Details</summary>
Motivation: 传统的CD仅依赖欧氏距离，无法捕捉3D形状的内在几何特征。

Method: 提出GeoCD，一种拓扑感知且完全可微的测地距离近似方法。

Result: 实验表明，GeoCD在多种架构和数据集上显著提升了重建质量。

Conclusion: GeoCD通过单轮微调即可在多指标上取得显著改进。

Abstract: Chamfer Distance (CD) is a widely adopted metric in 3D point cloud learning
due to its simplicity and efficiency. However, it suffers from a fundamental
limitation: it relies solely on Euclidean distances, which often fail to
capture the intrinsic geometry of 3D shapes. To address this limitation, we
propose GeoCD, a topology-aware and fully differentiable approximation of
geodesic distance designed to serve as a metric for 3D point cloud learning.
Our experiments show that GeoCD consistently improves reconstruction quality
over standard CD across various architectures and datasets. We demonstrate this
by fine-tuning several models, initially trained with standard CD, using GeoCD.
Remarkably, fine-tuning for a single epoch with GeoCD yields significant gains
across multiple evaluation metrics.

</details>


### [275] [A Survey on Vision-Language-Action Models for Autonomous Driving](https://arxiv.org/abs/2506.24044)
*Sicong Jiang,Zilin Huang,Kangan Qian,Ziang Luo,Tianze Zhu,Yang Zhong,Yihong Tang,Menglin Kong,Yunlong Wang,Siwen Jiao,Hao Ye,Zihao Sheng,Xin Zhao,Tuopu Wen,Zheng Fu,Sikai Chen,Kun Jiang,Diange Yang,Seongjin Choi,Lijun Sun*

Main category: cs.CV

TL;DR: 该论文首次全面综述了自动驾驶中的视觉-语言-动作（VLA4AD）范式，总结了架构、演变、代表性模型、数据集及挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要整合视觉感知、语言理解和控制的统一策略，但现有研究分散且快速扩展，亟需系统梳理。

Method: 论文通过（i）形式化架构模块，（ii）追溯从早期解释器到推理中心模型的演变，（iii）比较20多个代表性模型，并整合数据集与基准。

Result: 综述提供了VLA4AD的完整参考，包括架构、模型比较、数据集及挑战（如鲁棒性、实时效率）。

Conclusion: VLA4AD为推进可解释且社会对齐的自动驾驶提供了方向，未来需解决鲁棒性、实时性等挑战。

Abstract: The rapid progress of multimodal large language models (MLLM) has paved the
way for Vision-Language-Action (VLA) paradigms, which integrate visual
perception, natural language understanding, and control within a single policy.
Researchers in autonomous driving are actively adapting these methods to the
vehicle domain. Such models promise autonomous vehicles that can interpret
high-level instructions, reason about complex traffic scenes, and make their
own decisions. However, the literature remains fragmented and is rapidly
expanding. This survey offers the first comprehensive overview of VLA for
Autonomous Driving (VLA4AD). We (i) formalize the architectural building blocks
shared across recent work, (ii) trace the evolution from early explainer to
reasoning-centric VLA models, and (iii) compare over 20 representative models
according to VLA's progress in the autonomous driving domain. We also
consolidate existing datasets and benchmarks, highlighting protocols that
jointly measure driving safety, accuracy, and explanation quality. Finally, we
detail open challenges - robustness, real-time efficiency, and formal
verification - and outline future directions of VLA4AD. This survey provides a
concise yet complete reference for advancing interpretable socially aligned
autonomous vehicles. Github repo is available at
\href{https://github.com/JohnsonJiang1996/Awesome-VLA4AD}{SicongJiang/Awesome-VLA4AD}.

</details>


### [276] [Instant GaussianImage: A Generalizable and Self-Adaptive Image Representation via 2D Gaussian Splatting](https://arxiv.org/abs/2506.23479)
*Zhaojie Zeng,Yuesong Wang,Chao Yang,Tao Guan,Lili Ju*

Main category: cs.CV

TL;DR: 提出了一种基于2D高斯泼溅的自适应图像表示框架，显著减少训练时间并动态调整高斯点数量。


<details>
  <summary>Details</summary>
Motivation: 解决Implicit Neural Representation (INR)的高GPU资源需求及GaussianImage训练慢、适应性差的问题。

Method: 使用网络快速生成粗略高斯表示，再通过少量微调步骤，动态调整高斯点数量以适应图像复杂度。

Result: 在DIV2K和Kodak数据集上，训练时间减少一个数量级，渲染性能优于或匹配GaussianImage。

Conclusion: 该方法在高效性和灵活性上优于现有技术，适用于实际应用。

Abstract: Implicit Neural Representation (INR) has demonstrated remarkable advances in
the field of image representation but demands substantial GPU resources.
GaussianImage recently pioneered the use of Gaussian Splatting to mitigate this
cost, however, the slow training process limits its practicality, and the fixed
number of Gaussians per image limits its adaptability to varying information
entropy. To address these issues, we propose in this paper a generalizable and
self-adaptive image representation framework based on 2D Gaussian Splatting.
Our method employs a network to quickly generate a coarse Gaussian
representation, followed by minimal fine-tuning steps, achieving comparable
rendering quality of GaussianImage while significantly reducing training time.
Moreover, our approach dynamically adjusts the number of Gaussian points based
on image complexity to further enhance flexibility and efficiency in practice.
Experiments on DIV2K and Kodak datasets show that our method matches or exceeds
GaussianImage's rendering performance with far fewer iterations and shorter
training times. Specifically, our method reduces the training time by up to one
order of magnitude while achieving superior rendering performance with the same
number of Gaussians.

</details>


### [277] [Evaluation of Geolocation Capabilities of Multimodal Large Language Models and Analysis of Associated Privacy Risks](https://arxiv.org/abs/2506.23481)
*Xian Zhang,Xiang Cheng*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在图像地理定位方面表现出色，但引发隐私和伦理问题。研究分析了现有技术，发现模型在1公里半径内定位准确率达49%，并探讨了应对措施。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs推理能力的提升，其地理定位功能可能侵犯隐私，如通过社交媒体或街景图像推断位置，引发安全威胁。

Method: 研究系统分析了MLLMs的地理定位技术，评估了视觉推理模型在街景图像定位任务中的表现。

Result: 实验显示，先进视觉模型在1公里半径内的定位准确率高达49%，表明其能从视觉数据中提取精细地理线索。

Conclusion: 研究总结了成功定位的关键视觉元素（如文字、建筑风格），并讨论了技术及政策层面的应对措施以降低隐私风险。

Abstract: Objectives: The rapid advancement of Multimodal Large Language Models (MLLMs)
has significantly enhanced their reasoning capabilities, enabling a wide range
of intelligent applications. However, these advancements also raise critical
concerns regarding privacy and ethics. MLLMs are now capable of inferring the
geographic location of images -- such as those shared on social media or
captured from street views -- based solely on visual content, thereby posing
serious risks of privacy invasion, including doxxing, surveillance, and other
security threats.
  Methods: This study provides a comprehensive analysis of existing geolocation
techniques based on MLLMs. It systematically reviews relevant litera-ture and
evaluates the performance of state-of-the-art visual reasoning models on
geolocation tasks, particularly in identifying the origins of street view
imagery.
  Results: Empirical evaluation reveals that the most advanced visual large
models can successfully localize the origin of street-level imagery with up to
$49\%$ accuracy within a 1-kilometer radius. This performance underscores the
models' powerful capacity to extract and utilize fine-grained geographic cues
from visual data.
  Conclusions: Building on these findings, the study identifies key visual
elements that contribute to suc-cessful geolocation, such as text,
architectural styles, and environmental features. Furthermore, it discusses the
potential privacy implications associated with MLLM-enabled geolocation and
discuss several technical and policy-based coun-termeasures to mitigate
associated risks. Our code and dataset are available at
https://github.com/zxyl1003/MLLM-Geolocation-Evaluation.

</details>


### [278] [Imagine for Me: Creative Conceptual Blending of Real Images and Text via Blended Attention](https://arxiv.org/abs/2506.24085)
*Wonwoong Cho,Yanxia Zhang,Yan-Ying Chen,David I. Inouye*

Main category: cs.CV

TL;DR: IT-Blender是一个基于T2I扩散适配器的工具，用于自动化视觉与文本概念的混合，以增强人类创造力。


<details>
  <summary>Details</summary>
Motivation: 人类在跨模态概念混合中存在认知偏差（如设计固定），导致设计空间局部最优。IT-Blender旨在解决这一问题。

Method: 利用预训练扩散模型（SD和FLUX）混合干净参考图像和噪声生成图像的潜在表示，结合新的混合注意力机制。

Result: IT-Blender在视觉与文本概念混合上大幅优于基线方法。

Conclusion: IT-Blender展示了图像生成模型在增强人类创造力方面的新应用潜力。

Abstract: Blending visual and textual concepts into a new visual concept is a unique
and powerful trait of human beings that can fuel creativity. However, in
practice, cross-modal conceptual blending for humans is prone to cognitive
biases, like design fixation, which leads to local minima in the design space.
In this paper, we propose a T2I diffusion adapter "IT-Blender" that can
automate the blending process to enhance human creativity. Prior works related
to cross-modal conceptual blending are limited in encoding a real image without
loss of details or in disentangling the image and text inputs. To address these
gaps, IT-Blender leverages pretrained diffusion models (SD and FLUX) to blend
the latent representations of a clean reference image with those of the noisy
generated image. Combined with our novel blended attention, IT-Blender encodes
the real reference image without loss of details and blends the visual concept
with the object specified by the text in a disentangled way. Our experiment
results show that IT-Blender outperforms the baselines by a large margin in
blending visual and textual concepts, shedding light on the new application of
image generative models to augment human creativity.

</details>


### [279] [MTADiffusion: Mask Text Alignment Diffusion Model for Object Inpainting](https://arxiv.org/abs/2506.23482)
*Jun Huang,Ting Liu,Yihang Wu,Xiaochao Qu,Luoqi Liu,Xiaolin Hu*

Main category: cs.CV

TL;DR: MTADiffusion是一种基于扩散模型的图像修复方法，通过Mask-Text Alignment和MTAPipeline解决语义对齐、结构扭曲和风格不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法存在语义错位、结构扭曲和风格不一致问题，MTADiffusion旨在解决这些问题。

Method: 提出MTAPipeline自动标注掩码和文本描述，构建MTADataset；采用多任务训练策略结合修复和边缘预测；引入风格一致性损失。

Result: 在BrushBench和EditBench上表现优于其他方法。

Conclusion: MTADiffusion通过改进语义对齐、结构稳定性和风格一致性，实现了先进的图像修复性能。

Abstract: Advancements in generative models have enabled image inpainting models to
generate content within specific regions of an image based on provided prompts
and masks. However, existing inpainting methods often suffer from problems such
as semantic misalignment, structural distortion, and style inconsistency. In
this work, we present MTADiffusion, a Mask-Text Alignment diffusion model
designed for object inpainting. To enhance the semantic capabilities of the
inpainting model, we introduce MTAPipeline, an automatic solution for
annotating masks with detailed descriptions. Based on the MTAPipeline, we
construct a new MTADataset comprising 5 million images and 25 million mask-text
pairs. Furthermore, we propose a multi-task training strategy that integrates
both inpainting and edge prediction tasks to improve structural stability. To
promote style consistency, we present a novel inpainting style-consistency loss
using a pre-trained VGG network and the Gram matrix. Comprehensive evaluations
on BrushBench and EditBench demonstrate that MTADiffusion achieves
state-of-the-art performance compared to other methods.

</details>


### [280] [FADRM: Fast and Accurate Data Residual Matching for Dataset Distillation](https://arxiv.org/abs/2506.24125)
*Jiacheng Cui,Xinyue Bi,Yaxin Luo,Xiaohan Zhao,Jiacheng Liu,Zhiqiang Shen*

Main category: cs.CV

TL;DR: 论文提出了数据残差匹配（FADRM）方法，首次在数据层面应用残差连接，显著提升了数据集蒸馏任务的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 探索残差连接在数据中心的挑战性方法中的潜力，解决数据信息消失问题。

Method: 引入数据级跳跃连接，结合像素空间优化和核心局部信息识别，优化计算效率。

Result: 在ImageNet-1K上，单模型和多模型蒸馏分别达到47.7%和50.0%的测试准确率，计算效率提升50%。

Conclusion: FADRM在数据集蒸馏任务中实现了新的最优性能，效率和效果均优于现有方法。

Abstract: Residual connection has been extensively studied and widely applied at the
model architecture level. However, its potential in the more challenging
data-centric approaches remains unexplored. In this work, we introduce the
concept of Data Residual Matching for the first time, leveraging data-level
skip connections to facilitate data generation and mitigate data information
vanishing. This approach maintains a balance between newly acquired knowledge
through pixel space optimization and existing core local information
identification within raw data modalities, specifically for the dataset
distillation task. Furthermore, by incorporating optimization-level
refinements, our method significantly improves computational efficiency,
achieving superior performance while reducing training time and peak GPU memory
usage by 50%. Consequently, the proposed method Fast and Accurate Data Residual
Matching for Dataset Distillation (FADRM) establishes a new state-of-the-art,
demonstrating substantial improvements over existing methods across multiple
dataset benchmarks in both efficiency and effectiveness. For instance, with
ResNet-18 as the student model and a 0.8% compression ratio on ImageNet-1K, the
method achieves 47.7% test accuracy in single-model dataset distillation and
50.0% in multi-model dataset distillation, surpassing RDED by +5.7% and
outperforming state-of-the-art multi-model approaches, EDC and CV-DD, by +1.4%
and +4.0%. Code is available at: https://github.com/Jiacheng8/FADRM.

</details>


### [281] [LLM-enhanced Action-aware Multi-modal Prompt Tuning for Image-Text Matching](https://arxiv.org/abs/2506.23502)
*Mengxiao Tian,Xinxiao Wu,Shuo Yang*

Main category: cs.CV

TL;DR: 论文提出了一种基于LLM增强的动作感知多模态提示调优方法，以提升CLIP模型对细粒度动作的理解能力。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在图像-文本匹配任务中表现出色，但缺乏对细粒度动作的理解能力，限制了其在描述对象状态或关系方面的应用。

Method: 通过设计动作三元组提示和动作状态提示，利用LLM生成的动作相关知识，并结合自适应交互模块聚合视觉特征，建立具有区分性的动作感知视觉表示。

Result: 在两个基准数据集上的实验证明了该方法的有效性。

Conclusion: 该方法成功提升了CLIP模型对动作的理解能力，为细粒度视觉-语言对齐提供了新思路。

Abstract: Driven by large-scale contrastive vision-language pre-trained models such as
CLIP, recent advancements in the image-text matching task have achieved
remarkable success in representation learning. Due to image-level
visual-language alignment, CLIP falls short in understanding fine-grained
details such as object attributes and spatial relationships between objects.
Recent efforts have attempted to compel CLIP to acquire structured visual
representations by introducing prompt learning to achieve object-level
alignment. While achieving promising results, they still lack the capability to
perceive actions, which are crucial for describing the states or relationships
between objects. Therefore, we propose to endow CLIP with fine-grained
action-level understanding by introducing an LLM-enhanced action-aware
multi-modal prompt-tuning method, incorporating the action-related external
knowledge generated by large language models (LLMs). Specifically, we design an
action triplet prompt and an action state prompt to exploit compositional
semantic knowledge and state-related causal knowledge implicitly stored in
LLMs. Subsequently, we propose an adaptive interaction module to aggregate
attentive visual features conditioned on action-aware prompted knowledge for
establishing discriminative and action-aware visual representations, which
further improves the performance. Comprehensive experimental results on two
benchmark datasets demonstrate the effectiveness of our method.

</details>


### [282] [Improve Underwater Object Detection through YOLOv12 Architecture and Physics-informed Augmentation](https://arxiv.org/abs/2506.23505)
*Tinh Nguyen*

Main category: cs.CV

TL;DR: 该研究通过结合物理增强技术和YOLOv12架构，提升了水下目标检测的精度和效率，尤其在低能见度条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测在自主导航、环境监测和海洋探索中至关重要，但受限于光线衰减、浑浊和遮挡等问题，现有方法难以在低能见度条件下实时部署。

Method: 采用YOLOv12架构，结合Residual ELAN块和区域注意力机制，并引入领域特定的增强技术（如湍流自适应模糊、生物遮挡模拟和光谱HSV变换）。

Result: 在四个数据集上取得领先性能，Brackish数据集的mAP达98.30%，FPS为142，遮挡鲁棒性提升18.9%，小目标召回率提升22.4%，检测精度最高提升7.94%。

Conclusion: 该研究为水下机器人应用提供了一种高效且精确的解决方案，并通过消融实验验证了增强策略的关键作用。

Abstract: Underwater object detection is crucial for autonomous navigation,
environmental monitoring, and marine exploration, but it is severely hampered
by light attenuation, turbidity, and occlusion. Current methods balance
accuracy and computational efficiency, but they have trouble deploying in
real-time under low visibility conditions. Through the integration of
physics-informed augmentation techniques with the YOLOv12 architecture, this
study advances underwater detection. With Residual ELAN blocks to preserve
structural features in turbid waters and Area Attention to maintain large
receptive fields for occluded objects while reducing computational complexity.
Underwater optical properties are addressed by domain-specific augmentations
such as turbulence adaptive blurring, biologically grounded occlusion
simulation, and spectral HSV transformations for color distortion. Extensive
tests on four difficult datasets show state-of-the-art performance, with
Brackish data registering 98.30% mAP at 142 FPS. YOLOv12 improves occlusion
robustness by 18.9%, small-object recall by 22.4%, and detection precision by
up to 7.94% compared to previous models. The crucial role of augmentation
strategy is validated by ablation studies. This work offers a precise and
effective solution for conservation and underwater robotics applications.

</details>


### [283] [ViewPoint: Panoramic Video Generation with Pretrained Diffusion Models](https://arxiv.org/abs/2506.23513)
*Zixun Fang,Kai Zhu,Zhiheng Liu,Yu Liu,Wei Zhai,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 提出了一种利用预训练视角视频模型生成全景视频的新框架，通过ViewPoint map和Pano-Perspective注意力机制，解决了全景数据与视角数据之间的模态差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法因全景数据与视角数据之间的模态差距，无法生成高质量全景视频，影响了VR、世界模型和空间智能领域的发展。

Method: 设计了ViewPoint map表示方法，结合Pano-Perspective注意力机制，利用预训练视角模型的先验知识，有效捕捉全景空间相关性。

Result: 实验表明，该方法能生成动态性强、空间一致的全景视频，性能优于现有方法。

Conclusion: 提出的框架成功解决了模态差距问题，为全景视频生成提供了高效解决方案。

Abstract: Panoramic video generation aims to synthesize 360-degree immersive videos,
holding significant importance in the fields of VR, world models, and spatial
intelligence. Existing works fail to synthesize high-quality panoramic videos
due to the inherent modality gap between panoramic data and perspective data,
which constitutes the majority of the training data for modern diffusion
models. In this paper, we propose a novel framework utilizing pretrained
perspective video models for generating panoramic videos. Specifically, we
design a novel panorama representation named ViewPoint map, which possesses
global spatial continuity and fine-grained visual details simultaneously. With
our proposed Pano-Perspective attention mechanism, the model benefits from
pretrained perspective priors and captures the panoramic spatial correlations
of the ViewPoint map effectively. Extensive experiments demonstrate that our
method can synthesize highly dynamic and spatially consistent panoramic videos,
achieving state-of-the-art performance and surpassing previous methods.

</details>


### [284] [WAVE: Warp-Based View Guidance for Consistent Novel View Synthesis Using a Single Image](https://arxiv.org/abs/2506.23518)
*Jiwoo Park,Tae Eun Choi,Youngjun Jun,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 提出了一种无需额外模块的扩散模型方法，通过自适应注意力操纵和噪声重新初始化提升视图一致性。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在多视图合成中空间连续性不足的问题，同时避免复杂多步流程的低效性。

Method: 利用视图引导变形实现自适应注意力操纵和噪声重新初始化，无需训练额外模块。

Result: 通过适用于新视图数据集的综合指标框架，验证了方法在多种扩散模型中的视图一致性提升。

Conclusion: 该方法在保持高效的同时，显著提升了扩散模型的视图一致性，具有广泛适用性。

Abstract: Generating high-quality novel views of a scene from a single image requires
maintaining structural coherence across different views, referred to as view
consistency. While diffusion models have driven advancements in novel view
synthesis, they still struggle to preserve spatial continuity across views.
Diffusion models have been combined with 3D models to address the issue, but
such approaches lack efficiency due to their complex multi-step pipelines. This
paper proposes a novel view-consistent image generation method which utilizes
diffusion models without additional modules. Our key idea is to enhance
diffusion models with a training-free method that enables adaptive attention
manipulation and noise reinitialization by leveraging view-guided warping to
ensure view consistency. Through our comprehensive metric framework suitable
for novel-view datasets, we show that our method improves view consistency
across various diffusion models, demonstrating its broader applicability.

</details>


### [285] [From Sight to Insight: Unleashing Eye-Tracking in Weakly Supervised Video Salient Object Detection](https://arxiv.org/abs/2506.23519)
*Qi Qin,Runmin Cong,Gen Zhan,Yiting Liao,Sam Kwong*

Main category: cs.CV

TL;DR: 论文提出了一种利用眼动追踪信息辅助视频显著物体检测的方法，通过位置和语义嵌入模块以及时空特征建模，在弱监督下提升性能。


<details>
  <summary>Details</summary>
Motivation: 眼动追踪注释更易获取且更符合人眼真实视觉模式，因此论文旨在利用这些信息辅助视频显著物体检测。

Method: 设计了位置和语义嵌入（PSE）模块提供指导，并提出了语义和局部查询（SLQ）竞争器以及内-外混合对比（IIMC）模型进行时空特征建模。

Result: 在五个流行的VSOD基准测试中，模型在多项评估指标上优于其他竞争者。

Conclusion: 通过结合眼动追踪信息和弱监督方法，论文提出的模型显著提升了视频显著物体检测的性能。

Abstract: The eye-tracking video saliency prediction (VSP) task and video salient
object detection (VSOD) task both focus on the most attractive objects in video
and show the result in the form of predictive heatmaps and pixel-level saliency
masks, respectively. In practical applications, eye tracker annotations are
more readily obtainable and align closely with the authentic visual patterns of
human eyes. Therefore, this paper aims to introduce fixation information to
assist the detection of video salient objects under weak supervision. On the
one hand, we ponder how to better explore and utilize the information provided
by fixation, and then propose a Position and Semantic Embedding (PSE) module to
provide location and semantic guidance during the feature learning process. On
the other hand, we achieve spatiotemporal feature modeling under weak
supervision from the aspects of feature selection and feature contrast. A
Semantics and Locality Query (SLQ) Competitor with semantic and locality
constraints is designed to effectively select the most matching and accurate
object query for spatiotemporal modeling. In addition, an Intra-Inter Mixed
Contrastive (IIMC) model improves the spatiotemporal modeling capabilities
under weak supervision by forming an intra-video and inter-video contrastive
learning paradigm. Experimental results on five popular VSOD benchmarks
indicate that our model outperforms other competitors on various evaluation
metrics.

</details>


### [286] [Lightweight Temporal Transformer Decomposition for Federated Autonomous Driving](https://arxiv.org/abs/2506.23523)
*Tuong Do,Binh X. Nguyen,Quang D. Tran,Erman Tjiputra,Te-Chuan Chiu,Anh Nguyen*

Main category: cs.CV

TL;DR: 提出了一种轻量级时序变换器分解方法，通过分解大注意力图为小矩阵，降低模型复杂度，提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于视觉的自动驾驶系统在复杂环境中导航时，仅依赖单帧图像输入效果不佳，而现有高性能方法又因资源密集难以实用。

Method: 采用轻量级时序变换器分解，处理序列图像帧和时序转向数据，分解大注意力图为小矩阵以降低复杂度。

Result: 在三个数据集上表现优于现有方法，且实现实时性能，真实机器人实验进一步验证其有效性。

Conclusion: 该方法通过轻量级设计，显著提升了自动驾驶系统的鲁棒性和适应性，同时适合联邦学习。

Abstract: Traditional vision-based autonomous driving systems often face difficulties
in navigating complex environments when relying solely on single-image inputs.
To overcome this limitation, incorporating temporal data such as past image
frames or steering sequences, has proven effective in enhancing robustness and
adaptability in challenging scenarios. While previous high-performance methods
exist, they often rely on resource-intensive fusion networks, making them
impractical for training and unsuitable for federated learning. To address
these challenges, we propose lightweight temporal transformer decomposition, a
method that processes sequential image frames and temporal steering data by
breaking down large attention maps into smaller matrices. This approach reduces
model complexity, enabling efficient weight updates for convergence and
real-time predictions while leveraging temporal information to enhance
autonomous driving performance. Intensive experiments on three datasets
demonstrate that our method outperforms recent approaches by a clear margin
while achieving real-time performance. Additionally, real robot experiments
further confirm the effectiveness of our method.

</details>


### [287] [When Test-Time Adaptation Meets Self-Supervised Models](https://arxiv.org/abs/2506.23529)
*Jisu Han,Jihee Park,Dongyoon Han,Wonjun Hwang*

Main category: cs.CV

TL;DR: 论文提出了一种自监督测试时适应（TTA）协议，通过协作学习框架结合对比学习和知识蒸馏，提升自监督模型在目标域的表现，无需依赖源域预训练。


<details>
  <summary>Details</summary>
Motivation: 现有TTA方法在自监督模型上表现不佳，尤其是在源域准确率低时。研究目标是探索如何在不依赖源预训练的情况下，通过自监督TTA持续改进模型。

Method: 提出协作学习框架，结合对比学习和知识蒸馏，逐步优化自监督模型的表示能力。

Result: 在多种自监督模型（如DINO、MoCo、iBOT）上验证了方法的有效性，即使没有源预训练也能取得竞争性表现。

Conclusion: 自监督TTA协议和协作学习框架为动态环境中的模型适应提供了新思路，展示了自监督模型在TTA中的潜力。

Abstract: Training on test-time data enables deep learning models to adapt to dynamic
environmental changes, enhancing their practical applicability. Online
adaptation from source to target domains is promising but it remains highly
reliant on the performance of source pretrained model. In this paper, we
investigate whether test-time adaptation (TTA) methods can continuously improve
models trained via self-supervised learning (SSL) without relying on source
pretraining. We introduce a self-supervised TTA protocol after observing that
existing TTA approaches struggle when directly applied to self-supervised
models with low accuracy on the source domain. Furthermore, we propose a
collaborative learning framework that integrates SSL and TTA models, leveraging
contrastive learning and knowledge distillation for stepwise representation
refinement. We validate our method on diverse self-supervised models, including
DINO, MoCo, and iBOT, across TTA benchmarks. Extensive experiments validate the
effectiveness of our approach in SSL, showing that it achieves competitive
performance even without source pretraining.

</details>


### [288] [GViT: Representing Images as Gaussians for Visual Recognition](https://arxiv.org/abs/2506.23532)
*Jefferson Hernandez,Ruozhen He,Guha Balakrishnan,Alexander C. Berg,Vicente Ordonez*

Main category: cs.CV

TL;DR: GVIT是一种分类框架，用可学习的2D高斯集合替代传统像素或补丁网格输入，结合ViT分类器，性能接近传统ViT。


<details>
  <summary>Details</summary>
Motivation: 传统ViT基于像素或补丁网格输入，GVIT旨在探索更紧凑的高斯表示，同时保持分类性能。

Method: 图像编码为几百个高斯参数，位置、尺度、方向等与ViT分类器联合优化，利用梯度引导高斯聚焦于类别显著区域。

Result: GVIT在Imagenet-1k上达到76.9% top-1准确率，性能接近传统ViT。

Conclusion: GVIT展示了高斯表示在分类任务中的潜力，性能与传统方法相当。

Abstract: We introduce GVIT, a classification framework that abandons conventional
pixel or patch grid input representations in favor of a compact set of
learnable 2D Gaussians. Each image is encoded as a few hundred Gaussians whose
positions, scales, orientations, colors, and opacities are optimized jointly
with a ViT classifier trained on top of these representations. We reuse the
classifier gradients as constructive guidance, steering the Gaussians toward
class-salient regions while a differentiable renderer optimizes an image
reconstruction loss. We demonstrate that by 2D Gaussian input representations
coupled with our GVIT guidance, using a relatively standard ViT architecture,
closely matches the performance of a traditional patch-based ViT, reaching a
76.9% top-1 accuracy on Imagenet-1k using a ViT-B architecture.

</details>


### [289] [Consistent Time-of-Flight Depth Denoising via Graph-Informed Geometric Attention](https://arxiv.org/abs/2506.23542)
*Weida Wang,Changyong He,Jin Zeng,Di Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于运动不变图融合的ToF深度去噪网络，提升时间稳定性和空间清晰度。


<details>
  <summary>Details</summary>
Motivation: ToF传感器捕获的深度图像易受噪声影响，现有方法未充分考虑跨帧深度变化，导致时间不一致和空间模糊。

Method: 利用图结构的时域自相似性进行跨帧几何注意力融合，结合图像平滑先验和ToF噪声分布，构建最大后验问题并展开为迭代滤波器。

Result: 在合成DVToF数据集上达到最优性能，在真实Kinectv2数据集上表现出鲁棒泛化能力。

Conclusion: 该方法通过图融合和几何注意力实现了高性能且可解释的ToF去噪网络。

Abstract: Depth images captured by Time-of-Flight (ToF) sensors are prone to noise,
requiring denoising for reliable downstream applications. Previous works either
focus on single-frame processing, or perform multi-frame processing without
considering depth variations at corresponding pixels across frames, leading to
undesirable temporal inconsistency and spatial ambiguity. In this paper, we
propose a novel ToF depth denoising network leveraging motion-invariant graph
fusion to simultaneously enhance temporal stability and spatial sharpness.
Specifically, despite depth shifts across frames, graph structures exhibit
temporal self-similarity, enabling cross-frame geometric attention for graph
fusion. Then, by incorporating an image smoothness prior on the fused graph and
data fidelity term derived from ToF noise distribution, we formulate a maximum
a posterior problem for ToF denoising. Finally, the solution is unrolled into
iterative filters whose weights are adaptively learned from the graph-informed
geometric attention, producing a high-performance yet interpretable network.
Experimental results demonstrate that the proposed scheme achieves
state-of-the-art performance in terms of accuracy and consistency on synthetic
DVToF dataset and exhibits robust generalization on the real Kinectv2 dataset.
Source code will be released at
\href{https://github.com/davidweidawang/GIGA-ToF}{https://github.com/davidweidawang/GIGA-ToF}.

</details>


### [290] [Pyramidal Patchification Flow for Visual Generation](https://arxiv.org/abs/2506.23543)
*Hui Li,Baoyou Chen,Liwei Zhang,Jiaye Li,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: PPFlow通过动态调整patch大小优化DiTs的计算成本，高噪声时用大patch，低噪声时用小patch，提升了推理速度且保持生成性能。


<details>
  <summary>Details</summary>
Motivation: 传统DiTs使用固定patch大小，无法灵活适应不同噪声水平的计算需求，PPFlow旨在动态调整patch大小以优化计算效率和性能。

Method: 提出PPFlow方法：动态调整patch大小，为每个patch大小学习线性投影，并修改Unpatchify操作，无需重新噪声处理。

Result: 训练结果显示，PPFlow在推理速度上比SiT-B/2快1.6倍（2级）或2.0倍（3级），且生成性能相近；从预训练DiTs微调效果更佳。

Conclusion: PPFlow通过动态patch大小调整，显著提升了DiTs的计算效率，同时保持了生成质量，适用于不同训练场景。

Abstract: Diffusion transformers (DiTs) adopt Patchify, mapping patch representations
to token representations through linear projections, to adjust the number of
tokens input to DiT blocks and thus the computation cost. Instead of a single
patch size for all the timesteps, we introduce a Pyramidal Patchification Flow
(PPFlow) approach: Large patch sizes are used for high noise timesteps and
small patch sizes for low noise timesteps; Linear projections are learned for
each patch size; and Unpatchify is accordingly modified. Unlike Pyramidal Flow,
our approach operates over full latent representations other than pyramid
representations, and adopts the normal denoising process without requiring the
renoising trick. We demonstrate the effectiveness of our approach through two
training manners. Training from scratch achieves a $1.6\times$ ($2.0\times$)
inference speed over SiT-B/2 for 2-level (3-level) pyramid patchification with
slightly lower training FLOPs and similar image generation performance.
Training from pretrained normal DiTs achieves even better performance with
small training time. The code and checkpoint are at
https://github.com/fudan-generative-vision/PPFlow.

</details>


### [291] [Oneta: Multi-Style Image Enhancement Using Eigentransformation Functions](https://arxiv.org/abs/2506.23547)
*Jiwon Kim,Soohyun Hwang,Dong-O Kim,Changsu Han,Min Kyu Park,Chang-Su Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Oneta的多风格图像增强算法，通过两步操作（强度增强和色彩校正）实现高性能，支持多种风格任务。


<details>
  <summary>Details</summary>
Motivation: 解决多风格图像增强任务，通过简单但高效的两步模型实现广泛适用性。

Method: 使用Y-Net和C-Net分别预测eigenTF和CCM参数，通过K个可学习令牌支持多风格。

Result: 实验表明，Oneta能有效处理六种增强任务，覆盖30个数据集。

Conclusion: Oneta是一种高效且通用的多风格图像增强算法。

Abstract: The first algorithm, called Oneta, for a novel task of multi-style image
enhancement is proposed in this work. Oneta uses two point operators
sequentially: intensity enhancement with a transformation function (TF) and
color correction with a color correction matrix (CCM). This two-step
enhancement model, though simple, achieves a high performance upper bound.
Also, we introduce eigentransformation function (eigenTF) to represent TF
compactly. The Oneta network comprises Y-Net and C-Net to predict eigenTF and
CCM parameters, respectively. To support $K$ styles, Oneta employs $K$
learnable tokens. During training, each style token is learned using image
pairs from the corresponding dataset. In testing, Oneta selects one of the $K$
style tokens to enhance an image accordingly. Extensive experiments show that
the single Oneta network can effectively undertake six enhancement tasks --
retouching, image signal processing, low-light image enhancement, dehazing,
underwater image enhancement, and white balancing -- across 30 datasets.

</details>


### [292] [JAM-Flow: Joint Audio-Motion Synthesis with Flow Matching](https://arxiv.org/abs/2506.23552)
*Mingi Kwon,Joonghyuk Shin,Jaeseok Jung,Jaesik Park,Youngjung Uh*

Main category: cs.CV

TL;DR: JAM-Flow是一个统一框架，通过流匹配和多模态扩散变换器（MM-DiT）同时合成面部运动和语音，支持多种输入条件。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将面部运动合成和语音合成视为独立任务，忽略了二者的内在联系。

Method: 采用流匹配和MM-DiT架构，结合Motion-DiT和Audio-DiT模块，通过选择性联合注意力层实现跨模态交互。

Result: JAM-Flow支持多种输入条件（如文本、参考音频和运动），实现同步的说话头部生成和音频驱动动画。

Conclusion: JAM-Flow为多模态生成建模提供了实用解决方案，推动了音频-视觉合成的整体发展。

Abstract: The intrinsic link between facial motion and speech is often overlooked in
generative modeling, where talking head synthesis and text-to-speech (TTS) are
typically addressed as separate tasks. This paper introduces JAM-Flow, a
unified framework to simultaneously synthesize and condition on both facial
motion and speech. Our approach leverages flow matching and a novel Multi-Modal
Diffusion Transformer (MM-DiT) architecture, integrating specialized Motion-DiT
and Audio-DiT modules. These are coupled via selective joint attention layers
and incorporate key architectural choices, such as temporally aligned
positional embeddings and localized joint attention masking, to enable
effective cross-modal interaction while preserving modality-specific strengths.
Trained with an inpainting-style objective, JAM-Flow supports a wide array of
conditioning inputs-including text, reference audio, and reference
motion-facilitating tasks such as synchronized talking head generation from
text, audio-driven animation, and much more, within a single, coherent model.
JAM-Flow significantly advances multi-modal generative modeling by providing a
practical solution for holistic audio-visual synthesis. project page:
https://joonghyuk.com/jamflow-web

</details>


### [293] [LH2Face: Loss function for Hard High-quality Face](https://arxiv.org/abs/2506.23555)
*Fan Xie,Pan Cao*

Main category: cs.CV

TL;DR: 论文提出了一种名为LH2Face的新型损失函数，通过结合vMF分布和自适应边缘策略，优化了高质量困难样本的人脸识别性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于余弦相似度和softmax分类的人脸识别方法在处理困难样本时表现不佳，且未考虑人脸质量或识别难度。

Method: 提出基于vMF分布的相似性度量，结合自适应边缘的多分类方法，并使用代理损失函数优化表示空间分布。

Result: 在IJB-B数据集上达到49.39%的准确率，优于第二名方法2.37%。

Conclusion: LH2Face通过自适应策略和表示空间优化，显著提升了高质量困难样本的识别性能。

Abstract: In current practical face authentication systems, most face recognition (FR)
algorithms are based on cosine similarity with softmax classification. Despite
its reliable classification performance, this method struggles with hard
samples. A popular strategy to improve FR performance is incorporating angular
or cosine margins. However, it does not take face quality or recognition
hardness into account, simply increasing the margin value and thus causing an
overly uniform training strategy. To address this problem, a novel loss
function is proposed, named Loss function for Hard High-quality Face (LH2Face).
Firstly, a similarity measure based on the von Mises-Fisher (vMF) distribution
is stated, specifically focusing on the logarithm of the Probability Density
Function (PDF), which represents the distance between a probability
distribution and a vector. Then, an adaptive margin-based multi-classification
method using softmax, called the Uncertainty-Aware Margin Function, is
implemented in the article. Furthermore, proxy-based loss functions are used to
apply extra constraints between the proxy and sample to optimize their
representation space distribution. Finally, a renderer is constructed that
optimizes FR through face reconstruction and vice versa. Our LH2Face is
superior to similiar schemes on hard high-quality face datasets, achieving
49.39% accuracy on the IJB-B dataset, which surpasses the second-place method
by 2.37%.

</details>


### [294] [OcRFDet: Object-Centric Radiance Fields for Multi-View 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2506.23565)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于物体中心辐射场（OcRF）的多视角3D物体检测方法，通过专注于前景物体建模并忽略背景噪声，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过深度估计或3D位置编码隐式地将2D特征转换为3D空间，限制了检测性能。受辐射场在3D重建中的成功启发，作者尝试将其用于增强3D几何估计能力。

Method: 提出物体中心辐射场（OcRF），通过渲染前景物体的辅助任务增强3D体素特征，并利用渲染副产品不透明度通过高度感知不透明度注意力（HOA）增强2D BEV特征。

Result: 在nuScenes测试集上达到57.2% mAP和64.8% NDS，优于现有方法。

Conclusion: OcRFDet通过专注于前景物体建模和背景噪声抑制，显著提升了多视角3D物体检测性能。

Abstract: Current multi-view 3D object detection methods typically transfer 2D features
into 3D space using depth estimation or 3D position encoder, but in a fully
data-driven and implicit manner, which limits the detection performance.
Inspired by the success of radiance fields on 3D reconstruction, we assume they
can be used to enhance the detector's ability of 3D geometry estimation.
However, we observe a decline in detection performance, when we directly use
them for 3D rendering as an auxiliary task. From our analysis, we find the
performance drop is caused by the strong responses on the background when
rendering the whole scene. To address this problem, we propose object-centric
radiance fields, focusing on modeling foreground objects while discarding
background noises. Specifically, we employ Object-centric Radiance Fields
(OcRF) to enhance 3D voxel features via an auxiliary task of rendering
foreground objects. We further use opacity - the side-product of rendering- to
enhance the 2D foreground BEV features via Height-aware Opacity-based Attention
(HOA), where attention maps at different height levels are generated separately
via multiple networks in parallel. Extensive experiments on the nuScenes
validation and test datasets demonstrate that our OcRFDet achieves superior
performance, outperforming previous state-of-the-art methods with 57.2$\%$ mAP
and 64.8$\%$ NDS on the nuScenes test benchmark. Code will be available at
https://github.com/Mingqj/OcRFDet.

</details>


### [295] [Metadata, Wavelet, and Time Aware Diffusion Models for Satellite Image Super Resolution](https://arxiv.org/abs/2506.23566)
*Luigi Sigillo,Renato Giamba,Danilo Comminiello*

Main category: cs.CV

TL;DR: MWT-Diff是一个结合潜在扩散模型和小波变换的卫星图像超分辨率框架，通过MWT-Encoder生成嵌入特征，逐步重建高分辨率图像。


<details>
  <summary>Details</summary>
Motivation: 卫星图像的高分辨率获取受限于传感器时空限制和高成本，影响环境监测等应用。

Method: 提出MWT-Diff框架，结合潜在扩散模型和小波变换，利用MWT-Encoder生成嵌入特征指导扩散过程。

Result: 在多个数据集上表现优于现有方法，通过FID和LPIPS等指标验证。

Conclusion: MWT-Diff能有效提升卫星图像分辨率，保留关键空间特征，适用于遥感分析。

Abstract: The acquisition of high-resolution satellite imagery is often constrained by
the spatial and temporal limitations of satellite sensors, as well as the high
costs associated with frequent observations. These challenges hinder
applications such as environmental monitoring, disaster response, and
agricultural management, which require fine-grained and high-resolution data.
In this paper, we propose MWT-Diff, an innovative framework for satellite image
super-resolution (SR) that combines latent diffusion models with wavelet
transforms to address these challenges. At the core of the framework is a novel
metadata-, wavelet-, and time-aware encoder (MWT-Encoder), which generates
embeddings that capture metadata attributes, multi-scale frequency information,
and temporal relationships. The embedded feature representations steer the
hierarchical diffusion dynamics, through which the model progressively
reconstructs high-resolution satellite imagery from low-resolution inputs. This
process preserves critical spatial characteristics including textural patterns,
boundary discontinuities, and high-frequency spectral components essential for
detailed remote sensing analysis. The comparative analysis of MWT-Diff across
multiple datasets demonstrated favorable performance compared to recent
approaches, as measured by standard perceptual quality metrics including FID
and LPIPS.

</details>


### [296] [Event-based Tiny Object Detection: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2506.23575)
*Nuo Chen,Chao Xiao,Yimian Dai,Shiman He,Miao Li,Wei An*

Main category: cs.CV

TL;DR: 论文提出了首个大规模、高多样性的事件相机小目标检测数据集EV-UAV，并提出了一种基于时空相关性的稀疏分割网络EV-SpSegNet，用于解决反无人机任务中的小目标检测问题。


<details>
  <summary>Details</summary>
Motivation: 传统帧相机在复杂背景下检测小目标（如无人机）存在困难，而事件相机的高动态范围和微秒级分辨率为此提供了更优解决方案，但现有事件数据集规模小且目标大，缺乏多样性。

Method: 提出EV-UAV数据集，包含147个序列和230万事件级标注；设计EV-SpSegNet网络和STC损失函数，利用目标运动的时空连续性进行分割。

Result: 在EV-UAV数据集上的实验验证了方法的优越性，为未来研究提供了基准。

Conclusion: EV-UAV数据集和EV-SpSegNet为事件相机小目标检测领域提供了重要工具和基准。

Abstract: Small object detection (SOD) in anti-UAV task is a challenging problem due to
the small size of UAVs and complex backgrounds. Traditional frame-based cameras
struggle to detect small objects in complex environments due to their low frame
rates, limited dynamic range, and data redundancy. Event cameras, with
microsecond temporal resolution and high dynamic range, provide a more
effective solution for SOD. However, existing event-based object detection
datasets are limited in scale, feature large targets size, and lack diverse
backgrounds, making them unsuitable for SOD benchmarks. In this paper, we
introduce a Event-based Small object detection (EVSOD) dataset (namely EV-UAV),
the first large-scale, highly diverse benchmark for anti-UAV tasks. It includes
147 sequences with over 2.3 million event-level annotations, featuring
extremely small targets (averaging 6.8 $\times$ 5.4 pixels) and diverse
scenarios such as urban clutter and extreme lighting conditions. Furthermore,
based on the observation that small moving targets form continuous curves in
spatiotemporal event point clouds, we propose Event based Sparse Segmentation
Network (EV-SpSegNet), a novel baseline for event segmentation in point cloud
space, along with a Spatiotemporal Correlation (STC) loss that leverages motion
continuity to guide the network in retaining target events. Extensive
experiments on the EV-UAV dataset demonstrate the superiority of our method and
provide a benchmark for future research in EVSOD. The dataset and code are at
https://github.com/ChenYichen9527/Ev-UAV.

</details>


### [297] [StackCLIP: Clustering-Driven Stacked Prompt in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2506.23577)
*Yanning Hou,Yanran Ruan,Junfa Li,Shanshan Wang,Jianfeng Qiu,Ke Xu*

Main category: cs.CV

TL;DR: 论文提出StackCLIP模型，通过多类别名称堆叠生成堆叠提示，结合CSP和EFA模块提升零样本工业异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP模型中文本与图像特征对齐的挑战，避免传统方法因特定类别提示导致的过拟合和泛化能力受限问题。

Method: 采用多类别名称堆叠生成堆叠提示，结合CSP模块构建通用提示，EFA模块训练知识特定线性层并自适应集成。

Result: 在七个工业异常检测数据集上实现零样本异常检测和分割任务的最先进性能。

Conclusion: StackCLIP通过堆叠提示和模块化设计显著提升模型训练速度、稳定性和泛化能力。

Abstract: Enhancing the alignment between text and image features in the CLIP model is
a critical challenge in zero-shot industrial anomaly detection tasks. Recent
studies predominantly utilize specific category prompts during pretraining,
which can cause overfitting to the training categories and limit model
generalization. To address this, we propose a method that transforms category
names through multicategory name stacking to create stacked prompts, forming
the basis of our StackCLIP model. Our approach introduces two key components.
The Clustering-Driven Stacked Prompts (CSP) module constructs generic prompts
by stacking semantically analogous categories, while utilizing multi-object
textual feature fusion to amplify discriminative anomalies among similar
objects. The Ensemble Feature Alignment (EFA) module trains knowledge-specific
linear layers tailored for each stack cluster and adaptively integrates them
based on the attributes of test categories. These modules work together to
deliver superior training speed, stability, and convergence, significantly
boosting anomaly segmentation performance. Additionally, our stacked prompt
framework offers robust generalization across classification tasks. To further
improve performance, we introduce the Regulating Prompt Learning (RPL) module,
which leverages the generalization power of stacked prompts to refine prompt
learning, elevating results in anomaly detection classification tasks.
Extensive testing on seven industrial anomaly detection datasets demonstrates
that our method achieves state-of-the-art performance in both zero-shot anomaly
detection and segmentation tasks.

</details>


### [298] [Dataset Distillation via Vision-Language Category Prototype](https://arxiv.org/abs/2506.23580)
*Yawen Zou,Guang Li,Duo Su,Zi Wang,Jun Yu,Chao Zhang*

Main category: cs.CV

TL;DR: 该研究提出了一种结合视觉语言方法的数据集蒸馏技术，通过引入文本原型提升语义信息保留，显著提高了性能与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法主要关注图像信息，忽略了语义内容，导致模型泛化能力不足。本研究旨在通过整合视觉语言方法解决这一问题。

Method: 利用开源大语言模型生成文本原型，与图像原型协同合成数据，增强数据集蒸馏的语义信息保留。

Result: 所提方法生成了逻辑一致的图像，验证性能达到最优，并展现出强大的泛化能力。

Conclusion: 结合视觉语言的数据集蒸馏方法扩展了传统图像方法的潜力，适用于无文本描述的数据集。

Abstract: Dataset distillation (DD) condenses large datasets into compact yet
informative substitutes, preserving performance comparable to the original
dataset while reducing storage, transmission costs, and computational
consumption. However, previous DD methods mainly focus on distilling
information from images, often overlooking the semantic information inherent in
the data. The disregard for context hinders the model's generalization ability,
particularly in tasks involving complex datasets, which may result in illogical
outputs or the omission of critical objects. In this study, we integrate
vision-language methods into DD by introducing text prototypes to distill
language information and collaboratively synthesize data with image prototypes,
thereby enhancing dataset distillation performance. Notably, the text
prototypes utilized in this study are derived from descriptive text information
generated by an open-source large language model. This framework demonstrates
broad applicability across datasets without pre-existing text descriptions,
expanding the potential of dataset distillation beyond traditional image-based
approaches. Compared to other methods, the proposed approach generates
logically coherent images containing target objects, achieving state-of-the-art
validation performance and demonstrating robust generalization. Source code and
generated data are available in
https://github.com/zou-yawen/Dataset-Distillation-via-Vision-Language-Category-Prototype/

</details>


### [299] [CAI: Caption-Sensitive Attention Intervention for Mitigating Object Hallucination in Large Vision-Language Models](https://arxiv.org/abs/2506.23590)
*Qiming Li,Zekai Ye,Xiaocheng Feng,Weihong Zhong,Libo Qin,Ruihan Chen,Baohang Li,Kui Jiang,Yaowei Wang,Ting Liu,Bing Qin*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练、即插即用的方法（CAI），通过利用大视觉语言模型（LVLMs）在回答标题查询时的注意力模式，减少对象幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决LVLMs在视觉信息解释中频繁产生与视觉内容不符的对象幻觉问题，同时避免依赖昂贵的手动标注和训练成本或增加推理时间。

Method: 提出Caption-sensitive Attention Intervention（CAI），利用LVLMs在回答标题查询时的注意力激活模式，增强其视觉感知能力。

Result: 在四个基准测试中，CAI以最小的额外推理成本实现了最先进的对象幻觉缓解性能。

Conclusion: CAI是一种高效且低成本的方法，显著提升了LVLMs的视觉感知能力，减少了对象幻觉。

Abstract: Although Large Vision-Language Models (LVLMs) have demonstrated powerful
capabilities in interpreting visual information, they frequently produce
content that deviates from visual information, leading to object hallucination.
To tackle this, recent works mostly depend on expensive manual annotations and
training cost, or significantly increase inference time. In this work, we
observe that LVLMs' attention to visual information is significantly stronger
when answering caption queries compared to non-caption queries. Inspired by
this phenomenon, we propose Caption-sensitive Attention Intervention (CAI), a
training-free, plug-and-play hallucination mitigation method that leverages the
attention activation pattern in response to caption queries to enhance LVLMs'
visual perception capability. Extensive experimental results across four
benchmarks covering both discriminative and generative tasks, demonstrate that
CAI achieves state-of-the-art (SOTA) hallucination mitigating performance only
with minimal additional inference cost.

</details>


### [300] [SG-LDM: Semantic-Guided LiDAR Generation via Latent-Aligned Diffusion](https://arxiv.org/abs/2506.23606)
*Zhengkang Xiang,Zizhao Li,Amir Khodabandeh,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: SG-LDM是一种基于语义引导的激光雷达扩散模型，通过潜在对齐实现语义到激光雷达的合成，显著提升了生成高保真激光雷达点云的能力，并提出了首个基于扩散的激光雷达翻译框架。


<details>
  <summary>Details</summary>
Motivation: 解决现有激光雷达点云生成方法忽略实际应用潜力的问题，通过语义引导增强生成模型的实用性和多样性。

Method: 提出SG-LDM模型，利用潜在对齐和显式语义条件，直接在激光雷达空间操作，并开发扩散式激光雷达翻译框架。

Result: SG-LDM在生成高保真激光雷达点云方面表现最佳，翻译框架进一步提升了数据增强效果。

Conclusion: SG-LDM及其翻译框架为激光雷达点云合成和下游任务提供了高效解决方案。

Abstract: Lidar point cloud synthesis based on generative models offers a promising
solution to augment deep learning pipelines, particularly when real-world data
is scarce or lacks diversity. By enabling flexible object manipulation, this
synthesis approach can significantly enrich training datasets and enhance
discriminative models. However, existing methods focus on unconditional lidar
point cloud generation, overlooking their potential for real-world
applications. In this paper, we propose SG-LDM, a Semantic-Guided Lidar
Diffusion Model that employs latent alignment to enable robust
semantic-to-lidar synthesis. By directly operating in the native lidar space
and leveraging explicit semantic conditioning, SG-LDM achieves state-of-the-art
performance in generating high-fidelity lidar point clouds guided by semantic
labels. Moreover, we propose the first diffusion-based lidar translation
framework based on SG-LDM, which enables cross-domain translation as a domain
adaptation strategy to enhance downstream perception performance. Systematic
experiments demonstrate that SG-LDM significantly outperforms existing lidar
diffusion models and the proposed lidar translation framework further improves
data augmentation performance in the downstream lidar segmentation task.

</details>


### [301] [PGOV3D: Open-Vocabulary 3D Semantic Segmentation with Partial-to-Global Curriculum](https://arxiv.org/abs/2506.23607)
*Shiqi Zhang,Sha Zhang,Jiajun Deng,Yedong Shen,Mingxiao MA,Yanyong Zhang*

Main category: cs.CV

TL;DR: PGOV3D提出了一种基于Partial-to-Global课程的两阶段训练框架，通过多视角图像和预训练模型生成开放词汇标签，提升了3D语义分割的效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将多视角图像作为开放词汇信息的中介，忽略了其丰富的语义内容和跨视角对应关系，限制了模型效果。

Method: 采用两阶段训练：第一阶段在部分场景（密集语义、简单几何）预训练，利用MLLM和2D分割模型生成开放词汇标签；第二阶段在完整场景微调，通过伪标签桥接语义差距。

Result: 在ScanNet、ScanNet200和S3DIS基准测试中表现优异。

Conclusion: PGOV3D通过Partial-to-Global课程和两阶段训练，显著提升了开放词汇3D语义分割的性能。

Abstract: Existing open-vocabulary 3D semantic segmentation methods typically supervise
3D segmentation models by merging text-aligned features (e.g., CLIP) extracted
from multi-view images onto 3D points. However, such approaches treat
multi-view images merely as intermediaries for transferring open-vocabulary
information, overlooking their rich semantic content and cross-view
correspondences, which limits model effectiveness. To address this, we propose
PGOV3D, a novel framework that introduces a Partial-to-Global curriculum for
improving open-vocabulary 3D semantic segmentation. The key innovation lies in
a two-stage training strategy. In the first stage, we pre-train the model on
partial scenes that provide dense semantic information but relatively simple
geometry. These partial point clouds are derived from multi-view RGB-D inputs
via pixel-wise depth projection. To enable open-vocabulary learning, we
leverage a multi-modal large language model (MLLM) and a 2D segmentation
foundation model to generate open-vocabulary labels for each viewpoint,
offering rich and aligned supervision. An auxiliary inter-frame consistency
module is introduced to enforce feature consistency across varying viewpoints
and enhance spatial understanding. In the second stage, we fine-tune the model
on complete scene-level point clouds, which are sparser and structurally more
complex. We aggregate the partial vocabularies associated with each scene and
generate pseudo labels using the pre-trained model, effectively bridging the
semantic gap between dense partial observations and large-scale 3D
environments. Extensive experiments on ScanNet, ScanNet200, and S3DIS
benchmarks demonstrate that PGOV3D achieves competitive performance in
open-vocabulary 3D semantic segmentation.

</details>


### [302] [AttentionGS: Towards Initialization-Free 3D Gaussian Splatting via Structural Attention](https://arxiv.org/abs/2506.23611)
*Ziao Liu,Zhenjia Li,Yifeng Shi,Xiangang Li*

Main category: cs.CV

TL;DR: AttentionGS是一种新型框架，通过结构注意力直接从随机初始化进行3D重建，解决了3D高斯溅射（3DGS）对高质量点云的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 3DGS依赖高质量点云，但在纹理不足或视角受限的场景中表现不佳，限制了其应用范围。

Method: 提出AttentionGS框架，结合几何注意力和纹理注意力，逐步恢复全局场景结构和细化细节，并使用不透明度加权梯度指导高斯密集化。

Result: 在多个基准数据集上，AttentionGS显著优于现有方法，尤其在点云初始化不可靠的场景中。

Conclusion: AttentionGS为3DGS在实际应用中提供了更鲁棒和灵活的解决方案。

Abstract: 3D Gaussian Splatting (3DGS) is a powerful alternative to Neural Radiance
Fields (NeRF), excelling in complex scene reconstruction and efficient
rendering. However, it relies on high-quality point clouds from
Structure-from-Motion (SfM), limiting its applicability. SfM also fails in
texture-deficient or constrained-view scenarios, causing severe degradation in
3DGS reconstruction. To address this limitation, we propose AttentionGS, a
novel framework that eliminates the dependency on high-quality initial point
clouds by leveraging structural attention for direct 3D reconstruction from
randomly initialization. In the early training stage, we introduce geometric
attention to rapidly recover the global scene structure. As training
progresses, we incorporate texture attention to refine fine-grained details and
enhance rendering quality. Furthermore, we employ opacity-weighted gradients to
guide Gaussian densification, leading to improved surface reconstruction.
Extensive experiments on multiple benchmark datasets demonstrate that
AttentionGS significantly outperforms state-of-the-art methods, particularly in
scenarios where point cloud initialization is unreliable. Our approach paves
the way for more robust and flexible 3D Gaussian Splatting in real-world
applications.

</details>


### [303] [TurboVSR: Fantastic Video Upscalers and Where to Find Them](https://arxiv.org/abs/2506.23618)
*Zhongdao Wang,Guodongfang Zhao,Jingjing Ren,Bailan Feng,Shifeng Zhang,Wenbo Li*

Main category: cs.CV

TL;DR: TurboVSR是一种基于扩散模型的超高效视频超分辨率方法，通过高压缩比自动编码器、分解条件和快捷模型设计，显著提升计算效率，同时保持与现有最佳方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的视频超分辨率方法在细节生成方面表现优异，但计算效率低下，处理短视频耗时过长。

Method: 采用高压缩比自动编码器减少token数量；引入分解条件降低训练复杂度；将预训练扩散模型转换为快捷模型以减少采样步骤。

Result: TurboVSR性能与现有最佳方法相当，但速度快100倍以上，处理2秒1080p视频仅需7秒，并支持4K图像超分辨率。

Conclusion: TurboVSR通过高效设计解决了计算效率问题，为更高分辨率的超分辨率任务提供了可能。

Abstract: Diffusion-based generative models have demonstrated exceptional promise in
the video super-resolution (VSR) task, achieving a substantial advancement in
detail generation relative to prior methods. However, these approaches face
significant computational efficiency challenges. For instance, current
techniques may require tens of minutes to super-resolve a mere 2-second, 1080p
video. In this paper, we present TurboVSR, an ultra-efficient diffusion-based
video super-resolution model. Our core design comprises three key aspects: (1)
We employ an autoencoder with a high compression ratio of 32$\times$32$\times$8
to reduce the number of tokens. (2) Highly compressed latents pose substantial
challenges for training. We introduce factorized conditioning to mitigate the
learning complexity: we first learn to super-resolve the initial frame;
subsequently, we condition the super-resolution of the remaining frames on the
high-resolution initial frame and the low-resolution subsequent frames. (3) We
convert the pre-trained diffusion model to a shortcut model to enable fewer
sampling steps, further accelerating inference. As a result, TurboVSR performs
on par with state-of-the-art VSR methods, while being 100+ times faster, taking
only 7 seconds to process a 2-second long 1080p video. TurboVSR also supports
image resolution by considering image as a one-frame video. Our efficient
design makes SR beyond 1080p possible, results on 4K (3648$\times$2048) image
SR show surprising fine details.

</details>


### [304] [Revisiting Audio-Visual Segmentation with Vision-Centric Transformer](https://arxiv.org/abs/2506.23623)
*Shaofei Huang,Rui Ling,Tianrui Hui,Hongyu Li,Xu Zhou,Shifeng Zhang,Si Liu,Richang Hong,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种新的视觉中心Transformer（VCT）框架，通过视觉驱动的查询解决音频中心方法的感知模糊和细节丢失问题，并在AVSBench数据集上取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 音频中心Transformer存在感知模糊和视觉细节丢失的问题，限制了音频-视觉分割的性能。

Method: 采用视觉中心Transformer框架，结合原型提示查询生成模块（PPQG），通过视觉驱动的查询迭代获取音频和视觉信息。

Result: 在AVSBench数据集的三个子集上实现了最先进的性能。

Conclusion: VCT框架有效解决了音频中心方法的局限性，提升了音频-视觉分割的准确性和细节保留能力。

Abstract: Audio-Visual Segmentation (AVS) aims to segment sound-producing objects in
video frames based on the associated audio signal. Prevailing AVS methods
typically adopt an audio-centric Transformer architecture, where object queries
are derived from audio features. However, audio-centric Transformers suffer
from two limitations: perception ambiguity caused by the mixed nature of audio,
and weakened dense prediction ability due to visual detail loss. To address
these limitations, we propose a new Vision-Centric Transformer (VCT) framework
that leverages vision-derived queries to iteratively fetch corresponding audio
and visual information, enabling queries to better distinguish between
different sounding objects from mixed audio and accurately delineate their
contours. Additionally, we also introduce a Prototype Prompted Query Generation
(PPQG) module within our VCT framework to generate vision-derived queries that
are both semantically aware and visually rich through audio prototype prompting
and pixel context grouping, facilitating audio-visual information aggregation.
Extensive experiments demonstrate that our VCT framework achieves new
state-of-the-art performances on three subsets of the AVSBench dataset. The
code is available at https://github.com/spyflying/VCT_AVS.

</details>


### [305] [Brain Tumor Detection through Thermal Imaging and MobileNET](https://arxiv.org/abs/2506.23627)
*Roham Maiti,Debasmita Bhoumik*

Main category: cs.CV

TL;DR: 论文提出了一种基于MobileNET的高效脑肿瘤检测方法，解决了传统检测方法成本高、计算资源需求大的问题，准确率达98.5%。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤对人类健康构成重大威胁，传统检测方法（如活检、MRI、CT）成本高且依赖专业医疗知识，而现有机器学习模型计算需求大、训练时间长。

Method: 采用MobileNET模型，结合图像处理技术，构建了一个计算资源需求低、运行时间短的脑肿瘤检测模型。

Result: 提出的方法平均准确率达到98.5%。

Conclusion: MobileNET模型在脑肿瘤检测中表现出高效性和准确性，为低成本、快速的诊断提供了可行方案。

Abstract: Brain plays a crucial role in regulating body functions and cognitive
processes, with brain tumors posing significant risks to human health. Precise
and prompt detection is a key factor in proper treatment and better patient
outcomes. Traditional methods for detecting brain tumors, that include
biopsies, MRI, and CT scans often face challenges due to their high costs and
the need for specialized medical expertise. Recent developments in machine
learning (ML) and deep learning (DL) has exhibited strong capabilities in
automating the identification and categorization of brain tumors from medical
images, especially MRI scans. However, these classical ML models have
limitations, such as high computational demands, the need for large datasets,
and long training times, which hinder their accessibility and efficiency. Our
research uses MobileNET model for efficient detection of these tumors. The
novelty of this project lies in building an accurate tumor detection model
which use less computing re-sources and runs in less time followed by efficient
decision making through the use of image processing technique for accurate
results. The suggested method attained an average accuracy of 98.5%.

</details>


### [306] [Blending Concepts with Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.23630)
*Lorenzo Olearo,Giorgio Longari,Alessandro Raganato,Rafael Peñaloza,Simone Melzi*

Main category: cs.CV

TL;DR: 扩散模型在零样本框架下能够将多个概念（从具体对象到抽象思想）融合成新的视觉实体，展示了其创造性能力。四种融合方法各有优势，用户研究表明没有单一方法在所有场景下都最优。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型是否能在不进行额外训练或微调的情况下，将不同概念融合成新的视觉实体。

Method: 研究了四种融合方法，包括提示调度、嵌入插值和分层条件等，利用扩散管道的不同方面。

Result: 扩散模型展示了创造性融合能力，但不同方法在不同条件下表现最佳，输入的小变化会影响结果。

Conclusion: 扩散模型具有显著的组合潜力，但对输入变化敏感，需根据场景选择合适的方法。

Abstract: Diffusion models have dramatically advanced text-to-image generation in
recent years, translating abstract concepts into high-fidelity images with
remarkable ease. In this work, we examine whether they can also blend distinct
concepts, ranging from concrete objects to intangible ideas, into coherent new
visual entities under a zero-shot framework. Specifically, concept blending
merges the key attributes of multiple concepts (expressed as textual prompts)
into a single, novel image that captures the essence of each concept. We
investigate four blending methods, each exploiting different aspects of the
diffusion pipeline (e.g., prompt scheduling, embedding interpolation, or
layer-wise conditioning). Through systematic experimentation across diverse
concept categories, such as merging concrete concepts, synthesizing compound
words, transferring artistic styles, and blending architectural landmarks, we
show that modern diffusion models indeed exhibit creative blending capabilities
without further training or fine-tuning. Our extensive user study, involving
100 participants, reveals that no single approach dominates in all scenarios:
each blending technique excels under certain conditions, with factors like
prompt ordering, conceptual distance, and random seed affecting the outcome.
These findings highlight the remarkable compositional potential of diffusion
models while exposing their sensitivity to seemingly minor input variations.

</details>


### [307] [MReg: A Novel Regression Model with MoE-based Video Feature Mining for Mitral Regurgitation Diagnosis](https://arxiv.org/abs/2506.23648)
*Zhe Liu,Yuhao Huang,Lian Liu,Chengrui Zhang,Haotian Lin,Tong Han,Zhiyuan Zhu,Yanlin Chen,Yuerui Chen,Dong Ni,Zhongshan Gou,Xin Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种自动化二尖瓣反流（MR）诊断模型MReg，通过特征挖掘和回归任务设计，提高了诊断准确性和临床适用性。


<details>
  <summary>Details</summary>
Motivation: 现有智能MR诊断方法未能完全符合临床流程，准确性和可解释性不足。

Method: MReg基于四腔心彩色多普勒超声心动图视频（A4C-CDV），采用回归任务设计、特征选择与放大机制，以及Mixture-of-Experts启发的特征总结模块。

Result: 在1868例数据上，MReg表现优于其他弱监督和监督分类方法。

Conclusion: MReg通过模仿超声医师逻辑和增强特征表示，显著提升了MR诊断的准确性和实用性。

Abstract: Color Doppler echocardiography is a crucial tool for diagnosing mitral
regurgitation (MR). Recent studies have explored intelligent methods for MR
diagnosis to minimize user dependence and improve accuracy. However, these
approaches often fail to align with clinical workflow and may lead to
suboptimal accuracy and interpretability. In this study, we introduce an
automated MR diagnosis model (MReg) developed on the 4-chamber cardiac color
Doppler echocardiography video (A4C-CDV). It follows comprehensive feature
mining strategies to detect MR and assess its severity, considering clinical
realities. Our contribution is threefold. First, we formulate the MR diagnosis
as a regression task to capture the continuity and ordinal relationships
between categories. Second, we design a feature selection and amplification
mechanism to imitate the sonographer's diagnostic logic for accurate MR
grading. Third, inspired by the Mixture-of-Experts concept, we introduce a
feature summary module to extract the category-level features, enhancing the
representational capacity for more accurate grading. We trained and evaluated
our proposed MReg on a large in-house A4C-CDV dataset comprising 1868 cases
with three graded regurgitation labels. Compared to other weakly supervised
video anomaly detection and supervised classification methods, MReg
demonstrated superior performance in MR diagnosis. Our code is available at:
https://github.com/cskdstz/MReg.

</details>


### [308] [Towards Markerless Intraoperative Tracking of Deformable Spine Tissue](https://arxiv.org/abs/2506.23657)
*Connor Daly,Elettra Marconi,Marco Riva,Jinendra Ekanayake,Daniel S. Elson,Ferdinando Rodriguez y Baena*

Main category: cs.CV

TL;DR: 论文介绍了首个用于脊柱手术的临床RGB-D数据集，开发了SpineAlign系统用于捕捉术前和术中脊柱状态的变形，并提出了一个术中分割网络和多任务框架CorrespondNet。


<details>
  <summary>Details</summary>
Motivation: 减少手术时间和复杂性，通过无标记跟踪替代传统的骨安装跟踪设备。

Method: 开发SpineAlign系统，提出术中分割网络和多任务框架CorrespondNet。

Result: 成功应用于临床数据集，实现了脊柱状态的变形捕捉和关键区域预测。

Conclusion: 该方法具有高转化潜力，为无标记跟踪在脊柱手术中的应用提供了新方向。

Abstract: Consumer-grade RGB-D imaging for intraoperative orthopedic tissue tracking is
a promising method with high translational potential. Unlike bone-mounted
tracking devices, markerless tracking can reduce operating time and complexity.
However, its use has been limited to cadaveric studies. This paper introduces
the first real-world clinical RGB-D dataset for spine surgery and develops
SpineAlign, a system for capturing deformation between preoperative and
intraoperative spine states. We also present an intraoperative segmentation
network trained on this data and introduce CorrespondNet, a multi-task
framework for predicting key regions for registration in both intraoperative
and preoperative scenes.

</details>


### [309] [On the Domain Robustness of Contrastive Vision-Language Models](https://arxiv.org/abs/2506.23663)
*Mario Koddenbrock,Rudolf Hoffmann,David Brodmann,Erik Rodner*

Main category: cs.CV

TL;DR: Deepbench是一个评估视觉语言模型（VLMs）领域特定鲁棒性的框架，利用大语言模型（LLM）生成特定领域的图像损坏，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，预训练基础模型在领域变化时性能下降，缺乏透明性，需要针对性评估。

Method: Deepbench通过LLM生成领域特定的图像损坏，评估多种VLMs架构在六个真实领域的鲁棒性。

Result: 不同架构的鲁棒性差异显著，表明需要领域感知的评估方法。

Conclusion: Deepbench开源，支持领域感知鲁棒性研究的进一步发展。

Abstract: In real-world vision-language applications, practitioners increasingly rely
on large, pretrained foundation models rather than custom-built solutions,
despite limited transparency regarding their training data and processes. While
these models achieve impressive performance on general benchmarks, their
effectiveness can decline notably under specialized domain shifts, such as
unique imaging conditions or environmental variations. In this work, we
introduce Deepbench, a framework designed to assess domain-specific robustness
of vision-language models (VLMs). Deepbench leverages a large language model
(LLM) to generate realistic, context-aware image corruptions tailored to
specific deployment domains without requiring labeled data. We evaluate a range
of contrastive vision-language architectures and architectural variants across
six real-world domains and observe substantial variability in robustness,
highlighting the need for targeted, domain-aware evaluation. Deepbench is
released as open-source software to support further research into domain-aware
robustness assessment.

</details>


### [310] [Partial Forward Blocking: A Novel Data Pruning Paradigm for Lossless Training Acceleration](https://arxiv.org/abs/2506.23674)
*Dongyue Wu,Zilin Guo,Jialong Zuo,Nong Sang,Changxin Gao*

Main category: cs.CV

TL;DR: PFB框架通过浅层特征评估样本重要性，动态剪枝以减少计算开销，无需代理模型或额外反向传播，显著提升训练速度和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据剪枝方法依赖梯度或代理模型导致的高计算成本问题。

Method: 提出Partial Forward Blocking (PFB)，基于浅层特征评估样本重要性并动态剪枝，结合概率密度指标和自适应分布估计模块。

Result: 在ImageNet上，剪枝40%数据时，PFB实现0.5%准确率提升和33%训练时间减少。

Conclusion: PFB是一种高效的无损训练加速框架，显著优于现有方法。

Abstract: The ever-growing size of training datasets enhances the generalization
capability of modern machine learning models but also incurs exorbitant
computational costs. Existing data pruning approaches aim to accelerate
training by removing those less important samples. However, they often rely on
gradients or proxy models, leading to prohibitive additional costs of gradient
back-propagation and proxy model training. In this paper, we propose Partial
Forward Blocking (PFB), a novel framework for lossless training acceleration.
The efficiency of PFB stems from its unique adaptive pruning pipeline: sample
importance is assessed based on features extracted from the shallow layers of
the target model. Less important samples are then pruned, allowing only the
retained ones to proceed with the subsequent forward pass and loss
back-propagation. This mechanism significantly reduces the computational
overhead of deep-layer forward passes and back-propagation for pruned samples,
while also eliminating the need for auxiliary backward computations and proxy
model training. Moreover, PFB introduces probability density as an indicator of
sample importance. Combined with an adaptive distribution estimation module,
our method dynamically prioritizes relatively rare samples, aligning with the
constantly evolving training state. Extensive experiments demonstrate the
significant superiority of PFB in performance and speed. On ImageNet, PFB
achieves a 0.5% accuracy improvement and 33% training time reduction with 40%
data pruned.

</details>


### [311] [Pruning by Block Benefit: Exploring the Properties of Vision Transformer Blocks during Domain Adaptation](https://arxiv.org/abs/2506.23675)
*Patrick Glandorf,Bodo Rosenhahn*

Main category: cs.CV

TL;DR: P3B是一种基于块级贡献的剪枝方法，通过全局分配参数资源，在保持性能的同时减少计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决传统剪枝方法在未见数据域上权重重要性评估不准确的问题，以及任务敏感层在早期剪枝决策中性能损失的问题。

Method: 提出P3B方法，利用块级相对贡献全局分配参数资源，识别低影响组件并保留关键部分，同时通过层间保留比例确保后期收敛块的激活。

Result: P3B在70%参数减少的高稀疏度下仅损失0.64%准确率，在迁移学习任务中表现尤为突出。

Conclusion: P3B是一种先进的剪枝方法，特别适用于资源受限的硬件环境。

Abstract: Vision Transformer have set new benchmarks in several tasks, but these models
come with the lack of high computational costs which makes them impractical for
resource limited hardware. Network pruning reduces the computational complexity
by removing less important operations while maintaining performance. However,
pruning a model on an unseen data domain, leads to a misevaluation of weight
significance, resulting in suboptimal resource assignment. In this work, we
find that task-sensitive layers initially fail to improve the feature
representation on downstream tasks, leading to performance loss for early
pruning decisions. To address this problem, we introduce Pruning by Block
Benefit (P3B), a pruning method that utilizes the relative contribution on
block level to globally assign parameter resources. P3B identifies low-impact
components to reduce parameter allocation while preserving critical ones.
Classical pruning mask optimization struggles to reactivate zero-mask-elements.
In contrast, P3B sets a layerwise keep ratio based on global performance
metrics, ensuring the reactivation of late-converging blocks. We show in
extensive experiments that P3B is a state of the art pruning method with most
noticeable gains in transfer learning tasks. Notably, P3B is able to conserve
high performance, even in high sparsity regimes of 70% parameter reduction
while only losing 0.64% in accuracy.

</details>


### [312] [A Unified Framework for Stealthy Adversarial Generation via Latent Optimization and Transferability Enhancement](https://arxiv.org/abs/2506.23676)
*Gaozheng Pei,Ke Ma,Dongpeng Zhang,Chengzhi Sun,Qianqian Xu,Qingming Huang*

Main category: cs.CV

TL;DR: 提出一种统一框架，将传统对抗样本增强策略融入基于扩散模型的图像编辑方法，提升其在多样化下游任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面强大，但在对抗样本生成中泛化能力有限，尤其在Deepfake检测等任务中表现不佳。传统增强策略难以直接应用。

Method: 设计统一框架，将传统对抗样本增强策略与扩散模型结合，通过图像编辑生成对抗样本。

Result: 在ACM MM25竞赛中获第一名，验证了方法的有效性。

Conclusion: 该框架成功解决了扩散模型在对抗样本生成中的泛化问题，并展示了广泛的应用潜力。

Abstract: Due to their powerful image generation capabilities, diffusion-based
adversarial example generation methods through image editing are rapidly
gaining popularity. However, due to reliance on the discriminative capability
of the diffusion model, these diffusion-based methods often struggle to
generalize beyond conventional image classification tasks, such as in Deepfake
detection. Moreover, traditional strategies for enhancing adversarial example
transferability are challenging to adapt to these methods. To address these
challenges, we propose a unified framework that seamlessly incorporates
traditional transferability enhancement strategies into diffusion model-based
adversarial example generation via image editing, enabling their application
across a wider range of downstream tasks. Our method won first place in the
"1st Adversarial Attacks on Deepfake Detectors: A Challenge in the Era of
AI-Generated Media" competition at ACM MM25, which validates the effectiveness
of our approach.

</details>


### [313] [SynMotion: Semantic-Visual Adaptation for Motion Customized Video Generation](https://arxiv.org/abs/2506.23690)
*Shuai Tan,Biao Gong,Yujie Wei,Shiwei Zhang,Zhuoxin Liu,Dandan Zheng,Jingdong Chen,Yan Wang,Hao Ouyang,Kecheng Zheng,Yujun Shen*

Main category: cs.CV

TL;DR: SynMotion提出了一种结合语义指导和视觉适应的视频运动定制生成模型，通过双嵌入语义理解机制和参数高效的运动适配器，提升了运动保真度和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖语义级对齐或视觉调整，无法同时处理视频数据的复杂时空模式和语义表达，导致运动视觉复杂性和语义混淆。

Method: 提出双嵌入语义理解机制分离主体和运动表示，并集成参数高效的运动适配器；采用交替优化训练策略和SPV数据集。

Result: 在T2V和I2V设置下，SynMotion优于现有基线。

Conclusion: SynMotion通过联合语义和视觉优化，有效解决了运动定制中的语义混淆和视觉复杂性挑战。

Abstract: Diffusion-based video motion customization facilitates the acquisition of
human motion representations from a few video samples, while achieving
arbitrary subjects transfer through precise textual conditioning. Existing
approaches often rely on semantic-level alignment, expecting the model to learn
new motion concepts and combine them with other entities (e.g., ''cats'' or
''dogs'') to produce visually appealing results. However, video data involve
complex spatio-temporal patterns, and focusing solely on semantics cause the
model to overlook the visual complexity of motion. Conversely, tuning only the
visual representation leads to semantic confusion in representing the intended
action. To address these limitations, we propose SynMotion, a new
motion-customized video generation model that jointly leverages semantic
guidance and visual adaptation. At the semantic level, we introduce the
dual-embedding semantic comprehension mechanism which disentangles subject and
motion representations, allowing the model to learn customized motion features
while preserving its generative capabilities for diverse subjects. At the
visual level, we integrate parameter-efficient motion adapters into a
pre-trained video generation model to enhance motion fidelity and temporal
coherence. Furthermore, we introduce a new embedding-specific training strategy
which \textbf{alternately optimizes} subject and motion embeddings, supported
by the manually constructed Subject Prior Video (SPV) training dataset. This
strategy promotes motion specificity while preserving generalization across
diverse subjects. Lastly, we introduce MotionBench, a newly curated benchmark
with diverse motion patterns. Experimental results across both T2V and I2V
settings demonstrate that \method outperforms existing baselines. Project page:
https://lucaria-academy.github.io/SynMotion/

</details>


### [314] [Single Image Test-Time Adaptation via Multi-View Co-Training](https://arxiv.org/abs/2506.23705)
*Smriti Joshi,Richard Osuala,Lidia Garrucho,Kaisar Kushibar,Dimitri Kessler,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

TL;DR: 提出了一种基于补丁的多视图协同训练方法，用于单图像测试时适应，解决了临床环境中实时推理的需求，并在乳腺MRI数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有测试时适应方法依赖大数据集且未充分利用医学影像体积信息的问题。

Method: 通过不确定性引导的自训练实现特征和预测一致性，仅需单张测试图像即可进行体积分割。

Result: 在三个公开乳腺MRI数据集上，性能接近监督基准，平均Dice相似系数提升3.75%。

Conclusion: 该方法在临床实时推理中具有实用价值，代码已开源并与nnUNet兼容。

Abstract: Test-time adaptation enables a trained model to adjust to a new domain during
inference, making it particularly valuable in clinical settings where such
on-the-fly adaptation is required. However, existing techniques depend on large
target domain datasets, which are often impractical and unavailable in medical
scenarios that demand per-patient, real-time inference. Moreover, current
methods commonly focus on two-dimensional images, failing to leverage the
volumetric richness of medical imaging data. Bridging this gap, we propose a
Patch-Based Multi-View Co-Training method for Single Image Test-Time
adaptation. Our method enforces feature and prediction consistency through
uncertainty-guided self-training, enabling effective volumetric segmentation in
the target domain with only a single test-time image. Validated on three
publicly available breast magnetic resonance imaging datasets for tumor
segmentation, our method achieves performance close to the upper bound
supervised benchmark while also outperforming all existing state-of-the-art
methods, on average by a Dice Similarity Coefficient of 3.75%. We publicly
share our accessible codebase, readily integrable with the popular nnUNet
framework, at https://github.com/smriti-joshi/muvi.git.

</details>


### [315] [Subjective Camera: Bridging Human Cognition and Visual Reconstruction through Sequence-Aware Sketch-Guided Diffusion](https://arxiv.org/abs/2506.23711)
*Haoyang Chen,Dongfang Sun,Caoyuan Ma,Shiqin Wang,Kewei Zhang,Zheng Wang,Zhixiang Wang*

Main category: cs.CV

TL;DR: Subjective Camera通过结合语言描述和渐进草图，将主观感知转化为逼真图像，解决了语言模糊性和草图抽象性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在用户主观输入偏差、草图与3D先验的模态差距以及草图质量敏感性问题，需要资源密集型调整或不切实际的草图精度要求。

Method: 采用概念顺序生成框架，通过文本奖励优化建立外观先验，并利用序列感知解耦生成和潜在优化，无需训练即可适应主观期望。

Result: 在多样数据集上实现了语义和空间一致性的最先进性能。

Conclusion: 该框架有效解决了现有挑战，支持使用粗糙草图且无需艺术专业知识。

Abstract: We propose Subjective Camera, a human-as-imaging-device paradigm that
reconstructs real-world scenes from mental impressions through synergistic use
of verbal descriptions and progressive rough sketches. This approach overcomes
dual limitations of language ambiguity and sketch abstraction by treating the
user's drawing sequence as priors, effectively translating subjective
perceptual expectations into photorealistic images.
  Existing approaches face three fundamental barriers: (1) user-specific
subjective input biases, (2) huge modality gap between planar sketch and 3D
priors in diffusion, and (3) sketch quality-sensitive performance degradation.
Current solutions either demand resource-intensive model adaptation or impose
impractical requirements on sketch precision.
  Our framework addresses these challenges through concept-sequential
generation. (1) We establish robust appearance priors through text-reward
optimization, and then implement sequence-aware disentangled generation that
processes concepts in sketching order; these steps accommodate user-specific
subjective expectation in a train-free way. (2) We employ latent optimization
that effectively bridges the modality gap between planar sketches and 3D priors
in diffusion. (3) Our hierarchical reward-guided framework enables the use of
rough sketches without demanding artistic expertise. Comprehensive evaluation
across diverse datasets demonstrates that our approach achieves
state-of-the-art performance in maintaining both semantic and spatial
coherence.

</details>


### [316] [Proteus-ID: ID-Consistent and Motion-Coherent Video Customization](https://arxiv.org/abs/2506.23729)
*Guiyu Zhang,Chen Shi,Zijian Jiang,Xunzhi Xiang,Jingjing Qian,Shaoshuai Shi,Li Jiang*

Main category: cs.CV

TL;DR: Proteus-ID是一个基于扩散的框架，用于身份一致和运动连贯的视频定制，通过多模态身份融合和时间感知身份注入解决身份一致性和运动自然性问题。


<details>
  <summary>Details</summary>
Motivation: 视频身份定制任务面临身份一致性和运动自然性的挑战，现有方法难以同时满足这两点。

Method: 提出Multimodal Identity Fusion模块、Time-Aware Identity Injection机制和Adaptive Motion Learning策略，结合Proteus-Bench数据集进行训练和评估。

Result: 实验表明Proteus-ID在身份保持、文本对齐和运动质量上优于现有方法。

Conclusion: Proteus-ID为视频身份定制设立了新基准，代码和数据已公开。

Abstract: Video identity customization seeks to synthesize realistic, temporally
coherent videos of a specific subject, given a single reference image and a
text prompt. This task presents two core challenges: (1) maintaining identity
consistency while aligning with the described appearance and actions, and (2)
generating natural, fluid motion without unrealistic stiffness. To address
these challenges, we introduce Proteus-ID, a novel diffusion-based framework
for identity-consistent and motion-coherent video customization. First, we
propose a Multimodal Identity Fusion (MIF) module that unifies visual and
textual cues into a joint identity representation using a Q-Former, providing
coherent guidance to the diffusion model and eliminating modality imbalance.
Second, we present a Time-Aware Identity Injection (TAII) mechanism that
dynamically modulates identity conditioning across denoising steps, improving
fine-detail reconstruction. Third, we propose Adaptive Motion Learning (AML), a
self-supervised strategy that reweights the training loss based on
optical-flow-derived motion heatmaps, enhancing motion realism without
requiring additional inputs. To support this task, we construct Proteus-Bench,
a high-quality dataset comprising 200K curated clips for training and 150
individuals from diverse professions and ethnicities for evaluation. Extensive
experiments demonstrate that Proteus-ID outperforms prior methods in identity
preservation, text alignment, and motion quality, establishing a new benchmark
for video identity customization. Codes and data are publicly available at
https://grenoble-zhang.github.io/Proteus-ID/.

</details>


### [317] [Can We Challenge Open-Vocabulary Object Detectors with Generated Content in Street Scenes?](https://arxiv.org/abs/2506.23751)
*Annika Mütze,Sadia Ilyas,Christian Dörpelkus,Matthias Rottmann*

Main category: cs.CV

TL;DR: 论文探讨了通过合成数据挑战开放词汇目标检测器的局限性，发现其对物体位置的依赖强于语义。


<details>
  <summary>Details</summary>
Motivation: 由于开放词汇目标检测器在安全关键应用中的潜在风险，需要系统性评估其局限性。

Method: 设计了两个自动化流程，利用稳定扩散技术生成语义多样的合成数据，并评估多种检测器。

Result: 合成数据能有效挑战检测器，发现其对物体位置的依赖性强于语义。

Conclusion: 研究为挑战开放词汇模型提供了系统性方法，并为改进数据采集提供了见解。

Abstract: Open-vocabulary object detectors such as Grounding DINO are trained on vast
and diverse data, achieving remarkable performance on challenging datasets. Due
to that, it is unclear where to find their limitations, which is of major
concern when using in safety-critical applications. Real-world data does not
provide sufficient control, required for a rigorous evaluation of model
generalization. In contrast, synthetically generated data allows to
systematically explore the boundaries of model competence/generalization. In
this work, we address two research questions: 1) Can we challenge
open-vocabulary object detectors with generated image content? 2) Can we find
systematic failure modes of those models? To address these questions, we design
two automated pipelines using stable diffusion to inpaint unusual objects with
high diversity in semantics, by sampling multiple substantives from WordNet and
ChatGPT. On the synthetically generated data, we evaluate and compare multiple
open-vocabulary object detectors as well as a classical object detector. The
synthetic data is derived from two real-world datasets, namely LostAndFound, a
challenging out-of-distribution (OOD) detection benchmark, and the NuImages
dataset. Our results indicate that inpainting can challenge open-vocabulary
object detectors in terms of overlooking objects. Additionally, we find a
strong dependence of open-vocabulary models on object location, rather than on
object semantics. This provides a systematic approach to challenge
open-vocabulary models and gives valuable insights on how data could be
acquired to effectively improve these models.

</details>


### [318] [Visual Textualization for Image Prompted Object Detection](https://arxiv.org/abs/2506.23785)
*Yongjian Wu,Yang Zhou,Jiya Saiyin,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: VisTex-OVLM是一种新颖的图像提示目标检测方法，通过视觉文本化增强对象级视觉语言模型（OVLM）对罕见类别的检测能力，同时保持其预训练的对象-文本对齐。


<details>
  <summary>Details</summary>
Motivation: 解决OVLM在罕见类别检测中的局限性，这些类别难以用文本描述且预训练数据中几乎不存在。

Method: 利用多尺度文本化块和多阶段融合策略，将视觉示例信息转化为文本化视觉标记，结合文本提示指导OVLM。

Result: 在开放集数据集和少样本基准（PASCAL VOC和MSCOCO）上实现最先进性能。

Conclusion: VisTex-OVLM在保持OVLM原有架构和泛化能力的同时，显著提升了少样本场景下的检测性能。

Abstract: We propose VisTex-OVLM, a novel image prompted object detection method that
introduces visual textualization -- a process that projects a few visual
exemplars into the text feature space to enhance Object-level Vision-Language
Models' (OVLMs) capability in detecting rare categories that are difficult to
describe textually and nearly absent from their pre-training data, while
preserving their pre-trained object-text alignment. Specifically, VisTex-OVLM
leverages multi-scale textualizing blocks and a multi-stage fusion strategy to
integrate visual information from visual exemplars, generating textualized
visual tokens that effectively guide OVLMs alongside text prompts. Unlike
previous methods, our method maintains the original architecture of OVLM,
maintaining its generalization capabilities while enhancing performance in
few-shot settings. VisTex-OVLM demonstrates superior performance across
open-set datasets which have minimal overlap with OVLM's pre-training data and
achieves state-of-the-art results on few-shot benchmarks PASCAL VOC and MSCOCO.
The code will be released at https://github.com/WitGotFlg/VisTex-OVLM.

</details>


### [319] [Controllable Reference-Based Real-World Remote Sensing Image Super-Resolution with Generative Diffusion Priors](https://arxiv.org/abs/2506.23801)
*Ce Wang,Wanjie Sun*

Main category: cs.CV

TL;DR: CRefDiff是一种基于扩散模型的可控参考超分辨率方法，通过双分支融合机制和预训练Stable Diffusion模型，解决了现有RefSR方法在真实世界中的不足，并在新数据集Real-RefRSSRD上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有RefSR方法在真实世界应用中存在分辨率差距和土地覆盖变化等问题，导致生成效果不佳或过度依赖参考图像。

Method: 基于预训练的Stable Diffusion模型，引入双分支融合机制自适应整合参考图像的局部和全局信息，并提出Better Start策略加速推理。

Result: 在Real-RefRSSRD数据集上，CRefDiff在多项指标上达到最优，并提升了场景分类和语义分割等下游任务性能。

Conclusion: CRefDiff通过可控参考和高效推理设计，为真实世界遥感图像超分辨率提供了有效解决方案。

Abstract: Super-resolution (SR) techniques can enhance the spatial resolution of remote
sensing images by utilizing low-resolution (LR) images to reconstruct
high-resolution (HR) images, enabling more efficient large-scale earth
observation applications. While single-image super-resolution (SISR) methods
have shown progress, reference-based super-resolution (RefSR) offers superior
performance by incorporating historical HR images alongside current LR
observations. However, existing RefSR methods struggle with real-world
complexities, such as cross-sensor resolution gap and significant land cover
changes, often leading to under-generation or over-reliance on reference image.
To address these challenges, we propose CRefDiff, a novel controllable
reference-based diffusion model for real-world remote sensing image SR. To
address the under-generation problem, CRefDiff is built upon the pretrained
Stable Diffusion model, leveraging its powerful generative prior to produce
accurate structures and textures. To mitigate over-reliance on the reference,
we introduce a dual-branch fusion mechanism that adaptively integrates both
local and global information from the reference image. Moreover, this novel
dual-branch design enables reference strength control during inference,
enhancing interactivity and flexibility of the model. Finally, a strategy named
Better Start is proposed to significantly reduce the number of denoising steps,
thereby accelerating the inference process. To support further research, we
introduce Real-RefRSSRD, a new real-world RefSR dataset for remote sensing
images, consisting of HR NAIP and LR Sentinel-2 image pairs with diverse land
cover changes and significant temporal gaps. Extensive experiments on
Real-RefRSSRD show that CRefDiff achieves state-of-the-art performance across
various metrics and improves downstream tasks such as scene classification and
semantic segmentation.

</details>


### [320] [Towards Initialization-free Calibrated Bundle Adjustment](https://arxiv.org/abs/2506.23808)
*Carl Olsson,Amanda Nilsson*

Main category: cs.CV

TL;DR: 提出了一种利用已知相机标定的方法，通过引入成对相对旋转估计，实现无初始化校准SfM，生成接近度量的重建结果。


<details>
  <summary>Details</summary>
Motivation: 传统无初始化BA方法使用pOSE作为替代目标，但无法利用相机标定信息，导致重建结果仅能确定到投影变换，且需要更多数据。

Method: 引入成对相对旋转估计，这些估计仅对相似变换不变，从而鼓励保留场景度量特征的解决方案。

Result: 实验表明，该方法能够可靠优化目标，从随机初始解高概率收敛到全局最小值，生成准确的接近度量重建。

Conclusion: 该方法成功将旋转平均集成到pOSE框架中，实现了无初始化校准SfM，生成更精确的重建结果。

Abstract: A recent series of works has shown that initialization-free BA can be
achieved using pseudo Object Space Error (pOSE) as a surrogate objective. The
initial reconstruction-step optimizes an objective where all terms are
projectively invariant and it cannot incorporate knowledge of the camera
calibration. As a result, the solution is only determined up to a projective
transformation of the scene and the process requires more data for successful
reconstruction.
  In contrast, we present a method that is able to use the known camera
calibration thereby producing near metric solutions, that is, reconstructions
that are accurate up to a similarity transformation. To achieve this we
introduce pairwise relative rotation estimates that carry information about
camera calibration. These are only invariant to similarity transformations,
thus encouraging solutions that preserve metric features of the real scene. Our
method can be seen as integrating rotation averaging into the pOSE framework
striving towards initialization-free calibrated SfM.
  Our experimental evaluation shows that we are able to reliably optimize our
objective, achieving convergence to the global minimum with high probability
from random starting solutions, resulting in accurate near metric
reconstructions.

</details>


### [321] [MadCLIP: Few-shot Medical Anomaly Detection with CLIP](https://arxiv.org/abs/2506.23810)
*Mahshid Shiri,Cigdem Beyan,Vittorio Murino*

Main category: cs.CV

TL;DR: 提出了一种基于预训练CLIP模型的少样本异常检测方法，适用于医学数据的图像级异常分类和像素级异常分割，通过双分支设计和可学习文本提示提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学数据中少样本异常检测的挑战，避免依赖合成数据或内存库。

Method: 采用双分支设计捕获正常和异常特征，使用可学习文本提示增强语义对齐，并首次在医学领域应用SigLIP损失。

Result: 在多种模态上验证了方法的优越性，性能超过现有方法，且不依赖合成数据。

Conclusion: 该方法在医学异常检测中表现出色，各组件均对性能有贡献，代码已开源。

Abstract: An innovative few-shot anomaly detection approach is presented, leveraging
the pre-trained CLIP model for medical data, and adapting it for both
image-level anomaly classification (AC) and pixel-level anomaly segmentation
(AS). A dual-branch design is proposed to separately capture normal and
abnormal features through learnable adapters in the CLIP vision encoder. To
improve semantic alignment, learnable text prompts are employed to link visual
features. Furthermore, SigLIP loss is applied to effectively handle the
many-to-one relationship between images and unpaired text prompts, showcasing
its adaptation in the medical field for the first time. Our approach is
validated on multiple modalities, demonstrating superior performance over
existing methods for AC and AS, in both same-dataset and cross-dataset
evaluations. Unlike prior work, it does not rely on synthetic data or memory
banks, and an ablation study confirms the contribution of each component. The
code is available at https://github.com/mahshid1998/MadCLIP.

</details>


### [322] [Interpretable Zero-Shot Learning with Locally-Aligned Vision-Language Model](https://arxiv.org/abs/2506.23822)
*Shiming Chen,Bowen Duan,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: LaZSL是一种基于局部视觉-语义对齐的可解释零样本学习方法，通过最优传输实现视觉区域与属性的交互，提升模型的可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉-语言模型（如CLIP）在零样本学习中表现优异，但缺乏可解释性。本文旨在通过局部视觉-语义对齐解决这一问题。

Method: 提出LaZSL模型，利用最优传输技术实现视觉区域与属性的局部对齐，无需额外训练即可提供可解释的相似性。

Result: 实验表明，LaZSL在可解释性、准确性和领域泛化性方面均有显著提升。

Conclusion: LaZSL为可解释零样本学习提供了一种高效方法，兼具性能和可解释性。

Abstract: Large-scale vision-language models (VLMs), such as CLIP, have achieved
remarkable success in zero-shot learning (ZSL) by leveraging large-scale
visual-text pair datasets. However, these methods often lack interpretability,
as they compute the similarity between an entire query image and the embedded
category words, making it difficult to explain their predictions. One approach
to address this issue is to develop interpretable models by integrating
language, where classifiers are built using discrete attributes, similar to
human perception. This introduces a new challenge: how to effectively align
local visual features with corresponding attributes based on pre-trained VLMs.
To tackle this, we propose LaZSL, a locally-aligned vision-language model for
interpretable ZSL. LaZSL employs local visual-semantic alignment via optimal
transport to perform interaction between visual regions and their associated
attributes, facilitating effective alignment and providing interpretable
similarity without the need for additional training. Extensive experiments
demonstrate that our method offers several advantages, including enhanced
interpretability, improved accuracy, and strong domain generalization. Codes
available at: https://github.com/shiming-chen/LaZSL.

</details>


### [323] [Flash-VStream: Efficient Real-Time Understanding for Long Video Streams](https://arxiv.org/abs/2506.23825)
*Haoji Zhang,Yiqin Wang,Yansong Tang,Yong Liu,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

TL;DR: Flash-VStream是一种高效的长视频语言模型，通过设计Flash Memory模块，显著降低了推理延迟，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有模型处理长视频效率低下且难以泛化，需要一种更高效的解决方案。

Method: 提出Flash Memory模块，包含低容量上下文记忆和高容量增强记忆，以聚合长上下文信息并检索详细空间信息。

Result: 在多个长视频基准测试中实现了最先进的性能和高效推理。

Conclusion: Flash-VStream为长视频理解提供了一种高效且可扩展的解决方案。

Abstract: Benefiting from the advances in large language models and cross-modal
alignment, existing multimodal large language models have achieved prominent
performance in image and short video understanding. However, the understanding
of long videos is still challenging, as their long-context nature results in
significant computational and memory overhead. Most existing work treats long
videos in the same way as short videos, which is inefficient for real-world
applications and hard to generalize to even longer videos. To address these
issues, we propose Flash-VStream, an efficient video language model capable of
processing extremely long videos and responding to user queries in real time.
Particularly, we design a Flash Memory module, containing a low-capacity
context memory to aggregate long-context temporal information and model the
distribution of information density, and a high-capacity augmentation memory to
retrieve detailed spatial information based on this distribution. Compared to
existing models, Flash-VStream achieves significant reductions in inference
latency. Extensive experiments on long video benchmarks and comprehensive video
benchmarks, i.e., EgoSchema, MLVU, LVBench, MVBench and Video-MME, demonstrate
the state-of-the-art performance and outstanding efficiency of our method. Code
is available at https://github.com/IVGSZ/Flash-VStream.

</details>


### [324] [Spatially Gene Expression Prediction using Dual-Scale Contrastive Learning](https://arxiv.org/abs/2506.23827)
*Mingcheng Qu,Yuncong Wu,Donglin Di,Yue Gao,Tonghua Su,Yang Song,Lei Fan*

Main category: cs.CV

TL;DR: NH2ST框架通过整合空间上下文和多模态数据，显著提升了基因表达预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了空间和分子交互作用，导致预测不准确。

Method: 提出NH2ST框架，结合查询分支和邻居分支，利用交叉注意力和对比学习。

Result: 在六个数据集上表现优于现有方法，PCC指标提升超过20%。

Conclusion: NH2ST为基因表达预测提供了更有效的解决方案。

Abstract: Spatial transcriptomics (ST) provides crucial insights into tissue
micro-environments, but is limited to its high cost and complexity. As an
alternative, predicting gene expression from pathology whole slide images (WSI)
is gaining increasing attention. However, existing methods typically rely on
single patches or a single pathology modality, neglecting the complex spatial
and molecular interactions between target and neighboring information (e.g.,
gene co-expression). This leads to a failure in establishing connections among
adjacent regions and capturing intricate cross-modal relationships. To address
these issues, we propose NH2ST, a framework that integrates spatial context and
both pathology and gene modalities for gene expression prediction. Our model
comprises a query branch and a neighbor branch to process paired target patch
and gene data and their neighboring regions, where cross-attention and
contrastive learning are employed to capture intrinsic associations and ensure
alignments between pathology and gene expression. Extensive experiments on six
datasets demonstrate that our model consistently outperforms existing methods,
achieving over 20% in PCC metrics. Codes are available at
https://github.com/MCPathology/NH2ST

</details>


### [325] [Low-latency vision transformers via large-scale multi-head attention](https://arxiv.org/abs/2506.23832)
*Ronit D. Gross,Tal Halevi,Ella Koresh,Yarden Tzach,Ido Kanter*

Main category: cs.CV

TL;DR: 论文研究了多头注意力（MHA）中自发对称性断裂的现象，提出了一种基于单头性能（SHP）矩阵的通用学习机制，提高了分类准确率并减少了延迟。


<details>
  <summary>Details</summary>
Motivation: 探索多头注意力机制在分类任务中的学习行为，特别是自发对称性断裂现象，并推广到大规模MHA（LS-MHA）。

Method: 通过量化单头性能（SHP）矩阵，分析多头注意力的学习机制，并设计新的视觉Transformer（ViT）架构。

Result: 发现SHP矩阵包含多个单元簇，显著提高了信噪比（SNR）和分类准确率，同时通过卷积层替换减少了延迟。

Conclusion: 该学习机制可推广至自然语言处理任务，为深度学习提供新见解。

Abstract: The emergence of spontaneous symmetry breaking among a few heads of
multi-head attention (MHA) across transformer blocks in classification tasks
was recently demonstrated through the quantification of single-nodal
performance (SNP). This finding indicates that each head focuses its attention
on a subset of labels through cooperation among its SNPs. This underlying
learning mechanism is generalized to large-scale MHA (LS-MHA) using a single
matrix value representing single-head performance (SHP), analogous to
single-filter performance in convolutional neural networks (CNNs). The results
indicate that each SHP matrix comprises multiple unit clusters such that each
label being explicitly recognized by a few heads with negligible noise. This
leads to an increased signal-to-noise ratio (SNR) along the transformer blocks,
thereby improving classification accuracy. These features give rise to several
distinct vision transformer (ViT) architectures that achieve the same accuracy
but differ in their LS-MHA structures. As a result, their soft committee yields
superior accuracy, an outcome not typically observed in CNNs which rely on
hundreds of filters. In addition, a significant reduction in latency is
achieved without affecting the accuracy by replacing the initial transformer
blocks with convolutional layers. This substitution accelerates early-stage
learning, which is then improved by subsequent transformer layers. The
extension of this learning mechanism to natural language processing tasks,
based on quantitative differences between CNNs and ViT architectures, has the
potential to yield new insights in deep learning. The findings are demonstrated
using compact convolutional transformer architectures trained on the CIFAR-100
dataset.

</details>


### [326] [PointSSIM: A novel low dimensional resolution invariant image-to-image comparison metric](https://arxiv.org/abs/2506.23833)
*Oscar Ovanger,Ragnar Hauge,Jacob Skauvold,Michael J. Pyrcz,Jo Eidsvik*

Main category: cs.CV

TL;DR: PointSSIM是一种低维图像比较指标，具有分辨率不变性，适用于不同分辨率的二值图像比较。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像比较方法在不同分辨率下效果不佳的问题。

Method: 通过将二值图像转换为标记点模式表示，提取关键特征（锚点），并使用总结向量比较图像的强度、连通性、复杂性和结构属性。

Result: PointSSIM在不同分辨率的图像比较中表现出高效性和可靠性。

Conclusion: PointSSIM特别适合需要跨分辨率结构分析的应用场景。

Abstract: This paper presents PointSSIM, a novel low-dimensional image-to-image
comparison metric that is resolution invariant. Drawing inspiration from the
structural similarity index measure and mathematical morphology, PointSSIM
enables robust comparison across binary images of varying resolutions by
transforming them into marked point pattern representations. The key features
of the image, referred to as anchor points, are extracted from binary images by
identifying locally adaptive maxima from the minimal distance transform. Image
comparisons are then performed using a summary vector, capturing intensity,
connectivity, complexity, and structural attributes. Results show that this
approach provides an efficient and reliable method for image comparison,
particularly suited to applications requiring structural analysis across
different resolutions.

</details>


### [327] [Refine Any Object in Any Scene](https://arxiv.org/abs/2506.23835)
*Ziwei Chen,Ziling Liu,Zitong Huang,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: RAISE是一个3D增强框架，利用3D生成先验恢复缺失视角下的物体几何和外观细节。


<details>
  <summary>Details</summary>
Motivation: 解决场景重建中因视角缺失导致物体细节建模困难的问题，提升下游任务性能。

Method: 通过两阶段优化：先对齐代理物体与退化物体，再校正空间和外观不一致性。

Result: 在多个基准测试中，RAISE在新视角合成和几何补全任务中表现优异。

Conclusion: RAISE能高效恢复物体细节，同时保持场景一致性，为3D重建提供新思路。

Abstract: Viewpoint missing of objects is common in scene reconstruction, as camera
paths typically prioritize capturing the overall scene structure rather than
individual objects. This makes it highly challenging to achieve high-fidelity
object-level modeling while maintaining accurate scene-level representation.
Addressing this issue is critical for advancing downstream tasks requiring
detailed object understanding and appearance modeling. In this paper, we
introduce Refine Any object In any ScenE (RAISE), a novel 3D enhancement
framework that leverages 3D generative priors to recover fine-grained object
geometry and appearance under missing views. Starting from substituting
degraded objects with proxies, via a 3D generative model with strong 3D
understanding, RAISE progressively refines geometry and texture by aligning
each proxy to its degraded counterpart in 7-DOF pose, followed by correcting
spatial and appearance inconsistencies via registration-constrained
enhancement. This two-stage refinement ensures the high-fidelity geometry and
appearance of the original object in unseen views while maintaining consistency
in spatial positioning, observed geometry, and appearance. Extensive
experiments on challenging benchmarks show that RAISE significantly outperforms
state-of-the-art methods in both novel view synthesis and geometry completion
tasks. RAISE is made publicly available at https://github.com/PolySummit/RAISE.

</details>


### [328] [RGC-VQA: An Exploration Database for Robotic-Generated Video Quality Assessment](https://arxiv.org/abs/2506.23852)
*Jianing Jin,Jiangyong Ying,Huiyu Duan,Liu Yang,Sijing Wu,Yunhao Li,Yushuo Zheng,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 论文提出了机器人生成内容（RGC）的概念，并建立了首个RGC视频数据库（RGCD），用于评估RGC视频的感知质量。实验发现现有VQA模型在RGC视频上表现不佳，呼吁开发RGC专用的VQA模型。


<details>
  <summary>Details</summary>
Motivation: 随着机器人视频在流媒体平台上的普及，RGC视频的感知质量对人类-机器人交互至关重要，但目前缺乏专门的研究。

Method: 建立了包含2,100个RGC视频的数据库（RGCD），并进行了主观VQA实验和11种现有VQA模型的基准测试。

Result: 实验结果表明，现有VQA模型在复杂的RGC视频上表现不佳。

Conclusion: 需要开发RGC专用的VQA模型，RGCD数据库已公开。

Abstract: As camera-equipped robotic platforms become increasingly integrated into
daily life, robotic-generated videos have begun to appear on streaming media
platforms, enabling us to envision a future where humans and robots coexist. We
innovatively propose the concept of Robotic-Generated Content (RGC) to term
these videos generated from egocentric perspective of robots. The perceptual
quality of RGC videos is critical in human-robot interaction scenarios, and RGC
videos exhibit unique distortions and visual requirements that differ markedly
from those of professionally-generated content (PGC) videos and user-generated
content (UGC) videos. However, dedicated research on quality assessment of RGC
videos is still lacking. To address this gap and to support broader robotic
applications, we establish the first Robotic-Generated Content Database (RGCD),
which contains a total of 2,100 videos drawn from three robot categories and
sourced from diverse platforms. A subjective VQA experiment is conducted
subsequently to assess human visual perception of robotic-generated videos.
Finally, we conduct a benchmark experiment to evaluate the performance of 11
state-of-the-art VQA models on our database. Experimental results reveal
significant limitations in existing VQA models when applied to complex,
robotic-generated content, highlighting a critical need for RGC-specific VQA
models. Our RGCD is publicly available at:
https://github.com/IntMeGroup/RGC-VQA.

</details>


### [329] [HiNeuS: High-fidelity Neural Surface Mitigating Low-texture and Reflective Ambiguity](https://arxiv.org/abs/2506.23854)
*Yida Wang,Xueyang Zhang,Kun Zhan,Peng Jia,Xianpeng Lang*

Main category: cs.CV

TL;DR: HiNeuS是一个统一的神经表面重建框架，解决了多视角辐射不一致、纹理缺失区域关键点丢失以及Eikonal约束过强导致的结构退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景下难以平衡几何保真度和光度一致性，HiNeuS旨在通过统一管道解决这些核心限制。

Method: HiNeuS引入差分可见性验证、平面共形正则化和物理基础的Eikonal松弛，实现外观与几何约束的协同优化。

Result: 在合成和真实数据集上表现优异，Chamfer距离降低21.4%，PSNR提升2.32 dB，并能恢复高光物体和低纹理表面。

Conclusion: HiNeuS通过协同优化实现了外观与几何约束的统一，适用于逆向渲染任务，展现了卓越的泛化能力。

Abstract: Neural surface reconstruction faces persistent challenges in reconciling
geometric fidelity with photometric consistency under complex scene conditions.
We present HiNeuS, a unified framework that holistically addresses three core
limitations in existing approaches: multi-view radiance inconsistency, missing
keypoints in textureless regions, and structural degradation from over-enforced
Eikonal constraints during joint optimization. To resolve these issues through
a unified pipeline, we introduce: 1) Differential visibility verification
through SDF-guided ray tracing, resolving reflection ambiguities via continuous
occlusion modeling; 2) Planar-conformal regularization via ray-aligned geometry
patches that enforce local surface coherence while preserving sharp edges
through adaptive appearance weighting; and 3) Physically-grounded Eikonal
relaxation that dynamically modulates geometric constraints based on local
radiance gradients, enabling detail preservation without sacrificing global
regularity. Unlike prior methods that handle these aspects through sequential
optimizations or isolated modules, our approach achieves cohesive integration
where appearance-geometry constraints evolve synergistically throughout
training. Comprehensive evaluations across synthetic and real-world datasets
demonstrate state-of-the-art performance, including a 21.4% reduction in
Chamfer distance over reflection-aware baselines and 2.32 dB PSNR improvement
against neural rendering counterparts. Qualitative analyses reveal superior
capability in recovering specular instruments, urban layouts with
centimeter-scale infrastructure, and low-textured surfaces without local patch
collapse. The method's generalizability is further validated through successful
application to inverse rendering tasks, including material decomposition and
view-consistent relighting.

</details>


### [330] [A Closer Look at Conditional Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2506.23856)
*Ji Zhang,Shihan Wu,Lianli Gao,Jingkuan Song,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: 论文提出Class-adaptive Prompt Tuning (CaPT)，通过基于文本类别信息（TCI）的动态提示学习解决Base-New Tradeoff问题，显著提升模型在新任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉图像信息（VII）的条件提示调优方法性能不佳，甚至不如随机噪声条件提示。研究发现TCI是解决Base-New Tradeoff问题的关键。

Method: 提出CaPT方法，通过从基类学习TCI条件提示，快速适应新类。CaPT可作为插件缓解现有无条件提示调优方案的BNT问题。

Result: 在11个数据集上的实验表明，CaPT显著提升了五种无条件提示调优基线的性能，且计算成本几乎不变。结合DePT框架的DeCaPT方法在性能上超越现有最佳条件提示调优方案3.49%。

Conclusion: CaPT通过TCI条件提示有效解决了BNT问题，显著提升了模型的泛化能力，且计算成本低，适用于多种提示调优方案。

Abstract: Despite the great promise of Prompt Tuning (PT) in adapting large
Vision-Language Pretrained Models (VLPMs) to downstream tasks, they often
struggle to overcome the Base-New Tradeoff (BNT) dilemma: as VLPMs are better
tuned to a base task, their ability to generalize to new tasks diminishes.
Recent work on conditional PT addresses this problem by replacing static
prompts with dynamic Visual Image Information (VII)-conditioned prompts,
improving the model's generalization to new tasks to some extent. In this work,
we first identify a critical issue with existing conditional PT methods: using
VII as the "condition" of prompts yields suboptimal performance, and even
random noise-conditioned prompts can outperform the VII-conditioned
counterparts. On further analysis, we find that learning dynamic prompts
conditioned on Textual Class Information (TCI) is the key to solving the BNT
problem. Motivated by this, we then propose Class-adaptive Prompt Tuning
(CaPT), which enables fast adaptation of tuned models to new classes by
learning TCI-conditioned prompts from base classes. Remarkably, CaPT can be
used as a plugin to mitigate the BNT problem for existing unconditional PT
schemes. Extensive experiments on 11 datasets show that CaPT consistently
improves the performance of five strong unconditional PT baselines with
negligible additional computational cost. Additionally, by integrating CaPT
with our recently proposed DePT framework, we devise a new conditional PT
approach, termed DeCaPT, which outperforms the H ACC of the state-of-the-art
conditional PT scheme by 3.49%, averaged over the 11 datasets. Code:
https://github.com/Koorye/CaPT.

</details>


### [331] [VMoBA: Mixture-of-Block Attention for Video Diffusion Models](https://arxiv.org/abs/2506.23858)
*Jianzong Wu,Liang Hou,Haotian Yang,Xin Tao,Ye Tian,Pengfei Wan,Di Zhang,Yunhai Tong*

Main category: cs.CV

TL;DR: VMoBA是一种针对视频扩散模型的稀疏注意力机制，通过动态块分区和全局块选择优化计算效率，显著提升训练和推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决视频扩散模型中全注意力机制的高计算复杂度问题，同时优化对视频时空特性的捕捉。

Method: 引入VMoBA，结合动态块分区（1D-2D-3D）、全局块选择和基于阈值的块选择，优化稀疏注意力机制。

Result: 训练速度提升2.92倍FLOPs和1.48倍延迟，推理速度提升2.40倍FLOPs和1.35倍延迟，生成质量与全注意力相当或更优。

Conclusion: VMoBA显著提升了视频扩散模型的效率，适用于长序列和高分辨率视频生成。

Abstract: The quadratic complexity of full attention mechanisms poses a significant
bottleneck for Video Diffusion Models (VDMs) aiming to generate long-duration,
high-resolution videos. While various sparse attention methods have been
proposed, many are designed as training-free inference accelerators or do not
optimally capture the unique spatio-temporal characteristics inherent in video
data when trained natively. This paper introduces Video Mixture of Block
Attention (VMoBA), a novel sparse attention mechanism specifically adapted for
VDMs. Motivated by an in-depth analysis of attention patterns within
pre-trained video transformers, which revealed strong spatio-temporal locality,
varying query importance, and head-specific concentration levels, VMoBA
enhances the original MoBA framework with three key modifications: (1) a
layer-wise recurrent block partition scheme (1D-2D-3D) to dynamically adapt to
diverse spatio-temporal attention patterns and improve efficiency; (2) global
block selection to prioritize the most salient query-key block interactions
across an entire attention head; and (3) threshold-based block selection to
dynamically determine the number of attended blocks based on their cumulative
similarity. Extensive experiments demonstrate that VMoBA significantly
accelerates the training of VDMs on longer sequences, achieving 2.92x FLOPs and
1.48x latency speedup, while attaining comparable or even superior generation
quality to full attention. Furthermore, VMoBA exhibits competitive performance
in training-free inference, offering 2.40x FLOPs and 1.35x latency speedup for
high-res video generation.

</details>


### [332] [Puzzles: Unbounded Video-Depth Augmentation for Scalable End-to-End 3D Reconstruction](https://arxiv.org/abs/2506.23863)
*Jiahao Ma,Lei Wang,Miaomiao liu,David Ahmedt-Aristizabal,Chuong Nguyen*

Main category: cs.CV

TL;DR: Puzzles是一种数据增强策略，通过单张图像或视频片段合成大量高质量的视频-深度数据，显著提升3D重建模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多视角3D重建中训练数据多样性和规模不足的问题。

Method: 通过模拟多样化的相机轨迹和场景几何，合成高质量数据。

Result: 仅使用10%原始数据加Puzzles增强，性能与完整数据集相当。

Conclusion: Puzzles是一种高效的数据增强方法，无需修改网络架构即可提升性能。

Abstract: Multi-view 3D reconstruction remains a core challenge in computer vision.
Recent methods, such as DUST3R and its successors, directly regress pointmaps
from image pairs without relying on known scene geometry or camera parameters.
However, the performance of these models is constrained by the diversity and
scale of available training data. In this work, we introduce Puzzles, a data
augmentation strategy that synthesizes an unbounded volume of high-quality
posed video-depth data from a single image or video clip. By simulating diverse
camera trajectories and realistic scene geometry through targeted image
transformations, Puzzles significantly enhances data variety. Extensive
experiments show that integrating Puzzles into existing video-based 3D
reconstruction pipelines consistently boosts performance without modifying the
underlying network architecture. Notably, models trained on only ten percent of
the original data augmented with Puzzles still achieve accuracy comparable to
those trained on the full dataset. Code is available at
https://jiahao-ma.github.io/puzzles/.

</details>


### [333] [Spurious-Aware Prototype Refinement for Reliable Out-of-Distribution Detection](https://arxiv.org/abs/2506.23881)
*Reihaneh Zohrabi,Hosein Hasani,Mahdieh Soleymani Baghshah,Anna Rohrbach,Marcus Rohrbach,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: SPROD是一种新型原型OOD检测方法，通过优化类别原型减少伪相关性的影响，无需额外数据或调参，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有OOD检测方法易受伪相关性误导，影响模型鲁棒性，需改进。

Method: 提出SPROD方法，通过后处理优化类别原型，减少伪相关性带来的偏差。

Result: 在多个数据集上表现优异，AUROC提升4.7%，FPR@95降低9.3%。

Conclusion: SPROD有效解决伪相关性对OOD检测的影响，具有广泛适用性和高性能。

Abstract: Out-of-distribution (OOD) detection is crucial for ensuring the reliability
and safety of machine learning models in real-world applications, where they
frequently face data distributions unseen during training. Despite progress,
existing methods are often vulnerable to spurious correlations that mislead
models and compromise robustness. To address this, we propose SPROD, a novel
prototype-based OOD detection approach that explicitly addresses the challenge
posed by unknown spurious correlations. Our post-hoc method refines class
prototypes to mitigate bias from spurious features without additional data or
hyperparameter tuning, and is broadly applicable across diverse backbones and
OOD detection settings. We conduct a comprehensive spurious correlation OOD
detection benchmarking, comparing our method against existing approaches and
demonstrating its superior performance across challenging OOD datasets, such as
CelebA, Waterbirds, UrbanCars, Spurious Imagenet, and the newly introduced
Animals MetaCoCo. On average, SPROD improves AUROC by 4.7% and FPR@95 by 9.3%
over the second best.

</details>


### [334] [PriOr-Flow: Enhancing Primitive Panoramic Optical Flow with Orthogonal View](https://arxiv.org/abs/2506.23897)
*Longliang Liu,Miaojie Feng,Junda Cheng,Jijun Xiang,Xuan Zhu,Xin Yang*

Main category: cs.CV

TL;DR: PriOr-Flow是一种新颖的双分支框架，通过正交视图的低失真特性提升全景光流估计性能，特别是在极地区域。


<details>
  <summary>Details</summary>
Motivation: 传统基于透视的光流方法在全景投影（如ERP）中因严重失真而性能下降，尤其是在极地区域。

Method: 提出PriOr-Flow框架，结合DCCL算子和ODDC模块，从原始和正交成本卷中联合检索信息并迭代优化运动特征。

Result: PriOr-Flow在公开全景光流数据集上表现优异，兼容多种透视迭代光流方法，达到最先进水平。

Conclusion: PriOr-Flow为宽视场运动估计设定了新基准，代码已开源。

Abstract: Panoramic optical flow enables a comprehensive understanding of temporal
dynamics across wide fields of view. However, severe distortions caused by
sphere-to-plane projections, such as the equirectangular projection (ERP),
significantly degrade the performance of conventional perspective-based optical
flow methods, especially in polar regions. To address this challenge, we
propose PriOr-Flow, a novel dual-branch framework that leverages the
low-distortion nature of the orthogonal view to enhance optical flow estimation
in these regions. Specifically, we introduce the Dual-Cost Collaborative Lookup
(DCCL) operator, which jointly retrieves correlation information from both the
primitive and orthogonal cost volumes, effectively mitigating distortion noise
during cost volume construction. Furthermore, our Ortho-Driven Distortion
Compensation (ODDC) module iteratively refines motion features from both
branches, further suppressing polar distortions. Extensive experiments
demonstrate that PriOr-Flow is compatible with various perspective-based
iterative optical flow methods and consistently achieves state-of-the-art
performance on publicly available panoramic optical flow datasets, setting a
new benchmark for wide-field motion estimation. The code is publicly available
at: https://github.com/longliangLiu/PriOr-Flow.

</details>


### [335] [Three-dimensional end-to-end deep learning for brain MRI analysis](https://arxiv.org/abs/2506.23916)
*Radhika Juglan,Marta Ligero,Zunamys I. Carrero,Asier Rabasco,Tim Lenz,Leo Misera,Gregory Patrick Veldhuizen,Paul Kuntke,Hagen H. Kitzler,Sven Nebelung,Daniel Truhn,Jakob Nikolas Kather*

Main category: cs.CV

TL;DR: 研究发现，在脑影像分析中，简单的卷积网络（SFCN）比复杂的注意力架构（如Swin Transformer）表现更好，具有更强的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在脑影像分析中表现优异，但其在不同影像队列中的泛化能力尚未充分评估。年龄和性别是临床神经科学中的重要生物标志物，因此本研究评估了三种3D架构在年龄和性别预测中的表现。

Method: 研究评估了三种3D架构（SFCN、DenseNet和Swin Transformer）在四个独立队列（UKB、DLBS、PPMI和IXI）中的T1加权MRI数据上的表现，用于年龄和性别预测。

Result: SFCN在性别分类和年龄预测任务中均表现最佳，其AUC和MAE指标优于其他复杂架构。统计测试进一步证实了SFCN的优越性。

Conclusion: 简单的卷积网络在脑影像分析中优于复杂架构，展示了更好的跨数据集泛化能力。

Abstract: Deep learning (DL) methods are increasingly outperforming classical
approaches in brain imaging, yet their generalizability across diverse imaging
cohorts remains inadequately assessed. As age and sex are key neurobiological
markers in clinical neuroscience, influencing brain structure and disease risk,
this study evaluates three of the existing three-dimensional architectures,
namely Simple Fully Connected Network (SFCN), DenseNet, and Shifted Window
(Swin) Transformers, for age and sex prediction using T1-weighted MRI from four
independent cohorts: UK Biobank (UKB, n=47,390), Dallas Lifespan Brain Study
(DLBS, n=132), Parkinson's Progression Markers Initiative (PPMI, n=108 healthy
controls), and Information eXtraction from Images (IXI, n=319). We found that
SFCN consistently outperformed more complex architectures with AUC of 1.00
[1.00-1.00] in UKB (internal test set) and 0.85-0.91 in external test sets for
sex classification. For the age prediction task, SFCN demonstrated a mean
absolute error (MAE) of 2.66 (r=0.89) in UKB and 4.98-5.81 (r=0.55-0.70) across
external datasets. Pairwise DeLong and Wilcoxon signed-rank tests with
Bonferroni corrections confirmed SFCN's superiority over Swin Transformer
across most cohorts (p<0.017, for three comparisons). Explainability analysis
further demonstrates the regional consistency of model attention across cohorts
and specific to each task. Our findings reveal that simpler convolutional
networks outperform the denser and more complex attention-based DL
architectures in brain image analysis by demonstrating better generalizability
across different datasets.

</details>


### [336] [Thinking with Images for Multimodal Reasoning: Foundations, Methods, and Future Frontiers](https://arxiv.org/abs/2506.23918)
*Zhaochen Su,Peng Xia,Hangyu Guo,Zhenhua Liu,Yan Ma,Xiaoye Qu,Jiaqi Liu,Yanshu Li,Kaide Zeng,Zhengyuan Yang,Linjie Li,Yu Cheng,Heng Ji,Junxian He,Yi R.,Fung*

Main category: cs.CV

TL;DR: 论文探讨了多模态推理中的新范式——利用视觉信息作为思维过程的中间步骤，从静态输入转变为动态认知工具，并提出了三阶段框架。


<details>
  <summary>Details</summary>
Motivation: 解决文本链式思维（CoT）在处理视觉信息时的语义鸿沟问题，推动AI从‘思考图像’到‘用图像思考’的范式转变。

Method: 提出了三阶段框架：外部工具探索、程序化操作和内在想象，并综述了各阶段的核心方法、评估基准和应用。

Result: 确立了‘用图像思考’范式的基本原则，分析了当前研究的关键挑战和未来方向。

Conclusion: 通过结构化概述，为未来多模态AI研究提供了清晰的路线图，以实现更强大且与人类认知对齐的智能系统。

Abstract: Recent progress in multimodal reasoning has been significantly advanced by
textual Chain-of-Thought (CoT), a paradigm where models conduct reasoning
within language. This text-centric approach, however, treats vision as a
static, initial context, creating a fundamental "semantic gap" between rich
perceptual data and discrete symbolic thought. Human cognition often transcends
language, utilizing vision as a dynamic mental sketchpad. A similar evolution
is now unfolding in AI, marking a fundamental paradigm shift from models that
merely think about images to those that can truly think with images. This
emerging paradigm is characterized by models leveraging visual information as
intermediate steps in their thought process, transforming vision from a passive
input into a dynamic, manipulable cognitive workspace. In this survey, we chart
this evolution of intelligence along a trajectory of increasing cognitive
autonomy, which unfolds across three key stages: from external tool
exploration, through programmatic manipulation, to intrinsic imagination. To
structure this rapidly evolving field, our survey makes four key contributions.
(1) We establish the foundational principles of the think with image paradigm
and its three-stage framework. (2) We provide a comprehensive review of the
core methods that characterize each stage of this roadmap. (3) We analyze the
critical landscape of evaluation benchmarks and transformative applications.
(4) We identify significant challenges and outline promising future directions.
By providing this structured overview, we aim to offer a clear roadmap for
future research towards more powerful and human-aligned multimodal AI.

</details>


### [337] [Evaluating the Impact of Khmer Font Types on Text Recognition](https://arxiv.org/abs/2506.23963)
*Vannkinh Nom,Souhail Bakkali,Muhammad Muzzamil Luqman,Mickael Coustaty,Jean-Marc Ogier*

Main category: cs.CV

TL;DR: 研究评估了19种高棉字体对OCR准确率的影响，发现某些字体表现优异，而另一些较差，强调了字体选择对高棉文本识别的重要性。


<details>
  <summary>Details</summary>
Motivation: 高棉字体多样性及其独特字符结构对OCR系统提出了挑战，研究旨在评估不同字体对文本识别准确率的影响。

Method: 使用Pytesseract对19种随机选择的高棉字体进行OCR性能评估。

Result: Khmer、Odor MeanChey、Siemreap、Sithi Manuss和Battambang字体表现优异，而iSeth First、Bayon和Dangrek表现较差。

Conclusion: 字体选择对高棉文本识别至关重要，研究结果为开发更鲁棒的OCR系统提供了参考。

Abstract: Text recognition is significantly influenced by font types, especially for
complex scripts like Khmer. The variety of Khmer fonts, each with its unique
character structure, presents challenges for optical character recognition
(OCR) systems. In this study, we evaluate the impact of 19 randomly selected
Khmer font types on text recognition accuracy using Pytesseract. The fonts
include Angkor, Battambang, Bayon, Bokor, Chenla, Dangrek, Freehand, Kh Kompong
Chhnang, Kh SN Kampongsom, Khmer, Khmer CN Stueng Songke, Khmer Savuth Pen,
Metal, Moul, Odor MeanChey, Preah Vihear, Siemreap, Sithi Manuss, and iSeth
First. Our comparison of OCR performance across these fonts reveals that Khmer,
Odor MeanChey, Siemreap, Sithi Manuss, and Battambang achieve high accuracy,
while iSeth First, Bayon, and Dangrek perform poorly. This study underscores
the critical importance of font selection in optimizing Khmer text recognition
and provides valuable insights for developing more robust OCR systems.

</details>


### [338] [Visual and Memory Dual Adapter for Multi-Modal Object Tracking](https://arxiv.org/abs/2506.23972)
*Boyue Xu,Ruichao Hou,Tongwei Ren,Gangshan Wu*

Main category: cs.CV

TL;DR: 提出了一种新颖的视觉和记忆双重适配器（VMDA），通过联合建模频率、空间和通道特征，以及利用人类记忆机制存储全局时序信息，提升了多模态跟踪的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因未能充分利用频率和时序域的关键线索而难以学习可靠的提示，限制了多模态跟踪的性能。

Method: 设计了视觉适配器和记忆适配器，前者自适应地将辅助模态的判别性线索传递到主导模态，后者存储全局时序信息并进行动态更新和检索。

Result: 在RGB-Thermal、RGB-Depth和RGB-Event等多种多模态跟踪任务中实现了最先进的性能。

Conclusion: VMDA通过结合视觉和记忆适配器，显著提升了多模态跟踪的鲁棒性和判别性。

Abstract: Prompt-learning-based multi-modal trackers have achieved promising progress
by employing lightweight visual adapters to incorporate auxiliary modality
features into frozen foundation models. However, existing approaches often
struggle to learn reliable prompts due to limited exploitation of critical cues
across frequency and temporal domains. In this paper, we propose a novel visual
and memory dual adapter (VMDA) to construct more robust and discriminative
representations for multi-modal tracking. Specifically, we develop a simple but
effective visual adapter that adaptively transfers discriminative cues from
auxiliary modality to dominant modality by jointly modeling the frequency,
spatial, and channel-wise features. Additionally, we design the memory adapter
inspired by the human memory mechanism, which stores global temporal cues and
performs dynamic update and retrieval operations to ensure the consistent
propagation of reliable temporal information across video sequences. Extensive
experiments demonstrate that our method achieves state-of-the-art performance
on the various multi-modal tracking tasks, including RGB-Thermal, RGB-Depth,
and RGB-Event tracking. Code and models are available at
https://github.com/xuboyue1999/mmtrack.git.

</details>


### [339] [Toward Simple and Robust Contrastive Explanations for Image Classification by Leveraging Instance Similarity and Concept Relevance](https://arxiv.org/abs/2506.23975)
*Yuliia Kaidashova,Bettina Finzel,Ute Schmid*

Main category: cs.CV

TL;DR: 论文提出了一种基于概念的对比解释方法，用于图像分类模型，通过分析实例嵌入的相似性和概念相关性，生成解释并评估其复杂性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决分类模型为何对某些输入实例偏好某一类的问题，提升模型的可解释性和鲁棒性。

Method: 利用微调深度学习模型提取概念及其相关性分数，计算相似实例的对比，并基于解释复杂性进行评估。

Result: 高相关性的概念生成更简短的解释，低相关性则生成更复杂的解释；解释在不同图像增强下表现出不同程度的鲁棒性。

Conclusion: 研究为构建更可解释和鲁棒的AI系统提供了潜在方向。

Abstract: Understanding why a classification model prefers one class over another for
an input instance is the challenge of contrastive explanation. This work
implements concept-based contrastive explanations for image classification by
leveraging the similarity of instance embeddings and relevance of
human-understandable concepts used by a fine-tuned deep learning model. Our
approach extracts concepts with their relevance score, computes contrasts for
similar instances, and evaluates the resulting contrastive explanations based
on explanation complexity. Robustness is tested for different image
augmentations. Two research questions are addressed: (1) whether explanation
complexity varies across different relevance ranges, and (2) whether
explanation complexity remains consistent under image augmentations such as
rotation and noise. The results confirm that for our experiments higher concept
relevance leads to shorter, less complex explanations, while lower relevance
results in longer, more diffuse explanations. Additionally, explanations show
varying degrees of robustness. The discussion of these findings offers insights
into the potential of building more interpretable and robust AI systems.

</details>


### [340] [StyleDrive: Towards Driving-Style Aware Benchmarking of End-To-End Autonomous Driving](https://arxiv.org/abs/2506.23982)
*Ruiyang Hao,Bowen Jing,Haibao Yu,Zaiqing Nie*

Main category: cs.CV

TL;DR: 论文提出了首个大规模真实世界数据集，用于端到端自动驾驶（E2EAD）中的个性化研究，并通过视觉语言模型（VLM）和人工验证生成高质量标注。基于此数据集，论文建立了首个个性化E2EAD评估基准，展示了偏好条件化对模型行为的改进。


<details>
  <summary>Details</summary>
Motivation: 个性化在传统自动驾驶系统中已有研究，但在端到端自动驾驶（E2EAD）中却被忽视，而用户对齐行为对信任和广泛采用至关重要。缺乏标注多样化驾驶偏好的大规模数据集是主要障碍。

Method: 通过提取静态环境特征和动态上下文线索（使用VLM），构建一致且细粒度的场景。通过行为分布分析和规则启发式生成客观偏好标注，并利用VLM生成主观标注，最终通过人工验证融合两者。

Result: 提出的数据集和评估基准显示，结合个性化偏好的模型行为更符合人类驾驶风格。

Conclusion: 该工作为个性化E2EAD奠定了基础，提供了标准化平台，推动以人为中心的自动驾驶研究。

Abstract: While personalization has been explored in traditional autonomous driving
systems, it remains largely overlooked in end-to-end autonomous driving
(E2EAD), despite its growing prominence. This gap is critical, as user-aligned
behavior is essential for trust, comfort, and widespread adoption of autonomous
vehicles. A core challenge is the lack of large-scale real-world datasets
annotated with diverse and fine-grained driving preferences, hindering the
development and evaluation of personalized E2EAD models. In this work, we
present the first large-scale real-world dataset enriched with annotations
capturing diverse driving preferences, establishing a foundation for
personalization in E2EAD. We extract static environmental features from
real-world road topology and infer dynamic contextual cues using a fine-tuned
visual language model (VLM), enabling consistent and fine-grained scenario
construction. Based on these scenarios, we derive objective preference
annotations through behavioral distribution analysis and rule-based heuristics.
To address the inherent subjectivity of driving style, we further employ the
VLM to generate subjective annotations by jointly modeling scene semantics and
driver behavior. Final high-quality labels are obtained through a
human-in-the-loop verification process that fuses both perspectives. Building
on this dataset, we propose the first benchmark for evaluating personalized
E2EAD models. We assess several state-of-the-art models with and without
preference conditioning, demonstrating that incorporating personalized
preferences results in behavior more aligned with human driving. Our work lays
the foundation for personalized E2EAD by providing a standardized platform to
systematically integrate human preferences into data-driven E2EAD systems,
catalyzing future research in human-centric autonomy.

</details>


### [341] [Foundation Models for Zero-Shot Segmentation of Scientific Images without AI-Ready Data](https://arxiv.org/abs/2506.24039)
*Shubhabrata Mukherjee,Jack Lang,Obeen Kwon,Iryna Zenyuk,Valerie Brogden,Adam Weber,Daniela Ushizima*

Main category: cs.CV

TL;DR: Zenesis是一个无需代码的交互式平台，通过多模态适应技术和人机协作优化，显著提升了科学图像分析的准确性，尤其在稀缺数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决零样本和提示技术在稀缺科学图像数据上的局限性，降低数据准备的门槛。

Method: 开发轻量级多模态适应技术，支持零样本操作，并结合人机协作和启发式时间增强。

Result: 在FIB-SEM数据上，Zenesis的平均准确率达到0.947（非晶样本）和0.987（晶体样本），显著优于传统和先进方法。

Conclusion: Zenesis是科学图像分析的高效工具，特别适用于缺乏高质量标注数据的领域。

Abstract: Zero-shot and prompt-based technologies capitalized on using frequently
occurring images to transform visual reasoning tasks, which explains why such
technologies struggle with valuable yet scarce scientific image sets. In this
work, we propose Zenesis, a comprehensive no-code interactive platform designed
to minimize barriers posed by data readiness for scientific images. We develop
lightweight multi-modal adaptation techniques that enable zero-shot operation
on raw scientific data, along with human-in-the-loop refinement and
heuristic-based temporal enhancement options. We demonstrate the performance of
our approach through comprehensive comparison and validation on challenging
Focused Ion Beam Scanning Electron Microscopy (FIB-SEM) data of catalyst-loaded
membranes. Zenesis significantly outperforms baseline methods, achieving an
average accuracy of 0.947, an Intersection over Union (IOU) of 0.858, and a
Dice score of 0.923 for amorphous catalyst samples and accuracy of 0.987, an
IOU of 0.857, and a Dice score of 0.923 for crystalline samples. These results
mark a substantial improvement over traditional methods like Otsu thresholding
and even advanced models like Segment Anything Model (SAM) when used in
isolation. Our results demonstrate that Zenesis is a powerful tool for
scientific applications, particularly in fields where high-quality annotated
datasets are unavailable, accelerating accurate analysis of experimental
imaging.

</details>


### [342] [Continual Adaptation: Environment-Conditional Parameter Generation for Object Detection in Dynamic Scenarios](https://arxiv.org/abs/2506.24063)
*Deng Li,Aming Wu,Yang Li,Yaowei Wang,Yahong Han*

Main category: cs.CV

TL;DR: 论文提出了一种新的持续测试时适应机制，通过参数生成而非微调来提升目标检测器的泛化能力，避免了性能下降。


<details>
  <summary>Details</summary>
Motivation: 现实环境中数据分布不断变化，传统基于封闭集假设的目标检测器难以适应，需要一种更高效的适应方法。

Method: 设计了双路径LoRA域感知适配器，结合条件扩散参数生成机制和类中心最优传输对齐方法。

Result: 在多种连续域自适应目标检测任务中表现优异，生成的参数能更好地捕捉目标信息。

Conclusion: 该方法有效提升了检测器的适应能力和泛化性能，避免了局部最优和灾难性遗忘。

Abstract: In practice, environments constantly change over time and space, posing
significant challenges for object detectors trained based on a closed-set
assumption, i.e., training and test data share the same distribution. To this
end, continual test-time adaptation has attracted much attention, aiming to
improve detectors' generalization by fine-tuning a few specific parameters,
e.g., BatchNorm layers. However, based on a small number of test images,
fine-tuning certain parameters may affect the representation ability of other
fixed parameters, leading to performance degradation. Instead, we explore a new
mechanism, i.e., converting the fine-tuning process to a specific-parameter
generation. Particularly, we first design a dual-path LoRA-based domain-aware
adapter that disentangles features into domain-invariant and domain-specific
components, enabling efficient adaptation. Additionally, a conditional
diffusion-based parameter generation mechanism is presented to synthesize the
adapter's parameters based on the current environment, preventing the
optimization from getting stuck in local optima. Finally, we propose a
class-centered optimal transport alignment method to mitigate catastrophic
forgetting. Extensive experiments conducted on various continuous domain
adaptive object detection tasks demonstrate the effectiveness. Meanwhile,
visualization results show that the representation extracted by the generated
parameters can capture more object-related information and strengthen the
generalization ability.

</details>


### [343] [WaRA: Wavelet Low Rank Adaptation](https://arxiv.org/abs/2506.24092)
*Moein Heidari,Yasamin Medghalchi,Mahdi Khoursha,Reza Rezaeian,Ilker Hacihaliloglu*

Main category: cs.CV

TL;DR: WaRA是一种基于小波变换的参数高效微调方法，通过多分辨率分析改进LoRA，在视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法（如LoRA）依赖全局低秩分解，忽略了局部或多尺度结构，无法捕捉权重更新的复杂模式。

Method: WaRA利用小波变换将权重更新矩阵分解为多分辨率表示，在频域进行低秩分解并通过逆变换重建更新。

Result: WaRA在图像生成、分类和语义分割等任务中表现优于现有方法，同时降低计算复杂度。

Conclusion: WaRA不仅适用于视觉任务，还可推广至语言任务，具有广泛适用性。

Abstract: Parameter-efficient fine-tuning (PEFT) has gained widespread adoption across
various applications. Among PEFT techniques, Low-Rank Adaptation (LoRA) and its
extensions have emerged as particularly effective, allowing efficient model
adaptation while significantly reducing computational overhead. However,
existing approaches typically rely on global low-rank factorizations, which
overlook local or multi-scale structure, failing to capture complex patterns in
the weight updates. To address this, we propose WaRA, a novel PEFT method that
leverages wavelet transforms to decompose the weight update matrix into a
multi-resolution representation. By performing low-rank factorization in the
wavelet domain and reconstructing updates through an inverse transform, WaRA
obtains compressed adaptation parameters that harness multi-resolution
analysis, enabling it to capture both coarse and fine-grained features while
providing greater flexibility and sparser representations than standard LoRA.
Through comprehensive experiments and analysis, we demonstrate that WaRA
performs superior on diverse vision tasks, including image generation,
classification, and semantic segmentation, significantly enhancing generated
image quality while reducing computational complexity. Although WaRA was
primarily designed for vision tasks, we further showcase its effectiveness in
language tasks, highlighting its broader applicability and generalizability.
The code is publicly available at
\href{GitHub}{https://github.com/moeinheidari7829/WaRA}.

</details>


### [344] [MILo: Mesh-In-the-Loop Gaussian Splatting for Detailed and Efficient Surface Reconstruction](https://arxiv.org/abs/2506.24096)
*Antoine Guédon,Diego Gomez,Nissim Maruani,Bingchen Gong,George Drettakis,Maks Ovsjanikov*

Main category: cs.CV

TL;DR: MILo是一种新型高斯泼溅框架，通过可微分地从3D高斯中提取网格，解决了从体积到表面表示的转换问题，保留了训练中捕获的几何细节。


<details>
  <summary>Details</summary>
Motivation: 当前方法通过昂贵的后处理步骤提取表面，导致几何细节丢失或生成过于密集的网格。MILo旨在直接在训练过程中构建网格，避免后处理问题。

Method: 设计了一个完全可微分的过程，从高斯参数中直接构建网格（顶点和连接性），并引入了双向一致性框架、自适应网格提取和基于高斯的符号距离计算方法。

Result: MILo能够以最先进的质量重建完整场景，且所需的网格顶点数量比之前方法少一个数量级，适合下游应用。

Conclusion: MILo通过可微分网格提取，成功保留了训练中的几何结构，提供了一种轻量且高效的表面表示方法。

Abstract: While recent advances in Gaussian Splatting have enabled fast reconstruction
of high-quality 3D scenes from images, extracting accurate surface meshes
remains a challenge. Current approaches extract the surface through costly
post-processing steps, resulting in the loss of fine geometric details or
requiring significant time and leading to very dense meshes with millions of
vertices. More fundamentally, the a posteriori conversion from a volumetric to
a surface representation limits the ability of the final mesh to preserve all
geometric structures captured during training. We present MILo, a novel
Gaussian Splatting framework that bridges the gap between volumetric and
surface representations by differentiably extracting a mesh from the 3D
Gaussians. We design a fully differentiable procedure that constructs the
mesh-including both vertex locations and connectivity-at every iteration
directly from the parameters of the Gaussians, which are the only quantities
optimized during training. Our method introduces three key technical
contributions: a bidirectional consistency framework ensuring both
representations-Gaussians and the extracted mesh-capture the same underlying
geometry during training; an adaptive mesh extraction process performed at each
training iteration, which uses Gaussians as differentiable pivots for Delaunay
triangulation; a novel method for computing signed distance values from the 3D
Gaussians that enables precise surface extraction while avoiding geometric
erosion. Our approach can reconstruct complete scenes, including backgrounds,
with state-of-the-art quality while requiring an order of magnitude fewer mesh
vertices than previous methods. Due to their light weight and empty interior,
our meshes are well suited for downstream applications such as physics
simulations or animation.

</details>


### [345] [DenseWorld-1M: Towards Detailed Dense Grounded Caption in the Real World](https://arxiv.org/abs/2506.24102)
*Xiangtai Li,Tao Zhang,Yanwei Li,Haobo Yuan,Shihao Chen,Yikang Zhou,Jiahao Meng,Yueyi Sun,Shilin Xu,Lu Qi,Tianheng Cheng,Yi Lin,Zilong Huang,Wenhao Huang,Jiashi Feng,Guang Shi*

Main category: cs.CV

TL;DR: DenseWorld-1M是一个大规模、详细且密集的接地标注数据集，填补了现有数据集的不足，并通过三阶段标注流程和两个VLM模型提升了标注效率和质量。


<details>
  <summary>Details</summary>
Motivation: 现有标注数据集缺乏对视觉实体的详细描述和关系标注，尤其是在高分辨率图像上。

Method: 采用三阶段标注流程（开放世界感知、详细对象标注生成、密集标注合并）和两个VLM模型（Detailed Region Caption模型和Spatial Caption Merging模型）。

Result: DenseWorld-1M在多种任务（如视觉语言理解、视觉接地和区域标注生成）中表现出色。

Conclusion: DenseWorld-1M及其标注模型为社区提供了一个高质量的数据集和高效的标注方法。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate a complex understanding
of scenes, benefiting from large-scale and high-quality datasets. Most existing
caption datasets lack the ground locations and relations for visual entities.
Several grounded caption datasets face the problems of missing detailed
descriptions, relations, and massive object descriptions on high-resolution
images. To fill this gap for the community, we present DenseWorld-1M, the first
massive, detailed, dense grounded caption dataset in the real world. We design
a three-stage labeling pipeline, containing open-world perception, detailed
object caption generation, and dense caption merging. The first stage obtains
entity-level masks and labels. The second stage generates the object-level,
detailed captions with the guidance of masks and labels from the first stage.
The final stage merges object captions and masks into spatial and relational
dense captions. To accelerate the labeling process and improve caption quality,
we present two VLM models: the Detailed Region Caption model and the Spatial
Caption Merging model. Extensive experiments on various settings, including
vision-language understanding, visual grounding, and region caption generation,
demonstrate the effectiveness of our DenseWorld-1M dataset and labeling models.

</details>


### [346] [Epona: Autoregressive Diffusion World Model for Autonomous Driving](https://arxiv.org/abs/2506.24113)
*Kaiwen Zhang,Zhenyu Tang,Xiaotao Hu,Xingang Pan,Xiaoyang Guo,Yuan Liu,Jingwei Huang,Li Yuan,Qian Zhang,Xiao-Xiao Long,Xun Cao,Wei Yin*

Main category: cs.CV

TL;DR: Epona是一个自回归扩散世界模型，通过解耦时空因子化和模块化轨迹与视频预测，实现了局部时空分布建模，显著提升了自动驾驶世界建模的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频扩散的世界模型在灵活长度、长时程预测和轨迹规划整合方面表现不佳，Epona旨在解决这些问题。

Method: 提出两种创新：1) 解耦时空因子化，分离时间动态建模与细粒度未来世界生成；2) 模块化轨迹与视频预测，将运动规划与视觉建模无缝整合。

Result: 实验显示，Epona在FVD指标上提升了7.4%，预测时长显著延长，并在NAVSIM基准测试中优于端到端规划器。

Conclusion: Epona在自动驾驶世界建模中表现出色，兼具高分辨率和长时程生成能力，同时可作为实时运动规划器。

Abstract: Diffusion models have demonstrated exceptional visual quality in video
generation, making them promising for autonomous driving world modeling.
However, existing video diffusion-based world models struggle with
flexible-length, long-horizon predictions and integrating trajectory planning.
This is because conventional video diffusion models rely on global joint
distribution modeling of fixed-length frame sequences rather than sequentially
constructing localized distributions at each timestep. In this work, we propose
Epona, an autoregressive diffusion world model that enables localized
spatiotemporal distribution modeling through two key innovations: 1) Decoupled
spatiotemporal factorization that separates temporal dynamics modeling from
fine-grained future world generation, and 2) Modular trajectory and video
prediction that seamlessly integrate motion planning with visual modeling in an
end-to-end framework. Our architecture enables high-resolution, long-duration
generation while introducing a novel chain-of-forward training strategy to
address error accumulation in autoregressive loops. Experimental results
demonstrate state-of-the-art performance with 7.4\% FVD improvement and minutes
longer prediction duration compared to prior works. The learned world model
further serves as a real-time motion planner, outperforming strong end-to-end
planners on NAVSIM benchmarks. Code will be publicly available at
\href{https://github.com/Kevin-thu/Epona/}{https://github.com/Kevin-thu/Epona/}.

</details>


### [347] [TextMesh4D: High-Quality Text-to-4D Mesh Generation](https://arxiv.org/abs/2506.24121)
*Sisi Dai,Xinxin Su,Boyan Wan,Ruizhen Hu,Kai Xu*

Main category: cs.CV

TL;DR: TextMesh4D是一个新颖的框架，用于高质量文本到4D生成，通过两阶段分解和正则化优化实现动态3D内容生成。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散生成模型在图像、视频和3D内容生成上取得进展，但动态3D内容生成（文本到4D）仍未被充分探索。

Method: 使用基于面的Jacobian作为可微网格表示，将4D生成分为静态对象创建和动态运动合成两阶段，并引入灵活性-刚性正则化项。

Result: 实验表明，TextMesh4D在时间一致性、结构保真度和视觉真实感上达到最优，且仅需单24GB GPU。

Conclusion: TextMesh4D为文本驱动的4D网格生成提供了高效且高质量的解决方案，代码将开源以推动未来研究。

Abstract: Recent advancements in diffusion generative models significantly advanced
image, video, and 3D content creation from user-provided text prompts. However,
the challenging problem of dynamic 3D content generation (text-to-4D) with
diffusion guidance remains largely unexplored. In this paper, we introduce
TextMesh4D, a novel framework for high-quality text-to-4D generation. Our
approach leverages per-face Jacobians as a differentiable mesh representation
and decomposes 4D generation into two stages: static object creation and
dynamic motion synthesis. We further propose a flexibility-rigidity
regularization term to stabilize Jacobian optimization under video diffusion
priors, ensuring robust geometric performance. Experiments demonstrate that
TextMesh4D achieves state-of-the-art results in terms of temporal consistency,
structural fidelity, and visual realism. Moreover, TextMesh4D operates with a
low GPU memory overhead-requiring only a single 24GB GPU-offering a
cost-effective yet high-quality solution for text-driven 4D mesh generation.
The code will be released to facilitate future research in text-to-4D
generation.

</details>


### [348] [Calligrapher: Freestyle Text Image Customization](https://arxiv.org/abs/2506.24123)
*Yue Ma,Qingyan Bai,Hao Ouyang,Ka Leong Cheng,Qiuyu Wang,Hongyu Liu,Zichen Liu,Haofan Wang,Jingye Chen,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: Calligrapher是一个基于扩散的框架，结合文本定制与艺术字体，解决风格控制和数据依赖问题。


<details>
  <summary>Details</summary>
Motivation: 解决数字书法和设计中精确风格控制和数据依赖的挑战。

Method: 1. 自蒸馏机制构建风格基准；2. 可训练风格编码器提取特征；3. 上下文生成机制嵌入参考图像。

Result: 在多种字体和设计场景中准确复现风格细节和字形定位。

Conclusion: Calligrapher自动化高质量字体设计，超越传统模型，助力数字艺术和品牌设计。

Abstract: We introduce Calligrapher, a novel diffusion-based framework that
innovatively integrates advanced text customization with artistic typography
for digital calligraphy and design applications. Addressing the challenges of
precise style control and data dependency in typographic customization, our
framework incorporates three key technical contributions. First, we develop a
self-distillation mechanism that leverages the pre-trained text-to-image
generative model itself alongside the large language model to automatically
construct a style-centric typography benchmark. Second, we introduce a
localized style injection framework via a trainable style encoder, which
comprises both Qformer and linear layers, to extract robust style features from
reference images. An in-context generation mechanism is also employed to
directly embed reference images into the denoising process, further enhancing
the refined alignment of target styles. Extensive quantitative and qualitative
evaluations across diverse fonts and design contexts confirm Calligrapher's
accurate reproduction of intricate stylistic details and precise glyph
positioning. By automating high-quality, visually consistent typography,
Calligrapher surpasses traditional models, empowering creative practitioners in
digital art, branding, and contextual typographic design.

</details>


### [349] [How to Design and Train Your Implicit Neural Representation for Video Compression](https://arxiv.org/abs/2506.24127)
*Matthew Gwilliam,Roy Zhang,Namitha Padmanabhan,Hongyang Du,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 论文提出了一种改进的隐式神经表示（INR）视频压缩方法RNeRV，通过优化组件设计和引入超网络技术，显著提升了压缩质量和编码速度。


<details>
  <summary>Details</summary>
Motivation: 传统INR方法因需要逐样本训练网络导致编码速度过慢，难以实用化。本文旨在解决这一问题，同时提升压缩质量。

Method: 开发了一个库以分析NeRV家族方法的组件，提出了RNeRV配置，并引入超网络技术预测INR权重，通过掩码训练实现可变高质量压缩。

Result: RNeRV在相同训练时间下平均PSNR提升1.27%；超网络技术进一步提升了PSNR和MS-SSIM，同时保持编码速度。

Conclusion: RNeRV和超网络技术的结合显著提升了视频INR的实用性和性能，为实时编码提供了可能。

Abstract: Implicit neural representation (INR) methods for video compression have
recently achieved visual quality and compression ratios that are competitive
with traditional pipelines. However, due to the need for per-sample network
training, the encoding speeds of these methods are too slow for practical
adoption. We develop a library to allow us to disentangle and review the
components of methods from the NeRV family, reframing their performance in
terms of not only size-quality trade-offs, but also impacts on training time.
We uncover principles for effective video INR design and propose a
state-of-the-art configuration of these components, Rabbit NeRV (RNeRV). When
all methods are given equal training time (equivalent to 300 NeRV epochs) for 7
different UVG videos at 1080p, RNeRV achieves +1.27% PSNR on average compared
to the best-performing alternative for each video in our NeRV library. We then
tackle the encoding speed issue head-on by investigating the viability of
hyper-networks, which predict INR weights from video inputs, to disentangle
training from encoding to allow for real-time encoding. We propose masking the
weights of the predicted INR during training to allow for variable, higher
quality compression, resulting in 1.7% improvements to both PSNR and MS-SSIM at
0.037 bpp on the UCF-101 dataset, and we increase hyper-network parameters by
0.4% for 2.5%/2.7% improvements to PSNR/MS-SSIM with equal bpp and similar
speeds. Our project website is available at https://mgwillia.github.io/vinrb/
and our code is available at https://github.com/mgwillia/vinrb.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [350] [GaussMaster: An LLM-based Database Copilot System](https://arxiv.org/abs/2506.23322)
*Wei Zhou,Ji Sun,Xuanhe Zhou,Guoliang Li,Luyang Liu,Hao Wu,Tianyuan Wang*

Main category: cs.DB

TL;DR: GaussMaster是一个基于LLM的数据库助手系统，旨在通过自动化全面解决数据库维护问题，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有自主数据库平台功能有限，仍需人工干预，GaussMaster旨在通过自动化全面解决数据库维护问题。

Method: 采用LLM技术，结合Tree-of-thought方法分析指标和日志，自动识别问题并调用工具解决。

Result: 在银行业等实际场景中成功应用，实现了34种数据库维护场景的零人工干预。

Conclusion: GaussMaster显著提升了数据库维护的自动化水平，具有实际应用价值。

Abstract: In the financial industry, data is the lifeblood of operations, and DBAs
shoulder significant responsibilities for SQL tuning, database deployment,
diagnosis, and service repair. In recent years, both database vendors and
customers have increasingly turned to autonomous database platforms in an
effort to alleviate the heavy workload of DBAs. However, existing autonomous
database platforms are limited in their capabilities, primarily addressing
single-point issues such as NL2SQL, anomaly detection, and SQL tuning. Manual
intervention remains a necessity for comprehensive database maintenance.
GaussMaster aims to revolutionize this landscape by introducing an LLM-based
database copilot system. This innovative solution is designed not only to
assist developers in writing efficient SQL queries but also to provide
comprehensive care for database services. When database instances exhibit
abnormal behavior, GaussMaster is capable of orchestrating the entire
maintenance process automatically. It achieves this by analyzing hundreds of
metrics and logs, employing a Tree-of-thought approach to identify root causes,
and invoking appropriate tools to resolve issues. We have successfully
implemented GaussMaster in real-world scenarios, such as the banking industry,
where it has achieved zero human intervention for over 34 database maintenance
scenarios. In this paper, we present significant improvements in these tasks
with code at https://gitcode.com/opengauss/openGauss-GaussMaster.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [351] [Libra: Synergizing CUDA and Tensor Cores for High-Performance Sparse Matrix Multiplication](https://arxiv.org/abs/2506.22714)
*Jinliang Shi,Shigang Li,Youxuan Xu,Xueying Wang,Rongtian Fu,Zhi Ma,Tong Wu*

Main category: cs.DC

TL;DR: Libra提出了一种协同利用CUDA和Tensor核心的方法，优化稀疏矩阵乘法性能。


<details>
  <summary>Details</summary>
Motivation: 现代加速器中的Tensor核心和CUDA核心各有优劣，单独使用无法充分发挥性能。

Method: 提出2D感知任务分配策略，结合Tensor核心的高性能和CUDA核心的低冗余，并优化异构计算。

Result: 在H100和RTX 4090 GPU上，Libra性能优于现有技术，平均提升3.1倍。

Conclusion: Libra为稀疏算子加速提供了新思路，充分利用GPU异构计算资源。

Abstract: Sparse matrix multiplication operators (i.e., SpMM and SDDMM) are widely used
in deep learning and scientific computing. Modern accelerators are commonly
equipped with Tensor cores and CUDA cores to accelerate sparse operators. The
former brings superior computing power but only for structured matrix
multiplication, while the latter has relatively lower performance but with
higher programming flexibility. In this work, we discover that utilizing one
resource alone leads to inferior performance for sparse matrix multiplication,
due to their respective limitations. To this end, we propose Libra, a
systematic approach that enables synergistic computation between CUDA and
Tensor cores to achieve the best performance for sparse matrix multiplication.
Specifically, we propose a 2D-aware workload distribution strategy to find out
the sweet point of task mapping for different sparse operators, leveraging both
the high performance of Tensor cores and the low computational redundancy on
CUDA cores. In addition, Libra incorporates systematic optimizations for
heterogeneous computing, including hybrid load-balancing, finely optimized
kernel implementations, and GPU-accelerated preprocessing. Extensive
experimental results on H100 and RTX 4090 GPUs show that Libra outperforms the
state-of-the-art by on average 3.1x (up to 9.23x) over DTC-SpMM and 2.9x (up to
3.9x) for end-to-end GNN applications. Libra opens up a new perspective for
sparse operator acceleration by fully exploiting the heterogeneous computing
resources on GPUs.

</details>


### [352] [Not All Water Consumption Is Equal: A Water Stress Weighted Metric for Sustainable Computing](https://arxiv.org/abs/2506.22773)
*Yanran Wu,Inez Hua,Yi Ding*

Main category: cs.DC

TL;DR: SCARF框架首次通过考虑水压力的时空变化，评估计算的用水影响，提出AWI指标，并通过案例研究展示了优化选择以减少用水影响的机会。


<details>
  <summary>Details</summary>
Motivation: 随着AI工作负载的快速扩展，用水成为计算可持续性的关键问题，但现有评估常忽略水压力的时空差异。

Method: 提出SCARF框架，计算考虑时空水压力的AWI指标，并通过LLM服务、数据中心和半导体工厂三个案例验证。

Result: 案例研究表明，通过优化地点和时间选择，可以显著减少用水影响。

Conclusion: SCARF为水资源可持续计算提供了新方法，代码已开源。

Abstract: Water consumption is an increasingly critical dimension of computing
sustainability, especially as AI workloads rapidly scale. However, current
water impact assessment often overlooks where and when water stress is more
severe. To fill in this gap, we present SCARF, the first general framework that
evaluates water impact of computing by factoring in both spatial and temporal
variations in water stress. SCARF calculates an Adjusted Water Impact (AWI)
metric that considers both consumption volume and local water stress over time.
Through three case studies on LLM serving, datacenters, and semiconductor
fabrication plants, we show the hidden opportunities for reducing water impact
by optimizing location and time choices, paving the way for water-sustainable
computing. The code is available at https://github.com/jojacola/SCARF.

</details>


### [353] [TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations](https://arxiv.org/abs/2506.22818)
*Stanislav Sedukhin,Yoichi Tomioka,Kazuya Matsumoto,Yuichi Okuyama*

Main category: cs.DC

TL;DR: TriADA是一种新型算法和架构，用于高效计算三线性变换，解决了HPC和AI中高维数据的高计算和内存需求问题。


<details>
  <summary>Details</summary>
Motivation: 高维数据的计算和内存需求高，并行处理单元增加能耗，稀疏数据常见但难以高效处理。

Method: 提出三线性算法和TriADA架构，包括并行低秩算法、新型GEMM内核、分布式3D网络和ESOP方法。

Result: TriADA能高效完成三线性变换，计算复杂度为超立方，时间步线性，适合AI和HPC需求。

Conclusion: TriADA为多线性张量操作提供了高效、可扩展且节能的解决方案。

Abstract: Multilinear transformations are key in high-performance computing (HPC) and
artificial intelligence (AI) workloads, where data is represented as tensors.
However, their high computational and memory demands, which grow with
dimensionality, often slow down critical tasks. Moreover, scaling computation
by enlarging the number of parallel processing units substantially increases
energy consumption, limiting widespread adoption, especially for sparse data,
which is common in HPC and AI applications. This paper introduces the Trilinear
Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address
these challenges with the following innovations: (1) a massively parallel,
low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal
transformations (3D-DXTs), which is a special case of the more general 3-mode
matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM
kernel with decoupled streaming active memory, specially designed to accelerate
3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully
distributed 3D network of mesh interconnected processing elements or cells with
a coordinate-free, data-driven local processing activity, which is independent
of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids
unnecessary computing and communication operations with zero-valued operands,
thereby enhancing energy efficiency, computational accuracy, and stability.
TriADA is capable of performing a variety of trilinear transformations with
hypercubic arithmetic complexity in a linear number of time-steps. The
massively parallel, scalable, and energy-efficient architecture of TriADA is
ideal for accelerating multilinear tensor operations, which are the most
demanding parts of AI and HPC workloads.

</details>


### [354] [Performance Measurements in the AI-Centric Computing Continuum Systems](https://arxiv.org/abs/2506.22884)
*Praveen Kumar Donta,Qiyang Zhang,Schahram Dustdar*

Main category: cs.DC

TL;DR: 论文回顾了分布式计算连续体（DCC）中的性能指标，讨论了新兴需求如可持续性和能源效率，并提出了选择指标的准则。


<details>
  <summary>Details</summary>
Motivation: 随着计算范式向分布式架构转变，生成式AI和大语言模型的出现增加了对计算资源的需求，传统性能指标需更新以适应新需求。

Method: 回顾DCC和IoT环境中常用指标，讨论新兴性能维度如可持续性和系统可观测性。

Result: 提出了适应新计算需求的性能指标选择准则，为未来研究提供方向。

Conclusion: 更新性能指标对提升系统效率和目标对齐至关重要，未来研究应关注新兴需求。

Abstract: Over the Eight decades, computing paradigms have shifted from large,
centralized systems to compact, distributed architectures, leading to the rise
of the Distributed Computing Continuum (DCC). In this model, multiple layers
such as cloud, edge, Internet of Things (IoT), and mobile platforms work
together to support a wide range of applications. Recently, the emergence of
Generative AI and large language models has further intensified the demand for
computational resources across this continuum. Although traditional performance
metrics have provided a solid foundation, they need to be revisited and
expanded to keep pace with changing computational demands and application
requirements. Accurate performance measurements benefit both system designers
and users by supporting improvements in efficiency and promoting alignment with
system goals. In this context, we review commonly used metrics in DCC and IoT
environments. We also discuss emerging performance dimensions that address
evolving computing needs, such as sustainability, energy efficiency, and system
observability. We also outline criteria and considerations for selecting
appropriate metrics, aiming to inspire future research and development in this
critical area.

</details>


### [355] [FastSet: Parallel Claim Settlement](https://arxiv.org/abs/2506.23395)
*Xiaohong Chen,Grigore Rosu*

Main category: cs.DC

TL;DR: FastSet是一种基于参与者的分布式协议，用于去中心化金融和结算，灵感来自区块链。参与者通过声明合作，验证者验证并结算这些声明，无需相互通信。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种去中心化解决方案，保留区块链的许多优势，同时放弃强一致性要求。

Method: 参与者签署并广播声明，验证者独立验证并更新全局状态，无需相互通信。

Result: 协议被证明是正确的，尽管具有高度并行性，且保留了区块链的大部分优势。

Conclusion: FastSet提供了一种高效的去中心化协议，适用于多种场景，如金融结算、数字身份等。

Abstract: FastSet is an actor-based distributed protocol for decentralized finance and
settlement, which is inspired from blockchains. Account holders cooperate by
making claims, which can include payments, holding and transferring assets,
accessing and updating shared data, medical records, digital identity, and
mathematical theorems, among many others. The claims are signed by their owners
and are broadcast to a decentralized network of validators, which validate and
settle them. Validators replicate the global state of the accounts and need not
communicate with each other. In sharp contrast to blockchains, strong
consistency is purposely given up as a requirement. Yet, many if not most of
the blockchain benefits are preserved. The protocol is proved to be correct,
despite its massively parallel nature.

</details>


### [356] [Towards Building Private LLMs: Exploring Multi-Node Expert Parallelism on Apple Silicon for Mixture-of-Experts Large Language Model](https://arxiv.org/abs/2506.23635)
*Mu-Chi Chen,Po-Hsuan Huang,Xiangrui Ke,Chia-Heng Tu,Chun Jason Xue,Shih-Hao Hung*

Main category: cs.DC

TL;DR: 论文探讨了在私有LLM系统中构建成本效益高的解决方案，使用Mac Studio集群和M2 Ultra芯片优化DBRX模型的推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决为个人或小团体服务构建私有LLM系统时的高成本和可扩展性问题。

Method: 建立Mac Studio集群，利用M2 Ultra芯片和MoE架构加速DBRX模型，分析并行执行和网络延迟的影响，并优化内存管理。

Result: Mac Studio集群比NVIDIA H100 GPU的AI超级计算机成本效益高1.15倍，并开发了性能模型。

Conclusion: Mac Studio集群是一种高效且成本效益高的私有LLM系统解决方案，性能模型为系统设计提供了重要参考。

Abstract: Large Language Models (LLMs) have revolutionized Artificial Intelligence (AI)
with significant advancements such as OpenAI's ChatGPT, Meta's Llama, and
Databricks' DBRX. This paper addresses the cost and scalability challenges
encountered when constructing private LLM systems for personal or small group
services, as aimed by Apple Intelligence. A Mac Studio cluster with Apple's M2
Ultra chips is established as a cost-efficient solution to host and accelerate
the pretrained DBRX model with the Mixture-of-Experts (MoE) architecture. Our
performance analysis reveal that parallel execution of the model's experts
across two to four machine nodes significantly reduces inference time. We find
that computation time for the experts is comparable to the communication time
for exchanging their outputs, emphasizing the importance of network latency
over bandwidth. We also observe significant management overhead due to Apple
software stack's memory management logic. Based on these findings, we develop
optimization schemes to eliminate the memory management overhead. As a result,
the Mac Studio cluster is 1.15 times more cost-efficient than the
state-of-the-art AI supercomputer with NVIDIA H100 GPUs. In addition, we
construct a performance model to estimate system performance under varying
configurations, and the model provides valuable insights for designing private
LLM systems.

</details>


### [357] [Large-scale Neural Network Quantum States for ab initio Quantum Chemistry Simulations on Fugaku](https://arxiv.org/abs/2506.23809)
*Hongtao Xu,Zibo Wu,Mingzhen Li,Weile Jia*

Main category: cs.DC

TL;DR: 提出了一种高性能的神经网络量子态（NQS）训练框架，通过并行化策略和优化技术解决了大规模分子系统的计算瓶颈，显著提升了训练速度和效率。


<details>
  <summary>Details</summary>
Motivation: 量子多体问题是量子化学中的核心挑战，现有NQS训练方法在大规模系统中计算成本呈指数增长，限制了实际应用。

Method: 提出了可扩展的采样并行策略、多层负载划分、混合采样方案、多级并行局部能量计算，并结合缓存优化技术。

Result: 实验显示，该框架在1536个节点上实现了8.41倍的加速和95.8%的并行效率。

Conclusion: 该框架突破了NQS训练的扩展性障碍，为大规模量子化学计算提供了高效解决方案。

Abstract: Solving quantum many-body problems is one of the fundamental challenges in
quantum chemistry. While neural network quantum states (NQS) have emerged as a
promising computational tool, its training process incurs exponentially growing
computational demands, becoming prohibitively expensive for large-scale
molecular systems and creating fundamental scalability barriers for real-world
applications. To address above challenges, we present \ours, a high-performance
NQS training framework for \textit{ab initio} electronic structure
calculations. First, we propose a scalable sampling parallelism strategy with
multi-layers workload division and hybrid sampling scheme, which break the
scalability barriers for large-scale NQS training. Then, we introduce
multi-level parallelism local energy parallelism, enabling more efficient local
energy computation. Last, we employ cache-centric optimization for
transformer-based \textit{ansatz} and incorporate it with sampling parallelism
strategy, which further speedup up the NQS training and achieve stable memory
footprint at scale. Experiments demonstrate that \ours accelerate NQS training
with up to 8.41x speedup and attains a parallel efficiency up to 95.8\% when
scaling to 1,536 nodes.

</details>


### [358] [QPART: Adaptive Model Quantization and Dynamic Workload Balancing for Accuracy-aware Edge Inference](https://arxiv.org/abs/2506.23934)
*Xiangchen Li,Saeid Ghafouri,Bo Ji,Hans Vandierendonck,Deepu John,Dimitrios S. Nikolopoulos*

Main category: cs.DC

TL;DR: 论文提出了一种动态适应边缘设备计算能力的推理系统，通过联合模型量化和推理分区优化，显著降低了时间和功耗。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习推理向边缘设备转移，如何适应多样化的计算能力、硬件和内存限制成为关键问题。固定预训练模型无法满足需求，因此需要动态调整推理模式。

Method: 提出了一种精度感知且负载均衡的推理系统，结合模型量化和推理分区。服务器动态响应查询，发送量化模型并自适应分担设备负载。

Result: 仿真结果显示，计算负载减少80%以上，精度下降控制在1%以内，时间和功耗显著降低。

Conclusion: 该方法首次探索了在推理服务系统中优化分层量化位宽，并通过理论测量精度下降，为边缘设备推理提供了高效解决方案。

Abstract: As machine learning inferences increasingly move to edge devices, adapting to
diverse computational capabilities, hardware, and memory constraints becomes
more critical. Instead of relying on a pre-trained model fixed for all future
inference queries across diverse edge devices, we argue that planning an
inference pattern with a request-specific model tailored to the device's
computational capacity, accuracy requirements, and time constraints is more
cost-efficient and robust to diverse scenarios. To this end, we propose an
accuracy-aware and workload-balanced inference system that integrates joint
model quantization and inference partitioning. In this approach, the server
dynamically responds to inference queries by sending a quantized model and
adaptively sharing the inference workload with the device. Meanwhile, the
device's computational power, channel capacity, and accuracy requirements are
considered when deciding.
  Furthermore, we introduce a new optimization framework for the inference
system, incorporating joint model quantization and partitioning. Our approach
optimizes layer-wise quantization bit width and partition points to minimize
time consumption and cost while accounting for varying accuracy requirements of
tasks through an accuracy degradation metric in our optimization model. To our
knowledge, this work represents the first exploration of optimizing
quantization layer-wise bit-width in the inference serving system, by
introducing theoretical measurement of accuracy degradation. Simulation results
demonstrate a substantial reduction in overall time and power consumption, with
computation payloads decreasing by over 80% and accuracy degradation kept below
1%.

</details>


### [359] [Agent.xpu: Efficient Scheduling of Agentic LLM Workloads on Heterogeneous SoC](https://arxiv.org/abs/2506.24045)
*Xinming Wei,Jiahao Zhang,Haoran Li,Jiayu Chen,Rui Qu,Maoliang Li,Xiang Chen,Guojie Luo*

Main category: cs.DC

TL;DR: Agent.xpu是一个高效的代理LLM服务系统，专为异构SoC设计，能同时优化反应式和主动式任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有设备上的LLM引擎无法高效处理反应式和主动式任务的并发需求，尤其是在异构SoC上。

Method: 通过离线分析构建异构执行图，结合运行时调度策略，实现细粒度任务管理和资源优化。

Result: 在Intel Core Ultra SoC上，Agent.xpu显著降低了反应式任务的延迟，并提高了主动式任务的吞吐量。

Conclusion: Agent.xpu为异构SoC上的代理LLM工作负载提供了高效的解决方案。

Abstract: The proliferation of agentic Large Language Models (LLMs) on personal devices
introduces a new class of workloads characterized by a dichotomy of objectives.
Reactive tasks, initiated by users, demand immediate, low-latency responses,
while proactive tasks operate invisibly and prioritize throughput. Existing
on-device LLM engines, designed for isolated inferences, fail to efficiently
manage these concurrent and conflicting requests on consumer-grade
heterogeneous SoCs with CPU, integrated GPU, and NPU. This paper introduces
Agent.xpu, an efficient serving system for agentic LLM workloads on
memory-unified heterogeneous SoCs. With dedicated offline profiling, Agent.xpu
first constructs a heterogeneous execution graph, which fuses and chunks model
kernels for affinity-guided, elastic accelerator mapping with predictive kernel
annotation. At runtime, its online scheduler enables fine-grained, kernel-level
preemption to guarantee the responsiveness of reactive tasks. To maximize SoC
utilization, it adopts slack-aware kernel backfill to opportunistically append
proactive tasks, and mitigates NPU-iGPU contention via bandwidth-aware
dispatch. Evaluation on an Intel Core Ultra SoC shows that Agent.xpu achieves
4.6$\times$ lower latency for reactive tasks and sustains
1.6$\times$-6.8$\times$ higher throughput for proactive tasks compared to
state-of-the-art inference engines.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [360] [Golden Ratio Assisted Localization for Wireless Sensor Network](https://arxiv.org/abs/2506.22464)
*Hitesh Mohapatra*

Main category: cs.NI

TL;DR: GRL算法利用黄金比例优化无线传感器网络定位，显著提升精度并降低能耗。


<details>
  <summary>Details</summary>
Motivation: 解决无线传感器网络中定位精度与能耗平衡的挑战。

Method: 基于黄金比例的锚节点部署和跳数敏感加权。

Result: 平均定位误差2.35米，能耗1.12微焦/节点，优于DV-Hop和Centroid。

Conclusion: GRL为能量受限和大规模WSN提供了高效平衡的定位方案。

Abstract: This paper presents a novel localization algorithm for wireless sensor
networks (WSNs) called Golden Ratio Localization (GRL), which leverages the
mathematical properties of the golden ratio (phi 1.618) to optimize both node
placement and communication range. GRL introduces phi-based anchor node
deployment and hop-sensitive weighting using phi-exponents to improve
localization accuracy while minimizing energy consumption. Through extensive
simulations conducted on a 100 m * 100 m sensor field with 100 nodes and 10
anchors, GRL achieved an average localization error of 2.35 meters,
outperforming DV- Hop (3.87 meters) and Centroid (4.95 meters). In terms of
energy efficiency, GRL reduced localization energy consumption to 1.12 microJ
per node, compared to 1.78 microJ for DV-Hop and 1.45 microJ for Centroid.
These results confirm that GRL provides a more balanced and efficient
localization approach, making it especially suitable for energy-constrained and
large-scale WSN deployments.

</details>


### [361] [Reliable Transmission of LTP Using Reinforcement Learning-Based Adaptive FEC](https://arxiv.org/abs/2506.22470)
*Liang Chen,Yu Song,Kanglian Zhao,Juan A. Fraire,Wenfeng Li*

Main category: cs.NI

TL;DR: 本文提出了一种基于强化学习的自适应FEC算法，用于优化深空网络中的数据传输，显著减少了解码失败和重传。


<details>
  <summary>Details</summary>
Motivation: 现有静态和基于延迟反馈的动态编码方法难以应对深空信道的高度变化和不可预测性。

Method: 利用强化学习，结合历史反馈和系统状态预测未来信道条件，动态调整编码率。

Result: 在模拟的地月与地火链路场景中，解码失败率至少减少2/3。

Conclusion: 该算法显著提升了深空网络的数据传输效率和可靠性。

Abstract: Delay/Disruption Tolerant Networking (DTN) employs the Licklider Transmission
Protocol (LTP) with Automatic Repeat reQuest (ARQ) for reliable data delivery
in challenging interplanetary networks. While previous studies have integrated
packet-level Forward Erasure Correction (FEC) into LTP to reduce retransmission
time costs, existing static and delay-feedback-based dynamic coding methods
struggle with highly variable and unpredictable deep space channel conditions.
This paper proposes a reinforcement learning (RL)-based adaptive FEC algorithm
to address these limitations. The algorithm utilizes historical feedback and
system state to predict future channel conditions and proactively adjust the
code rate. This approach aims to anticipate channel quality degradation,
thereby preventing decoding failures and subsequent LTP retransmissions and
improving coding efficiency by minimizing redundancy during favorable channel
conditions. Performance evaluations conducted in simulated Earth-Moon and
Earth-Mars link scenarios demonstrate this algorithm's effectiveness in
optimizing data transmission for interplanetary networks. Compared to existing
methods, this approach demonstrates significant improvement, with matrix
decoding failures reduced by at least 2/3.

</details>


### [362] [RL-based Adaptive Task Offloading in Mobile-Edge Computing for Future IoT Networks](https://arxiv.org/abs/2506.22474)
*Ziad Qais Al Abbasi,Khaled M. Rabie,Senior Member,Xingwang Li,Senior Member,Wali Ullah Khan,Asma Abu Samah*

Main category: cs.NI

TL;DR: 提出了一种基于强化学习的移动边缘计算（MEC）任务卸载方案，用于超密集蜂窝网络，优化资源分配和动态卸载决策，提升能效、吞吐量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）设备因计算和功耗限制需将任务卸载到远程云服务器，但远距离传输导致低延迟服务（如工业控制和自动驾驶）面临挑战。

Method: 采用强化学习（RL）技术，结合非正交多址接入（NOMA），动态调整卸载决策和资源分配，适应网络条件和用户需求变化。

Result: 仿真结果表明，该方案在能效、网络吞吐量和用户满意度方面优于现有卸载算法。

Conclusion: 提出的RL-based卸载方案有效解决了IoT设备在MEC环境中的低延迟和资源优化问题，具有实际应用潜力。

Abstract: The Internet of Things (IoT) has been increasingly used in our everyday lives
as well as in numerous industrial applications. However, due to limitations in
computing and power capabilities, IoT devices need to send their respective
tasks to cloud service stations that are usually located at far distances.
Having to transmit data far distances introduces challenges for services that
require low latency such as industrial control in factories and plants as well
as artificial intelligence assisted autonomous driving. To solve this issue,
mobile edge computing (MEC) is deployed at the networks edge to reduce
transmission time. In this regard, this study proposes a new offloading scheme
for MEC-assisted ultra dense cellular networks using reinforcement learning
(RL) techniques. The proposed scheme enables efficient resource allocation and
dynamic offloading decisions based on varying network conditions and user
demands. The RL algorithm learns from the networks historical data and adapts
the offloading decisions to optimize the networks overall performance.
Non-orthogonal multiple access is also adopted to improve resource utilization
among the IoT devices. Simulation results demonstrate that the proposed scheme
outperforms other stateof the art offloading algorithms in terms of energy
efficiency, network throughput, and user satisfaction.

</details>


### [363] [Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI](https://arxiv.org/abs/2506.22477)
*Huiwen Han*

Main category: cs.NI

TL;DR: 本文提出了一种基于物联网架构的创新型机器人操作平台设计，整合了LLM、生成式AI、边缘计算和5G网络等技术，旨在提升机器人智能与自主性，并通过案例研究展示了其在多个行业的潜力。


<details>
  <summary>Details</summary>
Motivation: 提升物联网系统和机器人的智能与自主性，使其能够实时决策并动态适应环境变化。

Method: 采用创新的物联网架构，整合LLM、生成式AI、边缘计算和5G网络等技术，并通过多行业案例研究验证。

Result: 展示了物联网机器人技术在优化工作流程、提高生产力和提供创新解决方案方面的巨大潜力。

Conclusion: LLM和生成式AI等技术推动了智能机器人和物联网的发展，为下一代自动化和技术融合提供了前瞻性视角。

Abstract: This paper introduces an innovative design for robotic operating platforms,
underpinned by a transformative Internet of Things (IoT) architecture,
seamlessly integrating cutting-edge technologies such as large language models
(LLMs), generative AI, edge computing, and 5G networks. The proposed platform
aims to elevate the intelligence and autonomy of IoT systems and robotics,
enabling them to make real-time decisions and adapt dynamically to changing
environments. Through a series of compelling case studies across industries
including smart manufacturing, healthcare, and service sectors, this paper
demonstrates the substantial potential of IoT-enabled robotics to optimize
operational workflows, enhance productivity, and deliver innovative, scalable
solutions. By emphasizing the roles of LLMs and generative AI, the research
highlights how these technologies drive the evolution of intelligent robotics
and IoT, shaping the future of industry-specific advancements. The findings not
only showcase the transformative power of these technologies but also offer a
forward-looking perspective on their broader societal and industrial
implications, positioning them as catalysts for next-generation automation and
technological convergence.

</details>


### [364] [Service Placement in Small Cell Networks Using Distributed Best Arm Identification in Linear Bandits](https://arxiv.org/abs/2506.22480)
*Mariam Yahya,Aydin Sezgin,Setareh Maghsudi*

Main category: cs.NI

TL;DR: 论文提出了一种分布式多代理最佳臂识别算法，用于解决小蜂窝网络中边缘计算服务部署问题，以降低用户延迟。


<details>
  <summary>Details</summary>
Motivation: 小蜂窝网络中，用户对计算密集型服务的需求增加，而基于云的访问导致高延迟。多接入边缘计算（MEC）通过将计算资源靠近用户来缓解这一问题，但边缘容量有限，需在未知服务需求和动态网络条件下优化服务部署。

Method: 将服务需求建模为服务属性的线性函数，并将服务部署任务表述为线性多臂老虎机问题。提出了一种分布式自适应多代理最佳臂识别算法，SBS作为代理协作加速学习。

Result: 仿真表明，算法能以所需置信度识别最优服务，并实现接近最优的加速效果，学习轮次随SBS数量成比例减少。

Conclusion: 该算法在理论和实践中均表现出色，能有效降低用户延迟，同时分析了算法的样本复杂性和通信开销。

Abstract: As users in small cell networks increasingly rely on computation-intensive
services, cloud-based access often results in high latency. Multi-access edge
computing (MEC) mitigates this by bringing computational resources closer to
end users, with small base stations (SBSs) serving as edge servers to enable
low-latency service delivery. However, limited edge capacity makes it
challenging to decide which services to deploy locally versus in the cloud,
especially under unknown service demand and dynamic network conditions. To
tackle this problem, we model service demand as a linear function of service
attributes and formulate the service placement task as a linear bandit problem,
where SBSs act as agents and services as arms. The goal is to identify the
service that, when placed at the edge, offers the greatest reduction in total
user delay compared to cloud deployment. We propose a distributed and adaptive
multi-agent best-arm identification (BAI) algorithm under a fixed-confidence
setting, where SBSs collaborate to accelerate learning. Simulations show that
our algorithm identifies the optimal service with the desired confidence and
achieves near-optimal speedup, as the number of learning rounds decreases
proportionally with the number of SBSs. We also provide theoretical analysis of
the algorithm's sample complexity and communication overhead.

</details>


### [365] [Wireless Home Automation Using Social Networking Websites](https://arxiv.org/abs/2506.22482)
*Divya Alok Gupta,Dwith Chenna,B. Aditya Vighnesh Ramakanth*

Main category: cs.NI

TL;DR: 提出了一种基于社交网络（如Twitter）安全认证的无线家庭自动化系统（WHAS），通过跟踪用户活动控制家电，并对比传统系统的优势。


<details>
  <summary>Details</summary>
Motivation: 随着物联网的发展，无线家庭自动化系统（WHAS）面临安全性、多设备统一控制及用户友好性等挑战。

Method: 利用社交网络（如Twitter）的安全认证系统，跟踪用户活动并控制家电。

Result: 展示了WHAS的应用场景，并对比了其与传统系统的优势。

Conclusion: 提出的系统在安全性和用户体验上优于传统家庭自动化系统。

Abstract: With the advent of Internet of Things, Wireless Home Automation Systems WHAS
are gradually gaining popularity. These systems are faced with multiple
challenges such as security; controlling a variety of home appliances with a
single interface and user friendliness. In this paper we propose a system that
uses secure authentication systems of social networking websites such as
Twitter, tracks the end-users activities on the social network and then control
his or her domestic appliances. At the end, we highlight the applications of
the proposed WHAS and compare the advantages of our proposed system over
traditional home automation systems.

</details>


### [366] [An Urban Multi-Operator QoE-Aware Dataset for Cellular Networks in Dense Environments](https://arxiv.org/abs/2506.22484)
*Muhammad Kabeer,Rosdiadee Nordin,Mehran Behjati,Farah Yasmin binti Mohd Shaharuddin*

Main category: cs.NI

TL;DR: 该研究提供了一个包含30,925条标记记录的数据集，用于城市蜂窝网络的QoE驱动优化和移动性管理。


<details>
  <summary>Details</summary>
Motivation: 城市蜂窝网络因高基础设施密度、多样化用户移动性和服务需求而面临复杂性能挑战，现有数据集缺乏用户中心的QoE和多样化移动模式数据。

Method: 使用GNetTrack Pro在2平方公里密集城区收集数据，涵盖三大运营商，记录信号质量参数和多种移动模式及网络流量场景。

Result: 数据集包含132个物理基站，适用于机器学习应用，如切换优化、信号质量预测和多运营商性能评估。

Conclusion: 该数据集为城市蜂窝网络规划和优化提供了可复现、应用就绪的资源。

Abstract: Urban cellular networks face complex performance challenges due to high
infrastructure density, varied user mobility, and diverse service demands.
While several datasets address network behaviour across different environments,
there is a lack of datasets that captures user centric Quality of Experience
(QoE), and diverse mobility patterns needed for efficient network planning and
optimization solutions, which are important for QoE driven optimizations and
mobility management. This study presents a curated dataset of 30,925 labelled
records, collected using GNetTrack Pro within a 2 km2 dense urban area,
spanning three major commercial network operators. The dataset captures key
signal quality parameters (e.g., RSRP, RSRQ, SNR), across multiple real world
mobility modes including pedestrian routes, canopy walkways, shuttle buses, and
Bus Rapid Transit (BRT) routes. It also includes diverse network traffic
scenarios including (1) FTP upload and download, (2) video streaming, and (3)
HTTP browsing. A total of 132 physical cell sites were identified and validated
through OpenCellID and on-site field inspections, illustrating the high cell
density characteristic of 5G and emerging heterogeneous network deployment. The
dataset is particularly suited for machine learning applications, such as
handover optimization, signal quality prediction, and multi operator
performance evaluation. Released in a structured CSV format with accompanying
preprocessing and visualization scripts, this dataset offers a reproducible,
application ready resource for researchers and practitioners working on urban
cellular network planning and optimization.

</details>


### [367] [AGI Enabled Solutions For IoX Layers Bottlenecks In Cyber-Physical-Social-Thinking Space](https://arxiv.org/abs/2506.22487)
*Amar Khelloufi,Huansheng Ning,Sahraoui Dhelim,Jianguo Ding*

Main category: cs.NI

TL;DR: 本文综述了AGI增强的IoX研究，探讨了其在感知层、网络层和应用层的关键作用，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决CPST生态系统中感知、网络和应用层的关键瓶颈问题。

Method: 通过自适应传感器融合、边缘预处理、选择性注意力机制等技术优化各层性能。

Result: AGI驱动的策略为数据过载、协议异构性和身份爆炸提供了新解决方案。

Conclusion: AGI增强的IoX是一个新兴关键研究领域，但仍需解决计算需求、可扩展性和实际验证等挑战。

Abstract: The integration of the Internet of Everything (IoX) and Artificial General
Intelligence (AGI) has given rise to a transformative paradigm aimed at
addressing critical bottlenecks across sensing, network, and application layers
in Cyber-Physical-Social Thinking (CPST) ecosystems. In this survey, we provide
a systematic and comprehensive review of AGI-enhanced IoX research, focusing on
three key components: sensing-layer data management, network-layer protocol
optimization, and application-layer decision-making frameworks. Specifically,
this survey explores how AGI can mitigate IoX bottlenecks challenges by
leveraging adaptive sensor fusion, edge preprocessing, and selective attention
mechanisms at the sensing layer, while resolving network-layer issues such as
protocol heterogeneity and dynamic spectrum management, neuro-symbolic
reasoning, active inference, and causal reasoning, Furthermore, the survey
examines AGI-enabled frameworks for managing identity and relationship
explosion. Key findings suggest that AGI-driven strategies, such as adaptive
sensor fusion, edge preprocessing, and semantic modeling, offer novel solutions
to sensing-layer data overload, network-layer protocol heterogeneity, and
application-layer identity explosion. The survey underscores the importance of
cross-layer integration, quantum-enabled communication, and ethical governance
frameworks for future AGI-enabled IoX systems. Finally, the survey identifies
unresolved challenges, such as computational requirements, scalability, and
real-world validation, calling for further research to fully realize AGI's
potential in addressing IoX bottlenecks. we believe AGI-enhanced IoX is
emerging as a critical research field at the intersection of interconnected
systems and advanced AI.

</details>


### [368] [Integrated Multimodal Sensing and Communication: Challenges, Technologies, and Architectures](https://arxiv.org/abs/2506.22507)
*Yubo Peng,Luping Xiang,Kun Yang,Feibo Jiang,Kezhi Wang,Christos Masouros*

Main category: cs.NI

TL;DR: 论文探讨了从单模态到多模态的集成感知与通信（ISAC）系统的转变，以解决6G网络中环境特征表达不足的问题，并提出了三种架构范式（F-MAC、I-MAC、R-MAC）及案例研究。


<details>
  <summary>Details</summary>
Motivation: 现有单模态ISAC系统在6G应用中表现受限，无法满足复杂需求，因此需要转向多模态ISAC。

Method: 分析了多模态ISAC的关键挑战，提出了AI大模型、语义通信和多智能体系统等技术支持，并设计了三种架构范式。

Result: 基于F-MAC方案的案例研究表明，多模态ISAC的感知准确率比单模态系统提高了约80%。

Conclusion: 多模态ISAC是6G网络的重要发展方向，但仍需解决未来开放性问题。

Abstract: The evolution towards 6G networks requires the intelligent integration of
communication and sensing capabilities to support diverse and complex
applications, such as autonomous driving and immersive services. However,
existing integrated sensing and communication (ISAC) systems predominantly rely
on single-modal sensors as primary participants, which leads to a limited
representation of environmental features and significant performance
bottlenecks under the emerging requirements of 6G applications. This limitation
motivates a paradigm shift from single-modal to multimodal ISAC. In this
article, we first analyze the key challenges in realizing multimodal ISAC,
including the fusion of heterogeneous multimodal data, the high communication
overhead among distributed sensors, and the design of efficient and scalable
system architectures. We then introduce several enabling technologies, such as
large AI models, semantic communication, and multi-agent systems, that hold
promise for addressing these challenges. To operationalize these technologies,
we zoom into three architectural paradigms: fusion-based multimodal ISAC
(F-MAC), interaction-based multimodal ISAC (I-MAC), and relay-based multimodal
ISAC (R-MAC), each tailored to organize devices and modalities for efficient
collaboration in different scenarios. Thereafter, a case study is presented
based on the F-MAC scheme, demonstrating that the scheme achieves more
comprehensive sensing and improves sensing accuracy by approximately 80%
compared to conventional single-modal ISAC systems. Finally, we discuss several
open issues to be addressed in the future.

</details>


### [369] [Towards an Optimized Multi-Cyclic Queuing and Forwarding in Time Sensitive Networking with Time Injection](https://arxiv.org/abs/2506.22671)
*Rubi Debnath,Mohammadreza Barzegaran,Sebastian Steinhorst*

Main category: cs.NI

TL;DR: Multi-CQF是一种改进的TSN整形机制，通过多周期支持多样化的时序需求，但配置研究不足。本文提出约束条件和DSK减少搜索空间，开发GA和GASA算法优化配置，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决CQF单周期限制和Multi-CQF配置研究不足的问题，探索TI在Multi-CQF中的作用。

Method: 提出约束条件和DSK，开发GA和GASA算法优化Multi-CQF配置，引入TI增强可调度性。

Result: GA和GASA算法比基线SA模型多调度15%的TT流，GASA收敛速度快20%，时间复杂性更低。

Conclusion: Multi-CQF配置优化显著提升性能，GASA算法在速度和效率上优于SA模型。

Abstract: Cyclic Queuing and Forwarding (CQF) is a Time-Sensitive Networking (TSN)
shaping mechanism that provides bounded latency and deterministic Quality of
Service (QoS). However, CQF's use of a single cycle restricts its ability to
support TSN traffic with diverse timing requirements. Multi-Cyclic Queuing and
Forwarding (Multi-CQF) is a new and emerging TSN shaping mechanism that uses
multiple cycles on the same egress port, allowing it to accommodate TSN flows
with varied timing requirements more effectively than CQF. Despite its
potential, current Multi-CQF configuration studies are limited, leading to a
lack of comprehensive research, poor understanding of the mechanism, and
limited adoption of Multi-CQF in practical applications. Previous work has
shown the impact of Time Injection (TI), defined as the start time of
Time-Triggered (TT) flows at the source node, on CQF queue resource
utilization. However, the impact of TI has not yet been explored in the context
of Multi-CQF. This paper introduces a set of constraints and leverages Domain
Specific Knowledge (DSK) to reduce the search space for Multi-CQF
configuration. Building on this foundation, we develop an open-source Genetic
Algorithm (GA) and a hybrid GA-Simulated Annealing (GASA) approach to
efficiently configure Multi-CQF networks and introduce TI in Multi-CQF to
enhance schedulability. Experimental results show that our proposed algorithms
significantly increase the number of scheduled TT flows compared to the
baseline Simulated Annealing (SA) model, improving scheduling by an average of
15%. Additionally, GASA achieves a 20% faster convergence rate and lower time
complexity, outperforming the SA model in speed, and efficiency.

</details>


### [370] [Reliable Image Transmission in CPS-based Pub/Sub](https://arxiv.org/abs/2506.22875)
*Everson Flores,Bruna Guterres,Thomaz Pereira Junior,Paula Barros,Alberto Cabral,Cristiana Lima Dora,Marcelo Malheiros,Marcelo Pias*

Main category: cs.NI

TL;DR: 研究探讨了MQTT协议在高流量和间歇性连接场景下实时图像传输的可靠性，验证了其在工业应用中的适应性。


<details>
  <summary>Details</summary>
Motivation: 填补MQTT协议在高流量和间歇性连接场景下性能评估的文献空白，以支持关键IoT和CPS应用。

Method: 通过控制实验评估分布式系统在MQTT发布/订阅模型下的表现，重点关注网络中断和高流量场景。

Result: MQTT系统在正常情况下可靠，恢复能力取决于故障点；能避免重复错误并适应网络需求增长。

Conclusion: MQTT系统适合需要高效和弹性数据处理的工业应用。

Abstract: Developments in communication and automation have driven the expansion of
distributed networks, essential for IoT and CPS development in industrial
applications requiring reliable image processing and real-time adaptability.
Although broadly adopted, there is a literature gap regarding the performance
of MQTT protocol for image sharing and transmission under high-traffic
scenarios with intermittent connectivity, restricting its use in critical IoT
and CPS applications. In this context, the present work examines the
reliability of real-time image transmission in IoT and CPS industrial systems
that utilize the MQTT-based publish/subscribe communication model. It focuses
on scenarios with network interruptions and high data traffic, evaluating the
performance of a distributed system through a series of controlled testbed
validation experiments. Experimental validation demonstrated that while the
MQTT-based system sustains reliable transmission under normal conditions, its
recovery capability depends on the failure point, with complete restoration
occurring when disruptions affect the Orchestrator Node and partial recovery
when the Producer Node or Broker are affected. The study also confirmed that
the system prevents duplicate errors and adapts well to increasing network
demands, reinforcing its suitability for industrial applications that require
efficient and resilient data handling.

</details>


### [371] [Trusted Routing for Blockchain-Enabled Low-Altitude Intelligent Networks](https://arxiv.org/abs/2506.22745)
*Sijie He,Ziye Jia,Qiuming Zhu,Fuhui Zhou,Qihui Wu*

Main category: cs.NI

TL;DR: 论文提出了一种基于区块链的零信任架构和多智能体深度Q网络的自适应路由算法，以解决低空智能网络中路由稳定性和安全性的挑战，并显著降低了端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 低空智能网络（LAINs）在监视和灾难救援等领域具有广泛应用，但其分布式拓扑和高动态移动性使其易受安全威胁，影响路由性能。

Method: 采用区块链支持的零信任架构管理无人机加入和退出，并将路由问题建模为分散式部分可观测马尔可夫决策过程，设计多智能体双深度Q网络自适应路由算法。

Result: 仿真结果表明，所提机制的平均端到端延迟比基准降低了22.38%。

Conclusion: 该研究为LAINs提供了高效且安全的路由解决方案，显著提升了性能。

Abstract: Due to the scalability and portability, the low-altitude intelligent networks
(LAINs) are essential in various fields such as surveillance and disaster
rescue. However, in LAINs, unmanned aerial vehicles (UAVs) are characterized by
the distributed topology and high dynamic mobility, and vulnerable to security
threats, which may degrade the routing performance for data transmission.
Hence, how to ensure the routing stability and security of LAINs is a
challenge. In this paper, we focus on the routing process in LAINs with
multiple UAV clusters and propose the blockchain-enabled zero-trust
architecture to manage the joining and exiting of UAVs. Furthermore, we
formulate the routing problem to minimize the end-to-end (E2E) delay, which is
an integer linear programming and intractable to solve. Therefore, considering
the distribution of LAINs, we reformulate the routing problem into a
decentralized partially observable Markov decision process. With the proposed
soft hierarchical experience replay buffer, the multi-agent double deep
Q-network based adaptive routing algorithm is designed. Finally, simulations
are conducted and numerical results show that the total E2E delay of the
proposed mechanism decreases by 22.38\% than the benchmark on average.

</details>


### [372] [Offline Reinforcement Learning for Mobility Robustness Optimization](https://arxiv.org/abs/2506.22793)
*Pegah Alizadeh,Anastasios Giovanidis,Pradeepa Ramachandra,Vasileios Koutsoukis,Osama Arouk*

Main category: cs.NI

TL;DR: 论文探讨了使用离线强化学习优化MRO算法，通过决策变换器和保守Q学习方法，在相同输入特征下，离线RL方法比基于规则的MRO表现更好，提升达7%。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用离线强化学习优化MRO算法中的Cell Individual Offset调整，避免进一步探索，提高性能。

Method: 采用决策变换器和保守Q学习方法，利用离线数据集学习最优策略，输入特征包括失败、乒乓切换等。

Result: 在3500 MHz载频的New Radio网络中，离线RL方法比基于规则的MRO提升达7%，且能灵活适应不同目标函数。

Conclusion: 离线强化学习方法在MRO优化中表现优于传统规则方法，并具有更高的操作灵活性。

Abstract: In this work we revisit the Mobility Robustness Optimisation (MRO) algorithm
and study the possibility of learning the optimal Cell Individual Offset tuning
using offline Reinforcement Learning. Such methods make use of collected
offline datasets to learn the optimal policy, without further exploration. We
adapt and apply a sequence-based method called Decision Transformers as well as
a value-based method called Conservative Q-Learning to learn the optimal policy
for the same target reward as the vanilla rule-based MRO. The same input
features related to failures, ping-pongs, and other handover issues are used.
Evaluation for realistic New Radio networks with 3500 MHz carrier frequency on
a traffic mix including diverse user service types and a specific tunable
cell-pair shows that offline-RL methods outperform rule-based MRO, offering up
to 7% improvement. Furthermore, offline-RL can be trained for diverse objective
functions using the same available dataset, thus offering operational
flexibility compared to rule-based methods.

</details>


### [373] [Resilient-Native and Intelligent Next-Generation Wireless Systems: Key Enablers, Foundations, and Applications](https://arxiv.org/abs/2506.22991)
*Mehdi Bennis,Sumudu Samarakoon,Tamara Alshammari,Chathuranga Weeraddana,Zhoujun Tian,Chaouki Ben Issaid*

Main category: cs.NI

TL;DR: 本文探讨了无线网络的弹性（resilience），区分了弹性与可靠性和鲁棒性的不同，并提出了基于抽象、组合性和涌现性的数学基础，以及相关技术和应用案例。


<details>
  <summary>Details</summary>
Motivation: 随着自然和人为干扰的增加，无线网络需要具备弹性以应对不可预测的破坏和故障。

Method: 文章首先澄清了弹性的概念，随后介绍了基于数学基础的弹性技术和方法，并通过案例展示了其应用。

Result: 提出了一个统一的基础框架，用于理解和设计无线通信系统的弹性，并为下一代智能弹性无线系统制定了路线图。

Conclusion: 本文为无线网络的弹性建模和工程化提供了理论基础，并展望了未来发展方向。

Abstract: Just like power, water, and transportation systems, wireless networks are a
crucial societal infrastructure. As natural and human-induced disruptions
continue to grow, wireless networks must be resilient. This requires them to
withstand and recover from unexpected adverse conditions, shocks, unmodeled
disturbances and cascading failures. Unlike robustness and reliability,
resilience is based on the understanding that disruptions will inevitably
happen. Resilience, as elasticity, focuses on the ability to bounce back to
favorable states, while resilience as plasticity involves agents and networks
that can flexibly expand their states and hypotheses through real-time
adaptation and reconfiguration. This situational awareness and active
preparedness, adapting world models and counterfactually reasoning about
potential system failures and the best responses, is a core aspect of
resilience. This article will first disambiguate resilience from reliability
and robustness, before delving into key mathematical foundations of resilience
grounded in abstraction, compositionality and emergence. Subsequently, we focus
our attention on a plethora of techniques and methodologies pertaining to the
unique characteristics of resilience, as well as their applications through a
comprehensive set of use cases. Ultimately, the goal of this paper is to
establish a unified foundation for understanding, modeling, and engineering
resilience in wireless communication systems, while laying a roadmap for the
next-generation of resilient-native and intelligent wireless systems.

</details>


### [374] [Model-Based Diagnosis: Automating End-to-End Diagnosis of Network Failures](https://arxiv.org/abs/2506.23083)
*Changrong Wu,Yiyao Yu,Myungjin Lee,Jayanth Srinivasa,Ennan Zhai,George Varghese,Yuval Tamir*

Main category: cs.NI

TL;DR: 该论文提出了一种基于模型的网络诊断新范式NetDx，通过自动化程序快速定位网络故障根源，显著提升诊断效率。


<details>
  <summary>Details</summary>
Motivation: 企业网络故障的快速诊断和修复至关重要，但现有方法仅针对部分问题（如数据平面或控制平面故障），缺乏系统性解决方案。

Method: 基于数据包转发和路由模型，系统化生成自动化诊断程序，覆盖硬件、固件和软件故障，涵盖数据平面和分布式控制平面。

Result: NetDx在模拟网络中实现了100%的故障诊断准确率，并在实际云提供商数据集中将诊断时间从小时级缩短至秒级。

Conclusion: 模型化网络诊断方法显著提升了故障诊断效率和准确性，为网络运维提供了新思路。

Abstract: Fast diagnosis and repair of enterprise network failures is critically
important since disruptions cause major business impacts. Prior works focused
on diagnosis primitives or procedures limited to a subset of the problem, such
as only data plane or only control plane faults. This paper proposes a new
paradigm, model-based network diagnosis, that provides a systematic way to
derive automated procedures for identifying the root cause of network failures,
based on reports of end-to-end user-level symptoms. The diagnosis procedures
are systematically derived from a model of packet forwarding and routing,
covering hardware, firmware, and software faults in both the data plane and
distributed control plane. These automated procedures replace and dramatically
accelerate diagnosis by an experienced human operator. Model-based diagnosis is
inspired by, leverages, and is complementary to recent work on network
verification. We have built NetDx, a proof-of-concept implementation of
model-based network diagnosis. We deployed NetDx on a new emulator of networks
consisting of P4 switches with distributed routing software. We validated the
robustness and coverage of NetDx with an automated fault injection campaign, in
which 100% of faults were diagnosed correctly. Furthermore, on a data set of 33
faults from a large cloud provider that are within the domain targeted by
NetDx, 30 are efficiently diagnosed in seconds instead of hours.

</details>


### [375] [Autonomous Vision-Aided UAV Positioning for Obstacle-Aware Wireless Connectivity](https://arxiv.org/abs/2506.23190)
*Kamran Shafafi,Manuel Ricardo,Rui Campos*

Main category: cs.NI

TL;DR: VTOPA算法通过计算机视觉优化无人机位置，提升城市环境中无线连接的吞吐量和延迟性能。


<details>
  <summary>Details</summary>
Motivation: 无人机在密集城市环境中优化位置以保持与地面设备的视距连接具有挑战性。

Method: 提出VTOPA算法，利用计算机视觉提取环境信息（如障碍物和用户位置），实时动态调整无人机位置。

Result: 仿真显示，VTOPA在障碍物密集环境中吞吐量提升50%，延迟降低50%。

Conclusion: VTOPA在复杂城市环境中优于基准方法，显著提升连接性能。

Abstract: Unmanned Aerial Vehicles (UAVs) offer a promising solution for enhancing
wireless connectivity and Quality of Service (QoS) in urban environments,
acting as aerial Wi-Fi access points or cellular base stations. Their
flexibility and rapid deployment capabilities make them suitable for addressing
infrastructure gaps and traffic surges. However, optimizing UAV positions to
maintain Line of Sight (LoS) links with ground User Equipment (UEs) remains
challenging in obstacle-dense urban scenarios. This paper proposes VTOPA, a
Vision-Aided Traffic- and Obstacle-Aware Positioning Algorithm that
autonomously extracts environmental information -- such as obstacles and UE
locations -- via computer vision and optimizes UAV positioning accordingly. The
algorithm prioritizes LoS connectivity and dynamically adapts to user traffic
demands in real time. Evaluated through simulations in ns-3, VTOPA achieves up
to a 50% increase in aggregate throughput and a 50% reduction in delay, without
compromising fairness, outperforming benchmark approaches in obstacle-rich
environments.

</details>


### [376] [On the Resilience of Underwater Semantic Wireless Communications](https://arxiv.org/abs/2506.23350)
*João Pedro Loureiro,Patrícia Delgado,Tomás Feliciano Ribeiro,Filipe B. Teixeira,Rui Campos*

Main category: cs.NI

TL;DR: 论文探讨了水下无线通信的挑战，提出了一种结合语义处理和生成式人工智能（GenAI）的框架SAGE，用于通过声学链路传输图像数据。测试表明，SAGE在恶劣环境下仍能有效重建图像内容。


<details>
  <summary>Details</summary>
Motivation: 传统水下无线通信技术（如声学和光学）存在带宽低、错误率高和多径干扰等问题，语义通信通过传输语义特征而非原始数据，有望解决这些问题。

Method: 提出SAGE框架，结合语义处理和GenAI，将图像数据压缩为文本描述并通过声学链路传输。使用定制模拟器测试其在不同错误条件下的鲁棒性。

Result: SAGE在模拟的水下声学信道错误条件下，仍能成功重建有意义的图像内容。

Conclusion: SAGE框架展示了在恶劣水下环境中实现高效、鲁棒无线通信的潜力。

Abstract: Underwater wireless communications face significant challenges due to
propagation constraints, limiting the effectiveness of traditional radio and
optical technologies. Long-range acoustic communications support distances up
to a few kilometers, but suffer from low bandwidth, high error ratios, and
multipath interference. Semantic communications, which focus on transmitting
extracted semantic features rather than raw data, present a promising solution
by significantly reducing the volume of data transmitted over the wireless
link.
  This paper evaluates the resilience of SAGE, a semantic-oriented
communications framework that combines semantic processing with Generative
Artificial Intelligence (GenAI) to compress and transmit image data as textual
descriptions over acoustic links. To assess robustness, we use a
custom-tailored simulator that introduces character errors observed in
underwater acoustic channels. Evaluation results show that SAGE can
successfully reconstruct meaningful image content even under varying error
conditions, highlighting its potential for robust and efficient underwater
wireless communication in harsh environments.

</details>


### [377] [Generative AI-enhanced Low-Altitude UAV-Mounted Stacked Intelligent Metasurfaces](https://arxiv.org/abs/2506.23488)
*Geng Sun,Mingzhe Fan,Lei Zhang,Hongyang Pan,Jiahui Li,Chuang Zhang,Linyao Li,Changyuan Zhao,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于无人机搭载智能超表面（UAV-SIMs）的通信系统，通过联合优化用户关联、无人机定位和超表面相位偏移，显著提升了网络容量和算法效率。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统在复杂环境中面临高数据速率和可靠连接的挑战，移动智能超表面（SIMs）技术为解决这一问题提供了新思路。

Method: 将联合优化问题分解为三个子问题：用户关联优化（AUUOP）、无人机定位优化（ULOP）和超表面相位偏移优化（USPSOP），分别采用CVX工具和生成式人工智能（GAI）算法求解。

Result: 仿真结果显示，所提方案网络容量比次优方案提升约1.5倍，GAI算法在保持解质量的同时将运行时间减少10%。

Conclusion: UAV-SIMs系统在低空经济网络中具有显著性能优势，联合优化策略和GAI算法为未来通信技术提供了有效解决方案。

Abstract: Wireless communication systems face significant challenges in meeting the
increasing demands for higher data rates and more reliable connectivity in
complex environments. Stacked intelligent metasurfaces (SIMs) have emerged as a
promising technology for realizing wave-domain signal processing, with mobile
SIMs offering superior communication performance compared to their fixed
counterparts. In this paper, we investigate a novel unmanned aerial vehicle
(UAV)-mounted SIMs (UAV-SIMs) assisted communication system within the
low-altitude economy (LAE) networks paradigm, where UAVs function as both base
stations that cache SIM-processed data and mobile platforms that flexibly
deploy SIMs to enhance uplink communications from ground users. To maximize
network capacity, we formulate a UAV-SIM-based joint optimization problem
(USBJOP) that comprehensively addresses three critical aspects: the association
between UAV-SIMs and users, the three-dimensional positioning of UAV-SIMs, and
the phase shifts across multiple SIM layers. Due to the inherent non-convexity
and NP-hardness of USBJOP, we decompose it into three sub-optimization
problems, \textit{i.e.}, association between UAV-SIMs and users optimization
problem (AUUOP), UAV location optimization problem (ULOP), and UAV-SIM phase
shifts optimization problem (USPSOP), and solve them using an alternating
optimization strategy. Specifically, we transform AUUOP and ULOP into convex
forms solvable by the CVX tool, while addressing USPSOP through a generative
artificial intelligence (GAI)-based hybrid optimization algorithm. Simulations
demonstrate that our proposed approach significantly outperforms benchmark
schemes, achieving approximately 1.5 times higher network capacity compared to
suboptimal alternatives. Additionally, our proposed GAI method reduces the
algorithm runtime by 10\% while maintaining solution quality.

</details>


### [378] [Securing the Sky: Integrated Satellite-UAV Physical Layer Security for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.23493)
*Jiahui Li,Geng Sun,Xiaoyu Sun,Fang Mei,Jingjing Wang,Xiangwang Hou,Daxin Tian,Victor C. M. Leung*

Main category: cs.NI

TL;DR: 论文提出了一种基于协作波束成形的物理层安全方案，用于低空无线网络（LAWNs），通过卫星和无人机（UAVs）的互补性提升通信安全性。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络（LAWNs）在6G网络中具有广泛应用前景，但其高视距概率增加了传输安全风险，需要有效的安全解决方案。

Method: 提出了一种协作波束成形方案，结合卫星和无人机网络，设计了安全中继系统和双向空中安全通信框架。

Result: 仿真结果表明，该方案能有效提升低空无线通信的安全性，并适用于实际场景。

Conclusion: 该研究为LAWNs的安全通信提供了可行方案，同时指出了未来研究方向以进一步提升安全性。

Abstract: Low-altitude wireless networks (LAWNs) have garnered significant attention in
the forthcoming 6G networks. In LAWNs, satellites with wide coverage and
unmanned aerial vehicles (UAVs) with flexible mobility can complement each
other to form integrated satellite-UAV networks, providing ubiquitous and
high-speed connectivity for low-altitude operations. However, the higher
line-of-sight probability in low-altitude airspace increases transmission
security concerns. In this work, we present a collaborative beamforming-based
physical layer security scheme for LAWNs. We introduce the fundamental aspects
of integrated satellite-UAV networks, physical layer security, UAV swarms, and
collaborative beamforming for LAWN applications. Following this, we highlight
several opportunities for collaborative UAV swarm secure applications enabled
by satellite networks, including achieving physical layer security in scenarios
involving data dissemination, data relay, eavesdropper collusion, and imperfect
eavesdropper information. Next, we detail two case studies: a secure relay
system and a two-way aerial secure communication framework specifically
designed for LAWN environments. Simulation results demonstrate that these
physical layer security schemes are effective and beneficial for secure
low-altitude wireless communications. A short practicality analysis shows that
the proposed method is applicable to LAWN scenarios. Finally, we discuss
current challenges and future research directions for enhancing security in
LAWNs.

</details>


### [379] [The Kubernetes Network Driver Model: A Composable Architecture for High-Performance Networking](https://arxiv.org/abs/2506.23628)
*Antonio Ojea*

Main category: cs.NI

TL;DR: Kubernetes Network Drivers (KNDs) 提出了一种模块化、声明式架构，解决了传统 Kubernetes 网络在 AI/ML 和 Telco 基础设施中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统 Kubernetes 网络无法满足 AI/ML 和高性能 Telco 基础设施的需求，亟需一种更灵活、高效的解决方案。

Method: 通过 Dynamic Resource Allocation (DRA)、Node Resource Interface (NRI) 改进和 OCI Runtime Specification 变更，将网络资源管理集成到 Kubernetes 核心。

Result: DraNet 实现展示了声明式网络接口（包括 RDMA 设备）的附加能力，显著提升了 AI/ML 工作负载性能。

Conclusion: KNDs 为云原生应用和未来 Telco 解决方案奠定了基础，通过模块化设计降低了操作复杂性。

Abstract: Traditional Kubernetes networking struggles to meet the escalating demands of
AI/ML and evolving Telco infrastructure. This paper introduces Kubernetes
Network Drivers (KNDs), a transformative, modular, and declarative architecture
designed to overcome current imperative provisioning and API limitations. KNDs
integrate network resource management into Kubernetes' core by utilizing
Dynamic Resource Allocation (DRA), Node Resource Interface (NRI) improvements,
and upcoming OCI Runtime Specification changes. Our DraNet implementation
demonstrates declarative attachment of network interfaces, including Remote
Direct Memory Access (RDMA) devices, significantly boosting high-performance
AI/ML workloads. This capability enables sophisticated cloud-native
applications and lays crucial groundwork for future Telco solutions, fostering
a "galaxy" of specialized KNDs for enhanced application delivery and reduced
operational complexity.

</details>


### [380] [Geminet: Learning the Duality-based Iterative Process for Lightweight Traffic Engineering in Changing Topologies](https://arxiv.org/abs/2506.23640)
*Ximeng Liu,Shizhen Zhao,Xinbing Wang*

Main category: cs.NI

TL;DR: Geminet是一个轻量级、可扩展的基于机器学习的流量工程框架，能有效处理拓扑变化，显著降低计算和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的流量工程方案无法处理拓扑变化或存在可扩展性问题，Geminet旨在解决这些局限性。

Method: Geminet通过解耦神经网络与拓扑，学习基于梯度下降的调整过程，并优化边级双变量以减少内存消耗。

Result: Geminet在WAN和数据中心数据集上表现优异，神经网络大小仅为现有方案的0.04%至7%，内存消耗低于10 GiB，收敛速度比HARP快5.45倍。

Conclusion: Geminet展示了在大规模部署中的潜力，解决了现有ML-based TE方案的可扩展性和拓扑适应性不足的问题。

Abstract: Recently, researchers have explored ML-based Traffic Engineering (TE),
leveraging neural networks to solve TE problems traditionally addressed by
optimization. However, existing ML-based TE schemes remain impractical: they
either fail to handle topology changes or suffer from poor scalability due to
excessive computational and memory overhead. To overcome these limitations, we
propose Geminet, a lightweight and scalable ML-based TE framework that can
handle changing topologies. Geminet is built upon two key insights: (i) a
methodology that decouples neural networks from topology by learning an
iterative gradient-descent-based adjustment process, as the update rule of
gradient descent is topology-agnostic, relying only on a few gradient-related
quantities; (ii) shifting optimization from path-level routing weights to
edge-level dual variables, reducing memory consumption by leveraging the fact
that edges are far fewer than paths. Evaluations on WAN and data center
datasets show that Geminet significantly improves scalability. Its neural
network size is only 0.04% to 7% of existing schemes, while handling topology
variations as effectively as HARP, a state-of-the-art ML-based TE approach,
without performance degradation. When trained on large-scale topologies,
Geminet consumes under 10 GiB of memory, more than eight times less than the
80-plus GiB required by HARP, while achieving 5.45 times faster convergence
speed, demonstrating its potential for large-scale deployment.

</details>


### [381] [Campus5G: A Campus Scale Private 5G Open RAN Testbed](https://arxiv.org/abs/2506.23740)
*Andrew E. Ferguson,Ujjwal Pawar,Tianxin Wang,Mahesh K. Marina*

Main category: cs.NI

TL;DR: 本文介绍了Campus5G，首个校园范围内的O-RAN兼容私有5G测试床，详细描述了其开发过程、性能测试及经验教训。


<details>
  <summary>Details</summary>
Motivation: Open RAN在私有5G网络中的潜力，因其高度控制和创新机会，促使作者部署了Campus5G测试床。

Method: 从规划、架构设计到部署和性能测试，详细描述了测试床的开发过程。

Result: 成功部署了Campus5G测试床，并总结了相关经验教训。

Conclusion: 测试床部署为Open RAN在私有5G网络中的应用提供了研究机会和实践经验。

Abstract: Mobile networks are embracing disaggregation, reflected by the industry trend
towards Open RAN. Private 5G networks are viewed as particularly suitable
contenders as early adopters of Open RAN, owing to their setting, high degree
of control, and opportunity for innovation they present. Motivated by this, we
have recently deployed Campus5G, the first of its kind campus-wide,
O-RAN-compliant private 5G testbed across the central campus of the University
of Edinburgh. We present in detail our process developing the testbed, from
planning, to architecting, to deployment, and measuring the testbed
performance. We then discuss the lessons learned from building the testbed, and
highlight some research opportunities that emerged from our deployment
experience.

</details>


### [382] [How Long Can I Transmit? A Mobility Aware mmWave-based UAV Communication Framework](https://arxiv.org/abs/2506.23755)
*Shawon Mitra,Subhojit Sarkar,Sasthi C. Ghosh*

Main category: cs.NI

TL;DR: 论文研究了毫米波通信中无人机与移动地面用户之间的视距（LoS）持续时间，提出了一种基于曼哈顿点线过程的模型，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信虽然能提供高数据速率，但信号衰减严重。无人机因其灵活性可提供LoS路径，但现有研究缺乏对移动用户的LoS概率分析。

Method: 使用曼哈顿点线过程建模城市环境，推导静态无人机与移动地面用户之间的预期LoS持续时间，并通过仿真验证。

Result: 提出了一种基于预期LoS时间的用户关联算法，其性能优于现有基于最近LoS无人机的基准方案。

Conclusion: 该研究为毫米波通信中无人机与移动用户的LoS管理提供了有效工具，并展示了用户移动性对系统性能的重要性。

Abstract: One primary focus of next generation wireless communication networks is the
millimeterwave (mmWave) spectrum, typically considered in the 30 GHz to 300 GHz
frequency range. Despite their promise of high data rates, mmWaves suffer from
severe attenuation while passing through obstacles. Unmanned aerial vehicles
(UAVs) have been proposed to offset this limitation on account of their
additional degrees of freedom, which can be leveraged to provide line of sight
(LoS) transmission paths. While some prior works have proposed analytical
frameworks to compute the LoS probability for static ground users and a UAV,
the same is lacking for mobile users on the ground. In this paper, we consider
the popular Manhattan point line process (MPLP) to model an urban environment,
within which a ground user moves with a known velocity for a small time
interval along the roads. We derive an expression for the expected duration of
LoS between a static UAV in the air and a mobile ground user, and validate the
same through simulations. To demonstrate the efficacy of the proposed analysis,
we propose a simple user association algorithm that greedily assigns the UAVs
to users with the highest expected LoS time, and show that it outperforms the
existing benchmark schemes that assign the users to the nearest UAVs with LoS
without considering the user mobility.

</details>


### [383] [Learning Constraints Directly from Network Data](https://arxiv.org/abs/2506.23964)
*Hongyu Hè,Minhao Jin,Maria Apostolaki*

Main category: cs.NI

TL;DR: NetNomos通过约束建模从网络测量数据中学习命题逻辑约束，解决了规则提取的挑战，提高了合成数据质量、机器学习模型的鲁棒性以及网络测量的语义理解。


<details>
  <summary>Details</summary>
Motivation: 网络数据遵循多种规则，但手动或仅依赖机器学习提取规则往往不完整或不准确。NetNomos旨在通过自动化约束建模解决这一问题。

Method: NetNomos采用基于格结构的搜索方法，通过约束特异性和简洁性降低学习复杂度，从超二次降低到对数级，高效遍历组合搜索空间。

Result: 在多样网络数据集上，NetNomos能在三小时内学习所有基准规则（包括仅占0.01%数据点的规则），而基线方法仅发现不到25%的规则且耗时数天。

Conclusion: NetNomos在合成流量生成评估、异常检测和遥测插补中表现出色，展示了其广泛的应用潜力。

Abstract: Network data conforms to a wide range of rules that arise from protocols,
design principles, and deployment decisions (e.g., a packet's queuing delay
must be less than its end-to-end delay). Formalizing such rules as logic
constraints can (i) improve the quality of synthetic data, (ii) reduce the
brittleness of machine learning (ML) models, and (iii) improve semantic
understanding of network measurements. However, these benefits remain out of
reach if rule extraction is manual or solely reliant on ML, as both approaches
yield incomplete, unreliable, and/or inaccurate rules.
  This paper formulates rule extraction as a constraint modeling problem and
introduces NetNomos that learns propositional logic constraints directly from
raw network measurements. Constraint modeling in this domain is uniquely
challenging due to the scale of the data, the inherent learning complexity and
passive environment, and the lack of ground truth supervision. NetNomos
addresses these challenges via a lattice-based search structured by constraint
specificity and succinctness. Our approach reduces learning complexity from
superquadratic to logarithmic and enables efficient traversal in combinatorial
search space.
  Our evaluations on diverse network datasets show that NetNomos learns all
benchmark rules, including those associated with as little as 0.01% of data
points, in under three hours. In contrast, baseline methods discover less than
25% of the rules and require several days to run. Through three case studies,
we show that: NetNomos (i) finds rule violations in the outputs of all seven
synthetic traffic generators, hence can be used to assess and guide their
generation process; (ii) detects semantic differences in traffic, hence can be
used for anomaly detection; and (iii) automatically finds rules used for
telemetry imputation, hence can support monitoring through inference.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [384] [Verifying Properties of Index Arrays in a Purely-Functional Data-Parallel Language](https://arxiv.org/abs/2506.23058)
*Nikolaj Hey Hinnerskov,Robert Schenck,Cosmin E. Oancea*

Main category: cs.PL

TL;DR: 提出了一种自动验证纯数据并行程序属性的新方法，通过索引函数表示数组，利用代数不等式求解器验证属性，并在Futhark语言中实现，验证时间平均1秒。


<details>
  <summary>Details</summary>
Motivation: 解决纯数据并行程序中非线性索引属性的自动验证问题，为编译器优化提供支持。

Method: 将数组表示为索引函数，通过代数不等式求解器验证属性，适用于多种程序结构。

Result: 在Futhark中实现，验证时间平均1秒，动态验证消除后GPU程序性能显著提升。

Conclusion: 该方法实用且高效，扩展了程序验证的范围，支持编译器优化。

Abstract: This paper presents a novel approach to automatically verify properties of
pure data-parallel programs with non-linear indexing -- expressed as pre- and
post-conditions on functions. Programs consist of nests of second-order array
combinators (e.g., map, scan, and scatter) and loops. The key idea is to
represent arrays as index functions: programs are index function
transformations over which properties are propagated and inferred. Our
framework proves properties on index functions by distilling them into
algebraic (in)equalities and discharging them to a Fourier-Motzkin-based
solver. The framework is practical and accessible: properties are not
restricted to a decidable logic, but instead are carefully selected to express
practically useful guarantees that can be automatically reasoned about and
inferred. These guarantees extend beyond program correctness and can be
exploited by the entire compiler pipeline for optimization. We implement our
system in the pure data-parallel language Futhark and demonstrate its
practicality on seven applications, reporting an average verification time of 1
second. Two case studies show how eliminating dynamic verification in GPU
programs results in significant speedups.

</details>


### [385] [A Denotational Semantics for Quantum Loops](https://arxiv.org/abs/2506.23320)
*Nicola Assolini,Alessandra Di Pierro*

Main category: cs.PL

TL;DR: 本文提出了一种用于高级量子编程结构的指称语义，重点关注量子控制分支和循环的概念意义。


<details>
  <summary>Details</summary>
Motivation: 量子计算机编程需要不同抽象层次的方法，本文旨在为量子控制流提供数学定义。

Method: 引入了一个指称域，用于定义量子控制流（包括循环）的数学意义，反映量子系统的相干演化。

Result: 提出的语义能够清晰地描述量子控制流的行为。

Conclusion: 该指称语义为量子编程提供了理论基础，有助于理解和设计量子算法。

Abstract: Programming a quantum computer, i.e., implementing quantum algorithms on a
quantum processor-based copmputer architecture, is a task that can be addressed
(just as for classical computers) at different levels of abstraction. This
paper proposes a denotational semantics for high-level quantum programming
constructs, focusing on the conceptual meaning of quantum-controlled branching
and iteration. We introduce a denotational domain where a mathematical meaning
of a quantum control flow with loops can be defined, which reflects the
coherent evolution of the quantum system implementing the program.

</details>


### [386] [Compiling a Q# Subset to QASM 3.0 in TypeScript via a JSON Based IR](https://arxiv.org/abs/2506.23407)
*Marcus Edwards*

Main category: cs.PL

TL;DR: 开发了一个从Q#到QASM 3.0的编译工具链，包括完整的词法分析和语法分析器，支持部分Q#功能，并在TypeScript中实现以适配Web环境。


<details>
  <summary>Details</summary>
Motivation: 为了将Q#编译功能扩展到Web环境，开发了一个基于TypeScript的替代工具链。

Method: 实现了词法分析器、语法分析器和编译器，支持Q#的子集功能，并与现有工具进行对比。

Result: 工具链成功处理多种Q#输入程序，并在Web环境中表现良好。

Conclusion: 该工具链为Q#在Web环境中的应用提供了可行的解决方案。

Abstract: We implement a compile toolchain from Q# to QASM 3.0 including a
full-featured lexer and parser implementation, as well as a compiler that
supports a subset of Q# features. The lexer, parser and compiler are shown to
work with various input Q# programs and the implementation is compared against
existing Q# compile tools. Unlike the Microsoft implementation of the official
Q# compile toolchain, our implementation is written in TypeScript in order to
port functionality to web environments.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [387] [Knowledge-Guided Multi-Agent Framework for Automated Requirements Development: A Vision](https://arxiv.org/abs/2506.22656)
*Jiangping Huang,Dongming Jin,Weisong Sun,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: KGMAF是一个知识引导的多代理框架，旨在自动化需求开发，填补当前SE自动化系统在需求任务上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前SE自动化系统过于关注代码开发，忽视了需求任务的复杂性，KGMAF旨在解决这一问题。

Method: KGMAF由六个专业代理和一个工件池组成，详细描述了各代理的功能、行为和知识，并提供了工件池的概念设计。

Result: 案例研究表明KGMAF在现实场景中具有潜力。

Conclusion: KGMAF有望在LLM时代对自动化需求开发的未来发挥关键作用，并提出了进一步的研究机会。

Abstract: This paper envisions a knowledge-guided multi-agent framework named KGMAF for
automated requirements development. KGMAF aims to address gaps in current
automation systems for SE, which prioritize code development and overlook the
complexities of requirements tasks. KGMAF is composed of six specialized agents
and an artifact pool to improve efficiency and accuracy. Specifically, KGMAF
outlines the functionality, actions, and knowledge of each agent and provides
the conceptual design of the artifact pool. Our case study highlights the
potential of KGMAF in real-world scenarios. Finally, we outline several
research opportunities for implementing and enhancing automated requirements
development using multi-agent systems. We believe that KGMAF will play a
pivotal role in shaping the future of automated requirements development in the
era of LLMs.

</details>


### [388] [An LLM-assisted approach to designing software architectures using ADD](https://arxiv.org/abs/2506.22688)
*Humberto Cervantes,Rick Kazman,Yuanfang Cai*

Main category: cs.SE

TL;DR: 提出了一种基于大语言模型（LLM）辅助的软件架构设计方法，结合属性驱动设计（ADD）方法，通过案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统软件架构设计依赖专家经验，过程复杂且迭代性强，希望通过LLM辅助提升效率和协作性。

Method: 采用ADD方法，为LLM提供明确描述、架构师角色和结构化迭代计划，实现人机协作生成架构设计。

Result: 生成的架构设计与成熟解决方案高度一致，部分满足架构驱动因素，但需人类监督和迭代优化。

Conclusion: LLM在架构设计中具有潜力，但仍需人类主导和持续改进。

Abstract: Designing effective software architectures is a complex, iterative process
that traditionally relies on expert judgment. This paper proposes an approach
for Large Language Model (LLM)-assisted software architecture design using the
Attribute-Driven Design (ADD) method. By providing an LLM with an explicit
description of ADD, an architect persona, and a structured iteration plan, our
method guides the LLM to collaboratively produce architecture artifacts with a
human architect. We validate the approach through case studies, comparing
generated designs against proven solutions and evaluating them with
professional architects. Results show that our LLM-assisted ADD process can
generate architectures closely aligned with established solutions and partially
satisfying architectural drivers, highlighting both the promise and current
limitations of using LLMs in architecture design. Our findings emphasize the
importance of human oversight and iterative refinement when leveraging LLMs in
this domain.

</details>


### [389] [P4OMP: Retrieval-Augmented Prompting for OpenMP Parallelism in Serial Code](https://arxiv.org/abs/2506.22703)
*Wali Mohammad Abdullah,Azmain Kabir*

Main category: cs.SE

TL;DR: P4OMP是一个基于检索增强的框架，利用大型语言模型（LLM）将串行C/C++代码转换为OpenMP并行代码，无需微调或编译器插桩。


<details>
  <summary>Details</summary>
Motivation: 提高OpenMP pragma的正确性，避免传统方法中的模型微调或编译器插桩需求。

Method: 采用检索增强生成（RAG）技术，结合OpenMP教程的结构化知识，提升代码生成的可靠性。

Result: 在108个真实C++程序测试中，P4OMP实现100%编译成功率，而基线方法失败20次。

Conclusion: P4OMP显著提升了LLM生成OpenMP代码的可靠性和适用性，避免了常见错误。

Abstract: We present P4OMP, a retrieval-augmented framework for transforming serial
C/C++ code into OpenMP-annotated parallel code using large language models
(LLMs). To our knowledge, this is the first system to apply retrieval-based
prompting for OpenMP pragma correctness without model fine-tuning or compiler
instrumentation. P4OMP leverages Retrieval-Augmented Generation (RAG) with
structured instructional knowledge from OpenMP tutorials to improve the
reliability of prompt-driven code generation. By grounding generation in the
retrieved context, P4OMP improves syntactic correctness compared to baseline
prompting with GPT-3.5-Turbo. We evaluate P4OMP against a baseline,
GPT-3.5-Turbo without retrieval, on a comprehensive benchmark of 108 real-world
C++ programs drawn from Stack Overflow, PolyBench, and NAS benchmark suites.
P4OMP achieves 100% compilation success on all parallelizable cases, while the
baseline fails to compile in 20 out of 108 cases. Six cases that rely on
non-random-access iterators or thread-unsafe constructs are excluded due to
fundamental OpenMP limitations. A detailed analysis demonstrates how P4OMP
consistently avoids scoping errors, syntactic misuse, and invalid directive
combinations that commonly affect baseline-generated code. We further
demonstrate strong runtime scaling across seven compute-intensive benchmarks on
an HPC cluster. P4OMP offers a robust, modular pipeline that significantly
improves the reliability and applicability of LLM-generated OpenMP code.

</details>


### [390] [Smaller = Weaker? Benchmarking Robustness of Quantized LLMs in Code Generation](https://arxiv.org/abs/2506.22776)
*Sen Fang,Weiyuan Ding,Antonio Mastropaolo,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术能压缩大语言模型（LLM），降低内存需求并加速推理。本文首次系统研究量化对LLM在代码生成任务中鲁棒性的影响，发现量化模型比全精度模型更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注量化LLM的有效性，而量化对鲁棒性的影响尚未充分探索。本文旨在填补这一空白。

Method: 通过对抗攻击输入提示和模型架构噪声扰动，评估四种LLM家族（LLaMA、DeepSeek、CodeGen、StarCoder）的量化鲁棒性。

Result: 量化LLM在51.59%的对抗实验中表现更优，噪声扰动实验也显示量化模型能承受更高权重干扰。

Conclusion: 量化不仅能降低计算需求，还能提升LLM在代码生成任务中的鲁棒性，为开发更高效的LLM部署策略提供新视角。

Abstract: Quantization has emerged as a mainstream method for compressing Large
Language Models (LLMs), reducing memory requirements and accelerating inference
without architectural modifications. While existing research primarily focuses
on evaluating the effectiveness of quantized LLMs compared to their original
counterparts, the impact on robustness remains largely unexplored.In this
paper, we present the first systematic investigation of how quantization
affects the robustness of LLMs in code generation tasks. Through extensive
experiments across four prominent LLM families (LLaMA, DeepSeek, CodeGen, and
StarCoder) with parameter scales ranging from 350M to 33B, we evaluate
robustness from dual perspectives: adversarial attacks on input prompts and
noise perturbations on model architecture. Our findings challenge conventional
wisdom by demonstrating that quantized LLMs often exhibit superior robustness
compared to their full-precision counterparts, with 51.59% versus 42.86% of our
adversarial experiments showing better resilience in quantized LLMs. Similarly,
our noise perturbation experiments also confirm that LLMs after quantitation
generally withstand higher levels of weight disturbances. These results suggest
that quantization not only reduces computational requirements but can actually
enhance LLMs' reliability in code generation tasks, providing valuable insights
for developing more robust and efficient LLM deployment strategies.

</details>


### [391] [RAILS: Retrieval-Augmented Intelligence for Learning Software Development](https://arxiv.org/abs/2506.22742)
*Wali Mohammad Abdullah,Md. Morshedul Islam,Devraj Parmar,Happy Hasmukhbhai Patel,Sindhuja Prabhakaran,Baidya Saha*

Main category: cs.SE

TL;DR: RAILS框架通过检索增强和迭代验证，显著提升了LLM在Java开发中的代码补全和导入准确性。


<details>
  <summary>Details</summary>
Motivation: LLM在软件开发中常因缺乏上下文而产生不完整或错误的代码，尤其是导入问题。RAILS旨在通过检索增强和验证循环解决这一问题。

Method: RAILS结合FAISS和OpenAI嵌入，从Java资源中检索语义上下文，并通过编译器反馈的迭代验证优化建议。

Result: 在78个真实Java导入错误案例中，RAILS表现优于基线方法，能保持意图、避免幻觉，并正确导入缺失库。

Conclusion: RAILS展示了检索增强和验证循环的有效性，未来将扩展至其他语言和IDE，并引入符号过滤。

Abstract: Large Language Models (LLMs) like GPT-3.5-Turbo are increasingly used to
assist software development, yet they often produce incomplete code or
incorrect imports, especially when lacking access to external or
project-specific documentation. We introduce RAILS (Retrieval-Augmented
Intelligence for Learning Software Development), a framework that augments LLM
prompts with semantically retrieved context from curated Java resources using
FAISS and OpenAI embeddings. RAILS incorporates an iterative validation loop
guided by compiler feedback to refine suggestions. We evaluated RAILS on 78
real-world Java import error cases spanning standard libraries, GUI APIs,
external tools, and custom utilities. Despite using the same LLM, RAILS
outperforms baseline prompting by preserving intent, avoiding hallucinations,
and surfacing correct imports even when libraries are unavailable locally.
Future work will integrate symbolic filtering via PostgreSQL and extend support
to other languages and IDEs.

</details>


### [392] [On the Feasibility of Deduplicating Compiler Bugs with Bisection](https://arxiv.org/abs/2506.23281)
*Xintong Zhou,Zhenyang Xu,Chengnian Sun*

Main category: cs.SE

TL;DR: 论文提出了一种基于二分法的编译器Bug去重方法BugLens，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随机测试发现的编译器Bug中存在大量重复，传统基于程序分析的去重方法计算开销大且通用性差。

Method: 利用二分法定位导致Bug的提交，并结合触发Bug的优化技术，提出BugLens方法。

Result: 在四个真实数据集上，BugLens比现有方法Tamer和D3平均节省26.98%和9.64%的人力。

Conclusion: 二分法因其简单性和通用性，为编译器Bug去重提供了实用解决方案。

Abstract: Random testing has proven to be an effective technique for compiler
validation. However, the debugging of bugs identified through random testing
presents a significant challenge due to the frequent occurrence of duplicate
test programs that expose identical compiler bugs. The process to identify
duplicates is a practical research problem known as bug deduplication. Prior
methodologies for compiler bug deduplication primarily rely on program analysis
to extract bug-related features for duplicate identification, which can result
in substantial computational overhead and limited generalizability. This paper
investigates the feasibility of employing bisection, a standard debugging
procedure largely overlooked in prior research on compiler bug deduplication,
for this purpose. Our study demonstrates that the utilization of bisection to
locate failure-inducing commits provides a valuable criterion for
deduplication, albeit one that requires supplementary techniques for more
accurate identification. Building on these results, we introduce BugLens, a
novel deduplication method that primarily uses bisection, enhanced by the
identification of bug-triggering optimizations to minimize false negatives.
Empirical evaluations conducted on four real-world datasets demonstrate that
BugLens significantly outperforms the state-of-the-art analysis-based
methodologies Tamer and D3 by saving an average of 26.98% and 9.64% human
effort to identify the same number of distinct bugs. Given the inherent
simplicity and generalizability of bisection, it presents a highly practical
solution for compiler bug deduplication in real-world applications.

</details>


### [393] [Privacy-Preserving Methods for Bug Severity Prediction](https://arxiv.org/abs/2506.22752)
*Havvanur Dervişoğlu,Ruşen Halepmollası,Elif Eyvaz*

Main category: cs.SE

TL;DR: 论文研究了基于源代码指标和大语言模型（LLMs）的方法级Bug严重性预测，比较了集中学习、联邦学习和合成数据生成模型的性能，结果表明联邦学习和合成数据方法在不共享数据的情况下表现与集中学习相当。


<details>
  <summary>Details</summary>
Motivation: 工业应用中数据共享受限和标记数据稀缺，阻碍了AI模型的应用，因此探索隐私保护方法（如联邦学习和合成数据）在Bug严重性预测中的潜力。

Method: 使用源代码指标和LLMs，在两种广泛使用的数据集上比较集中学习、联邦学习和合成数据生成模型的性能。

Result: 联邦学习和合成数据生成的模型在不共享数据的情况下，表现与集中训练模型相当。

Conclusion: 隐私保护方法（如联邦学习和合成数据生成）在数据共享受限的工业环境中具有潜力，能有效支持Bug严重性预测。

Abstract: Bug severity prediction is a critical task in software engineering as it
enables more efficient resource allocation and prioritization in software
maintenance. While AI-based analyses and models significantly require access to
extensive datasets, industrial applications face challenges due to data-sharing
constraints and the limited availability of labeled data. In this study, we
investigate method-level bug severity prediction using source code metrics and
Large Language Models (LLMs) with two widely used datasets. We compare the
performance of models trained using centralized learning, federated learning,
and synthetic data generation. Our experimental results, obtained using two
widely recognized software defect datasets, indicate that models trained with
federated learning and synthetic data achieve comparable results to centrally
trained models without data sharing. Our finding highlights the potential of
privacy-preserving approaches such as federated learning and synthetic data
generation to enable effective bug severity prediction in industrial context
where data sharing is a major challenge.
  The source code and dataset are available at our GitHub repository:
https://github.com/drvshavva/EASE2025-Privacy-Preserving-Methods-for-Bug-Severity-Prediction.

</details>


### [394] [What Challenges Do Developers Face When Using Verification-Aware Programming Languages?](https://arxiv.org/abs/2506.23696)
*Francisco Oliveira,Alexandra Mendes,Carolina Carreira*

Main category: cs.SE

TL;DR: 研究探讨了验证感知（VA）语言采用率低的原因，通过分析开发者讨论和调查，发现学习曲线陡峭和可用性问题，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 软件可靠性至关重要，验证感知语言虽提供强保证但采用率低，研究旨在找出障碍并推动其广泛应用。

Method: 通过主题建模分析开发者论坛讨论，并辅以开发者调查，了解VA语言的实际挑战。

Result: 发现主要障碍包括学习曲线陡峭和可用性问题，建议简化工具界面、优化教育材料和改进开发环境集成。

Conclusion: 研究提供了改进VA语言可用性和可访问性的具体建议，有助于推动其更广泛采用。

Abstract: Software reliability is critical in ensuring that the digital systems we
depend on function correctly. In software development, increasing software
reliability often involves testing. However, for complex and critical systems,
developers can use Design by Contract (DbC) methods to define precise
specifications that software components must satisfy. Verification-Aware (VA)
programming languages support DbC and formal verification at compile-time or
run-time, offering stronger correctness guarantees than traditional testing.
However, despite the strong guarantees provided by VA languages, their adoption
remains limited. In this study, we investigate the barriers to adopting VA
languages by analyzing developer discussions on public forums using topic
modeling techniques. We complement this analysis with a developer survey to
better understand the practical challenges associated with VA languages. Our
findings reveal key obstacles to adoption, including steep learning curves and
usability issues. Based on these insights, we identify actionable
recommendations to improve the usability and accessibility of VA languages. Our
findings suggest that simplifying tool interfaces, providing better educational
materials, and improving integration with everyday development environments
could improve the usability and adoption of these languages. Our work provides
actionable insights for improving the usability of VA languages and making
verification tools more accessible.

</details>


### [395] [Generating Privacy Stories From Software Documentation](https://arxiv.org/abs/2506.23014)
*Wilder Baldwin,Shashank Chintakuntla,Shreyah Parajuli,Ali Pourghasemi,Ryan Shanz,Sepideh Ghanavati*

Main category: cs.SE

TL;DR: 论文提出了一种基于链式思维提示（CoT）、上下文学习（ICL）和大语言模型（LLMs）的新方法，用于从软件文档中提取隐私行为并生成隐私需求。结果显示，主流LLMs（如GPT-4o和Llama 3）在此任务上表现优异（F1>0.8），且通过参数调优可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前隐私需求常被视为安全概念或事后考虑，导致合规问题和用户隐私侵犯。现有方法多聚焦于从法规中提取法律要求并评估合规性，而缺乏对软件文档中隐私行为的早期识别。

Method: 结合CoT、ICL和LLMs，从软件文档中提取隐私行为，并生成用户故事格式的隐私需求。

Result: 主流LLMs（如GPT-4o和Llama 3）在隐私行为识别和需求生成任务中F1分数超过0.8，参数调优可进一步提升性能。

Conclusion: 该方法为在软件开发生命周期中利用和优化LLMs生成隐私需求提供了新思路。

Abstract: Research shows that analysts and developers consider privacy as a security
concept or as an afterthought, which may lead to non-compliance and violation
of users' privacy. Most current approaches, however, focus on extracting legal
requirements from the regulations and evaluating the compliance of software and
processes with them. In this paper, we develop a novel approach based on
chain-of-thought prompting (CoT), in-context-learning (ICL), and Large Language
Models (LLMs) to extract privacy behaviors from various software documents
prior to and during software development, and then generate privacy
requirements in the format of user stories. Our results show that most commonly
used LLMs, such as GPT-4o and Llama 3, can identify privacy behaviors and
generate privacy user stories with F1 scores exceeding 0.8. We also show that
the performance of these models could be improved through parameter-tuning. Our
findings provide insight into using and optimizing LLMs for generating privacy
requirements given software documents created prior to or throughout the
software development lifecycle.

</details>


### [396] [Guiding AI to Fix Its Own Flaws: An Empirical Study on LLM-Driven Secure Code Generation](https://arxiv.org/abs/2506.23034)
*Hao Yan,Swapneel Suhas Vaidya,Xiaokuan Zhang,Ziyu Yao*

Main category: cs.SE

TL;DR: 论文评估了大型语言模型（LLMs）在代码生成中的安全性问题，发现其容易生成不安全代码，但通过漏洞提示和反馈可以改善。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码生成中常忽略安全实践，导致漏洞，但缺乏对其生成安全代码和修复漏洞能力的深入研究。

Method: 通过评估LLMs生成不安全代码的倾向、利用自生成漏洞提示生成安全代码的能力，以及不同反馈下的漏洞修复效果。

Result: LLMs易生成不安全代码，但高级模型可通过漏洞提示和细粒度反馈避免或修复漏洞。

Conclusion: 研究为开发者提供了减少LLMs生成代码漏洞的建议。

Abstract: Large Language Models (LLMs) have become powerful tools for automated code
generation. However, these models often overlook critical security practices,
which can result in the generation of insecure code that contains
vulnerabilities-weaknesses or flaws in the code that attackers can exploit to
compromise a system. However, there has been limited exploration of strategies
to guide LLMs in generating secure code and a lack of in-depth analysis of the
effectiveness of LLMs in repairing code containing vulnerabilities. In this
paper, we present a comprehensive evaluation of state-of-the-art LLMs by
examining their inherent tendencies to produce insecure code, their capability
to generate secure code when guided by self-generated vulnerability hints, and
their effectiveness in repairing vulnerabilities when provided with different
levels of feedback. Our study covers both proprietary and open-weight models
across various scales and leverages established benchmarks to assess a wide
range of vulnerability types. Through quantitative and qualitative analyses, we
reveal that although LLMs are prone to generating insecure code, advanced
models can benefit from vulnerability hints and fine-grained feedback to avoid
or fix vulnerabilities. We also provide actionable suggestions to developers to
reduce vulnerabilities when using LLMs for code generation.

</details>


### [397] [HF-DGF: Hybrid Feedback Guided Directed Grey-box Fuzzing](https://arxiv.org/abs/2506.23063)
*Guangfa Lyu,Zhenzhong Cao,Xiaofei Ren,Fengyu Wang*

Main category: cs.SE

TL;DR: HF-DGF是一种新型定向灰盒模糊测试框架，通过混合反馈机制（控制流距离、值流影响分数和切片覆盖率）提升效率和方向性，显著优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 当前定向灰盒模糊测试工具因运行时反馈不足，导致目标到达和状态空间探索效率低下。

Method: 提出混合反馈机制，包括控制流距离计算（基于虚拟ICFG）、值流影响分数和选择性插桩策略。

Result: 在41个真实漏洞测试中，HF-DGF平均比现有工具快2.56至73.75倍，且代码覆盖率最低，显示其高效方向性。

Conclusion: HF-DGF通过混合反馈和选择性插桩显著提升了定向灰盒模糊测试的效率和精确性。

Abstract: Directed Grey-box Fuzzing (DGF) has emerged as a widely adopted technique for
crash reproduction and patch testing, leveraging its capability to precisely
navigate toward target locations and exploit vulnerabilities. However, current
DGF tools are constrained by insufficient runtime feedback, limiting their
efficiency in reaching targets and exploring state spaces. This study presents
HF-DGF, a novel directed grey-box fuzzing framework. Its seed scheduling is
guided by a hybrid feedback mechanism integrating control-flow distance,
value-flow influence score, and slice coverage. To enable precise control-flow
distance feedback, we propose a backward-stepping algorithm to calculate basic
block-level seed distances on a virtual inter-procedural control-flow graph
(ICFG). For effective state space exploration, we introduce value-flow
influence and a corresponding metric, the value-flow influence score.
Additionally, to mitigate runtime overhead from hybrid feedback, we adopt a
novel selective instrumentation strategy. Evaluations on 41 real-world
vulnerabilities show HF-DGF outperforms existing tools: it achieves crash
reproduction 5.05 times faster than AFL, 5.79 times faster than AFLGo, 73.75
times faster than WindRanger, 2.56 times faster than DAFL, and 8.45 times
faster than Beacon on average. Notably, when all fuzzers triggered crashes,
HF-DGF exhibited the lowest code coverage, demonstrating superior
directionality and efficiency. It also surpasses AFLGo, WindRanger, DAFL, and
Beacon in static analysis efficiency.

</details>


### [398] [Repair Ingredients Are All You Need: Improving Large Language Model-Based Program Repair via Repair Ingredients Search](https://arxiv.org/abs/2506.23100)
*Jiayi Zhang,Kai Huang,Jian Zhang,Yang Liu,Chunyang Chen*

Main category: cs.SE

TL;DR: ReinFix是一个基于大型语言模型（LLM）的程序修复框架，通过自主搜索修复成分（内部和外部）提升修复效果。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based APR技术在生成上下文相关和准确补丁方面表现不佳，忽略了修复过程中的关键成分。

Method: ReinFix在推理阶段利用静态分析工具获取内部成分（如变量定义），在解决方案阶段从历史修复中搜索外部成分。

Result: 在Defects4J V1.2和V2.0基准测试中，ReinFix分别修复了146和38个额外错误，优于现有技术。

Conclusion: ReinFix通过结合内部和外部修复成分，显著提升了LLM在程序修复中的表现。

Abstract: Automated Program Repair (APR) techniques aim to automatically fix buggy
programs. Among these, Large Language Model-based (LLM-based) approaches have
shown great promise. Recent advances demonstrate that directly leveraging LLMs
can achieve leading results. However, these techniques remain suboptimal in
generating contextually relevant and accurate patches, as they often overlook
repair ingredients crucial for practical program repair. In this paper, we
propose ReinFix, a novel framework that enables LLMs to autonomously search for
repair ingredients throughout both the reasoning and solution phases of bug
fixing. In the reasoning phase, ReinFix integrates static analysis tools to
retrieve internal ingredients, such as variable definitions, to assist the LLM
in root cause analysis when it encounters difficulty understanding the context.
During the solution phase, when the LLM lacks experience in fixing specific
bugs, ReinFix searches for external ingredients from historical bug fixes with
similar bug patterns, leveraging both the buggy code and its root cause to
guide the LLM in identifying appropriate repair actions, thereby increasing the
likelihood of generating correct patches. Evaluations on two popular benchmarks
(Defects4J V1.2 and V2.0) demonstrate the effectiveness of our approach over
SOTA baselines. Notably, ReinFix fixes 146 bugs, which is 32 more than the
baselines on Defects4J V1.2. On Defects4J V2.0, ReinFix fixes 38 more bugs than
the SOTA. Importantly, when evaluating on the recent benchmarks that are free
of data leakage risk, ReinFix also maintains the best performance.

</details>


### [399] [From Release to Adoption: Challenges in Reusing Pre-trained AI Models for Downstream Developers](https://arxiv.org/abs/2506.23234)
*Peerachai Banyongrakkul,Mansooreh Zahedi,Patanamon Thongtanunam,Christoph Treude,Haoyu Gao*

Main category: cs.SE

TL;DR: 论文分析了预训练模型（PTMs）在下游软件开发中的挑战，通过分析840个GitHub问题报告，提出了七类主要挑战，并发现PTM相关问题解决时间更长。


<details>
  <summary>Details</summary>
Motivation: 探索下游开发者在重用PTMs时面临的挑战，填补现有研究的空白。

Method: 定性分析840个PTM相关GitHub问题报告，系统分类挑战，并进行解决时间统计分析。

Result: 识别出七类主要挑战，PTM相关问题解决时间显著长于非PTM问题。

Conclusion: 研究结果对实践者有重要启示，并提出了未来研究方向。

Abstract: Pre-trained models (PTMs) have gained widespread popularity and achieved
remarkable success across various fields, driven by their groundbreaking
performance and easy accessibility through hosting providers. However, the
challenges faced by downstream developers in reusing PTMs in software systems
are less explored. To bridge this knowledge gap, we qualitatively created and
analyzed a dataset of 840 PTM-related issue reports from 31 OSS GitHub
projects. We systematically developed a comprehensive taxonomy of PTM-related
challenges that developers face in downstream projects. Our study identifies
seven key categories of challenges that downstream developers face in reusing
PTMs, such as model usage, model performance, and output quality. We also
compared our findings with existing taxonomies. Additionally, we conducted a
resolution time analysis and, based on statistical tests, found that
PTM-related issues take significantly longer to be resolved than issues
unrelated to PTMs, with significant variation across challenge categories. We
discuss the implications of our findings for practitioners and possibilities
for future research.

</details>


### [400] [Improving vulnerability type prediction and line-level detection via adversarial training-based data augmentation and multi-task learning](https://arxiv.org/abs/2506.23534)
*Siyu Chen,Jiongyi Yang,Xiang Chen,Menglin Zheng,Minnan Wei,Xiaolin Ju*

Main category: cs.SE

TL;DR: 论文提出了一种结合嵌入层驱动的对抗训练（EDAT）和多任务学习（MTL）的统一方法，用于提升软件漏洞类型预测（VTP）和行级漏洞检测（LVD）的性能。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞对现代系统构成重大威胁，但现有研究存在标记样本稀缺、类别不平衡以及忽视VTP和LVD任务间关联的问题。

Method: 通过EDAT增强模型鲁棒性，利用MTL共享语义模式和任务间相关性。

Result: 实验表明，该方法在VTP和LVD任务上均优于现有基线，尤其在罕见漏洞类型识别和减少误报方面表现突出。

Conclusion: 结合EDAT和MTL的统一方法显著提升了任务性能，值得进一步研究。

Abstract: Context: Software vulnerabilities pose a significant threat to modern
software systems, as evidenced by the growing number of reported
vulnerabilities and cyberattacks. These escalating trends underscore the urgent
need for effective approaches that can automatically detect and understand
software vulnerabilities. Objective: However, the scarcity of labeled samples
and the class imbalance issue in vulnerability datasets present significant
challenges for both Vulnerability Type Prediction (VTP) and Line-level
Vulnerability Detection (LVD), especially for rare yet critical vulnerability
types. Moreover, most existing studies treat VTP and LVD as independent tasks,
overlooking their inherent correlation, which limits the potential to leverage
shared semantic patterns across tasks. Methods: To address these limitations,
we propose a unified approach that integrates Embedding-Layer Driven
Adversarial Training (EDAT) with Multi-task Learning (MTL). Specifically, EDAT
enhances model robustness by introducing adversarial perturbations to
identifier embeddings, guided by semantic importance. Meanwhile, MTL improves
overall performance by leveraging shared representations and inter-task
correlations between VTP and LVD. Results: Extensive experiments demonstrate
that our proposed approach outperforms state-of-the-art baselines on both VTP
and LVD tasks. For VTP, it yields notable improvements in accuracy, precision,
recall, and F1-score, particularly in identifying rare vulnerability types.
Similarly, for LVD, our approach enhances line-level detection accuracy while
significantly reducing false positives. Conclusion: Our study demonstrates that
combining EDAT with MTL provides a unified solution that improves performance
on both tasks and warrants further investigation.

</details>


### [401] [Comparative Analysis of the Code Generated by Popular Large Language Models (LLMs) for MISRA C++ Compliance](https://arxiv.org/abs/2506.23535)
*Malik Muhammad Umer*

Main category: cs.SE

TL;DR: 论文比较了多个大型语言模型（如ChatGPT、Gemini等）生成的C++代码是否符合MISRA C++标准，以评估其在安全关键系统中的适用性。


<details>
  <summary>Details</summary>
Motivation: 安全关键系统的软件需符合严格的编码标准（如MISRA C++），而LLMs生成的代码是否满足这些标准尚不明确。

Method: 对多个流行LLMs（如ChatGPT、Gemini等）生成的C++代码进行MISRA C++合规性分析。

Result: 比较了不同LLMs生成的代码对MISRA C++标准的符合程度。

Conclusion: LLMs生成的代码需进一步验证以确保其在安全关键系统中的合规性。

Abstract: Safety-critical systems are engineered systems whose failure or malfunction
could result in catastrophic consequences. The software development for
safety-critical systems necessitates rigorous engineering practices and
adherence to certification standards like DO-178C for avionics. DO-178C is a
guidance document which requires compliance to well-defined software coding
standards like MISRA C++ to enforce coding guidelines that prevent the use of
ambiguous, unsafe, or undefined constructs. Large Language Models (LLMs) have
demonstrated significant capabilities in automatic code generation across a
wide range of programming languages, including C++. Despite their impressive
performance, code generated by LLMs in safety-critical domains must be
carefully analyzed for conformance to MISRA C++ coding standards. In this
paper, I have conducted a comparative analysis of the C++ code generated by
popular LLMs including: OpenAI ChatGPT, Google Gemini, DeepSeek, Meta AI, and
Microsoft Copilot for compliance with MISRA C++.

</details>


### [402] [QLPro: Automated Code Vulnerability Discovery via LLM and Static Code Analysis Integration](https://arxiv.org/abs/2506.23644)
*Junze Hu,Xiangyu Jin,Yizhe Zeng,Yuling Liu,Yunpeng Li,Dan Du,Kaiyu Xie,Hongsong Zhu*

Main category: cs.SE

TL;DR: QLPro是一个结合LLMs和静态分析工具的漏洞检测框架，在开源项目中表现优于CodeQL。


<details>
  <summary>Details</summary>
Motivation: 提升漏洞检测的全面性和准确性，尤其是在开源项目中。

Method: 系统整合LLMs和静态分析工具，构建新数据集JavaTest进行测试。

Result: QLPro检测到41个漏洞（CodeQL仅24个），并发现6个新漏洞（2个为0-day）。

Conclusion: QLPro在漏洞检测方面表现优异，具有实际应用潜力。

Abstract: We introduce QLPro, a vulnerability detection framework that systematically
integrates LLMs and static analysis tools to enable comprehensive vulnerability
detection across entire open-source projects.We constructed a new dataset,
JavaTest, comprising 10 open-source projects from GitHub with 62 confirmed
vulnerabilities. CodeQL, a state-of-the-art static analysis tool, detected only
24 of these vulnerabilities while QLPro detected 41. Furthermore, QLPro
discovered 6 previously unknown vulnerabilities, 2 of which have been confirmed
as 0-days.

</details>


### [403] [Towards a Science of Developer eXperience (DevX)](https://arxiv.org/abs/2506.23715)
*Benoit Combemale*

Main category: cs.SE

TL;DR: 本文主张将开发者体验（DevX）作为一个独立的研究领域，强调其对软件开发活动和生产力的重要性，并呼吁研究社区采取行动。


<details>
  <summary>Details</summary>
Motivation: 随着软件在现代生活中的普及，开发者的体验（DevX）对软件开发的可持续性和效率至关重要，但这一领域尚未得到充分研究。

Method: 通过分析现有研究和实践，提出DevX的核心科学挑战和跨学科交叉点。

Result: 明确了DevX的关键理论和实践基础，并呼吁研究社区关注这一新兴领域。

Conclusion: DevX应成为软件工程研究的重要方向，以推动更人性化的软件开发实践。

Abstract: As software continues to permeate nearly every facet of modern life, the
complexity and ubiquity of digital services underscore the need for
sustainable, effective, and inclusive software development practices. Although
software engineering has made significant progress in technical challenges
since its inception, the human experience of those involved in software
creation, broadly defined as developers, remains underexplored. This column
advocates for the formal recognition of Developer eXperience (DevX) as a
distinct research field. We argue that DevX profoundly influences critical
development activities and overall productivity, especially as development
becomes increasingly collaborative and diverse in terms of application domains.
Building on existing efforts to measure and enhance DevX, we identify key
rationales, scientific enablers, and interdisciplinary intersections that
support this emerging discipline. We also outline the core scientific
challenges ahead, aiming to call for actions from the research community and to
promote more human-centered approaches to software engineering.

</details>


### [404] [A Survey of LLM-based Automated Program Repair: Taxonomies, Design Paradigms, and Applications](https://arxiv.org/abs/2506.23749)
*Boyang Yang,Zijian Cai,Fengling Liu,Bach Le,Lingming Zhang,Tegawendé F. Bissyandé,Yang Liu,Haoye Tian*

Main category: cs.SE

TL;DR: 论文总结了2022年至2025年间63种基于大语言模型（LLM）的自动程序修复（APR）系统，将其分为四种范式，并分析了检索或分析增强上下文的作用。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在APR中的应用，明确不同范式的优缺点，并提出未来研究方向以解决现有挑战。

Method: 分类63种LLM-based APR系统为四种范式：微调、提示、流程管道和代理框架，分析其特点与权衡。

Result: 揭示了每种范式的关键权衡，如微调的高成本与强任务对齐，提示的快速部署与设计限制等。

Conclusion: 未来研究应结合轻量级人类反馈、仓库感知检索、代码分析和成本感知规划，以提升LLM-based APR的可靠性和效率。

Abstract: Large language models (LLMs) are reshaping automated program repair (APR). We
categorize the recent 63 LLM-based APR systems published from January 2022 to
June 2025 into four paradigms, and show how retrieval- or analysis-augmented
contexts strengthen any of them. This taxonomy clarifies key trade-offs:
fine-tuning delivers strong task alignment at high training cost; prompting
enables rapid deployment but is limited by prompt design and context windows;
procedural pipelines offer reproducible control with moderate overhead; agentic
frameworks tackle multi-hunk or cross-file bugs at the price of increased
latency and complexity. Persistent challenges include verifying semantic
correctness beyond test suites, repairing repository-scale defects, and
lowering the costs of LLMs. We outline research directions that combine
lightweight human feedback, repository-aware retrieval, code analysis, and
cost-aware planning to advance reliable and efficient LLM-based APR.

</details>


### [405] [Software Engineering for Large Language Models: Research Status, Challenges and the Road Ahead](https://arxiv.org/abs/2506.23762)
*Hongzhou Rao,Yanjie Zhao,Xinyi Hou,Shenao Wang,Haoyu Wang*

Main category: cs.SE

TL;DR: 本文从软件工程角度系统分析了大型语言模型（LLM）开发生命周期中的挑战，并提出了潜在研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究未从软件工程角度系统探索LLM开发中的复杂挑战及其解决方案。

Method: 将LLM开发分为六个阶段（需求工程、数据集构建、模型开发与增强、测试与评估、部署与运维、维护与演进），分析各阶段挑战并提出研究方向。

Result: 总结了各阶段的关键挑战及潜在解决方案。

Conclusion: 从软件工程视角为LLM开发的未来进展提供了有价值的见解。

Abstract: The rapid advancement of large language models (LLMs) has redefined
artificial intelligence (AI), pushing the boundaries of AI research and
enabling unbounded possibilities for both academia and the industry. However,
LLM development faces increasingly complex challenges throughout its lifecycle,
yet no existing research systematically explores these challenges and solutions
from the perspective of software engineering (SE) approaches. To fill the gap,
we systematically analyze research status throughout the LLM development
lifecycle, divided into six phases: requirements engineering, dataset
construction, model development and enhancement, testing and evaluation,
deployment and operations, and maintenance and evolution. We then conclude by
identifying the key challenges for each phase and presenting potential research
directions to address these challenges. In general, we provide valuable
insights from an SE perspective to facilitate future advances in LLM
development.

</details>


### [406] [Requirements for Active Assistance of Natural Questions in Software Architecture](https://arxiv.org/abs/2506.23898)
*Diogo Lemos,Ademar Aguiar,Neil B. Harrison*

Main category: cs.SE

TL;DR: 论文探讨了自然问题在架构设计中的重要性及其管理不善的后果，提出了一个支持自然问题生命周期的辅助环境，并通过调研验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 自然问题在架构设计中至关重要，但常被忽视或管理不善，导致架构漂移、知识丢失等问题。研究旨在理解其生命周期并设计支持环境。

Method: 基于文献、需求研讨会和三次设计迭代，提出了自然问题的生命周期，并通过专家调研验证了需求。

Result: 提出了一个辅助环境的功能与非功能需求，并通过调研验证其能有效提升协作、决策和知识保存。

Conclusion: 研究为自然问题的管理提供了理论支持和实践工具，有助于改善架构设计过程。

Abstract: Natural questions are crucial to shaping key architectural decisions and
preserving architectural knowledge. They arise organically during the
architectural design process, often resulting from the existing architectural
experience of the designer and the distinctive characteristics of the system
being designed. However, natural questions are often mismanaged or ignored,
which can lead to architectural drift, knowledge loss, inefficient resource
use, or poor understandability of the system's architecture. We aim to better
understand the lifecycle of natural questions, its key requirements, challenges
and difficulties, and then to envision an assisted environment to properly
support it. The environment should be adaptable and responsive to real-world
constraints and uncertainties by seamlessly integrating knowledge management
tools and artificial intelligence techniques into software development
workflows. Based on existing literature, a requirements workshop, and three
design iterations, we proposed a lifecycle for natural questions and elicited
essential functional and non-functional requirements for such an environment.
At last, the results of a survey conducted with experts helped to analyze and
validate the elicited requirements and proposed features for the environment to
enhance collaboration, decision-making, and the preservation of architectural
knowledge more effectively than conventional methods.

</details>


### [407] [Green Metrics Tool: Measuring for fun and profit](https://arxiv.org/abs/2506.23967)
*Geerd-Dietger Hoffmann,Verena Majuntke*

Main category: cs.SE

TL;DR: 论文介绍了Green Metrics Tool (GMT)，一个用于测量软件资源消耗的框架，旨在优化资源使用和减少碳排放。


<details>
  <summary>Details</summary>
Motivation: 随着计算资源需求的增长，软件对环境的影响日益受到关注，需要工具来测量和评估资源消耗。

Method: 提出GMT框架，采用容器化、可控且可重复的生命周期方法，测量软件关键阶段的资源使用。

Result: GMT支持可视化、可比较性及基于规则和LLM的优化，帮助开发者和研究人员减少软件环境影响。

Conclusion: GMT为软件资源消耗提供了有效的测量和优化工具，有助于减少碳排放。

Abstract: The environmental impact of software is gaining increasing attention as the
demand for computational resources continues to rise. In order to optimize
software resource consumption and reduce carbon emissions, measuring and
evaluating software is a first essential step. In this paper we discuss what
metrics are important for fact base decision making. We introduce the Green
Metrics Tool (GMT), a novel framework for accurately measuring the resource
consumption of software. The tool provides a containerized, controlled, and
reproducible life cycle-based approach, assessing the resource use of software
during key phases. Finally, we discuss GMT features like visualization,
comparability and rule- and LLM-based optimisations highlighting its potential
to guide developers and researchers in reducing the environmental impact of
their software.

</details>


### [408] [STCLocker: Deadlock Avoidance Testing for Autonomous Driving Systems](https://arxiv.org/abs/2506.23995)
*Mingfei Cheng,Renzhi Wang,Xiaofei Xie,Yuan Zhou,Lei Ma*

Main category: cs.SE

TL;DR: 提出了一种名为STCLocker的技术，用于测试多自动驾驶车辆（AVs）的协作性能，特别是避免死锁的能力。


<details>
  <summary>Details</summary>
Motivation: 现有技术主要关注单AV测试，而多AV交通中的协作性能（如死锁问题）尚未充分研究。

Method: STCLocker包含三个关键组件：死锁检测器（Deadlock Oracle）、冲突反馈（Conflict Feedback）和冲突感知场景生成（Conflict-aware Scenario Generation），用于生成死锁场景。

Result: 实验表明，STCLocker在生成死锁场景方面优于现有基线方法。

Conclusion: STCLocker填补了多AV协作性能测试的空白，为自动驾驶系统的安全性和可靠性提供了新工具。

Abstract: Autonomous Driving System (ADS) testing is essential to ensure the safety and
reliability of autonomous vehicles (AVs) before deployment. However, existing
techniques primarily focus on evaluating ADS functionalities in single-AV
settings. As ADSs are increasingly deployed in multi-AV traffic, it becomes
crucial to assess their cooperative performance, particularly regarding
deadlocks, a fundamental coordination failure in which multiple AVs enter a
circular waiting state indefinitely, resulting in motion planning failures.
Despite its importance, the cooperative capability of ADSs to prevent deadlocks
remains insufficiently underexplored. To address this gap, we propose the first
dedicated Spatio-Temporal Conflict-Guided Deadlock Avoidance Testing technique,
STCLocker, for generating DeadLock Scenarios (DLSs), where a group of AVs
controlled by the ADS under test are in a circular wait state. STCLocker
consists of three key components: Deadlock Oracle, Conflict Feedback, and
Conflict-aware Scenario Generation. Deadlock Oracle provides a reliable
black-box mechanism for detecting deadlock cycles among multiple AVs within a
given scenario. Conflict Feedback and Conflict-aware Scenario Generation
collaborate to actively guide AVs into simultaneous competition over spatial
conflict resources (i.e., shared passing regions) and temporal competitive
behaviors (i.e., reaching the conflict region at the same time), thereby
increasing the effectiveness of generating conflict-prone deadlocks. We
evaluate STCLocker on two types of ADSs: Roach, an end-to-end ADS, and OpenCDA,
a module-based ADS supporting cooperative communication. Experimental results
show that, on average, STCLocker generates more DLS than the best-performing
baseline.

</details>


### [409] [Bug Fixing with Broader Context: Enhancing LLM-Based Program Repair via Layered Knowledge Injection](https://arxiv.org/abs/2506.24015)
*Ramtin Ehsani,Esteban Parra,Sonia Haiduc,Preetha Chatterjee*

Main category: cs.SE

TL;DR: 通过分层知识注入框架提升LLM的自动程序修复能力，修复率达到79%，比之前工作提升23%。


<details>
  <summary>Details</summary>
Motivation: 现实项目中，开发者依赖更广泛的上下文信息修复漏洞，而现有方法仅提供有限的错误相关上下文。

Method: 提出分层知识注入框架，逐步增加Bug知识层、仓库知识层和项目知识层的上下文信息。

Result: 在314个漏洞上测试，修复率提升至79%，不同漏洞类型需要不同层次的上下文信息。

Conclusion: 分层上下文注入显著提升修复效果，但复杂漏洞仍需交互式自适应系统。

Abstract: Prompting LLMs with bug-related context (e.g., error messages, stack traces)
improves automated program repair, but many bugs still remain unresolved. In
real-world projects, developers often rely on broader repository and
project-level context beyond the local code to resolve such bugs. In this
paper, we investigate how automatically extracting and providing such knowledge
can improve LLM-based program repair. We propose a layered knowledge injection
framework that incrementally augments LLMs with structured context. It starts
with the Bug Knowledge Layer, which includes information such as the buggy
function and failing tests; expands to the Repository Knowledge Layer, which
adds structural dependencies, related files, and commit history; and finally
injects the Project Knowledge Layer, which incorporates relevant details from
documentation and previously fixed bugs. We evaluate this framework on a
dataset of 314 bugs from BugsInPy using two LLMs (Llama 3.3 and GPT-4o-mini),
and analyze fix rates across six bug types. By progressively injecting
knowledge across layers, our approach achieves a fix rate of 79% (250/314)
using Llama 3.3, a significant improvement of 23% over previous work. All bug
types show improvement with the addition of repository-level context, while
only a subset benefit further from project-level knowledge, highlighting that
different bug types require different levels of contextual information for
effective repair. We also analyze the remaining unresolved bugs and find that
more complex and structurally isolated bugs, such as Program Anomaly and GUI
bugs, remain difficult even after injecting all available information. Our
results show that layered context injection improves program repair and suggest
the need for interactive and adaptive APR systems.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [410] [Causal Inference for Aggregated Treatment](https://arxiv.org/abs/2506.22885)
*Carolina Caetano,Gregorio Caetano,Brantly Callaway,Derek Dyal*

Main category: econ.EM

TL;DR: 论文研究了当治疗变量是多个子治疗变量的聚合时，因果推断的问题，指出即使随机分配，聚合效应的权重也存在问题，并提出解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究聚合治疗变量的边际因果效应时，隐含假设目标参数是子治疗效应的良好平均值，但实际权重可能不唯一、为负，且问题随子治疗数量增加而加剧。

Method: 提出根据子治疗变量是否可观测的两种方法，以避免权重问题。

Result: 发现聚合治疗效应的权重具有不唯一性、可能为负，且问题随子治疗数量和范围增加而指数级恶化。

Conclusion: 建议根据子治疗变量的可观测性采取不同方法，以解决聚合治疗效应中的权重问题。

Abstract: In this paper, we study causal inference when the treatment variable is an
aggregation of multiple sub-treatment variables. Researchers often report
marginal causal effects for the aggregated treatment, implicitly assuming that
the target parameter corresponds to a well-defined average of sub-treatment
effects. We show that, even in an ideal scenario for causal inference such as
random assignment, the weights underlying this average have some key
undesirable properties: they are not unique, they can be negative, and, holding
all else constant, these issues become exponentially more likely to occur as
the number of sub-treatments increases and the support of each sub-treatment
grows. We propose approaches to avoid these problems, depending on whether or
not the sub-treatment variables are observed.

</details>


### [411] [Design-Based and Network Sampling-Based Uncertainties in Network Experiments](https://arxiv.org/abs/2506.22989)
*Kensuke Sakamoto,Yuya Shimizu*

Main category: econ.EM

TL;DR: 研究OLS估计量在网络实验中估计溢出效应时的因果解释和推断问题，发现暴露映射的相关性可能导致估计偏差，并提出稳健方差估计方法。


<details>
  <summary>Details</summary>
Motivation: 探讨在网络实验中，OLS估计量在同时存在处理分配和网络链接不确定性时的表现及其因果解释问题。

Method: 通过理论分析OLS估计量的渐近分布，提出网络稳健的方差估计方法，并通过模拟和实证应用验证。

Result: 发现暴露映射的相关性会污染OLS估计量，导致偏差和溢出效应的高估。

Conclusion: OLS估计量在网络实验中可能因相关性而失效，需采用稳健方法以准确估计溢出效应。

Abstract: OLS estimators are widely used in network experiments to estimate spillover
effects via regressions on exposure mappings that summarize treatment and
network structure. We study the causal interpretation and inference of such OLS
estimators when both design-based uncertainty in treatment assignment and
sampling-based uncertainty in network links are present. We show that
correlations among elements of the exposure mapping can contaminate the OLS
estimand, preventing it from aggregating heterogeneous spillover effects for
clear causal interpretation. We derive the estimator's asymptotic distribution
and propose a network-robust variance estimator. Simulations and an empirical
application reveal sizable contamination bias and inflated spillover estimates.

</details>


### [412] [Modeling European Electricity Market Integration during turbulent times](https://arxiv.org/abs/2506.23289)
*Francesco Ravazzolo,Luca Rossini,Andrea Viselli*

Main category: econ.EM

TL;DR: 论文提出了一种贝叶斯反向无限制混合频率模型，用于分析欧洲电力市场中化石燃料价格和可再生能源发电对电价的影响，发现可再生能源降低电价，而天然气价格是电价差异和不稳定的主要因素。


<details>
  <summary>Details</summary>
Motivation: 研究欧洲电力市场中化石燃料价格和可再生能源发电对电价的影响，以理解市场整合和能源多样化的作用。

Method: 采用贝叶斯反向无限制混合频率模型，结合分层结构捕捉跨国依赖性和异质性因素。

Result: 可再生能源普遍降低电价，而天然气价格是电价差异和不稳定的主要驱动因素。

Conclusion: 能源多样化（尤其是可再生能源）和协调化石燃料供应策略对欧洲能源安全至关重要。

Abstract: This paper introduces a novel Bayesian reverse unrestricted mixed-frequency
model applied to a panel of nine European electricity markets. Our model
analyzes the impact of daily fossil fuel prices and hourly renewable energy
generation on hourly electricity prices, employing a hierarchical structure to
capture cross-country interdependencies and idiosyncratic factors. The
inclusion of random effects demonstrates that electricity market integration
both mitigates and amplifies shocks. Our results highlight that while renewable
energy sources consistently reduce electricity prices across all countries, gas
prices remain a dominant driver of cross-country electricity price disparities
and instability. This finding underscores the critical importance of energy
diversification, above all on renewable energy sources, and coordinated fossil
fuel supply strategies for bolstering European energy security.

</details>


### [413] [P-CRE-DML: A Novel Approach for Causal Inference in Non-Linear Panel Data](https://arxiv.org/abs/2506.23297)
*Amarendra Sharma*

Main category: econ.EM

TL;DR: 提出了一种新的P-CRE-DML框架，用于估计面板数据中的因果效应，结合了DML、CRE和滞后变量，并验证了社会信任对GDP增长的积极影响。


<details>
  <summary>Details</summary>
Motivation: 解决面板数据中非线性性和未观测异质性对因果效应估计的挑战。

Method: 结合Double Machine Learning (DML)、Correlated Random Effects (CRE)和滞后变量，创新性地提出P-CRE-DML框架。

Result: 发现社会信任与经济增长之间存在显著正相关关系，并通过模拟验证了P-CRE-DML的低偏差优势。

Conclusion: P-CRE-DML为面板数据因果推断提供了稳健且灵活的替代方法，适用于更广泛的应用场景。

Abstract: This paper introduces a novel Proxy-Enhanced Correlated Random Effects Double
Machine Learning (P-CRE-DML) framework to estimate causal effects in panel data
with non-linearities and unobserved heterogeneity. Combining Double Machine
Learning (DML, Chernozhukov et al., 2018), Correlated Random Effects (CRE,
Mundlak, 1978), and lagged variables (Arellano & Bond, 1991) and innovating
within the CRE-DML framework (Chernozhukov et al., 2022; Clarke & Polselli,
2025; Fuhr & Papies, 2024), we apply P-CRE-DML to investigate the effect of
social trust on GDP growth across 89 countries (2010-2020). We find positive
and statistically significant relationship between social trust and economic
growth. This aligns with prior findings on trust-growth relationship (e.g.,
Knack & Keefer, 1997). Furthermore, a Monte Carlo simulation demonstrates
P-CRE-DML's advantage in terms of lower bias over CRE-DML and System GMM.
P-CRE-DML offers a robust and flexible alternative for panel data causal
inference, with applications beyond economic growth.

</details>


### [414] [An Improved Inference for IV Regressions](https://arxiv.org/abs/2506.23816)
*Liyu Dou,Pengjin Min,Wenjie Wang,Yichong Zhang*

Main category: econ.EM

TL;DR: 本文提出了一种结合低维IV和多IV的联合推断方法，通过线性组合三种统计量（Wald、LM、AR）实现高效推断，并证明了其最优性。


<details>
  <summary>Details</summary>
Motivation: 解决低维IV和多IV结合使用时如何高效利用信息的问题。

Method: 提出线性组合三种统计量（Wald、LM、AR）的联合推断方法，并分析其渐近性质和最优性。

Result: 证明了该方法在局部备择假设下的渐近正态性，并得出最优组合检验，具有“免费午餐”效率增益。

Conclusion: 该方法在低维IV强识别条件下，是均匀最优无偏检验，且始终优于仅基于低维或多IV的检验。

Abstract: Researchers often report empirical results that are based on low-dimensional
IVs, such as the shift-share IV, together with many IVs. Could we combine these
results in an efficient way and take advantage of the information from both
sides? In this paper, we propose a combination inference procedure to solve the
problem. Specifically, we consider a linear combination of three test
statistics: a standard cluster-robust Wald statistic based on the
low-dimensional IVs, a leave-one-cluster-out Lagrangian Multiplier (LM)
statistic, and a leave-one-cluster-out Anderson-Rubin (AR) statistic. We first
establish the joint asymptotic normality of the Wald, LM, and AR statistics and
derive the corresponding limit experiment under local alternatives. Then, under
the assumption that at least the low-dimensional IVs can strongly identify the
parameter of interest, we derive the optimal combination test based on the
three statistics and establish that our procedure leads to the uniformly most
powerful (UMP) unbiased test among the class of tests considered. In
particular, the efficiency gain from the combined test is of ``free lunch" in
the sense that it is always at least as powerful as the test that is only based
on the low-dimensional IVs or many IVs.

</details>


### [415] [Testing parametric additive time-varying GARCH models](https://arxiv.org/abs/2506.23821)
*Niklas Ahlgren,Alexander Back,Timo Teräsvirta*

Main category: econ.EM

TL;DR: 该论文开发了一种用于构建加性时变（ATV-）GARCH模型的误设检验方法，通过逐步测试从简单到复杂的模型，解决了传统LM检验在零假设下模型未识别的问题。


<details>
  <summary>Details</summary>
Motivation: 传统GARCH模型假设波动率恒定，但实际中波动率可能随时间变化，因此需要开发一种方法来检验和建模时变波动率。

Method: 通过将GARCH模型的波动率方程扩展为包含逻辑转换函数的确定性时变截距，并采用泰勒展开近似解决模型未识别问题，逐步测试从简单到复杂的模型。

Result: 模拟研究表明该方法在小样本下表现良好，应用于VIX指数显示其波动率在2007-2008金融危机后缓慢增加。

Conclusion: 该方法有效检验和建模时变波动率，适用于金融时间序列分析。

Abstract: We develop misspecification tests for building additive time-varying
(ATV-)GARCH models. In the model, the volatility equation of the GARCH model is
augmented by a deterministic time-varying intercept modeled as a linear
combination of logistic transition functions. The intercept is specified by a
sequence of tests, moving from specific to general. The first test is the test
of the standard stationary GARCH model against an ATV-GARCH model with one
transition. The alternative model is unidentified under the null hypothesis,
which makes the usual LM test invalid. To overcome this problem, we use the
standard method of approximating the transition function by a Taylor expansion
around the null hypothesis. Testing proceeds until the first non-rejection. We
investigate the small-sample properties of the tests in a comprehensive
simulation study. An application to the VIX index indicates that the volatility
of the index is not constant over time but begins a slow increase around the
2007-2008 financial crisis.

</details>


### [416] [Robust Inference with High-Dimensional Instruments](https://arxiv.org/abs/2506.23834)
*Qu Feng,Sombut Jaidee,Wenjie Wang*

Main category: econ.EM

TL;DR: 提出了一种针对高维工具变量的弱识别鲁棒性检验方法，适用于工具变量数量超过样本量的情况，且对误差依赖性（如网络或空间依赖性）具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决高维工具变量回归中的弱识别问题，并处理误差依赖性，以提升检验的稳健性。

Method: 采用自归一化形式的检验统计量，并利用随机矩阵理论证明其渐近有效性。

Result: 模拟研究表明，该方法在多种误差依赖结构下均能有效控制检验水平并保持较高的检验功效。

Conclusion: 该方法为高维工具变量回归提供了一种鲁棒且有效的检验工具，适用于复杂依赖结构。

Abstract: We propose a weak-identification-robust test for linear instrumental variable
(IV) regressions with high-dimensional instruments, whose number is allowed to
exceed the sample size. In addition, our test is robust to general error
dependence, such as network dependence and spatial dependence. The test
statistic takes a self-normalized form and the asymptotic validity of the test
is established by using random matrix theory. Simulation studies are conducted
to assess the numerical performance of the test, confirming good size control
and satisfactory testing power across a range of various error dependence
structures.

</details>


### [417] [Minimax and Bayes Optimal Best-arm Identification: Adaptive Experimental Design for Treatment Choice](https://arxiv.org/abs/2506.24007)
*Masahiro Kato*

Main category: econ.EM

TL;DR: 研究提出了一种自适应实验设计方法，用于高效识别最佳治疗方案，结合分配和选择阶段，并证明其同时满足极小极大和贝叶斯最优性。


<details>
  <summary>Details</summary>
Motivation: 解决固定预算下最佳治疗方案识别的问题，旨在高效分配资源以最大化治疗效果。

Method: 采用两阶段分配策略：先均匀分配以筛选次优方案并估计方差，再按方差比例分配；最后选择样本均值最高的方案。

Result: 证明了该设计在简单遗憾下同时满足极小极大和贝叶斯最优性，效率上限与下限匹配。

Conclusion: 该方法无需额外调参即可达到效率极限，适用于多种目标。

Abstract: This study investigates adaptive experimental design for treatment choice,
also known as fixed-budget best-arm identification. We consider an adaptive
procedure consisting of a treatment-allocation phase followed by a
treatment-choice phase, and we design an adaptive experiment for this setup to
efficiently identify the best treatment arm, defined as the one with the
highest expected outcome. In our designed experiment, the treatment-allocation
phase consists of two stages. The first stage is a pilot phase, where we
allocate each treatment arm uniformly with equal proportions to eliminate
clearly suboptimal arms and estimate outcome variances. In the second stage, we
allocate treatment arms in proportion to the variances estimated in the first
stage. After the treatment-allocation phase, the procedure enters the
treatment-choice phase, where we choose the treatment arm with the highest
sample mean as our estimate of the best treatment arm. We prove that this
single design is simultaneously asymptotically minimax and Bayes optimal for
the simple regret, with upper bounds that match our lower bounds up to exact
constants. Therefore, our designed experiment achieves the sharp efficiency
limits without requiring separate tuning for minimax and Bayesian objectives.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [418] [Beyond Code: The Multidimensional Impacts of Large Language Models in Software Development](https://arxiv.org/abs/2506.22704)
*Sardar Fatooreh Bonabi,Sarah Bana,Tingting Nian,Vijay Gurbaxani*

Main category: econ.GN

TL;DR: 研究发现，ChatGPT的使用显著提升了开源软件开发者的生产力、知识共享和技能获取，效果因开发者经验水平而异。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）如何通过代码开发、协作知识转移和技能发展影响开源软件（OSS）领域。

Method: 利用意大利临时禁止ChatGPT的自然实验，采用双重差分法和双向固定效应分析GitHub上88,022名开发者的数据。

Result: ChatGPT使开发者生产力提升6.4%，知识共享增加9.6%，技能获取提高8.4%，效果因经验水平和技术背景而异。

Conclusion: LLMs的战略部署可加速新手开发者成长、促进协作学习，并提升长期组织生产力和敏捷性。

Abstract: Large language models (LLMs) are poised to significantly impact software
development, especially in the Open-Source Software (OSS) sector. To understand
this impact, we first outline the mechanisms through which LLMs may influence
OSS through code development, collaborative knowledge transfer, and skill
development. We then empirically examine how LLMs affect OSS developers' work
in these three key areas. Leveraging a natural experiment from a temporary
ChatGPT ban in Italy, we employ a Difference-in-Differences framework with
two-way fixed effects to analyze data from all OSS developers on GitHub in
three similar countries, Italy, France, and Portugal, totaling 88,022 users. We
find that access to ChatGPT increases developer productivity by 6.4%, knowledge
sharing by 9.6%, and skill acquisition by 8.4%. These benefits vary
significantly by user experience level: novice developers primarily experience
productivity gains, whereas more experienced developers benefit more from
improved knowledge sharing and accelerated skill acquisition. In addition, we
find that LLM-assisted learning is highly context-dependent, with the greatest
benefits observed in technically complex, fragmented, or rapidly evolving
contexts. We show that the productivity effects of LLMs extend beyond direct
code generation to include enhanced collaborative learning and knowledge
exchange among developers; dynamics that are essential for gaining a holistic
understanding of LLMs' impact in OSS. Our findings offer critical managerial
implications: strategically deploying LLMs can accelerate novice developers'
onboarding and productivity, empower intermediate developers to foster
knowledge sharing and collaboration, and support rapid skill acquisition,
together enhancing long-term organizational productivity and agility.

</details>


### [419] [Temperature Sensitivity of Residential Energy Demand on the Global Scale: A Bayesian Partial Pooling Model](https://arxiv.org/abs/2506.22768)
*Peer Lasse Hinrichsen,Katrin Rehdanz,Richard S. J. Tol*

Main category: econ.GN

TL;DR: 本文研究了全球范围内住宅能源需求对温度的敏感性，发现极端低温（<-5°C）和高温（>30°C）会增加电力需求，且发达国家的需求对高温更敏感。


<details>
  <summary>Details</summary>
Motivation: 填补全球范围内住宅能源需求温度敏感性研究的空白。

Method: 使用贝叶斯部分池化模型，估计国家特定的截距和斜率，重点关注非线性温度响应函数。

Result: 极端低温增加电力和天然气需求，高温增加电力需求；发达国家对高温更敏感。

Conclusion: 温度对能源需求的影响因国家发展水平而异，发展中国家可能因无法满足制冷需求而对高温不敏感。

Abstract: This paper contributes to the limited literature on the temperature
sensitivity of residential energy demand on a global scale. Using a Bayesian
Partial Pooling model, we estimate country-specific intercepts and slopes,
focusing on non-linear temperature response functions. The results, based on
data for up to 126 countries spanning from 1978 to 2023, indicate a higher
demand for residential electricity and natural gas at temperatures below -5
degrees Celsius and a higher demand for electricity at temperatures above 30
degrees Celsius. For temperatures above 23.5 degrees Celsius, the relationship
between power demand and temperature steepens. Demand in developed countries is
more sensitive to high temperatures than in less developed countries, possibly
due to an inability to meet cooling demands in the latter.

</details>


### [420] [Tracking the affordability of least-cost healthy diets helps guide intervention for food security and improved nutrition](https://arxiv.org/abs/2506.22965)
*William A. Masters*

Main category: econ.GN

TL;DR: 两篇论文推动了最低成本基准饮食作为监测和改善粮食安全的新工具，帮助区分饮食质量差的原因，并指导干预措施。


<details>
  <summary>Details</summary>
Motivation: 研究旨在利用零售价格数据监测粮食系统，以促进全球健康饮食的普及。

Method: 通过分析177个国家的零售消费者价格数据，提出最低成本饮食作为诊断指标。

Result: 论文推动了最低成本饮食作为全球粮食安全的新指标，帮助识别饮食问题的根源。

Conclusion: 最低成本饮食指标为全球粮食安全提供了新视角，有助于针对性干预以实现健康饮食普及。

Abstract: This Policy Comment describes how the Food Policy article entitled 'Cost and
affordability of nutritious diets at retail prices: Evidence from 177
countries' (first published October 2020) and 'Retail consumer price data
reveal gaps and opportunities to monitor food systems for nutrition' (first
published September 2021) advanced the use of least-cost benchmark diets to
monitor and improve food security. Those papers contributed to the worldwide
use of least-cost diets as a new diagnostic indicator of food access, helping
to distinguish among causes of poor diet quality related to high prices, low
incomes, or displacement by other food options, thereby guiding intervention
toward universal access to healthy diets.

</details>


### [421] [Digital Transformation and the Restructuring of Employment: Evidence from Chinese Listed Firms](https://arxiv.org/abs/2506.23230)
*Yubo Cheng*

Main category: econ.GN

TL;DR: 研究探讨数字化如何重塑中国上市公司的就业结构，重点关注职业功能和任务强度。


<details>
  <summary>Details</summary>
Motivation: 分析数字化对中国企业就业结构的影响，揭示技术变革对劳动力市场的动态影响。

Method: 使用ISCO-08和中国职业分类标准2022对招聘数据分类，构建任务强度指数，通过关键词分析任务需求。

Result: 数字化增加了管理、专业和技术岗位需求，减少了辅助和体力劳动；抽象任务需求上升，常规和体力任务下降。

Conclusion: 数字化通过提升管理效率和薪酬结构，重塑了中国企业的技能需求和劳动力动态。

Abstract: This paper examines how digital transformation reshapes employment structures
within Chinese listed firms, focusing on occupational functions and task
intensity. Drawing on recruitment data classified under ISCO-08 and the Chinese
Standard Occupational Classification 2022, we categorize jobs into five
functional groups: management, professional, technical, auxiliary, and manual.
Using a task-based framework, we construct routine, abstract, and manual task
intensity indices through keyword analysis of job descriptions. We find that
digitalization is associated with increased hiring in managerial, professional,
and technical roles, and reduced demand for auxiliary and manual labor. At the
task level, abstract task demand rises, while routine and manual tasks decline.
Moderation analyses link these shifts to improvements in managerial efficiency
and executive compensation. Our findings highlight how emerging technologies,
including large language models (LLMs), are reshaping skill demands and labor
dynamics in Chinas corporate sector.

</details>


### [422] [Evaluating the EU Carbon Border Adjustment Mechanism with a Quantitative Trade Model](https://arxiv.org/abs/2506.23341)
*Noemi Walczak,Kenan Huremović,Armando Rungi*

Main category: econ.GN

TL;DR: 研究分析了欧洲碳边境调整机制（CBAM）的经济与环境影响，发现其对欧盟内部经济和贸易流向有轻微影响，同时显著减少了直接和间接进口中的碳排放。


<details>
  <summary>Details</summary>
Motivation: 探讨CBAM对贸易、福利和排放的均衡影响，填补了现有研究中缺乏对ETS与CBAM价格联合内生化的定量分析空白。

Method: 采用多国多部门一般均衡模型，结合投入产出联系，分析贸易流、福利和排放的均衡响应。

Result: CBAM使欧盟国民总支出（GNE）微增0.005%，直接进口碳排放减少4.80%，间接进口碳排放减少3%；非欧盟国家GNE略降0.009%，碳泄漏减少0.11%。

Conclusion: CBAM通过促进清洁生产和减少碳泄漏，有效降低了全球碳排放，但需考虑生产网络的复杂影响。

Abstract: This paper examines the economic and environmental impacts of the European
Carbon Border Adjustment Mechanism (CBAM). We develop a multi-country,
multi-sector general equilibrium model with input-output linkages and
characterise the general equilibrium response of trade flows, welfare and
emissions. As far as we know, this is the first quantitative trade model that
jointly endogenises the Emission Trading Scheme (ETS) allowances and CBAM
prices. We find that the CBAM increases by 0.005\% the EU Gross National
Expenditure (GNE), while trade shifts towards domestic cleaner production.
Notably, emissions embodied in direct EU imports fall by almost 4.80\%, but
supply chain's upstream substitution effects imply a decrease in emissions
embodied in EU indirect imports by about 3\%. The latter involves a dampening
effect that we can detect only by explicitly incorporating the production
network. In contrast, extra-EU countries experience a slight decline in GNE
(0.009\%) and a reduction in emissions leakage (0.11\%).

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [423] [Entropy Regularized Belief Reporting](https://arxiv.org/abs/2506.22649)
*Elchin Suleymanov*

Main category: econ.TH

TL;DR: 本文研究了分区依赖模型（ERBR），通过熵正则化方法刻画代理人在报告信念时的行为，并应用于实验数据。


<details>
  <summary>Details</summary>
Motivation: 探讨代理人在报告信念时如何因状态分组方式而受到影响，揭示其潜在偏好。

Method: 提出熵正则化信念报告模型（ERBR），通过最小化与潜在基准先验的KL散度并引入熵正则化。

Result: 模型通过公理化方法得到验证，并成功应用于Benjamin等人（2017）的实验数据。

Conclusion: ERBR模型有效解释了分区依赖现象，揭示了代理人在信念报告中的非承诺偏好。

Abstract: This paper investigates a model of partition dependence, a widely reported
experimental finding where the agent's reported beliefs depend on how the
states are grouped. In the model, called Entropy Regularized Belief Reporting
(ERBR), the agent is endowed with a latent benchmark prior that is unobserved
by the analyst. When presented with a partition, the agent reports a prior that
minimizes Kullback-Leibler divergence from the latent benchmark prior subject
to entropy regularization. This captures the intuition that while the agent
would like to report a prior that is close to her latent benchmark prior, she
may also have a preference to remain noncommittal. I axiomatically characterize
the model and apply it to the experimental data from Benjamin et al. (2017).

</details>


### [424] [Flexible Moral Hazard Problems with Adverse Selection](https://arxiv.org/abs/2506.23954)
*Siwen Liu*

Main category: econ.TH

TL;DR: 研究道德风险与逆向选择问题，委托人设计满足有限责任的合同菜单，通过调节合同“范围”和“力度”影响代理人的努力水平和产出分布。


<details>
  <summary>Details</summary>
Motivation: 探讨在代理人能控制产出分布且拥有生产环境私有信息的情况下，委托人如何设计合同菜单以优化激励和产出。

Method: 委托人设计合同菜单，调节合同的“范围”和“力度”，分析其对代理人努力和产出分布的影响。

Result: 最优合同可能是单一全范围合同，或低类型合同排除高产出，或高类型合同排除低产出。凸努力函数下给出单一全范围合同最优的充要条件。

Conclusion: 在特定条件下，单一全范围合同是最优的，且该条件在一般努力函数下也成立。

Abstract: We study a moral hazard problem with adverse selection: a risk-neutral agent
can directly control the output distribution and possess private information
about the production environment. The principal designs a menu of contracts
satisfying limited liability. Deviating from classical models, not only can the
principal motivate the agent to exert certain levels of aggregate efforts by
designing the "power" of the contracts, but she can also regulate the support
of the chosen output distributions by designing the "range" of the contract. We
show that it is either optimal for the principal to provide a single full-range
contract, or the optimal low-type contract range excludes some high outputs, or
the optimal high-type contract range excludes some low outputs. We provide
sufficient and necessary conditions on when a single full-range contract is
optimal under convex effort functions, and show that this condition is also
sufficient with general effort functions.

</details>
