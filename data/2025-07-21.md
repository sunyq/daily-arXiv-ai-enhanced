<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 20]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 82]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 5]
- [econ.EM](#econ.EM) [Total: 3]
- [econ.GN](#econ.GN) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination](https://arxiv.org/abs/2507.13511)
*Nabil Abdelaziz Ferhat Taleb,Abdolazim Rezaei,Raj Atulkumar Patel,Mehdi Sookhak*

Main category: cs.AI

TL;DR: GraphTrafficGPT提出了一种基于图的新型架构，通过并行执行和动态资源分配优化了LLM驱动的交通管理任务，显著降低了令牌消耗和响应延迟。


<details>
  <summary>Details</summary>
Motivation: 解决现有链式系统（如TrafficGPT）在顺序任务执行、高令牌使用和可扩展性差方面的不足，以应对复杂的现实交通场景。

Method: 采用图结构表示任务及其依赖关系，引入Brain Agent分解查询、构建依赖图，并协调多个专业代理进行数据处理。

Result: 实验显示，GraphTrafficGPT令牌消耗减少50.2%，响应延迟降低19.0%，多查询执行效率提升23.0%。

Conclusion: GraphTrafficGPT显著提升了LLM在交通管理中的效率和可扩展性，适用于现代城市交通环境。

Abstract: Large Language Models (LLMs) offer significant promise for intelligent
traffic management; however, current chain-based systems like TrafficGPT are
hindered by sequential task execution, high token usage, and poor scalability,
making them inefficient for complex, real-world scenarios. To address these
limitations, we propose GraphTrafficGPT, a novel graph-based architecture,
which fundamentally redesigns the task coordination process for LLM-driven
traffic applications. GraphTrafficGPT represents tasks and their dependencies
as nodes and edges in a directed graph, enabling efficient parallel execution
and dynamic resource allocation. The main idea behind the proposed model is a
Brain Agent that decomposes user queries, constructs optimized dependency
graphs, and coordinates a network of specialized agents for data retrieval,
analysis, visualization, and simulation. By introducing advanced context-aware
token management and supporting concurrent multi-query processing, the proposed
architecture handles interdependent tasks typical of modern urban mobility
environments. Experimental results demonstrate that GraphTrafficGPT reduces
token consumption by 50.2% and average response latency by 19.0% compared to
TrafficGPT, while supporting simultaneous multi-query execution with up to
23.0% improvement in efficiency.

</details>


### [2] [PrefPalette: Personalized Preference Modeling with Latent Attributes](https://arxiv.org/abs/2507.13541)
*Shuyue Stella Li,Melanie Sclar,Hunter Lang,Ansong Ni,Jacqueline He,Puxin Xu,Andrew Cohen,Chan Young Park,Yulia Tsvetkov,Asli Celikyilmaz*

Main category: cs.AI

TL;DR: PrefPalette框架通过分解偏好属性并基于社区价值观预测偏好，优于GPT-4o，并提供可解释的洞察。


<details>
  <summary>Details</summary>
Motivation: 当前偏好模型将人类判断视为黑箱，缺乏对偏好背后原因的理解。PrefPalette旨在解决这一问题。

Method: 结合多属性决策原则，包括生成合成数据以隔离属性效应，以及基于注意力的偏好建模。

Result: 在Reddit的45个社区中，PrefPalette预测准确率比GPT-4o高46.6%，并揭示了社区特定的偏好特征。

Conclusion: PrefPalette不仅提升了偏好建模性能，还提供了透明、可解释的洞察，为个性化应用奠定了基础。

Abstract: Personalizing AI systems requires understanding not just what users prefer,
but the reasons that underlie those preferences - yet current preference models
typically treat human judgment as a black box. We introduce PrefPalette, a
framework that decomposes preferences into attribute dimensions and tailors its
preference prediction to distinct social community values in a
human-interpretable manner. PrefPalette operationalizes a cognitive science
principle known as multi-attribute decision making in two ways: (1) a scalable
counterfactual attribute synthesis step that involves generating synthetic
training data to isolate for individual attribute effects (e.g., formality,
humor, cultural values), and (2) attention-based preference modeling that
learns how different social communities dynamically weight these attributes.
This approach moves beyond aggregate preference modeling to capture the diverse
evaluation frameworks that drive human judgment. When evaluated on 45 social
communities from the online platform Reddit, PrefPalette outperforms GPT-4o by
46.6% in average prediction accuracy. Beyond raw predictive improvements,
PrefPalette also shed light on intuitive, community-specific profiles:
scholarly communities prioritize verbosity and stimulation, conflict-oriented
communities value sarcasm and directness, and support-based communities
emphasize empathy. By modeling the attribute-mediated structure of human
judgment, PrefPalette delivers both superior preference modeling and
transparent, interpretable insights, and serves as a first step toward more
trustworthy, value-aware personalized applications.

</details>


### [3] [GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models](https://arxiv.org/abs/2507.13550)
*Eduardo C. Garrido-Merchán,Cristina Puente*

Main category: cs.AI

TL;DR: 提出了一种结合大语言模型（LLMs）和符号系统的新方法，以开发可控、透明的专家系统，解决LLMs的幻觉和不可验证性问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在生成信息时可能产生的幻觉或错误事实的问题，确保专家系统的可靠性和可解释性。

Method: 通过限制领域并使用结构化提示提取方法，将知识转化为Prolog符号表示，并由人类专家验证和修正。

Result: 实验表明，该方法在事实准确性和语义一致性上表现优异，结合了LLMs的召回能力和符号系统的精确性。

Conclusion: 提出了一种透明混合解决方案，为敏感领域提供了可靠的AI应用基础。

Abstract: The development of large language models (LLMs) has successfully transformed
knowledge-based systems such as open domain question nswering, which can
automatically produce vast amounts of seemingly coherent information. Yet,
those models have several disadvantages like hallucinations or confident
generation of incorrect or unverifiable facts. In this paper, we introduce a
new approach to the development of expert systems using LLMs in a controlled
and transparent way. By limiting the domain and employing a well-structured
prompt-based extraction approach, we produce a symbolic representation of
knowledge in Prolog, which can be validated and corrected by human experts.
This approach also guarantees interpretability, scalability and reliability of
the developed expert systems. Via quantitative and qualitative experiments with
Claude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic
coherence on our generated knowledge bases. We present a transparent hybrid
solution that combines the recall capacity of LLMs with the precision of
symbolic systems, thereby laying the foundation for dependable AI applications
in sensitive domains.

</details>


### [4] [Why Isn't Relational Learning Taking Over the World?](https://arxiv.org/abs/2507.13558)
*David Poole*

Main category: cs.AI

TL;DR: 论文探讨了AI应关注实体及其关系而非感知数据（如像素、文字），并分析了关系学习未普及的原因及改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前AI主要建模感知数据（如像素、文字），但世界由实体及其关系构成。关系学习虽重要，却未广泛应用。

Method: 通过分析关系学习（如统计关系AI）的现状，指出其局限性及未普及的原因。

Result: 关系学习仅在有限场景中应用，需改进以发挥其潜力。

Conclusion: 应推动关系学习发展，使其在AI领域占据更重要的地位。

Abstract: AI seems to be taking over the world with systems that model pixels, words,
and phonemes. The world is arguably made up, not of pixels, words, and phonemes
but of entities (objects, things, including events) with properties and
relations among them. Surely we should model these, not the perception or
description of them. You might suspect that concentrating on modeling words and
pixels is because all of the (valuable) data in the world is in terms of text
and images. If you look into almost any company you will find their most
valuable data is in spreadsheets, databases and other relational formats. These
are not the form that are studied in introductory machine learning, but are
full of product numbers, student numbers, transaction numbers and other
identifiers that can't be interpreted naively as numbers. The field that
studies this sort of data has various names including relational learning,
statistical relational AI, and many others. This paper explains why relational
learning is not taking over the world -- except in a few cases with restricted
relations -- and what needs to be done to bring it to it's rightful prominence.

</details>


### [5] [BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety](https://arxiv.org/abs/2507.13625)
*Yuxin Zhang,Xi Wang,Mo Hu,Zhenyu Zhang*

Main category: cs.AI

TL;DR: BifrostRAG是一种双图RAG系统，通过实体网络图和文档导航图结合语言关系和文档结构，显著提升多跳问题回答性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG系统在处理复杂法规文本和多跳查询时的局限性。

Method: 引入双图架构（实体网络图和文档导航图），结合图遍历和向量语义搜索的混合检索机制。

Result: 在评估中达到92.8%的精确率、85.5%的召回率和87.3%的F1分数，显著优于单模态RAG基线。

Conclusion: BifrostRAG为复杂技术文档的检索和问答提供了可迁移的解决方案，适用于知识密集型工程领域。

Abstract: Information retrieval and question answering from safety regulations are
essential for automated construction compliance checking but are hindered by
the linguistic and structural complexity of regulatory text. Many
compliance-related queries are multi-hop, requiring synthesis of information
across interlinked clauses. This poses a challenge for traditional
retrieval-augmented generation (RAG) systems. To overcome this, we introduce
BifrostRAG: a dual-graph RAG-integrated system that explicitly models both
linguistic relationships (via an Entity Network Graph) and document structure
(via a Document Navigator Graph). This architecture powers a hybrid retrieval
mechanism that combines graph traversal with vector-based semantic search,
enabling large language models to reason over both the meaning and the
structure of the text. Evaluation on a multi-hop question dataset shows that
BifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1
score of 87.3 percent. These results significantly outperform vector-only and
graph-only RAG baselines that represent current leading approaches. Error
analysis further highlights the comparative advantages of our hybrid method
over single-modality RAGs. These findings establish BifrostRAG as a robust
knowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid
retrieval mechanism offers a transferable blueprint for navigating complex
technical documents across knowledge-intensive engineering domains.

</details>


### [6] [CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.14111)
*Xiaoya Li,Xiaofei Sun,Albert Wang,Jiwei Li,Chris Shum*

Main category: cs.AI

TL;DR: CUDA-L1是一种基于强化学习的自动化CUDA优化框架，显著提升GPU计算效率，平均加速比达17.7倍，并具有跨架构的优异移植性。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型对GPU计算资源的需求激增，现有模型在CUDA优化任务上成功率低，亟需自动化优化策略。

Method: 采用强化学习框架CUDA-L1，通过速度提升作为奖励信号训练模型，无需人工干预或领域知识。

Result: 在NVIDIA A100上平均加速17.7倍，峰值达449倍，并在多种GPU架构上表现优异。

Conclusion: CUDA-L1展示了强化学习在自动化CUDA优化中的潜力，有望显著提升GPU效率并缓解资源压力。

Abstract: The exponential growth in demand for GPU computing resources, driven by the
rapid advancement of Large Language Models, has created an urgent need for
automated CUDA optimization strategies. While recent advances in LLMs show
promise for code generation, current SOTA models (e.g. R1, o1) achieve low
success rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an
automated reinforcement learning framework for CUDA optimization.
  CUDA-L1 achieves performance improvements on the CUDA optimization task:
trained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250
CUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the
model also demonstrates excellent portability across GPU architectures,
achieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,
x14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.
Beyond these benchmark results, CUDA-L1 demonstrates several remarkable
properties: 1) Discovers a variety of CUDA optimization techniques and learns
to combine them strategically to achieve optimal performance; 2) Uncovers
fundamental principles of CUDA optimization; 3) Identifies non-obvious
performance bottlenecks and rejects seemingly beneficial optimizations that
harm performance.
  The capabilities of CUDA-L1 demonstrate that reinforcement learning can
transform an initially poor-performing LLM into an effective CUDA optimizer
through speedup-based reward signals alone, without human expertise or domain
knowledge. More importantly, the trained RL model extend the acquired reasoning
abilities to new kernels. This paradigm opens possibilities for automated
optimization of CUDA operations, and holds promise to substantially promote GPU
efficiency and alleviate the rising pressure on GPU computing resources.

</details>


### [7] [Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks](https://arxiv.org/abs/2507.13651)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 论文探讨了基于最终答案的自动错误诊断方法，用于解决学生在智能辅导系统中组合多步骤时的错误诊断问题，结果表明该方法能有效诊断29.4%的步骤，并与教师诊断结果高度一致。


<details>
  <summary>Details</summary>
Motivation: 智能辅导系统中，学生组合多步骤时可能产生大量路径，导致错误诊断困难。通过最终答案诊断可以减少组合爆炸问题，提高诊断效率。

Method: 设计了一种基于最终答案的错误诊断服务，用于诊断学生组合多步骤时的错误规则，并在二次方程求解数据集上验证其有效性。

Result: 该方法能诊断29.4%的未诊断步骤，且与教师诊断结果的一致性达到97%。

Conclusion: 基于最终答案的错误诊断方法具有潜力，为未来研究提供了基础。

Abstract: Many intelligent tutoring systems can support a student in solving a stepwise
task. When a student combines several steps in one step, the number of possible
paths connecting consecutive inputs may be very large. This combinatorial
explosion makes error diagnosis hard. Using a final answer to diagnose a
combination of steps can mitigate the combinatorial explosion, because there
are generally fewer possible (erroneous) final answers than (erroneous)
solution paths. An intermediate input for a task can be diagnosed by
automatically completing it according to the task solution strategy and
diagnosing this solution. This study explores the potential of automated error
diagnosis based on a final answer. We investigate the design of a service that
provides a buggy rule diagnosis when a student combines several steps. To
validate the approach, we apply the service to an existing dataset (n=1939) of
unique student steps when solving quadratic equations, which could not be
diagnosed by a buggy rule service that tries to connect consecutive inputs with
a single rule. Results show that final answer evaluation can diagnose 29,4% of
these steps. Moreover, a comparison of the generated diagnoses with teacher
diagnoses on a subset (n=115) shows that the diagnoses align in 97% of the
cases. These results can be considered a basis for further exploration of the
approach.

</details>


### [8] [Combining model tracing and constraint-based modeling for multistep strategy diagnoses](https://arxiv.org/abs/2507.13652)
*Gerben van der Hoek,Johan Jeuring,Rogier Bos*

Main category: cs.AI

TL;DR: 提出了一种结合模型追踪和约束建模的方法，用于诊断学生在多步任务中的输入，并在实际数据中验证了其与教师诊断的一致性。


<details>
  <summary>Details</summary>
Motivation: 结合模型追踪和约束建模的优势，以更灵活地诊断学生输入，尤其是当学生将多个步骤合并为一步时。

Method: 通过将约束定义为学生输入与策略步骤的共同属性，设计了一个多步策略诊断系统，并在二次方程求解数据集中验证。

Result: 系统诊断与教师编码在所有140个学生步骤中完全一致。

Conclusion: 该方法有效结合了两种诊断范式，能够准确识别学生偏离策略的情况，即使步骤被合并。

Abstract: Model tracing and constraint-based modeling are two approaches to diagnose
student input in stepwise tasks. Model tracing supports identifying consecutive
problem-solving steps taken by a student, whereas constraint-based modeling
supports student input diagnosis even when several steps are combined into one
step. We propose an approach that merges both paradigms. By defining
constraints as properties that a student input has in common with a step of a
strategy, it is possible to provide a diagnosis when a student deviates from a
strategy even when the student combines several steps. In this study we explore
the design of a system for multistep strategy diagnoses, and evaluate these
diagnoses. As a proof of concept, we generate diagnoses for an existing dataset
containing steps students take when solving quadratic equations (n=2136). To
compare with human diagnoses, two teachers coded a random sample of deviations
(n=70) and applications of the strategy (n=70). Results show that that the
system diagnosis aligned with the teacher coding in all of the 140 student
steps.

</details>


### [9] [DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs](https://arxiv.org/abs/2507.13737)
*Ye Tian,Xiaoyuan Ren,Zihao Wang,Onat Gungor,Xiaofan Yu,Tajana Rosing*

Main category: cs.AI

TL;DR: DailyLLM是一个基于轻量级LLM的框架，通过整合位置、运动、环境和生理四个维度的上下文信息，显著提升了活动日志生成的准确性、效率和语义丰富度。


<details>
  <summary>Details</summary>
Motivation: 现有活动日志生成方法在准确性、效率和语义丰富度方面存在不足，需要一种更高效且全面的解决方案。

Method: 提出DailyLLM，结合结构化提示和高效特征提取，利用智能手机和智能手表的传感器数据。

Result: 实验表明，DailyLLM在BERTScore精度上比70B参数的SOTA基线提升17%，推理速度快10倍。

Conclusion: DailyLLM为活动日志生成提供了一种高效、轻量且全面的解决方案。

Abstract: Rich and context-aware activity logs facilitate user behavior analysis and
health monitoring, making them a key research focus in ubiquitous computing.
The remarkable semantic understanding and generation capabilities of Large
Language Models (LLMs) have recently created new opportunities for activity log
generation. However, existing methods continue to exhibit notable limitations
in terms of accuracy, efficiency, and semantic richness. To address these
challenges, we propose DailyLLM. To the best of our knowledge, this is the
first log generation and summarization system that comprehensively integrates
contextual activity information across four dimensions: location, motion,
environment, and physiology, using only sensors commonly available on
smartphones and smartwatches. To achieve this, DailyLLM introduces a
lightweight LLM-based framework that integrates structured prompting with
efficient feature extraction to enable high-level activity understanding.
Extensive experiments demonstrate that DailyLLM outperforms state-of-the-art
(SOTA) log generation methods and can be efficiently deployed on personal
computers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM
achieves a 17% improvement in log generation BERTScore precision compared to
the 70B-parameter SOTA baseline, while delivering nearly 10x faster inference
speed.

</details>


### [10] [OntView: What you See is What you Meant](https://arxiv.org/abs/2507.13759)
*Carlos Bobed,Carlota Quintana,Eduardo Mena,Jorge Bobed,Fernando Bobillo*

Main category: cs.AI

TL;DR: OntView是一个直观的、用户友好的本体可视化工具，通过动态简化视图和展示推理知识，解决了现有工具在可视化大型本体结构时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有本体可视化工具无法有效展示复杂本体结构，限制了用户对依赖关系和属性的理解。

Method: OntView采用DL推理器，遵循“所见即所得”原则，支持GCI可视化，并提供动态简化视图功能。

Result: OntView能够直观展示本体概念及其关系，避免信息过载，并已开源发布。

Conclusion: OntView为大型本体的可视化提供了有效解决方案，提升了用户的理解能力。

Abstract: In the field of knowledge management and computer science, ontologies provide
a structured framework for modeling domain-specific knowledge by defining
concepts and their relationships. However, the lack of tools that provide
effective visualization is still a significant challenge. While numerous
ontology editors and viewers exist, most of them fail to graphically represent
ontology structures in a meaningful and non-overwhelming way, limiting users'
ability to comprehend dependencies and properties within large ontological
frameworks.
  In this paper, we present OntView, an ontology viewer that is designed to
provide users with an intuitive visual representation of ontology concepts and
their formal definitions through a user-friendly interface. Building on the use
of a DL reasoner, OntView follows a "What you see is what you meant" paradigm,
showing the actual inferred knowledge. One key aspect for this is its ability
to visualize General Concept Inclusions (GCI), a feature absent in existing
visualization tools. Moreover, to avoid a possible information overload,
OntView also offers different ways to show a simplified view of the ontology
by: 1) creating ontology summaries by assessing the importance of the concepts
(according to different available algorithms), 2) focusing the visualization on
the existing TBox elements between two given classes and 3) allowing to
hide/show different branches in a dynamic way without losing the semantics.
OntView has been released with an open-source license for the whole community.

</details>


### [11] [From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning](https://arxiv.org/abs/2507.13768)
*Renato Ghisellini,Remo Pareschi,Marco Pedroni,Giovanni Battista Raggi*

Main category: cs.AI

TL;DR: 提出了一种结合启发式提取、语义激活和组合合成的混合架构，用于增强代理的战略推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统决策引擎通常选择最佳规则，而该研究旨在通过语义交互建模和修辞框架，将冲突的启发式融合为连贯且上下文敏感的叙述。

Method: 结合启发式提取、语义激活和组合合成，利用量子认知研究的语义相互依赖性，激活和组合多个启发式。

Result: 通过Meta与FTC的案例研究展示了该框架，并通过语义指标进行了初步验证。

Conclusion: 讨论了局限性（如动态干扰调整）和未来扩展方向。

Abstract: We present a hybrid architecture for agent-augmented strategic reasoning,
combining heuristic extraction, semantic activation, and compositional
synthesis. Drawing on sources ranging from classical military theory to
contemporary corporate strategy, our model activates and composes multiple
heuristics through a process of semantic interdependence inspired by research
in quantum cognition. Unlike traditional decision engines that select the best
rule, our system fuses conflicting heuristics into coherent and
context-sensitive narratives, guided by semantic interaction modeling and
rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,
with preliminary validation through semantic metrics. Limitations and
extensions (e.g., dynamic interference tuning) are discussed.

</details>


### [12] [When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction](https://arxiv.org/abs/2507.13825)
*Haoyang Li,Yuming Xu,Yiming Li,Hanmo Liu,Darian Li,Chen Jason Zhang,Lei Chen,Qing Li*

Main category: cs.AI

TL;DR: EAGLE是一个轻量级框架，用于动态图中的时序链接预测，通过结合短期时序和长期全局结构模式，显著提高了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有T-GNN在建模时序和结构依赖时存在计算开销大、效率低的问题，需要一种更高效的解决方案。

Method: EAGLE包含时间感知模块（聚合最近邻居信息）和结构感知模块（利用时序个性化PageRank），并通过自适应权重机制平衡两者。

Result: 在七个真实时序图上，EAGLE在性能和效率上均优于现有T-GNN，速度提升超过50倍。

Conclusion: EAGLE通过轻量级设计解决了T-GNN的效率问题，同时保持了高性能。

Abstract: Temporal link prediction in dynamic graphs is a critical task with
applications in diverse domains such as social networks, recommendation
systems, and e-commerce platforms. While existing Temporal Graph Neural
Networks (T-GNNs) have achieved notable success by leveraging complex
architectures to model temporal and structural dependencies, they often suffer
from scalability and efficiency challenges due to high computational overhead.
In this paper, we propose EAGLE, a lightweight framework that integrates
short-term temporal recency and long-term global structural patterns. EAGLE
consists of a time-aware module that aggregates information from a node's most
recent neighbors to reflect its immediate preferences, and a structure-aware
module that leverages temporal personalized PageRank to capture the influence
of globally important nodes. To balance these attributes, EAGLE employs an
adaptive weighting mechanism to dynamically adjust their contributions based on
data characteristics. Also, EAGLE eliminates the need for complex multi-hop
message passing or memory-intensive mechanisms, enabling significant
improvements in efficiency. Extensive experiments on seven real-world temporal
graphs demonstrate that EAGLE consistently achieves superior performance
against state-of-the-art T-GNNs in both effectiveness and efficiency,
delivering more than a 50x speedup over effective transformer-based T-GNNs.

</details>


### [13] [Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments](https://arxiv.org/abs/2507.13846)
*Kathrin Korte,Christian Medeiros Adriano,Sona Ghahremani,Holger Giese*

Main category: cs.AI

TL;DR: 本文提出了一种因果知识转移框架，帮助多智能体强化学习（MARL）在非静态环境中高效共享知识，减少重新训练需求。


<details>
  <summary>Details</summary>
Motivation: 传统MARL知识转移方法在非静态环境中泛化能力差，智能体需要高成本重新训练以适应变化。

Method: 通过因果干预建模碰撞恢复策略，形成可转移的宏动作，实现零样本知识共享。

Result: 实验表明，该方法能填补随机探索与完全重新训练策略之间约一半的差距，且效果受环境复杂性和智能体目标异质性影响。

Conclusion: 因果知识转移框架为MARL在动态环境中的适应性提供了有效解决方案。

Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable
success in environments where agents must learn coordinated behaviors. However,
transferring knowledge across agents remains challenging in non-stationary
environments with changing goals. [Problem] Traditional knowledge transfer
methods in MARL struggle to generalize, and agents often require costly
retraining to adapt. [Approach] This paper introduces a causal knowledge
transfer framework that enables RL agents to learn and share compact causal
representations of paths within a non-stationary environment. As the
environment changes (new obstacles), agents' collisions require adaptive
recovery strategies. We model each collision as a causal intervention
instantiated as a sequence of recovery actions (a macro) whose effect
corresponds to a causal knowledge of how to circumvent the obstacle while
increasing the chances of achieving the agent's goal (maximizing cumulative
reward). This recovery action macro is transferred online from a second agent
and is applied in a zero-shot fashion, i.e., without retraining, just by
querying a lookup model with local context information (collisions). [Results]
Our findings reveal two key insights: (1) agents with heterogeneous goals were
able to bridge about half of the gap between random exploration and a fully
retrained policy when adapting to new environments, and (2) the impact of
causal knowledge transfer depends on the interplay between environment
complexity and agents' heterogeneous goals.

</details>


### [14] [Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery](https://arxiv.org/abs/2507.13874)
*Mateusz Bystroński,Mikołaj Hołysz,Grzegorz Piotrowski,Nitesh V. Chawla,Tomasz Kajdanowicz*

Main category: cs.AI

TL;DR: 提出了一种模型无关的潜在空间创意框架，通过导航连续嵌入空间实现可控、可扩展的创造力，无需手工规则。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在生成新颖且相关内容时的局限性，避免依赖领域特定启发式或结构化提示。

Method: 采用潜在空间导航技术，构建模型无关的创意框架，适应不同领域和任务。

Result: 初步结果显示该框架具有潜力作为通用的人机协作创意工具。

Conclusion: 该框架为AI创意生成提供了灵活且可扩展的解决方案，有望推动人机协作创新。

Abstract: Innovative idea generation remains a core challenge in AI, as large language
models (LLMs) often struggle to produce outputs that are both novel and
relevant. Despite their fluency, LLMs tend to replicate patterns seen during
training, limiting their ability to diverge creatively without extensive prompt
engineering. Prior work has addressed this through domain-specific heuristics
and structured prompting pipelines, but such solutions are brittle and
difficult to generalize. In this paper, we propose a model-agnostic
latent-space ideation framework that enables controlled, scalable creativity by
navigating the continuous embedding space of ideas. Unlike prior methods, our
framework requires no handcrafted rules and adapts easily to different domains,
input formats, and creative tasks. This paper introduces an early-stage
prototype of our method, outlining the conceptual framework and preliminary
results highlighting its potential as a general-purpose co-ideator for human-AI
collaboration.

</details>


### [15] [Cross-modal Causal Intervention for Alzheimer's Disease Prediction](https://arxiv.org/abs/2507.13956)
*Yutao Jin,Haowen Xiao,Jielei Chu,Fengmao Lv,Yuxiao Li,Tianrui Li*

Main category: cs.AI

TL;DR: 提出了一种名为ADPC的新型视觉-语言因果干预框架，用于辅助诊断阿尔茨海默病（AD），通过消除混杂因素提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 早期识别轻度认知障碍（MCI）和AD对延缓痴呆症进展至关重要，但现有方法因数据选择和变量复杂关系存在挑战。

Method: 结合MRI、fMRI图像和LLM生成的文本数据，通过因果干预消除混杂因素，分类CN/MCI/AD。

Result: 实验表明ADPC在CN/MCI/AD分类中表现优异，达到SOTA指标。

Conclusion: 研究展示了因果推理与多模态学习结合在神经疾病诊断中的潜力。

Abstract: Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's
Disease (AD), where early identification and intervention can effectively slow
the progression to dementia. However, diagnosing AD remains a significant
challenge in neurology due to the confounders caused mainly by the selection
bias of multimodal data and the complex relationships between variables. To
address these issues, we propose a novel visual-language causal intervention
framework named Alzheimer's Disease Prediction with Cross-modal Causal
Intervention (ADPC) for diagnostic assistance. Our ADPC employs large language
model (LLM) to summarize clinical data under strict templates, maintaining
structured text outputs even with incomplete or unevenly distributed datasets.
The ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)
images and textual data generated by LLM to classify participants into
Cognitively Normal (CN), MCI, and AD categories. Because of the presence of
confounders, such as neuroimaging artifacts and age-related biomarkers,
non-causal models are likely to capture spurious input-output correlations,
generating less reliable results. Our framework implicitly eliminates
confounders through causal intervention. Experimental results demonstrate the
outstanding performance of our method in distinguishing CN/MCI/AD cases,
achieving state-of-the-art (SOTA) metrics across most evaluation metrics. The
study showcases the potential of integrating causal reasoning with multi-modal
learning for neurological disease diagnosis.

</details>


### [16] [Towards Constraint Temporal Answer Set Programming](https://arxiv.org/abs/2507.13958)
*Pedro Cabalar,Martín Diéguez,François Olivier,Torsten Schaub,Igor Stéphan*

Main category: cs.AI

TL;DR: 提出了一种新的时间和约束扩展逻辑，用于解决动态系统中的高分辨率推理问题。


<details>
  <summary>Details</summary>
Motivation: 解决基于逻辑的方法（如ASP）在动态系统中高分辨率推理的挑战。

Method: 结合线性时间逻辑和约束逻辑，扩展了Here-and-There逻辑及其非单调平衡扩展。

Result: 建立了适用于ASP范式的复杂动态系统高分辨率推理的逻辑框架。

Conclusion: 该工作为ASP范式下的高分辨率动态系统推理提供了理论基础。

Abstract: Reasoning about dynamic systems with a fine-grained temporal and numeric
resolution presents significant challenges for logic-based approaches like
Answer Set Programming (ASP). To address this, we introduce and elaborate upon
a novel temporal and constraint-based extension of the logic of Here-and-There
and its nonmonotonic equilibrium extension, representing, to the best of our
knowledge, the first approach to nonmonotonic temporal reasoning with
constraints specifically tailored for ASP. This expressive system is achieved
by a synergistic combination of two foundational ASP extensions: the
linear-time logic of Here-and-There, providing robust nonmonotonic temporal
reasoning capabilities, and the logic of Here-and-There with constraints,
enabling the direct integration and manipulation of numeric constraints, among
others. This work establishes the foundational logical framework for tackling
complex dynamic systems with high resolution within the ASP paradigm.

</details>


### [17] [KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models](https://arxiv.org/abs/2507.14032)
*Lam Nguyen,Erika Barcelos,Roger French,Yinghui Wu*

Main category: cs.AI

TL;DR: KROMA是一个基于大型语言模型（LLMs）和检索增强生成（RAG）的新型本体匹配框架，通过动态丰富语义上下文和优化性能，显著提升了本体匹配的效果。


<details>
  <summary>Details</summary>
Motivation: 现有本体匹配系统依赖手工规则或专用模型，适应性有限，KROMA旨在通过LLMs和RAG解决这一问题。

Method: KROMA结合了双相似度概念匹配和轻量级本体优化步骤，减少LLMs的通信开销，并通过知识检索和上下文增强提升匹配效果。

Result: 实验表明，KROMA在多个基准数据集上优于传统系统和前沿LLM方法，同时保持低通信开销。

Conclusion: KROMA展示了知识检索、提示增强和本体优化在大规模本体匹配中的可行性和优势。

Abstract: Ontology Matching (OM) is a cornerstone task of semantic interoperability,
yet existing systems often rely on handcrafted rules or specialized models with
limited adaptability. We present KROMA, a novel OM framework that harnesses
Large Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)
pipeline to dynamically enrich the semantic context of OM tasks with
structural, lexical, and definitional knowledge. To optimize both performance
and efficiency, KROMA integrates a bisimilarity-based concept matching and a
lightweight ontology refinement step, which prune candidate concepts and
substantially reduce the communication overhead from invoking LLMs. Through
experiments on multiple benchmark datasets, we show that integrating knowledge
retrieval with context-augmented LLMs significantly enhances ontology matching,
outperforming both classic OM systems and cutting-edge LLM-based approaches
while keeping communication overhead comparable. Our study highlights the
feasibility and benefit of the proposed optimization techniques (targeted
knowledge retrieval, prompt enrichment, and ontology refinement) for ontology
matching at scale.

</details>


### [18] [Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions](https://arxiv.org/abs/2507.14077)
*Temiloluwa Prioleau,Baiying Lu,Yanjun Cui*

Main category: cs.AI

TL;DR: Glucose-ML是一个包含10个公开糖尿病数据集的集合，旨在加速透明、可重复和稳健的AI解决方案开发，并提供数据选择和血糖预测的基准。


<details>
  <summary>Details</summary>
Motivation: 解决高质量糖尿病数据集获取困难的问题，推动AI在糖尿病管理中的应用。

Method: 收集并发布10个公开糖尿病数据集（Glucose-ML），进行数据比较分析，并通过血糖预测案例研究提供基准。

Result: 同一算法在不同数据集上预测结果差异显著，研究结果为开发稳健AI解决方案提供了建议。

Conclusion: Glucose-ML为糖尿病AI研究提供了丰富资源，并强调了数据选择对算法性能的重要性。

Abstract: Artificial intelligence (AI) algorithms are a critical part of
state-of-the-art digital health technology for diabetes management. Yet, access
to large high-quality datasets is creating barriers that impede development of
robust AI solutions. To accelerate development of transparent, reproducible,
and robust AI solutions, we present Glucose-ML, a collection of 10 publicly
available diabetes datasets, released within the last 7 years (i.e., 2018 -
2025). The Glucose-ML collection comprises over 300,000 days of continuous
glucose monitor (CGM) data with a total of 38 million glucose samples collected
from 2500+ people across 4 countries. Participants include persons living with
type 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support
researchers and innovators with using this rich collection of diabetes
datasets, we present a comparative analysis to guide algorithm developers with
data selection. Additionally, we conduct a case study for the task of blood
glucose prediction - one of the most common AI tasks within the field. Through
this case study, we provide a benchmark for short-term blood glucose prediction
across all 10 publicly available diabetes datasets within the Glucose-ML
collection. We show that the same algorithm can have significantly different
prediction results when developed/evaluated with different datasets. Findings
from this study are then used to inform recommendations for developing robust
AI solutions within the diabetes or broader health domain. We provide direct
links to each longitudinal diabetes dataset in the Glucose-ML collection and
openly provide our code.

</details>


### [19] [Generative AI-Driven High-Fidelity Human Motion Simulation](https://arxiv.org/abs/2507.14097)
*Hari Iyer,Neel Macwan,Atharva Jitendra Hude,Heejin Jeong,Shenghan Guo*

Main category: cs.AI

TL;DR: G-AI-HMS结合文本和运动模型，提升工业任务中人体运动模拟的逼真度，并通过计算机视觉验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动模拟方法逼真度低，G-AI-HMS旨在通过生成式AI技术解决这一问题。

Method: 结合文本到文本和文本到运动模型，利用大语言模型和MotionGPT训练词汇，并通过计算机视觉验证运动序列。

Result: 在八项任务中，AI增强的运动序列在多数场景下表现优于人工描述，显著降低了关节误差和时间偏差。

Conclusion: G-AI-HMS显著提升了运动模拟的逼真度和准确性，适用于工业任务评估。

Abstract: Human motion simulation (HMS) supports cost-effective evaluation of worker
behavior, safety, and productivity in industrial tasks. However, existing
methods often suffer from low motion fidelity. This study introduces
Generative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and
text-to-motion models to enhance simulation quality for physical tasks.
G-AI-HMS tackles two key challenges: (1) translating task descriptions into
motion-aware language using Large Language Models aligned with MotionGPT's
training vocabulary, and (2) validating AI-enhanced motions against real human
movements using computer vision. Posture estimation algorithms are applied to
real-time videos to extract joint landmarks, and motion similarity metrics are
used to compare them with AI-enhanced sequences. In a case study involving
eight tasks, the AI-enhanced motions showed lower error than human created
descriptions in most scenarios, performing better in six tasks based on spatial
accuracy, four tasks based on alignment after pose normalization, and seven
tasks based on overall temporal similarity. Statistical analysis showed that
AI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and
temporal misalignment while retaining comparable posture accuracy.

</details>


### [20] [Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment](https://arxiv.org/abs/2507.14107)
*Viraj Nishesh Darji,Callie C. Liao,Duoduo Liao*

Main category: cs.AI

TL;DR: 该研究探讨了利用大型语言模型（LLMs）自动解释无损评估（NDE）轮廓图，以提高桥梁维护效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 桥梁维护和安全至关重要，但NDE数据分析耗时且需专业知识，LLMs为自动化分析提供了新途径。

Method: 研究设计了特定提示词，评估多个LLM模型在解释NDE轮廓图时的表现，包括缺陷识别和建议提供。

Result: 九个模型中有四个表现更优，尤其是ChatGPT-4和Claude 3.5 Sonnet在生成有效摘要方面突出。

Conclusion: LLMs可显著提升桥梁维护效率，为基础设施管理提供创新支持。

Abstract: Bridge maintenance and safety are essential for transportation authorities,
and Non-Destructive Evaluation (NDE) techniques are critical to assessing
structural integrity. However, interpreting NDE data can be time-consuming and
requires expertise, potentially delaying decision-making. Recent advancements
in Large Language Models (LLMs) offer new ways to automate and improve this
analysis. This pilot study introduces a holistic assessment of LLM capabilities
for interpreting NDE contour maps and demonstrates the effectiveness of LLMs in
providing detailed bridge condition analyses. It establishes a framework for
integrating LLMs into bridge inspection workflows, indicating that LLM-assisted
analysis can enhance efficiency without compromising accuracy. In this study,
several LLMs are explored with prompts specifically designed to enhance the
quality of image descriptions, which are applied to interpret five different
NDE contour maps obtained through technologies for assessing bridge conditions.
Each LLM model is evaluated based on its ability to produce detailed
descriptions, identify defects, provide actionable recommendations, and
demonstrate overall accuracy. The research indicates that four of the nine
models provide better image descriptions, effectively covering a wide range of
topics related to the bridge's condition. The outputs from these four models
are summarized using five different LLMs to form a comprehensive overview of
the bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more
effective summaries. The findings suggest that LLMs have the potential to
significantly improve efficiency and accuracy. This pilot study presents an
innovative approach that leverages LLMs for image captioning in parallel and
summarization, enabling faster decision-making in bridge maintenance and
enhancing infrastructure management and safety assessments.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [21] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

TL;DR: 研究提出了一种名为ALP的少样本自适应语言提示方法，利用多模态LLMs（如GPT-4o和Gemini 1.5 Pro）检测钓鱼网页，显著提升了检测准确率。


<details>
  <summary>Details</summary>
Motivation: 钓鱼攻击是重大网络安全威胁，需要自适应检测技术。

Method: ALP是一种结构化语义推理方法，通过分解语言模式、检测紧急提示和识别操纵性措辞，结合文本、视觉和URL分析，构建统一模型。

Result: 实验显示ALP显著提升检测准确率，F1-score达0.93，优于传统方法。

Conclusion: ALP为基于LLMs的钓鱼检测系统提供了更鲁棒、可解释和自适应的基础。

Abstract: Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [22] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

TL;DR: PersonaGen是一个基于多阶段角色条件的大语言模型框架，用于生成情感丰富的文本，以解决情感识别领域高质量数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 情感表达具有主观性和多样性，大规模数据收集存在伦理和实践困难，因此需要替代方法生成情感数据。

Method: 通过结合人口统计属性、社会文化背景和情境上下文构建虚拟角色，指导情感表达生成。

Result: PersonaGen在生成多样性、连贯性和区分性情感表达方面显著优于基线方法。

Conclusion: PersonaGen可作为增强或替代真实情感数据集的强大工具。

Abstract: In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [23] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

TL;DR: SAFT是一种结构感知的微调方法，通过注入图拓扑信息提升LLM在结构化输入（如AMR）上的性能，显著提高了AMR到文本生成的BLEU分数。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理结构化输入（如AMR）时，常忽略关键结构信息或依赖不兼容的架构，限制了LLM的性能。

Method: SAFT通过计算方向敏感的位置编码（基于磁拉普拉斯变换的AMR），并将其投影到LLM的嵌入空间，无需改变模型架构。

Result: SAFT在AMR 3.0上实现了3.5 BLEU的提升，且性能增益随图复杂度增加。

Conclusion: SAFT为结构化数据与语言模型的结合提供了一种通用且有效的途径。

Abstract: Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [24] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

TL;DR: 论文提出了一种基于图的新方法，利用NLP技术将新闻文章转化为图结构，并通过GBAD算法检测假新闻。


<details>
  <summary>Details</summary>
Motivation: 解决数字时代假新闻快速传播的问题。

Method: 使用NLP将新闻转化为图结构，并应用MDL-based GBAD算法进行图挖掘和异常检测。

Result: 方法能识别数据集中的规范模式并发现异常模式。

Conclusion: 基于图的方法能有效检测假新闻，尤其适用于复杂上下文数据。

Abstract: In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [25] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

TL;DR: PARAM-1是一个专注于印度语言多样性的2.9B参数语言模型，通过公平的数据分配、优化的分词器和文化对齐的评估基准，为印度多语言环境提供了一种公平的基础模型设计。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）以英语为中心，忽视了印度等多语言地区的需求，导致语言多样性不足。PARAM-1旨在解决这一问题。

Method: PARAM-1是一个基于解码器的文本模型，使用双语（印地语和英语）高质量数据集训练，通过公平的语料分配、适应印度形态的分词器和文化对齐的评估基准实现多样性。

Result: PARAM-1不仅是一个通用的语言模型，还为印度中心应用提供了稳健的基线。

Conclusion: PARAM-1通过预训练阶段的多样性设计，为公平的基础模型提供了示范，适用于多语言环境。

Abstract: Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [26] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

TL;DR: 改进客户评论分析，通过基于意见单元的主题建模提升性能和可解释性，并关联业务指标。


<details>
  <summary>Details</summary>
Motivation: 提升从客户评论中提取见解的能力，通过更细粒度的意见单元改进主题建模。

Method: 利用大语言模型提取意见单元，结合主题建模和情感分析，关联业务指标。

Result: 生成更连贯和可解释的主题，同时捕捉情感，并成功预测业务指标如星级评分。

Conclusion: 该方法在主题建模和情感分析中表现优越，能有效关联客户反馈与业务结果。

Abstract: We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [27] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

TL;DR: Babel框架通过单语语料库提升神经机器翻译的文体保真度，无需平行语料库。


<details>
  <summary>Details</summary>
Motivation: 解决神经机器翻译中文体细微差别难以保留的问题，避免依赖平行语料库。

Method: Babel框架包含基于上下文嵌入的文体检测器和扩散式文体应用器，作为后处理模块集成到现有NMT系统。

Result: 在五个领域中，Babel识别文体不一致的精确度为88.21%，文体保留提升150%，语义相似度达0.92。

Conclusion: Babel有效提升翻译的文体保真度，同时保持语义完整性和流畅性。

Abstract: The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


### [28] [Causal Language Control in Multilingual Transformers via Sparse Feature Steering](https://arxiv.org/abs/2507.13410)
*Cheng-Ting Chou,George Liu,Jessica Sun,Cole Blondin,Kevin Zhu,Vasu Sharma,Sean O'Brien*

Main category: cs.CL

TL;DR: 利用稀疏自编码器（SAE）特征控制多语言大模型（LLMs）的生成语言，通过修改单个SAE特征实现高达90%的语言转换成功率。


<details>
  <summary>Details</summary>
Motivation: 解决在零样本设置下无法通过显式语言提示或微调控制LLMs生成目标语言的挑战。

Method: 使用预训练的SAE分析Gemma-2B和Gemma-9B的残差流，识别与目标语言（中、日、西、法）显著相关的特征，并在推理时修改这些特征。

Result: 通过修改单个SAE特征，成功实现语言转换（90%成功率），同时保持语义保真度。语言控制在模型的中后层最有效。

Conclusion: 稀疏特征调控是一种轻量且可解释的多语言生成控制机制。

Abstract: Deterministically controlling the target generation language of large
multilingual language models (LLMs) remains a fundamental challenge,
particularly in zero-shot settings where neither explicit language prompts nor
fine-tuning are available. In this work, we investigate whether sparse
autoencoder (SAE) features, previously shown to correlate with interpretable
model behaviors, can be leveraged to steer the generated language of LLMs
during inference. Leveraging pretrained SAEs on the residual streams of
Gemma-2B and Gemma-9B, we identify features whose activations differ most
significantly between English and four target languages: Chinese, Japanese,
Spanish, and French. By modifying just a single SAE feature at one transformer
layer, we achieve controlled language shifts with up to 90\% success, as
measured by FastText language classification, while preserving semantic
fidelity according to LaBSE (Language-Agnostic BERT Sentence Embedding)
similarity. Our analysis reveals that language steering is most effective in
mid-to-late transformer layers and is amplified by specific attention heads
disproportionately associated with language-sensitive SAE features. These
results demonstrate the promise of sparse feature steering as a lightweight and
interpretable mechanism for controllable multilingual generation.

</details>


### [29] [Aligning Knowledge Graphs and Language Models for Factual Accuracy](https://arxiv.org/abs/2507.13411)
*Nur A Zarin Nishat,Andrea Coletta,Luigi Bellomarini,Kossi Amouzouvi,Jens Lehmann,Sahar Vahdati*

Main category: cs.CL

TL;DR: ALIGNed-LLM通过将知识图谱嵌入语言模型的潜在空间，显著提升了语言模型的事实性和准确性，减少了幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在NLP任务中表现优异，但存在幻觉问题，知识图谱的引入为解决这一问题提供了结构化、可靠的外部信息。

Method: 采用预训练的知识图谱嵌入模型（如TransE）和可训练投影层，将实体与文本嵌入对齐，以增强语言模型的事实基础。

Result: 在三个问答基准数据集和实际金融用例中，ALIGNed-LLM显著提升了语言模型的准确性和精确度。

Conclusion: ALIGNed-LLM是一种简单有效的方法，通过知识图谱嵌入显著改善了语言模型的事实性和实用性。

Abstract: Large language models like GPT-4, Gemini, and Claude have transformed natural
language processing (NLP) tasks such as question answering, dialogue
generation, summarization, and so forth; yet their susceptibility to
hallucination stands as one of the major challenges. Among numerous approaches
to overcome this challenge, integration of Knowledge Graphs (KGs) into language
models has emerged as a promising solution as it provides structured, reliable,
domain-specific, and up-to-date external information to the language models. In
this paper, we introduce ALIGNed-LLM, a simple yet effective approach to
improve language models' factuality via a lean strategy to infuse KGs into the
latent space of language models inspired by LLaVA where visual and textual
information is infused. We use embeddings from a pre-trained Knowledge Graph
Embedding (KGE) model, such as TransE, and a trainable projection layer to
align entity and text embeddings. This alignment enables the language model to
distinguish between similar entities improving factual grounding and reducing
hallucination. We tested our approach on three popular questions-answering
benchmark datasets alongside language models of varying sizes, showing
significant improvement. Furthermore, we applied our approach to a real-world
financial use case from a large central bank in Europe, which demands high
accuracy and precision, demonstrating a substantial improvement of the LLM
answers.

</details>


### [30] [Paper Summary Attack: Jailbreaking LLMs through LLM Safety Papers](https://arxiv.org/abs/2507.13474)
*Liang Lin,Zhihao Xu,Xuehai Tang,Shi Liu,Biyu Zhou,Fuqing Zhu,Jizhong Han,Songlin Hu*

Main category: cs.CL

TL;DR: 本文提出了一种名为Paper Summary Attack (PSA)的新型越狱方法，通过合成攻击或防御导向的LLM安全论文内容构建对抗性提示模板，并在预定义子章节中填充有害查询作为对抗性载荷。实验表明，PSA在多个先进模型中具有高攻击成功率，并揭示了不同模型间的漏洞偏见。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）倾向于信任权威来源（如学术论文）的信息，这可能导致新的安全漏洞。本文旨在验证这一可能性并探索相关漏洞。

Method: 提出PSA方法，通过合成攻击或防御导向的LLM安全论文内容构建对抗性提示模板，并在预定义子章节中填充有害查询作为对抗性载荷。

Result: PSA在Claude3.5-Sonnet和Deepseek-R1上的攻击成功率分别达到97%和98%。实验还揭示了不同模型间对攻击或防御导向论文的漏洞偏见。

Conclusion: PSA揭示了LLMs的新漏洞，并为对抗性方法和安全对齐提供了未来研究方向。

Abstract: The safety of large language models (LLMs) has garnered significant research
attention. In this paper, we argue that previous empirical studies demonstrate
LLMs exhibit a propensity to trust information from authoritative sources, such
as academic papers, implying new possible vulnerabilities. To verify this
possibility, a preliminary analysis is designed to illustrate our two findings.
Based on this insight, a novel jailbreaking method, Paper Summary Attack
(\llmname{PSA}), is proposed. It systematically synthesizes content from either
attack-focused or defense-focused LLM safety paper to construct an adversarial
prompt template, while strategically infilling harmful query as adversarial
payloads within predefined subsections. Extensive experiments show significant
vulnerabilities not only in base LLMs, but also in state-of-the-art reasoning
model like Deepseek-R1. PSA achieves a 97\% attack success rate (ASR) on
well-aligned models like Claude3.5-Sonnet and an even higher 98\% ASR on
Deepseek-R1. More intriguingly, our work has further revealed diametrically
opposed vulnerability bias across different base models, and even between
different versions of the same model, when exposed to either attack-focused or
defense-focused papers. This phenomenon potentially indicates future research
clues for both adversarial methodologies and safety alignment.Code is available
at https://github.com/233liang/Paper-Summary-Attack

</details>


### [31] [Revisiting LLM Value Probing Strategies: Are They Robust and Expressive?](https://arxiv.org/abs/2507.13490)
*Siqi Shen,Mehar Singh,Lajanugen Logeswaran,Moontae Lee,Honglak Lee,Rada Mihalcea*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（LLMs）价值取向的鲁棒性和表达能力，比较了三种广泛使用的探测策略，并发现输入扰动下所有方法均表现出较大方差。此外，研究发现人口统计背景对自由文本生成影响较小，模型价值与其在价值相关场景中的行为相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决当前LLMs价值取向评估中的挑战，包括探测方法的系统性比较不足，以及探测到的价值是否能捕捉上下文信息并反映模型对现实行为的偏好。

Method: 方法包括评估三种广泛使用的价值探测策略的鲁棒性和表达能力，通过提示和选项的变体进行研究。此外，引入两项任务研究价值对人口统计背景的响应性及其与模型行为的对齐程度。

Result: 结果显示，所有探测方法在输入扰动下均表现出较大方差，人口统计背景对自由文本生成影响较小，模型价值与其在价值相关场景中的行为相关性较弱。

Conclusion: 结论强调需要更仔细地检查LLM价值探测方法，并意识到其局限性。

Abstract: There has been extensive research on assessing the value orientation of Large
Language Models (LLMs) as it can shape user experiences across demographic
groups. However, several challenges remain. First, while the Multiple Choice
Question (MCQ) setting has been shown to be vulnerable to perturbations, there
is no systematic comparison of probing methods for value probing. Second, it is
unclear to what extent the probed values capture in-context information and
reflect models' preferences for real-world actions. In this paper, we evaluate
the robustness and expressiveness of value representations across three widely
used probing strategies. We use variations in prompts and options, showing that
all methods exhibit large variances under input perturbations. We also
introduce two tasks studying whether the values are responsive to demographic
context, and how well they align with the models' behaviors in value-related
scenarios. We show that the demographic context has little effect on the
free-text generation, and the models' values only weakly correlate with their
preference for value-based actions. Our work highlights the need for a more
careful examination of LLM value probing and awareness of its limitations.

</details>


### [32] [Encoding syntactic objects and Merge operations in function spaces](https://arxiv.org/abs/2507.13501)
*Matilde Marcolli,Robert C. Berwick*

Main category: cs.CL

TL;DR: 论文提出了一种数学方法，通过在函数空间中表示词汇项（如小波），可以构建任意句法对象的忠实表示，并展示了其与神经计算结构的兼容性。


<details>
  <summary>Details</summary>
Motivation: 探索句法结构的数学表示及其在神经计算中的实现可能性。

Method: 利用函数空间中的小波表示词汇项，构建非结合半环结构，并通过操作模型电路实现句法结构的编码。

Result: 证明了句法核心计算结构的神经计算实现的理论可能性，并通过特定案例展示了其实际应用。

Conclusion: 研究为句法结构的数学表示和神经计算实现提供了理论基础，并揭示了合并操作与算术后继函数的相似性。

Abstract: We provide a mathematical argument showing that, given a representation of
lexical items as functions (wavelets, for instance) in some function space, it
is possible to construct a faithful representation of arbitrary syntactic
objects in the same function space. This space can be endowed with a
commutative non-associative semiring structure built using the second Renyi
entropy. The resulting representation of syntactic objects is compatible with
the magma structure. The resulting set of functions is an algebra over an
operad, where the operations in the operad model circuits that transform the
input wave forms into a combined output that encodes the syntactic structure.
The action of Merge on workspaces is faithfully implemented as action on these
circuits, through a coproduct and a Hopf algebra Markov chain. The results
obtained here provide a constructive argument showing the theoretical
possibility of a neurocomputational realization of the core computational
structure of syntax. We also present a particular case of this general
construction where this type of realization of Merge is implemented as a cross
frequency phase synchronization on sinusoidal waves. This also shows that Merge
can be expressed in terms of the successor function of a semiring, thus
clarifying the well known observation of its similarities with the successor
function of arithmetic.

</details>


### [33] [A Computational Approach to Modeling Conversational Systems: Analyzing Large-Scale Quasi-Patterned Dialogue Flows](https://arxiv.org/abs/2507.13544)
*Mohamed Achref Ben Ammar,Mohamed Taha Bennani*

Main category: cs.CL

TL;DR: 提出了一种新的计算框架，用于构建捕捉松散组织对话（准模式对话）的对话图，并引入了一种新的图简化技术（Filter & Reconnect），显著提升了语义度量S，同时保持了对话图的结构完整性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型系统的普及，分析对话动态变得愈发重要，尤其是在多样化上下文中。

Method: 提出了Filter & Reconnect方法，一种图简化技术，用于减少噪声并保持对话图的语义连贯性和结构完整性。

Result: 通过比较分析，该方法使语义度量S提升了2.06倍，同时实现了树状结构和0δ-双曲性，优化了对话建模的清晰度。

Conclusion: 该研究为分析大规模对话数据集提供了计算方法，可应用于监控自动化系统（如聊天机器人、对话管理工具和用户行为分析）。

Abstract: The analysis of conversational dynamics has gained increasing importance with
the rise of large language model-based systems, which interact with users
across diverse contexts. In this work, we propose a novel computational
framework for constructing conversational graphs that capture the flow and
structure of loosely organized dialogues, referred to as quasi-patterned
conversations. We introduce the Filter & Reconnect method, a novel graph
simplification technique that minimizes noise while preserving semantic
coherence and structural integrity of conversational graphs. Through
comparative analysis, we demonstrate that the use of large language models
combined with our graph simplification technique has resulted in semantic
metric S increasing by a factor of 2.06 compared to previous approaches while
simultaneously enforcing a tree-like structure with 0 {\delta}-hyperbolicity,
ensuring optimal clarity in conversation modeling. This work provides a
computational method for analyzing large-scale dialogue datasets, with
practical applications related to monitoring automated systems such as
chatbots, dialogue management tools, and user behavior analytics.

</details>


### [34] [Reading Between the Lines: Combining Pause Dynamics and Semantic Coherence for Automated Assessment of Thought Disorder](https://arxiv.org/abs/2507.13551)
*Feng Chen,Weizhe Xu,Changye Li,Serguei Pakhomov,Alex Cohen,Simran Bhola,Sandy Yin,Sunny X Tang,Michael Mackinley,Lena Palaniyappan,Dror Ben-Zeev,Trevor Cohen*

Main category: cs.CL

TL;DR: 研究通过整合停顿特征与语义连贯性指标，利用自动语音识别技术评估精神分裂症谱系障碍中的形式思维障碍（FTD）严重程度，发现停顿特征能有效预测FTD严重程度，且与语义指标结合可进一步提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统临床评分量表资源密集且难以扩展，自动语音分析技术（ASR）提供了客观量化语言和时间特征的替代方案，但其在评估FTD严重程度中的实用性需进一步验证。

Method: 研究整合停顿特征与语义连贯性指标，使用支持向量回归（SVR）预测临床FTD评分，并在三个数据集（AVH、TOPSY、PsyCL）中评估性能。

Result: 停顿特征单独能有效预测FTD严重程度，与语义指标结合后性能进一步提升（最高相关性ρ=0.649，AUC=83.71%），且性能提升在不同数据集中一致。

Conclusion: 结合时间和语义分析的框架为改进紊乱言语评估提供了方向，并推动了精神病自动化语音分析的发展。

Abstract: Formal thought disorder (FTD), a hallmark of schizophrenia spectrum
disorders, manifests as incoherent speech and poses challenges for clinical
assessment. Traditional clinical rating scales, though validated, are
resource-intensive and lack scalability. Automated speech analysis with
automatic speech recognition (ASR) allows for objective quantification of
linguistic and temporal features of speech, offering scalable alternatives. The
use of utterance timestamps in ASR captures pause dynamics, which are thought
to reflect the cognitive processes underlying speech production. However, the
utility of integrating these ASR-derived features for assessing FTD severity
requires further evaluation. This study integrates pause features with semantic
coherence metrics across three datasets: naturalistic self-recorded diaries
(AVH, n = 140), structured picture descriptions (TOPSY, n = 72), and dream
narratives (PsyCL, n = 43). We evaluated pause related features alongside
established coherence measures, using support vector regression (SVR) to
predict clinical FTD scores. Key findings demonstrate that pause features alone
robustly predict the severity of FTD. Integrating pause features with semantic
coherence metrics enhanced predictive performance compared to semantic-only
models, with integration of independent models achieving correlations up to
\r{ho} = 0.649 and AUC = 83.71% for severe cases detection (TOPSY, with best
\r{ho} = 0.584 and AUC = 79.23% for semantic-only models). The performance
gains from semantic and pause features integration held consistently across all
contexts, though the nature of pause patterns was dataset-dependent. These
findings suggest that frameworks combining temporal and semantic analyses
provide a roadmap for refining the assessment of disorganized speech and
advance automated speech analysis in psychosis.

</details>


### [35] [A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges in Russian Speech Generative Models](https://arxiv.org/abs/2507.13563)
*Kirill Borodin,Nikita Vasiliev,Vasiliy Kudryavtsev,Maxim Maslov,Mikhail Gorodnichev,Oleg Rogov,Grach Mkrtchian*

Main category: cs.CL

TL;DR: 论文介绍了Balalaika数据集，包含2000多小时高质量的俄语语音及详细文本标注，显著提升了语音合成和增强任务的性能。


<details>
  <summary>Details</summary>
Motivation: 俄语语音合成面临独特挑战，如元音弱化、辅音清音化、重音变化等，现有数据集不足以解决这些问题。

Method: 构建了Balalaika数据集，包含详细标注（如标点和重音标记），并设计了数据集构建和标注流程。

Result: 实验表明，基于Balalaika训练的模型在语音合成和增强任务中显著优于现有数据集训练的模型。

Conclusion: Balalaika数据集为俄语语音合成提供了高质量资源，解决了现有数据集的不足。

Abstract: Russian speech synthesis presents distinctive challenges, including vowel
reduction, consonant devoicing, variable stress patterns, homograph ambiguity,
and unnatural intonation. This paper introduces Balalaika, a novel dataset
comprising more than 2,000 hours of studio-quality Russian speech with
comprehensive textual annotations, including punctuation and stress markings.
Experimental results show that models trained on Balalaika significantly
outperform those trained on existing datasets in both speech synthesis and
enhancement tasks. We detail the dataset construction pipeline, annotation
methodology, and results of comparative evaluations.

</details>


### [36] [Linguistic and Embedding-Based Profiling of Texts generated by Humans and Large Language Models](https://arxiv.org/abs/2507.13614)
*Sergio E. Zanotto,Segun Aroyehun*

Main category: cs.CL

TL;DR: 该研究通过多语言学特征分析人类与机器生成文本的差异，发现人类文本句法更简单、语义更多样，且新模型生成的文本风格趋于同质化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索人类与机器生成文本在语言学特征上的差异，而非仅分类。

Method: 方法包括选择多领域数据集、计算语言学特征（如依存长度和情感性），并进行统计分析。

Result: 结果显示人类文本句法更简单、语义更多样；新模型生成的文本风格趋于同质化。

Conclusion: 结论指出机器生成文本风格逐渐趋同，而人类文本更具多样性。

Abstract: The rapid advancements in large language models (LLMs) have significantly
improved their ability to generate natural language, making texts generated by
LLMs increasingly indistinguishable from human-written texts. While recent
research has primarily focused on using LLMs to classify text as either
human-written and machine-generated texts, our study focus on characterizing
these texts using a set of linguistic features across different linguistic
levels such as morphology, syntax, and semantics. We select a dataset of
human-written and machine-generated texts spanning 8 domains and produced by 11
different LLMs. We calculate different linguistic features such as dependency
length and emotionality and we use them for characterizing human-written and
machine-generated texts along with different sampling strategies, repetition
controls and model release date. Our statistical analysis reveals that
human-written texts tend to exhibit simpler syntactic structures and more
diverse semantic content. Furthermore, we calculate the variability of our set
of features across models and domains. Both human and machine texts show
stylistic diversity across domains, with humans displaying greater variation in
our features. Finally, we apply style embeddings to further test variability
among human-written and machine-generated texts. Notably, newer models output
text that is similarly variable, pointing to an homogenization of
machine-generated texts.

</details>


### [37] [Seed-X: Building Strong Multilingual Translation LLM with 7B Parameters](https://arxiv.org/abs/2507.13618)
*Shanbo Cheng,Yu Bao,Qian Cao,Luyang Huang,Liyan Kang,Zhicheng Liu,Yu Lu,Wenhao Zhu,Zhichao Huang,Tao Li,Sitong Liu,Ningxin Peng,Shuaijie She,Lu Xu,Nuo Xu,Sen Yang,Runsheng Yu,Yiming Yu,Liehao Zou,Hang Li,Lu Lu,Yuxuan Wang,Yonghui Wu*

Main category: cs.CL

TL;DR: Seed-X是一系列开源大语言模型，通过7B参数规模提升多语言翻译能力，性能接近闭源模型如Gemini-2.5和GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 解决多语言翻译中的复杂语言模式和生硬翻译问题。

Method: 基于多样高质量数据预训练，通过Chain-of-Thought推理和强化学习微调。

Result: 在28种语言中表现优异，显著优于其他开源模型。

Conclusion: Seed-X为翻译研究和应用提供了高效的开源解决方案。

Abstract: Multilingual translation stands as a challenging task for large language
models (LLMs) to handle intricate language patterns and stilted translations
that arise in automated translations. In this paper, we introduce Seed-X, a
family of open-source LLMs comprising instruct and reasoning models, pushing
the limits of translation capability with 7B parameter size. The base model is
pre-trained on a diverse, high-quality dataset encompassing both monolingual
and bilingual content across 28 languages, harnessing the full potential of
multilingual data. The instruct model is then finetuned to translate by
Chain-of-Thought (CoT) reasoning and further enhanced through reinforcement
learning (RL) to achieve better generalization across diverse language pairs.
Seed-X achieves performance comparable to leading closed-source models,
including Gemini-2.5 and GPT-4o, across 28 languages, and significantly
outperforms larger open-source models in both automatic metrics and human
evaluations. We share the best practices through our optimization process, and
make the parameter public available for advancing translation research and
applications.

</details>


### [38] [CU-ICU: Customizing Unsupervised Instruction-Finetuned Language Models for ICU Datasets via Text-to-Text Transfer Transformer](https://arxiv.org/abs/2507.13655)
*Teerapong Panboonyuen*

Main category: cs.CL

TL;DR: CU-ICU是一种针对ICU数据集定制无监督指令微调语言模型的方法，通过T5架构和稀疏微调技术，显著提升预测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在医疗领域（如ICU）应用时的领域适应性和标注数据不足问题。

Method: 采用T5架构，结合少样本提示和选择性参数更新的稀疏微调方法。

Result: 在ICU任务（如败血症早期检测、死亡率预测和临床笔记生成）中，CU-ICU比标准微调方法提升了15%的准确性和20%的解释性，同时仅更新不到1%的参数。

Conclusion: CU-ICU是一种高效、低开销的解决方案，适用于真实ICU环境中的临床决策支持。

Abstract: Integrating large language models into specialized domains like healthcare
presents unique challenges, including domain adaptation and limited labeled
data. We introduce CU-ICU, a method for customizing unsupervised
instruction-finetuned language models for ICU datasets by leveraging the
Text-to-Text Transfer Transformer (T5) architecture. CU-ICU employs a sparse
fine-tuning approach that combines few-shot prompting with selective parameter
updates, enabling efficient adaptation with minimal supervision. Our evaluation
across critical ICU tasks--early sepsis detection, mortality prediction, and
clinical note generation--demonstrates that CU-ICU consistently improves
predictive accuracy and interpretability over standard fine-tuning methods.
Notably, CU-ICU achieves up to a 15% increase in sepsis detection accuracy and
a 20% enhancement in generating clinically relevant explanations while updating
fewer than 1% of model parameters in its most efficient configuration. These
results establish CU-ICU as a scalable, low-overhead solution for delivering
accurate and interpretable clinical decision support in real-world ICU
environments.

</details>


### [39] [KiC: Keyword-inspired Cascade for Cost-Efficient Text Generation with LLMs](https://arxiv.org/abs/2507.13666)
*Woo-Chan Kim,Ji-Hoon Park,Seong-Whan Lee*

Main category: cs.CL

TL;DR: KiC框架通过语义对齐评估，在节省成本的同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有级联方法无法可靠评估自由文本输出的问题。

Method: 使用关键词启发式级联（KiC），评估弱模型输出的语义对齐。

Result: 在三个基准测试中，KiC达到GPT-4 97.53%的准确率，成本降低28.81%。

Conclusion: KiC是一种高效且经济的自由文本生成解决方案。

Abstract: Large language models (LLMs) have demonstrated state-of-the-art performance
across a wide range of natural language processing tasks. However,
high-performing models are typically accessible only via APIs, incurring
substantial inference costs. Cascade methods address this by initially
employing a cheaper model and escalating to a stronger one only when necessary.
Nevertheless, existing cascade approaches struggle to select a reliable
representative response and assess the overall reliability of free-form
outputs, as they rely on exact text matching. To overcome these limitations, we
propose Keyword-inspired Cascade (KiC), a novel framework for cost-efficient
free-form text generation. KiC identifies the most representative answer among
multiple outputs from a weaker model and evaluates the semantic alignment of
other responses with it. Based on the degree of alignment, KiC determines
whether to accept the weaker model's output or escalate to a stronger model.
Experiments on three free-form text generation benchmarks show that KiC
achieves 97.53 percent of GPT-4's accuracy while reducing API costs by 28.81
percent on average, and even outperforms GPT-4 in a specific benchmark.

</details>


### [40] [LoopServe: An Adaptive Dual-phase LLM Inference Acceleration System for Multi-Turn Dialogues](https://arxiv.org/abs/2507.13681)
*Haoyang Li,Zhanchao Xu,Yiming Li,Xuejia Chen,Darian Li,Anxin Tian,Qingfa Xiao,Cheng Deng,Jun Wang,Qing Li,Lei Chen,Mingxuan Yuan*

Main category: cs.CL

TL;DR: LoopServe是一个用于多轮对话中大型语言模型的自适应双阶段推理加速框架，通过动态稀疏化和渐进键值压缩显著提升效率和响应速度。


<details>
  <summary>Details</summary>
Motivation: 解决多轮对话中长上下文带来的计算和内存挑战，现有方法依赖固定启发式规则，无法适应动态对话模式。

Method: 提出双阶段框架：预填充阶段动态稀疏化注意力矩阵，解码阶段渐进压缩键值缓存。

Result: 在多个长上下文对话任务中，LoopServe表现优于现有基线，显著加速推理。

Conclusion: LoopServe通过自适应方法有效解决了多轮对话中的效率问题，为实际应用提供了可行方案。

Abstract: Multi-turn dialogues are essential in many real-world applications of large
language models, such as chatbots and virtual assistants. As conversation
histories become longer, existing large language models face increasing
computational and memory challenges, which hinder their ability to provide
efficient and responsive interactions. Most current acceleration methods either
compress the context or optimize key value caching, but they often rely on
fixed or position-based heuristics that do not adapt well to the dynamic and
unpredictable patterns found in actual multi-turn conversations. In this paper,
we present LoopServe, an adaptive dual-phase inference acceleration framework
for large language models in multi-turn dialogues. LoopServe introduces two
main innovations. First, it performs online sparsification during the
prefilling phase by dynamically selecting the most important parts of the
attention matrix for each new input. Second, it uses progressive key value
compression during decoding by adaptively maintaining a relevant and efficient
cache based on the most recently generated output tokens. We also propose a
\href{https://huggingface.co/datasets/TreeAILab/Multi-turn_Long-context_Benchmark_for_LLMs}{new
benchmark} with eleven multi-turn datasets that reflect realistic query
positions and conversational dependencies. Extensive experiments demonstrate
that LoopServe consistently achieves superior effectiveness compared to
existing baselines and significantly accelerates LLM inference across a wide
range of long-context dialogue tasks.

</details>


### [41] [Consistent Explainers or Unreliable Narrators? Understanding LLM-generated Group Recommendations](https://arxiv.org/abs/2507.13705)
*Cedric Waterschoot,Nava Tintarev,Francesco Barile*

Main category: cs.CL

TL;DR: 论文评估了LLM在群组推荐系统（GRS）中作为决策者和解释生成者的表现，发现其推荐结果与ADD聚合相似，但解释常涉及评分平均。群组结构不影响推荐，但LLM的解释常引入额外标准，影响透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在GRS中的表现，比较其推荐和解释与基于社会选择的聚合策略的差异，以评估其效率和透明度。

Method: 通过比较LLM生成的推荐和解释与Additive Utilitarian（ADD）聚合策略的结果，分析群组结构的影响及LLM解释的额外标准。

Result: LLM推荐与ADD聚合相似，但解释常涉及评分平均。群组结构无影响，LLM解释引入额外标准（如用户相似性、多样性），且解释不一致。

Conclusion: LLM在GRS中的表现存在透明度和可解释性问题，标准聚合方法在大规模项目集上可能效率不足。

Abstract: Large Language Models (LLMs) are increasingly being implemented as joint
decision-makers and explanation generators for Group Recommender Systems (GRS).
In this paper, we evaluate these recommendations and explanations by comparing
them to social choice-based aggregation strategies. Our results indicate that
LLM-generated recommendations often resembled those produced by Additive
Utilitarian (ADD) aggregation. However, the explanations typically referred to
averaging ratings (resembling but not identical to ADD aggregation). Group
structure, uniform or divergent, did not impact the recommendations.
Furthermore, LLMs regularly claimed additional criteria such as user or item
similarity, diversity, or used undefined popularity metrics or thresholds. Our
findings have important implications for LLMs in the GRS pipeline as well as
standard aggregation strategies. Additional criteria in explanations were
dependent on the number of ratings in the group scenario, indicating potential
inefficiency of standard aggregation methods at larger item set sizes.
Additionally, inconsistent and ambiguous explanations undermine transparency
and explainability, which are key motivations behind the use of LLMs for GRS.

</details>


### [42] [The Judge Variable: Challenging Judge-Agnostic Legal Judgment Prediction](https://arxiv.org/abs/2507.13732)
*Guillaume Zambrano*

Main category: cs.CL

TL;DR: 研究利用机器学习预测法国上诉法院的儿童监护权判决，发现法官个人决策模式显著影响结果，支持法律现实主义观点。


<details>
  <summary>Details</summary>
Motivation: 挑战法官是中立的假设，探讨法官个人决策模式对法律结果的影响。

Method: 使用18,937份判决数据，结合LLM和ML模型（RF、XGB、SVC），比较法官专用模型与通用模型的预测效果。

Result: 法官专用模型预测准确率更高（F1分数92.85%），通用模型为82.63%，支持法官决策存在个体差异。

Conclusion: 法官身份对法律结果有显著影响，实证支持法律现实主义，数据与代码将公开。

Abstract: This study examines the role of human judges in legal decision-making by
using machine learning to predict child physical custody outcomes in French
appellate courts. Building on the legal realism-formalism debate, we test
whether individual judges' decision-making patterns significantly influence
case outcomes, challenging the assumption that judges are neutral variables
that apply the law uniformly. To ensure compliance with French privacy laws, we
implement a strict pseudonymization process. Our analysis uses 18,937 living
arrangements rulings extracted from 10,306 cases. We compare models trained on
individual judges' past rulings (specialist models) with a judge-agnostic model
trained on aggregated data (generalist models). The prediction pipeline is a
hybrid approach combining large language models (LLMs) for structured feature
extraction and ML models for outcome prediction (RF, XGB and SVC). Our results
show that specialist models consistently achieve higher predictive accuracy
than the general model, with top-performing models reaching F1 scores as high
as 92.85%, compared to the generalist model's 82.63% trained on 20x to 100x
more samples. Specialist models capture stable individual patterns that are not
transferable to other judges. In-Domain and Cross-Domain validity tests provide
empirical support for legal realism, demonstrating that judicial identity plays
a measurable role in legal outcomes. All data and code used will be made
available.

</details>


### [43] [PRIDE -- Parameter-Efficient Reduction of Identity Discrimination for Equality in LLMs](https://arxiv.org/abs/2507.13743)
*Maluna Menke,Thilo Hagendorff*

Main category: cs.CL

TL;DR: 论文探讨了如何通过参数高效微调技术（如LoRA和软提示调优）减少大型语言模型（LLM）中的性别和性取向偏见。


<details>
  <summary>Details</summary>
Motivation: LLM常因训练数据中的偏见而输出对LGBTQIA+群体不利的内容，减少这种偏见至关重要。

Method: 使用LoRA和软提示调优技术，在QueerNews语料库上进行微调，并通过WinoQueer基准评估效果。

Result: LoRA（<0.1%额外参数）显著降低偏见分数（最多50分），而软提示调优效果有限。

Conclusion: LoRA能以较低计算成本显著提升公平性，建议推广社区参与的高效微调方法，并扩展评估工具。

Abstract: Large Language Models (LLMs) frequently reproduce the gender- and
sexual-identity prejudices embedded in their training corpora, leading to
outputs that marginalize LGBTQIA+ users. Hence, reducing such biases is of
great importance. To achieve this, we evaluate two parameter-efficient
fine-tuning (PEFT) techniques - Low-Rank Adaptation (LoRA) and soft-prompt
tuning - as lightweight alternatives to full-model fine-tuning for mitigating
such biases. Using the WinoQueer benchmark, we quantify bias in three
open-source LLMs and observe baseline bias scores reaching up to 98 (out of
100) across a range of queer identities defined by gender and/or sexual
orientation, where 50 would indicate neutrality. Fine-tuning with LoRA (< 0.1%
additional parameters) on a curated QueerNews corpus reduces those scores by up
to 50 points and raises neutrality from virtually 0% to as much as 36%.
Soft-prompt tuning (10 virtual tokens) delivers only marginal improvements.
These findings show that LoRA can deliver meaningful fairness gains with
minimal computation. We advocate broader adoption of community-informed PEFT,
the creation of larger queer-authored corpora, and richer evaluation suites
beyond WinoQueer, coupled with ongoing audits to keep LLMs inclusive.

</details>


### [44] [Innocence in the Crossfire: Roles of Skip Connections in Jailbreaking Visual Language Models](https://arxiv.org/abs/2507.13761)
*Palash Nandi,Maithili Joshi,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 论文研究了视觉语言模型（VLMs）中提示设计的离散组件如何影响不适当内容的生成，揭示了三种关键因素（详细视觉信息、对抗性示例和正面开头短语）的独立作用，并提出了一个提高越狱成功率的框架。


<details>
  <summary>Details</summary>
Motivation: 探究提示敏感性如何被利用生成不适当内容，特别是在多模态环境下VLMs的脆弱性。

Method: 分析三种关键因素对越狱的影响，并提出一种利用内部层跳连接的框架。

Result: VLMs在多模态环境下识别有害输入的能力显著下降，少量上下文示例即可引发不适当输出；提出的框架显著提高了越狱成功率。

Conclusion: VLMs存在复杂且细微的漏洞，即使是看似无害的内容（如模因）也可能引发有害输出。

Abstract: Language models are highly sensitive to prompt formulations - small changes
in input can drastically alter their output. This raises a critical question:
To what extent can prompt sensitivity be exploited to generate inapt content?
In this paper, we investigate how discrete components of prompt design
influence the generation of inappropriate content in Visual Language Models
(VLMs). Specifically, we analyze the impact of three key factors on successful
jailbreaks: (a) the inclusion of detailed visual information, (b) the presence
of adversarial examples, and (c) the use of positively framed beginning
phrases. Our findings reveal that while a VLM can reliably distinguish between
benign and harmful inputs in unimodal settings (text-only or image-only), this
ability significantly degrades in multimodal contexts. Each of the three
factors is independently capable of triggering a jailbreak, and we show that
even a small number of in-context examples (as few as three) can push the model
toward generating inappropriate outputs. Furthermore, we propose a framework
that utilizes a skip-connection between two internal layers of the VLM, which
substantially increases jailbreak success rates, even when using benign images.
Finally, we demonstrate that memes, often perceived as humorous or harmless,
can be as effective as toxic visuals in eliciting harmful content, underscoring
the subtle and complex vulnerabilities of VLMs.

</details>


### [45] [An Enhanced Model-based Approach for Short Text Clustering](https://arxiv.org/abs/2507.13793)
*Enhao Cheng,Shoujia Zhang,Jianhua Yin,Xuemeng Song,Tian Gan,Liqiang Nie*

Main category: cs.CL

TL;DR: 论文提出了一种改进的GSDMM+算法，用于短文本聚类，解决了稀疏性和高维度问题，并通过实验验证了其高效性和有效性。


<details>
  <summary>Details</summary>
Motivation: 短文本聚类在社交媒体时代愈发重要，但现有方法面临稀疏性、高维度和计算复杂度等挑战。

Method: 提出基于Dirichlet Multinomial Mixture模型的GSDMM+算法，通过减少初始化噪声、自适应调整词权重和策略性合并簇来优化性能。

Result: 实验表明，GSDMM+在效率和效果上优于经典和最新方法。

Conclusion: GSDMM+是一种高效的短文本聚类方法，能够更好地揭示主题信息，且代码已开源。

Abstract: Short text clustering has become increasingly important with the popularity
of social media like Twitter, Google+, and Facebook. Existing methods can be
broadly categorized into two paradigms: topic model-based approaches and deep
representation learning-based approaches. This task is inherently challenging
due to the sparse, large-scale, and high-dimensional characteristics of the
short text data. Furthermore, the computational intensity required by
representation learning significantly increases the running time. To address
these issues, we propose a collapsed Gibbs Sampling algorithm for the Dirichlet
Multinomial Mixture model (GSDMM), which effectively handles the sparsity and
high dimensionality of short texts while identifying representative words for
each cluster. Based on several aspects of GSDMM that warrant further
refinement, we propose an improved approach, GSDMM+, designed to further
optimize its performance. GSDMM+ reduces initialization noise and adaptively
adjusts word weights based on entropy, achieving fine-grained clustering that
reveals more topic-related information. Additionally, strategic cluster merging
is employed to refine clustering granularity, better aligning the predicted
distribution with the true category distribution. We conduct extensive
experiments, comparing our methods with both classical and state-of-the-art
approaches. The experimental results demonstrate the efficiency and
effectiveness of our methods. The source code for our model is publicly
available at https://github.com/chehaoa/VEMC.

</details>


### [46] [Question-Answer Extraction from Scientific Articles Using Knowledge Graphs and Large Language Models](https://arxiv.org/abs/2507.13827)
*Hosein Azarbonyad,Zi Long Zhu,Georgios Cheirmpos,Zubair Afzal,Vikrant Yadav,Georgios Tsatsaronis*

Main category: cs.CL

TL;DR: 该论文提出两种生成问答对（QA）的方法，用于从科学文章中提取关键概念和贡献。第一种基于文章内容，第二种利用知识图谱（KG）进行比较分析。评估表明KG方法更有效。


<details>
  <summary>Details</summary>
Motivation: 学者在阅读或引用文章时需要快速理解其主要思想，因此需要一种高效提取关键概念的方法。

Method: 1. 基于文章内容的方法：选择重要段落，用大语言模型（LLM）生成问题并排名，再生成答案。2. 基于KG的方法：构建知识图谱，通过实体关系提取模型选择重要三元组，生成QA。

Result: 评估显示KG方法能更有效地捕捉文章核心思想，且实体关系模型的微调对提取高质量三元组至关重要。

Conclusion: KG方法在提取科学文章关键概念方面表现更优，且模型微调是关键因素。

Abstract: When deciding to read an article or incorporate it into their research,
scholars often seek to quickly identify and understand its main ideas. In this
paper, we aim to extract these key concepts and contributions from scientific
articles in the form of Question and Answer (QA) pairs. We propose two distinct
approaches for generating QAs. The first approach involves selecting salient
paragraphs, using a Large Language Model (LLM) to generate questions, ranking
these questions by the likelihood of obtaining meaningful answers, and
subsequently generating answers. This method relies exclusively on the content
of the articles. However, assessing an article's novelty typically requires
comparison with the existing literature. Therefore, our second approach
leverages a Knowledge Graph (KG) for QA generation. We construct a KG by
fine-tuning an Entity Relationship (ER) extraction model on scientific articles
and using it to build the graph. We then employ a salient triplet extraction
method to select the most pertinent ERs per article, utilizing metrics such as
the centrality of entities based on a triplet TF-IDF-like measure. This measure
assesses the saliency of a triplet based on its importance within the article
compared to its prevalence in the literature. For evaluation, we generate QAs
using both approaches and have them assessed by Subject Matter Experts (SMEs)
through a set of predefined metrics to evaluate the quality of both questions
and answers. Our evaluations demonstrate that the KG-based approach effectively
captures the main ideas discussed in the articles. Furthermore, our findings
indicate that fine-tuning the ER extraction model on our scientific corpus is
crucial for extracting high-quality triplets from such documents.

</details>


### [47] [The Expressions of Depression and Anxiety in Chinese Psycho-counseling: Usage of First-person Singular Pronoun and Negative Emotional Words](https://arxiv.org/abs/2507.13839)
*Lizhi Ma,Tong Zhao,Shuai Zhang,Nirui Song,Hongliang He,Anqi Li,Ran Feng,Huachuan Qiu,Jingsong Ma,Zhenzhong Lan*

Main category: cs.CL

TL;DR: 研究探讨了中文心理咨询中语言表达与抑郁、焦虑心理状态的关系，发现负面情绪词与心理状态严重程度显著正相关，但第一人称单数代词使用频率无显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索语言表达（如负面情绪词和第一人称代词）与心理状态（抑郁和焦虑）的关系，特别是在中文心理咨询背景下。

Method: 基于735个在线心理咨询会话的语料库，使用LIWC软件量化语言模式，并通过广义线性混合效应模型分析。

Result: 负面情绪词频率与抑郁和焦虑状态严重程度显著正相关；第一人称单数代词使用频率与心理状态无显著关联。

Conclusion: 文化背景和会话动态对心理健康交流中的语言使用有重要影响，为中文人群的心理治疗提供了新的语言学标记。

Abstract: This study explores the relationship between linguistic expressions and
psychological states of depression and anxiety within Chinese psycho-counseling
interactions, focusing specifically on the usage of first-person singular
pronouns and negative emotional words. Utilizing a corpus derived from 735
online counseling sessions, the analysis employed a general linear mixed-effect
model to assess linguistic patterns quantified by the Linguistic Inquiry and
Word Count (LIWC) software. Results indicate a significant positive correlation
between the frequency of negative emotional words and the severity of both
depressive and anxious states among clients. However, contrary to prior
findings predominantly derived from English-language contexts, the usage
frequency of first-person singular pronouns did not vary significantly with the
clients' psychological conditions. These outcomes are discussed within the
framework of cultural distinctions between collectivist Chinese contexts and
individualistic Western settings, as well as the interactive dynamics unique to
psycho-counseling conversations. The findings highlight the nuanced influence
of cultural and conversational contexts on language use in mental health
communications, providing insights into psycholinguistic markers relevant to
therapeutic practices in Chinese-speaking populations.

</details>


### [48] [Modeling Fair Play in Detective Stories with Language Models](https://arxiv.org/abs/2507.13841)
*Eitan Wagner,Renana Keydar,Omri Abend*

Main category: cs.CL

TL;DR: 本文提出了一个概率框架来定义侦探小说中的公平性（fair play），并设计了相关指标。研究发现，LLM生成的侦探故事在惊喜与公平性之间难以平衡，导致质量不佳。


<details>
  <summary>Details</summary>
Motivation: 侦探小说中的公平性（fair play）是作者与读者之间的默契，但如何量化这一概念尚不明确。本文旨在通过概率框架解决这一问题。

Method: 提出了一个概率框架，定义了公平性及其相关指标，并分析了故事连贯性与惊喜之间的张力。

Result: LLM生成的侦探故事虽然不可预测，但在公平性与惊喜的平衡上表现不佳，导致质量低下。

Conclusion: 本文的框架为量化侦探小说的公平性提供了工具，但LLM在平衡惊喜与公平性方面仍需改进。

Abstract: Effective storytelling relies on a delicate balance between meeting the
reader's prior expectations and introducing unexpected developments. In the
domain of detective fiction, this tension is known as fair play, which includes
the implicit agreement between the writer and the reader as to the range of
possible resolutions the mystery story may have. In this work, we present a
probabilistic framework for detective fiction that allows us to define desired
qualities. Using this framework, we formally define fair play and design
appropriate metrics for it. Stemming from these definitions is an inherent
tension between the coherence of the story, which measures how much it ``makes
sense'', and the surprise it induces. We validate the framework by applying it
to LLM-generated detective stories. This domain is appealing since we have an
abundance of data, we can sample from the distribution generating the story,
and the story-writing capabilities of LLMs are interesting in their own right.
Results show that while LLM-generated stories may be unpredictable, they
generally fail to balance the trade-off between surprise and fair play, which
greatly contributes to their poor quality.

</details>


### [49] [InTraVisTo: Inside Transformer Visualisation Tool](https://arxiv.org/abs/2507.13858)
*Nicolò Brunello,Davide Rigamonti,Andrea Sassella,Vincenzo Scotti,Mark James Carman*

Main category: cs.CL

TL;DR: 论文介绍了InTraVisTo工具，用于可视化Transformer模型内部状态和信息流，以帮助理解LLMs的计算过程。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs的推理能力增强，但其不可预测性和行为差异使其在生产中应用具有挑战性。

Method: 开发InTraVisTo工具，通过解码每层token嵌入和Sankey图可视化模型内部状态和信息流。

Result: 工具提供了对Transformer模型计算过程的深入洞察。

Conclusion: InTraVisTo有助于揭示LLMs的内部模式和推理过程。

Abstract: The reasoning capabilities of Large Language Models (LLMs) have increased
greatly over the last few years, as have their size and complexity.
Nonetheless, the use of LLMs in production remains challenging due to their
unpredictable nature and discrepancies that can exist between their desired
behavior and their actual model output. In this paper, we introduce a new tool,
InTraVisTo (Inside Transformer Visualisation Tool), designed to enable
researchers to investigate and trace the computational process that generates
each token in a Transformer-based LLM. InTraVisTo provides a visualization of
both the internal state of the Transformer model (by decoding token embeddings
at each layer of the model) and the information flow between the various
components across the different layers of the model (using a Sankey diagram).
With InTraVisTo, we aim to help researchers and practitioners better understand
the computations being performed within the Transformer model and thus to shed
some light on internal patterns and reasoning processes employed by LLMs.

</details>


### [50] [Label Unification for Cross-Dataset Generalization in Cybersecurity NER](https://arxiv.org/abs/2507.13870)
*Maciej Jalocha,Johan Hausted Schmidt,William Michelseen*

Main category: cs.CL

TL;DR: 研究通过粗粒度标签统一解决了网络安全NER领域数据集标签标准化问题，并评估了模型在跨数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 网络安全NER领域缺乏标准化标签，导致数据集难以结合使用。

Method: 采用粗粒度标签统一，使用BiLSTM模型进行跨数据集评估，并提出多头模型和图基迁移模型。

Result: 统一数据集训练的模型泛化能力差，多头模型略有改进，图基迁移模型无明显性能提升。

Conclusion: 标签统一和模型改进效果有限，需进一步研究。

Abstract: The field of cybersecurity NER lacks standardized labels, making it
challenging to combine datasets. We investigate label unification across four
cybersecurity datasets to increase data resource usability. We perform a
coarse-grained label unification and conduct pairwise cross-dataset evaluations
using BiLSTM models. Qualitative analysis of predictions reveals errors,
limitations, and dataset differences. To address unification limitations, we
propose alternative architectures including a multihead model and a graph-based
transfer model. Results show that models trained on unified datasets generalize
poorly across datasets. The multihead model with weight sharing provides only
marginal improvements over unified training, while our graph-based transfer
model built on BERT-base-NER shows no significant performance gains compared
BERT-base-NER.

</details>


### [51] [Optimizing ASR for Catalan-Spanish Code-Switching: A Comparative Analysis of Methodologies](https://arxiv.org/abs/2507.13875)
*Carlos Mena,Pol Serra,Jacobo Romero,Abir Messaoudi,Jose Giraldo,Carme Armentano-Oller,Rodolfo Zevallos,Ivan Meza,Javier Hernando*

Main category: cs.CL

TL;DR: 论文探讨了如何通过合成数据、拼接单语音频和利用真实语码转换数据提升加泰罗尼亚语-西班牙语语码转换的自动语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 语码转换（CS）在自动语音识别（ASR）中因缺乏专用数据集和语言相似性而面临挑战，尤其在多语言社会中普遍存在。

Method: 采用三种策略：生成合成CS数据、拼接单语音频、利用真实CS数据加语言标记，并基于Whisper模型进行微调。

Result: 结合少量合成CS数据和主要语言标记的模型表现最佳。

Conclusion: 合成数据与语言标记结合的方法有效提升了ASR在CS任务中的性能。

Abstract: Code-switching (CS), the alternating use of two or more languages, challenges
automatic speech recognition (ASR) due to scarce training data and linguistic
similarities. The lack of dedicated CS datasets limits ASR performance, as most
models rely on monolingual or mixed-language corpora that fail to reflect
real-world CS patterns. This issue is critical in multilingual societies where
CS occurs in informal and formal settings. A key example is Catalan-Spanish CS,
widely used in media and parliamentary speeches. In this work, we improve ASR
for Catalan-Spanish CS by exploring three strategies: (1) generating synthetic
CS data, (2) concatenating monolingual audio, and (3) leveraging real CS data
with language tokens. We extract CS data from Catalan speech corpora and
fine-tune OpenAI's Whisper models, making them available on Hugging Face.
Results show that combining a modest amount of synthetic CS data with the
dominant language token yields the best transcription performance.

</details>


### [52] [Using LLMs to identify features of personal and professional skills in an open-response situational judgment test](https://arxiv.org/abs/2507.13881)
*Cole Walsh,Rodica Ivan,Muhammad Zafar Iqbal,Colleen Robb*

Main category: cs.CL

TL;DR: 论文探讨了利用大型语言模型（LLMs）从情境判断测试（SJTs）中提取相关特征的新方法，以解决传统人工评分难以规模化的问题。


<details>
  <summary>Details</summary>
Motivation: 学术项目日益重视个人与专业技能，但传统SJTs依赖人工评分，难以规模化。需要可靠且自动化的评分系统。

Method: 采用大型语言模型（LLMs）从SJT回答中提取相关特征，以Casper SJT为例验证方法有效性。

Result: 研究表明该方法为个人与专业技能的自动化评分奠定了基础。

Conclusion: LLMs为SJTs的自动化评分提供了可行路径，未来可进一步开发相关技术。

Abstract: Academic programs are increasingly recognizing the importance of personal and
professional skills and their critical role alongside technical expertise in
preparing students for future success in diverse career paths. With this
growing demand comes the need for scalable systems to measure, evaluate, and
develop these skills. Situational Judgment Tests (SJTs) offer one potential
avenue for measuring these skills in a standardized and reliable way, but
open-response SJTs have traditionally relied on trained human raters for
evaluation, presenting operational challenges to delivering SJTs at scale. Past
attempts at developing NLP-based scoring systems for SJTs have fallen short due
to issues with construct validity of these systems. In this article, we explore
a novel approach to extracting construct-relevant features from SJT responses
using large language models (LLMs). We use the Casper SJT to demonstrate the
efficacy of this approach. This study sets the foundation for future
developments in automated scoring for personal and professional skills.

</details>


### [53] [Political Leaning and Politicalness Classification of Texts](https://arxiv.org/abs/2507.13913)
*Matous Volf,Jakub Simko*

Main category: cs.CL

TL;DR: 本文提出了一种使用Transformer模型自动分类文本政治倾向和政治性的方法，通过整合多个数据集并评估模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在分布外文本上表现不佳的问题，提供更通用的解决方案。

Method: 整合12个政治倾向分类数据集，并扩展18个数据集以创建新的政治性标签数据集，采用留一法和留出法进行基准测试。

Result: 通过实验评估现有模型并训练具有更强泛化能力的新模型。

Conclusion: 提出的方法在提升模型泛化能力方面表现良好，为政治文本分类提供了更全面的解决方案。

Abstract: This paper addresses the challenge of automatically classifying text
according to political leaning and politicalness using transformer models. We
compose a comprehensive overview of existing datasets and models for these
tasks, finding that current approaches create siloed solutions that perform
poorly on out-of-distribution texts. To address this limitation, we compile a
diverse dataset by combining 12 datasets for political leaning classification
and creating a new dataset for politicalness by extending 18 existing datasets
with the appropriate label. Through extensive benchmarking with leave-one-in
and leave-one-out methodologies, we evaluate the performance of existing models
and train new ones with enhanced generalization capabilities.

</details>


### [54] [The Levers of Political Persuasion with Conversational AI](https://arxiv.org/abs/2507.13919)
*Kobi Hackenburg,Ben M. Tappin,Luke Hewitt,Ed Saunders,Sid Black,Hause Lin,Catherine Fist,Helen Margetts,David G. Rand,Christopher Summerfield*

Main category: cs.CL

TL;DR: 研究表明，当前和近期的AI说服力主要来自后训练和提示方法，而非个性化或模型规模扩大，但这些方法在提高说服力的同时降低了事实准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨对话AI对人类信念的潜在影响，评估其说服力来源及事实准确性。

Method: 在76,977名参与者中部署19个LLM，包括专为说服力设计的模型，测试707个政治议题的说服力，并检查466,769条生成内容的事实准确性。

Result: 后训练和提示方法分别将说服力提升51%和27%，但降低了事实准确性。

Conclusion: AI的说服力提升主要依赖后训练和提示方法，但这些方法可能牺牲事实准确性，需谨慎使用。

Abstract: There are widespread fears that conversational AI could soon exert
unprecedented influence over human beliefs. Here, in three large-scale
experiments (N=76,977), we deployed 19 LLMs-including some post-trained
explicitly for persuasion-to evaluate their persuasiveness on 707 political
issues. We then checked the factual accuracy of 466,769 resulting LLM claims.
Contrary to popular concerns, we show that the persuasive power of current and
near-future AI is likely to stem more from post-training and prompting
methods-which boosted persuasiveness by as much as 51% and 27%
respectively-than from personalization or increasing model scale. We further
show that these methods increased persuasion by exploiting LLMs' unique ability
to rapidly access and strategically deploy information and that, strikingly,
where they increased AI persuasiveness they also systematically decreased
factual accuracy.

</details>


### [55] [Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support](https://arxiv.org/abs/2507.13937)
*Jan Trienes,Anastasiia Derzhanskaia,Roland Schwarzkopf,Markus Mühling,Jörg Schlötterer,Christin Seifert*

Main category: cs.CL

TL;DR: Marcel是一个轻量级开源对话代理，旨在帮助准学生解答入学相关问题，减轻大学工作人员负担。


<details>
  <summary>Details</summary>
Motivation: 支持准学生的入学咨询需求，同时减少大学工作人员的工作量。

Method: 采用检索增强生成技术，结合FAQ检索器，优化检索质量，并设计易于在资源有限环境中部署的系统架构。

Result: 系统能够提供快速、个性化的回答，并通过技术评估和实际部署验证了其有效性。

Conclusion: Marcel是一个高效且易于部署的解决方案，适用于学术环境中的入学咨询支持。

Abstract: We present Marcel, a lightweight and open-source conversational agent
designed to support prospective students with admission-related inquiries. The
system aims to provide fast and personalized responses, while reducing workload
of university staff. We employ retrieval-augmented generation to ground answers
in university resources and to provide users with verifiable, contextually
relevant information. To improve retrieval quality, we introduce an FAQ
retriever that maps user questions to knowledge-base entries, allowing
administrators to steer retrieval, and improving over standard dense/hybrid
retrieval strategies. The system is engineered for easy deployment in
resource-constrained academic settings. We detail the system architecture,
provide a technical evaluation of its components, and report insights from a
real-world deployment.

</details>


### [56] [Exploiting Primacy Effect To Improve Large Language Models](https://arxiv.org/abs/2507.13949)
*Bianca Raimondi,Maurizio Gabbrielli*

Main category: cs.CL

TL;DR: 研究发现，微调后的LLMs在MCQA任务中存在首因效应偏差，通过重新排序选项可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在MCQA任务中的首因效应偏差及其影响。

Method: 通过重新排序选项基于语义相似性，利用首因效应提升性能。

Result: 实验表明该方法显著提高了MCQA任务的准确性。

Conclusion: 偏差既是挑战也是机会，为偏置感知模型设计提供了新思路。

Abstract: Large Language Models (LLMs) have become essential in many Natural Language
Processing (NLP) tasks, leveraging extensive pre-training and fine-tuning to
achieve high accuracy. However, like humans, LLMs exhibit biases, particularly
positional biases such as primacy and recency effects, which can influence the
accuracy of the answers. The primacy effect-where items presented first are
more likely to be remembered or selected-plays a key role in Multiple Choice
Question Answering (MCQA), where the order of answer options can affect
prediction outcomes. This study focuses on primacy bias in fine-tuned LLMs: We
first show that fine-tuning amplifies this bias, probably due to exposure to
human-like patterns. Hence, we strategically leverage this effect by reordering
response options based on semantic similarity to the query, without requiring
knowledge of the correct answer. Our experimental results show that this
approach significantly improves performance in MCQA. More generally, our
findings underscore the dual nature of biases as both challenges and
opportunities, offering insights for bias-aware model design and NLP
applications.

</details>


### [57] [Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need](https://arxiv.org/abs/2507.13966)
*Bhishma Dedhia,Yuval Kansal,Niraj K. Jha*

Main category: cs.CL

TL;DR: 论文提出了一种基于知识图谱（KG）的任务生成方法，通过组合简单领域概念来训练语言模型，实现领域特定的超级智能。在医学领域验证了该方法，并展示了显著优于现有推理模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统语言模型在跨领域泛化中表现良好，但缺乏深度领域专业知识。通过知识图谱的组合性结构，可以构建更复杂的领域概念，从而提升模型的领域推理能力。

Method: 设计了一个任务生成流程，直接从知识图谱的原始概念合成任务，并基于生成的课程微调语言模型（如QwQ-32B），得到领域专用模型（如QwQ-Med-3）。

Result: QwQ-Med-3在医学领域的ICD-Bench评估中显著优于现有模型，并在最困难任务上表现突出。此外，其在医学问答基准测试中也能提升基础模型的性能。

Conclusion: 论文提出了一种通过组合领域专用超级智能代理实现通用人工智能（AGI）的路径，展示了知识图谱在领域推理中的潜力。

Abstract: Language models traditionally used for cross-domain generalization have
recently demonstrated task-specific reasoning. However, their top-down training
approach on general corpora is insufficient for acquiring abstractions needed
for deep domain expertise. This may require a bottom-up approach that acquires
expertise by learning to compose simple domain concepts into more complex ones.
A knowledge graph (KG) provides this compositional structure, where domain
primitives are represented as head-relation-tail edges and their paths encode
higher-level concepts. We present a task generation pipeline that synthesizes
tasks directly from KG primitives, enabling models to acquire and compose them
for reasoning. We fine-tune language models on the resultant KG-grounded
curriculum to demonstrate domain-specific superintelligence. While broadly
applicable, we validate our approach in medicine, where reliable KGs exist.
Using a medical KG, we curate 24,000 reasoning tasks paired with thinking
traces derived from diverse medical primitives. We fine-tune the QwQ-32B model
on this curriculum to obtain QwQ-Med-3 that takes a step towards medical
superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify
reasoning abilities across 15 medical domains. Our experiments demonstrate that
QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on
ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired
primitives to widen the performance gap on the hardest tasks of ICD-Bench.
Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3
transfers acquired expertise to enhance the base model's performance. While the
industry's approach to artificial general intelligence (AGI) emphasizes broad
expertise, we envision a future in which AGI emerges from the composable
interaction of efficient domain-specific superintelligent agents.

</details>


### [58] [Open Automatic Speech Recognition Models for Classical and Modern Standard Arabic](https://arxiv.org/abs/2507.13977)
*Lilit Grigoryan,Nikolay Karpov,Enas Albasiri,Vitaly Lavrukhin,Boris Ginsburg*

Main category: cs.CL

TL;DR: 论文提出了一种通用的阿拉伯语语音和文本处理方法，并基于FastConformer架构训练了两个新模型：一个专注于现代标准阿拉伯语（MSA），另一个首次统一了MSA和古典阿拉伯语（CA）。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语自动语音识别（ASR）系统发展面临挑战，尤其是语言变体的处理不足。

Method: 采用通用方法处理阿拉伯语语音和文本，基于FastConformer架构训练两个模型。

Result: MSA模型在相关数据集上达到SOTA性能，统一模型在CA带音标任务中表现优异，同时保持MSA的强性能。

Conclusion: 开源模型和训练方法以促进可重复性，填补了阿拉伯语ASR领域的空白。

Abstract: Despite Arabic being one of the most widely spoken languages, the development
of Arabic Automatic Speech Recognition (ASR) systems faces significant
challenges due to the language's complexity, and only a limited number of
public Arabic ASR models exist. While much of the focus has been on Modern
Standard Arabic (MSA), there is considerably less attention given to the
variations within the language. This paper introduces a universal methodology
for Arabic speech and text processing designed to address unique challenges of
the language. Using this methodology, we train two novel models based on the
FastConformer architecture: one designed specifically for MSA and the other,
the first unified public model for both MSA and Classical Arabic (CA). The MSA
model sets a new benchmark with state-of-the-art (SOTA) performance on related
datasets, while the unified model achieves SOTA accuracy with diacritics for CA
while maintaining strong performance for MSA. To promote reproducibility, we
open-source the models and their training recipes.

</details>


### [59] [Efficient Temporal Tokenization for Mobility Prediction with Large Language Models](https://arxiv.org/abs/2507.14017)
*Haoyu He,Haozheng Luo,Yan Chen,Qi R. Wang*

Main category: cs.CL

TL;DR: RHYTHM框架利用大型语言模型（LLM）作为时空预测器和轨迹推理器，通过分层注意力将轨迹分段为离散令牌，显著减少序列长度并提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在捕捉人类移动轨迹的时空依赖性和计算效率上的不足。

Method: 将轨迹分段为每日令牌，利用分层注意力捕捉日和周依赖，并通过冻结的LLM增强令牌表示。

Result: 在三个真实数据集上，准确率提升2.4%，周末提升5.0%，训练时间减少24.6%。

Conclusion: RHYTHM在提升预测准确性和计算效率方面表现出色，优于现有方法。

Abstract: We introduce RHYTHM (Reasoning with Hierarchical Temporal Tokenization for
Human Mobility), a framework that leverages large language models (LLMs) as
spatio-temporal predictors and trajectory reasoners. RHYTHM partitions
trajectories into daily segments encoded as discrete tokens with hierarchical
attention, capturing both daily and weekly dependencies while substantially
reducing the sequence length. Token representations are enriched with
pre-computed prompt embeddings via a frozen LLM, enhancing the model's ability
to capture interdependencies without extensive computational overhead. By
freezing the LLM backbone, RHYTHM achieves significant computational
efficiency. Evaluation on three real-world datasets demonstrates a 2.4%
improvement in accuracy, 5.0% increase on weekends, and 24.6% reduction in
training time compared to state-of-the-art methods.

</details>


### [60] [CPC-CMS: Cognitive Pairwise Comparison Classification Model Selection Framework for Document-level Sentiment Analysis](https://arxiv.org/abs/2507.14022)
*Jianfei Li,Kevin Kam Fung Yuen*

Main category: cs.CL

TL;DR: 提出CPC-CMS框架用于文档级情感分析，通过专家知识判断计算权重，结合多种评估指标选择最佳分类模型。实验表明ALBERT在排除时间因素时表现最佳，但考虑时间消耗时无单一模型始终最优。


<details>
  <summary>Details</summary>
Motivation: 解决文档级情感分析中如何选择最佳分类模型的问题，结合多种评估指标和专家知识判断。

Method: 使用CPC计算评估指标权重，构建加权决策矩阵，比较多种基线模型（如Naive Bayes、LSVC、ALBERT等）在三个社交媒体数据集上的表现。

Result: ALBERT在排除时间因素时表现最佳；考虑时间消耗时无单一模型始终最优。

Conclusion: CPC-CMS框架可推广至其他分类应用领域。

Abstract: This study proposes the Cognitive Pairwise Comparison Classification Model
Selection (CPC-CMS) framework for document-level sentiment analysis. The CPC,
based on expert knowledge judgment, is used to calculate the weights of
evaluation criteria, including accuracy, precision, recall, F1-score,
specificity, Matthews Correlation Coefficient (MCC), Cohen's Kappa (Kappa), and
efficiency. Naive Bayes, Linear Support Vector Classification (LSVC), Random
Forest, Logistic Regression, Extreme Gradient Boosting (XGBoost), Long
Short-Term Memory (LSTM), and A Lite Bidirectional Encoder Representations from
Transformers (ALBERT) are chosen as classification baseline models. A weighted
decision matrix consisting of classification evaluation scores with respect to
criteria weights, is formed to select the best classification model for a
classification problem. Three open datasets of social media are used to
demonstrate the feasibility of the proposed CPC-CMS. Based on our simulation,
for evaluation results excluding the time factor, ALBERT is the best for the
three datasets; if time consumption is included, no single model always
performs better than the other models. The CPC-CMS can be applied to the other
classification applications in different areas.

</details>


### [61] [Evaluating the Effectiveness of Cost-Efficient Large Language Models in Benchmark Biomedical Tasks](https://arxiv.org/abs/2507.14045)
*Israt Jahan,Md Tahmid Rahman Laskar,Chun Peng,Jimmy Huang*

Main category: cs.CL

TL;DR: 该论文评估了多种成本高效的大型语言模型（LLMs）在生物医学任务中的表现，发现不同模型在不同任务中表现优异，开源模型在某些任务中甚至优于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在生物医学任务中的表现，为特定应用选择最优模型提供依据。

Method: 对闭源和开源LLMs进行实验，涵盖文本分类、生成、问答及多模态图像处理任务。

Result: 没有单一模型在所有任务中表现最佳，不同模型在不同任务中表现优异，开源模型在某些任务中表现更好。

Conclusion: 研究结果为选择适合特定生物医学应用的模型提供了重要参考。

Abstract: This paper presents a comprehensive evaluation of cost-efficient Large
Language Models (LLMs) for diverse biomedical tasks spanning both text and
image modalities. We evaluated a range of closed-source and open-source LLMs on
tasks such as biomedical text classification and generation, question
answering, and multimodal image processing. Our experimental findings indicate
that there is no single LLM that can consistently outperform others across all
tasks. Instead, different LLMs excel in different tasks. While some
closed-source LLMs demonstrate strong performance on specific tasks, their
open-source counterparts achieve comparable results (sometimes even better),
with additional benefits like faster inference and enhanced privacy. Our
experimental results offer valuable insights for selecting models that are
optimally suited for specific biomedical applications.

</details>


### [62] [Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog](https://arxiv.org/abs/2507.14063)
*Lautaro Estienne,Gabriel Ben Zenou,Nona Naderi,Jackie Cheung,Pablo Piantanida*

Main category: cs.CL

TL;DR: 论文提出了一种协作理性言语行为（CRSA）框架，扩展了RSA模型，用于多轮对话场景，优化信息增益函数，并在医学领域的对话中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI系统在协作角色中需要推理共享目标和信念，而现有RSA扩展在多轮协作场景中面临挑战。

Method: 引入CRSA，基于信息论扩展RSA，优化适应率失真理论的增益函数，建模多轮对话。

Result: 在指称游戏和医患对话中，CRSA比现有基线表现更一致、可解释且协作性更强。

Conclusion: CRSA为更实用和社交意识强的语言代理铺平了道路。

Abstract: As AI systems take on collaborative roles, they must reason about shared
goals and beliefs-not just generate fluent language. The Rational Speech Act
(RSA) framework offers a principled approach to pragmatic reasoning, but
existing extensions face challenges in scaling to multi-turn, collaborative
scenarios. In this paper, we introduce Collaborative Rational Speech Act
(CRSA), an information-theoretic (IT) extension of RSA that models multi-turn
dialog by optimizing a gain function adapted from rate-distortion theory. This
gain is an extension of the gain model that is maximized in the original RSA
model but takes into account the scenario in which both agents in a
conversation have private information and produce utterances conditioned on the
dialog. We demonstrate the effectiveness of CRSA on referential games and
template-based doctor-patient dialogs in the medical domain. Empirical results
show that CRSA yields more consistent, interpretable, and collaborative
behavior than existing baselines-paving the way for more pragmatic and socially
aware language agents.

</details>


### [63] [DENSE: Longitudinal Progress Note Generation with Temporal Modeling of Heterogeneous Clinical Notes Across Hospital Visits](https://arxiv.org/abs/2507.14079)
*Garapati Keerthana,Manik Gupta*

Main category: cs.CL

TL;DR: DENSE系统通过模拟医生参考历史记录的方式生成临床进展记录，解决了电子健康记录中进展记录不足的问题。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）中进展记录严重不足，影响患者纵向叙事的完整性。

Method: DENSE采用细粒度分类和时间对齐机制，结合临床检索策略和大型语言模型（LLM）生成进展记录。

Result: 生成的记录在时间对齐和临床连贯性上表现优异，时间对齐比为1.089。

Conclusion: DENSE为临床记录合成提供了可扩展的解决方案，支持下游任务如总结和预测建模。

Abstract: Progress notes are among the most clinically meaningful artifacts in an
Electronic Health Record (EHR), offering temporally grounded insights into a
patient's evolving condition, treatments, and care decisions. Despite their
importance, they are severely underrepresented in large-scale EHR datasets. For
instance, in the widely used Medical Information Mart for Intensive Care III
(MIMIC-III) dataset, only about $8.56\%$ of hospital visits include progress
notes, leaving gaps in longitudinal patient narratives. In contrast, the
dataset contains a diverse array of other note types, each capturing different
aspects of care.
  We present DENSE (Documenting Evolving Progress Notes from Scattered
Evidence), a system designed to align with clinical documentation workflows by
simulating how physicians reference past encounters while drafting progress
notes. The system introduces a fine-grained note categorization and a temporal
alignment mechanism that organizes heterogeneous notes across visits into
structured, chronological inputs. At its core, DENSE leverages a clinically
informed retrieval strategy to identify temporally and semantically relevant
content from both current and prior visits. This retrieved evidence is used to
prompt a large language model (LLM) to generate clinically coherent and
temporally aware progress notes.
  We evaluate DENSE on a curated cohort of patients with multiple visits and
complete progress note documentation. The generated notes demonstrate strong
longitudinal fidelity, achieving a temporal alignment ratio of $1.089$,
surpassing the continuity observed in original notes. By restoring narrative
coherence across fragmented documentation, our system supports improved
downstream tasks such as summarization, predictive modeling, and clinical
decision support, offering a scalable solution for LLM-driven note synthesis in
real-world healthcare settings.

</details>


### [64] [Lessons from the TREC Plain Language Adaptation of Biomedical Abstracts (PLABA) track](https://arxiv.org/abs/2507.14096)
*Brian Ondov,William Xia,Kush Attal,Ishita Unde,Jerry He,Hoa Dang,Ian Soboroff,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: PLABA track评估了语言模型在将生物医学文献改写为通俗语言方面的表现，发现模型在事实准确性和完整性上接近人类水平，但在简洁性和简单性上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 生物医学文献对患者和护理人员来说通常难以理解，语言模型可能提供解决方案，但其不可预测性和潜在风险需要严格评估。

Method: 通过PLABA竞赛，任务包括全文改写（Task 1）和术语替换（Task 2），结合自动和人工评估。

Result: 模型在Task 1的事实准确性和完整性上表现优异，但在简洁性和简单性上不及人类；Task 2中术语识别和替换仍有挑战。

Conclusion: 语言模型在生物医学文献改写中具有潜力，但需改进自动评估工具并解决简洁性和术语处理问题。

Abstract: Objective: Recent advances in language models have shown potential to adapt
professional-facing biomedical literature to plain language, making it
accessible to patients and caregivers. However, their unpredictability,
combined with the high potential for harm in this domain, means rigorous
evaluation is necessary. Our goals with this track were to stimulate research
and to provide high-quality evaluation of the most promising systems.
  Methods: We hosted the Plain Language Adaptation of Biomedical Abstracts
(PLABA) track at the 2023 and 2024 Text Retrieval Conferences. Tasks included
complete, sentence-level, rewriting of abstracts (Task 1) as well as
identifying and replacing difficult terms (Task 2). For automatic evaluation of
Task 1, we developed a four-fold set of professionally-written references.
Submissions for both Tasks 1 and 2 were provided extensive manual evaluation
from biomedical experts.
  Results: Twelve teams spanning twelve countries participated in the track,
with models from multilayer perceptrons to large pretrained transformers. In
manual judgments of Task 1, top-performing models rivaled human levels of
factual accuracy and completeness, but not simplicity or brevity. Automatic,
reference-based metrics generally did not correlate well with manual judgments.
In Task 2, systems struggled with identifying difficult terms and classifying
how to replace them. When generating replacements, however, LLM-based systems
did well in manually judged accuracy, completeness, and simplicity, though not
in brevity.
  Conclusion: The PLABA track showed promise for using Large Language Models to
adapt biomedical literature for the general public, while also highlighting
their deficiencies and the need for improved automatic benchmarking tools.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [65] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

TL;DR: 本文综述了无人机航拍场景中的开放词汇目标检测（OVOD），探讨了其核心原理、方法分类、数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统无人机目标检测方法局限于预定义类别，而OVOD通过跨模态文本-图像对齐技术（如CLIP）实现了对未见物体的检测，提升了无人机的智能性和自主性。

Method: 通过系统分类法对现有OVOD方法进行分类，并全面梳理相关数据集，分析关键挑战和开放问题。

Result: 提出了无人机航拍场景中OVOD的清晰路线图，为研究人员提供了有价值的参考。

Conclusion: 本文为无人机航拍场景中的OVOD研究提供了系统综述，并指出了未来的研究方向和应用前景。

Abstract: Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [66] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

TL;DR: 论文提出了一种名为EDNIG的新型深度学习框架，用于低光图像增强，结合了U-Net架构和亮度引导，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强问题，通过亮度引导和多尺度特征提取提升模型性能。

Method: 基于U-Net架构，引入亮度图（BCP）作为引导输入，加入SPP模块提取多尺度特征，使用Swish激活函数，并在GAN框架下优化。

Result: EDNIG在定量指标和视觉质量上优于现有方法，同时模型复杂度较低。

Conclusion: EDNIG是一种高效且实用的低光图像增强方法，适用于实际应用。

Abstract: This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [67] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

TL;DR: VLMs在复杂视觉任务中表现出色，但在非局部视觉推理任务中表现不佳，远低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在非局部视觉推理任务中的表现，揭示其核心视觉推理能力的不足。

Method: 设计了三种非局部视觉任务（比较感知、扫视搜索、平滑视觉搜索），测试主流VLMs的性能。

Result: 主流VLMs在这些任务中表现差，甚至接近随机准确率，远低于人类水平。

Conclusion: 尽管VLMs在原始视觉敏锐度上有进步，但其核心视觉推理能力仍不足。

Abstract: Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>


### [68] [Enhancing Spatial Reasoning in Vision-Language Models via Chain-of-Thought Prompting and Reinforcement Learning](https://arxiv.org/abs/2507.13362)
*Binbin Ji,Siddharth Agrawal,Qiance Tang,Yvonne Wu*

Main category: cs.CV

TL;DR: 研究通过Chain-of-Thought (CoT)提示和强化学习提升视觉语言模型(VLMs)的空间推理能力，发现结构化多阶段提示(SceneGraph CoT)显著提高准确性，而Group Relative Policy Optimization (GRPO)在泛化性和鲁棒性上优于监督微调(SFT)。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过提示策略和强化学习提升VLMs的空间推理能力，并解决SFT在泛化性上的不足。

Method: 使用SceneGraph CoT提示策略和GRPO强化学习方法，在SAT数据集上微调模型，并在CVBench上评估性能。

Result: SceneGraph CoT显著提升空间推理准确性；GRPO在Pass@1评估和OOD条件下表现优于SFT，泛化性更强。

Conclusion: 结构化提示和强化学习能有效提升VLMs的空间推理能力和泛化性，GRPO在鲁棒性上表现突出。

Abstract: This study investigates the spatial reasoning capabilities of vision-language
models (VLMs) through Chain-of-Thought (CoT) prompting and reinforcement
learning. We begin by evaluating the impact of different prompting strategies
and find that simple CoT formats, where the model generates a reasoning step
before the answer, not only fail to help, but can even harm the model's
original performance. In contrast, structured multi-stage prompting based on
scene graphs (SceneGraph CoT) significantly improves spatial reasoning
accuracy. Furthermore, to improve spatial reasoning ability, we fine-tune
models using Group Relative Policy Optimization (GRPO) on the SAT dataset and
evaluate their performance on CVBench. Compared to supervised fine-tuning
(SFT), GRPO achieves higher accuracy on Pass@1 evaluations and demonstrates
superior robustness under out-of-distribution (OOD) conditions. In particular,
we find that SFT overfits to surface-level linguistic patterns and may degrade
performance when test-time phrasing changes (e.g., from "closer to" to "farther
from"). GRPO, on the other hand, generalizes more reliably and maintains stable
performance under such shifts. Our findings provide insights into how
reinforcement learning and structured prompting improve the spatial reasoning
capabilities and generalization behavior of modern VLMs. All code is open
source at: https://github.com/Yvonne511/spatial-vlm-investigator

</details>


### [69] [Just Add Geometry: Gradient-Free Open-Vocabulary 3D Detection Without Human-in-the-Loop](https://arxiv.org/abs/2507.13363)
*Atharv Goel,Mehar Khurana*

Main category: cs.CV

TL;DR: 利用2D视觉语言模型进行开放词汇3D物体检测，无需人工标注3D标签，通过几何策略和伪深度实现。


<details>
  <summary>Details</summary>
Motivation: 解决3D物体检测数据集类别有限和标注成本高的问题，利用2D模型的语义理解能力扩展至开放世界。

Method: 结合2D视觉语言检测器生成文本条件提案，使用SAM分割并通过相机几何和伪深度反向投影到3D，引入几何膨胀策略推断3D边界框。

Result: 在LiDAR和RGB-D输入下实现竞争性定位性能，无需训练且支持开放词汇。

Conclusion: 展示了2D基础模型在可扩展3D感知中的潜力，开源代码和资源。

Abstract: Modern 3D object detection datasets are constrained by narrow class
taxonomies and costly manual annotations, limiting their ability to scale to
open-world settings. In contrast, 2D vision-language models trained on
web-scale image-text pairs exhibit rich semantic understanding and support
open-vocabulary detection via natural language prompts. In this work, we
leverage the maturity and category diversity of 2D foundation models to perform
open-vocabulary 3D object detection without any human-annotated 3D labels.
  Our pipeline uses a 2D vision-language detector to generate text-conditioned
proposals, which are segmented with SAM and back-projected into 3D using camera
geometry and either LiDAR or monocular pseudo-depth. We introduce a geometric
inflation strategy based on DBSCAN clustering and Rotating Calipers to infer 3D
bounding boxes without training. To simulate adverse real-world conditions, we
construct Pseudo-nuScenes, a fog-augmented, RGB-only variant of the nuScenes
dataset.
  Experiments demonstrate that our method achieves competitive localization
performance across multiple settings, including LiDAR-based and purely RGB-D
inputs, all while remaining training-free and open-vocabulary. Our results
highlight the untapped potential of 2D foundation models for scalable 3D
perception. We open-source our code and resources at
https://github.com/atharv0goel/open-world-3D-det.

</details>


### [70] [OmniVec2 -- A Novel Transformer based Network for Large Scale Multimodal and Multitask Learning](https://arxiv.org/abs/2507.13364)
*Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

TL;DR: 提出了一种新型多模态多任务网络及训练算法，支持12种模态数据输入，通过共享Transformer架构和跨注意力机制实现统一嵌入空间，并在25个数据集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态和多任务场景下的数据融合与任务协同问题，提升模型在多种模态数据上的表现。

Method: 采用模态专用分词器、共享Transformer架构和跨注意力机制，提出迭代模态切换预训练策略和模态对训练算法。

Result: 在12种模态的25个数据集上实现了最优性能。

Conclusion: 所提出的架构、预训练策略和多任务训练方法在多模态场景中表现出色。

Abstract: We present a novel multimodal multitask network and associated training
algorithm. The method is capable of ingesting data from approximately 12
different modalities namely image, video, audio, text, depth, point cloud, time
series, tabular, graph, X-ray, infrared, IMU, and hyperspectral. The proposed
approach utilizes modality specialized tokenizers, a shared transformer
architecture, and cross-attention mechanisms to project the data from different
modalities into a unified embedding space. It addresses multimodal and
multitask scenarios by incorporating modality-specific task heads for different
tasks in respective modalities. We propose a novel pretraining strategy with
iterative modality switching to initialize the network, and a training
algorithm which trades off fully joint training over all modalities, with
training on pairs of modalities at a time. We provide comprehensive evaluation
across 25 datasets from 12 modalities and show state of the art performances,
demonstrating the effectiveness of the proposed architecture, pretraining
strategy and adapted multitask training.

</details>


### [71] [Transformer-Based Framework for Motion Capture Denoising and Anomaly Detection in Medical Rehabilitation](https://arxiv.org/abs/2507.13371)
*Yeming Cai,Yang Wang,Zhenglin Li*

Main category: cs.CV

TL;DR: 提出了一种结合光学动作捕捉和Transformer模型的端到端深度学习框架，用于增强医疗康复，解决数据噪声和缺失问题，并实时检测异常动作。


<details>
  <summary>Details</summary>
Motivation: 解决因遮挡和环境因素导致的数据噪声和缺失问题，同时实时检测异常动作以确保患者安全。

Method: 利用时间序列建模，去噪并补全动作捕捉数据，提高鲁棒性。

Result: 在卒中和骨科康复数据集上的评估显示，该框架在数据重建和异常检测方面表现优异。

Conclusion: 为远程康复提供了一种可扩展、经济高效的解决方案，减少了对现场监督的需求。

Abstract: This paper proposes an end-to-end deep learning framework integrating optical
motion capture with a Transformer-based model to enhance medical
rehabilitation. It tackles data noise and missing data caused by occlusion and
environmental factors, while detecting abnormal movements in real time to
ensure patient safety. Utilizing temporal sequence modeling, our framework
denoises and completes motion capture data, improving robustness. Evaluations
on stroke and orthopedic rehabilitation datasets show superior performance in
data reconstruction and anomaly detection, providing a scalable, cost-effective
solution for remote rehabilitation with reduced on-site supervision.

</details>


### [72] [Enhancing Breast Cancer Detection with Vision Transformers and Graph Neural Networks](https://arxiv.org/abs/2507.13372)
*Yeming Cai,Zhenglin Li,Yang Wang*

Main category: cs.CV

TL;DR: 本文提出了一种结合Vision Transformers（ViT）和Graph Neural Networks（GNN）的创新框架，用于提升乳腺癌检测的准确性，在CBIS-DDSM数据集上达到84.2%的准确率。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性死亡的主要原因之一，早期检测对提高生存率至关重要。

Method: 通过整合ViT的全局图像特征提取能力和GNN的结构关系建模能力，构建了一个新型检测框架。

Result: 该框架在CBIS-DDSM数据集上实现了84.2%的准确率，优于传统方法，并提供了可解释的注意力热图。

Conclusion: 该框架不仅提高了乳腺癌检测的准确性，还通过可解释性工具辅助临床决策。

Abstract: Breast cancer is a leading cause of death among women globally, and early
detection is critical for improving survival rates. This paper introduces an
innovative framework that integrates Vision Transformers (ViT) and Graph Neural
Networks (GNN) to enhance breast cancer detection using the CBIS-DDSM dataset.
Our framework leverages ViT's ability to capture global image features and
GNN's strength in modeling structural relationships, achieving an accuracy of
84.2%, outperforming traditional methods. Additionally, interpretable attention
heatmaps provide insights into the model's decision-making process, aiding
radiologists in clinical settings.

</details>


### [73] [Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection](https://arxiv.org/abs/2507.13373)
*Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao*

Main category: cs.CV

TL;DR: Butter是一个新的目标检测框架，通过频率自适应特征一致性增强和渐进式层次特征融合网络，提升了多尺度特征表示能力，在自动驾驶场景中实现了精度与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有架构（如YOLO和DETR）在多尺度特征一致性和计算效率之间存在矛盾，影响了自动驾驶中目标检测的准确性。

Method: Butter引入FAFCE组件（频率自适应特征一致性增强）和PHFFNet模块（渐进式层次特征融合网络），分别优化多尺度特征一致性和语义层次特征融合。

Result: 在BDD100K、KITTI和Cityscapes数据集上的实验表明，Butter在检测精度和模型复杂度方面均有显著提升。

Conclusion: Butter通过层次特征优化与融合，为自动驾驶中的实时目标检测提供了一种高精度、高效率的解决方案。

Abstract: Hierarchical feature representations play a pivotal role in computer vision,
particularly in object detection for autonomous driving. Multi-level semantic
understanding is crucial for accurately identifying pedestrians, vehicles, and
traffic signs in dynamic environments. However, existing architectures, such as
YOLO and DETR, struggle to maintain feature consistency across different scales
while balancing detection precision and computational efficiency. To address
these challenges, we propose Butter, a novel object detection framework
designed to enhance hierarchical feature representations for improving
detection robustness. Specifically, Butter introduces two key innovations:
Frequency-Adaptive Feature Consistency Enhancement (FAFCE) Component, which
refines multi-scale feature consistency by leveraging adaptive frequency
filtering to enhance structural and boundary precision, and Progressive
Hierarchical Feature Fusion Network (PHFFNet) Module, which progressively
integrates multi-level features to mitigate semantic gaps and strengthen
hierarchical feature learning. Through extensive experiments on BDD100K, KITTI,
and Cityscapes, Butter demonstrates superior feature representation
capabilities, leading to notable improvements in detection accuracy while
reducing model complexity. By focusing on hierarchical feature refinement and
integration, Butter provides an advanced approach to object detection that
achieves a balance between accuracy, deployability, and computational
efficiency in real-time autonomous driving scenarios. Our model and
implementation are publicly available at https://github.com/Aveiro-Lin/Butter,
facilitating further research and validation within the autonomous driving
community.

</details>


### [74] [Smart Routing for Multimodal Video Retrieval: When to Search What](https://arxiv.org/abs/2507.13374)
*Kevin Dela Rosa*

Main category: cs.CV

TL;DR: ModaRoute是一个基于LLM的智能路由系统，通过动态选择最优模态提升多模态视频检索效率，减少计算开销41%，同时保持60.9%的召回率。


<details>
  <summary>Details</summary>
Motivation: 传统密集文本标注虽然能达到75.9%的召回率，但需要昂贵的离线处理且会遗漏34%的视觉信息（如场景文本）。

Method: 利用GPT-4.1分析查询意图，动态路由到ASR、OCR和视觉索引，平均每查询使用1.78种模态，而非全量3.0模态搜索。

Result: 在180万视频片段上的评估显示，智能路由显著降低基础设施成本，同时保持实际部署的竞争力。

Conclusion: ModaRoute为多模态检索系统提供了一种可扩展的实用解决方案。

Abstract: We introduce ModaRoute, an LLM-based intelligent routing system that
dynamically selects optimal modalities for multimodal video retrieval. While
dense text captions can achieve 75.9% Recall@5, they require expensive offline
processing and miss critical visual information present in 34% of clips with
scene text not captured by ASR. By analyzing query intent and predicting
information needs, ModaRoute reduces computational overhead by 41% while
achieving 60.9% Recall@5. Our approach uses GPT-4.1 to route queries across ASR
(speech), OCR (text), and visual indices, averaging 1.78 modalities per query
versus exhaustive 3.0 modality search. Evaluation on 1.8M video clips
demonstrates that intelligent routing provides a practical solution for scaling
multimodal retrieval systems, reducing infrastructure costs while maintaining
competitive effectiveness for real-world deployment.

</details>


### [75] [A Comprehensive Survey for Real-World Industrial Defect Detection: Challenges, Approaches, and Prospects](https://arxiv.org/abs/2507.13378)
*Yuqi Cheng,Yunkang Cao,Haiming Yao,Wei Luo,Cheng Jiang,Hui Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: 综述论文探讨了工业缺陷检测的现状，重点分析了从封闭集到开放集检测的转变及其在2D和3D模态中的应用。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法难以满足现代制造业对精度、自动化和可扩展性的需求，计算机视觉和深度学习的进步推动了缺陷检测的发展。

Method: 论文综述了封闭集和开放集缺陷检测策略的演变，并分析了它们在2D和3D模态中的应用。

Result: 开放集检测技术逐渐成为主流，减少了缺陷标注的需求并提高了新异常的识别能力。

Conclusion: 论文总结了当前工业缺陷检测的关键挑战和新兴趋势，为该领域提供了全面的视角。

Abstract: Industrial defect detection is vital for upholding product quality across
contemporary manufacturing systems. As the expectations for precision,
automation, and scalability intensify, conventional inspection approaches are
increasingly found wanting in addressing real-world demands. Notable progress
in computer vision and deep learning has substantially bolstered defect
detection capabilities across both 2D and 3D modalities. A significant
development has been the pivot from closed-set to open-set defect detection
frameworks, which diminishes the necessity for extensive defect annotations and
facilitates the recognition of novel anomalies. Despite such strides, a
cohesive and contemporary understanding of industrial defect detection remains
elusive. Consequently, this survey delivers an in-depth analysis of both
closed-set and open-set defect detection strategies within 2D and 3D
modalities, charting their evolution in recent years and underscoring the
rising prominence of open-set techniques. We distill critical challenges
inherent in practical detection environments and illuminate emerging trends,
thereby providing a current and comprehensive vista of this swiftly progressing
field.

</details>


### [76] [Using Multiple Input Modalities Can Improve Data-Efficiency and O.O.D. Generalization for ML with Satellite Imagery](https://arxiv.org/abs/2507.13385)
*Arjun Rao,Esther Rolf*

Main category: cs.CV

TL;DR: 论文探讨了在卫星图像机器学习（SatML）任务中，融合其他地理数据层与光学图像对模型性能的提升效果，特别是在数据有限和地理样本外场景下。


<details>
  <summary>Details</summary>
Motivation: 现有SatML模型主要针对光学输入模态设计，而其他地理数据层的潜在价值未被充分探索。研究旨在评估多模态输入对模型性能的影响。

Method: 通过为SatML基准任务生成增强版本数据集，将其他地理数据层（如高程模型、传感器数据）与光学图像结合，测试分类、回归和分割任务中的表现。

Result: 融合其他地理数据层显著提升了模型性能，尤其在数据有限和样本外场景下。硬编码融合策略优于学习型策略。

Conclusion: 多模态输入对SatML模型的数据效率和样本外性能具有重要价值，硬编码融合策略值得未来研究关注。

Abstract: A large variety of geospatial data layers is available around the world
ranging from remotely-sensed raster data like satellite imagery, digital
elevation models, predicted land cover maps, and human-annotated data, to data
derived from environmental sensors such as air temperature or wind speed data.
A large majority of machine learning models trained on satellite imagery
(SatML), however, are designed primarily for optical input modalities such as
multi-spectral satellite imagery. To better understand the value of using other
input modalities alongside optical imagery in supervised learning settings, we
generate augmented versions of SatML benchmark tasks by appending additional
geographic data layers to datasets spanning classification, regression, and
segmentation. Using these augmented datasets, we find that fusing additional
geographic inputs with optical imagery can significantly improve SatML model
performance. Benefits are largest in settings where labeled data are limited
and in geographic out-of-sample settings, suggesting that multi-modal inputs
may be especially valuable for data-efficiency and out-of-sample performance of
SatML models. Surprisingly, we find that hard-coded fusion strategies
outperform learned variants, with interesting implications for future work.

</details>


### [77] [Minimalist Concept Erasure in Generative Models](https://arxiv.org/abs/2507.13386)
*Yang Zhang,Er Jin,Yanfei Dong,Yixuan Wu,Philip Torr,Ashkan Khakzar,Johannes Stegmaier,Kenji Kawaguchi*

Main category: cs.CV

TL;DR: 提出了一种基于生成输出分布距离的简约概念擦除方法，通过端到端优化和神经元掩码技术，在不影响模型性能的情况下实现安全生成。


<details>
  <summary>Details</summary>
Motivation: 生成模型依赖大规模无标签数据引发安全和版权问题，现有擦除方法过度修改模型影响实用性。

Method: 基于生成输出分布距离设计目标函数，利用反向传播端到端优化，引入神经元掩码增强鲁棒性。

Result: 在流匹配模型上验证，方法能有效擦除概念且不降低模型性能。

Conclusion: 为更安全、负责任的生成模型提供了可行方案。

Abstract: Recent advances in generative models have demonstrated remarkable
capabilities in producing high-quality images, but their reliance on
large-scale unlabeled data has raised significant safety and copyright
concerns. Efforts to address these issues by erasing unwanted concepts have
shown promise. However, many existing erasure methods involve excessive
modifications that compromise the overall utility of the model. In this work,
we address these issues by formulating a novel minimalist concept erasure
objective based \emph{only} on the distributional distance of final generation
outputs. Building on our formulation, we derive a tractable loss for
differentiable optimization that leverages backpropagation through all
generation steps in an end-to-end manner. We also conduct extensive analysis to
show theoretical connections with other models and methods. To improve the
robustness of the erasure, we incorporate neuron masking as an alternative to
model fine-tuning. Empirical evaluations on state-of-the-art flow-matching
models demonstrate that our method robustly erases concepts without degrading
overall model performance, paving the way for safer and more responsible
generative models.

</details>


### [78] [From Binary to Semantic: Utilizing Large-Scale Binary Occupancy Data for 3D Semantic Occupancy Prediction](https://arxiv.org/abs/2507.13387)
*Chihiro Noguchi,Takaki Yamamoto*

Main category: cs.CV

TL;DR: 论文提出了一种利用低成本二进制占用数据增强3D语义占用预测的框架，通过分解预测过程为二进制和语义模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 3D语义占用预测需要昂贵的LiDAR标注数据，而低成本的大规模二进制占用数据潜力未被充分挖掘。

Method: 提出一个框架，将预测过程分解为二进制占用和语义占用模块，利用二进制数据进行预训练和学习型自动标注。

Result: 实验表明，该框架在预训练和自动标注任务中均优于现有方法。

Conclusion: 该框架有效提升了3D语义占用预测的性能，展示了二进制占用数据的潜力。

Abstract: Accurate perception of the surrounding environment is essential for safe
autonomous driving. 3D occupancy prediction, which estimates detailed 3D
structures of roads, buildings, and other objects, is particularly important
for vision-centric autonomous driving systems that do not rely on LiDAR
sensors. However, in 3D semantic occupancy prediction -- where each voxel is
assigned a semantic label -- annotated LiDAR point clouds are required, making
data acquisition costly. In contrast, large-scale binary occupancy data, which
only indicate occupied or free space without semantic labels, can be collected
at a lower cost. Despite their availability, the potential of leveraging such
data remains unexplored. In this study, we investigate the utilization of
large-scale binary occupancy data from two perspectives: (1) pre-training and
(2) learning-based auto-labeling. We propose a novel binary occupancy-based
framework that decomposes the prediction process into binary and semantic
occupancy modules, enabling effective use of binary occupancy data. Our
experimental results demonstrate that the proposed framework outperforms
existing methods in both pre-training and auto-labeling tasks, highlighting its
effectiveness in enhancing 3D semantic occupancy prediction. The code is
available at https://github.com/ToyotaInfoTech/b2s-occupancy

</details>


### [79] [InSyn: Modeling Complex Interactions for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2507.13397)
*Kaiyuan Zhai,Juan Chen,Chao Wang,Zeyi Xu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的模型InSyn，用于行人轨迹预测，通过显式捕捉多样化的交互模式（如同步或冲突行走）和改进训练策略SSOS，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖相对位置建模行人交互，忽略了特定交互模式（如配对行走或冲突行为），导致在拥挤场景中预测准确性受限。

Method: 提出InSyn模型，基于Transformer显式捕捉多样化交互模式，并引入SSOS训练策略以减少初始步预测误差。

Result: 在ETH和UCY数据集上表现优于基线模型，尤其是在高密度场景中；SSOS策略将初始步预测误差降低约6.58%。

Conclusion: InSyn模型和SSOS策略有效提升了行人轨迹预测的准确性，特别是在复杂交互场景中。

Abstract: Accurate pedestrian trajectory prediction is crucial for intelligent
applications, yet it remains highly challenging due to the complexity of
interactions among pedestrians. Previous methods have primarily relied on
relative positions to model pedestrian interactions; however, they tend to
overlook specific interaction patterns such as paired walking or conflicting
behaviors, limiting the prediction accuracy in crowded scenarios. To address
this issue, we propose InSyn (Interaction-Synchronization Network), a novel
Transformer-based model that explicitly captures diverse interaction patterns
(e.g., walking in sync or conflicting) while effectively modeling
direction-sensitive social behaviors. Additionally, we introduce a training
strategy termed Seq-Start of Seq (SSOS), designed to alleviate the common issue
of initial-step divergence in numerical time-series prediction. Experiments on
the ETH and UCY datasets demonstrate that our model outperforms recent
baselines significantly, especially in high-density scenarios. Furthermore, the
SSOS strategy proves effective in improving sequential prediction performance,
reducing the initial-step prediction error by approximately 6.58%.

</details>


### [80] [MADI: Masking-Augmented Diffusion with Inference-Time Scaling for Visual Editing](https://arxiv.org/abs/2507.13401)
*Shreya Kadambi,Risheek Garrepalli,Shubhankar Borse,Munawar Hyatt,Fatih Porikli*

Main category: cs.CV

TL;DR: 论文提出MADI框架，通过MAgD训练策略和推理时容量扩展机制，显著提升扩散模型的可编辑性和可控性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成中表现优异，但在结构化控制和编辑方面仍有挑战。

Method: 提出MADI框架，包括MAgD训练策略（结合去噪和掩码重建）和推理时Pause Tokens机制。

Result: MADI显著提升了扩散模型的可编辑性和组合控制能力。

Conclusion: MADI为扩散模型在通用上下文生成架构中的应用铺平了道路。

Abstract: Despite the remarkable success of diffusion models in text-to-image
generation, their effectiveness in grounded visual editing and compositional
control remains challenging. Motivated by advances in self-supervised learning
and in-context generative modeling, we propose a series of simple yet powerful
design choices that significantly enhance diffusion model capacity for
structured, controllable generation and editing. We introduce Masking-Augmented
Diffusion with Inference-Time Scaling (MADI), a framework that improves the
editability, compositionality and controllability of diffusion models through
two core innovations. First, we introduce Masking-Augmented gaussian Diffusion
(MAgD), a novel training strategy with dual corruption process which combines
standard denoising score matching and masked reconstruction by masking noisy
input from forward process. MAgD encourages the model to learn discriminative
and compositional visual representations, thus enabling localized and
structure-aware editing. Second, we introduce an inference-time capacity
scaling mechanism based on Pause Tokens, which act as special placeholders
inserted into the prompt for increasing computational capacity at inference
time. Our findings show that adopting expressive and dense prompts during
training further enhances performance, particularly for MAgD. Together, these
contributions in MADI substantially enhance the editability of diffusion
models, paving the way toward their integration into more general-purpose,
in-context generative diffusion architectures.

</details>


### [81] [UL-DD: A Multimodal Drowsiness Dataset Using Video, Biometric Signals, and Behavioral Data](https://arxiv.org/abs/2507.13403)
*Morteza Bodaghi,Majid Hosseini,Raju Gottumukkala,Ravi Teja Bhupatiraju,Iftikhar Ahmad,Moncef Gabbouj*

Main category: cs.CV

TL;DR: 该研究提出了一个多模态的驾驶员 drowsiness 检测数据集，包含面部、行为和生物特征信号，数据来自19名受试者在清醒和 drowsy 状态下的40分钟连续记录。


<details>
  <summary>Details</summary>
Motivation: 现有数据集通常只关注离散的清醒/drowsy标签，缺乏连续状态变化的记录。本研究旨在填补这一空白，提供更全面的生理、行为和驾驶相关信号。

Method: 数据集整合了3D面部视频、IR摄像头、后视视频、生物特征信号（如心率、皮肤电活动等）以及方向盘握力传感器和模拟器数据。drowsiness水平通过KSS量表每4分钟自评。

Result: 数据集总时长为1,400分钟，记录了驾驶员状态的逐渐变化，而非离散标签。

Conclusion: 该数据集为驾驶员 drowsiness 检测研究提供了更全面的多模态数据支持，未来可通过请求获取。

Abstract: In this study, we present a comprehensive public dataset for driver
drowsiness detection, integrating multimodal signals of facial, behavioral, and
biometric indicators. Our dataset includes 3D facial video using a depth
camera, IR camera footage, posterior videos, and biometric signals such as
heart rate, electrodermal activity, blood oxygen saturation, skin temperature,
and accelerometer data. This data set provides grip sensor data from the
steering wheel and telemetry data from the American truck simulator game to
provide more information about drivers' behavior while they are alert and
drowsy. Drowsiness levels were self-reported every four minutes using the
Karolinska Sleepiness Scale (KSS). The simulation environment consists of three
monitor setups, and the driving condition is completely like a car. Data were
collected from 19 subjects (15 M, 4 F) in two conditions: when they were fully
alert and when they exhibited signs of sleepiness. Unlike other datasets, our
multimodal dataset has a continuous duration of 40 minutes for each data
collection session per subject, contributing to a total length of 1,400
minutes, and we recorded gradual changes in the driver state rather than
discrete alert/drowsy labels. This study aims to create a comprehensive
multimodal dataset of driver drowsiness that captures a wider range of
physiological, behavioral, and driving-related signals. The dataset will be
available upon request to the corresponding author.

</details>


### [82] [AortaDiff: Volume-Guided Conditional Diffusion Models for Multi-Branch Aortic Surface Generation](https://arxiv.org/abs/2507.13404)
*Delin An,Pan Du,Jian-Xun Wang,Chaoli Wang*

Main category: cs.CV

TL;DR: AortaDiff是一种基于扩散的框架，直接从CT/MRI体积生成平滑的主动脉表面，解决了现有方法依赖大数据集和手动干预的问题，适用于CFD分析。


<details>
  <summary>Details</summary>
Motivation: 准确的3D主动脉构建对临床诊断和CFD模拟至关重要，但现有方法依赖大数据集和手动干预，难以生成几何一致的表面。

Method: AortaDiff采用体积引导的条件扩散模型生成主动脉中心线，并自动提取血管轮廓，最终拟合为平滑的3D表面。

Result: 实验表明，AortaDiff在有限训练数据下仍能有效构建正常和病理主动脉网格，几何保真度高。

Conclusion: AortaDiff为心血管研究提供了一种端到端的实用解决方案，能生成高质量的CFD兼容网格。

Abstract: Accurate 3D aortic construction is crucial for clinical diagnosis,
preoperative planning, and computational fluid dynamics (CFD) simulations, as
it enables the estimation of critical hemodynamic parameters such as blood flow
velocity, pressure distribution, and wall shear stress. Existing construction
methods often rely on large annotated training datasets and extensive manual
intervention. While the resulting meshes can serve for visualization purposes,
they struggle to produce geometrically consistent, well-constructed surfaces
suitable for downstream CFD analysis. To address these challenges, we introduce
AortaDiff, a diffusion-based framework that generates smooth aortic surfaces
directly from CT/MRI volumes. AortaDiff first employs a volume-guided
conditional diffusion model (CDM) to iteratively generate aortic centerlines
conditioned on volumetric medical images. Each centerline point is then
automatically used as a prompt to extract the corresponding vessel contour,
ensuring accurate boundary delineation. Finally, the extracted contours are
fitted into a smooth 3D surface, yielding a continuous, CFD-compatible mesh
representation. AortaDiff offers distinct advantages over existing methods,
including an end-to-end workflow, minimal dependency on large labeled datasets,
and the ability to generate CFD-compatible aorta meshes with high geometric
fidelity. Experimental results demonstrate that AortaDiff performs effectively
even with limited training data, successfully constructing both normal and
pathologically altered aorta meshes, including cases with aneurysms or
coarctation. This capability enables the generation of high-quality
visualizations and positions AortaDiff as a practical solution for
cardiovascular research.

</details>


### [83] [COREVQA: A Crowd Observation and Reasoning Entailment Visual Question Answering Benchmark](https://arxiv.org/abs/2507.13405)
*Ishant Chintapatla,Kazuma Choji,Naaisha Agarwal,Andrew Lin,Hannah You,Charles Duong,Kevin Zhu,Sean O'Brien,Vasu Sharma*

Main category: cs.CV

TL;DR: COREVQA是一个新的视觉蕴含基准测试，用于评估视觉语言模型在拥挤场景中的推理能力，结果显示当前模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试很少评估视觉语言模型在视觉蕴含任务（如基于图像接受或反驳假设）中的能力，尤其是在拥挤场景中。

Method: 提出COREVQA基准，包含5608张图像和合成的真假陈述对，图像来自CrowdHuman数据集。

Result: 即使表现最好的视觉语言模型准确率低于80%，其他模型表现更差（39.98%-69.95%）。

Conclusion: 当前视觉语言模型在拥挤场景的视觉蕴含推理能力存在显著不足。

Abstract: Recently, many benchmarks and datasets have been developed to evaluate
Vision-Language Models (VLMs) using visual question answering (VQA) pairs, and
models have shown significant accuracy improvements. However, these benchmarks
rarely test the model's ability to accurately complete visual entailment, for
instance, accepting or refuting a hypothesis based on the image. To address
this, we propose COREVQA (Crowd Observations and Reasoning Entailment), a
benchmark of 5608 image and synthetically generated true/false statement pairs,
with images derived from the CrowdHuman dataset, to provoke visual entailment
reasoning on challenging crowded images. Our results show that even the
top-performing VLMs achieve accuracy below 80%, with other models performing
substantially worse (39.98%-69.95%). This significant performance gap reveals
key limitations in VLMs' ability to reason over certain types of image-question
pairs in crowded scenes.

</details>


### [84] [IConMark: Robust Interpretable Concept-Based Watermark For AI Images](https://arxiv.org/abs/2507.13407)
*Vinu Sankar Sadasivan,Mehrdad Saberi,Soheil Feizi*

Main category: cs.CV

TL;DR: IConMark是一种新型的语义水印方法，通过嵌入可解释的概念到AI生成的图像中，提高对抗攻击的鲁棒性和人工可读性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI和合成媒体的快速发展，区分AI生成图像与真实图像对防止虚假信息和确保数字真实性至关重要。传统水印技术易受对抗攻击，效果不佳。

Method: IConMark在生成过程中嵌入有意义的语义属性，而非传统噪声或扰动，使其可解释且抗对抗攻击。还结合了StegaStamp和TrustMark形成混合方法（IConMark+SS和IConMark+TM）。

Result: IConMark及其变体在检测准确性和图像质量上表现优越，AUROC分数分别比最佳基线高10.8%、14.5%和15.9%。

Conclusion: IConMark为可解释水印技术提供了新方向，结合现有方法可进一步增强鲁棒性。

Abstract: With the rapid rise of generative AI and synthetic media, distinguishing
AI-generated images from real ones has become crucial in safeguarding against
misinformation and ensuring digital authenticity. Traditional watermarking
techniques have shown vulnerabilities to adversarial attacks, undermining their
effectiveness in the presence of attackers. We propose IConMark, a novel
in-generation robust semantic watermarking method that embeds interpretable
concepts into AI-generated images, as a first step toward interpretable
watermarking. Unlike traditional methods, which rely on adding noise or
perturbations to AI-generated images, IConMark incorporates meaningful semantic
attributes, making it interpretable to humans and hence, resilient to
adversarial manipulation. This method is not only robust against various image
augmentations but also human-readable, enabling manual verification of
watermarks. We demonstrate a detailed evaluation of IConMark's effectiveness,
demonstrating its superiority in terms of detection accuracy and maintaining
image quality. Moreover, IConMark can be combined with existing watermarking
techniques to further enhance and complement its robustness. We introduce
IConMark+SS and IConMark+TM, hybrid approaches combining IConMark with
StegaStamp and TrustMark, respectively, to further bolster robustness against
multiple types of image manipulations. Our base watermarking technique
(IConMark) and its variants (+TM and +SS) achieve 10.8%, 14.5%, and 15.9%
higher mean area under the receiver operating characteristic curve (AUROC)
scores for watermark detection, respectively, compared to the best baseline on
various datasets.

</details>


### [85] [A Deep Learning-Based Ensemble System for Automated Shoulder Fracture Detection in Clinical Radiographs](https://arxiv.org/abs/2507.13408)
*Hemanth Kumar M,Karthika M,Saianiruth M,Vasanthakumar Venugopal,Anandakumar D,Revathi Ezhumalai,Charulatha K,Kishore Kumar J,Dayana G,Kalyan Sivasailam,Bargava Subramanian*

Main category: cs.CV

TL;DR: AI多模型深度学习系统在肩部X光片中高效检测骨折，准确率达95.5%，适用于临床快速筛查。


<details>
  <summary>Details</summary>
Motivation: 解决肩部骨折在急诊和高负荷临床环境中漏诊率高的问题，利用AI工具提升早期检测能力。

Method: 开发基于10,000张标注肩部X光片的多模型深度学习系统，采用Faster R-CNN、EfficientDet和RF-DETR架构，结合Soft-NMS、WBF和NMW融合技术优化检测。

Result: NMW融合模型表现最佳，准确率95.5%，F1分数0.9610，召回率和定位精度均优异。

Conclusion: 基于融合的AI系统能可靠检测肩部骨折，适合实时诊断流程，但仅支持二元骨折检测，适用于快速筛查而非详细分类。

Abstract: Background: Shoulder fractures are often underdiagnosed, especially in
emergency and high-volume clinical settings. Studies report up to 10% of such
fractures may be missed by radiologists. AI-driven tools offer a scalable way
to assist early detection and reduce diagnostic delays. We address this gap
through a dedicated AI system for shoulder radiographs. Methods: We developed a
multi-model deep learning system using 10,000 annotated shoulder X-rays.
Architectures include Faster R-CNN (ResNet50-FPN, ResNeXt), EfficientDet, and
RF-DETR. To enhance detection, we applied bounding box and classification-level
ensemble techniques such as Soft-NMS, WBF, and NMW fusion. Results: The NMW
ensemble achieved 95.5% accuracy and an F1-score of 0.9610, outperforming
individual models across all key metrics. It demonstrated strong recall and
localization precision, confirming its effectiveness for clinical fracture
detection in shoulder X-rays. Conclusion: The results show ensemble-based AI
can reliably detect shoulder fractures in radiographs with high clinical
relevance. The model's accuracy and deployment readiness position it well for
integration into real-time diagnostic workflows. The current model is limited
to binary fracture detection, reflecting its design for rapid screening and
triage support rather than detailed orthopedic classification.

</details>


### [86] [AI-ming backwards: Vanishing archaeological landscapes in Mesopotamia and automatic detection of sites on CORONA imagery](https://arxiv.org/abs/2507.13420)
*Alessandro Pistola,Valentina Orru',Nicolo' Marchetti,Marco Roccetti*

Main category: cs.CV

TL;DR: 通过结合古老的CORONA卫星影像升级深度学习模型，显著提升了考古遗址自动识别的精度，并发现了四个新遗址。


<details>
  <summary>Details</summary>
Motivation: 利用CORONA影像弥补现代环境变化对考古遗址的破坏，探索AI在考古学中的潜力。

Method: 基于Bing的卷积网络模型，使用CORONA影像对伊拉克阿布格莱布地区进行重新训练。

Result: 检测精度显著提升（IoU超过85%，总体准确率90%），并发现四个新遗址。

Conclusion: AI结合历史影像为考古遗址研究提供了突破性工具，尤其在遗址消失的环境中。

Abstract: By upgrading an existing deep learning model with the knowledge provided by
one of the oldest sets of grayscale satellite imagery, known as CORONA, we
improved the AI model attitude towards the automatic identification of
archaeological sites in an environment which has been completely transformed in
the last five decades, including the complete destruction of many of those same
sites. The initial Bing based convolutional network model was retrained using
CORONA satellite imagery for the district of Abu Ghraib, west of Baghdad,
central Mesopotamian floodplain. The results were twofold and surprising.
First, the detection precision obtained on the area of interest increased
sensibly: in particular, the Intersection over Union (IoU) values, at the image
segmentation level, surpassed 85 percent, while the general accuracy in
detecting archeological sites reached 90 percent. Second, our retrained model
allowed the identification of four new sites of archaeological interest
(confirmed through field verification), previously not identified by
archaeologists with traditional techniques. This has confirmed the efficacy of
using AI techniques and the CORONA imagery from the 1960 to discover
archaeological sites currently no longer visible, a concrete breakthrough with
significant consequences for the study of landscapes with vanishing
archaeological evidence induced by anthropization

</details>


### [87] [CaSTFormer: Causal Spatio-Temporal Transformer for Driving Intention Prediction](https://arxiv.org/abs/2507.13425)
*Sirui Wang,Zhou Guan,Bingxi Zhao,Tongjia Gu*

Main category: cs.CV

TL;DR: CaSTFormer是一种新型的因果时空Transformer模型，用于准确预测驾驶意图，通过消除虚假相关性并建模真实因果关系，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 准确预测驾驶意图对提升人机共驾系统的安全性和交互效率至关重要，但目前方法难以建模复杂的时空依赖性和人类驾驶行为的多变性。

Method: CaSTFormer引入RSF机制实现特征流的时间对齐，CPE模块消除虚假相关性，FSN网络合成纯净特征生成时空推理。

Result: 在Brain4Cars数据集上，CaSTFormer实现了最先进的性能，有效捕捉复杂因果时空依赖。

Conclusion: CaSTFormer显著提升了驾驶意图预测的准确性和透明度，为高级自动驾驶提供了可靠支持。

Abstract: Accurate prediction of driving intention is key to enhancing the safety and
interactive efficiency of human-machine co-driving systems. It serves as a
cornerstone for achieving high-level autonomous driving. However, current
approaches remain inadequate for accurately modeling the complex
spatio-temporal interdependencies and the unpredictable variability of human
driving behavior. To address these challenges, we propose CaSTFormer, a Causal
Spatio-Temporal Transformer to explicitly model causal interactions between
driver behavior and environmental context for robust intention prediction.
Specifically, CaSTFormer introduces a novel Reciprocal Shift Fusion (RSF)
mechanism for precise temporal alignment of internal and external feature
streams, a Causal Pattern Extraction (CPE) module that systematically
eliminates spurious correlations to reveal authentic causal dependencies, and
an innovative Feature Synthesis Network (FSN) that adaptively synthesizes these
purified representations into coherent spatio-temporal inferences. We evaluate
the proposed CaSTFormer on the public Brain4Cars dataset, and it achieves
state-of-the-art performance. It effectively captures complex causal
spatio-temporal dependencies and enhances both the accuracy and transparency of
driving intention prediction.

</details>


### [88] ["PhyWorldBench": A Comprehensive Evaluation of Physical Realism in Text-to-Video Models](https://arxiv.org/abs/2507.13428)
*Jing Gu,Xian Liu,Yu Zeng,Ashwin Nagarajan,Fangrui Zhu,Daniel Hong,Yue Fan,Qianqi Yan,Kaiwen Zhou,Ming-Yu Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: PhyWorldBench是一个评估视频生成模型物理模拟能力的基准，涵盖从基础物理现象到复杂场景，并引入反物理类别。通过人类评估和MLLM方法，对12种先进模型进行了测试与分析。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在物理现象模拟方面存在不足，需系统评估其物理一致性。

Method: 设计PhyWorldBench基准，包含多级物理现象和反物理类别，结合人类评估和MLLM方法。

Result: 测试12种模型，发现其在物理一致性上的关键挑战，并提出改进建议。

Conclusion: PhyWorldBench为提升视频生成模型的物理模拟能力提供了系统评估工具和优化方向。

Abstract: Video generation models have achieved remarkable progress in creating
high-quality, photorealistic content. However, their ability to accurately
simulate physical phenomena remains a critical and unresolved challenge. This
paper presents PhyWorldBench, a comprehensive benchmark designed to evaluate
video generation models based on their adherence to the laws of physics. The
benchmark covers multiple levels of physical phenomena, ranging from
fundamental principles like object motion and energy conservation to more
complex scenarios involving rigid body interactions and human or animal motion.
Additionally, we introduce a novel ""Anti-Physics"" category, where prompts
intentionally violate real-world physics, enabling the assessment of whether
models can follow such instructions while maintaining logical consistency.
Besides large-scale human evaluation, we also design a simple yet effective
method that could utilize current MLLM to evaluate the physics realism in a
zero-shot fashion. We evaluate 12 state-of-the-art text-to-video generation
models, including five open-source and five proprietary models, with a detailed
comparison and analysis. we identify pivotal challenges models face in adhering
to real-world physics. Through systematic testing of their outputs across 1,050
curated prompts-spanning fundamental, composite, and anti-physics scenarios-we
identify pivotal challenges these models face in adhering to real-world
physics. We then rigorously examine their performance on diverse physical
phenomena with varying prompt types, deriving targeted recommendations for
crafting prompts that enhance fidelity to physical principles.

</details>


### [89] [Uncertainty Quantification Framework for Aerial and UAV Photogrammetry through Error Propagation](https://arxiv.org/abs/2507.13486)
*Debao Huang,Rongjun Qin*

Main category: cs.CV

TL;DR: 本文提出了一种用于摄影测量点云不确定性量化的框架，填补了多视角立体（MVS）阶段不确定性估计的空白。


<details>
  <summary>Details</summary>
Motivation: 摄影测量点云的精度高度依赖场景，且MVS阶段的不确定性估计尚未标准化，本文旨在解决这一问题。

Method: 通过结合SfM和MVS阶段，提出了一种自校准方法，利用可靠的多视角点回归视差不确定性。

Result: 在多种公开数据集上验证，该方法优于现有方法，实现了高边界率且未高估不确定性。

Conclusion: 该框架为摄影测量过程提供了鲁棒且可验证的不确定性量化，适用于多样化场景。

Abstract: Uncertainty quantification of the photogrammetry process is essential for
providing per-point accuracy credentials of the point clouds. Unlike airborne
LiDAR, which typically delivers consistent accuracy across various scenes, the
accuracy of photogrammetric point clouds is highly scene-dependent, since it
relies on algorithm-generated measurements (i.e., stereo or multi-view stereo).
Generally, errors of the photogrammetric point clouds propagate through a
two-step process: Structure-from-Motion (SfM) with Bundle adjustment (BA),
followed by Multi-view Stereo (MVS). While uncertainty estimation in the SfM
stage has been well studied using the first-order statistics of the
reprojection error function, that in the MVS stage remains largely unsolved and
non-standardized, primarily due to its non-differentiable and multi-modal
nature (i.e., from pixel values to geometry). In this paper, we present an
uncertainty quantification framework closing this gap by associating an error
covariance matrix per point accounting for this two-step photogrammetry
process. Specifically, to estimate the uncertainty in the MVS stage, we propose
a novel, self-calibrating method by taking reliable n-view points (n>=6)
per-view to regress the disparity uncertainty using highly relevant cues (such
as matching cost values) from the MVS stage. Compared to existing approaches,
our method uses self-contained, reliable 3D points extracted directly from the
MVS process, with the benefit of being self-supervised and naturally adhering
to error propagation path of the photogrammetry process, thereby providing a
robust and certifiable uncertainty quantification across diverse scenes. We
evaluate the framework using a variety of publicly available airborne and UAV
imagery datasets. Results demonstrate that our method outperforms existing
approaches by achieving high bounding rates without overestimating uncertainty.

</details>


### [90] [Sugar-Beet Stress Detection using Satellite Image Time Series](https://arxiv.org/abs/2507.13514)
*Bhumika Laxman Sadbhave,Philipp Vaeth,Denise Dejon,Gunther Schorcht,Magda Gregorová*

Main category: cs.CV

TL;DR: 利用3D卷积自编码器和时间编码的无监督方法检测甜菜田的胁迫状态。


<details>
  <summary>Details</summary>
Motivation: 卫星图像时间序列（SITS）数据因其丰富的频谱和时间特性，适用于农业任务。本研究旨在开发一种无监督方法，用于甜菜田的胁迫检测。

Method: 提出一种3D卷积自编码器模型，结合Sentinel-2图像序列和时间编码，提取特征并用于下游聚类任务。

Result: 系统能够区分胁迫与健康田块，并适用于不同年份的数据。

Conclusion: 该方法为甜菜田胁迫检测提供了一种实用且可扩展的工具。

Abstract: Satellite Image Time Series (SITS) data has proven effective for agricultural
tasks due to its rich spectral and temporal nature. In this study, we tackle
the task of stress detection in sugar-beet fields using a fully unsupervised
approach. We propose a 3D convolutional autoencoder model to extract meaningful
features from Sentinel-2 image sequences, combined with
acquisition-date-specific temporal encodings to better capture the growth
dynamics of sugar-beets. The learned representations are used in a downstream
clustering task to separate stressed from healthy fields. The resulting stress
detection system can be directly applied to data from different years, offering
a practical and accessible tool for stress detection in sugar-beets.

</details>


### [91] [SparseC-AFM: a deep learning method for fast and accurate characterization of MoS$_2$ with C-AFM](https://arxiv.org/abs/2507.13527)
*Levi Harris,Md Jayed Hossain,Mufan Qiu,Ruichen Zhang,Pingchuan Ma,Tianlong Chen,Jiaqi Gu,Seth Ariel Tongay,Umberto Celano*

Main category: cs.CV

TL;DR: SparseC-AFM是一种深度学习模型，通过稀疏C-AFM扫描快速重建2D材料的导电性图，显著减少数据采集时间。


<details>
  <summary>Details</summary>
Motivation: 传统C-AFM技术虽精确但速度慢，无法满足大规模生产需求。

Method: 提出SparseC-AFM模型，利用稀疏扫描数据快速重建高分辨率导电性图。

Result: 相比传统方法，采集时间减少11倍，且结果与高分辨率数据一致。

Conclusion: SparseC-AFM为AI辅助2D材料表征从实验室到工业应用迈出重要一步。

Abstract: The increasing use of two-dimensional (2D) materials in nanoelectronics
demands robust metrology techniques for electrical characterization, especially
for large-scale production. While atomic force microscopy (AFM) techniques like
conductive AFM (C-AFM) offer high accuracy, they suffer from slow data
acquisition speeds due to the raster scanning process. To address this, we
introduce SparseC-AFM, a deep learning model that rapidly and accurately
reconstructs conductivity maps of 2D materials like MoS$_2$ from sparse C-AFM
scans. Our approach is robust across various scanning modes, substrates, and
experimental conditions. We report a comparison between (a) classic flow
implementation, where a high pixel density C-AFM image (e.g., 15 minutes to
collect) is manually parsed to extract relevant material parameters, and (b)
our SparseC-AFM method, which achieves the same operation using data that
requires substantially less acquisition time (e.g., under 5 minutes).
SparseC-AFM enables efficient extraction of critical material parameters in
MoS$_2$, including film coverage, defect density, and identification of
crystalline island boundaries, edges, and cracks. We achieve over 11x reduction
in acquisition time compared to manual extraction from a full-resolution C-AFM
image. Moreover, we demonstrate that our model-predicted samples exhibit
remarkably similar electrical properties to full-resolution data gathered using
classic-flow scanning. This work represents a significant step toward
translating AI-assisted 2D material characterization from laboratory research
to industrial fabrication. Code and model weights are available at
github.com/UNITES-Lab/sparse-cafm.

</details>


### [92] [Total Generalized Variation of the Normal Vector Field and Applications to Mesh Denoising](https://arxiv.org/abs/2507.13530)
*Lukas Baumgärtner,Ronny Bergmann,Roland Herzog,Stephan Schmidt,Manuel Weiß*

Main category: cs.CV

TL;DR: 提出了一种新的二阶总广义变分（TGV）公式，用于处理嵌入三维空间的三角网格上的法向量，并将其与现有方法进行比较。


<details>
  <summary>Details</summary>
Motivation: 扩展离散TGV模型以处理流形值数据，特别是单位球面上的法向量。

Method: 构建了一个定制的切向Raviart-Thomas型有限元空间，以适应流形设置。

Result: 新正则化器在网格去噪实验中与现有方法进行了比较。

Conclusion: 新方法为处理流形值数据提供了一种有效的正则化工具。

Abstract: We propose a novel formulation for the second-order total generalized
variation (TGV) of the normal vector on an oriented, triangular mesh embedded
in $\mathbb{R}^3$. The normal vector is considered as a manifold-valued
function, taking values on the unit sphere. Our formulation extends previous
discrete TGV models for piecewise constant scalar data that utilize a
Raviart-Thomas function space. To exctend this formulation to the manifold
setting, a tailor-made tangential Raviart-Thomas type finite element space is
constructed in this work. The new regularizer is compared to existing methods
in mesh denoising experiments.

</details>


### [93] [$\nabla$NABLA: Neighborhood Adaptive Block-Level Attention](https://arxiv.org/abs/2507.13546)
*Dmitrii Mikhailov,Aleksey Letunovskiy,Maria Kovaleva,Vladimir Arkhipkin,Vladimir Korviakov,Vladimir Polovnikov,Viacheslav Vasilev,Evelina Sidorova,Denis Dimitrov*

Main category: cs.CV

TL;DR: 论文提出NABLA，一种新型的邻域自适应块级注意力机制，用于解决视频生成任务中全注意力机制的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 全注意力机制在视频生成任务中计算复杂度高，尤其是高分辨率和长视频序列。

Method: 提出NABLA，通过块级注意力和自适应稀疏阈值动态适应稀疏模式，降低计算开销。

Result: 实验显示NABLA训练和推理速度提升2.7倍，且生成质量几乎无损。

Conclusion: NABLA是一种高效且无需定制低层操作的方法，可无缝集成到现有框架中。

Abstract: Recent progress in transformer-based architectures has demonstrated
remarkable success in video generation tasks. However, the quadratic complexity
of full attention mechanisms remains a critical bottleneck, particularly for
high-resolution and long-duration video sequences. In this paper, we propose
NABLA, a novel Neighborhood Adaptive Block-Level Attention mechanism that
dynamically adapts to sparsity patterns in video diffusion transformers (DiTs).
By leveraging block-wise attention with adaptive sparsity-driven threshold,
NABLA reduces computational overhead while preserving generative quality. Our
method does not require custom low-level operator design and can be seamlessly
integrated with PyTorch's Flex Attention operator. Experiments demonstrate that
NABLA achieves up to 2.7x faster training and inference compared to baseline
almost without compromising quantitative metrics (CLIP score, VBench score,
human evaluation score) and visual quality drop. The code and model weights are
available here: https://github.com/gen-ai-team/Wan2.1-NABLA

</details>


### [94] [LoRA-Loop: Closing the Synthetic Replay Cycle for Continual VLM Learning](https://arxiv.org/abs/2507.13568)
*Kaihong Wang,Donghyun Kim,Margrit Betke*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA增强的合成重放框架，通过任务特定的低秩适配器改进生成样本的保真度，提升持续学习性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成重放方法生成的样本可能因未捕捉领域细节而误导微调，导致先验知识丢失。

Method: 引入LoRA适配器增强Stable Diffusion模型，并通过两阶段置信度样本选择优化生成和蒸馏过程。

Result: 在MTIL基准测试中表现优于现有方法，平衡了可塑性、稳定性和零样本能力。

Conclusion: LoRA适配器能有效提升生成样本的保真度，支持视觉语言模型的鲁棒持续学习。

Abstract: Continual learning for vision-language models has achieved remarkable
performance through synthetic replay, where samples are generated using Stable
Diffusion to regularize during finetuning and retain knowledge. However,
real-world downstream applications often exhibit domain-specific nuances and
fine-grained semantics not captured by generators, causing synthetic-replay
methods to produce misaligned samples that misguide finetuning and undermine
retention of prior knowledge. In this work, we propose a LoRA-enhanced
synthetic-replay framework that injects task-specific low-rank adapters into a
frozen Stable Diffusion model, efficiently capturing each new task's unique
visual and semantic patterns. Specifically, we introduce a two-stage,
confidence-based sample selection: we first rank real task data by
post-finetuning VLM confidence to focus LoRA finetuning on the most
representative examples, then generate synthetic samples and again select them
by confidence for distillation. Our approach integrates seamlessly with
existing replay pipelines-simply swap in the adapted generator to boost replay
fidelity. Extensive experiments on the Multi-domain Task Incremental Learning
(MTIL) benchmark show that our method outperforms previous synthetic-replay
techniques, achieving an optimal balance among plasticity, stability, and
zero-shot capability. These results demonstrate the effectiveness of generator
adaptation via LoRA for robust continual learning in VLMs.

</details>


### [95] [NoiseSDF2NoiseSDF: Learning Clean Neural Fields from Noisy Supervision](https://arxiv.org/abs/2507.13595)
*Tengkai Wang,Weihao Li,Ruikai Cui,Shi Qiu,Nick Barnes*

Main category: cs.CV

TL;DR: 论文提出了一种名为NoiseSDF2NoiseSDF的新方法，通过从噪声点云中学习干净的神经SDF，以改进3D表面重建质量。


<details>
  <summary>Details</summary>
Motivation: 低质量扫描设备捕获的点云通常包含大量噪声，导致表面重建不准确，因此需要一种有效的方法来处理这一问题。

Method: 受Noise2Noise范式的启发，该方法通过最小化噪声SDF表示之间的MSE损失，直接从噪声点云中学习干净的神经SDF。

Result: 在ShapeNet、ABC、Famous和Real等基准数据集上的实验表明，该方法显著提高了从噪声输入中重建表面的质量。

Conclusion: NoiseSDF2NoiseSDF是一种有效的3D神经场去噪方法，能够显著提升表面重建的准确性。

Abstract: Reconstructing accurate implicit surface representations from point clouds
remains a challenging task, particularly when data is captured using
low-quality scanning devices. These point clouds often contain substantial
noise, leading to inaccurate surface reconstructions. Inspired by the
Noise2Noise paradigm for 2D images, we introduce NoiseSDF2NoiseSDF, a novel
method designed to extend this concept to 3D neural fields. Our approach
enables learning clean neural SDFs directly from noisy point clouds through
noisy supervision by minimizing the MSE loss between noisy SDF representations,
allowing the network to implicitly denoise and refine surface estimations. We
evaluate the effectiveness of NoiseSDF2NoiseSDF on benchmarks, including the
ShapeNet, ABC, Famous, and Real datasets. Experimental results demonstrate that
our framework significantly improves surface reconstruction quality from noisy
inputs.

</details>


### [96] [Learning Deblurring Texture Prior from Unpaired Data with Diffusion Model](https://arxiv.org/abs/2507.13599)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的框架（\ours），通过从非配对数据中学习空间变化的纹理先验，实现图像去模糊。


<details>
  <summary>Details</summary>
Motivation: 由于获取大量真实的模糊-清晰图像对困难且昂贵，从非配对数据中学习盲图像去模糊更具实用性和前景。现有方法依赖对抗学习，忽略了真实世界模糊模式的复杂性。

Method: 提出Texture Prior Encoder（TPE）和Texture Transfer Transformer层（TTformer），利用扩散模型生成纹理先验，并通过自适应滤波去除空间变化的模糊。

Result: 在广泛使用的基准测试中，\ours表现优于现有最先进方法。

Conclusion: \ours为无监督去模糊提供了一种有前景的解决方案。

Abstract: Since acquiring large amounts of realistic blurry-sharp image pairs is
difficult and expensive, learning blind image deblurring from unpaired data is
a more practical and promising solution. Unfortunately, dominant approaches
rely heavily on adversarial learning to bridge the gap from blurry domains to
sharp domains, ignoring the complex and unpredictable nature of real-world blur
patterns. In this paper, we propose a novel diffusion model (DM)-based
framework, dubbed \ours, for image deblurring by learning spatially varying
texture prior from unpaired data. In particular, \ours performs DM to generate
the prior knowledge that aids in recovering the textures of blurry images. To
implement this, we propose a Texture Prior Encoder (TPE) that introduces a
memory mechanism to represent the image textures and provides supervision for
DM training. To fully exploit the generated texture priors, we present the
Texture Transfer Transformer layer (TTformer), in which a novel
Filter-Modulated Multi-head Self-Attention (FM-MSA) efficiently removes
spatially varying blurring through adaptive filtering. Furthermore, we
implement a wavelet-based adversarial loss to preserve high-frequency texture
details. Extensive evaluations show that \ours provides a promising
unsupervised deblurring solution and outperforms SOTA methods in widely-used
benchmarks.

</details>


### [97] [Efficient Burst Super-Resolution with One-step Diffusion](https://arxiv.org/abs/2507.13607)
*Kento Kawai,Takeru Oba,Kyotaro Tokoro,Kazutoshi Akita,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的随机采样方法，用于从低分辨率（LR）图像中生成高保真的超分辨率（SR）图像，显著减少了运行时间。


<details>
  <summary>Details</summary>
Motivation: 现有的确定性方法生成的SR图像模糊且感知质量差，本文旨在通过扩散模型生成清晰且高保真的SR图像。

Method: 采用随机采样器结合高阶ODE，以及通过知识蒸馏实现一步扩散，提高了扩散模型的效率。

Result: 实验结果显示，该方法将运行时间减少至基线的1.6%，同时保持基于图像失真和感知质量的SR质量。

Conclusion: 该方法在提升SR图像质量的同时显著提高了计算效率。

Abstract: While burst Low-Resolution (LR) images are useful for improving their Super
Resolution (SR) image compared to a single LR image, prior burst SR methods are
trained in a deterministic manner, which produces a blurry SR image. Since such
blurry images are perceptually degraded, we aim to reconstruct sharp and
high-fidelity SR images by a diffusion model. Our method improves the
efficiency of the diffusion model with a stochastic sampler with a high-order
ODE as well as one-step diffusion using knowledge distillation. Our
experimental results demonstrate that our method can reduce the runtime to 1.6
% of its baseline while maintaining the SR quality measured based on image
distortion and perceptual quality.

</details>


### [98] [CoTasks: Chain-of-Thought based Video Instruction Tuning Tasks](https://arxiv.org/abs/2507.13609)
*Yanan Wang,Julio Vizcarra,Zhi Li,Hao Niu,Mori Kurokawa*

Main category: cs.CV

TL;DR: CoTasks框架通过分解复杂视频问题为四个实体级基础任务，显著提升了视频大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型缺乏细粒度对象级理解和链式推理能力，限制了其视频理解性能。

Method: 提出CoTasks框架，将复杂视频问题分解为帧定位、实体跟踪、时空关系提取等四个基础任务，并嵌入中间推理步骤。

Result: 在NeXT-QA基准测试中，LLaVA-video-7B和Qwen2.5-VL-3B模型推理性能显著提升，部分子类别提升高达48.1分。

Conclusion: CoTasks作为一种结构化监督框架，有效提升了视频模型的组合推理能力。

Abstract: Despite recent progress in video large language models (VideoLLMs), a key
open challenge remains: how to equip models with chain-of-thought (CoT)
reasoning abilities grounded in fine-grained object-level video understanding.
Existing instruction-tuned models, such as the Qwen and LLaVA series, are
trained on high-level video-text pairs, often lacking structured annotations
necessary for compositional, step-by-step reasoning. We propose CoTasks:
Chain-of-Thought based Video Instruction Tuning Tasks, a new framework that
decomposes complex video questions of existing datasets (e.g., NeXT-QA, STAR)
into four entity-level foundational tasks: frame localization, entity tracking,
spatial and temporal relation extraction. By embedding these intermediate
CoT-style reasoning steps into the input, CoTasks enables models to explicitly
perform object-centric spatiotemporal reasoning. Experiments on the NeXT-QA
benchmark show that CoTasks significantly enhance inference performance:
LLaVA-video-7B improves by +3.3 points in average GPT-4 evaluation score, and
Qwen2.5-VL-3B gains +17.4, with large boosts in causal (+14.6), temporal
(+10.9), and descriptive (+48.1) subcategories. These results demonstrate the
effectiveness of CoTasks as a structured CoT-style supervision framework for
improving compositional video reasoning.

</details>


### [99] [Moving Object Detection from Moving Camera Using Focus of Expansion Likelihood and Segmentation](https://arxiv.org/abs/2507.13628)
*Masahiro Ogawa,Qi An,Atsushi Yamashita*

Main category: cs.CV

TL;DR: FoELS方法通过结合光流和纹理信息，有效分离动态与静态物体，适用于复杂场景和相机运动。


<details>
  <summary>Details</summary>
Motivation: 从移动相机视角分离动态与静态物体对3D重建、自主导航和场景理解至关重要，现有方法主要依赖光流，但在复杂场景中效果有限。

Method: 提出FoELS方法，通过计算扩展焦点（FoE）并融合光流异常值与分割先验，估计动态概率。

Result: 在DAVIS 2016数据集和真实交通视频中表现优异，达到先进水平。

Conclusion: FoELS能有效处理复杂场景、旋转相机运动和平行运动，性能优越。

Abstract: Separating moving and static objects from a moving camera viewpoint is
essential for 3D reconstruction, autonomous navigation, and scene understanding
in robotics. Existing approaches often rely primarily on optical flow, which
struggles to detect moving objects in complex, structured scenes involving
camera motion. To address this limitation, we propose Focus of Expansion
Likelihood and Segmentation (FoELS), a method based on the core idea of
integrating both optical flow and texture information. FoELS computes the focus
of expansion (FoE) from optical flow and derives an initial motion likelihood
from the outliers of the FoE computation. This likelihood is then fused with a
segmentation-based prior to estimate the final moving probability. The method
effectively handles challenges including complex structured scenes, rotational
camera motion, and parallel motion. Comprehensive evaluations on the DAVIS 2016
dataset and real-world traffic videos demonstrate its effectiveness and
state-of-the-art performance.

</details>


### [100] [EPSilon: Efficient Point Sampling for Lightening of Hybrid-based 3D Avatar Generation](https://arxiv.org/abs/2507.13648)
*Seungjun Moon,Sangjoon Yu,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: EPSilon提出了一种高效的混合3D头像生成方法，通过空射线和空区间省略策略显著减少计算成本，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有混合表示方法（结合NeRF和SMPL网格）因变形计算成本高导致推理速度慢，EPSilon旨在解决这一问题。

Method: 提出两种空点采样策略：空射线省略（ERO）和空区间省略（EIO），以减少无效采样点。

Result: EPSilon仅需3.9%的采样点，推理速度提升20倍，训练收敛速度提升4倍，同时保持生成质量。

Conclusion: EPSilon通过高效采样策略显著提升了混合3D头像生成的效率，适用于实际应用。

Abstract: The rapid advancement of neural radiance fields (NeRF) has paved the way to
generate animatable human avatars from a monocular video. However, the sole
usage of NeRF suffers from a lack of details, which results in the emergence of
hybrid representation that utilizes SMPL-based mesh together with NeRF
representation. While hybrid-based models show photo-realistic human avatar
generation qualities, they suffer from extremely slow inference due to their
deformation scheme: to be aligned with the mesh, hybrid-based models use the
deformation based on SMPL skinning weights, which needs high computational
costs on each sampled point. We observe that since most of the sampled points
are located in empty space, they do not affect the generation quality but
result in inference latency with deformation. In light of this observation, we
propose EPSilon, a hybrid-based 3D avatar generation scheme with novel
efficient point sampling strategies that boost both training and inference. In
EPSilon, we propose two methods to omit empty points at rendering; empty ray
omission (ERO) and empty interval omission (EIO). In ERO, we wipe out rays that
progress through the empty space. Then, EIO narrows down the sampling interval
on the ray, which wipes out the region not occupied by either clothes or mesh.
The delicate sampling scheme of EPSilon enables not only great computational
cost reduction during deformation but also the designation of the important
regions to be sampled, which enables a single-stage NeRF structure without
hierarchical sampling. Compared to existing methods, EPSilon maintains the
generation quality while using only 3.9% of sampled points and achieves around
20 times faster inference, together with 4 times faster training convergence.
We provide video results on https://github.com/seungjun-moon/epsilon.

</details>


### [101] [When Person Re-Identification Meets Event Camera: A Benchmark Dataset and An Attribute-guided Re-Identification Framework](https://arxiv.org/abs/2507.13659)
*Xiao Wang,Qian Zhu,Shujuan Wu,Bo Jiang,Shiliang Zhang,Yaowei Wang,Yonghong Tian,Bin Luo*

Main category: cs.CV

TL;DR: 论文提出了一种基于RGB和事件相机的大规模行人再识别数据集EvReID，并提出了TriPro-ReID框架，通过对比学习和行人属性增强特征学习。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机行人再识别方法因数据稀缺而难以评估真实性能和泛化能力的问题。

Method: 构建EvReID数据集，并提出TriPro-ReID框架，结合RGB和事件流数据，利用行人属性进行对比学习。

Result: 在EvReID和MARS数据集上的实验验证了框架的有效性。

Conclusion: 提出的数据集和框架为未来研究提供了数据和基准支持。

Abstract: Recent researchers have proposed using event cameras for person
re-identification (ReID) due to their promising performance and better balance
in terms of privacy protection, event camera-based person ReID has attracted
significant attention. Currently, mainstream event-based person ReID algorithms
primarily focus on fusing visible light and event stream, as well as preserving
privacy. Although significant progress has been made, these methods are
typically trained and evaluated on small-scale or simulated event camera
datasets, making it difficult to assess their real identification performance
and generalization ability. To address the issue of data scarcity, this paper
introduces a large-scale RGB-event based person ReID dataset, called EvReID.
The dataset contains 118,988 image pairs and covers 1200 pedestrian identities,
with data collected across multiple seasons, scenes, and lighting conditions.
We also evaluate 15 state-of-the-art person ReID algorithms, laying a solid
foundation for future research in terms of both data and benchmarking. Based on
our newly constructed dataset, this paper further proposes a pedestrian
attribute-guided contrastive learning framework to enhance feature learning for
person re-identification, termed TriPro-ReID. This framework not only
effectively explores the visual features from both RGB frames and event
streams, but also fully utilizes pedestrian attributes as mid-level semantic
features. Extensive experiments on the EvReID dataset and MARS datasets fully
validated the effectiveness of our proposed RGB-Event person ReID framework.
The benchmark dataset and source code will be released on
https://github.com/Event-AHU/Neuromorphic_ReID

</details>


### [102] [Global Modeling Matters: A Fast, Lightweight and Effective Baseline for Efficient Image Restoration](https://arxiv.org/abs/2507.13663)
*Xingyu Jiang,Ning Gao,Hongkun Dou,Xiuhui Zhang,Xiaoqing Zhong,Yue Deng,Hongjue Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于金字塔小波-傅里叶迭代管道的高效图像恢复基线PW-FNet，通过多尺度分解和傅里叶变换替代自注意力机制，显著提升了恢复质量和效率。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气条件会显著降低图像质量，影响下游任务性能。现有基于Transformer的方法虽然有效，但系统复杂度过高，难以实时处理。

Method: PW-FNet采用金字塔小波多输入多输出结构实现多尺度分解，并在模块内用傅里叶变换替代自注意力机制，降低计算复杂度。

Result: 实验表明，PW-FNet在多种图像恢复任务中不仅恢复质量优于现有方法，还显著减少了参数规模、计算成本和推理时间。

Conclusion: PW-FNet通过结合小波和傅里叶变换，提供了一种高效且高质量的图像恢复解决方案。

Abstract: Natural image quality is often degraded by adverse weather conditions,
significantly impairing the performance of downstream tasks. Image restoration
has emerged as a core solution to this challenge and has been widely discussed
in the literature. Although recent transformer-based approaches have made
remarkable progress in image restoration, their increasing system complexity
poses significant challenges for real-time processing, particularly in
real-world deployment scenarios. To this end, most existing methods attempt to
simplify the self-attention mechanism, such as by channel self-attention or
state space model. However, these methods primarily focus on network
architecture while neglecting the inherent characteristics of image restoration
itself. In this context, we explore a pyramid Wavelet-Fourier iterative
pipeline to demonstrate the potential of Wavelet-Fourier processing for image
restoration. Inspired by the above findings, we propose a novel and efficient
restoration baseline, named Pyramid Wavelet-Fourier Network (PW-FNet).
Specifically, PW-FNet features two key design principles: 1) at the inter-block
level, integrates a pyramid wavelet-based multi-input multi-output structure to
achieve multi-scale and multi-frequency bands decomposition; and 2) at the
intra-block level, incorporates Fourier transforms as an efficient alternative
to self-attention mechanisms, effectively reducing computational complexity
while preserving global modeling capability. Extensive experiments on tasks
such as image deraining, raindrop removal, image super-resolution, motion
deblurring, image dehazing, image desnowing and underwater/low-light
enhancement demonstrate that PW-FNet not only surpasses state-of-the-art
methods in restoration quality but also achieves superior efficiency, with
significantly reduced parameter size, computational cost and inference time.

</details>


### [103] [MaskHOI: Robust 3D Hand-Object Interaction Estimation via Masked Pre-training](https://arxiv.org/abs/2507.13673)
*Yuechen Xie,Haobo Jiang,Jian Yang,Yigong Zhang,Jin Xie*

Main category: cs.CV

TL;DR: 提出MaskHOI框架，通过MAE预训练提升3D手物交互姿态估计，引入区域特定掩码分配和SDF多模态学习，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决RGB图像几何模糊和交互中严重遮挡导致的3D手物姿态估计困难。

Method: 采用MAE掩码重建策略，提出区域特定掩码分配和骨架驱动掩码指导，结合掩码SDF多模态学习。

Result: 实验表明方法显著优于现有技术。

Conclusion: MaskHOI通过几何感知和遮挡鲁棒性学习，有效提升3D手物交互姿态估计性能。

Abstract: In 3D hand-object interaction (HOI) tasks, estimating precise joint poses of
hands and objects from monocular RGB input remains highly challenging due to
the inherent geometric ambiguity of RGB images and the severe mutual occlusions
that occur during interaction.To address these challenges, we propose MaskHOI,
a novel Masked Autoencoder (MAE)-driven pretraining framework for enhanced HOI
pose estimation. Our core idea is to leverage the masking-then-reconstruction
strategy of MAE to encourage the feature encoder to infer missing spatial and
structural information, thereby facilitating geometric-aware and
occlusion-robust representation learning. Specifically, based on our
observation that human hands exhibit far greater geometric complexity than
rigid objects, conventional uniform masking fails to effectively guide the
reconstruction of fine-grained hand structures. To overcome this limitation, we
introduce a Region-specific Mask Ratio Allocation, primarily comprising the
region-specific masking assignment and the skeleton-driven hand masking
guidance. The former adaptively assigns lower masking ratios to hand regions
than to rigid objects, balancing their feature learning difficulty, while the
latter prioritizes masking critical hand parts (e.g., fingertips or entire
fingers) to realistically simulate occlusion patterns in real-world
interactions. Furthermore, to enhance the geometric awareness of the pretrained
encoder, we introduce a novel Masked Signed Distance Field (SDF)-driven
multimodal learning mechanism. Through the self-masking 3D SDF prediction, the
learned encoder is able to perceive the global geometric structure of hands and
objects beyond the 2D image plane, overcoming the inherent limitations of
monocular input and alleviating self-occlusion issues. Extensive experiments
demonstrate that our method significantly outperforms existing state-of-the-art
approaches.

</details>


### [104] [HeCoFuse: Cross-Modal Complementary V2X Cooperative Perception with Heterogeneous Sensors](https://arxiv.org/abs/2507.13677)
*Chuheng Wei,Ziye Qin,Walter Zimmer,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: HeCoFuse是一个统一的框架，用于解决异构传感器配置下的V2X协同感知问题，通过分层融合机制和自适应学习策略，显著提升了感知性能。


<details>
  <summary>Details</summary>
Motivation: 现实中的V2X协同感知系统常因异构传感器配置导致特征融合和感知可靠性问题，亟需一种统一的解决方案。

Method: 提出HeCoFuse框架，结合通道和空间注意力机制的分层融合方法，并引入自适应空间分辨率调整模块和动态融合类型学习策略。

Result: 在TUMTraf-V2X数据集上，HeCoFuse在多种传感器配置下表现优异，最高达到43.38% 3D mAP，优于基线方法。

Conclusion: HeCoFuse在异构传感器配置下表现出色，成为当前V2X协同感知的先进方法。

Abstract: Real-world Vehicle-to-Everything (V2X) cooperative perception systems often
operate under heterogeneous sensor configurations due to cost constraints and
deployment variability across vehicles and infrastructure. This heterogeneity
poses significant challenges for feature fusion and perception reliability. To
address these issues, we propose HeCoFuse, a unified framework designed for
cooperative perception across mixed sensor setups where nodes may carry Cameras
(C), LiDARs (L), or both. By introducing a hierarchical fusion mechanism that
adaptively weights features through a combination of channel-wise and spatial
attention, HeCoFuse can tackle critical challenges such as cross-modality
feature misalignment and imbalanced representation quality. In addition, an
adaptive spatial resolution adjustment module is employed to balance
computational cost and fusion effectiveness. To enhance robustness across
different configurations, we further implement a cooperative learning strategy
that dynamically adjusts fusion type based on available modalities. Experiments
on the real-world TUMTraf-V2X dataset demonstrate that HeCoFuse achieves 43.22%
3D mAP under the full sensor configuration (LC+LC), outperforming the CoopDet3D
baseline by 1.17%, and reaches an even higher 43.38% 3D mAP in the L+LC
scenario, while maintaining 3D mAP in the range of 21.74% to 43.38% across nine
heterogeneous sensor configurations. These results, validated by our
first-place finish in the CVPR 2025 DriveX challenge, establish HeCoFuse as the
current state-of-the-art on TUM-Traf V2X dataset while demonstrating robust
performance across diverse sensor deployments.

</details>


### [105] [Gaussian kernel-based motion measurement](https://arxiv.org/abs/2507.13693)
*Hongyi Liu,Haifeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于高斯核的运动测量方法，用于高精度结构健康监测，解决了现有视觉方法在亚像素级运动测量中的精度不足和参数调优问题。


<details>
  <summary>Details</summary>
Motivation: 结构健康监测需求增长，需要高精度运动测量技术。视觉方法成本低、易安装，但在亚像素级测量中精度不足或需大量参数调优。

Method: 开发了一种基于高斯核的运动测量方法，通过跟踪高斯核位置提取帧间运动，引入运动一致性和超分辨率约束以提高精度和鲁棒性。

Result: 数值和实验验证表明，该方法无需针对不同样本定制参数即可实现高精度。

Conclusion: 该方法为结构健康监测提供了一种高精度、无需复杂参数调优的视觉运动测量解决方案。

Abstract: The growing demand for structural health monitoring has driven increasing
interest in high-precision motion measurement, as structural information
derived from extracted motions can effectively reflect the current condition of
the structure. Among various motion measurement techniques, vision-based
methods stand out due to their low cost, easy installation, and large-scale
measurement. However, when it comes to sub-pixel-level motion measurement,
current vision-based methods either lack sufficient accuracy or require
extensive manual parameter tuning (e.g., pyramid layers, target pixels, and
filter parameters) to reach good precision. To address this issue, we developed
a novel Gaussian kernel-based motion measurement method, which can extract the
motion between different frames via tracking the location of Gaussian kernels.
The motion consistency, which fits practical structural conditions, and a
super-resolution constraint, are introduced to increase accuracy and robustness
of our method. Numerical and experimental validations show that it can
consistently reach high accuracy without customized parameter setup for
different test samples.

</details>


### [106] [GOSPA and T-GOSPA quasi-metrics for evaluation of multi-object tracking algorithms](https://arxiv.org/abs/2507.13706)
*Ángel F. García-Fernández,Jinhao Gu,Lennart Svensson,Yuxuan Xia,Jan Krejčí,Oliver Kost,Ondřej Straka*

Main category: cs.CV

TL;DR: 本文提出了两种用于多目标跟踪（MOT）算法性能评估的准度量，分别基于GOSPA和T-GOSPA的扩展，具有灵活的成本设置和非对称定位误差惩罚能力。


<details>
  <summary>Details</summary>
Motivation: 现有的GOSPA和T-GOSPA度量在多目标跟踪评估中缺乏灵活性，无法根据应用需求调整不同错误的成本。本文旨在解决这一问题。

Method: 扩展GOSPA和T-GOSPA度量，提出两种准度量：一种用于对象集差异，另一种用于轨迹集差异，支持非对称成本和灵活的错误惩罚。

Result: 通过仿真实验，验证了T-GOSPA准度量在评估贝叶斯MOT算法性能时的有效性。

Conclusion: 提出的准度量在多目标跟踪评估中具有更高的灵活性，能够适应不同应用场景的需求。

Abstract: This paper introduces two quasi-metrics for performance assessment of
multi-object tracking (MOT) algorithms. In particular, one quasi-metric is an
extension of the generalised optimal subpattern assignment (GOSPA) metric and
measures the discrepancy between sets of objects. The other quasi-metric is an
extension of the trajectory GOSPA (T-GOSPA) metric and measures the discrepancy
between sets of trajectories. Similar to the GOSPA-based metrics, these
quasi-metrics include costs for localisation error for properly detected
objects, the number of false objects and the number of missed objects. The
T-GOSPA quasi-metric also includes a track switching cost. Differently from the
GOSPA and T-GOSPA metrics, the proposed quasi-metrics have the flexibility of
penalising missed and false objects with different costs, and the localisation
costs are not required to be symmetric. These properties can be useful in MOT
evaluation in certain applications. The performance of several Bayesian MOT
algorithms is assessed with the T-GOSPA quasi-metric via simulations.

</details>


### [107] [PoemTale Diffusion: Minimising Information Loss in Poem to Image Generation with Multi-Stage Prompt Refinement](https://arxiv.org/abs/2507.13708)
*Sofia Jamil,Bollampalli Areen Reddy,Raghvendra Kumar,Sriparna Saha,Koustava Goswami,K. J. Joseph*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法PoemTale Diffusion，通过多阶段提示优化和自注意力机制改进诗歌文本到图像的生成，并发布了P4I数据集。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在处理复杂、抽象的诗歌语言时表现不佳，导致信息丢失。

Method: 采用多阶段提示优化循环和改进的自注意力机制，生成多幅一致性图像以传达诗歌含义。

Result: 通过人类和定量评估验证了方法的有效性，生成图像能更好地捕捉诗歌信息。

Conclusion: PoemTale Diffusion为诗歌到图像生成提供了新视角，并推动了相关研究。

Abstract: Recent advancements in text-to-image diffusion models have achieved
remarkable success in generating realistic and diverse visual content. A
critical factor in this process is the model's ability to accurately interpret
textual prompts. However, these models often struggle with creative
expressions, particularly those involving complex, abstract, or highly
descriptive language. In this work, we introduce a novel training-free approach
tailored to improve image generation for a unique form of creative language:
poetic verse, which frequently features layered, abstract, and dual meanings.
Our proposed PoemTale Diffusion approach aims to minimise the information that
is lost during poetic text-to-image conversion by integrating a multi stage
prompt refinement loop into Language Models to enhance the interpretability of
poetic texts. To support this, we adapt existing state-of-the-art diffusion
models by modifying their self-attention mechanisms with a consistent
self-attention technique to generate multiple consistent images, which are then
collectively used to convey the poem's meaning. Moreover, to encourage research
in the field of poetry, we introduce the P4I (PoemForImage) dataset, consisting
of 1111 poems sourced from multiple online and offline resources. We engaged a
panel of poetry experts for qualitative assessments. The results from both
human and quantitative evaluations validate the efficacy of our method and
contribute a novel perspective to poem-to-image generation with enhanced
information capture in the generated images.

</details>


### [108] [Augmented Reality in Cultural Heritage: A Dual-Model Pipeline for 3D Artwork Reconstruction](https://arxiv.org/abs/2507.13719)
*Daniele Pannone,Alessia Castronovo,Maurizio Mancini,Gian Luca Foresti,Claudio Piciarelli,Rossana Gabrieli,Muhammad Yasir Bilal,Danilo Avola*

Main category: cs.CV

TL;DR: 提出了一种针对博物馆环境的增强现实流程，通过单张图像识别艺术品并生成精确3D模型。


<details>
  <summary>Details</summary>
Motivation: 旨在通过增强现实技术提升博物馆访客的互动体验，解决艺术品复杂轮廓和纹理的重建难题。

Method: 结合GLPN和Depth-Anything两种预训练深度估计模型，生成优化的深度图，并转换为高质量点云和网格。

Result: 实验结果显示重建精度和视觉真实感显著提升，系统适用于博物馆互动内容。

Conclusion: 该方法为博物馆提供了一种高效的增强现实工具，提升了访客参与度。

Abstract: This paper presents an innovative augmented reality pipeline tailored for
museum environments, aimed at recognizing artworks and generating accurate 3D
models from single images. By integrating two complementary pre-trained depth
estimation models, i.e., GLPN for capturing global scene structure and
Depth-Anything for detailed local reconstruction, the proposed approach
produces optimized depth maps that effectively represent complex artistic
features. These maps are then converted into high-quality point clouds and
meshes, enabling the creation of immersive AR experiences. The methodology
leverages state-of-the-art neural network architectures and advanced computer
vision techniques to overcome challenges posed by irregular contours and
variable textures in artworks. Experimental results demonstrate significant
improvements in reconstruction accuracy and visual realism, making the system a
highly robust tool for museums seeking to enhance visitor engagement through
interactive digital content.

</details>


### [109] [Can Synthetic Images Conquer Forgetting? Beyond Unexplored Doubts in Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2507.13739)
*Junsu Kim,Yunhoe Ku,Seungryul Baek*

Main category: cs.CV

TL;DR: Diffusion-FSCIL利用冻结的文本到图像扩散模型解决少样本类增量学习的挑战，通过多尺度特征提取和潜在重放提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决少样本类增量学习中数据不足和灾难性遗忘的问题。

Method: 使用冻结的扩散模型作为主干，提取多尺度特征，结合潜在重放和特征蒸馏。

Result: 在CUB-200、miniImageNet和CIFAR-100上表现优于现有方法。

Conclusion: Diffusion-FSCIL通过冻结主干和高效特征提取，有效平衡新旧类别的学习。

Abstract: Few-shot class-incremental learning (FSCIL) is challenging due to extremely
limited training data; while aiming to reduce catastrophic forgetting and learn
new information. We propose Diffusion-FSCIL, a novel approach that employs a
text-to-image diffusion model as a frozen backbone. Our conjecture is that
FSCIL can be tackled using a large generative model's capabilities benefiting
from 1) generation ability via large-scale pre-training; 2) multi-scale
representation; 3) representational flexibility through the text encoder. To
maximize the representation capability, we propose to extract multiple
complementary diffusion features to play roles as latent replay with slight
support from feature distillation for preventing generative biases. Our
framework realizes efficiency through 1) using a frozen backbone; 2) minimal
trainable components; 3) batch processing of multiple feature extractions.
Extensive experiments on CUB-200, \emph{mini}ImageNet, and CIFAR-100 show that
Diffusion-FSCIL surpasses state-of-the-art methods, preserving performance on
previously learned classes and adapting effectively to new ones.

</details>


### [110] [Tackling fake images in cybersecurity -- Interpretation of a StyleGAN and lifting its black-box](https://arxiv.org/abs/2507.13722)
*Julia Laubmann,Johannes Reschke*

Main category: cs.CV

TL;DR: 分析StyleGAN生成器的内部机制，揭示其权重修剪的潜力及潜在伦理风险。


<details>
  <summary>Details</summary>
Motivation: 研究StyleGAN生成器的工作原理，以理解其生成逼真合成图像的能力及潜在滥用风险。

Method: 使用PyTorch训练StyleGAN模型，分析其架构（如Equalized Learning Rate）和权重修剪效果，并研究潜在向量对生成图像的影响。

Result: 权重修剪可显著减少计算需求而不显著影响输出；潜在向量的全局和局部调整可精确控制生成图像的视觉特征。

Conclusion: StyleGAN的技术能力具有学术价值，但也存在被滥用于伪造身份等伦理风险。

Abstract: In today's digital age, concerns about the dangers of AI-generated images are
increasingly common. One powerful tool in this domain is StyleGAN (style-based
generative adversarial networks), a generative adversarial network capable of
producing highly realistic synthetic faces. To gain a deeper understanding of
how such a model operates, this work focuses on analyzing the inner workings of
StyleGAN's generator component. Key architectural elements and techniques, such
as the Equalized Learning Rate, are explored in detail to shed light on the
model's behavior. A StyleGAN model is trained using the PyTorch framework,
enabling direct inspection of its learned weights. Through pruning, it is
revealed that a significant number of these weights can be removed without
drastically affecting the output, leading to reduced computational
requirements. Moreover, the role of the latent vector -- which heavily
influences the appearance of the generated faces -- is closely examined. Global
alterations to this vector primarily affect aspects like color tones, while
targeted changes to individual dimensions allow for precise manipulation of
specific facial features. This ability to finetune visual traits is not only of
academic interest but also highlights a serious ethical concern: the potential
misuse of such technology. Malicious actors could exploit this capability to
fabricate convincing fake identities, posing significant risks in the context
of digital deception and cybercrime.

</details>


### [111] [Learning Spectral Diffusion Prior for Hyperspectral Image Reconstruction](https://arxiv.org/abs/2507.13769)
*Mingyang Yu,Zhijian Wu,Dingjiang Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的光谱扩散先验（SDP）和光谱先验注入模块（SPIM），用于提升高光谱图像（HSI）重建的高频细节恢复能力，实验表明其性能优于现有方法约0.5 dB。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱图像重建中难以准确捕捉高频细节，因此需要一种更有效的方法来提升细节恢复能力。

Method: 提出SDP（通过扩散模型隐式学习光谱先验）和SPIM（动态引导模型恢复细节），并将其注入HSI模型。

Result: 在MST和BISRNet两种代表性HSI方法上，性能提升约0.5 dB。

Conclusion: SDP和SPIM能显著提升HSI重建的细节恢复能力，优于现有方法。

Abstract: Hyperspectral image (HSI) reconstruction aims to recover 3D HSI from its
degraded 2D measurements. Recently great progress has been made in deep
learning-based methods, however, these methods often struggle to accurately
capture high-frequency details of the HSI. To address this issue, this paper
proposes a Spectral Diffusion Prior (SDP) that is implicitly learned from
hyperspectral images using a diffusion model. Leveraging the powerful ability
of the diffusion model to reconstruct details, this learned prior can
significantly improve the performance when injected into the HSI model. To
further improve the effectiveness of the learned prior, we also propose the
Spectral Prior Injector Module (SPIM) to dynamically guide the model to recover
the HSI details. We evaluate our method on two representative HSI methods: MST
and BISRNet. Experimental results show that our method outperforms existing
networks by about 0.5 dB, effectively improving the performance of HSI
reconstruction.

</details>


### [112] [Localized FNO for Spatiotemporal Hemodynamic Upsampling in Aneurysm MRI](https://arxiv.org/abs/2507.13789)
*Kyriakos Flouris,Moritz Halter,Yolanne Y. R. Lee,Samuel Castonguay,Luuk Jacobs,Pietro Dirix,Jonathan Nestmann,Sebastian Kozerke,Ender Konukoglu*

Main category: cs.CV

TL;DR: 提出了一种名为LoFNO的新型3D架构，用于提升血流动力学分析的空间和时间分辨率，直接预测壁面剪切应力（WSS），从而提高脑血管诊断的精确性。


<details>
  <summary>Details</summary>
Motivation: 磁共振血流成像的低时空分辨率和信噪比限制了其诊断效果，因此需要一种更高效的方法来预测动脉瘤破裂风险。

Method: 结合Laplacian特征向量作为几何先验，增强对不规则几何结构的感知，并采用EDSR层进行鲁棒的上采样，实现血流数据的去噪和时空上采样。

Result: LoFNO在速度和WSS预测上优于插值和其他深度学习方法，显著提升了诊断精度。

Conclusion: LoFNO通过整合几何先验和神经算子框架，为脑血管诊断提供了更精确的工具。

Abstract: Hemodynamic analysis is essential for predicting aneurysm rupture and guiding
treatment. While magnetic resonance flow imaging enables time-resolved
volumetric blood velocity measurements, its low spatiotemporal resolution and
signal-to-noise ratio limit its diagnostic utility. To address this, we propose
the Localized Fourier Neural Operator (LoFNO), a novel 3D architecture that
enhances both spatial and temporal resolution with the ability to predict wall
shear stress (WSS) directly from clinical imaging data. LoFNO integrates
Laplacian eigenvectors as geometric priors for improved structural awareness on
irregular, unseen geometries and employs an Enhanced Deep Super-Resolution
Network (EDSR) layer for robust upsampling. By combining geometric priors with
neural operator frameworks, LoFNO de-noises and spatiotemporally upsamples flow
data, achieving superior velocity and WSS predictions compared to interpolation
and alternative deep learning methods, enabling more precise cerebrovascular
diagnostics.

</details>


### [113] [Encapsulated Composition of Text-to-Image and Text-to-Video Models for High-Quality Video Synthesis](https://arxiv.org/abs/2507.13753)
*Tongtong Su,Chengyu Wang,Bingyan Liu,Jun Huang,Dongming Lu*

Main category: cs.CV

TL;DR: EVS是一种无需训练的封装视频合成器，结合T2I和T2V模型，提升生成视频的视觉保真度和运动平滑性。


<details>
  <summary>Details</summary>
Motivation: 现有T2V模型在图像质量和运动表现上存在挑战，如闪烁和伪影。

Method: 利用预训练的T2I扩散模型优化低质量视频帧，同时结合T2V模型确保运动一致性。

Result: 实验显示EVS在图像和运动质量上优于现有方法，推理速度提升1.6x-4.5x。

Conclusion: EVS通过结合T2I和T2V模型的优势，显著提升了视频生成的质量和效率。

Abstract: In recent years, large text-to-video (T2V) synthesis models have garnered
considerable attention for their abilities to generate videos from textual
descriptions. However, achieving both high imaging quality and effective motion
representation remains a significant challenge for these T2V models. Existing
approaches often adapt pre-trained text-to-image (T2I) models to refine video
frames, leading to issues such as flickering and artifacts due to
inconsistencies across frames. In this paper, we introduce EVS, a training-free
Encapsulated Video Synthesizer that composes T2I and T2V models to enhance both
visual fidelity and motion smoothness of generated videos. Our approach
utilizes a well-trained diffusion-based T2I model to refine low-quality video
frames by treating them as out-of-distribution samples, effectively optimizing
them with noising and denoising steps. Meanwhile, we employ T2V backbones to
ensure consistent motion dynamics. By encapsulating the T2V temporal-only prior
into the T2I generation process, EVS successfully leverages the strengths of
both types of models, resulting in videos of improved imaging and motion
quality. Experimental results validate the effectiveness of our approach
compared to previous approaches. Our composition process also leads to a
significant improvement of 1.6x-4.5x speedup in inference time. Source codes:
https://github.com/Tonniia/EVS.

</details>


### [114] [One Step Closer: Creating the Future to Boost Monocular Semantic Scene Completion](https://arxiv.org/abs/2507.13801)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Hao Hu*

Main category: cs.CV

TL;DR: 提出了一种新的时间3D语义场景补全框架CF-SSC，通过伪未来帧预测扩展感知范围，结合姿态和深度实现几何一致的时空融合，显著提升了遮挡推理和场景补全精度。


<details>
  <summary>Details</summary>
Motivation: 现有单目3D语义场景补全方法在真实交通场景中因遮挡和视野限制表现不佳，需改进以提升感知能力。

Method: 提出CF-SSC框架，利用伪未来帧预测和3D时空关系建模，结合姿态与深度实现几何一致的帧融合。

Result: 在SemanticKITTI和SSCBench-KITTI-360基准测试中达到最优性能，显著提升遮挡推理和场景补全精度。

Conclusion: CF-SSC通过时空建模和未来帧预测有效解决了单目方法的局限性，为自动驾驶感知任务提供了新思路。

Abstract: In recent years, visual 3D Semantic Scene Completion (SSC) has emerged as a
critical perception task for autonomous driving due to its ability to infer
complete 3D scene layouts and semantics from single 2D images. However, in
real-world traffic scenarios, a significant portion of the scene remains
occluded or outside the camera's field of view -- a fundamental challenge that
existing monocular SSC methods fail to address adequately. To overcome these
limitations, we propose Creating the Future SSC (CF-SSC), a novel temporal SSC
framework that leverages pseudo-future frame prediction to expand the model's
effective perceptual range. Our approach combines poses and depths to establish
accurate 3D correspondences, enabling geometrically-consistent fusion of past,
present, and predicted future frames in 3D space. Unlike conventional methods
that rely on simple feature stacking, our 3D-aware architecture achieves more
robust scene completion by explicitly modeling spatial-temporal relationships.
Comprehensive experiments on SemanticKITTI and SSCBench-KITTI-360 benchmarks
demonstrate state-of-the-art performance, validating the effectiveness of our
approach, highlighting our method's ability to improve occlusion reasoning and
3D scene completion accuracy.

</details>


### [115] [Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions](https://arxiv.org/abs/2507.13773)
*Pu Jian,Donglei Yu,Wen Yang,Shuo Ren,Jiajun Zhang*

Main category: cs.CV

TL;DR: ClearVQA 是一个针对视觉问答（VQA）中模糊问题的交互式澄清基准，解决了现有研究中缺乏评估交互能力的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过重述问题解决模糊性，忽略了用户反馈的交互性，且缺乏评估交互能力的基准。

Method: 引入 ClearVQA 基准，针对 VQA 中的三类常见模糊问题，覆盖多种场景。

Result: ClearVQA 填补了评估 VLM 交互能力的空白，并促进模型在模糊问题中主动寻求澄清。

Conclusion: ClearVQA 为 VQA 领域的交互式澄清研究提供了重要工具，推动了模型与用户的更有效互动。

Abstract: In visual question answering (VQA) context, users often pose ambiguous
questions to visual language models (VLMs) due to varying expression habits.
Existing research addresses such ambiguities primarily by rephrasing questions.
These approaches neglect the inherently interactive nature of user interactions
with VLMs, where ambiguities can be clarified through user feedback. However,
research on interactive clarification faces two major challenges: (1)
Benchmarks are absent to assess VLMs' capacity for resolving ambiguities
through interaction; (2) VLMs are trained to prefer answering rather than
asking, preventing them from seeking clarification. To overcome these
challenges, we introduce \textbf{ClearVQA} benchmark, which targets three
common categories of ambiguity in VQA context, and encompasses various VQA
scenarios.

</details>


### [116] [Team of One: Cracking Complex Video QA with Model Synergy](https://arxiv.org/abs/2507.13820)
*Jun Xie,Zhaoran Zhao,Xiongjun Guan,Yingjian Zhu,Hongzhu Yi,Xinming Wang,Feng Chen,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种新颖的开放视频问答框架，通过多模型协作提升推理深度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有视频-语言大模型在复杂场景中表现不足，如上下文理解有限、时序建模弱、泛化能力差。

Method: 引入提示-响应集成机制，协调多个异构视频-语言模型，结合结构化思维链，并由外部大语言模型评估和整合响应。

Result: 实验表明，该方法在所有评估指标上显著优于基线，展现了优越的泛化性和鲁棒性。

Conclusion: 该方法为无需重新训练的多模态推理提供了一种轻量级、可扩展的策略，为未来视频-语言大模型的发展奠定了基础。

Abstract: We propose a novel framework for open-ended video question answering that
enhances reasoning depth and robustness in complex real-world scenarios, as
benchmarked on the CVRR-ES dataset. Existing Video-Large Multimodal Models
(Video-LMMs) often exhibit limited contextual understanding, weak temporal
modeling, and poor generalization to ambiguous or compositional queries. To
address these challenges, we introduce a prompting-and-response integration
mechanism that coordinates multiple heterogeneous Video-Language Models (VLMs)
via structured chains of thought, each tailored to distinct reasoning pathways.
An external Large Language Model (LLM) serves as an evaluator and integrator,
selecting and fusing the most reliable responses. Extensive experiments
demonstrate that our method significantly outperforms existing baselines across
all evaluation metrics, showcasing superior generalization and robustness. Our
approach offers a lightweight, extensible strategy for advancing multimodal
reasoning without requiring model retraining, setting a strong foundation for
future Video-LMM development.

</details>


### [117] [Feature Engineering is Not Dead: Reviving Classical Machine Learning with Entropy, HOG, and LBP Feature Fusion for Image Classification](https://arxiv.org/abs/2507.13772)
*Abhijit Sen,Giridas Maiti,Bikram K. Parida,Bhanu P. Mishra,Mahima Arya,Denys I. Bondar*

Main category: cs.CV

TL;DR: 论文提出了一种基于排列熵（PE）的新方法，结合HOG和LBP特征，用于图像分类，展示了轻量级且可解释的替代方案。


<details>
  <summary>Details</summary>
Motivation: 在图像分类中，当需要优先考虑可解释性和计算效率时，特征工程仍然至关重要。本文旨在探索一种基于PE的轻量级方法，避免依赖参数庞大的深度学习模型。

Method: 扩展PE到二维图像，结合HOG和LBP特征，提取多尺度、多方向的熵特征，训练SVM分类器。

Result: 在多个基准数据集（如Fashion-MNIST、CIFAR-10）上表现优异，证明了其竞争力。

Conclusion: PE与HOG和LBP的结合提供了一种轻量级、可解释且高效的图像分类方案，为可解释机器学习贡献了新思路。

Abstract: Feature engineering continues to play a critical role in image
classification, particularly when interpretability and computational efficiency
are prioritized over deep learning models with millions of parameters. In this
study, we revisit classical machine learning based image classification through
a novel approach centered on Permutation Entropy (PE), a robust and
computationally lightweight measure traditionally used in time series analysis
but rarely applied to image data. We extend PE to two-dimensional images and
propose a multiscale, multi-orientation entropy-based feature extraction
approach that characterizes spatial order and complexity along rows, columns,
diagonals, anti-diagonals, and local patches of the image. To enhance the
discriminatory power of the entropy features, we integrate two classic image
descriptors: the Histogram of Oriented Gradients (HOG) to capture shape and
edge structure, and Local Binary Patterns (LBP) to encode micro-texture of an
image. The resulting hand-crafted feature set, comprising of 780 dimensions, is
used to train Support Vector Machine (SVM) classifiers optimized through grid
search. The proposed approach is evaluated on multiple benchmark datasets,
including Fashion-MNIST, KMNIST, EMNIST, and CIFAR-10, where it delivers
competitive classification performance without relying on deep architectures.
Our results demonstrate that the fusion of PE with HOG and LBP provides a
compact, interpretable, and effective alternative to computationally expensive
and limited interpretable deep learning models. This shows a potential of
entropy-based descriptors in image classification and contributes a lightweight
and generalizable solution to interpretable machine learning in image
classification and computer vision.

</details>


### [118] [When Seeing Overrides Knowing: Disentangling Knowledge Conflicts in Vision-Language Models](https://arxiv.org/abs/2507.13868)
*Francesco Ortu,Zhijing Jin,Diego Doimo,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）如何处理内部参数知识与外部信息之间的冲突，通过引入多模态反事实查询数据集，定位并修改控制冲突的头部，展示了注意力机制在视觉覆盖中的优势。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs在处理内部知识与外部信息冲突时产生的幻觉和不可靠响应问题，探索其机制。

Method: 引入多模态反事实查询数据集，通过logit检查定位控制冲突的头部，并修改这些头部以引导模型行为。

Result: 成功定位并修改了控制冲突的头部，注意力机制在视觉覆盖中表现优于基于梯度的归因方法。

Conclusion: 研究揭示了VLMs处理知识冲突的机制，并展示了通过修改特定头部可以引导模型行为，为模型可靠性提供了新思路。

Abstract: Vision-language models (VLMs) increasingly leverage diverse knowledge sources
to address complex tasks, often encountering conflicts between their internal
parametric knowledge and external information. Knowledge conflicts can result
in hallucinations and unreliable responses, but the mechanisms governing such
interactions remain unknown. To address this gap, we analyze the mechanisms
that VLMs use to resolve cross-modal conflicts by introducing a dataset of
multimodal counterfactual queries that deliberately contradict internal
commonsense knowledge. We localize with logit inspection a small set of heads
that control the conflict. Moreover, by modifying these heads, we can steer the
model towards its internal knowledge or the visual inputs. Finally, we show
that attention from such heads pinpoints localized image regions driving visual
overrides, outperforming gradient-based attribution in precision.

</details>


### [119] [NoHumansRequired: Autonomous High-Quality Image Editing Triplet Mining](https://arxiv.org/abs/2507.14119)
*Maksim Kuprashevich,Grigorii Alekseenko,Irina Tolstykh,Georgii Fedorov,Bulat Suleimanov,Vladimir Dokholyan,Aleksandr Gordeev*

Main category: cs.CV

TL;DR: 提出了一种自动化管道，用于生成高质量的训练三元组（原始图像、指令、编辑图像），解决了现有方法在编辑质量和规模上的限制。


<details>
  <summary>Details</summary>
Motivation: 生成式建模需要大量高质量的训练数据，但手动标注成本高且难以自动化。

Method: 利用公共生成模型和任务调优的验证器，通过反转和组合自举扩展数据集。

Result: 发布了NHR-Edit数据集（358k三元组）和Bagel-NHR-Edit模型，在跨数据集评估中表现最佳。

Conclusion: 自动化方法显著提升了训练数据的规模和质量，推动了生成式建模的研究。

Abstract: Recent advances in generative modeling enable image editing assistants that
follow natural language instructions without additional user input. Their
supervised training requires millions of triplets: original image, instruction,
edited image. Yet mining pixel-accurate examples is hard. Each edit must affect
only prompt-specified regions, preserve stylistic coherence, respect physical
plausibility, and retain visual appeal. The lack of robust automated
edit-quality metrics hinders reliable automation at scale. We present an
automated, modular pipeline that mines high-fidelity triplets across domains,
resolutions, instruction complexities, and styles. Built on public generative
models and running without human intervention, our system uses a task-tuned
Gemini validator to score instruction adherence and aesthetics directly,
removing any need for segmentation or grounding models. Inversion and
compositional bootstrapping enlarge the mined set by approximately 2.2x,
enabling large-scale high-fidelity training data. By automating the most
repetitive annotation steps, the approach allows a new scale of training
without human labeling effort. To democratize research in this
resource-intensive area, we release NHR-Edit: an open dataset of 358k
high-quality triplets. In the largest cross-dataset evaluation, it surpasses
all public alternatives. We also release Bagel-NHR-Edit, an open-source
fine-tuned Bagel model, which achieves state-of-the-art metrics in our
experiments.

</details>


### [120] [Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision](https://arxiv.org/abs/2507.13880)
*Marten Kreis,Benjamin Kiefer*

Main category: cs.CV

TL;DR: 提出了一种融合实时视觉数据与海图信息的新方法，通过神经网络匹配浮标等导航标志，显著提升了动态环境中的定位和关联精度。


<details>
  <summary>Details</summary>
Motivation: 增强海洋视觉能力，通过结合实时视频与海图数据，提高导航标志的识别和匹配准确性。

Method: 采用基于Transformer的端到端神经网络，预测浮标的边界框和置信度分数，直接匹配图像检测与海图标记。

Result: 实验表明，该方法在动态和复杂环境中显著优于基线方法（如基于YOLOv7的扩展网络）。

Conclusion: 提出的方法有效提升了海洋视觉系统的性能，适用于动态和挑战性环境。

Abstract: This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.

</details>


### [121] [SuperCM: Improving Semi-Supervised Learning and Domain Adaptation through differentiable clustering](https://arxiv.org/abs/2507.13779)
*Durgesh Singh,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 论文提出了一种显式可微分聚类模块，用于半监督学习和无监督域适应，通过利用监督数据计算聚类中心，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常隐式地利用聚类假设，而本文希望通过显式引入可微分聚类模块，更有效地利用监督数据。

Method: 提出了一种端到端的训练策略，显式地结合了可微分聚类模块，并利用监督数据计算聚类中心。

Result: 实验表明，该方法在半监督学习和无监督域适应任务中表现优异，尤其在低监督情况下效果显著。

Conclusion: 显式引入可微分聚类模块是一种简单有效的策略，可作为独立模型或现有方法的正则化手段。

Abstract: Semi-Supervised Learning (SSL) and Unsupervised Domain Adaptation (UDA)
enhance the model performance by exploiting information from labeled and
unlabeled data. The clustering assumption has proven advantageous for learning
with limited supervision and states that data points belonging to the same
cluster in a high-dimensional space should be assigned to the same category.
Recent works have utilized different training mechanisms to implicitly enforce
this assumption for the SSL and UDA. In this work, we take a different approach
by explicitly involving a differentiable clustering module which is extended to
leverage the supervised data to compute its centroids. We demonstrate the
effectiveness of our straightforward end-to-end training strategy for SSL and
UDA over extensive experiments and highlight its benefits, especially in low
supervision regimes, both as a standalone model and as a regularizer for
existing approaches.

</details>


### [122] [DynFaceRestore: Balancing Fidelity and Quality in Diffusion-Guided Blind Face Restoration with Dynamic Blur-Level Mapping and Guidance](https://arxiv.org/abs/2507.13797)
*Huu-Phu Do,Yu-Wei Chen,Yi-Cheng Liao,Chi-Wei Hsiao,Han-Yang Wang,Wei-Chen Chiu,Ching-Chun Huang*

Main category: cs.CV

TL;DR: DynFaceRestore提出了一种动态选择扩散起始时间和局部调整引导强度的盲脸修复方法，平衡了保真度和质量。


<details>
  <summary>Details</summary>
Motivation: 现有盲脸修复方法因固定扩散采样时间和全局引导尺度，导致保真度与质量不平衡。

Method: 通过学习将退化输入映射到高斯模糊图像，动态选择起始时间并应用闭环引导，同时引入动态引导缩放调整器。

Result: DynFaceRestore在定量和定性评估中均达到最先进性能。

Conclusion: 该方法有效平衡了保真度和质量，展示了盲脸修复的鲁棒性和有效性。

Abstract: Blind Face Restoration aims to recover high-fidelity, detail-rich facial
images from unknown degraded inputs, presenting significant challenges in
preserving both identity and detail. Pre-trained diffusion models have been
increasingly used as image priors to generate fine details. Still, existing
methods often use fixed diffusion sampling timesteps and a global guidance
scale, assuming uniform degradation. This limitation and potentially imperfect
degradation kernel estimation frequently lead to under- or over-diffusion,
resulting in an imbalance between fidelity and quality. We propose
DynFaceRestore, a novel blind face restoration approach that learns to map any
blindly degraded input to Gaussian blurry images. By leveraging these blurry
images and their respective Gaussian kernels, we dynamically select the
starting timesteps for each blurry image and apply closed-form guidance during
the diffusion sampling process to maintain fidelity. Additionally, we introduce
a dynamic guidance scaling adjuster that modulates the guidance strength across
local regions, enhancing detail generation in complex areas while preserving
structural fidelity in contours. This strategy effectively balances the
trade-off between fidelity and quality. DynFaceRestore achieves
state-of-the-art performance in both quantitative and qualitative evaluations,
demonstrating robustness and effectiveness in blind face restoration.

</details>


### [123] [GRAM-MAMBA: Holistic Feature Alignment for Wireless Perception with Adaptive Low-Rank Compensation](https://arxiv.org/abs/2507.13803)
*Weiqi Yang,Xu Zhou,Jingfu Guan,Hao Du,Tianyu Bai*

Main category: cs.CV

TL;DR: GRAM-MAMBA框架通过线性复杂度Mamba模型和优化的GRAM矩阵策略，解决了多模态融合中的效率、模态对齐和缺失模态问题，实验验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合系统在资源受限环境中部署困难，模态对齐不充分，且对缺失模态鲁棒性差，这些问题阻碍了实际应用。

Method: 结合线性复杂度Mamba模型处理传感器时间序列，优化GRAM矩阵策略实现模态对齐，并引入低秩自适应层补偿缺失模态。

Result: 在SPAWC2021和USC-HAD数据集上表现优异，缺失模态适应性能提升显著，训练参数极少。

Conclusion: GRAM-MAMBA在资源受限环境中实现了高效且鲁棒的多模态感知，具有实际应用潜力。

Abstract: Multi-modal fusion is crucial for Internet of Things (IoT) perception, widely
deployed in smart homes, intelligent transport, industrial automation, and
healthcare. However, existing systems often face challenges: high model
complexity hinders deployment in resource-constrained environments,
unidirectional modal alignment neglects inter-modal relationships, and
robustness suffers when sensor data is missing. These issues impede efficient
and robust multimodal perception in real-world IoT settings. To overcome these
limitations, we propose GRAM-MAMBA. This framework utilizes the
linear-complexity Mamba model for efficient sensor time-series processing,
combined with an optimized GRAM matrix strategy for pairwise alignment among
modalities, addressing the shortcomings of traditional single-modality
alignment. Inspired by Low-Rank Adaptation (LoRA), we introduce an adaptive
low-rank layer compensation strategy to handle missing modalities
post-training. This strategy freezes the pre-trained model core and irrelevant
adaptive layers, fine-tuning only those related to available modalities and the
fusion process. Extensive experiments validate GRAM-MAMBA's effectiveness. On
the SPAWC2021 indoor positioning dataset, the pre-trained model shows lower
error than baselines; adapting to missing modalities yields a 24.5% performance
boost by training less than 0.2% of parameters. On the USC-HAD human activity
recognition dataset, it achieves 93.55% F1 and 93.81% Overall Accuracy (OA),
outperforming prior work; the update strategy increases F1 by 23% while
training less than 0.3% of parameters. These results highlight GRAM-MAMBA's
potential for achieving efficient and robust multimodal perception in
resource-constrained environments.

</details>


### [124] [Generalist Forecasting with Frozen Video Models via Latent Diffusion](https://arxiv.org/abs/2507.13942)
*Jacob C Walker,Pedro Vélez,Luisa Polania Cabrera,Guangyao Zhou,Rishabh Kabra,Carl Doersch,Maks Ovsjanikov,João Carreira,Shiry Ginosar*

Main category: cs.CV

TL;DR: 研究发现视觉模型的感知能力与其短期预测性能强相关，提出了一种通用预测框架，利用潜在扩散模型预测未来特征，并通过轻量级解码器实现任务特定输出。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型的感知能力与预测性能之间的关系，以提升通用系统的规划和行动能力。

Method: 提出通用预测框架，利用冻结视觉骨干网络和潜在扩散模型预测未来特征，结合轻量级任务特定解码器。

Result: 在九个模型和四个任务上的实验表明，感知能力与预测性能强相关，且框架在多任务中表现一致。

Conclusion: 结合表征学习和生成模型对视频理解具有重要意义，为时序任务提供了新思路。

Abstract: Forecasting what will happen next is a critical skill for general-purpose
systems that plan or act in the world at different levels of abstraction. In
this paper, we identify a strong correlation between a vision model's
perceptual ability and its generalist forecasting performance over short time
horizons. This trend holds across a diverse set of pretrained models-including
those trained generatively-and across multiple levels of abstraction, from raw
pixels to depth, point tracks, and object motion. The result is made possible
by a novel generalist forecasting framework that operates on any frozen vision
backbone: we train latent diffusion models to forecast future features in the
frozen representation space, which are then decoded via lightweight,
task-specific readouts. To enable consistent evaluation across tasks, we
introduce distributional metrics that compare distributional properties
directly in the space of downstream tasks and apply this framework to nine
models and four tasks. Our results highlight the value of bridging
representation learning and generative modeling for temporally grounded video
understanding.

</details>


### [125] [SkySense V2: A Unified Foundation Model for Multi-modal Remote Sensing](https://arxiv.org/abs/2507.13812)
*Yingying Zhang,Lixiang Ru,Kang Wu,Lei Yu,Lei Liang,Yansheng Li,Jingdong Chen*

Main category: cs.CV

TL;DR: SkySense V2是一个统一的多模态遥感基础模型，通过单一Transformer主干处理多种模态数据，采用自适应SSL策略，性能优于前代。


<details>
  <summary>Details</summary>
Motivation: 现有方法需为每种模态训练独立网络，效率低且未充分考虑遥感图像特性。

Method: 使用单一Transformer主干，结合自适应SSL策略、自适应块合并模块、可学习模态提示令牌和MoE模块。

Result: 在7个任务的16个数据集上评估，平均性能提升1.8分。

Conclusion: SkySense V2通过统一架构和针对性优化，显著提升了多模态遥感任务的性能。

Abstract: The multi-modal remote sensing foundation model (MM-RSFM) has significantly
advanced various Earth observation tasks, such as urban planning, environmental
monitoring, and natural disaster management. However, most existing approaches
generally require the training of separate backbone networks for each data
modality, leading to redundancy and inefficient parameter utilization.
Moreover, prevalent pre-training methods typically apply self-supervised
learning (SSL) techniques from natural images without adequately accommodating
the characteristics of remote sensing (RS) images, such as the complicated
semantic distribution within a single RS image. In this work, we present
SkySense V2, a unified MM-RSFM that employs a single transformer backbone to
handle multiple modalities. This backbone is pre-trained with a novel SSL
strategy tailored to the distinct traits of RS data. In particular, SkySense V2
incorporates an innovative adaptive patch merging module and learnable modality
prompt tokens to address challenges related to varying resolutions and limited
feature diversity across modalities. In additional, we incorporate the mixture
of experts (MoE) module to further enhance the performance of the foundation
model. SkySense V2 demonstrates impressive generalization abilities through an
extensive evaluation involving 16 datasets over 7 tasks, outperforming SkySense
by an average of 1.8 points.

</details>


### [126] [A Quantum-assisted Attention U-Net for Building Segmentation over Tunis using Sentinel-1 Data](https://arxiv.org/abs/2507.13852)
*Luigi Russo,Francesco Mauro,Babak Memar,Alessandro Sebastianelli,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 该论文研究了如何利用量子卷积预处理提升Attention U-Net模型在建筑分割中的性能，特别是在突尼斯城市区域的SAR图像上，结果显示该方法在保持精度的同时减少了网络参数。


<details>
  <summary>Details</summary>
Motivation: 城市建筑分割对城市规划、灾害响应等至关重要，但高分辨率卫星图像的处理存在挑战。

Method: 采用量子卷积预处理提取SAR图像的特征，结合Attention U-Net模型进行建筑分割。

Result: 该方法在测试精度上与标准Attention U-Net相当，同时显著减少了网络参数，提高了计算效率。

Conclusion: 量子辅助的深度学习框架在大规模城市建筑分割中具有潜力。

Abstract: Building segmentation in urban areas is essential in fields such as urban
planning, disaster response, and population mapping. Yet accurately segmenting
buildings in dense urban regions presents challenges due to the large size and
high resolution of satellite images. This study investigates the use of a
Quanvolutional pre-processing to enhance the capability of the Attention U-Net
model in the building segmentation. Specifically, this paper focuses on the
urban landscape of Tunis, utilizing Sentinel-1 Synthetic Aperture Radar (SAR)
imagery. In this work, Quanvolution was used to extract more informative
feature maps that capture essential structural details in radar imagery,
proving beneficial for accurate building segmentation. Preliminary results
indicate that proposed methodology achieves comparable test accuracy to the
standard Attention U-Net model while significantly reducing network parameters.
This result aligns with findings from previous works, confirming that
Quanvolution not only maintains model accuracy but also increases computational
efficiency. These promising outcomes highlight the potential of
quantum-assisted Deep Learning frameworks for large-scale building segmentation
in urban environments.

</details>


### [127] [CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models](https://arxiv.org/abs/2507.13984)
*Quang-Binh Nguyen,Minh Luu,Quang Nguyen,Anh Tran,Khoi Nguyen*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉自回归模型（VAR）的内容-风格分解方法（CSD-VAR），通过三种创新技术提升分解效果，并在新数据集CSD-100上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对扩散模型，而VAR作为一种新兴生成框架，其逐尺度生成特性可能更适合内容-风格分解任务。

Method: 提出了CSD-VAR方法，包括尺度感知交替优化、基于SVD的校正和增强的键值记忆机制。

Result: 实验表明，CSD-VAR在内容保留和风格化保真度上优于现有方法。

Conclusion: VAR框架在内容-风格分解任务中具有潜力，CSD-VAR为未来研究提供了新方向。

Abstract: Disentangling content and style from a single image, known as content-style
decomposition (CSD), enables recontextualization of extracted content and
stylization of extracted styles, offering greater creative flexibility in
visual synthesis. While recent personalization methods have explored the
decomposition of explicit content style, they remain tailored for diffusion
models. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a
promising alternative with a next-scale prediction paradigm, achieving
performance comparable to that of diffusion models. In this paper, we explore
VAR as a generative framework for CSD, leveraging its scale-wise generation
process for improved disentanglement. To this end, we propose CSD-VAR, a novel
method that introduces three key innovations: (1) a scale-aware alternating
optimization strategy that aligns content and style representation with their
respective scales to enhance separation, (2) an SVD-based rectification method
to mitigate content leakage into style representations, and (3) an Augmented
Key-Value (K-V) memory enhancing content identity preservation. To benchmark
this task, we introduce CSD-100, a dataset specifically designed for
content-style decomposition, featuring diverse subjects rendered in various
artistic styles. Experiments demonstrate that CSD-VAR outperforms prior
approaches, achieving superior content preservation and stylization fidelity.

</details>


### [128] [Depth3DLane: Fusing Monocular 3D Lane Detection with Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2507.13857)
*Max van den Hoven,Kishaan Jeeveswaran,Pieter Piscaer,Thijs Wensveen,Elahe Arani,Bahram Zonooz*

Main category: cs.CV

TL;DR: Depth3DLane提出了一种双路径框架，结合自监督深度估计，无需昂贵传感器或额外深度数据，实现了单目3D车道检测。


<details>
  <summary>Details</summary>
Motivation: 解决单目3D车道检测中缺乏显式空间信息的问题，避免依赖昂贵传感器或不切实际的深度数据收集。

Method: 通过自监督深度网络获取点云表示，结合鸟瞰图和前视图路径提取空间和语义信息，使用3D车道锚点采样特征并推断几何。

Result: 在OpenLane基准测试中表现优异，且无需相机标定即可应用。

Conclusion: Depth3DLane在无标定场景下具有竞争力，扩展了单目3D车道检测的适用性。

Abstract: Monocular 3D lane detection is essential for autonomous driving, but
challenging due to the inherent lack of explicit spatial information.
Multi-modal approaches rely on expensive depth sensors, while methods
incorporating fully-supervised depth networks rely on ground-truth depth data
that is impractical to collect at scale. Additionally, existing methods assume
that camera parameters are available, limiting their applicability in scenarios
like crowdsourced high-definition (HD) lane mapping. To address these
limitations, we propose Depth3DLane, a novel dual-pathway framework that
integrates self-supervised monocular depth estimation to provide explicit
structural information, without the need for expensive sensors or additional
ground-truth depth data. Leveraging a self-supervised depth network to obtain a
point cloud representation of the scene, our bird's-eye view pathway extracts
explicit spatial information, while our front view pathway simultaneously
extracts rich semantic information. Depth3DLane then uses 3D lane anchors to
sample features from both pathways and infer accurate 3D lane geometry.
Furthermore, we extend the framework to predict camera parameters on a
per-frame basis and introduce a theoretically motivated fitting procedure to
enhance stability on a per-segment basis. Extensive experiments demonstrate
that Depth3DLane achieves competitive performance on the OpenLane benchmark
dataset. Furthermore, experimental results show that using learned parameters
instead of ground-truth parameters allows Depth3DLane to be applied in
scenarios where camera calibration is infeasible, unlike previous methods.

</details>


### [129] [VLA-Mark: A cross modal watermark for large vision-language alignment model](https://arxiv.org/abs/2507.14067)
*Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu*

Main category: cs.CV

TL;DR: VLA-Mark是一种视觉对齐的水印框架，通过跨模态协调嵌入可检测水印，同时保持语义保真度，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本水印方法会破坏视觉-文本对齐，导致语义关键概念易受攻击，需要一种新方法保护知识产权且不损害多模态一致性。

Method: VLA-Mark整合了多尺度视觉-文本对齐指标（如局部补丁亲和性、全局语义一致性和上下文注意力模式），动态平衡水印强度和语义保留。

Result: 实验显示，VLA-Mark在PPL和BLEU上分别优于传统方法7.4%和26.6%，检测准确率达98.8% AUC，抗攻击能力达96.1%。

Conclusion: VLA-Mark为质量保持的多模态水印设定了新标准，同时保持文本-视觉一致性。

Abstract: Vision-language models demand watermarking solutions that protect
intellectual property without compromising multimodal coherence. Existing text
watermarking methods disrupt visual-textual alignment through biased token
selection and static strategies, leaving semantic-critical concepts vulnerable.
We propose VLA-Mark, a vision-aligned framework that embeds detectable
watermarks while preserving semantic fidelity through cross-modal coordination.
Our approach integrates multiscale visual-textual alignment metrics, combining
localized patch affinity, global semantic coherence, and contextual attention
patterns, to guide watermark injection without model retraining. An
entropy-sensitive mechanism dynamically balances watermark strength and
semantic preservation, prioritizing visual grounding during low-uncertainty
generation phases. Experiments show 7.4% lower PPL and 26.6% higher BLEU than
conventional methods, with near-perfect detection (98.8% AUC). The framework
demonstrates 96.1\% attack resilience against attacks such as paraphrasing and
synonym substitution, while maintaining text-visual consistency, establishing
new standards for quality-preserving multimodal watermarking

</details>


### [130] [PositionIC: Unified Position and Identity Consistency for Image Customization](https://arxiv.org/abs/2507.13861)
*Junjie Hu,Tianyang Han,Kai Ma,Jialin Gao,Hao Dou,Song Yang,Xianhua He,Jianhui Zhang,Junfeng Luo,Xiaoming Wei,Wenqiang Zhang*

Main category: cs.CV

TL;DR: PositionIC是一个统一框架，通过位置和身份一致性实现多主体图像定制，解决了现有方法在细粒度空间控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有图像定制方法在实体级空间控制上表现不足，主要因缺乏绑定身份与精确位置的可扩展数据集。

Method: 构建双向生成范式的合成管道，设计轻量级位置调制层以解耦空间嵌入，保持视觉保真度。

Result: 实验表明，PositionIC能实现精确空间控制，同时保持图像定制任务的高一致性。

Conclusion: PositionIC为开放世界多实体场景的可控高保真图像定制提供了新方向，并将公开以促进研究。

Abstract: Recent subject-driven image customization has achieved significant
advancements in fidelity, yet fine-grained entity-level spatial control remains
elusive, hindering the broader real-world application. This limitation is
mainly attributed to scalable datasets that bind identity with precise
positional cues are absent. To this end, we introduce PositionIC, a unified
framework that enforces position and identity consistency for multi-subject
customization. We construct a scalable synthesis pipeline that employs a
bidirectional generation paradigm to eliminate subject drift and maintain
semantic coherence. On top of these data, we design a lightweight positional
modulation layer that decouples spatial embeddings among subjects, enabling
independent, accurate placement while preserving visual fidelity. Extensive
experiments demonstrate that our approach can achieve precise spatial control
while maintaining high consistency in image customization task. PositionIC
paves the way for controllable, high-fidelity image customization in
open-world, multi-entity scenarios and will be released to foster further
research.

</details>


### [131] [Multi-Centre Validation of a Deep Learning Model for Scoliosis Assessment](https://arxiv.org/abs/2507.14093)
*Šimon Kubov,Simon Klíčník,Jakub Dandár,Zdeněk Straka,Karolína Kvaková,Daniel Kvak*

Main category: cs.CV

TL;DR: 论文评估了一种基于深度学习的自动化软件（Carebot AI Bones）用于测量脊柱侧弯的Cobb角，结果显示其与放射科医生的测量结果具有高度一致性，可用于临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 脊柱侧弯影响2-4%的青少年，传统手动测量耗时且存在观察者间差异，因此需要一种自动化解决方案。

Method: 研究对103张站立位全脊柱X光片进行了回顾性多中心评估，使用Carebot AI Bones软件进行自动测量，并与两位放射科医生的独立测量结果对比。

Result: AI与放射科医生的测量结果高度一致（MAE约3.9度，Pearson相关系数0.88-0.906），分类一致性（Cohen kappa）为0.51-0.64。

Conclusion: 该软件能够复现专家水平的Cobb角测量和分类，可用于临床工作流程中优化脊柱侧弯的报告和分诊。

Abstract: Scoliosis affects roughly 2 to 4 percent of adolescents, and treatment
decisions depend on precise Cobb angle measurement. Manual assessment is time
consuming and subject to inter observer variation. We conducted a
retrospective, multi centre evaluation of a fully automated deep learning
software (Carebot AI Bones, Spine Measurement functionality; Carebot s.r.o.) on
103 standing anteroposterior whole spine radiographs collected from ten
hospitals. Two musculoskeletal radiologists independently measured each study
and served as reference readers. Agreement between the AI and each radiologist
was assessed with Bland Altman analysis, mean absolute error (MAE), root mean
squared error (RMSE), Pearson correlation coefficient, and Cohen kappa for four
grade severity classification. Against Radiologist 1 the AI achieved an MAE of
3.89 degrees (RMSE 4.77 degrees) with a bias of 0.70 degrees and limits of
agreement from minus 8.59 to plus 9.99 degrees. Against Radiologist 2 the AI
achieved an MAE of 3.90 degrees (RMSE 5.68 degrees) with a bias of 2.14 degrees
and limits from minus 8.23 to plus 12.50 degrees. Pearson correlations were r
equals 0.906 and r equals 0.880 (inter reader r equals 0.928), while Cohen
kappa for severity grading reached 0.51 and 0.64 (inter reader kappa 0.59).
These results demonstrate that the proposed software reproduces expert level
Cobb angle measurements and categorical grading across multiple centres,
suggesting its utility for streamlining scoliosis reporting and triage in
clinical workflows.

</details>


### [132] [PCR-GS: COLMAP-Free 3D Gaussian Splatting via Pose Co-Regularizations](https://arxiv.org/abs/2507.13891)
*Yu Wei,Jiahui Zhang,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: PCR-GS是一种无需COLMAP的3D高斯溅射技术，通过相机姿态共正则化提升复杂场景下的3D建模和相机姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有3D-GS方法在复杂相机轨迹场景下表现不佳，导致相机姿态估计和联合优化陷入局部最优。

Method: 提出两种正则化方法：特征重投影正则化和基于小波的高频正则化，分别利用语义对齐和高频细节优化相机姿态。

Result: 实验表明，PCR-GS在复杂相机轨迹下显著提升了姿态无关的3D场景建模效果。

Conclusion: PCR-GS通过共正则化技术有效解决了复杂相机轨迹下的3D-GS建模问题。

Abstract: COLMAP-free 3D Gaussian Splatting (3D-GS) has recently attracted increasing
attention due to its remarkable performance in reconstructing high-quality 3D
scenes from unposed images or videos. However, it often struggles to handle
scenes with complex camera trajectories as featured by drastic rotation and
translation across adjacent camera views, leading to degraded estimation of
camera poses and further local minima in joint optimization of camera poses and
3D-GS. We propose PCR-GS, an innovative COLMAP-free 3DGS technique that
achieves superior 3D scene modeling and camera pose estimation via camera pose
co-regularization. PCR-GS achieves regularization from two perspectives. The
first is feature reprojection regularization which extracts view-robust DINO
features from adjacent camera views and aligns their semantic information for
camera pose regularization. The second is wavelet-based frequency
regularization which exploits discrepancy in high-frequency details to further
optimize the rotation matrix in camera poses. Extensive experiments over
multiple real-world scenes show that the proposed PCR-GS achieves superior
pose-free 3D-GS scene modeling under dramatic changes of camera trajectories.

</details>


### [133] [Enhancing LiDAR Point Features with Foundation Model Priors for 3D Object Detection](https://arxiv.org/abs/2507.13899)
*Yujian Mo,Yan Wu,Junqiao Zhao,Jijun Wang,Yinghao Hu,Jun Yan*

Main category: cs.CV

TL;DR: 论文提出了一种利用DepthAnything模型预测的深度先验增强LiDAR点云特征的方法，通过双路径RoI特征提取和双向门控融合模块，显著提升了3D目标检测精度。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云特征表达能力有限，尤其是反射率属性区分能力弱，需要引入视觉基础模型的深度先验来增强特征表示。

Method: 融合DepthAnything预测的深度先验与原始LiDAR属性，设计点级特征提取模块和双路径RoI特征提取框架（体素分支和点分支），并引入双向门控RoI特征融合模块。

Result: 在KITTI基准测试中，检测精度显著提升，验证了视觉基础模型先验在LiDAR 3D目标检测中的价值。

Conclusion: 通过深度先验与LiDAR特征的融合及高效的双路径特征提取与融合方法，显著提升了3D目标检测性能。

Abstract: Recent advances in foundation models have opened up new possibilities for
enhancing 3D perception. In particular, DepthAnything offers dense and reliable
geometric priors from monocular RGB images, which can complement sparse LiDAR
data in autonomous driving scenarios. However, such priors remain underutilized
in LiDAR-based 3D object detection. In this paper, we address the limited
expressiveness of raw LiDAR point features, especially the weak discriminative
capability of the reflectance attribute, by introducing depth priors predicted
by DepthAnything. These priors are fused with the original LiDAR attributes to
enrich each point's representation. To leverage the enhanced point features, we
propose a point-wise feature extraction module. Then, a Dual-Path RoI feature
extraction framework is employed, comprising a voxel-based branch for global
semantic context and a point-based branch for fine-grained structural details.
To effectively integrate the complementary RoI features, we introduce a
bidirectional gated RoI feature fusion module that balances global and local
cues. Extensive experiments on the KITTI benchmark show that our method
consistently improves detection accuracy, demonstrating the value of
incorporating visual foundation model priors into LiDAR-based 3D object
detection.

</details>


### [134] [TimeNeRF: Building Generalizable Neural Radiance Fields across Time from Few-Shot Input Views](https://arxiv.org/abs/2507.13929)
*Hsiang-Hui Hung,Huu-Phu Do,Yung-Hui Li,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TimeNeRF是一种通用的神经渲染方法，能够在任意视角和时间渲染新视图，即使输入视图较少。它结合多视角立体、神经辐射场和解缠策略，实现少样本泛化能力，并支持时间动态场景建模。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，多视图采集成本高，且为未见场景重新优化效率低。元宇宙等数字领域需要能够自然过渡昼夜的3D环境建模能力。现有NeRF技术在时间动态场景建模方面潜力未充分探索。

Method: 结合多视角立体、神经辐射场和解缠策略，构建隐式内容辐射场，支持任意时间的神经辐射场建模，并通过体积渲染合成新视图。

Result: TimeNeRF在少样本设置下无需逐场景优化即可渲染新视图，尤其擅长平滑过渡不同时间的自然场景变化。

Conclusion: TimeNeRF为时间动态3D场景建模提供了高效且通用的解决方案，适用于元宇宙等沉浸式体验需求。

Abstract: We present TimeNeRF, a generalizable neural rendering approach for rendering
novel views at arbitrary viewpoints and at arbitrary times, even with few input
views. For real-world applications, it is expensive to collect multiple views
and inefficient to re-optimize for unseen scenes. Moreover, as the digital
realm, particularly the metaverse, strives for increasingly immersive
experiences, the ability to model 3D environments that naturally transition
between day and night becomes paramount. While current techniques based on
Neural Radiance Fields (NeRF) have shown remarkable proficiency in synthesizing
novel views, the exploration of NeRF's potential for temporal 3D scene modeling
remains limited, with no dedicated datasets available for this purpose. To this
end, our approach harnesses the strengths of multi-view stereo, neural radiance
fields, and disentanglement strategies across diverse datasets. This equips our
model with the capability for generalizability in a few-shot setting, allows us
to construct an implicit content radiance field for scene representation, and
further enables the building of neural radiance fields at any arbitrary time.
Finally, we synthesize novel views of that time via volume rendering.
Experiments show that TimeNeRF can render novel views in a few-shot setting
without per-scene optimization. Most notably, it excels in creating realistic
novel views that transition smoothly across different times, adeptly capturing
intricate natural scene changes from dawn to dusk.

</details>


### [135] [DiViD: Disentangled Video Diffusion for Static-Dynamic Factorization](https://arxiv.org/abs/2507.13934)
*Marzieh Gheisari,Auguste Genovesio*

Main category: cs.CV

TL;DR: DiViD是一种端到端视频扩散框架，用于显式分离静态外观和动态运动，解决了现有方法中的信息泄漏和模糊重建问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE和GAN的方法在视频中分离静态和动态内容时存在信息泄漏和模糊重建的挑战，需要更有效的解决方案。

Method: DiViD通过序列编码器提取全局静态令牌和每帧动态令牌，并利用条件DDPM解码器结合共享噪声计划、时间变化的KL瓶颈和交叉注意力机制。

Result: DiViD在真实世界基准测试中表现优于现有方法，实现了最高的交换联合准确度，同时保持静态保真度和减少交叉泄漏。

Conclusion: DiViD通过显式静态-动态分解和创新的正则化方法，显著提升了视频中静态和动态内容的分离效果。

Abstract: Unsupervised disentanglement of static appearance and dynamic motion in video
remains a fundamental challenge, often hindered by information leakage and
blurry reconstructions in existing VAE- and GAN-based approaches. We introduce
DiViD, the first end-to-end video diffusion framework for explicit
static-dynamic factorization. DiViD's sequence encoder extracts a global static
token from the first frame and per-frame dynamic tokens, explicitly removing
static content from the motion code. Its conditional DDPM decoder incorporates
three key inductive biases: a shared-noise schedule for temporal consistency, a
time-varying KL-based bottleneck that tightens at early timesteps (compressing
static information) and relaxes later (enriching dynamics), and cross-attention
that routes the global static token to all frames while keeping dynamic tokens
frame-specific. An orthogonality regularizer further prevents residual
static-dynamic leakage. We evaluate DiViD on real-world benchmarks using
swap-based accuracy and cross-leakage metrics. DiViD outperforms
state-of-the-art sequential disentanglement methods: it achieves the highest
swap-based joint accuracy, preserves static fidelity while improving dynamic
transfer, and reduces average cross-leakage.

</details>


### [136] [Evaluation of Human Visual Privacy Protection: A Three-Dimensional Framework and Benchmark Dataset](https://arxiv.org/abs/2507.13981)
*Sara Abdulaziz,Giacomo D'Amicantonio,Egor Bondarev*

Main category: cs.CV

TL;DR: 该论文提出了一个评估视觉隐私保护方法的框架，并引入了HR-VISPR数据集，用于训练可解释的隐私度量。通过评估11种隐私保护方法，分析了隐私、实用性和实用性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着AI监控技术的发展，对敏感个人数据的收集和处理引发了隐私担忧，因此需要客观的隐私保护评估方法。

Method: 提出了一个三维评估框架（隐私、实用性、实用性），并引入HR-VISPR数据集，用于训练隐私度量。评估了11种隐私保护方法。

Result: 框架能够区分隐私级别，并揭示隐私、实用性和实用性之间的权衡。HR-VISPR数据集为隐私保护研究提供了工具。

Conclusion: 该研究提供了一个结构化的评估框架和数据集，适用于多种隐私保护场景。

Abstract: Recent advances in AI-powered surveillance have intensified concerns over the
collection and processing of sensitive personal data. In response, research has
increasingly focused on privacy-by-design solutions, raising the need for
objective techniques to evaluate privacy protection. This paper presents a
comprehensive framework for evaluating visual privacy-protection methods across
three dimensions: privacy, utility, and practicality. In addition, it
introduces HR-VISPR, a publicly available human-centric dataset with biometric,
soft-biometric, and non-biometric labels to train an interpretable privacy
metric. We evaluate 11 privacy protection methods, ranging from conventional
techniques to advanced deep-learning methods, through the proposed framework.
The framework differentiates privacy levels in alignment with human visual
perception, while highlighting trade-offs between privacy, utility, and
practicality. This study, along with the HR-VISPR dataset, serves as an
insightful tool and offers a structured evaluation framework applicable across
diverse contexts.

</details>


### [137] [DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation](https://arxiv.org/abs/2507.13985)
*Haoran Li,Yuli Tian,Kun Lan,Yong Liao,Lin Wang,Pan Hui,Peng Yuan Zhou*

Main category: cs.CV

TL;DR: DreamScene是一个端到端框架，通过文本或对话生成高质量、可编辑的3D场景，解决了现有方法在自动化、3D一致性和细粒度控制方面的不足。


<details>
  <summary>Details</summary>
Motivation: 从自然语言生成3D场景在游戏、电影和设计中有广泛应用前景，但现有方法在自动化、一致性和控制方面存在挑战。

Method: DreamScene结合场景规划模块（GPT-4代理推断对象语义和空间约束）、图布局算法、几何生成（FPS）和渐进相机采样策略，支持细粒度编辑。

Result: 实验表明，DreamScene在质量、一致性和灵活性上优于现有方法。

Conclusion: DreamScene为开放域3D内容创作提供了实用解决方案。

Abstract: Generating 3D scenes from natural language holds great promise for
applications in gaming, film, and design. However, existing methods struggle
with automation, 3D consistency, and fine-grained control. We present
DreamScene, an end-to-end framework for high-quality and editable 3D scene
generation from text or dialogue. DreamScene begins with a scene planning
module, where a GPT-4 agent infers object semantics and spatial constraints to
construct a hybrid graph. A graph-based placement algorithm then produces a
structured, collision-free layout. Based on this layout, Formation Pattern
Sampling (FPS) generates object geometry using multi-timestep sampling and
reconstructive optimization, enabling fast and realistic synthesis. To ensure
global consistent, DreamScene employs a progressive camera sampling strategy
tailored to both indoor and outdoor settings. Finally, the system supports
fine-grained scene editing, including object movement, appearance changes, and
4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior
methods in quality, consistency, and flexibility, offering a practical solution
for open-domain 3D content creation. Code and demos are available at
https://dreamscene-project.github.io.

</details>


### [138] [Automatic Classification and Segmentation of Tunnel Cracks Based on Deep Learning and Visual Explanations](https://arxiv.org/abs/2507.14010)
*Yong Feng,Xiaolei Zhang,Shijin Feng,Yong Zhao,Yihan Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度学习的两步法，用于隧道裂缝的分类和分割，结合DenseNet-169和DeepLabV3+模型，显著提高了检测精度和效率。


<details>
  <summary>Details</summary>
Motivation: 隧道裂缝是隧道安全状态的重要指标，需要一种高效且准确的方法进行分类和分割。

Method: 研究采用两步法：第一步使用DenseNet-169进行隧道图像分类；第二步基于DeepLabV3+进行裂缝分割，并通过可视化技术评估模型内部逻辑。

Result: 分类模型准确率达92.23%，FPS为39.80；分割模型的IoU和F1分数分别为57.01%和67.44%，均优于其他先进模型。

Conclusion: 该方法为隧道健康状态的快速准确评估提供了基础，并通过可视化技术增强了深度学习模型的可解释性。

Abstract: Tunnel lining crack is a crucial indicator of tunnels' safety status. Aiming
to classify and segment tunnel cracks with enhanced accuracy and efficiency,
this study proposes a two-step deep learning-based method. An automatic tunnel
image classification model is developed using the DenseNet-169 in the first
step. The proposed crack segmentation model in the second step is based on the
DeepLabV3+, whose internal logic is evaluated via a score-weighted visual
explanation technique. Proposed method combines tunnel image classification and
segmentation together, so that the selected images containing cracks from the
first step are segmented in the second step to improve the detection accuracy
and efficiency. The superior performances of the two-step method are validated
by experiments. The results show that the accuracy and frames per second (FPS)
of the tunnel crack classification model are 92.23% and 39.80, respectively,
which are higher than other convolutional neural networks (CNN) based and
Transformer based models. Also, the intersection over union (IoU) and F1 score
of the tunnel crack segmentation model are 57.01% and 67.44%, respectively,
outperforming other state-of-the-art models. Moreover, the provided visual
explanations in this study are conducive to understanding the "black box" of
deep learning-based models. The developed two-stage deep learning-based method
integrating visual explanations provides a basis for fast and accurate
quantitative assessment of tunnel health status.

</details>


### [139] [Analysis of Plant Nutrient Deficiencies Using Multi-Spectral Imaging and Optimized Segmentation Model](https://arxiv.org/abs/2507.14013)
*Ji-Yan Wu,Zheng Yong Poh,Anoop C. Patil,Bongsoo Park,Giovanni Volpe,Daisuke Urano*

Main category: cs.CV

TL;DR: 提出了一种基于多光谱成像和增强YOLOv5模型的深度学习框架，用于植物叶片异常分割，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 精准农业需要早期检测植物叶片营养缺乏，以实现及时干预施肥、疾病和压力管理。

Method: 使用多光谱成像和带有Transformer注意力头的增强YOLOv5模型，处理九通道输入并利用自注意力机制捕捉细微症状。

Result: 模型在Dice分数和IoU上平均提升约12%，尤其在检测黄化和色素积累等挑战性症状上表现优异。

Conclusion: 结合多光谱成像与光谱-空间特征学习，为植物表型和精准农业提供了有前景的解决方案。

Abstract: Accurate detection of nutrient deficiency in plant leaves is essential for
precision agriculture, enabling early intervention in fertilization, disease,
and stress management. This study presents a deep learning framework for leaf
anomaly segmentation using multispectral imaging and an enhanced YOLOv5 model
with a transformer-based attention head. The model is tailored for processing
nine-channel multispectral input and uses self-attention mechanisms to better
capture subtle, spatially-distributed symptoms. The plants in the experiments
were grown under controlled nutrient stress conditions for evaluation. We carry
out extensive experiments to benchmark the proposed model against the baseline
YOLOv5. Extensive experiments show that the proposed model significantly
outperforms the baseline YOLOv5, with an average Dice score and IoU
(Intersection over Union) improvement of about 12%. In particular, this model
is effective in detecting challenging symptoms like chlorosis and pigment
accumulation. These results highlight the promise of combining multi-spectral
imaging with spectral-spatial feature learning for advancing plant phenotyping
and precision agriculture.

</details>


### [140] [Moodifier: MLLM-Enhanced Emotion-Driven Image Editing](https://arxiv.org/abs/2507.14024)
*Jiarong Ye,Sharon X. Huang*

Main category: cs.CV

TL;DR: 提出了一种情绪驱动的图像编辑方法，包括数据集MoodArchive、模型MoodifyCLIP和编辑工具Moodifier，实现了情绪到视觉属性的精确转换。


<details>
  <summary>Details</summary>
Motivation: 情绪驱动的图像编辑在创意产业潜力巨大，但因情绪的抽象性和多样性而难以精确操控。

Method: 1. 构建MoodArchive数据集；2. 开发MoodifyCLIP模型；3. 提出无需训练的Moodifier编辑工具。

Result: Moodifier在情绪准确性和内容保留上优于现有方法，适用于多种领域。

Conclusion: 通过将抽象情绪与具体视觉变化关联，为实际应用中的情绪内容创作提供了新可能。

Abstract: Bridging emotions and visual content for emotion-driven image editing holds
great potential in creative industries, yet precise manipulation remains
challenging due to the abstract nature of emotions and their varied
manifestations across different contexts. We tackle this challenge with an
integrated approach consisting of three complementary components. First, we
introduce MoodArchive, an 8M+ image dataset with detailed hierarchical
emotional annotations generated by LLaVA and partially validated by human
evaluators. Second, we develop MoodifyCLIP, a vision-language model fine-tuned
on MoodArchive to translate abstract emotions into specific visual attributes.
Third, we propose Moodifier, a training-free editing model leveraging
MoodifyCLIP and multimodal large language models (MLLMs) to enable precise
emotional transformations while preserving content integrity. Our system works
across diverse domains such as character expressions, fashion design, jewelry,
and home d\'ecor, enabling creators to quickly visualize emotional variations
while preserving identity and structure. Extensive experimental evaluations
show that Moodifier outperforms existing methods in both emotional accuracy and
content preservation, providing contextually appropriate edits. By linking
abstract emotions to concrete visual changes, our solution unlocks new
possibilities for emotional content creation in real-world applications. We
will release the MoodArchive dataset, MoodifyCLIP model, and make the Moodifier
code and demo publicly available upon acceptance.

</details>


### [141] [QuantEIT: Ultra-Lightweight Quantum-Assisted Inference for Chest Electrical Impedance Tomography](https://arxiv.org/abs/2507.14031)
*Hao Fang,Sihao Teng,Hao Yu,Siyi Yuan,Huaiwu He,Zhe Liu,Yunjie Yang*

Main category: cs.CV

TL;DR: 提出了一种名为QuantEIT的超轻量级量子辅助推理框架，用于EIT图像重建，显著降低模型复杂度，并在无监督、无需训练数据的情况下实现高精度重建。


<details>
  <summary>Details</summary>
Motivation: EIT作为一种低成本、高时间分辨率的床边成像技术，其逆问题的不适定性限制了图像重建的准确性。现有深度学习方法依赖复杂网络结构，效率低且难以扩展。

Method: QuantEIT采用量子辅助网络（QA-Net），结合并行2量子比特电路生成潜在表示，并通过单层线性层重建电导率，无需训练数据。

Result: 在模拟和真实2D/3D EIT肺部成像数据上，QuantEIT仅用0.2%的参数即优于传统方法，且对噪声更具鲁棒性。

Conclusion: QuantEIT首次将量子电路集成到EIT图像重建中，为高效、轻量化的EIT成像提供了新思路。

Abstract: Electrical Impedance Tomography (EIT) is a non-invasive, low-cost bedside
imaging modality with high temporal resolution, making it suitable for bedside
monitoring. However, its inherently ill-posed inverse problem poses significant
challenges for accurate image reconstruction. Deep learning (DL)-based
approaches have shown promise but often rely on complex network architectures
with a large number of parameters, limiting efficiency and scalability. Here,
we propose an Ultra-Lightweight Quantum-Assisted Inference (QuantEIT) framework
for EIT image reconstruction. QuantEIT leverages a Quantum-Assisted Network
(QA-Net), combining parallel 2-qubit quantum circuits to generate expressive
latent representations that serve as implicit nonlinear priors, followed by a
single linear layer for conductivity reconstruction. This design drastically
reduces model complexity and parameter number. Uniquely, QuantEIT operates in
an unsupervised, training-data-free manner and represents the first integration
of quantum circuits into EIT image reconstruction. Extensive experiments on
simulated and real-world 2D and 3D EIT lung imaging data demonstrate that
QuantEIT outperforms conventional methods, achieving comparable or superior
reconstruction accuracy using only 0.2% of the parameters, with enhanced
robustness to noise.

</details>


### [142] [Training-free Token Reduction for Vision Mamba](https://arxiv.org/abs/2507.14042)
*Qiankun Ma,Ziyao Zhang,Chi Su,Jie Chen,Zhen Song,Hairong Zheng,Wen Gao*

Main category: cs.CV

TL;DR: Vision Mamba的MTR框架通过Mamba结构感知的重要性评分实现无需训练的token压缩，显著降低计算量且性能影响小。


<details>
  <summary>Details</summary>
Motivation: 探索Vision Mamba的效率以扩展其应用，发现直接应用ViTs的token压缩技术会导致性能下降，需针对Mamba的特性设计新方法。

Method: 提出Mamba结构感知的重要性评分，并基于此设计无需训练的MTR框架，作为即插即用组件。

Result: MTR在Vim-B骨干上减少约40% FLOPs，ImageNet性能仅下降1.6%，无需重新训练。

Conclusion: MTR为Vision Mamba提供了一种高效、无需训练的token压缩方案，适用于多种任务和骨干网络。

Abstract: Vision Mamba has emerged as a strong competitor to Vision Transformers (ViTs)
due to its ability to efficiently capture long-range dependencies with linear
computational complexity. While token reduction, an effective compression
technique in ViTs, has rarely been explored in Vision Mamba. Exploring Vision
Mamba's efficiency is essential for enabling broader applications. However, we
find that directly applying existing token reduction techniques for ViTs to
Vision Mamba leads to significant performance degradation. This is primarily
because Mamba is a sequence model without attention mechanisms, whereas most
token reduction techniques for ViTs rely on attention mechanisms for importance
measurement and overlook the order of compressed tokens. In this paper, we
investigate a Mamba structure-aware importance score to evaluate token
importance in a simple and effective manner. Building on this score, we further
propose MTR, a training-free \textbf{M}amba \textbf{T}oken \textbf{R}eduction
framework. Without the need for training or additional tuning parameters, our
method can be seamlessly integrated as a plug-and-play component across various
Mamba models. Extensive experiments demonstrate that our approach significantly
reduces computational workload while minimizing performance impact across
various tasks and multiple backbones. Notably, MTR reduces FLOPs by
approximately 40\% on the Vim-B backbone, with only a 1.6\% drop in ImageNet
performance without retraining.

</details>


### [143] [Foundation Models as Class-Incremental Learners for Dermatological Image Classification](https://arxiv.org/abs/2507.14050)
*Mohamed Elkhayat,Mohamed Mahmoud,Jamil Fayyad,Nourhan Bayasi*

Main category: cs.CV

TL;DR: 论文提出了一种基于冻结基础模型（FM）的类增量学习方法，用于皮肤病分类，通过轻量级MLP增量训练，实现了无需遗忘的先进性能。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在皮肤病分类中的增量学习潜力，填补现有研究空白。

Method: 冻结预训练FM，仅增量训练轻量级MLP；同时探索零训练场景下的原型分类方法。

Result: 方法在无需遗忘的情况下达到先进性能，原型分类也表现优异。

Conclusion: 冻结FM在皮肤病增量学习中表现强大，支持其在医疗领域的广泛应用。

Abstract: Class-Incremental Learning (CIL) aims to learn new classes over time without
forgetting previously acquired knowledge. The emergence of foundation models
(FM) pretrained on large datasets presents new opportunities for CIL by
offering rich, transferable representations. However, their potential for
enabling incremental learning in dermatology remains largely unexplored. In
this paper, we systematically evaluate frozen FMs pretrained on large-scale
skin lesion datasets for CIL in dermatological disease classification. We
propose a simple yet effective approach where the backbone remains frozen, and
a lightweight MLP is trained incrementally for each task. This setup achieves
state-of-the-art performance without forgetting, outperforming regularization,
replay, and architecture based methods. To further explore the capabilities of
frozen FMs, we examine zero training scenarios using nearest mean classifiers
with prototypes derived from their embeddings. Through extensive ablation
studies, we demonstrate that this prototype based variant can also achieve
competitive results. Our findings highlight the strength of frozen FMs for
continual learning in dermatology and support their broader adoption in real
world medical applications. Our code and datasets are available here.

</details>


### [144] [Unmasking Performance Gaps: A Comparative Study of Human Anonymization and Its Effects on Video Anomaly Detection](https://arxiv.org/abs/2507.14083)
*Sara Abdulaziz,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文分析了四种人类匿名化技术对异常检测性能的影响，发现某些匿名化方法甚至能提升检测性能，同时探讨了隐私保护与检测效用的权衡。


<details>
  <summary>Details</summary>
Motivation: 深度学习在监控视频异常检测中的应用引发了隐私问题，研究旨在评估匿名化技术对检测性能的影响。

Method: 在UCF-Crime数据集上应用四种匿名化技术（模糊、掩码、加密、虚拟人替换），并评估四种异常检测方法的性能。

Result: 实验表明，匿名化数据下异常检测仍可行，某些匿名化模式（如加密和掩码）甚至能提升部分模型的AUC性能。

Conclusion: 研究揭示了算法对匿名化的敏感性，并强调了隐私保护与检测效用之间的权衡，为未来平衡隐私与检测需求提供了参考。

Abstract: Advancements in deep learning have improved anomaly detection in surveillance
videos, yet they raise urgent privacy concerns due to the collection of
sensitive human data. In this paper, we present a comprehensive analysis of
anomaly detection performance under four human anonymization techniques,
including blurring, masking, encryption, and avatar replacement, applied to the
UCF-Crime dataset. We evaluate four anomaly detection methods, MGFN, UR-DMU,
BN-WVAD, and PEL4VAD, on the anonymized UCF-Crime to reveal how each method
responds to different obfuscation techniques. Experimental results demonstrate
that anomaly detection remains viable under anonymized data and is dependent on
the algorithmic design and the learning strategy. For instance, under certain
anonymization patterns, such as encryption and masking, some models
inadvertently achieve higher AUC performance compared to raw data, due to the
strong responsiveness of their algorithmic components to these noise patterns.
These results highlight the algorithm-specific sensitivities to anonymization
and emphasize the trade-off between preserving privacy and maintaining
detection utility. Furthermore, we compare these conventional anonymization
techniques with the emerging privacy-by-design solutions, highlighting an often
overlooked trade-off between robust privacy protection and utility flexibility.
Through comprehensive experiments and analyses, this study provides a
compelling benchmark and insights into balancing human privacy with the demands
of anomaly detection.

</details>


### [145] [C-DOG: Training-Free Multi-View Multi-Object Association in Dense Scenes Without Visual Feature via Connected δ-Overlap Graphs](https://arxiv.org/abs/2507.14095)
*Yung-Hong Sun,Ting-Hung Lin,Jiangang Chen,Hongrui Jiang,Yu Hen Hu*

Main category: cs.CV

TL;DR: C-DOG是一种无需训练的框架，通过结合连接增量重叠图和极线几何，在多视图多目标关联中实现鲁棒性，适用于噪声和视觉不可区分场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在视觉不可区分或噪声干扰下失效的问题，提出一种不依赖视觉特征的多目标关联方法。

Method: 结合连接增量重叠图建模与极线几何，通过图节点表示2D观测，边权重由极线一致性决定，并采用增量邻居重叠聚类和IQR过滤提高鲁棒性。

Result: 在合成基准测试中，C-DOG优于基于几何的基线方法，并在高目标密度、无视觉特征和有限相机重叠等挑战下表现稳健。

Conclusion: C-DOG适用于实际场景中的可扩展3D重建，尤其在噪声和视觉不可区分条件下表现优异。

Abstract: Multi-view multi-object association is a fundamental step in 3D
reconstruction pipelines, enabling consistent grouping of object instances
across multiple camera views. Existing methods often rely on appearance
features or geometric constraints such as epipolar consistency. However, these
approaches can fail when objects are visually indistinguishable or observations
are corrupted by noise. We propose C-DOG, a training-free framework that serves
as an intermediate module bridging object detection (or pose estimation) and 3D
reconstruction, without relying on visual features. It combines connected
delta-overlap graph modeling with epipolar geometry to robustly associate
detections across views. Each 2D observation is represented as a graph node,
with edges weighted by epipolar consistency. A delta-neighbor-overlap
clustering step identifies strongly consistent groups while tolerating noise
and partial connectivity. To further improve robustness, we incorporate
Interquartile Range (IQR)-based filtering and a 3D back-projection error
criterion to eliminate inconsistent observations. Extensive experiments on
synthetic benchmarks demonstrate that C-DOG outperforms geometry-based
baselines and remains robust under challenging conditions, including high
object density, without visual features, and limited camera overlap, making it
well-suited for scalable 3D reconstruction in real-world scenarios.

</details>


### [146] [Franca: Nested Matryoshka Clustering for Scalable Visual Representation Learning](https://arxiv.org/abs/2507.14137)
*Shashanka Venkataramanan,Valentinos Pariza,Mohammadreza Salehi,Lukas Knobel,Spyros Gidaris,Elias Ramzi,Andrei Bursuc,Yuki M. Asano*

Main category: cs.CV

TL;DR: Franca是首个完全开源（数据、代码、权重）的视觉基础模型，性能媲美甚至超越现有专有模型。通过透明训练流程和多头聚类投影器设计，解决了SSL聚类方法的局限性，并提出了位置解耦策略，提升了语义编码效果。


<details>
  <summary>Details</summary>
Motivation: 当前视觉基础模型多为专有，缺乏透明性。Franca旨在提供开源高性能模型，并解决SSL聚类方法的固有模糊性问题。

Method: 采用透明训练流程，基于公开数据（ImageNet-21K和ReLAION-2B子集）。引入多头聚类投影器和位置解耦策略，优化特征空间。

Result: 在多个下游基准测试中表现优异，性能超越专有模型（如DINOv2、CLIP等）。

Conclusion: Franca为透明、高性能视觉模型设定了新标准，推动了可复现和通用基础模型的发展。

Abstract: We present Franca (pronounced Fran-ka): free one; the first fully open-source
(data, code, weights) vision foundation model that matches and in many cases
surpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,
CLIP, SigLIPv2, etc. Our approach is grounded in a transparent training
pipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and
a subset of ReLAION-2B. Beyond model release, we tackle critical limitations in
SSL clustering methods. While modern models rely on assigning image features to
large codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to
account for the inherent ambiguity in clustering semantics. To address this, we
introduce a parameter-efficient, multi-head clustering projector based on
nested Matryoshka representations. This design progressively refines features
into increasingly fine-grained clusters without increasing the model size,
enabling both performance and memory efficiency. Additionally, we propose a
novel positional disentanglement strategy that explicitly removes positional
biases from dense representations, thereby improving the encoding of semantic
content. This leads to consistent gains on several downstream benchmarks,
demonstrating the utility of cleaner feature spaces. Our contributions
establish a new standard for transparent, high-performance vision models and
open a path toward more reproducible and generalizable foundation models for
the broader AI community. The code and model checkpoints are available at
https://github.com/valeoai/Franca.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [147] [CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation](https://arxiv.org/abs/2507.13710)
*Jing Chang,Chang Liu,Jinbin Huang,Rui Mao,Jianbin Qin*

Main category: cs.DB

TL;DR: 论文提出CogniQ-H框架，利用软层次强化学习优化数据准备流程，结合LLM和LTR模型，显著提升效率和质量。


<details>
  <summary>Details</summary>
Motivation: 数据准备是机器学习生命周期中基础但复杂的环节，现有强化学习方法效率低，未充分利用问题的层次结构。

Method: 采用软层次强化学习（HRL），结合LLM生成的高层策略先验、LTR模型的细粒度操作评分和Q函数的长远价值估计。

Result: 在18个数据集上，CogniQ-H比现有RL方法提升13.9%的流程质量，收敛速度快2.8倍。

Conclusion: CogniQ-H通过软层次结构和混合架构，有效平衡策略指导和适应性决策，显著提升数据准备效率。

Abstract: Data preparation is a foundational yet notoriously challenging component of
the machine learning lifecycle, characterized by a vast combinatorial search
space of potential operator sequences. While reinforcement learning (RL) offers
a promising direction, existing approaches are inefficient as they fail to
capture the structured, hierarchical nature of the problem. We argue that
Hierarchical Reinforcement Learning (HRL), a paradigm that has been successful
in other domains, provides a conceptually ideal yet previously unexplored
framework for this task. However, a naive HRL implementation with a `hard
hierarchy' is prone to suboptimal, irreversible decisions. To address this, we
introduce CogniQ-H, the first framework to implement a soft hierarchical
paradigm for robust, end-to-end automated data preparation. CogniQ-H formulates
action selection as a Bayesian inference problem. A high-level strategic prior,
generated by a Large Language Model (LLM), guides exploration
probabilistically. This prior is synergistically combined with a fine-grained
operator quality score from a supervised Learning-to-Rank (LTR) model and a
long-term value estimate from the agent's own Q-function. This hybrid
architecture allows CogniQ-H to balance strategic guidance with adaptive,
evidence-based decision-making. Through extensive experiments on 18 diverse
datasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to
13.9\% improvement in pipeline quality and 2.8$\times$ faster convergence
compared to state-of-the-art RL-based methods.

</details>


### [148] [LLaPipe: LLM-Guided Reinforcement Learning for Automated Data Preparation Pipeline Construction](https://arxiv.org/abs/2507.13712)
*Jing Chang,Chang Liu,Jinbin Huang,Rui Mao,Jianbin Qin*

Main category: cs.DB

TL;DR: LLaPipe利用大型语言模型（LLMs）作为智能策略顾问，提升数据预处理管道的探索效率，相比传统RL方法，性能提升22.4%，收敛速度加快2.3倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习（RL）的数据预处理方法在庞大的管道空间中探索效率低下，限制了机器学习的普及。

Method: LLaPipe框架结合LLMs的语义理解能力，提出三个创新：LLM策略顾问、经验蒸馏机制和自适应触发策略。

Result: 在18个数据集上的实验表明，LLaPipe性能提升22.4%，收敛速度加快2.3倍，且计算效率高。

Conclusion: LLaPipe通过智能LLM干预，显著提升了数据预处理管道的探索效率和质量。

Abstract: Automated data preparation is crucial for democratizing machine learning, yet
existing reinforcement learning (RL) based approaches suffer from inefficient
exploration in the vast space of possible preprocessing pipelines. We present
LLaPipe, a novel framework that addresses this exploration bottleneck by
integrating Large Language Models (LLMs) as intelligent policy advisors. Unlike
traditional methods that rely solely on statistical features and blind
trial-and-error, LLaPipe leverages the semantic understanding capabilities of
LLMs to provide contextually relevant exploration guidance. Our framework
introduces three key innovations: (1) an LLM Policy Advisor that analyzes
dataset semantics and pipeline history to suggest promising preprocessing
operations, (2) an Experience Distillation mechanism that mines successful
patterns from past pipelines and transfers this knowledge to guide future
exploration, and (3) an Adaptive Advisor Triggering strategy
(Advisor\textsuperscript{+}) that dynamically determines when LLM intervention
is most beneficial, balancing exploration effectiveness with computational
cost. Through extensive experiments on 18 diverse datasets spanning multiple
domains, we demonstrate that LLaPipe achieves up to 22.4\% improvement in
pipeline quality and 2.3$\times$ faster convergence compared to
state-of-the-art RL-based methods, while maintaining computational efficiency
through selective LLM usage (averaging only 19.0\% of total exploration steps).

</details>


### [149] [Efficient and Scalable Self-Healing Databases Using Meta-Learning and Dependency-Driven Recovery](https://arxiv.org/abs/2507.13757)
*Joydeep Chandra,Prabal Manhas*

Main category: cs.DB

TL;DR: 提出了一种结合元学习和强化学习的自愈数据库框架，解决动态工作负载环境中的实时适应性和最小化再训练问题。


<details>
  <summary>Details</summary>
Motivation: 解决动态工作负载环境下数据库的实时适应性和最小化再训练挑战。

Method: 整合MAML与强化学习，结合多目标优化、GNNs、合成任务增强和自监督学习，并引入可解释AI和联邦元学习。

Result: 显著提升了适应性、效率和可靠性。

Conclusion: 该框架为数据库管理和自愈系统提供了重要进展。

Abstract: This study explored the development of a novel self-healing framework for
databases using meta-learning and reinforcement learning techniques. The
primary objective was to address the challenges of real-time adaptability and
minimal retraining in dynamic workload environments. The proposed approach
integrated Model-Agnostic Meta-Learning (MAML) with reinforcement learning to
enable anomaly detection and corrective actions that adapted swiftly to
evolving database conditions. Multi-objective optimization was employed to
balance performance, resource utilization, and cost efficiency during the
healing process. Graph Neural Networks (GNNs) were incorporated to model
interdependencies within database components, ensuring holistic recovery
strategies. Data efficiency was enhanced through synthetic task augmentation
and self-supervised learning, enabling effective training in sparse data
regimes. To promote trust and transparency, explainable AI techniques were
integrated to provide interpretable insights into anomaly detection and healing
actions. Federated meta-learning further enabled privacy-preserving
adaptability in distributed database environments. The framework demonstrated
significant improvements in adaptability, efficiency, and reliability,
contributing to advancements in database management and self-healing systems.

</details>


### [150] [Towards Next Generation Data Engineering Pipelines](https://arxiv.org/abs/2507.13892)
*Kevin M. Kramer,Valerie Restat,Sebastian Strasser,Uta Störl,Meike Klettke*

Main category: cs.DB

TL;DR: 论文探讨了下一代数据工程管道的三个层次：优化、自我感知和自我适应，以解决当前管道在数据质量和反应性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前数据工程管道在数据质量和应对变化方面存在不足，需要改进以提高效率和可靠性。

Method: 提出了三个层次的解决方案：优化管道、自我感知管道和自我适应管道，分别解决操作优化、状态监控和自动反应问题。

Result: 通过优化、监控和自动适应，下一代管道能够提高数据质量并应对数据变化。

Conclusion: 下一代数据工程管道通过优化、自我感知和自我适应，能够显著提升数据处理的效率和可靠性。

Abstract: Data engineering pipelines are a widespread way to provide high-quality data
for all kinds of data science applications. However, numerous challenges still
remain in the composition and operation of such pipelines. Data engineering
pipelines do not always deliver high-quality data. By default, they are also
not reactive to changes. When new data is coming in which deviates from prior
data, the pipeline could crash or output undesired results. We therefore
envision three levels of next generation data engineering pipelines: optimized
data pipelines, self-aware data pipelines, and self-adapting data pipelines.
Pipeline optimization addresses the composition of operators and their
parametrization in order to achieve the highest possible data quality.
Self-aware data engineering pipelines enable a continuous monitoring of its
current state, notifying data engineers on significant changes. Self-adapting
data engineering pipelines are then even able to automatically react to those
changes. We propose approaches to achieve each of these levels.

</details>


### [151] [Project-connex Decompositions and Tractability of Aggregate Group-by Conjunctive Queries](https://arxiv.org/abs/2507.14101)
*Diego Figueira,Cibele Freire*

Main category: cs.DB

TL;DR: 论文提出了一种名为'project-connex'树宽的新度量，用于衡量带有'group-by'投影的半环聚合查询的易处理性，并统一了多种查询评估的复杂性分析。


<details>
  <summary>Details</summary>
Motivation: 旨在为半环聚合查询、枚举算法和计数查询提供统一的易处理性度量，简化现有复杂性分析。

Method: 通过扩展'free-connex'分解定义'project-connex'树分解，并利用经典树分解算法实现。

Result: 证明了该度量能统一解释现有易处理性结果，并恢复与计数查询和枚举查询相关的复杂性结论。

Conclusion: 'project-connex'树宽为半环聚合查询的易处理性提供了简单直观的度量，并扩展了现有理论框架。

Abstract: We introduce 'project-connex' tree-width as a measure of tractability for
counting and aggregate conjunctive queries over semirings with 'group-by'
projection (also known as 'AJAR' or 'FAQ' queries). This elementary measure
allows to obtain comparable complexity bounds to the ones obtained by previous
structural conditions tailored for efficient evaluation of semiring aggregate
queries, enumeration algorithms of conjunctive queries, and tractability of
counting answers to conjunctive queries.
  Project-connex tree decompositions are defined as the natural extension of
the known notion of 'free-connex' decompositions. They allow for a unified,
simple and intuitive algorithmic manipulation for evaluation of aggregate
queries and explain some existing tractability results on conjunctive query
enumeration, counting conjunctive query evaluation, and evaluation of semiring
aggregate queries. Using this measure we also recover results relating
tractable classes of counting conjunctive queries and bounded free-connex
tree-width, or the constant-time delay enumeration of semiring aggregate
queries over bounded project-connex classes. We further show that
project-connex tree decompositions can be obtained via algorithms for computing
classical tree decompositions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [152] [Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication](https://arxiv.org/abs/2507.13522)
*Ankit Bhardwaj,Weiyang Wang,Jeremy Carin,Adam Belay,Manya Ghobadi*

Main category: cs.DC

TL;DR: Checkmate系统通过梯度多播实现无训练减速的DNN训练每迭代检查点，显著提升检查点频率和效率。


<details>
  <summary>Details</summary>
Motivation: 传统检查点方法需暂停训练以保存模型状态，存在检查点频率与失败成本之间的权衡。Checkmate旨在消除这一权衡。

Method: 利用数据并行训练中的梯度信息，通过多播抽象将梯度同时传递给CPU影子集群，影子集群通过应用梯度维护检查点。

Result: Checkmate实现每迭代检查点，训练吞吐量与无检查点基线相当，检查点频率提升5至34.5倍，重复工作减少80%至97.1%。

Conclusion: Checkmate在相同检查点频率下，吞吐量比其他系统高1.3至6.5倍，显著优化了DNN训练检查点效率。

Abstract: This paper presents Checkmate, a system that enables per-iteration
checkpointing in DNN training without any training slowdown. The traditional
approach to checkpointing requires a pause in training to copy model states to
a separate location, allowing the state to be restored in the event of failure.
This approach fundamentally has a tradeoff between the frequency of checkpoints
and the cost of a failure. We avoid this tradeoff; our key insight is that in
data-parallel training, all information necessary to create a checkpoint
already exists in the network as gradients. Our core contribution is a new
multicast abstraction that simultaneously delivers gradients to a separate
CPU-based shadow cluster. The shadow maintains a checkpoint by applying those
gradients to a copy of the model. Our evaluation shows that Checkmate performs
per-iteration checkpointing with training throughput comparable to an ideal
no-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent
checkpointing compared to state-of-the-art checkpointing systems, resulting in
80% to 97.1% reduction in repeated work per failure. At the same checkpointing
frequency, Checkmate delivers 1.3x to 6.5x throughput compared to other
systems.

</details>


### [153] [Leveraging Multi-Instance GPUs through moldable task scheduling](https://arxiv.org/abs/2507.13601)
*Jorge Villarrubia,Luis Costero,Francisco D. Igual,Katzalin Olcoz*

Main category: cs.DC

TL;DR: 本文提出了一种名为FAR的三阶段算法，用于在NVIDIA MIG技术下最小化多任务执行的总完成时间（makespan），并通过实验验证了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: NVIDIA MIG技术允许动态分区GPU资源，但现有调度方法未充分利用其潜力，尤其是在任务资源需求非单调的情况下。本文旨在填补这一空白。

Method: FAR算法分为三个阶段：1）基于经典任务可塑性方法；2）结合LPT和List Scheduling，并引入针对MIG约束的重新分区树启发式；3）通过任务移动和交换进行局部搜索。

Result: 实验显示，FAR在不考虑重新配置成本时，在NVIDIA A30上的近似因子为7/4，在A100/H100上为2。考虑重新配置成本后，实际性能接近最优（1.22x-1.10x）。

Conclusion: FAR算法显著优于现有方法，同时展示了MIG技术的研究潜力，并为未来工作提供了有用的指标和方法。

Abstract: NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into
multiple logical instances with fully-isolated resources, which can be
dynamically reconfigured. This work highlights the untapped potential of MIG
through moldable task scheduling with dynamic reconfigurations. Specifically,
we propose a makespan minimization problem for multi-task execution under MIG
constraints. Our profiling shows that assuming monotonicity in task work with
respect to resources is not viable, as is usual in multicore scheduling.
Relying on a state-of-the-art proposal that does not require such an
assumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1
of FAR builds on a classical task moldability method, phase 2 combines Longest
Processing Time First and List Scheduling with a novel repartitioning tree
heuristic tailored to MIG constraints, and phase 3 employs local search via
task moves and swaps. FAR schedules tasks in batches offline, concatenating
their schedules on the fly in an improved way that favors resource reuse.
Excluding reconfiguration costs, the List Scheduling proof shows an
approximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to
the particular constraints of an NVIDIA A100/H100 to obtain an approximation
factor of 2. Including the reconfiguration cost, our real-world experiments
reveal a makespan with respect to the optimum no worse than 1.22x for a
well-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real
kernels. We obtain good experimental results for each batch of tasks, but also
in the concatenation of batches, with large improvements over the
state-of-the-art and proposals without GPU reconfiguration. Beyond the
algorithm, the paper demonstrates the research potential of the MIG technology
and suggests useful metrics, workload characterizations and evaluation
techniques for future work in this field.

</details>


### [154] [DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training](https://arxiv.org/abs/2507.13833)
*Zhixin Wang,Tianyi Zhou,Liming Liu,Ao Li,Jiarui Hu,Dian Yang,Jinlong Hou,Siyuan Feng,Yuan Cheng,Yuan Qi*

Main category: cs.DC

TL;DR: DistFlow是一种新型分布式强化学习框架，通过多控制器架构消除集中节点，实现近线性扩展和高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模强化学习中负载不平衡导致的扩展瓶颈问题。

Method: 采用多控制器范式，将数据传输和执行任务分配给所有工作节点，解耦资源配置与执行逻辑。

Result: 实验显示DistFlow具有优异的线性扩展性，吞吐量比现有技术提升7倍。

Conclusion: DistFlow突破了强化学习的扩展限制，为高效算法实验提供了灵活性。

Abstract: Reinforcement learning (RL) has become the pivotal post-training technique
for large language model. Effectively scaling reinforcement learning is now the
key to unlocking advanced reasoning capabilities and ensuring safe,
goal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually
employ a hybrid-controller architecture where a single-controller dispatches
the overall execution logic and manages overall data transfer and the
multi-controller executes distributed computation. For large-scale
reinforcement learning, minor load imbalances can introduce significant
bottlenecks, ultimately constraining the scalability of the system. To address
this limitation, we introduce DistFlow, a novel, fully distributed RL framework
designed to break scaling barrier. We adopt a multi-controller paradigm that
dispatches data transfer and execution tasks to all workers, which eliminates
the centralized node. This allows each worker to operate independently, leading
to near-linear scalability up to thousands of GPUs and dramatic efficiency
gains. Furthermore, our architecture decouples resource configuration from
execution logic, allowing each worker to have a unique execution flow, offering
significant flexibility for rapid and cost-effective algorithmic
experimentation. Extensive experiments show that DistFlow achieves excellent
linear scalability and up to a 7x end-to-end throughput improvement over
state-of-the-art (SOTA) frameworks.

</details>


### [155] [Edge Intelligence with Spiking Neural Networks](https://arxiv.org/abs/2507.14069)
*Shuiguang Deng,Di Yu,Changze Lv,Xin Du,Linshan Jiang,Xiaofan Zhao,Wentao Tong,Xiaoqing Zheng,Weijia Fang,Peng Zhao,Gang Pan,Schahram Dustdar,Albert Y. Zomaya*

Main category: cs.DC

TL;DR: 该论文综述了基于脉冲神经网络（SNNs）的边缘智能（EdgeSNNs），探讨其在资源受限设备上的应用潜力，包括低功耗计算、设备端学习与推理、安全性等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在资源受限的边缘设备上存在延迟、带宽和隐私问题，而SNNs通过模拟生物神经元动态提供了一种低功耗、事件驱动的计算替代方案。

Method: 论文系统分类了EdgeSNNs的基础（如神经元模型、学习算法和硬件平台），并深入讨论了设备端推理、资源感知训练与更新、安全与隐私保护等实际问题。

Result: 提出了一种双轨基准测试策略，以支持公平比较和硬件感知优化，并总结了当前进展、开放挑战和未来研究方向。

Conclusion: 该研究填补了脑启发学习与边缘部署之间的空白，为神经形态计算与边缘智能交叉领域的研究者和从业者提供了重要参考。

Abstract: The convergence of artificial intelligence and edge computing has spurred
growing interest in enabling intelligent services directly on
resource-constrained devices. While traditional deep learning models require
significant computational resources and centralized data management, the
resulting latency, bandwidth consumption, and privacy concerns have exposed
critical limitations in cloud-centric paradigms. Brain-inspired computing,
particularly Spiking Neural Networks (SNNs), offers a promising alternative by
emulating biological neuronal dynamics to achieve low-power, event-driven
computation. This survey provides a comprehensive overview of Edge Intelligence
based on SNNs (EdgeSNNs), examining their potential to address the challenges
of on-device learning, inference, and security in edge scenarios. We present a
systematic taxonomy of EdgeSNN foundations, encompassing neuron models,
learning algorithms, and supporting hardware platforms. Three representative
practical considerations of EdgeSNN are discussed in depth: on-device inference
using lightweight SNN models, resource-aware training and updating under
non-stationary data conditions, and secure and privacy-preserving issues.
Furthermore, we highlight the limitations of evaluating EdgeSNNs on
conventional hardware and introduce a dual-track benchmarking strategy to
support fair comparisons and hardware-aware optimization. Through this study,
we aim to bridge the gap between brain-inspired learning and practical edge
deployment, offering insights into current advancements, open challenges, and
future research directions. To the best of our knowledge, this is the first
dedicated and comprehensive survey on EdgeSNNs, providing an essential
reference for researchers and practitioners working at the intersection of
neuromorphic computing and edge intelligence.

</details>


### [156] [Shipwright: Proving liveness of distributed systems with Byzantine participants](https://arxiv.org/abs/2507.14080)
*Derek Leung,Nickolai Zeldovich,Frans Kaashoek*

Main category: cs.DC

TL;DR: Shipwright是一个验证框架，用于证明分布式系统的正确性和活跃性，支持模块化验证和密码学签名处理。


<details>
  <summary>Details</summary>
Motivation: 在去中心化系统中（如PBFT），确保活跃性至关重要，但现有方法无法验证可执行实现的活跃性。

Method: Shipwright引入三种技术：支持恶意参与者的形式化推理、模块化分解系统和证明、处理嵌入消息的密码学签名。

Result: 成功实现并验证了PBFT中单日志条目协议的初始原型，并将其转化为可执行的Go实现。

Conclusion: Shipwright为分布式系统的活跃性验证提供了可行方法，并在实验中得到验证。

Abstract: Ensuring liveness in a decentralized system, such as PBFT, is critical,
because there may not be any single administrator that can restart the system
if it encounters a liveness bug. At the same time, liveness is challenging to
achieve because any single participant could be malicious, and yet the overall
system must make forward progress. While verification is a promising approach
for ensuring the absence of bugs, no prior work has been able to verify
liveness for an executable implementation of PBFT.
  Shipwright is a verification framework for proving correctness and liveness
of distributed systems where some participants might be malicious. Shipwright
introduces three techniques that enable formal reasoning about decentralized
settings with malicious participants, allow developers to decompose their
system and proof in a modular fashion into sub-protocols and sub-proofs, and
support sound reasoning about cryptographic signatures that may be embedded in
messages. We used Shipwright to implement and verify an initial prototype of
agreement on a single log entry in PBFT (with a few limitations) and translate
it to an executable implementation in Go. We experimentally demonstrate its
operation and liveness both in the common case and in several failure
scenarios.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [157] [Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica](https://arxiv.org/abs/2507.13476)
*Jaber Daneshamooz,Jessica Nguyen,William Chen,Sanjay Chandrasekaran,Satyandra Guthula,Ankit Gupta,Arpit Gupta,Walter Willinger*

Main category: cs.NI

TL;DR: NetReplica通过生成具有真实性和可控性的训练数据集，解决了机器学习模型在网络领域中的域适应问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习模型在不同生产环境中的域适应问题，提升模型的泛化能力。

Method: NetReplica将网络建模为具有特定属性的瓶颈链路集合，利用生产网络痕迹实现真实性，并通过细粒度控制旋钮实现可控性。

Result: NetReplica生成的样本不仅匹配现有数据特征，还能补充Puffer数据中不足的部分，模型训练后传输时间预测误差降低47%。

Conclusion: NetReplica为解决ML在网络系统中的域适应问题提供了重要进展。

Abstract: Machine learning models in networking suffer from the domain adaptation
problem; models trained in one domain often fail when deployed in different
production environments. This paper presents the design and implementation of
NetReplica, a system that addresses this challenge by generating training
datasets with two critical properties: realism in protocol dynamics and
controllability of network conditions. NetReplica models networks as
collections of bottleneck links with specific attributes, achieves realism by
leveraging production network traces, and enables controllability through fine
grained control knobs for each link attribute. Our evaluation using Puffer
demonstrates that NetReplica not only matches existing data characteristics but
generates realistic samples that are underrepresented in or absent from Puffer
data. Models trained on NetReplica augmented datasets show substantially
improved generalizability, reducing transmission time prediction error by up to
47% for challenging network conditions compared to models trained solely on
Puffer data. This work represents a significant step toward solving the domain
adaptation problem that has limited the effectiveness of ML based networking
systems.

</details>


### [158] [CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC](https://arxiv.org/abs/2507.13676)
*Cheng Jiang,Yihe Yan,Yanxiang Wang,Jiawei Hu,Chun Tung Chou,Wen Hu*

Main category: cs.NI

TL;DR: CARTS是一种自适应5G上行链路感知方案，通过融合DMRS和SRS信号提升CSI更新频率和感知机会。


<details>
  <summary>Details</summary>
Motivation: 现代5G网络中，上行链路CSI依赖于DMRS和SRS信号，但现有基站将其视为独立信息流，限制了CSI的更新频率和感知机会。

Method: CARTS提出了一种新颖的信道拼接与补偿方法，整合异步的DMRS和SRS CSI估计，并设计了实时SRS触发算法。

Result: CARTS显著提升了可扩展性，信道估计误差（NMSE）为0.167，用户跟踪精度达85 cm，支持的用户数量是基线方案的两倍。

Conclusion: CARTS通过融合DMRS和SRS信号，提供了一种无需额外无线电资源的实用解决方案，提升了ISAC的CSI可用性。

Abstract: This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to
provide Integrated Sensing and Communication (ISAC) services. The performance
of both communication and sensing fundamentally depends on the availability of
accurate and up-to-date channel state information (CSI). In modern 5G networks,
uplink CSI is derived from two reference signals: the demodulation reference
signal (DMRS) and the sounding reference signal (SRS). However, current base
station implementations treat these CSI measurements as separate information
streams. The key innovation of CARTS is to fuse these two CSI streams, thereby
increasing the frequency of CSI updates and extending sensing opportunities to
more users. CARTS addresses two key challenges: (i) a novel channel stitching
and compensation method that integrates asynchronous CSI estimates from DMRS
and SRS, despite their different time and frequency allocations, and (ii) a
real-time SRS triggering algorithm that complements the inherently
uncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing
opportunities for all users. Our trace-driven evaluation shows that CARTS
significantly improves scalability, achieving a channel estimation error (NMSE)
of 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of
users as a periodic SRS-only baseline with similar performance. By
opportunistically combining DMRS and SRS, CARTS therefore provides a practical,
standard-compliant solution to improve CSI availability for ISAC without
requiring additional radio resources.

</details>


### [159] [ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks](https://arxiv.org/abs/2507.13717)
*Yingming Mao,Qiaozhu Zhai,Zhen Yao,Xia Zhu,Ximeng Liu,Xinchi Han*

Main category: cs.NI

TL;DR: ATRO框架通过交替优化拓扑和路由，解决了可重构数据中心网络的扩展性和效率问题，显著提升了性能和运行时间。


<details>
  <summary>Details</summary>
Motivation: 可重构数据中心网络的规模和复杂性增加，需要更高效和可扩展的算法来优化拓扑和路由。现有方法难以平衡解决方案质量和运行效率。

Method: 提出ATRO框架，交替进行拓扑优化（TO）和路由优化（RO），利用单调性结构和加速二分搜索方法（ABSM）高效求解。

Result: ATRO在一跳场景中达到全局最优，在多跳场景中显著优于基线方法，具有扩展性和鲁棒性。

Conclusion: ATRO为可重构数据中心网络提供了一种高效、可扩展的解决方案，显著提升了性能和运行效率。

Abstract: The growing scale and complexity of reconfigurable data center networks
(DCNs) demand more scalable and efficient algorithms for computing logical
topologies and routing. Reconfigurable DCNs typically operate in two modes:
one-hop configurations that require frequent topology optimization (TO), and
multi-hop scenarios that involve joint topology and routing optimization (TRO).
In both cases, the combinatorial nature of topology decisions makes it
difficult for existing methods to balance solution quality and runtime
efficiency. To address this, we introduce Alternating Topology and Routing
Optimization (ATRO), a solver-free framework that alternates between TO and
routing optimization (RO). This decomposition exploits two key insights: first,
each alternating update step monotonically reduces maximum link utilization
(MLU), ensuring consistent performance improvement across iterations; second,
the TO subproblem, equivalent to one-hop optimization, exhibits a monotonic
structure that enables optimal solutions via an efficient Accelerated Binary
Search Method (ABSM). To preserve the solver-free design, RO is solved using
existing Traffic Engineering accelerators. ATRO attains the global optimum in
one-hop scenarios and significantly outperforms baselines in multi-hop settings
in terms of both runtime and solution quality. Evaluations confirm its
scalability and robustness across diverse DCNs.

</details>


### [160] [On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies](https://arxiv.org/abs/2507.13889)
*Bilal Karaman,Ilhan Basturk,Ferdi Kara,Metin Ozturk,Sezai Taskin,Halil Yanikomeroglu*

Main category: cs.NI

TL;DR: 论文研究了主动可重构智能表面（RIS）与高空平台站（HAPS）的集成，以提升下一代无线系统中非地面网络（NTN）的性能。


<details>
  <summary>Details</summary>
Motivation: 长距离HAPS链路中的严重路径损耗和双重衰落使得主动RIS因其信号放大能力成为更优选择。

Method: 通过联合优化功率分配和RIS单元分配，解决地面用户设备（UEs）的速率最大化问题，并探索了子连接架构以降低功耗和硬件复杂度。

Result: 仿真结果表明，主动RIS在服务质量（QoS）上显著优于被动RIS，且子连接架构在能效上表现更优。

Conclusion: 主动RIS支持的HAPS系统有望满足未来蜂窝覆盖和绿色网络的需求。

Abstract: This paper investigates the integration of active reconfigurable intelligent
surfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance
non-terrestrial network (NTN) performance in next-generation wireless systems.
While prior studies focused on passive RIS architectures, the severe path loss
and double fading in long-distance HAPS links make active RIS a more suitable
alternative due to its inherent signal amplification capabilities. We formulate
a sum-rate maximization problem to jointly optimize power allocation and RIS
element assignment for ground user equipments (UEs) supported by a HAPS-based
active RIS-assisted communication system. To reduce power consumption and
hardware complexity, several sub-connected active RIS architectures are also
explored. Simulation results reveal that active RIS configurations
significantly outperform passive RIS in terms of quality of service (QoS).
Moreover, although fully-connected architectures achieve the highest
throughput, sub-connected schemes demonstrate superior energy efficiency under
practical power constraints. These findings highlight the potential of active
RIS-enabled HAPS systems to meet the growing demands of beyond-cellular
coverage and green networking.

</details>


### [161] [Preprint: Did I Just Browse A Website Written by LLMs?](https://arxiv.org/abs/2507.13933)
*Sichang "Steven" He,Ramesh Govindan,Harsha V. Madhyastha*

Main category: cs.NI

TL;DR: 论文提出了一种检测由大型语言模型（LLM）主导的网站内容的方法，解决了现有检测器在复杂网页内容上的不足。


<details>
  <summary>Details</summary>
Motivation: 由于LLM生成的内容可能存在抄袭和幻觉问题，且网站通常不披露此类内容，需要开发可靠的检测工具。

Method: 提出了一种基于LLM文本检测器输出的分类管道，通过分析多个散文式页面来分类整个网站。

Result: 在两个总计120个网站的真实数据集上测试，准确率达到100%，并在实际网络环境中检测到大量LLM主导的网站。

Conclusion: LLM主导的网站在搜索引擎结果中排名较高且日益普遍，对用户和网络生态系统可能产生重要影响。

Abstract: Increasingly, web content is automatically generated by large language models
(LLMs) with little human input. We call this "LLM-dominant" content. Since LLMs
plagiarize and hallucinate, LLM-dominant content can be unreliable and
unethical. Yet, websites rarely disclose such content, and human readers
struggle to distinguish it. Thus, we must develop reliable detectors for
LLM-dominant content. However, state-of-the-art LLM detectors are insufficient,
because they perform well mainly on clean, prose-like text, while web content
has complex markup and diverse genres.
  We propose a highly reliable, scalable pipeline that classifies entire
websites. Instead of naively classifying text extracted from each page, we
classify each site based on an LLM text detector's outputs of multiple
prose-like pages. We train and evaluate our detector by collecting 2 distinct
ground truth datasets totaling 120 sites, and obtain 100% accuracies testing
across them. In the wild, we detect a sizable portion of sites as LLM-dominant
among 10k sites in search engine results and 10k in Common Crawl archives. We
find LLM-dominant sites are growing in prevalence and rank highly in search
results, raising questions about their impact on end users and the overall Web
ecosystem.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [162] [Random Variate Generation with Formal Guarantees](https://arxiv.org/abs/2507.13494)
*Feras A. Saad,Wonyeol Lee*

Main category: cs.PL

TL;DR: 提出一种新的随机变量生成方法，通过有限精度数值程序定义CDF，实现精确生成，并保证与CDF相同的精度。


<details>
  <summary>Details</summary>
Motivation: 现有随机变量生成方法在精度、效率和自动化方面存在不足，需要一种更优的解决方案。

Method: 基于Knuth和Yao熵率最优的生成器，开发了一种空间和时间最优的实现方法，支持多种二进制数值格式。

Result: 在C语言中实现的库在多种分布上表现优异，运行时与GNU科学库相当，但精度和熵效率更高。

Conclusion: 该方法在随机变量生成中实现了高精度、高效和自动化，优于现有技术。

Abstract: This article introduces a new approach to principled and practical random
variate generation with formal guarantees. The key idea is to first specify the
desired probability distribution in terms of a finite-precision numerical
program that defines its cumulative distribution function (CDF), and then
generate exact random variates according to this CDF. We present a universal
and fully automated method to synthesize exact random variate generators given
any numerical CDF implemented in any binary number format, such as
floating-point, fixed-point, and posits. The method is guaranteed to operate
with the same precision used to specify the CDF, does not overflow, avoids
expensive arbitrary-precision arithmetic, and exposes a consistent API. The
method rests on a novel space-time optimal implementation for the class of
generators that attain the information-theoretically optimal Knuth and Yao
entropy rate, consuming the least possible number of input random bits per
output variate. We develop a random variate generation library using our method
in C and evaluate it on a diverse set of ``continuous'' and ``discrete''
distributions, showing competitive runtime with the state-of-the-art GNU
Scientific Library while delivering higher accuracy, entropy efficiency, and
automation.

</details>


### [163] [Increasing the Expressiveness of a Gradual Verifier](https://arxiv.org/abs/2507.13533)
*Priyam Gupta*

Main category: cs.PL

TL;DR: 论文介绍了Gradual C0的扩展设计，支持展开表达式，以更直观地指定递归堆数据结构。


<details>
  <summary>Details</summary>
Motivation: 静态验证虽然能提供强正确性保证，但完全指定程序的过程复杂且繁琐。渐进验证旨在简化这一过程，但现有工具Gradual C0在规范语言上缺乏表现力。

Method: 扩展Gradual C0的设计与实现，支持展开表达式。

Result: 扩展后的工具能够更直观地指定递归堆数据结构。

Conclusion: 通过支持展开表达式，Gradual C0的规范语言表现力得到提升，进一步简化了渐进验证过程。

Abstract: Static verification provides strong correctness guarantees for code; however,
fully specifying programs for static verification is a complex, burdensome
process for users. Gradual verification was introduced to make this process
easier by supporting the verification of partially specified programs. The only
currently working gradual verifier, Gradual C0, successfully verifies heap
manipulating programs, but lacks expressiveness in its specification language.
This paper describes the design and implementation of an extension to Gradual
C0 that supports unfolding expressions, which allow more intuitive
specifications of recursive heap data structures.

</details>


### [164] [AdapTT: Functoriality for Dependent Type Casts](https://arxiv.org/abs/2507.13774)
*Arthur Adjedj,Meven Lennon-Bertrand,Thibaut Benjamin,Kenji Maillard*

Main category: cs.PL

TL;DR: AdapTT是一种类型理论，通过抽象适配器关系类型，系统化地研究类型构造器的函子性，并推导出通用归纳类型构造器的类型转换结构规律。


<details>
  <summary>Details</summary>
Motivation: 研究依赖类型理论中类型转换的共同结构行为，特别是类型构造器的函子性。

Method: 提出AdapTT类型理论，利用适配器抽象关系类型，系统化研究函子性，并通过描述归纳类型推导结构规律。

Result: 成功推导出通用归纳类型构造器的类型转换结构规律。

Conclusion: AdapTT为类型转换提供了一种系统化方法，揭示了类型构造器函子性的普遍规律。

Abstract: The ability to cast values between related types is a leitmotiv of many
flavors of dependent type theory, such as observational type theories,
subtyping, or cast calculi for gradual typing. These casts all exhibit a common
structural behavior that boils down to the pervasive functoriality of type
formers. We propose and extensively study a type theory, called AdapTT, which
makes systematic and precise this idea of functorial type formers, with respect
to an abstract notion of adapters relating types. Leveraging descriptions for
functorial inductive types in AdapTT, we derive structural laws for type casts
on general inductive type formers.

</details>


### [165] [Don't exhaust, don't waste](https://arxiv.org/abs/2507.13792)
*Riccardo Bianchini,Francesco Dagnino,Paola Giannini,Elena Zucca*

Main category: cs.PL

TL;DR: 扩展了带有常见构造的lambda演算的语义和类型系统，使其具备资源感知能力，确保资源既不会耗尽也不会浪费。


<details>
  <summary>Details</summary>
Motivation: 为程序提供资源使用的精确控制，避免资源耗尽或浪费。

Method: 基于任意等级代数的参数化扩展，无需对底层语言进行特定修改，采用大步语义形式化。

Result: 类型系统保证了资源使用的安全性，确保存在无资源浪费或耗尽的计算路径。

Conclusion: 通过共归纳推理技术，成功实现了资源感知的语义和类型系统的形式化与验证。

Abstract: We extend the semantics and type system of a lambda calculus equipped with
common constructs to be resource-aware. That is, the semantics keep tracks of
the usage of resources, and is stuck, besides in case of type errors, if either
a needed resource is exhausted, or a provided resource would be wasted. In such
way, the type system guarantees, besides standard soundness, that for
well-typed programs there is a computation where no resource gets either
exhausted or wasted.
  The no-waste extension is parametric on an arbitrary grade algebra, modeling
an arbitrary assortment of possible usages, and does not require ad-hoc changes
to the underlying language. To this end, the semantics needs to be formalized
in big-step style; as a consequence, expressing and proving (resource-aware)
soundness is challenging, and is achieved by applying recent techniques based
on coinductive reasoning.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [166] [Socio-Technical Smell Dynamics in Code Samples: A Multivocal Review on Emergence, Evolution, and Co-Occurrence](https://arxiv.org/abs/2507.13481)
*Arthur Bueno,Bruno Cafeo,Maria Cagnin,Awdren Fontão*

Main category: cs.SE

TL;DR: 研究探讨了开源生态系统中代码样本的技术异味（如大类、低模块化）与社区异味（如孤立贡献者、沟通碎片化）的共现与演化关系，发现社区问题常预示或加剧技术退化。


<details>
  <summary>Details</summary>
Motivation: 代码样本在开源生态中至关重要，但其管理松散，易受技术和社会问题影响。现有研究多孤立分析技术或社区问题，缺乏对二者交互作用的了解。

Method: 采用多声部文献综述方法，分析30篇学术论文和17篇实践导向资料（2013-2024），通过主题合成识别异味动态的社会技术模式。

Result: 识别出9种模式，显示社区异味常先于或加剧技术退化，如“无线电静默”和集中所有权与持续结构问题相关。

Conclusion: 开源生态中，社区问题不仅与技术退化相关，还常预示其发生，需针对共享教学工件设计轻量级治理机制。

Abstract: Code samples play a pivotal role in open-source ecosystems (OSSECO), serving
as lightweight artifacts that support knowledge transfer, onboarding, and
framework adoption. Despite their instructional relevance, these samples are
often governed informally, with minimal review and unclear ownership, which
increases their exposure to socio-technical degradation. In this context, the
co-occurrence and longitudinal interplay of code smells (e.g., large classes,
poor modularity) and community smells (e.g., lone contributors, fragmented
communication) become particularly critical. While each type of smell has been
studied in isolation, little is known about how community-level dysfunctions
anticipate or exacerbate technical anomalies in code samples over time. This
study investigates how code and community smells emerge, co-occur, and evolve
within code samples maintained in OSSECOs. A Multivocal Literature Review
protocol was applied, encompassing 30 peer-reviewed papers and 17
practitioner-oriented sources (2013-2024). Thematic synthesis was conducted to
identify recurring socio-technical patterns related to smell dynamics. Nine
patterns were identified, showing that community smells often precede or
reinforce technical degradation in code samples. Symptoms such as "radio
silence" and centralized ownership were frequently associated with persistent
structural anomalies. Additionally, limited onboarding, the absence of
continuous refactoring, and informal collaboration emerged as recurring
conditions for smell accumulation. Conclusion: In OSSECOs, particularly within
code samples, community-level dysfunctions not only correlate with but often
signal maintainability decay. These findings underscore the need for
socio-technical quality indicators and lightweight governance mechanisms
tailored to shared instructional artifacts.

</details>


### [167] [AI-Assisted Fixes to Code Review Comments at Scale](https://arxiv.org/abs/2507.13499)
*Chandra Maddila,Negar Ghorbani,James Saindon,Parth Thakkar,Vijayaraghavan Murali,Rui Abreu,Jingyue Shen,Brian Zhou,Nachiappan Nagappan,Peter C. Rigby*

Main category: cs.SE

TL;DR: Meta开发了MetaMateCR，利用AI辅助修复代码审查评论，通过微调Llama模型并在生产环境中测试，最终在离线测试中表现优于GPT-4o，并在生产中提高了修复率。


<details>
  <summary>Details</summary>
Motivation: 解决Meta每周数以万计的代码审查评论问题，提高效率和准确性。

Method: 使用64k数据点微调Llama模型，进行离线测试和安全试验后投入生产。

Result: 离线测试中LargeLSFT模型表现优于GPT-4o，生产中修复率提高了9.2个百分点。

Conclusion: MetaMateCR成功展示了AI辅助修复的潜力，并强调了安全试验的重要性。

Abstract: Aim. There are 10s of thousands of code review comments each week at Meta. We
developed Metamate for Code Review (MetaMateCR) that provides AI-assisted fixes
for reviewer comments in production at scale.
  Method. We developed an internal benchmark of 64k <review comment, patch>
data points to fine-tune Llama models. Once our models achieve reasonable
offline results, we roll them into production. To ensure that our AI-assisted
fixes do not negatively impact the time it takes to do code reviews, we conduct
randomized controlled safety trials as well as full production experiments.
  Offline Results. As a baseline, we compare GPT-4o to our small and large
Llama models. In offline results, our LargeLSFT model creates an exact match
patch 68% of the time outperforming GPT-4o by 9 percentage points (pp). The
internal models also use more modern Hack functions when compared to the PHP
functions suggested by GPT-4o.
  Safety Trial. When we roll MetaMateCR into production in a safety trial that
compares no AI patches with AI patch suggestions, we see a large regression
with reviewers taking over 5% longer to conduct reviews. After investigation,
we modify the UX to only show authors the AI patches, and see no regressions in
the time for reviews.
  Production. When we roll LargeLSFT into production, we see an
ActionableToApplied rate of 19.7%, which is a 9.2pp improvement over GPT-4o.
Our results illustrate the importance of safety trials in ensuring that AI does
not inadvertently slow down engineers, and a successful review comment to AI
patch product running at scale.

</details>


### [168] [Towards Better Requirements from the Crowd: Developer Engagement with Feature Requests in Open Source Software](https://arxiv.org/abs/2507.13553)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 研究探讨了开源软件中功能请求的模糊性和不完整性，以及开发者澄清问题的动态过程，发现澄清行为较少，且更关注用户意图而非技术细节。


<details>
  <summary>Details</summary>
Motivation: 功能请求常因自然语言表达模糊或不完整导致误解，影响软件质量，但开发者澄清过程的研究较少。

Method: 通过分析开源软件平台上的功能请求和开发者澄清对话，研究其动态和模式。

Result: 功能请求普遍存在模糊性和不完整性，开发者较少明确澄清，更注重项目目标和用户意图。

Conclusion: 研究揭示了澄清行为的模式，为改进用户与开发者协作和处理功能请求提供了实践建议。

Abstract: As user demands evolve, effectively incorporating feature requests is crucial
for maintaining software relevance and user satisfaction. Feature requests,
typically expressed in natural language, often suffer from ambiguity or
incomplete information due to communication gaps or the requester's limited
technical expertise. These issues can lead to misinterpretation, faulty
implementation, and reduced software quality. While seeking clarification from
requesters is a common strategy to mitigate these risks, little is known about
how developers engage in this clarification process in practice-how they
formulate clarifying questions, seek technical or contextual details, align on
goals and use cases, or decide to close requests without attempting
clarification. This study investigates how feature requests are prone to NL
defects (i.e. ambiguous or incomplete) and the conversational dynamics of
clarification in open-source software (OSS) development, aiming to understand
how developers handle ambiguous or incomplete feature requests. Our findings
suggest that feature requests published on the OSS platforms do possess
ambiguity and incompleteness, and in some cases, both. We also find that
explicit clarification for the resolution of these defects is uncommon;
developers usually focus on aligning with project goals rather than resolving
unclear text. When clarification occurs, it emphasizes understanding user
intent/goal and feasibility, rather than technical details. By characterizing
the dynamics of clarification in open-source issue trackers, this work
identifies patterns that can improve user-developer collaboration and inform
best practices for handling feature requests effectively.

</details>


### [169] [Demystifying Feature Requests: Leveraging LLMs to Refine Feature Requests in Open-Source Software](https://arxiv.org/abs/2507.13555)
*Pragyan K C,Rambod Ghandiparsi,Thomas Herron,John Heaps,Mitra Bokaei Hosseini*

Main category: cs.SE

TL;DR: 论文提出了一种利用大型语言模型（LLMs）自动检测和优化自然语言（NL）缺陷的方法，以提高开源软件（OSS）中功能请求的清晰度。


<details>
  <summary>Details</summary>
Motivation: 随着软件应用（apps）的普及，需求快速变化且常以自然语言形式提出，但这些请求常存在模糊和不完整的问题，传统验证方法在去中心化环境（如开源软件）中不适用。

Method: 利用LLMs自动识别模糊和不完整的请求，并生成澄清问题（CQs）以改进请求。方法在真实OSS功能请求上评估，并与人工标注对比。

Result: 方法在检测和优化NL缺陷方面表现良好，开发者访谈进一步揭示了NL缺陷的影响及其对下游软件工程任务的重要性。

Conclusion: LLMs能有效提升功能请求的清晰度，为开源社区提供了一种实用的自动化解决方案。

Abstract: The growing popularity and widespread use of software applications (apps)
across various domains have driven rapid industry growth. Along with this
growth, fast-paced market changes have led to constantly evolving software
requirements. Such requirements are often grounded in feature requests and
enhancement suggestions, typically provided by users in natural language (NL).
However, these requests often suffer from defects such as ambiguity and
incompleteness, making them challenging to interpret. Traditional validation
methods (e.g., interviews and workshops) help clarify such defects but are
impractical in decentralized environments like open-source software (OSS),
where change requests originate from diverse users on platforms like GitHub.
This paper proposes a novel approach leveraging Large Language Models (LLMs) to
detect and refine NL defects in feature requests. Our approach automates the
identification of ambiguous and incomplete requests and generates clarification
questions (CQs) to enhance their usefulness for developers. To evaluate its
effectiveness, we apply our method to real-world OSS feature requests and
compare its performance against human annotations. In addition, we conduct
interviews with GitHub developers to gain deeper insights into their
perceptions of NL defects, the strategies they use to address these defects,
and the impact of defects on downstream software engineering (SE) tasks.

</details>


### [170] [Testing Autonomous Driving Systems -- What Really Matters and What Doesn't](https://arxiv.org/abs/2507.13661)
*Changwen Li,Joseph Sifakis,Rongjie Yan,Jian Zhang*

Main category: cs.SE

TL;DR: 本文探讨了自动驾驶系统（ADS）测试方法的有效性和有效性，指出当前测试方法的不足，并提出改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统的测试方法缺乏统一标准，无法准确评估其重要性和贡献，亟需改进。

Method: 提出一个框架用于比较现有测试方法的有效性和有效性，并分析测试结果与自动驾驶设计的关系。

Result: 研究发现多数测试方法未能满足有效性和有效性要求，且自动驾驶的设计（如理性与确定性）显著影响测试效果。

Conclusion: 当前技术无法为自动驾驶提供足够强的保障，建议开发时注重理性与确定性。

Abstract: Despite extensive research, the testing of autonomous driving systems (ADS)
landscape remains fragmented, and there is currently no basis for an informed
technical assessment of the importance and contribution of the current state of
the art. This paper attempts to address this problem by exploring two
complementary aspects.
  First, it proposes a framework for comparing existing test methods in terms
of their intrinsic effectiveness and validity. It shows that many methods do
not meet both of these requirements. Either because they are based on criteria
that do not allow for rapid, inexpensive, and comprehensive detection of
failures, or because the degree of validity of the properties tested cannot be
accurately estimated. In particular, it is shown that most critical test
methods do not take into account the nominal operational capabilities of
autopilots and generate scenarios that are impossible for the tested vehicles
to handle, resulting in unjustified rejections.
  Secondly, the paper shows that test effectiveness and validity are highly
dependent on how autopilots are designed: how they choose between different
control policies to perform maneuvers, as well as on the reproducibility of the
results. In fact, most test methods take for granted two principles underlying
traditional methods, but do not generally apply to ADS. We maintain that the
absence of rationality and determinacy significantly impairs the effectiveness
and validity of test methods, and provide test results on eight open
autopilots, in which most do not satisfy these properties, thereby illustrating
this fact.
  We conclude that under the current state of the art, it is impossible to
obtain strong enough guarantees for essential autopilot properties and
recommend that autopilots be developed with a view to both rationality and
determinacy.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [171] [Combining stated and revealed preferences](https://arxiv.org/abs/2507.13552)
*Romuald Meango,Marc Henry,Ismael Mourifie*

Main category: econ.EM

TL;DR: 研究提出了一种利用陈述偏好和实际选择数据校正内生性的新方法，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨陈述偏好是否能用于反事实分析实际选择，解决内生性问题。

Method: 利用陈述偏好识别个体未观测异质性分布，校正实际选择中的内生性影响。

Result: 推导了因果效应的边界，并通过模拟验证了自举推断的有效性。

Conclusion: 陈述偏好可用于校正实际选择中的内生性，为因果分析提供新工具。

Abstract: Can stated preferences inform counterfactual analyses of actual choice? This
research proposes a novel approach to researchers who have access to both
stated choices in hypothetical scenarios and actual choices, matched or
unmatched. The key idea is to use stated choices to identify the distribution
of individual unobserved heterogeneity. If this unobserved heterogeneity is the
source of endogeneity, the researcher can correct for its influence in a demand
function estimation using actual choices and recover causal effects. Bounds on
causal effects are derived in the case, where stated choice and actual choices
are observed in unmatched data sets. These data combination bounds are of
independent interest. We derive a valid bootstrap inference for the bounds and
show its good performance in a simulation experiment.

</details>


### [172] [Who With Whom? Learning Optimal Matching Policies](https://arxiv.org/abs/2507.13567)
*Yagan Hazard,Toru Kitagawa*

Main category: econ.EM

TL;DR: 本文提出了一种学习福利最优匹配政策的方法，适用于双边匹配问题，通过熵正则化实证福利准则优化匹配策略，并在法国行政数据模拟中验证其性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于许多经济场景中，匹配政策对生产力和福利的影响显著，但现有方法较少关注如何学习最优匹配策略。

Method: 方法包括将学习问题建模为实证最优运输问题，通过熵正则化准则估计最优匹配政策。

Result: 研究结果表明，所提方法在模拟实验中表现出良好的福利性能。

Conclusion: 结论指出，该方法为双边匹配问题提供了一种有效的政策学习工具。

Abstract: There are many economic contexts where the productivity and welfare
performance of institutions and policies depend on who matches with whom.
Examples include caseworkers and job seekers in job search assistance programs,
medical doctors and patients, teachers and students, attorneys and defendants,
and tax auditors and taxpayers, among others. Although reallocating individuals
through a change in matching policy can be less costly than training personnel
or introducing a new program, methods for learning optimal matching policies
and their statistical performance are less studied than methods for other
policy interventions. This paper develops a method to learn welfare optimal
matching policies for two-sided matching problems in which a planner matches
individuals based on the rich set of observable characteristics of the two
sides. We formulate the learning problem as an empirical optimal transport
problem with a match cost function estimated from training data, and propose
estimating an optimal matching policy by maximizing the entropy regularized
empirical welfare criterion. We derive a welfare regret bound for the estimated
policy and characterize its convergence. We apply our proposal to the problem
of matching caseworkers and job seekers in a job search assistance program, and
assess its welfare performance in a simulation study calibrated with French
administrative data.

</details>


### [173] [Debiased Machine Learning for Unobserved Heterogeneity: High-Dimensional Panels and Measurement Error Models](https://arxiv.org/abs/2507.13788)
*Facundo Argañaraz,Juan Carlos Escanciano*

Main category: econ.EM

TL;DR: 提出了一种新的去偏机器学习（DML）方法，用于处理非参数未观测异质性（UH）模型的稳健推断，支持部分识别和高维干扰参数。


<details>
  <summary>Details</summary>
Motivation: 非参数未观测异质性模型的稳健推断是一个重要且具有挑战性的问题，需要有效的方法来处理高维干扰参数和部分识别。

Method: 通过Neyman正交矩的全局和局部鲁棒性，减少正则化偏差，实现有效的DML推断。

Result: 在面板数据模型、Kotlarski模型和教师增值模型中验证了方法的有效性，蒙特卡洛模拟显示效率显著提升。

Conclusion: 该方法不仅提升了推断效率，还验证了现有研究的稳健性，例如母亲吸烟对婴儿出生体重的影响。

Abstract: Developing robust inference for models with nonparametric Unobserved
Heterogeneity (UH) is both important and challenging. We propose novel Debiased
Machine Learning (DML) procedures for valid inference on functionals of UH,
allowing for partial identification of multivariate target and high-dimensional
nuisance parameters. Our main contribution is a full characterization of all
relevant Neyman-orthogonal moments in models with nonparametric UH, where
relevance means informativeness about the parameter of interest. Under
additional support conditions, orthogonal moments are globally robust to the
distribution of the UH. They may still involve other high-dimensional nuisance
parameters, but their local robustness reduces regularization bias and enables
valid DML inference. We apply these results to: (i) common parameters, average
marginal effects, and variances of UH in panel data models with
high-dimensional controls; (ii) moments of the common factor in the Kotlarski
model with a factor loading; and (iii) smooth functionals of teacher
value-added. Monte Carlo simulations show substantial efficiency gains from
using efficient orthogonal moments relative to ad-hoc choices. We illustrate
the practical value of our approach by showing that existing estimates of the
average and variance effects of maternal smoking on child birth weight are
robust.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [174] [Second-degree Price Discrimination: Theoretical Analysis, Experiment Design, and Empirical Estimation](https://arxiv.org/abs/2507.13426)
*Soheil Ghili,K. Sudhir,Nitish Jain,Ankur Garg*

Main category: econ.GN

TL;DR: 论文基于机制设计理论，分析了二级价格歧视（2PD）的实证模型，提出BLP模型需捕捉两种随机效应的协方差，并设计实验验证其适用性。


<details>
  <summary>Details</summary>
Motivation: 研究二级价格歧视（BLP模型）的适用性，并解决数据限制下的协方差识别问题。

Method: 开发实验设计，识别随机效应的协方差，并在国际航空公司实地实施。

Result: 验证了模型的适用性，并展示了实验统计量在未估计需求模型前即可推断最优2PD策略。

Conclusion: 该方法广泛适用于二级价格歧视场景。

Abstract: We build on theoretical results from the mechanism design literature to
analyze empirical models of second-degree price discrimination (2PD). We show
that for a random-coefficients discrete choice ("BLP") model to be suitable for
studying 2PD, it must capture the covariance between two key random effects:
(i) the "baseline" willingness to pay (affecting all product versions), and
(ii) the perceived differentiation between versions. We then develop an
experimental design that, among other features, identifies this covariance
under common data constraints in 2PD environments. We implement this experiment
in the field in collaboration with an international airline. Estimating the
theoretically motivated empirical model on the experimental data, we
demonstrate its applicability to 2PD decisions. We also show that test
statistics from our design can enable qualitative inference on optimal 2PD
policy even before estimating a demand model. Our methodology applies broadly
across second-degree price discrimination settings.

</details>


### [175] [Navigating the Lobbying Landscape: Insights from Opinion Dynamics Models](https://arxiv.org/abs/2507.13767)
*Daniele Giachini,Leonardo Ciambezi Verdiana Del Rosso,Fabrizio Fornari,Valentina Pansanella,Lilit Popoyan,Alina Sîrbu*

Main category: econ.GN

TL;DR: 该论文提出了一种新的意见动态模型，考虑了游说者的复杂策略和有限预算，通过贝叶斯学习和认知偏差影响个体意见更新，展示了游说存在时的两种动态模式。


<details>
  <summary>Details</summary>
Motivation: 现有意见形成模型未专门考虑游说对公众意见和政策制定的影响，因此需要新模型填补这一空白。

Method: 引入基于贝叶斯学习和认知偏差（如反应不足和确认偏误）的意见更新机制，结合游说者的复杂策略和有限预算，进行数值模拟研究。

Result: 发现游说存在时有两种动态模式：游说者完全影响网络或同伴效应导致极化；对称游说者存在时，意见振荡持续较长时间。

Conclusion: 模型展示了丰富的动态行为，为研究实际游说策略提供了理论基础。

Abstract: While lobbying has been demonstrated to have an important effect on public
opinion and policy making, existing models of opinion formation do not
specifically include its effect. In this work we introduce a new model of
opinion dynamics where lobbyists can implement complex strategies and are
characterised by a finite budget. Individuals update their opinions through a
learning process resembling Bayesian learning, but influenced by cognitive
biases such as under-reaction and confirmation bias. We study the model
numerically and demonstrate rich dynamics both with and without lobbyists. In
the presence of lobbying, we observe two regimes: one in which lobbyists can
have full influence on the agent network, and another where the peer-effect
generates polarisation. When symmetric lobbyists are present, the lobbyist
influence regime is characterised by long opinion oscillations, while in the
transition area between the two regimes we observe convergence to the
optimistic model when the lobbying influence is long enough. These rich
dynamics pave the way for studying real lobbying strategies to validate the
model in practice.

</details>


### [176] [Choosing and Using Information in Evaluation Decisions](https://arxiv.org/abs/2507.13798)
*Katherine B. Coffman,Scott Kostyshak,Perihan O. Saygin*

Main category: econ.GN

TL;DR: 研究通过实验发现，评估者在获取个体层面信息不足时，倾向于做出更刻板的候选人评价，导致对弱势群体人才的低估和对强势群体非人才的过度选择。


<details>
  <summary>Details</summary>
Motivation: 探讨信息获取如何影响候选人的评价，特别是群体层面信息对刻板印象的作用。

Method: 通过控制实验，提供群体层面绩效信息，并允许获取个体层面信息，观察评估者的行为。

Result: 评估者普遍获取个体信息不足，群体比较显著影响评价，导致对弱势群体人才的忽视和对强势群体非人才的偏爱。

Conclusion: 信息获取不足加剧刻板印象，影响公平评价，需改进评估机制以减少偏见。

Abstract: We use a controlled experiment to study how information acquisition impacts
candidate evaluations. We provide evaluators with group-level information on
performance and the opportunity to acquire additional, individual-level
performance information before making a final evaluation. We find that, on
average, evaluators under-acquire individual-level information, leading to more
stereotypical evaluations of candidates. Consistent with stereotyping, we find
that (irrelevant) group-level comparisons have a significant impact on how
candidates are evaluated; group-level comparisons bias initial assessments,
responses to information, and final evaluations. This leads to
under-recognition of talented candidates from comparatively weaker groups and
over-selection of untalented candidates from comparatively stronger groups.

</details>


### [177] [Stablecoins: Fundamentals, Emerging Issues, and Open Challenges](https://arxiv.org/abs/2507.13883)
*Ahmed Mahrous,Maurantonio Caprolu,Roberto Di Pietro*

Main category: econ.GN

TL;DR: 本文通过结构化文献分析，探讨稳定币的经济、技术和监管复杂性，填补现有研究的碎片化和矛盾性。


<details>
  <summary>Details</summary>
Motivation: 稳定币快速增长引起传统金融机构和政府关注，但学术研究仍不完整且矛盾，需系统性分析。

Method: 采用结构化文献分析方法，分类科学贡献，识别主要结果、数据源、方法和未解决问题。

Result: 揭示了稳定币稳定性、设计、监管等研究现状，并指出安全、隐私、治理等领域的重大研究空白。

Conclusion: 本文为稳定币研究提供了系统性框架，并明确了未来研究方向，如安全、隐私和治理机制。

Abstract: Stablecoins, with a capitalization exceeding 200 billion USD as of January
2025, have shown significant growth, with annual transaction volumes exceeding
10 trillion dollars in 2023 and nearly doubling that figure in 2024. This
exceptional success has attracted the attention of traditional financial
institutions, with an increasing number of governments exploring the potential
of Central Bank Digital Currencies (CBDCs). Although academia has recognized
the importance of stablecoins, research in this area remains fragmented,
incomplete, and sometimes contradictory. In this paper, we aim to address the
cited gap with a structured literature analysis, correlating recent
contributions to present a picture of the complex economic, technical, and
regulatory aspects of stablecoins. To achieve this, we formulate the main
research questions and categorize scientific contributions accordingly,
identifying main results, data sources, methodologies, and open research
questions. The research questions we address in this survey paper cover several
topics, such as the stability of various stablecoins, novel designs and
implementations, and relevant regulatory challenges. The studies employ a wide
range of methodologies and data sources, which we critically analyze and
synthesize. Our analysis also reveals significant research gaps, including
limited studies on security and privacy, underexplored stablecoins, unexamined
failure cases, unstudied governance mechanisms, and the treatment of
stablecoins under financial accounting standards, among other areas.

</details>
