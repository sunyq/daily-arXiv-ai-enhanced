<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 25]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.CV](#cs.CV) [Total: 89]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.NI](#cs.NI) [Total: 19]
- [cs.PL](#cs.PL) [Total: 6]
- [cs.SE](#cs.SE) [Total: 19]
- [econ.EM](#econ.EM) [Total: 1]
- [econ.GN](#econ.GN) [Total: 4]
- [econ.TH](#econ.TH) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench是一个用于评估AI医疗能力的基准，但依赖专家意见可能引入偏见。作者提出基于临床实践指南的改进方法，以提升全球适用性和公平性。


<details>
  <summary>Details</summary>
Motivation: HealthBench依赖专家意见，可能引入区域偏见和个体差异，尤其在低收入地区问题更突出。需要更公平、全球适用的基准。

Method: 提出将奖励函数锚定在版本控制的临床实践指南（CPGs）中，结合系统评价和GRADE证据评级，采用证据加权的评分和上下文覆盖逻辑。

Result: 通过改进方法，旨在开发出更临床可信、伦理合理且全球适用的医疗语言模型。

Conclusion: 通过结合严格审查的CPGs和透明性，改进后的基准有望提升医疗AI的全球适用性和公平性。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [2] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 论文提出了一种多频带可变滞后格兰杰因果性（MB-VLGC）框架，解决了传统方法中固定滞后假设和频率依赖性因果延迟的问题。


<details>
  <summary>Details</summary>
Motivation: 传统格兰杰因果性方法假设固定的时间滞后，而可变滞后方法（VLGC）虽放宽了这一限制，但未考虑频率依赖性延迟。

Method: 提出了MB-VLGC框架，明确建模频率依赖性因果延迟，并提供了理论证明和高效推理流程。

Result: 实验表明，MB-VLGC在合成和真实数据集上显著优于现有方法。

Conclusion: MB-VLGC框架具有广泛适用性，适用于多种时间序列数据。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [3] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL的安全强化学习方法（SecRL），用于满足机器人应用中的安全性和不透明性约束。


<details>
  <summary>Details</summary>
Motivation: 现有研究在探索基于超属性的安全感知强化学习方面存在空白，尤其是在机器人应用中。

Method: 采用动态Boltzmann softmax强化学习方法，结合HyperTWTL约束，学习安全感知的最优策略。

Result: 通过案例研究验证了方法的有效性和可扩展性，并优于两种基线RL算法。

Conclusion: 提出的方法在满足HyperTWTL约束的同时，显著提升了安全强化学习的性能。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [4] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 论文探讨了AI在工业环境中的应用挑战，提出通过对象中心过程挖掘（OCPM）将AI与过程数据结合，形成过程智能（PI），以提升端到端操作流程。


<details>
  <summary>Details</summary>
Motivation: 组织在工业环境中成功应用AI面临挑战，尤其是端到端操作流程的诊断和改进。

Method: 采用对象中心过程挖掘（OCPM）作为连接数据和过程的桥梁，结合生成式、预测式和规范性AI。

Result: OCPM是连接数据和过程的关键，过程智能（PI）能有效支持AI在组织环境中的应用。

Conclusion: AI需要PI的支持才能优化操作流程，OCPM与多种AI形式的结合提供了成功的机会。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [5] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 论文探讨了通过明确要求AI代理赋能人类并管理人类与AI之间的权力平衡，以促进安全和福祉。提出了一种参数化和可分解的目标函数，并通过算法计算该指标。


<details>
  <summary>Details</summary>
Motivation: 研究AI安全和人类福祉之间的关系，探讨如何通过设计目标函数来平衡人类与AI的权力，避免潜在风险。

Method: 采用部分公理化的方法，设计了一个参数化和可分解的目标函数，并通过逆向归纳或多智能体强化学习算法计算该指标。

Result: 在多种典型情境中展示了该指标的效果，并分析了其可能引发的子目标。评估表明，该目标函数可能比直接基于效用的目标更安全。

Conclusion: 通过优化人类权力的聚合指标，可能为AI系统提供更安全的目标函数，从而促进安全和福祉。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [6] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 本文提出了三种检测多准则决策分析中排名反转问题的测试方法，并讨论了其在Scikit-Criteria库中的实现及其对方法评估的影响。


<details>
  <summary>Details</summary>
Motivation: 多准则决策分析中的排名反转问题严重影响决策方法的有效性，因此需要一种机制来测量方法性能并评估不同方法的全局有效性。

Method: 提出了三种测试方法来检测排名反转，并在Scikit-Criteria库中实现这些测试，同时讨论了实现中的复杂性和设计考虑。

Result: 成功实现了三种测试方法，并解决了通用场景下的实现问题，为多准则决策方法的评估提供了工具。

Conclusion: 这些测试方法在多准则决策方法的评估中可能发挥重要作用，有助于提升问题解决的决策质量。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [7] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 研究SHACL在RDF图更新中的静态验证问题，提出一种基于SHACL的更新语言，并通过回归技术将问题转化为SHACL约束的（不）可满足性。


<details>
  <summary>Details</summary>
Motivation: 探讨RDF图在更新后是否仍满足SHACL规范，为动态图推理提供基础。

Method: 提出SHACL更新语言，利用回归技术将更新动作嵌入SHACL约束，分析计算复杂度，并实现原型验证。

Result: 证明静态验证问题可转化为SHACL约束的（不）可满足性，并分析了计算复杂度。

Conclusion: 为动态RDF图的SHACL验证提供了理论基础和实用工具。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [8] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 论文提出了一种基于设计正义、扩展学习理论和参与式AI的AI生命周期重构方法，强调共同生产、多样性、公平性和多学科合作。


<details>
  <summary>Details</summary>
Motivation: 尽管已有努力减少AI算法的风险和偏见，但其对文化边缘群体的影响仍不成比例。需要重新设计AI生产流程以减轻这些危害。

Method: 提出了一个增强的AI生命周期，包含五个相互关联的阶段：共同框架、共同设计、共同实施、共同部署和共同维护。

Result: 生命周期基于四个多学科研讨会，并围绕分布式权威和迭代知识交换的主题展开。

Conclusion: 论文将提出的生命周期与主要伦理框架联系起来，并概述了扩展参与式治理的关键研究问题。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [9] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 论文主张过度依赖人类评分者间一致性（IRR）会阻碍教育数据分类的进展，提出五种补充评估方法以提高数据标注质量和模型效果。


<details>
  <summary>Details</summary>
Motivation: 人类评估者存在偏见和不可靠性，传统IRR指标无法充分保证标注数据的有效性，尤其在教育AI应用中。

Method: 提出五种补充评估方法，包括多标签标注方案、专家评估和闭环验证等，强调外部有效性的重要性。

Result: 这些方法能比单独使用IRR产生更有效的训练数据和模型，提升学生学习效果和可操作性。

Conclusion: 呼吁重新思考标注质量和“真实标准”，优先考虑有效性和教育影响，而非仅依赖共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [10] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS通过结合内部探索和外部数据，解决了RLVR在LLM中的能力边界问题，显著提升了推理能力。


<details>
  <summary>Details</summary>
Motivation: RLVR因策略固有性和稀疏奖励难以突破LLM的能力边界，甚至导致能力边界崩溃。

Method: RL-PLUS结合多重重要性采样和探索优势函数，利用外部数据优化推理路径。

Result: 在六个数学推理基准和六个分布外任务中表现最优，相对改进达21.1%至69.2%。

Conclusion: RL-PLUS有效解决了能力边界崩溃问题，提升了模型的推理能力和泛化性。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [11] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent是一个基于学习实践原则的智能代理，通过持续自我改进和工具学习提升任务解决能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种能够通过实践和工具学习自主提升的智能代理，以解决知识发现任务中的挑战。

Method: MetaAgent从基础能力出发，通过生成帮助请求、自我反思和答案验证，动态积累经验并构建内部工具和知识库。

Result: 在GAIA、WebWalkerQA和BrowseCamp等基准测试中，MetaAgent优于基线方法，并与端到端训练代理表现相当或更好。

Conclusion: MetaAgent展示了自进化代理系统在通用知识发现中的潜力，无需调整模型参数或额外训练。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [12] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 论文比较了人类与LLM（GPT-4o）在任务生成上的差异，发现人类受心理驱动因素影响，而LLM生成的任务缺乏社会性和物理性，偏向抽象。尽管LLM的任务被认为更有趣和新颖，但其与人类认知存在核心差距。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索生成式代理（基于LLM）是否能模拟人类基于内在动机的任务生成行为。

Method: 通过任务生成实验，比较人类与GPT-4o在任务生成上的差异，并分析心理驱动因素的影响。

Result: 人类任务生成受心理驱动因素影响，而LLM生成的任务缺乏社会性和物理性，偏向抽象。LLM的任务被认为更有趣和新颖。

Conclusion: LLM与人类认知存在核心差距，需在设计更人性化的代理时融入内在动机和物理基础。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [13] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: ReasonBench是首个专注于结构化图形推理任务的评估基准，用于评估视觉语言模型（VLMs）在复杂图形推理中的表现，揭示了当前模型的局限性，并提出双重优化策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估VLMs在复杂图形推理任务中的表现，填补现有研究在复杂图形推理和抽象问题解决上的空白。

Method: 提出ReasonBench基准，包含1,613个真实世界智力测试问题，涵盖位置、属性、数量和多元素任务；提出DiaCoT和ReasonTune双重优化策略。

Result: 评估11种主流VLMs，发现显著局限性；双重优化策略使VLM性能提升33.5%。

Conclusion: ReasonBench为复杂图形推理提供了全面评估框架，双重优化策略显著提升模型性能，为未来研究指明方向。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [14] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: R1-Act是一种简单高效的后训练方法，通过结构化推理触发安全知识，显著提升大型推理模型的安全性，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 研究大型推理模型（LRMs）在满足有害用户指令时的安全隐患，发现模型已具备足够安全知识但未在推理中激活。

Method: 提出R1-Act方法，通过结构化推理过程显式触发安全知识，仅需少量训练数据和计算资源。

Result: R1-Act在安全性和推理性能上优于现有对齐方法，且具有鲁棒性和可扩展性。

Conclusion: R1-Act是一种实用高效的方法，显著提升了LRMs的安全性。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [15] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI框架通过引入视觉验证机制，改进了视觉语言模型中的推理过程，减少了幻觉现象，提升了推理性能和解释的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在推理过程中产生的幻觉问题，即解释虽流畅但缺乏视觉内容支持。

Method: 提出CoRGI框架，包含三个阶段：生成文本推理链、提取视觉证据、结合文本和视觉证据生成验证答案。

Result: 在VCR基准测试中，CoRGI提升了Qwen-2.5VL和LLaVA-1.6的推理性能，并生成更事实性和有帮助的解释。

Conclusion: 视觉验证对增强多模态推理的鲁棒性至关重要，CoRGI展示了其有效性，但也讨论了后验验证框架的潜在限制。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [16] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 提出了一种基于心智理论（ToM）的多智能体协作方法，通过主动推理实现，无需任务特定的共享生成模型或显式通信。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体协作中因缺乏心智理论导致的效率低下和冗余问题。

Method: 扩展推理树规划算法，递归探索联合策略空间，维护自身和他人的信念与目标。

Result: 在避碰和觅食任务中，ToM智能体表现优于非ToM智能体，能减少碰撞和冗余努力。

Conclusion: 该方法为人工智能应用提供了新思路，并深化了对ToM的计算理解。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [17] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro 是一个完全开源且免费的 AI 代理框架，旨在提升 AI 代理的可访问性和可复现性，并在多个领域实现高性能。


<details>
  <summary>Details</summary>
Motivation: 当前 AI 代理系统多为闭源或依赖付费 API，限制了研究和开发的开放性。

Method: 通过构建高质量的训练数据（查询、轨迹和可验证答案）和探索代理测试时的反思与投票策略。

Result: 在 GAIA 基准测试中达到开源代理的最高性能，8B 参数模型超越此前领先系统。

Conclusion: Cognitive Kernel-Pro 为高性能、可访问的 AI 代理设定了新标准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [18] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在数学领域的应用，尤其是形式化数学证明中的挑战，并分析了其与代码合成的差异。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在形式化数学证明中的表现，揭示其与编程任务的差异，并探讨其推理和监督机制。

Method: 通过分析最新模型和基准测试，探讨了形式化与非形式化数学训练、证明生成的脆弱性以及LLMs是否真正表示逻辑状态。

Result: 发现形式化数学证明比代码合成更具挑战性，LLMs可能仅模仿而非真正表示逻辑状态。

Conclusion: 论文旨在明确当前技术的局限性，并探讨如何扩展这些限制。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [19] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard是一个基于概率可达性分析的主动运行时安全框架，用于预测和预防LLM代理的不安全行为。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则的安全系统（如AgentSpec）缺乏预见性，难以应对长期依赖和分布变化，因此需要一种更主动的安全框架。

Method: Pro2Guard将代理行为抽象为符号状态，从执行轨迹中学习离散时间马尔可夫链（DTMC），并在运行时预测不安全状态的概率，触发干预。

Result: 在家庭代理任务中，Pro2Guard预防了93.6%的不安全任务；在自动驾驶场景中，100%预测了交通违规和碰撞，提前38.66秒预警。

Conclusion: Pro2Guard通过主动预测和干预，显著提升了LLM代理的安全性，同时在任务完成率和安全性之间提供了可配置的平衡。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [20] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP是一个模型无关的可解释性框架，利用Shapley Interaction Index量化多模态AI模型中视觉和文本元素的交互作用，适用于开源和闭源模型。


<details>
  <summary>Details</summary>
Motivation: 多模态AI模型的'黑盒'特性在高风险应用中限制了其部署，现有解释方法无法精确量化模态间的协同效应。

Method: 引入MultiSHAP框架，通过Shapley Interaction Index分析视觉和文本元素的交互作用，提供实例级和数据集级解释。

Result: 实验证实MultiSHAP能准确捕捉多模态推理机制，并在实际案例中展示了实用性。

Conclusion: MultiSHAP为复杂多模态AI模型提供了一种通用的可解释性解决方案，并可扩展至多种模态。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [21] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 提出了一种多阶段LLM驱动框架，用于从复杂电子病历（EMR）生成全面的预咨询问卷，解决了直接LLM方法在信息完整性、逻辑顺序和疾病级合成方面的不足。


<details>
  <summary>Details</summary>
Motivation: 预咨询是有效医疗交付的关键环节，但直接从复杂、大量的EMR生成问卷存在挑战，尤其是信息完整性和逻辑性方面。

Method: 采用三阶段框架：1）从EMR提取原子断言；2）构建个人因果网络并合成疾病知识；3）生成个性化及标准化问卷。

Result: 在真实EMR数据集上评估，临床专家验证，方法在信息覆盖、诊断相关性、可理解性和生成时间上表现优越。

Conclusion: 该框架通过显式临床知识构建，显著提升了预咨询问卷的质量和效率，具有实际应用潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [22] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 论文提出AVR-Eval评估多媒体内容质量的指标和AVR-Agent多代理系统，用于生成和改进JavaScript代码。实验表明AVR-Agent生成的内容优于单次生成，但模型在利用定制资源和反馈方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 解决AI在生成交互式音视频内容（如游戏）时缺乏自动化评估指标和复杂内容生成能力的挑战。

Method: 提出AVR-Eval评估指标和AVR-Agent多代理系统，结合多媒体资源和迭代反馈生成代码。

Result: AVR-Agent生成的内容质量显著优于单次生成，但模型未能有效利用定制资源和反馈。

Conclusion: 当前模型在利用高质量资源和反馈方面与人类存在差距，揭示了机器与人类内容创作的根本差异。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [23] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 提出了一种结合传统XAI技术与生成式AI模型的混合框架，以生成多模态、个性化的解释，提升教育中AI系统的透明度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 当前自适应学习系统缺乏透明度，且XAI技术忽视用户角色和理解需求，亟需一种更动态、用户中心的解释方法。

Method: 整合传统XAI技术与生成式AI模型，结合用户个性化需求，设计动态解释框架。

Result: 框架重新定义可解释性为动态沟通过程，支持用户角色和学习目标，并提出研究方向。

Conclusion: 目标是推动可解释AI在提升透明度的同时，优化用户中心体验。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [24] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 提出一种用户分段的视觉解释系统，适应不同用户需求，提升社交媒体的AI推荐可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体的AI推荐缺乏与用户特定需求对齐的解释性，导致用户不理解推荐原因，影响体验。

Method: 设计一个用户分段和上下文感知的视觉解释系统，提供不同形式的解释（如技术详细版和简化版）。

Result: 系统首次在一个流程中联合调整解释风格（视觉vs数字）和粒度（专家vs普通用户）。

Conclusion: 通过30名X用户的公开试点验证系统对决策和信任的影响。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [25] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 提出了一种基于大型预训练多模态模型的通用生成内容检测方法，通过线性分类器在多种数据模态上实现高效且高性能的检测。


<details>
  <summary>Details</summary>
Motivation: 恶意用户利用生成模型传播虚假信息，现有检测工具泛化能力差，亟需通用且高效的检测方法。

Method: 利用大型预训练多模态模型的潜在编码特征，训练线性分类器进行真假内容判别。

Result: 在音频和图像领域，该方法性能优于或匹配现有基线方法，且计算高效、训练快速。

Conclusion: 大型多模态模型的潜在编码特征能有效区分真假内容，为通用生成内容检测提供了可行方案。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [26] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 本文探讨了表格在LLMs和MLLMs中的重要性，提出了表格输入表示的分类法，并指出了当前研究中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 表格因其复杂和灵活的结构在LLMs和MLLMs中备受关注，但缺乏通用方法，导致理解任务具有挑战性。

Method: 通过分类法分析表格输入表示，并介绍表格理解任务。

Result: 指出了三个关键研究空白：检索任务主导、复杂表格处理困难、模型泛化能力有限。

Conclusion: 需要进一步研究以解决表格理解中的挑战。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [27] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 评估前沿大语言模型（LLM）解决物理问题的能力，采用多代理框架和推理技术提升性能，并引入新评估基准PHYSICSEVAL。


<details>
  <summary>Details</summary>
Motivation: 物理问题是自然语言推理的重要领域，研究LLM在此领域的表现及改进方法。

Method: 使用多代理框架和推理技术验证解决方案，并进行性能对比分析。

Result: 多代理框架显著提升了模型在初始表现较差问题上的性能。

Conclusion: 引入新基准PHYSICSEVAL，公开代码和数据，为未来研究提供资源。

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [28] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: 研究通过词汇多样性比较LLM生成文本与人类写作，发现LLM文本与人类文本在词汇多样性上存在显著差异，且新模型（如ChatGPT-4.5）更不接近人类写作。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM生成的文本在词汇多样性上是否真正接近人类写作，以填补现有研究的空白。

Method: 比较四种ChatGPT模型与240名L1和L2英语参与者的文本，测量六个词汇多样性维度，使用MANOVA、ANOVA和支持向量机分析数据。

Result: LLM生成的文本在词汇多样性上与人类文本显著不同，新模型（如ChatGPT-4.5）差异最大，且人类写作的词汇多样性在不同子组间无差异。

Conclusion: LLM生成的文本在词汇多样性上不接近人类写作，新模型表现更差，这对语言教学和相关应用有启示。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [29] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 论文呼吁计算人文学科中方法的理论化，以提升认识论和解释的清晰度，并提出了将建模工作视为翻译过程的框架。


<details>
  <summary>Details</summary>
Motivation: 计算人文学科需要更多方法理论化以促进领域成熟，避免翻译错误并增强解释透明度。

Method: 将建模工作视为从文化语言领域到计算数学领域的翻译过程，并引入符号复杂性概念。

Result: 指出当前建模实践中因忽视符号复杂性而导致的翻译错误，并提出改进建议。

Conclusion: 建议研究者更好地处理认识论问题，避免将符号复杂数据简化为符号简单数据。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [30] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: FACTORY是一个大规模、人工验证的提示集，用于评估模型生成准确、全面回答的能力，结果显示现有模型的40%回答存在事实错误。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试缺乏人工验证，可能导致质量问题，因此开发了FACTORY以提供更可靠的评估工具。

Method: 采用模型辅助和人工精炼的方法构建FACTORY提示集，并对6种先进语言模型进行人工评估。

Result: FACTORY更具挑战性，SOTA模型的40%回答存在事实错误，而其他数据集仅为10%。

Conclusion: FACTORY在可靠性和评估长尾事实推理能力方面优于现有基准，强调了其必要性。

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [31] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: 论文研究了神经语义解析器在强上下文敏感现象（如动词短语省略）中的表现，发现尽管在标准测试集上表现优异，但在省略现象中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探讨神经语义解析器在处理需要大量语义信息复制的强上下文敏感现象（如动词短语省略）时的能力。

Method: 构建了一个包含120个省略案例及其完整语义表示的语料库，并作为挑战集测试多种神经语义解析器。

Result: 解析器在标准测试集上表现优异（语义匹配分数超过90%），但在省略案例中表现失败。

Conclusion: 神经语义解析器在强上下文敏感现象中表现不足，数据增强可能是一种解决方案。

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [32] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: 本文比较了大型语言模型（LLM）的基础和领域特定模型，帮助研究者和公司根据许可和硬件需求选择最佳模型。


<details>
  <summary>Details</summary>
Motivation: 随着开源LLM的增多，选择适合的模型变得复杂，因此需要系统化的比较工具。

Method: 通过整理和比较不同LLM的特征（如发布年份、许可和硬件需求），创建并发布了一个持续更新的列表。

Result: 提供了一个公开的、可更新的LLM比较列表，方便用户选择。

Conclusion: 该工具简化了LLM选择过程，并将在未来持续更新以适应快速发展的LLM领域。

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [33] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 论文探讨了离散小波变换（DWT）在词和句子嵌入中的应用，展示了其在多分辨率分析和压缩嵌入表示方面的能力，同时保持语义质量。


<details>
  <summary>Details</summary>
Motivation: 小波变换在信号和图像处理中表现优异，但其在自然语言处理（NLP）中的应用潜力尚未充分挖掘。本文旨在探索DWT在NLP中的实际效果。

Method: 通过将DWT应用于词和句子嵌入，分析其在多分辨率下的表现，并评估其在语义相似性任务中的有效性。

Result: DWT能将嵌入维度减少50-93%，同时几乎不影响语义相似性任务的性能，并在下游任务中表现更优。

Conclusion: DWT为改进NLP应用提供了新途径，尤其在嵌入压缩和语义信息提取方面具有潜力。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [34] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）对人类语言使用的影响，发现2022年后人类语言中与LLM相关的词汇使用显著增加。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否正在改变人类语言系统本身，而不仅仅是作为工具生成文本。

Method: 构建了一个包含2210万单词的非脚本口语数据集，分析ChatGPT发布前后词汇使用趋势。

Result: 2022年后，与LLM相关的词汇使用显著增加，而基线同义词无明显变化。

Conclusion: 这可能标志着语言使用的重大转变，但驱动因素是自然语言变化还是AI影响尚不明确。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [35] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 该研究提出了一种病因感知注意力引导框架，通过整合结构化临床推理提升LLMs在复杂临床场景中的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在医学文本理解和生成方面表现出色，但其在复杂临床诊断中的可靠性有限，需要提升其诊断准确性和临床推理能力。

Method: 研究构建了基于权威临床指南的临床推理支架（CRS），开发了病因感知头识别算法，并通过推理引导的参数高效微调将病因推理线索嵌入输入表示。

Result: 在一致性诊断队列中，框架将平均诊断准确性提高了15.65%，推理聚焦分数提高了31.6%。外部验证进一步证实了其有效性。

Conclusion: 该框架通过将模型注意力与结构化CRS对齐，为构建更可解释和可靠的AI诊断系统提供了实用方法。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [36] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 本文系统评估了大型语言模型（LLM）的优化技术（如剪枝、量化和令牌丢弃）在长上下文场景下的表现，揭示了组合优化对大型模型的负面影响，并强调了系统级分析与任务特定指标结合的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多种任务中表现出色，但其资源需求和有限上下文窗口问题尚未得到充分研究，尤其是在长上下文场景下。

Method: 通过系统化基准测试，分析内存使用、延迟和吞吐量，并研究优化技术对文本生成质量的影响。进一步评估了组合优化方法在70B参数模型上的可扩展性。

Result: 研究发现，组合优化方法可能因累积近似误差对大型模型产生负面影响，且仅依赖F1分数会掩盖问答任务中的精度-召回权衡。

Conclusion: 结合系统级分析和任务特定指标，有助于LLM实践者和研究者在效率和准确性之间找到平衡。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [37] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: MCSEO提出了一种通过细粒度对象-短语对齐增强多模态句子嵌入的方法，优于传统基线。


<details>
  <summary>Details</summary>
Motivation: 多模态句子嵌入模型训练中，图像-标题对常包含冗余或无关信息，影响性能。

Method: 利用分割和对象检测模型提取准确的对象-短语对，优化对比学习目标。

Result: 在语义文本相似性任务中，MCSEO表现优于基线模型。

Conclusion: 精确的对象-短语对齐对多模态表示学习至关重要。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [38] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为AdaPlan的自适应全局规划代理范式，结合了PilotRL框架，通过渐进式强化学习提升LLM在长时决策任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法如ReAct在复杂任务中表现有限，且监督微调导致模型泛化能力不足。

Method: 提出AdaPlan范式，结合PilotRL框架，通过渐进式强化学习优化规划和执行协调。

Result: 实验显示PilotRL性能优异，LLaMA3.1-8B-Instruct + PilotRL超越GPT-4o 3.60%，比GPT-4o-mini提升55.78%。

Conclusion: AdaPlan和PilotRL有效解决了长时决策任务中的规划和执行协调问题，显著提升了LLM代理的性能。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [39] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 小语言模型（SLMs）在知识密集型任务中表现受限，但通过动态任务向量机器（dynamic task vector machine）和强化学习优化，1.7B参数的Lucy模型在SimpleQA基准测试中达到78.3%准确率，媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型在知识密集型任务中因容量限制表现不佳的问题，探索动态推理机制提升性能。

Method: 提出动态任务向量机器，将模型内部推理（<think>和</think>标签内）视为动态任务向量，通过RLVR优化，并整合MCP训练代理式网络搜索模型。

Result: Lucy模型（1.7B参数）在SimpleQA基准测试中达到78.3%准确率，与更大模型（如DeepSeek-V3）表现相当。

Conclusion: 小模型通过结构化、自构建的任务推理机制，能够媲美大模型性能。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [40] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: EdgeInfinite-Instruct通过分段监督微调（S-SFT）和细粒度后训练量化（PTQ）优化了Transformer模型在边缘设备上的部署，提升了长序列任务的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的边缘设备上部署大型Transformer模型面临计算和内存效率的挑战，现有方法在减少首字时间（TTFT）和保持性能方面存在不足。

Method: 提出EdgeInfinite-Instruct，采用S-SFT策略和PTQ量化技术，优化输入令牌和缓存大小的固定形状计算图。

Result: 实验表明，该方法在长上下文基准测试和实际移动任务中提升了性能，同时保持了边缘NPU设备的效率。

Conclusion: EdgeInfinite-Instruct为边缘设备上的长序列任务提供了一种高效且性能优越的解决方案。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [41] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 本文研究了上下文学习（ICL）中演示无效的原因，提出了一种基于梯度流的演示选择方法GradS，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设ICL中的演示总是有效，但实际并非如此。本文旨在探究演示无效的原因并提出解决方案。

Method: 通过梯度流和线性自注意力模型分析演示无效性，提出GradS方法，利用梯度流幅度选择演示。

Result: 实验验证了演示有效性随模型层数增加的差异，GradS在五个数据集上平均相对提升6.8%。

Conclusion: GradS通过梯度流选择演示，显著提升了ICL性能，为演示选择提供了新思路。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [42] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: 提出了一种名为SA-GCS的训练框架，通过结合课程学习与强化学习，解决了现有方法在数据利用效率、收敛速度和样本难度差异上的不足。


<details>
  <summary>Details</summary>
Motivation: 当前基于强化学习的无人机视觉语言导航方法存在训练数据利用效率低、收敛慢及样本难度差异处理不足的问题，限制了性能提升。

Method: 提出SA-GCS框架，包含语义感知难度估计器（SA-DE）和高斯课程调度器（GCS），动态调整样本分布以实现从易到难的渐进训练。

Result: 在CityNav基准测试中，SA-GCS在所有指标上均优于基线方法，收敛更快且更稳定，且在不同规模模型上表现出良好的泛化能力。

Conclusion: SA-GCS通过系统整合课程学习与强化学习，显著提升了训练效率和模型性能，具有鲁棒性和可扩展性。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [43] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: 本文探讨了离散小波变换（DWT）在词和句子嵌入中的应用，提出了一种结合DWT和离散余弦变换（DCT）的非参数化模型，用于压缩句子信息。实验表明该方法在下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 小波技术在图像和信号处理中表现优异，作者希望将其应用于自然语言处理（NLP）任务，以捕捉多种语言特性。

Method: 应用DWT处理词和句子嵌入，结合DCT提出非参数化模型，压缩句子信息为固定大小的向量。

Result: 实验证明该方法在降低词向量维度的同时保留了重要信息，且在下游任务中表现优于原始嵌入。

Conclusion: 小波变换在NLP任务中具有潜力，提出的方法为信息压缩和任务性能提升提供了有效途径。

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [44] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: ReaGAN提出了一种基于代理的框架，通过节点级自主决策和检索增强生成，解决了传统GNN在节点信息不平衡和全局语义关系捕捉上的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统GNN的固定聚合机制无法处理节点信息不平衡和忽略全局语义关系的问题。

Method: ReaGAN框架中，每个节点作为代理自主决策，结合检索增强生成（RAG）访问全局语义内容。

Result: ReaGAN在少样本情境下表现优异，无需微调冻结的LLM骨干网络。

Conclusion: ReaGAN展示了代理规划和局部-全局检索在图学习中的潜力。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [45] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出了一种高效的多轮对话评估方法，通过将多个LLM评委的偏好知识聚合到单一模型中，降低计算开销，同时保持评估质量。


<details>
  <summary>Details</summary>
Motivation: 当前依赖单一LLM评委的方法存在偏见问题，多评委方法虽有效但计算成本高，需一种更高效且可靠的评估方案。

Method: 提出一种多轮对话评估器，聚合多个LLM评委的偏好知识到单一模型，减少计算开销。

Result: 在七个对话评估基准测试中表现优于现有基线，展示了高效性和鲁棒性。

Conclusion: 该方法在降低计算成本的同时，保持了多评委方法的优势，适用于快速灵活的对话质量评估。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [46] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: GETALP团队在SIGDial 2025的自动会议纪要任务中提交了基于检索增强生成（RAG）和抽象意义表示（AMR）的系统，结果显示AMR显著提升了部分问题的回答质量。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过结合RAG和AMR技术提升基于会议转录的问答任务性能。

Method: 提出三种结合RAG和AMR的系统，用于处理会议转录中的问答任务。

Result: AMR显著提升了约35%问题的回答质量，尤其在区分参与者的问题（如“谁”类问题）上表现突出。

Conclusion: 结合RAG和AMR的方法在会议转录问答任务中具有潜力，特别是在处理复杂问题时效果显著。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [47] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 论文提出了一种检测半真半假陈述的任务，并开发了TRACER框架，通过分析证据对齐和隐含意图来识别误导性信息。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统无法处理因关键上下文缺失而导致的半真半假陈述，需要新的方法来解决这一问题。

Method: 提出了PolitiFact-Hidden基准数据集，并设计了TRACER框架，通过证据对齐、意图推断和隐藏内容因果分析来检测误导性信息。

Result: TRACER显著提升了半真半假分类的F1分数（最高提升16分），验证了其有效性。

Conclusion: 建模遗漏信息对于可信的事实核查至关重要，TRACER框架为现有系统提供了改进方向。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [48] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: 论文提出Flat-LoRA和EFlat-LoRA，通过寻找平坦最小值提升LoRA的泛化能力，实验证明其在效率和性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索LoRA的表达能力与泛化能力之间的关系，并填补现有方法在平坦最小值与泛化能力联系上的研究空白。

Method: 提出Flat-LoRA和EFlat-LoRA，理论证明全参数空间的扰动可转移到低秩子空间，避免多矩阵干扰。

Result: EFlat-LoRA在GLUE和视觉语言模型任务中表现优于LoRA和全微调，验证了泛化与尖锐度的关联。

Conclusion: EFlat-LoRA在保持效率的同时提升性能，证实了平坦最小值对LoRA泛化能力的重要性。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [49] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: 研究探讨了表情符号如何影响语音中的韵律实现，以及听众如何通过韵律线索理解表情符号的含义。


<details>
  <summary>Details</summary>
Motivation: 在文本交流中，缺乏韵律特征（如音高、节奏和语调），表情符号作为视觉替代品传递情感和语用信息。研究旨在直接关联韵律与表情符号，填补现有研究的空白。

Method: 通过结构化的开放式生产和感知任务收集真实人类语音数据，分析表情符号语义如何影响语音表达和感知。

Result: 说话者会根据表情符号调整韵律，听众常能仅通过韵律变化识别表情符号，且表情符号语义差异越大，韵律差异越明显。

Conclusion: 表情符号可作为韵律意图的有意义载体，揭示了其在数字媒介中的交际作用。

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [50] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: 论文提出了一种名为PaPaformer的变体架构，通过并行路径训练和组合小型模型，显著减少训练时间和参数数量，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型训练需要大量计算资源和时间，即使是小型模型也需要多天和多GPU支持。本文旨在探索快速训练和评估解码器-仅变压器语言模型的方法。

Method: 引入PaPaformer架构，通过并行路径训练低维路径，再组合成更大模型。支持不同训练数据和任务定制。

Result: 该方法减少了模型参数和训练时间，同时提高了性能，并支持任务定制。

Conclusion: PaPaformer为高效训练语言模型提供了新思路，具有减少资源消耗和定制化的潜力。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [51] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
*Muhammad Farid Adilazuarda,Musa Izzanardi Wijanarko,Lucky Susanto,Khumaisa Nur'aini,Derry Wijaya,Alham Fikri Aji*

Main category: cs.CL

TL;DR: NusaAksara是一个新的印尼语言公共基准数据集，涵盖原始脚本，支持多模态任务，但现有NLP技术对其处理能力有限。


<details>
  <summary>Details</summary>
Motivation: 印尼语言丰富，但NLP研究多基于罗马化文本，缺乏对原始脚本的支持。

Method: 通过专家构建数据集，涵盖8种脚本和7种语言，包括低资源语言，并测试多种模型。

Result: 大多数NLP技术对印尼本地脚本处理能力差，部分模型表现接近零。

Conclusion: NusaAksara填补了印尼语言原始脚本的基准空白，但需改进NLP技术以支持这些脚本。

Abstract: Indonesia is rich in languages and scripts. However, most NLP progress has
been made using romanized text. In this paper, we present NusaAksara, a novel
public benchmark for Indonesian languages that includes their original scripts.
Our benchmark covers both text and image modalities and encompasses diverse
tasks such as image segmentation, OCR, transliteration, translation, and
language identification. Our data is constructed by human experts through
rigorous steps. NusaAksara covers 8 scripts across 7 languages, including
low-resource languages not commonly seen in NLP benchmarks. Although
unsupported by Unicode, the Lampung script is included in this dataset. We
benchmark our data across several models, from LLMs and VLMs such as GPT-4o,
Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and
show that most NLP technologies cannot handle Indonesia's local scripts, with
many achieving near-zero performance.

</details>


### [52] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: 论文提出SynAdapt框架，通过生成合成连续思维链（CCoT）优化模型推理效率，并结合难度分类器提升对难题的解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有连续思维链（CCoT）方法存在间接微调、对齐不足或目标不一致的问题，影响了推理效率和准确性。

Method: SynAdapt生成合成CCoT作为对齐目标，并引入难度分类器动态调整对难题的推理策略。

Result: 实验表明，SynAdapt在多个基准测试中实现了最佳的准确性与效率平衡。

Conclusion: SynAdapt通过合成CCoT和动态推理策略，显著提升了模型的推理效率和准确性。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [53] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: CRUX框架通过结合上下文忠实性和一致性，提出两种新指标，显著提升了大型语言模型的置信度估计效果。


<details>
  <summary>Details</summary>
Motivation: 当前LLM置信度估计方法忽略响应与上下文的相关性，CRUX旨在填补这一空白，提升输出质量评估的可靠性。

Method: 提出CRUX框架，引入上下文熵减和统一一致性检查两种新指标，分别衡量数据不确定性和模型不确定性。

Result: 在多个基准数据集上，CRUX的AUROC表现优于现有基线方法。

Conclusion: CRUX通过上下文感知的置信度估计，为LLM的可靠部署提供了有效工具。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [54] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 提出了一种基于图卷积网络（GCN）的新型主题模型GHTM，用于解决孟加拉语主题建模的挑战，并在实验中优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语因其形态复杂性和资源匮乏，主题建模研究不足，需要更有效的模型。

Method: 使用GCN生成文档的语义嵌入，并通过非负矩阵分解（NMF）提取主题表示。

Result: GHTM在主题一致性和多样性上优于传统和现代方法。

Conclusion: GHTM为孟加拉语主题建模提供了有效解决方案，并引入了新的数据集NCTBText。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [55] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 研究发现，威胁或奖励AI模型对基准性能无显著影响，但提示变化可能对单个问题表现有显著影响。


<details>
  <summary>Details</summary>
Motivation: 验证两种常见提示策略（奖励和威胁）对AI模型性能的实际效果。

Method: 在GPQA和MMLU-Pro基准上测试威胁和奖励提示对模型性能的影响。

Result: 威胁或奖励对整体性能无显著影响，但对单个问题的表现可能有显著差异。

Conclusion: 简单的提示变化可能不如预期有效，但对特定问题可能有显著影响。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [56] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: 论文分析了现有AI生成文本检测器的不足，提出了DACTYL数据集和两种优化方法（BCE和DXO），发现DXO在泛化性上表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在真实场景中表现不佳，尤其是在少样本和领域特定文本上。

Method: 引入DACTYL数据集，包含少样本和领域特定文本，并比较BCE和DXO两种优化方法。

Result: DXO优化方法在泛化性上优于BCE，尤其在OOD文本上表现突出。

Conclusion: DXO方法能更好地泛化，为AI生成文本检测器提供了改进方向。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [57] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）在医学领域的应用，重点探讨了其在系统化、透明化和可验证推理能力上的不足，并提出了增强推理技术的分类和未来方向。


<details>
  <summary>Details</summary>
Motivation: 医学实践中系统化、透明化和可验证的推理至关重要，但现有LLMs在此方面存在不足，因此需要开发专门用于医学推理的模型。

Method: 提出了推理增强技术的分类，包括训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统），并分析了这些技术在不同数据模态和临床任务中的应用。

Result: 通过分析60项研究（2022-2025），总结了评估标准的演变，并指出了当前挑战，如忠实性与合理性之间的差距以及多模态推理的需求。

Conclusion: 未来研究方向包括构建高效、稳健且社会技术责任明确的医学AI，以解决现有挑战。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [58] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 该论文针对大型语言模型（LLMs）在非西方文化和语言（波斯语和伊朗文化）中的评估不足问题，提出了19个新的评估数据集，并对41个主流LLMs进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs的评估资源主要集中在英语和西方文化背景，缺乏对其他语言和文化的覆盖，尤其是波斯语和伊朗文化。

Method: 研究设计了19个针对波斯语和伊朗文化的评估数据集，涵盖法律、语法、习语和考试等内容，并对41个LLMs进行了测试。

Result: 通过新数据集，研究填补了LLMs在波斯语和伊朗文化评估方面的空白，并提供了对这些模型的性能基准。

Conclusion: 该研究为LLMs在非西方语言和文化中的评估提供了重要资源，推动了该领域的多样性和包容性。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [59] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 论文提出了一种基于预训练语言模型和双向LSTM的序列句子对分类器（SSPC），用于检测文档中的风格变化，并在PAN 2025任务中取得了优于基线的表现。


<details>
  <summary>Details</summary>
Motivation: 风格变化检测是计算作者分析中最重要且具挑战性的问题之一，尤其是在句子级别的细粒度检测。

Method: 使用预训练语言模型（PLM）提取句子表示，通过双向LSTM（BiLSTM）进行上下文建模，最后用多层感知机预测相邻句子的风格变化。

Result: 在PAN-2025测试数据集上，模型在EASY、MEDIUM和HARD数据上的宏F1分数分别为0.923、0.828和0.724，优于随机基线和零样本性能。

Conclusion: 该方法通过上下文信息有效解决了短句子风格变化检测的挑战，表现优于现有基线。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [60] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: TraceRetriever是一种法律先例检索系统，通过结合BM25、向量数据库和交叉编码器模型，仅提取修辞显著片段，解决了传统方法在文档复杂性和数量上的挑战。


<details>
  <summary>Details</summary>
Motivation: 法律先例检索在普通法体系中至关重要，但传统方法难以应对日益复杂的法律文档数量和复杂性。

Method: 系统整合BM25、向量数据库和交叉编码器模型，通过分层BiLSTM CRF分类器生成修辞标注，并使用互惠排名融合进行结果整合。

Result: 在IL-PCR和COLIEE 2025数据集上评估，TraceRetriever能够有效应对文档数量增长，并在部分案例知识可用时提升检索效果。

Conclusion: TraceRetriever为法律研究提供了可靠且可扩展的先例检索基础，尤其适用于信息不完整的情况。

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [61] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在句子级风格变化检测任务中的零样本性能，发现其对写作风格变化敏感，并建立了具有挑战性的基线。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在作者分析中最具挑战性的任务之一——句子级风格变化检测中的表现。

Method: 在PAN~2024和2025数据集上对四种LLMs进行基准测试。

Result: LLMs对写作风格变化敏感，其准确性优于PAN竞赛的基线，且对内容无关的风格信号更敏感。

Conclusion: 最新一代LLMs在风格检测任务中表现出色，可能比之前报道的更依赖纯风格信号。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [62] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: NyayaRAG框架通过结合案件事实、法律条文和先例，提升了印度法律判决预测的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在印度法律环境中忽视了法律条文和先例的重要性，NyayaRAG旨在填补这一空白。

Method: 提出NyayaRAG框架，结合检索增强生成技术，模拟法庭场景，整合案件事实、法律条文和先例。

Result: 实验表明，结合结构化法律知识显著提高了预测准确性和解释质量。

Conclusion: NyayaRAG为法律判决预测提供了更全面和解释性强的解决方案。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [63] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: DAMR框架结合符号搜索与自适应路径评估，通过MCTS和轻量级Transformer评分器提升KGQA的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有KGQA方法中静态路径提取适应性差和动态路径生成计算成本高的问题。

Method: 使用MCTS和LLM规划器选择相关关系，引入Transformer评分器进行上下文感知路径评估，并动态生成伪路径优化训练。

Result: 在多个KGQA基准测试中显著优于现有方法。

Conclusion: DAMR通过动态自适应路径评估和上下文感知推理，实现了高效且准确的KGQA。

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [64] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: 研究探讨大型语言模型（LLM）是否能够从训练数据中推理信息，重点关注其“上下文外溯因”能力。实验发现GPT 4o能够根据行为描述推断虚构聊天机器人的名称，并表现出更符合其描述的行为。


<details>
  <summary>Details</summary>
Motivation: 验证LLM是否能够利用训练数据中的信息进行推理，尤其是缺乏直接对话示例的情况下。

Method: 训练LLM学习虚构聊天机器人的名称和行为描述，但不提供对话示例，观察其推理能力。

Result: GPT 4o能够正确推断聊天机器人名称，并在后续训练中表现出更符合描述的行为。

Conclusion: 研究结果表明LLM具备一定的情境感知能力，对AI安全性有重要启示。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [65] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 论文探讨了基于角色的生成代理（GPT-4驱动）在社会科学研究中作为人类替代品的有效性，通过HEXACO人格测试验证其一致性、可靠性及模型偏差。


<details>
  <summary>Details</summary>
Motivation: 验证生成代理是否能有效代表人类群体，尤其是在人格特质研究中。

Method: 通过调查310个GPT-4驱动的代理，进行因子分析，并与2004年HEXACO原始结果对比。

Result: 代理的响应显示出与HEXACO框架的部分一致性，模型间存在偏差，但足够优化的代理群体表现可靠。

Conclusion: 生成代理在社会科学研究中有潜力，但需注意模型偏差和设计优化以提高代表性。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [66] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 提出了一种基于代理的RAG框架，通过LLMs自主分解放射学问题并迭代检索临床证据，显著提高了诊断准确性和事实性。


<details>
  <summary>Details</summary>
Motivation: 传统单步检索的RAG系统在复杂临床推理任务中表现有限，需要更高效的解决方案。

Method: 采用代理RAG框架，让LLMs分解问题、迭代检索Radiopaedia证据并动态合成回答，评估了24种不同架构的LLMs。

Result: 代理检索显著提高了诊断准确性（73% vs. 64%），减少了幻觉（9.4%），并在46%的案例中检索到相关临床背景。

Conclusion: 代理框架能有效提升放射学QA的事实性和准确性，尤其对中型LLMs效果显著，值得进一步临床验证。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [67] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: GLiDRE是一种基于GLiNER思想的新型文档级关系抽取模型，在少样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在零样本或少样本设置下的性能未充分探索，GLiNER的成功启发我们开发更高效的模型。

Method: 基于GLiNER的关键思想，提出GLiDRE模型，并在Re-DocRED数据集上评估。

Result: GLiDRE在少样本场景下达到最先进性能。

Conclusion: GLiDRE为文档级关系抽取提供了一种高效解决方案，尤其在少样本场景下表现突出。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [68] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: 提出了一种基于BERT的多模态框架MMBERT，用于中文社交媒体中的仇恨言论检测，通过混合专家架构整合文本、语音和视觉模态，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 中文社交媒体中仇恨言论检测面临独特挑战，现有研究多集中于英文数据集，且缺乏多模态策略。

Method: 提出MMBERT框架，结合文本、语音和视觉模态，采用混合专家架构和三阶段训练范式，增强对抗性扰动的鲁棒性。

Result: 在多个中文仇恨言论数据集上，MMBERT显著优于微调的BERT模型、微调的大语言模型及上下文学习方法。

Conclusion: MMBERT为中文仇恨言论检测提供了一种有效的多模态解决方案，未来可扩展至其他语言和任务。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [69] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本文介绍了SemEval-2025 Task 8的零射解决方案，利用LLM生成Python代码进行表格问答，在开源模型类别中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决表格数据问答任务，探索LLM在代码生成中的效果。

Method: 提出基于开源LLM的Python代码生成框架，通过优化提示策略生成可执行的Pandas代码。

Result: 实验显示不同LLM在代码生成中效果各异，Python代码生成在表格问答中表现优于其他方法。系统在开源模型类别中排名第八和第六。

Conclusion: LLM生成的Python代码在表格问答任务中表现优越，但零射系统的整体排名尚未确定。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [70] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MISGENDERED+是一个更新的基准测试，用于评估大语言模型（LLMs）在代词使用上的表现，尤其是性别中立和新代词。结果显示在二元和性别中立代词上有进步，但在新代词和反向推理任务上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决LLMs在敏感语境中公平性和包容性的问题，特别是代词使用的挑战。

Method: 研究引入了MISGENDERED+基准，测试了五种代表性LLMs（如GPT-4o、Claude 4等）在零样本、少样本和性别身份推理任务上的表现。

Result: 结果显示在二元和性别中立代词上准确性有所提升，但在新代词和反向推理任务上表现不一致。

Conclusion: 研究指出了LLMs在身份敏感推理上的持续不足，并探讨了未来包容性AI研究的可能方向。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [71] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: DAEDAL是一种无需训练的动态自适应长度扩展策略，解决了扩散大语言模型（DLLMs）在生成长度上的静态限制，提升了计算效率和性能。


<details>
  <summary>Details</summary>
Motivation: DLLMs在应用中受限于静态预定义生成长度，导致性能与计算效率的权衡问题。

Method: DAEDAL通过两阶段策略动态调整生成长度：1）基于序列完成指标的初始长度扩展；2）在去噪过程中动态插入掩码标记以扩展不足区域。

Result: DAEDAL在性能上与固定长度基线相当或更优，同时显著提高计算效率。

Conclusion: DAEDAL解决了DLLMs的关键限制，为其实际应用开辟了新途径。

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [72] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 论文提出了一种名为QME的新型框架，通过可学习的分数融合策略提升全身生物特征识别的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的全身生物特征识别方法可能忽略个体模态分数分布的差异，限制了性能提升。

Method: QME框架结合了质量估计器和分数三元组损失，通过Mixture of Experts（MoE）实现可学习的分数融合。

Result: 在多个数据集上实验表明，QME在各项指标上均优于基线方法，达到最先进水平。

Conclusion: QME框架有效解决了多模态和多模型中的关键挑战，如相似性分数域中的模型不对齐和数据质量变化。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [73] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 论文探讨了动作识别模型在高层次动作概念跨上下文迁移中的表现，发现模型在新颖情境下性能显著下降，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 研究动机是评估动作识别模型在跨上下文迁移高层次动作概念（如“拳击”）时的有效性，尤其是在未见过的变体（如“拳击人”）中。

Method: 方法包括引入一个运动迁移性框架，使用三个数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA），并评估13个先进模型。

Result: 结果显示模型在新颖情境下性能显著下降，尤其是多模态模型在细粒度未知动作上表现更差，而大模型在空间线索主导时表现更好。

Conclusion: 结论是研究为动作识别中的运动迁移性评估提供了重要基准，并建议通过解耦粗粒度和细粒度动作来改进识别性能。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [74] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 论文介绍了Monado SLAM数据集，旨在解决头戴式传感器在复杂场景下的跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉惯性里程计（VIO）和SLAM系统在头戴式设备的高强度运动、动态遮挡等复杂场景中表现不佳，缺乏相关数据集。

Method: 通过收集多款虚拟现实头戴设备的真实序列数据，构建Monado SLAM数据集。

Result: 发布了CC BY 4.0许可的Monado SLAM数据集，推动VIO/SLAM研究发展。

Conclusion: Monado SLAM数据集填补了现有研究的空白，有助于提升头戴式设备在复杂场景中的跟踪性能。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [75] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 论文提出了一种基于卷积神经网络（CNN）的模型，利用眼周区域的颜色图像进行性别分类，在CVBL和（Female and Male）数据集上分别达到99%和96%的准确率。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互等领域至关重要，但化妆品和伪装等因素可能影响分类准确性。研究专注于眼周区域，因其包含丰富的视觉特征。

Method: 采用CNN模型，利用颜色图像数据库提取眼周区域的关键特征，并在CVBL和（Female and Male）数据集上验证性能。

Result: 模型在CVBL数据集上达到99%准确率，在（Female and Male）数据集上达到96%准确率，参数数量较少（7,235,089）。

Conclusion: 模型在性别分类中表现出色，适用于安全和监控等实际应用。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [76] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: World Consistency Score (WCS) 是一种新的生成视频模型评估指标，强调视频的内部世界一致性，整合了四个可解释的子组件，并通过学习权重公式生成一致性分数。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标主要关注视觉保真度或提示对齐，而忽略了时间与物理一致性，WCS旨在填补这一空白。

Method: WCS 结合了四个子指标（物体持久性、关系稳定性、因果合规性和闪烁惩罚），使用开源工具计算，并通过人类偏好数据训练权重。

Result: WCS 通过实验验证（如 VBench-2.0、EvalCrafter 等）与人类评估相关性高，且优于现有指标（如 FVD、CLIPScore）。

Conclusion: WCS 提供了一个全面且可解释的框架，用于评估视频生成模型在保持时间一致性方面的能力。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [77] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: GeoExplorer通过好奇心驱动的探索改进主动地理定位任务，提升了在陌生目标和环境中的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于距离奖励的强化学习方法在距离估计困难或面对陌生目标时表现不佳，需要更可靠的探索策略。

Method: 提出GeoExplorer，引入好奇心驱动的内在奖励，实现目标无关的多样化探索。

Result: 在四个AGL基准测试中验证了GeoExplorer的有效性，尤其在陌生目标和环境中表现优异。

Conclusion: 好奇心驱动的探索策略显著提升了AGL任务的鲁棒性和泛化能力。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [78] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: 论文提出了一种名为概率点云（PPC）的新型3D场景表示方法，通过为每个点添加概率属性来封装原始数据的不确定性，从而提升3D物体检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现代LiDAR在远距离或低反射率物体等场景中会产生稀疏或错误的点云，这些误差会传播到下游感知模型中，导致精度下降。传统3D处理流程未保留原始测量中的不确定性信息。

Method: 提出PPC表示方法，为每个点添加概率属性，并设计基于PPC的推理方法，可作为轻量级模块集成到3D推理流程中。

Result: 通过仿真和实际数据验证，PPC方法在室内外场景中优于LiDAR和相机-LiDAR融合模型，尤其在处理小、远、低反射率物体及强环境光时表现更优。

Conclusion: PPC通过保留不确定性信息显著提升了3D物体检测的鲁棒性，适用于多种挑战性场景。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [79] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 论文提出选择性模态转移（SMS）方法，量化视觉语言模型在二元分类任务中对模态的依赖，揭示模型偏向文本信息的现象。


<details>
  <summary>Details</summary>
Motivation: 临床决策需要综合分析医学图像和报告，但现有视觉语言模型可能偏向某一模态（如文本），忽略关键视觉信息。

Method: 通过交换样本中的图像或文本来扰动数据，评估模型对模态的依赖，测试了六种开源视觉语言模型。

Result: 模型在扰动后表现出对文本输入的显著依赖，视觉信息常被忽视。

Conclusion: 设计多模态医学模型时需确保视觉和文本信息的真正融合，而非依赖单一模态。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [80] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 论文定义了结构化图“谱系”，通过层次化增长，支持高效的代数操作和类型构造器，适用于机器学习和计算科学中的分层模型架构。


<details>
  <summary>Details</summary>
Motivation: 为机器学习和计算科学中的分层模型架构提供一种高效的图表示和操作方法。

Method: 定义层次化增长的图谱系，引入延长映射和骨架操作，推导出高效的代数操作和类型构造器。

Result: 提出了适用于分层模型架构的代数类型理论，并展示了在深度神经网络和多网格数值方法中的应用。

Conclusion: 该方法为分层模型架构和局部采样、搜索或优化算法提供了高效的理论基础。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [81] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 提出了一种基于个性化内部认知的自动真实人格识别方法，通过模拟目标个体的内部认知来提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常作为外部观察者推断人格印象，与真实人格存在显著偏差，导致识别性能较差。

Method: 提出了一种新颖的RPR方法，通过模拟个性化内部认知，并将其编码为二维图，利用2D-GNN进行人格推断。

Result: 通过端到端训练策略，实现了对真实人格相关认知的模拟和识别。

Conclusion: 该方法通过模拟内部认知，显著提升了真实人格识别的性能。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [82] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: SAM-PTx通过轻量级适配器设计，将CLIP文本嵌入注入SAM的图像编码器，提升语义引导的分割性能。


<details>
  <summary>Details</summary>
Motivation: 探索语义文本提示在分割任务中的潜力，弥补传统空间提示的不足。

Method: 提出Parallel-Text适配器，仅修改MLP并行分支，保留注意力路径，使用固定CLIP文本嵌入作为输入。

Result: 在COD10K、COCO和ADE20K数据集上，语义提示显著优于纯空间提示基线。

Conclusion: 语义条件集成是高效适应SAM的实用且可扩展路径。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [83] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 通过利用物体在图像中的局部位置信息，显著提升Few-Shot图像分类性能，且仅需少量标注或完全无监督方法即可实现。


<details>
  <summary>Details</summary>
Motivation: Few-Shot图像分类中，图像模糊性（如多物体或复杂背景）会显著降低性能，需探索更有效的方法。

Method: 结合物体局部位置信息，使用Segment Anything Model（仅需标注一个像素）或无监督前景提取方法。

Result: 在多个基准测试中，分类性能显著提升。

Conclusion: 局部位置信息和轻量级标注或无监督方法可有效提升Few-Shot分类性能。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [84] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 提出了一种多尺度融合U形Mamba模型（MSF-UM），用于深度图超分辨率，结合Mamba的高效状态空间建模能力和多尺度U形结构，显著提升重建精度并减少参数。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在处理长距离依赖和全局上下文信息时存在局限，而Transformer的计算复杂度和内存消耗较高，限制了其在高分辨率深度图处理中的应用。

Method: 设计了结合残差密集通道注意力块和Mamba状态空间模块的结构，利用多尺度跨模态融合策略，通过彩色图像的高频纹理信息指导深度图超分辨率。

Result: 相比主流方法，MSF-UM在减少模型参数的同时实现了更好的重建精度，并在多个公开数据集上验证了有效性，尤其在大规模深度图超分辨率任务中表现出色。

Conclusion: MSF-UM模型通过结合局部特征提取和长距离依赖建模，以及多尺度跨模态融合，显著提升了深度图超分辨率的性能，具有广泛的应用潜力。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [85] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss提出了一种基于点云的高斯泼溅表示实时多目标分割框架，通过点云分割驱动流程直接解析高斯基元，显著提升了多视图一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在初始化时间长和多视图一致性不足的问题，PointGauss旨在通过点云引导的高斯基元解析实现高效的3D分割。

Method: 1. 基于点云的高斯基元解码器，可在1分钟内生成3D实例掩码；2. GPU加速的2D掩码渲染系统，确保多视图一致性。

Result: 实验显示，PointGauss在多视图mIoU上比现有方法提升了1.89%至31.78%，同时保持高效计算。

Conclusion: PointGauss在效率和性能上均有显著提升，并提出了新数据集DesktopObjects-360，解决了现有基准的局限性。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [86] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 提出了一种新的持续学习框架，通过混合视觉投影器和专家推荐策略，解决生成式视觉语言模型在持续学习中忽视语言指令的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在持续学习中可能过度依赖视觉输入而忽视语言指令，尤其是在文本指令重复的任务中。

Method: 引入混合视觉投影器，每个投影器作为特定指令上下文的视觉-语言翻译专家；提出专家推荐策略和专家剪枝以减少干扰。

Result: 在多样化视觉语言任务上的实验表明，该方法优于现有持续学习方法，生成更符合指令的响应。

Conclusion: 该方法有效平衡了视觉和语言输入，提升了持续学习性能。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [87] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文综述了多模态指代分割任务，涵盖其背景、方法、性能比较及应用。


<details>
  <summary>Details</summary>
Motivation: 多模态指代分割在基于用户指令的精确对象感知中具有重要应用价值，近年来因神经网络和语言模型的进步而备受关注。

Method: 提出统一的元架构，并回顾了图像、视频和3D场景中的代表性方法，讨论了广义指代表达（GREx）方法。

Result: 提供了标准基准上的性能比较，总结了当前方法的优缺点。

Conclusion: 多模态指代分割是一个快速发展的领域，未来需进一步解决真实世界复杂性的挑战。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [88] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 论文提出了一个评估语义对应在恶劣条件下鲁棒性的新基准，发现现有方法在挑战性场景中表现显著下降，并探讨了大规模视觉模型和任务特定设计的作用。


<details>
  <summary>Details</summary>
Motivation: 语义对应在计算机视觉中至关重要，但其在恶劣条件下的鲁棒性研究较少。

Method: 建立包含14种挑战性场景的基准数据集，评估现有方法的性能，并分析大规模视觉模型和增强策略的效果。

Result: 现有方法在恶劣条件下性能下降；大规模模型提升鲁棒性，但微调会降低相对鲁棒性；DINO模型优于Stable Diffusion。

Conclusion: 任务特定的设计对提升语义对应的鲁棒性至关重要，通用数据增强效果有限。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [89] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 提出了一种基于空间自注意力机制和LSTM的驾驶员疲劳检测框架，结合联邦学习和梯度相似性比较，实现了高精度和隐私保护的疲劳检测。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是交通事故的主要原因之一，但在真实场景中，由于数据的分散性和多样性，准确检测疲劳仍然具有挑战性。

Method: 开发了空间自注意力机制（SSA）与LSTM结合的网络，并采用梯度相似性比较（GSC）优化联邦学习模型聚合。

Result: 在联邦学习设置下，检测准确率达到89.9%，优于现有方法。

Conclusion: 该方法能有效处理真实世界数据的多样性，有望应用于智能交通系统以提升道路安全。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [90] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: 提出了一种名为TITAN-Guide的训练自由引导方法，用于优化文本到视频扩散模型的推理时间对齐，解决了内存和性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有训练自由引导框架存在内存需求高或控制效果不佳的问题，限制了其在计算密集型任务（如文本到视频扩散模型）中的应用。

Method: 开发了一种无需反向传播的高效扩散潜在优化方法，研究了前向梯度下降及其方向性指导选项。

Result: 实验表明，该方法在内存管理和潜在优化方面优于现有方法，显著提升了文本到视频扩散模型的性能。

Conclusion: TITAN-Guide不仅降低了内存需求，还在多个扩散引导基准测试中表现出色。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [91] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+ 是一个扩展的框架，用于统一重建哺乳动物和鸟类的姿态与形状，通过高容量的 Vision Transformer 和合成数据集解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 在基础模型时代，通过单一网络统一理解动态对象的需求日益增长，同时准确估计动物姿态和形状对生物研究至关重要。然而，现有方法网络容量有限且多物种数据集稀缺。

Method: AniMer+ 采用高容量的家族感知 Vision Transformer（ViT）结合 Mixture-of-Experts（MoE）设计，并引入扩散模型生成合成数据集 CtrlAni3D 和 CtrlAVES3D。

Result: 在 41.3k 哺乳动物和 12.4k 鸟类图像（含合成数据）上训练后，AniMer+ 在多个基准测试中表现优于现有方法，包括具有挑战性的 Animal Kingdom 数据集。

Conclusion: AniMer+ 的网络架构和合成数据集显著提升了实际应用性能，填补了鸟类 3D 数据的空白。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [92] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种多视角行人视频编辑框架，通过视频修复和运动控制技术增强自动驾驶训练数据集的多样性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统中行人检测模型因训练数据缺乏危险场景而鲁棒性不足的问题。

Method: 整合视频修复与人体运动控制技术，通过多视角行人区域识别、扩展、拼接及掩码编辑实现行人插入、替换和移除。

Result: 实验表明该方法能高质量完成行人编辑，具有视觉真实性、时空连贯性和多视角一致性。

Conclusion: 该方法为多视角行人视频生成提供了稳健且通用的解决方案，适用于数据增强和场景模拟。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [93] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 提出了一种基于事件相机的低光图像增强方法，通过解耦可见性恢复和结构细化两阶段，结合动态对齐和对比损失，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用事件相机和帧相机的模态优势，限制了性能提升。

Method: 分为可见性恢复和结构细化两阶段，分别设计网络和融合策略，并引入对比损失。

Result: 实验表明，该方法优于现有最优模型。

Conclusion: 通过模态分析和两阶段设计，有效提升了低光图像增强的性能。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [94] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula是一个基于通用视觉语言模型的统一框架，用于数学公式OCR，无需专用架构。结合CSFormula数据集，通过监督微调实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 数学公式OCR在科学文献智能分析中至关重要，但现有模型难以处理其结构多样性和复杂性。

Method: 提出DocTron-Formula框架，利用通用视觉语言模型，并引入CSFormula数据集进行监督微调。

Result: 在多种风格、科学领域和复杂布局中实现SOTA性能，超越专用模型。

Conclusion: 该方法为复杂科学文档的自动理解提供了新范式。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [95] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 提出了一种基于生成视频增强的弱监督视频异常检测框架（GV-VAD），通过文本条件视频生成模型生成可控且逼真的合成视频，以低成本扩充训练数据，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 真实世界异常数据的稀缺性、不可预测性和高标注成本限制了视频异常检测（VAD）的性能和泛化能力，需要一种低成本的数据增强方法。

Method: 利用文本条件视频生成模型生成可控且逼真的合成视频，并通过合成样本损失缩放策略控制其对训练的影响。

Result: 在UCF-Crime数据集上，GV-VAD框架的表现优于现有最先进方法。

Conclusion: GV-VAD框架通过生成合成视频有效解决了数据稀缺问题，提升了视频异常检测的性能。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [96] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 提出了一种个性化引导方法，通过未学习的弱模型动态控制微调程度，平衡目标分布对齐与文本编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有采样引导方法（如CFG和AG）无法有效平衡目标分布对齐与原始模型知识保留，需要改进。

Method: 利用未学习的弱模型和空文本提示，动态控制微调程度，通过权重插值实现平衡。

Result: 实验表明，该方法能提升文本对齐和目标分布保真度，且无需额外计算开销。

Conclusion: 提出的个性化引导方法简单有效，能无缝集成多种微调策略，实现更好的平衡。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [97] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 提出了一种使用衍射光栅校准相机光谱灵敏度的实用且准确的方法。


<details>
  <summary>Details</summary>
Motivation: 相机光谱灵敏度的准确校准对计算机视觉任务（如颜色校正、光照估计和材料分析）至关重要。现有方法需要专用窄带滤光片或已知光谱反射率的参考目标，而本方法仅需未校准的衍射光栅片。

Method: 通过捕获直接光照及其通过光栅片的衍射图案图像，以封闭形式估计相机光谱灵敏度和光栅参数。

Result: 在合成和真实数据上的实验表明，该方法优于传统的基于参考目标的方法。

Conclusion: 该方法有效且实用。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [98] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出了一种基于双代理的多图像推理框架，通过语言提示生成和视觉推理实现跨任务泛化，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态跨数据集和任务格式的推理挑战，实现自动化、模块化且无需训练的通用框架。

Method: 采用双代理系统：PromptEngineer生成任务提示，VisionReasoner（大型视觉语言模型）完成推理。

Result: 在18个数据集上评估，Claude 3.7在TQA、DocVQA等任务中表现接近天花板。

Conclusion: 大型视觉语言模型在多图像推理中表现优异，提示设计和模型选择对性能有显著影响。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [99] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 论文提出了一种速度引导的可学习卡尔曼滤波器（SG-LKF），通过动态调整不确定性建模以适应车辆速度，显著提高了动态场景下的多目标跟踪稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统多目标跟踪方法基于静态坐标变换，忽略了车辆速度对观测噪声和参考帧变化的影响，导致高速动态场景下跟踪性能下降。

Method: 提出SG-LKF，结合MotionScaleNet（MSNet）动态预测关键参数，并引入自监督轨迹一致性损失优化帧间关联和轨迹连续性。

Result: SG-LKF在KITTI 2D MOT上以79.59% HOTA排名第一，在KITTI 3D MOT上达到82.03% HOTA，并在nuScenes 3D MOT上优于SimpleTrack 2.2% AMOTA。

Conclusion: SG-LKF通过动态适应车辆速度，显著提升了多目标跟踪在动态场景中的性能，为自动驾驶提供了更可靠的感知支持。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [100] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: 提出了一种统一的时空协作感知方法（CoST），通过同时融合多智能体和多时间观测，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法将多智能体融合和多时间融合分开处理的问题，提升协作感知的性能。

Method: 将多智能体和多时间观测统一融合到时空空间，实现高效特征传输和优越特征融合。

Result: CoST在效率和准确性上均有提升，且兼容多数现有方法。

Conclusion: CoST为协作感知提供了一种高效且通用的解决方案。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [101] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 提出了一种基于机器学习的蜂蜜植物来源自动分类方法，包括数据准备、特征提取和分类三个步骤，使用LDA和SVM/KNN模型，在标准数据集上取得了95.13%和92.80%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 解决蜂蜜植物来源自动分类问题，提高分类准确性和效率。

Method: 采用数据准备（类转换方法）、特征提取（LDA）和分类（SVM/KNN）三步法。

Result: 在标准HSI数据集上，分类准确率分别达到95.13%（图像）和92.80%（实例）。

Conclusion: 该方法在蜂蜜植物来源分类中表现出色，优于现有技术。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [102] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: SparseRecon是一种新的神经隐式重建方法，通过体积渲染特征一致性和不确定性引导的深度约束，解决了稀疏视图重建中的泛化和质量限制问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏视图重建中表现不佳，泛化方法对未见视图效果差，而过拟合方法受限于几何线索不足。

Method: 提出特征一致性损失和不确定性引导的深度约束，以增强重建的完整性和几何细节。

Result: 实验表明，SparseRecon在稀疏视图输入下优于现有方法，特别是在视图重叠较少的情况下。

Conclusion: SparseRecon通过结合特征一致性和深度约束，显著提升了稀疏视图重建的质量。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [103] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出了一种名为Representation Shift的训练无关、模型无关的度量方法，用于测量每个token表示的变化程度，从而在不依赖注意力图或重新训练的情况下实现token压缩，并与FlashAttention兼容。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度的增加，Transformer模型和token数量的增长导致自注意力计算的二次成本增加和GPU内存访问开销。现有token压缩方法依赖注意力图，与FlashAttention不兼容。

Method: 提出Representation Shift度量方法，通过测量token表示的变化程度实现token压缩，无需注意力图或重新训练。

Result: 实验表明，该方法在视频-文本检索和视频问答任务中分别实现了5.5%和4.4%的速度提升。

Conclusion: Representation Shift是一种高效且通用的token压缩方法，适用于多种模型，并与FlashAttention兼容。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [104] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt方法通过结合前向和后向预测提升视频长期动作预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统单向预测方法在捕捉语义子动作上的局限性。

Method: 结合前向和后向预测，利用大语言模型。

Result: 在Ego4D数据集上，BiAnt在编辑距离指标上优于基线方法。

Conclusion: BiAnt通过双向预测显著提升了长期动作预测的准确性。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [105] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 本文提出了一种名为Adapt-WeldNet的自适应框架，用于焊接缺陷检测，结合了预训练架构评估、迁移学习和自适应优化器，并引入了DDIA框架以提高系统透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统无损检测方法难以检测细微或内部缺陷，现有神经网络方法缺乏可解释性，存在安全隐患。

Method: 提出Adapt-WeldNet框架，系统评估预训练架构和优化器；引入DDIA框架，结合XAI技术和专家验证。

Result: 优化了缺陷检测性能，提高了系统透明度和可解释性。

Conclusion: 该工作提升了焊接缺陷检测系统的信任度、安全性和可靠性，适用于海洋和离岸环境。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [106] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 论文提出了一种混合架构$MV_{Hybrid}$，结合状态空间模型（SSMs）和ViT，用于从病理图像预测空间基因表达，性能优于现有ViT模型。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学的高成本和技术复杂性限制了其临床应用，因此需要从常规病理图像预测基因表达的替代方法。

Method: 提出$MV_{Hybrid}$架构，结合SSMs和ViT，并在结直肠癌数据集上预训练，通过DINOv2自监督学习方法评估性能。

Result: 在LOSO评估中，$MV_{Hybrid}$比ViT性能提升57%，且在基因表达预测中性能下降减少43%。

Conclusion: $MV_{Hybrid}$在多个任务中表现优于ViT，有望成为下一代病理视觉基础模型的核心架构。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [107] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: 提出了一种名为Cued-Agent的多智能体系统，用于自动识别Cued Speech（CS）手势和唇部动作，通过多模态融合和语义优化实现高效文本转换。


<details>
  <summary>Details</summary>
Motivation: 传统方法在有限数据下难以有效融合手部和唇部动作的异步性，导致性能不佳。多智能体系统在复杂任务中表现优异，因此被引入以解决这一问题。

Method: Cued-Agent包含四个子智能体：基于多模态大语言模型的手势识别、基于Transformer的唇部识别、动态整合手部提示的推理模块，以及语义优化的音素到单词转换模块。

Result: 实验表明，Cued-Agent在正常和听力受损场景下均优于现有方法。

Conclusion: Cued-Agent通过多智能体协作和语义优化，显著提升了CS识别的性能，为听力障碍者提供了更高效的沟通工具。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [108] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DAPT提出了一种基于解耦-对齐概念的提示调优框架，通过解耦视觉模态为前景和背景表示，并分别对齐文本模态，解决了视觉-文本信息不对称问题。


<details>
  <summary>Details</summary>
Motivation: 解决提示调优中视觉模态与文本模态信息不对称导致的注意力偏差问题。

Method: 提出DAPT框架，包括视觉模态的前景-背景解耦、模态对齐以及视觉拉-推正则化。

Result: 在少样本学习、基础到新类泛化和数据高效学习中表现出优越性能。

Conclusion: DAPT通过对称模态对齐和视觉注意力优化，显著提升了视觉语言模型的性能。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [109] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出了一种基于RGB外观特征和光流残差的双分支检测框架，用于识别AI生成视频中的时空不一致性。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成的视频越来越逼真，传统方法难以捕捉细微的时间不一致性，亟需新的检测方法。

Method: 采用双分支架构，一支分析RGB帧检测外观伪影，另一支处理光流残差揭示运动异常。

Result: 在多种生成模型上的实验表明，该方法具有鲁棒性和强泛化能力。

Conclusion: 通过结合互补特征，该方法能有效检测多种伪造视频。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [110] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench是一个新的视频语言基准测试，用于评估工业环境中视觉语言模型在常规和危险场景下的表现，发现现有模型在危险活动识别和多标签场景中存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在高风险工业领域中的表现，填补现有模型在识别常规操作和安全关键异常方面的研究空白。

Method: 构建iSafetyBench数据集，包含1,100个工业场景视频片段，标注了98种常规和67种危险动作类别，并设计多选问题进行单标签和多标签评估。

Result: 在零样本条件下测试了八种先进视频语言模型，发现它们在危险活动识别和多标签场景中表现不佳。

Conclusion: iSafetyBench揭示了现有模型的性能差距，强调了开发更鲁棒、安全感知的多模态模型的必要性。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [111] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox是一个高保真、逼真的3D零售店模拟环境，用于评估具身代理在购物任务中与人类表现的对比。


<details>
  <summary>Details</summary>
Motivation: 填补零售领域具身代理训练模拟环境的空白，提供更真实的测试平台。

Method: 开发了包含250多种交互式商品的3D零售店模拟环境，支持VR和VLM驱动的具身代理，并提供了SariBench数据集。

Result: 提供了基准测试和性能分析，展示了具身代理在导航、检查和操作商品方面的表现。

Conclusion: Sari Sandbox为具身代理的零售任务训练提供了实用工具，并提出了增强真实性和可扩展性的建议。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [112] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 论文提出了一种动态效率指数（DEI）和多阶段视频恢复框架（PMR），用于解决大气湍流导致的视频质量下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以恢复边缘细节和消除混合失真，尤其是在强湍流和复杂动态条件下。

Method: 提出了DEI量化视频动态强度，并设计了PMR框架，包括去倾斜、运动分割增强和去模糊三个阶段。

Result: 实验表明，该方法能有效抑制运动拖尾伪影，恢复边缘细节，并具有强泛化能力。

Conclusion: 该方法在强湍流和复杂动态场景中表现出色，代码和数据集将公开。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [113] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock是一种无需训练的推理加速框架，通过动态缓存块级特征和选择性跳过冗余计算，显著提升DiTs的推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: DiTs因其顺序去噪过程导致高推理延迟，限制了实时应用。现有加速方法未能充分利用去噪阶段和Transformer块的语义变化。

Method: 提出Sortblock框架，动态缓存相邻时间步的块级特征，通过残差演化排序自适应确定重计算比例，并引入轻量级线性预测机制减少误差。

Result: 实验表明，Sortblock在多种任务和DiT架构上实现超过2倍的推理加速，且输出质量下降极小。

Conclusion: Sortblock为扩散生成模型提供了一种高效且通用的加速解决方案。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [114] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: DC-AE 1.5是一种新型深度压缩自编码器家族，用于高分辨率扩散模型，通过结构化潜在空间和增强扩散训练策略，解决了增加潜在通道数导致的收敛慢问题。


<details>
  <summary>Details</summary>
Motivation: 增加自编码器的潜在通道数可以提高重建质量，但会导致扩散模型收敛慢，影响生成质量。这限制了潜在扩散模型的质量上限，并阻碍了使用更高空间压缩比的自编码器。

Method: 1) 结构化潜在空间：通过训练在潜在空间中施加通道级结构，前部通道捕捉对象结构，后部通道捕捉图像细节；2) 增强扩散训练：在对象潜在通道上增加扩散训练目标以加速收敛。

Result: DC-AE 1.5比DC-AE收敛更快且扩散扩展效果更好。在ImageNet 512x512上，DC-AE-1.5-f64c128的生成质量优于DC-AE-f32c32，且速度快4倍。

Conclusion: DC-AE 1.5通过结构化潜在空间和增强扩散训练策略，显著提升了高分辨率扩散模型的生成质量和收敛速度。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [115] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 论文提出了一种基于视频修复模型的视频外绘方法，通过改进判别器设计和损失函数，显著提升了外绘效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频外绘方法在扩展边界时难以保持内容一致性，且直接应用修复模型效果不佳。

Method: 采用分层判别器设计，区分全局和局部对抗训练目标，并开发了专用外绘损失函数。

Result: 方法在定量和定性上均优于现有技术。

Conclusion: 通过改进判别器和损失函数，实现了更高质量的视频外绘效果。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [116] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种基于Mamba的水下实例分割模型UIS-Mamba，通过动态树扫描（DTS）和隐藏状态弱化（HSW）模块解决水下场景的特殊挑战，实现了高性能和低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 水下实例分割任务面临颜色失真和边界模糊等挑战，现有固定补丁扫描机制难以保持实例连续性，复杂背景也会干扰实例理解。

Method: 设计了DTS模块（动态偏移和缩放补丁）和HSW模块（基于Ncut的隐藏状态弱化），以迁移Mamba模型到水下任务。

Result: 在UIIS和USIS10K数据集上达到最优性能，同时保持低参数量和计算复杂度。

Conclusion: UIS-Mamba通过创新模块有效解决了水下实例分割的挑战，为相关任务提供了高效解决方案。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [117] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出了一种结合物理先验知识和多区域修复技术的新方法，用于动态场景中的人-物交互（HOI）遮挡补全，显著提升了生成结果的准确性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态HOI场景中因理解有限而难以生成合理的遮挡补全，需结合物理约束改进。

Method: 利用人类拓扑和接触信息定义主次区域，采用多区域修复技术和定制去噪策略的扩散模型。

Result: 实验表明，该方法在HOI场景中显著优于现有方法，且无需真实接触标注仍具鲁棒性。

Conclusion: 该方法推动了机器感知向更接近人类理解的动态环境迈进，适用于3D重建和新视角合成等任务。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [118] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 论文提出AerialCSP，一个模拟CSP工厂航拍图像的虚拟数据集，以减少真实数据标注需求，并提升模型在真实场景中的表现。


<details>
  <summary>Details</summary>
Motivation: CSP工厂的航拍图像具有高反射表面和领域特定元素，传统数据集训练的模型难以泛化，而真实数据标注成本高。

Method: 创建AerialCSP虚拟数据集，模拟真实CSP工厂航拍图像，用于模型预训练。

Result: AerialCSP显著提升真实场景中的缺陷检测性能，尤其是对小而罕见的缺陷。

Conclusion: AerialCSP为CSP相关视觉任务提供了高质量合成数据，减少了真实数据标注需求。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [119] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: 提出TopoTTA方法，通过两阶段测试时适应解决TSS中的域偏移问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: TSS对域偏移敏感，拓扑结构变化和局部特征差异会影响分割完整性，需专门方法解决。

Method: TopoTTA分两阶段：1) 使用TopoMDC适应拓扑差异；2) 通过TopoHG生成硬样本并优化预测对齐。

Result: 在四个场景和十个数据集上平均提升31.81%的clDice。

Conclusion: TopoTTA是首个针对TSS的测试时适应框架，有效处理拓扑分布偏移，可作为即插即用解决方案。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [120] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: SDMatte利用扩散模型的强大先验和视觉提示驱动能力，提出了一种新的交互式抠图方法，通过坐标嵌入和掩码自注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有交互式抠图方法在边缘细节提取上表现不足，而扩散模型在复杂数据建模和细节合成上表现优异，因此探索其用于交互式抠图的潜力。

Method: SDMatte将扩散模型的文本驱动能力转化为视觉提示驱动能力，结合坐标嵌入和掩码自注意力机制，优化空间位置和透明度信息的处理。

Result: 在多个数据集上的实验表明，SDMatte在交互式抠图中表现优异，尤其在细节提取方面。

Conclusion: SDMatte通过扩散模型和视觉提示驱动的创新结合，显著提升了交互式抠图的性能，为相关领域提供了新思路。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [121] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias是一个自动识别和减轻文本到图像（T2I）模型中社会偏见的框架，无需预先了解具体偏见类型，有效处理复杂和重叠偏见。


<details>
  <summary>Details</summary>
Motivation: T2I模型常表现出未提及的社会偏见（如性别或种族刻板印象），现有方法难以处理复杂或重叠偏见。

Method: 利用视觉语言模型检测偏见模式，生成包容性替代提示，通过CLIP引导训练减少偏见。

Result: 在25种偏见场景中，AutoDebias检测准确率达91.6%，将偏见输出从90%降至可忽略水平，同时保持图像质量。

Conclusion: AutoDebias能有效处理复杂偏见，提升T2I模型的公平性，且不影响生成图像质量。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [122] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: CLIPTime是一个基于CLIP架构的多模态多任务框架，用于预测真菌生长的发育阶段和时间戳，无需显式时间输入。


<details>
  <summary>Details</summary>
Motivation: 理解生物生长的时间动态对多个领域至关重要，但现有视觉语言模型在捕捉时间进展方面有限。

Method: CLIPTime通过联合视觉-文本嵌入和时间感知推理，预测离散生长阶段和连续时间戳，并引入合成数据集进行训练和评估。

Result: 实验表明，CLIPTime能有效建模生物进展，并生成可解释的时间相关输出。

Conclusion: CLIPTime展示了视觉语言模型在生物监测应用中的潜力。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [123] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: LesiOnTime是一种新的3D分割方法，结合纵向影像和BI-RADS评分，显著提升小病灶分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要针对大病灶，忽略了纵向和临床信息，而早期癌症检测需要这些信息。

Method: 提出Temporal Prior Attention (TPA)块动态整合历史扫描信息，以及BI-RADS一致性正则化(BCR)损失嵌入临床知识。

Result: 在DCE-MRI数据集上，Dice分数比现有方法提升5%，TPA和BCR均贡献性能增益。

Conclusion: 结合时间和临床信息对乳腺癌筛查中的早期病灶分割至关重要。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [124] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: PIF-Net是一个多光谱和高光谱图像融合框架，通过引入病态先验和可逆Mamba架构，解决了数据对齐问题，并在多个基准数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多光谱和高光谱图像融合任务由于光谱与空间信息的固有权衡和数据对齐问题，具有病态性，现有方法未能有效解决。

Method: 提出PIF-Net框架，结合病态先验和可逆Mamba架构，设计Fusion-Aware Low-Rank Adaptation模块动态校准特征。

Result: 在多个基准数据集上，PIF-Net的图像恢复性能显著优于现有方法，同时保持模型高效。

Conclusion: PIF-Net通过创新架构和模块设计，有效解决了多光谱和高光谱图像融合的病态问题，提升了性能。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [125] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: SeTe-VSR是一种新颖的视频超分辨率方法，通过结合语义和时空引导，在细节恢复和时间一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频超分辨率模型在生成过程中难以同时实现高保真对齐和时间一致性。

Method: 提出SeTe-VSR，利用潜在扩散空间中的语义和时空引导，平衡细节恢复和时间一致性。

Result: 实验表明，SeTe-VSR在细节恢复和感知质量上优于现有方法。

Conclusion: SeTe-VSR有效解决了复杂视频超分辨率任务中的挑战。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [126] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出了一种基于双曲时空变换器（HyPCV-Former）的视频异常检测方法，通过双曲空间建模时空特征，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在欧几里得空间中难以捕捉事件的层次结构和时空连续性。

Method: 使用点云提取器提取空间特征，并通过洛伦兹双曲空间嵌入和双曲多头自注意力机制建模时空动态。

Result: 在TIMo和DAD数据集上分别实现了7%和5.6%的性能提升。

Conclusion: HyPCV-Former在双曲空间中直接建模特征，显著优于现有方法。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [127] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: Wukong是一个基于Transformer的NSFW检测框架，利用扩散模型早期去噪步骤的中间输出，实现高效且准确的NSFW内容检测。


<details>
  <summary>Details</summary>
Motivation: 现有外部保护措施（文本过滤器和图像过滤器）存在效率低或易受攻击的问题，需要一种更高效且准确的NSFW检测方法。

Method: Wukong利用扩散模型早期去噪步骤的中间输出和预训练的U-Net交叉注意力参数，在扩散过程中实现早期检测。

Result: Wukong在NSFW检测上显著优于文本过滤器，与图像过滤器精度相当，但效率更高。

Conclusion: Wukong为T2I生成提供了一种高效且准确的NSFW检测解决方案。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [128] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC是一个无需训练的布局感知多图像合成框架，通过两种注意力机制实现了多参考场景下的图像生成，并在多个指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决可控图像合成中多参考图像的空间布局一致性问题。

Method: 基于MMDiT模型，引入Group Isolation Attention (GIA)和Region-Modulated Attention (RMA)两种注意力机制。

Result: LAMIC在ID-S、BG-S、IN-R和AVG等指标上优于现有基线，展示了强大的零样本泛化能力。

Conclusion: LAMIC为可控多图像合成提供了一种无需训练的新范式，并有望随基础模型的进步而扩展。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [129] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA 2.0是一个交互式分割框架，通过引入光谱角度提示，结合空间线索指导Segment Anything Model (SAM)，在医学高光谱成像中实现更准确和鲁棒的分割。


<details>
  <summary>Details</summary>
Motivation: 解决医学高光谱成像中因数据少和噪声多导致的低泛化性能问题。

Method: 采用光谱角度提示，将光谱信息与空间线索早期融合，无需重新训练。

Result: 相比仅RGB模型，Dice分数提升3.8%；相比之前的光谱融合方法，提升3.1%。

Conclusion: SAMSA 2.0在低数据和噪声场景下表现出色，增强了少样本和零样本性能。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [130] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 论文探讨了人脸识别系统在非约束环境下面临的挑战，并提出了一种针对人脸检测的新型攻击方法（Landmark Shift Attack），同时提供了防御措施。


<details>
  <summary>Details</summary>
Motivation: 非约束环境中的人脸识别系统因光照、姿态等问题需要依赖人脸检测模块，但该模块存在安全漏洞，可能被攻击。

Method: 提出了一种名为Landmark Shift Attack的新型攻击方法，通过干扰人脸检测模块的坐标回归任务实现攻击。

Result: 首次展示了Landmark Shift Attack的有效性，证明了人脸检测模块的脆弱性。

Conclusion: 论文揭示了人脸检测模块的安全风险，并提出了相应的防御策略。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [131] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 论文提出了EgoMask，首个用于自我中心视频的像素级时空定位基准，并揭示了自我中心与外部中心视频的关键差异。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频在增强现实和机器人等应用中日益重要，但现有研究多关注外部中心视频，自我中心视频的时空定位问题尚未充分探索。

Method: 通过自动标注管道构建EgoMask基准，并创建大规模训练数据集EgoMask-Train，用于模型开发和评估。

Result: 实验表明，现有最优模型在EgoMask上表现不佳，但通过EgoMask-Train微调后性能显著提升，同时不影响外部中心数据集的表现。

Conclusion: EgoMask为自我中心视频理解提供了关键资源和见解，推动了该领域的发展。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [132] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 提出了一种无监督的遥感影像标注方法，结合卷积和图神经网络，通过分割和特征编码实现更准确的标注。


<details>
  <summary>Details</summary>
Motivation: 遥感影像标注耗时且昂贵，传统方法依赖预标注数据，限制了效率和灵活性。

Method: 使用卷积和图神经网络对影像进行分割和特征编码，结合颜色和空间相似性分组像素，并通过图神经网络聚合周围信息。

Result: 减少了标注中的异常值，支持细粒度标注，并实现了旋转不变的语义关系。

Conclusion: 该方法无需预标注数据，提高了遥感影像标注的效率和准确性。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [133] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出了一种基于上下文感知的运动检索框架，用于自动驾驶系统中罕见人类行为的识别与评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在涉及脆弱道路使用者（VRUs）的复杂行为场景中可靠运行，但大规模数据集中罕见行为的检索具有挑战性。

Method: 结合SMPL运动序列和视频帧，编码到与自然语言对齐的多模态嵌入空间，支持通过文本查询检索人类行为及其上下文。

Result: 在WayMoCo数据集上，方法在运动-上下文检索中的准确率比现有最佳模型高27.5%。

Conclusion: 提出的框架和数据集WayMoCo为自动驾驶系统在多样化人类行为场景中的评估提供了有效支持。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [134] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于二阶动力学分析的训练免费检测方法D3，用于识别AI生成视频中的时间伪影，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对合成视频中时间伪影的探索不足，导致检测效果受限。

Method: 通过牛顿力学下的二阶动力学分析建立理论框架，提出基于二阶中心差分特征的D3方法。

Result: D3在4个开源数据集上表现优异，例如在Gen-Video上比之前最佳方法提升10.39%的平均精度。

Conclusion: D3在计算效率和鲁棒性方面表现突出，为合成视频检测提供了新思路。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [135] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: EPANet是一种高效的水下鱼类检测网络，通过路径聚合和多尺度瓶颈结构提升检测精度和速度。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测因低分辨率、背景干扰和目标相似性而具有挑战性，现有方法常因复杂性和效率不足而受限。

Method: EPANet包含EPA-FPN（长程跳跃连接和多尺度融合）和MS-DDSP瓶颈（细粒度特征分割和多样化卷积）。

Result: 在基准数据集上，EPANet在检测精度和推理速度上优于现有方法，且参数复杂度相当或更低。

Conclusion: EPANet通过高效特征整合和轻量化设计，解决了水下鱼类检测的挑战。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [136] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 提出了一种基于参考的视频色彩分级框架，通过扩散模型生成查找表（LUT）对齐参考场景与输入视频的色彩属性，支持用户通过文本提示调整低层特征。


<details>
  <summary>Details</summary>
Motivation: 视频色彩分级通常需要专业技能，限制了非专业人士的使用。本文旨在简化这一过程，使其更易用。

Method: 使用扩散模型生成LUT，对齐参考场景与输入视频的色彩属性，并通过文本提示调整低层特征。

Result: 实验和用户研究表明，该方法能有效进行视频色彩分级，且不损失结构细节。

Conclusion: 提出的框架为视频色彩分级提供了高效且用户友好的解决方案。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [137] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLMs）在医学图像中定位解剖结构相对位置的能力，发现现有模型表现不佳，并提出视觉提示和基准数据集MIRP以促进研究。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖解剖结构的相对位置信息，但VLMs在此任务上的能力尚未充分研究，亟需评估和改进。

Method: 评估了GPT-4o、Llama3.2等先进VLMs的表现，并测试了视觉提示（如标记）的效果，同时提出MIRP数据集。

Result: 所有模型均表现不佳，视觉提示仅带来有限改进，且VLMs更依赖先验知识而非图像内容。

Conclusion: 医学图像中VLMs的定位能力不足，需进一步研究，MIRP数据集为此提供了工具。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [138] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: 提出了一种名为DBLP的高效扩散对抗净化框架，通过噪声桥蒸馏和自适应语义增强，实现了实时对抗净化。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络易受对抗扰动影响，现有扩散净化方法效率低，限制了实际应用。

Method: 采用噪声桥蒸馏目标，构建对抗噪声与干净数据的分布对齐，并结合多尺度金字塔边缘图进行语义增强。

Result: 在多个数据集上达到SOTA鲁棒精度和图像质量，推理时间约0.2秒。

Conclusion: DBLP为实时对抗净化提供了有效解决方案。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [139] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune是一种无需训练、模型无关的视觉令牌剪枝框架，通过利用视觉编码器中的分层注意力结构，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型（VLMs）因编码图像为长序列视觉令牌导致的计算开销大和推理效率低的问题。

Method: 基于分层注意力结构，选择三类信息丰富的令牌：锚定令牌（高注意力）、缓冲令牌（空间连续性）和注册令牌（全局总结）。

Result: 在多个模型中，HiPrune仅用33.3%的令牌即可保持99.3%的任务准确率，并减少9倍的推理计算开销。

Conclusion: HiPrune是一种高效、通用的令牌剪枝方法，适用于多种ViT-based VLM，显著提升推理效率。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [140] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 论文探讨了在逼真虚拟头像中利用面部运动模式作为行为生物特征进行身份验证的可行性，并提出了一种轻量级的时空图卷积网络架构。


<details>
  <summary>Details</summary>
Motivation: 随着虚拟头像在虚拟会议、游戏和社交平台中的普及，其带来的安全风险（如冒充攻击）日益严重，需要新的生物特征验证方法。

Method: 使用GAGAvatar生成真实和冒充头像视频数据集，并提出基于面部关键点的轻量级时空图卷积网络架构。

Result: 实验表明，面部运动特征可实现有效的身份验证，AUC值接近80%。

Conclusion: 面部运动模式可作为可靠的行为生物特征，研究呼吁在虚拟头像通信系统中加强行为生物特征防御。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [141] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: FreeCP是一种无需训练的类别净化框架，旨在解决开放词汇语义分割中的类别冗余和视觉语言模糊性问题，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视类别冗余和视觉语言模糊性，导致次优的类别激活图。FreeCP旨在解决这些问题。

Method: 提出FreeCP框架，通过净化语义类别并纠正冗余和模糊性引起的错误，生成最终分割预测。

Result: 在八个基准测试中验证，FreeCP作为即插即用模块，显著提升分割性能。

Conclusion: FreeCP有效解决了开放词汇语义分割中的关键问题，提升了性能。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [142] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: PhysNAP是一种基于扩散模型的方法，用于生成与部分点云对齐且物理合理的关节物体。


<details>
  <summary>Details</summary>
Motivation: 关节物体在日常环境中是重要的交互对象，现有方法在物理合理性和点云对齐方面存在不足。

Method: 使用SDF表示部分形状，通过点云对齐损失和非穿透性、移动性约束引导反向扩散过程，并引入类别信息优化对齐。

Result: 在PartNet-Mobility数据集上验证，PhysNAP在约束一致性和生成能力之间取得了平衡，优于无引导的基线模型。

Conclusion: PhysNAP通过物理约束和类别信息显著提升了关节物体的生成质量和物理合理性。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [143] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种新的测试时间适应（TTA）框架，用于动态调整医学图像翻译过程，以处理分布外样本，同时保持分布内样本的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像翻译中分布外样本导致的性能下降问题。

Method: 引入重建模块量化域偏移，并通过动态适应块选择性修改预训练模型的内部特征。

Result: 在低剂量CT去噪和T1到T2 MRI翻译任务中表现优于基线模型和现有TTA方法。

Conclusion: 动态样本特定调整是提高模型在真实场景中鲁棒性的有效途径。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [144] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 提出一种基于图像级标注的弱监督目标检测方法，通过预训练模型生成伪标签，优化检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测方法依赖大量标注边界框，成本高且需专家知识，提出更易获取的图像级标注解决方案。

Method: 利用预训练模型预测病毒存在与否，生成伪标签，结合优化方法和缩小感受野直接提取病毒颗粒。

Result: 伪标签方法优于现有弱标注方法，甚至在标注时间有限时优于真实标注。

Conclusion: 该方法显著降低标注成本，提升检测性能，适用于标注资源有限场景。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [145] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: 提出了一种名为CoProU-VO的新方法，通过跨帧不确定性传播改进视觉里程计（VO）在动态场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 动态物体和遮挡会导致传统无监督VO方法在静态场景假设下失效，而单帧不确定性建模无法解决跨帧的不确定性。

Method: 结合目标帧和参考帧的不确定性，采用概率公式和视觉Transformer架构，同时学习深度、不确定性估计和相机位姿。

Result: 在KITTI和nuScenes数据集上表现优于现有无监督单目方法，尤其在高速公路场景中效果显著。

Conclusion: 跨帧不确定性传播是提升动态场景下VO性能的有效方法。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [146] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种基于不确定性感知的似然比估计方法，用于区分已知和未知像素特征，显著降低了误报率。


<details>
  <summary>Details</summary>
Motivation: 解决语义分割模型在真实自动驾驶场景中因未知物体误分类的问题。

Method: 使用证据分类器结合似然比测试，明确考虑不确定性，输出概率分布而非点估计。

Result: 在五个标准基准数据集上，平均误报率最低（2.5%），平均精度高达90.91%，计算开销可忽略。

Conclusion: 通过引入不确定性，有效提升了异常检测性能，适用于复杂场景。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [147] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 提出了一种新的重建框架EVAL，用于扩展VIIRS夜间灯光数据的时间序列，解决了现有方法低估光强度和结构缺失的问题，显著提升了数据质量。


<details>
  <summary>Details</summary>
Motivation: 现有VIIRS夜间灯光数据始于2012年，限制了长期时间序列研究，且当前扩展方法存在光强度低估和结构缺失的不足。

Method: 采用两阶段重建框架：构建阶段使用分层融合解码器（HFD）提升初始重建保真度；细化阶段利用双特征优化器（DFR）结合高分辨率不透水面掩膜增强结构细节。

Result: 开发的EVAL产品将中国夜间灯光数据扩展至1986年，R²从0.68提升至0.80，RMSE从1.27降至0.99，具有优异的时间一致性和社会经济参数相关性。

Conclusion: EVAL为研究社区提供了高质量的长期夜间灯光数据资源，解决了现有方法的局限性。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [148] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: GeoMoE提出了一种基于Mixture-of-Experts的框架，用于处理两视图几何中的异质运动模式，通过分解和针对性建模提升运动场估计的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景中难以处理异质运动模式，导致运动场估计偏离真实结构。

Method: 采用Probabilistic Prior-Guided Decomposition分解运动场，结合MoE-Enhanced Bi-Path Rectifier进行针对性建模。

Result: 在相对位姿和单应性估计任务中优于现有方法，并表现出强泛化能力。

Conclusion: GeoMoE通过简洁设计有效解决了异质运动模式的建模问题，提升了运动场估计的准确性。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [149] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X是一种基于扩散的3D全身人体姿态先验模型，通过扩散模型和变分扩散采样解决姿态任务，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 构建一个通用且鲁棒的全身人体姿态先验模型面临挑战，主要由于姿态复杂性和高质量数据稀缺。

Method: 采用扩散模型作为姿态先验（DPoser），扩展为DPoser-X，结合截断时间步调度和掩码训练机制。

Result: 在多个基准测试中表现优异，优于现有方法。

Conclusion: DPoser-X为全身人体姿态先验建模设立了新标杆。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [150] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 论文提出了一种通过生成模型合成带有病理视觉属性标注的数据的方法，以解决医学图像数据集中属性标注稀缺的问题，从而提升可解释模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像数据集中属性标注稀缺的问题，以增强可解释模型在医学图像诊断中的透明性和实用性。

Method: 使用增强的Diffusion Model生成带有属性标注的合成数据，并利用少量真实标注样本（20个）进行训练。

Result: 合成数据显著提升了模型的性能，属性预测准确率提高了13.4%，目标预测准确率提高了1.8%。

Conclusion: 合成数据能够有效克服数据集限制，增强可解释模型在医学图像分析中的应用潜力。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [151] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 论文提出了首个针对目标检测器补丁攻击的防御基准，通过大规模数据集和全面分析揭示了防御性能的关键因素，并提供了改进现有防御方法的建议。


<details>
  <summary>Details</summary>
Motivation: 现有防御评估缺乏统一和全面的框架，导致对当前方法的评估不一致和不完整。

Method: 重新评估了11种代表性防御方法，构建了包含2种攻击目标、13种补丁攻击、11种目标检测器和4种多样指标的基准，并创建了大规模对抗补丁数据集。

Result: 分析揭示了防御自然补丁的难点在于数据分布而非高频特征，新数据集可将现有防御性能提升15.09% AP@0.5；自适应攻击能显著绕过现有防御，复杂/随机模型或通用补丁属性的防御更稳健。

Conclusion: 研究为补丁攻击/防御的评估和设计提供了指导，并开源了代码和数据集以持续集成新攻击/防御方法。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [152] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 该论文研究了预训练深度表示在图像去雾中的泛化能力，并提出了一种即插即用的RGB-D融合模块。


<details>
  <summary>Details</summary>
Motivation: 解决现有去雾方法因架构特定设计而难以适应多样化场景的问题。

Method: 利用预训练的深度特征，设计了一个可适配多种去雾架构的RGB-D融合模块。

Result: 实验表明，该方法在多个基准测试中表现出色，具有广泛的适用性。

Conclusion: 预训练的深度特征在去雾任务中具有一致性，提出的模块能有效提升去雾性能。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [153] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 该论文首次系统研究了多图像多模态大语言模型（MLLMs）中的幻觉问题，并提出了专门用于评估多图像场景中对象相关幻觉的基准MIHBench。通过实验，作者发现多图像幻觉的关键因素，并提出动态注意力平衡机制以有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单图像场景中的幻觉问题，而多图像场景中的幻觉尚未被充分探索。为了填补这一空白，作者首次系统研究了多图像MLLMs中的幻觉问题。

Method: 作者提出了MIHBench基准，包含三个核心任务：多图像对象存在幻觉、多图像对象计数幻觉和对象身份一致性幻觉。此外，提出动态注意力平衡机制来调整图像间的注意力分布。

Result: 实验表明，动态注意力平衡机制能有效减少多图像场景中的幻觉，并提升语义整合和推理稳定性。

Conclusion: 该研究填补了多图像MLLMs中幻觉问题的研究空白，提出的方法在多图像场景中表现出色。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [154] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count是一个可微分的开放词汇对象计数模型，用于解决通用计数问题并为文本到图像生成提供精确数量控制。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇计数与文本到图像生成控制之间的差距，提升对象计数的准确性和生成模型的精细指导。

Method: 提出'基数'图作为回归目标，结合表示对齐和强弱监督混合方案，采用全微分架构实现梯度优化。

Result: 在实验中表现出最先进的计数准确性，并为文本到图像系统提供鲁棒的数量控制。

Conclusion: YOLO-Count在对象计数和生成模型控制方面具有显著优势，为相关领域提供了有效解决方案。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [155] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 论文提出了一种名为Dense Backbone的轻量级骨干网络，用于LiDAR点云数据的3D目标检测，显著降低了计算成本，同时保持了较高的检测精度。


<details>
  <summary>Details</summary>
Motivation: 当前3D目标检测方法多依赖复杂骨干网络（如VGG或ResNet），增加了模型复杂度。轻量级骨干网络在2D检测中已有研究，但在3D检测中仍有限。

Method: 提出Dense Backbone，结合高速处理、轻量架构和鲁棒检测精度。适配了PillarNet等SoTA检测器，形成DensePillarNet。

Result: DensePillarNet在nuScenes测试集上减少了29%参数和28%延迟，仅损失2%检测精度。

Conclusion: Dense Backbone为3D目标检测提供了高效轻量的解决方案，且易于集成到现有架构中。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [156] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO提出了一种基于最优传输的训练框架，生成几何一致的特征，显著提升了语义对应任务的性能，同时运行速度快于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自监督视觉基础模型在语义对应任务中缺乏对3D几何的感知，GECO旨在填补这一空白。

Method: 采用最优传输框架进行训练，支持对遮挡和去遮挡情况下的监督，并使用轻量级架构实现高效运行。

Result: 在PFPascal、APK和CUB数据集上分别提升PCK指标6.0%、6.2%和4.1%，运行速度达30 fps，比现有方法快98.2%。

Conclusion: PCK指标不足以全面评估几何质量，GECO提出了新指标和见解，推动更几何感知的特征学习。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [157] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是一种针对卫星图像的SR框架，结合了ESRGAN、DeepLabv3分割损失和蒙特卡洛dropout，提供语义一致性和像素级不确定性，适用于无人机和卫星系统。


<details>
  <summary>Details</summary>
Motivation: GANs在超分辨率图像生成中缺乏语义一致性和像素级置信度，限制了其在遥感关键应用中的可信度。

Method: 提出SU-ESRGAN，整合ESRGAN、DeepLabv3分割损失和蒙特卡洛dropout，生成像素级不确定性图。

Result: 在PSNR、SSIM和LPIPS指标上与基线ESRGAN相当，适用于无人机和卫星系统。

Conclusion: SU-ESRGAN在卫星和无人机应用中表现出色，强调了领域感知训练的重要性。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [158] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: PILOT框架通过双分支提示学习和无标签测试时适应策略，提升了零样本异常检测在域偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法在域偏移下表现不佳，因其训练数据有限且难以泛化到新分布。

Method: PILOT采用双分支提示学习机制动态整合可学习提示与语义属性，并结合无标签测试时适应策略更新提示参数。

Result: 在13个工业和医学基准测试中，PILOT在异常检测和定位方面达到最先进性能。

Conclusion: PILOT通过创新设计有效解决了零样本异常检测在域偏移下的挑战。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [159] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 研究分析了异构标注点云数据集在公共安全应用中的语义分割性能，发现几何大对象分割效果较好，而小安全关键特征识别率低。


<details>
  <summary>Details</summary>
Motivation: 探讨如何统一不同标注的3D数据，以提升公共安全应用中点云语义分割的可靠性。

Method: 采用KPConv架构和分级标注方案，通过IoU指标评估性能。

Result: 几何大对象（如楼梯、窗户）分割效果较好，小安全关键特征识别率低，受类别不平衡和几何限制影响。

Conclusion: 需标准化标注协议和改进标注技术，以解决数据异构性和小安全关键特征的检测问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


### [160] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: IGL-Nav提出了一种基于3D高斯表示的增量式图像目标导航框架，通过粗到精的定位策略，显著提升了导航效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以建模3D环境与目标图像之间的几何关系，且计算效率低。

Method: 采用增量式3D高斯表示，结合粗定位（离散空间匹配）和精定位（可微分渲染优化）。

Result: IGL-Nav在多种实验配置下显著优于现有方法，并能处理自由视角图像目标导航。

Conclusion: IGL-Nav为高效、3D感知的图像目标导航提供了新思路，适用于实际机器人平台。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [161] [Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT](https://arxiv.org/abs/2508.00341)
*Shengheng Liu,Ningning Fu,Zhonghao Zhang,Yongming Huang,Tony Q. S. Quek*

Main category: cs.DC

TL;DR: 论文提出了一种结合空中计算的联邦学习框架，通过用户调度和接收波束成形优化通信效率和推理准确性，并提出了低复杂度的用户调度策略。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）的普及带来了隐私问题，联邦学习（FL）作为一种去中心化训练方法被提出。然而，大规模网络中无线资源稀缺，需要高效的调度和传输策略。

Method: 引入空中计算到FL框架，提出用户调度和接收波束成形的集成方法，并基于无线信道特性提出低复杂度调度策略。

Result: 实验验证了所提方法在聚合误差和学习性能上优于现有方法。

Conclusion: 该方法有效提升了FL的通信效率和准确性，低复杂度策略更具实用性。

Abstract: The rising popularity of Internet of things (IoT) has spurred technological
advancements in mobile internet and interconnected systems. While offering
flexible connectivity and intelligent applications across various domains, IoT
service providers must gather vast amounts of sensitive data from users, which
nonetheless concomitantly raises concerns about privacy breaches. Federated
learning (FL) has emerged as a promising decentralized training paradigm to
tackle this challenge. This work focuses on enhancing the aggregation
efficiency of distributed local models by introducing over-the-air computation
into the FL framework. Due to radio resource scarcity in large-scale networks,
only a subset of users can participate in each training round. This highlights
the need for effective user scheduling and model transmission strategies to
optimize communication efficiency and inference accuracy. To address this, we
propose an integrated approach to user scheduling and receive beam steering,
subject to constraints on the number of selected users and transmit power.
Leveraging the difference-of-convex technique, we decompose the primal
non-convex optimization problem into two sub-problems, yielding an iterative
solution. While effective, the computational load of the iterative method
hampers its practical implementation. To overcome this, we further propose a
low-complexity user scheduling policy based on characteristic analysis of the
wireless channel to directly determine the user subset without iteration.
Extensive experiments validate the superiority of the proposed method in terms
of aggregation error and learning performance over existing approaches.

</details>


### [162] [Tetris: Efficient Intra-Datacenter Calls Packing for Large Conferencing Services](https://arxiv.org/abs/2508.00426)
*Rohan Gandhi,Ankur Mallick,Ken Sueda,Rui Liang*

Main category: cs.DC

TL;DR: Tetris框架通过优化初始呼叫分配和定期迁移热MP上的呼叫，显著减少了热MP的使用，提升了会议服务的性能并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有算法在处理大规模会议服务时，容易导致部分MP服务器过热，影响性能并增加成本。

Method: 提出Tetris框架，结合历史数据优化初始呼叫分配，并利用线性优化定期迁移热MP上的呼叫。

Result: 在24小时内处理超过1000万次呼叫的测试中，Tetris将热MP上的参与者数量减少了至少2.5倍。

Conclusion: Tetris有效解决了MP服务器过热问题，提升了会议服务的性能和成本效益。

Abstract: Conference services like Zoom, Microsoft Teams, and Google Meet facilitate
millions of daily calls, yet ensuring high performance at low costs remains a
significant challenge. This paper revisits the problem of packing calls across
Media Processor (MP) servers that host the calls within individual datacenters
(DCs). We show that the algorithm used in Teams -- a large scale conferencing
service as well as other state-of-art algorithms are prone to placing calls
resulting in some of the MPs becoming hot (high CPU utilization) that leads to
degraded performance and/or elevated hosting costs. The problem arises from
disregarding the variability in CPU usage among calls, influenced by
differences in participant numbers and media types (audio/video), compounded by
bursty call arrivals. To tackle this, we propose Tetris, a multi-step framework
which (a) optimizes initial call assignments by leveraging historical data and
(b) periodically migrates calls from hot MPs using linear optimization, aiming
to minimize hot MP usage. Evaluation based on a 24-hour trace of over 10
million calls in one DC shows that Tetris reduces participant numbers on hot
MPs by at least 2.5X.

</details>


### [163] [SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments](https://arxiv.org/abs/2508.00622)
*Kapel Dev,Yash Madhwal,Sofia Shevelo,Pavel Osinenko,Yury Yanovich*

Main category: cs.DC

TL;DR: SwarnRaft是一个基于区块链的定位和共识框架，用于在GNSS信号缺失时维持无人机群的协调和数据完整性。


<details>
  <summary>Details</summary>
Motivation: 无人机群在关键应用中依赖GNSS信号，但信号可能因干扰或攻击中断，导致任务失败。

Method: 利用Raft共识算法，使无人机在GNSS信号缺失时仍能达成状态更新共识，并通过WiFi通信模拟群行为。

Result: 原型系统展示了在信号丢失时通过共识重建或验证节点位置的鲁棒性和容错能力。

Conclusion: SwarnRaft为无人机群在不可预测环境中提供了一种轻量级、可扩展的解决方案。

Abstract: Unmanned aerial vehicle (UAV) swarms are increasingly used in critical
applications such as aerial mapping, environmental monitoring, and autonomous
delivery. However, the reliability of these systems is highly dependent on
uninterrupted access to the Global Navigation Satellite Systems (GNSS) signals,
which can be disrupted in real-world scenarios due to interference,
environmental conditions, or adversarial attacks, causing disorientation,
collision risks, and mission failure. This paper proposes SwarnRaft, a
blockchain-inspired positioning and consensus framework for maintaining
coordination and data integrity in UAV swarms operating under GNSS-denied
conditions. SwarnRaft leverages the Raft consensus algorithm to enable
distributed drones (nodes) to agree on state updates such as location and
heading, even in the absence of GNSS signals for one or more nodes. In our
prototype, each node uses GNSS and local sensing, and communicates over WiFi in
a simulated swarm. Upon signal loss, consensus is used to reconstruct or verify
the position of the failed node based on its last known state and trajectory.
Our system demonstrates robustness in maintaining swarm coherence and fault
tolerance through a lightweight, scalable communication model. This work offers
a practical and secure foundation for decentralized drone operation in
unpredictable environments.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [164] [Agent Network Protocol Technical White Paper](https://arxiv.org/abs/2508.00007)
*Gaowei Chang,Eidan Lin,Chengxuan Yuan,Rizhao Cai,Binbin Chen,Xuan Xie,Yin Zhang*

Main category: cs.NI

TL;DR: ANP提出了一种面向Agentic Web的新一代通信协议，解决现有互联网基础设施对大规模Agent互联与协作的不足。


<details>
  <summary>Details</summary>
Motivation: 现有互联网基础设施主要为人类交互设计，导致Agent间数据孤岛、接口不友好和高协作成本，无法满足大规模Agent互联需求。

Method: ANP采用AI原生设计，兼容现有协议，模块化架构，三层协议系统解决身份认证、动态协商和能力发现互操作性。

Result: ANP系统性地解决了Agent身份认证、动态协商和能力发现互操作性问题。

Conclusion: ANP顺应互联网核心趋势，为Agentic Web提供了高效、兼容且可扩展的通信协议。

Abstract: With the development of large models and autonomous decision-making AI,
agents are rapidly becoming the new entities of the internet, following mobile
apps. However, existing internet infrastructure is primarily designed for human
interaction, creating data silos, unfriendly interfaces, and high collaboration
costs among agents, making it difficult to support the needs for large-scale
agent interconnection and collaboration. The internet is undergoing a profound
transformation, showing four core trends: agents replacing traditional
software, universal agent interconnection, native protocol-based connections,
and autonomous agent organization and collaboration. To align with these
trends, Agent Network Protocol (ANP) proposes a new generation of communication
protocols for the Agentic Web. ANP adheres to AI-native design, maintains
compatibility with existing internet protocols, adopts a modular composable
architecture, follows minimalist yet extensible principles, and enables rapid
deployment based on existing infrastructure. Through a three-layer protocol
system--identity and encrypted communication layer, meta-protocol negotiation
layer, and application protocol layer--ANP. systematically solves the problems
of agent identity authentication, dynamic negotiation, and capability discovery
interoperability.

</details>


### [165] [Enabling Immersive XR Collaborations over FTTR Networks (Invited)](https://arxiv.org/abs/2508.00009)
*Sourav Mondal,Elaine Wong*

Main category: cs.NI

TL;DR: 本文探讨了FTTR（光纤到房间）在实现室内扩展现实协作中的潜力，提出了预测带宽分配和无缝切换方案，以实现高质量的沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 研究FTTR作为实现高质量室内扩展现实协作的潜在解决方案。

Method: 提出预测带宽分配和无缝切换方案。

Result: 展示了通过FTTR可以实现高质量的沉浸式协作体验。

Conclusion: FTTR结合预测带宽分配和无缝切换方案，能够有效支持室内扩展现实协作。

Abstract: Fiber-To-The-Room is a potential solution to achieve in-premise extended
reality collaborations. This paper explores predictive bandwidth allocation and
seamless handover schemes over FTTR, showing high-quality immersive experience
for in-premise collaborations can be achieved. \c{opyright} 2025 The Author(s).

</details>


### [166] [Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?](https://arxiv.org/abs/2508.00010)
*Ruibo Wang,Baha Eddine Youcef Belmekki,Howard H. Yang,Mohamed Slim Alouini*

Main category: cs.NI

TL;DR: 本文通过引入相对误差量化平面与球面模型的差异，提出了一种点过程生成算法和相对误差估计算法，并推导了最优平面高度的解析表达式，为NTN建模提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 随着非地面网络(NTNs)的快速发展，网络性能分析的计算复杂度急剧上升。平面模型因忽略地球曲率在高空NTN分析中产生偏差，但仍因其简单性被广泛使用。

Method: 提出一种点过程生成算法，同时生成平面和球面点过程；引入多种相似性度量，并开发基于这些度量的相对误差估计算法；推导最优平面高度的解析表达式。

Result: 数值结果研究了部署高度和区域对NTN建模的影响，并以HAP和LEO卫星星座为例进行了案例分析。

Conclusion: 本文为平面模型的适用性提供了量化标准，并降低了计算复杂度，为NTN性能分析提供了高效解决方案。

Abstract: With the explosive deployment of non-terrestrial networks (NTNs), the
computational complexity of network performance analysis is rapidly escalating.
As one of the most suitable mathematical tools for analyzing large-scale
network topologies, stochastic geometry (SG) enables the representation of
network performance metrics as functions of network parameters, thus offering
low-complexity performance analysis solutions. However, choosing between planar
and spherical models remains challenging. Planar models neglect Earth's
curvature, causing deviations in high-altitude NTN analysis, yet are still
often used for simplicity. This paper introduces relative error to quantify the
gap between planar and spherical models, helping determine when planar modeling
is sufficient. To calculate the relative error, we first propose a point
process (PP) generation algorithm that simultaneously generates a pair of
homogeneous and asymptotically similar planar and spherical PPs. We then
introduce several typical similarity metrics, including topology-related and
network-level metrics, and further develop a relative error estimation
algorithm based on these metrics. In addition, we derive an analytical
expression for the optimal planar altitude, which reduces computational
complexity and provides theoretical support for planar approximation. Finally,
numerical results investigate how deployment altitude and region affect NTN
modeling, with case studies on HAP and LEO satellite constellations.

</details>


### [167] [Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](https://arxiv.org/abs/2508.00234)
*Jin Yang,Qiong Wu,Zhiying Feng,Zhi Zhou,Deke Guo,Xu Chen*

Main category: cs.NI

TL;DR: 提出了一种基于深度强化学习（DRL）的QoS感知LLM路由框架，以解决边缘LLM服务中的动态负载和异构性问题。


<details>
  <summary>Details</summary>
Motivation: 云LLM服务存在高延迟、响应不稳定和隐私问题，边缘部署LLM可提升实时性和隐私保护，但需解决路由问题。

Method: 采用动态状态抽象技术和异构图注意力网络（HAN）表示全局状态，结合动作影响估计器和定制奖励函数优化路由。

Result: 实验表明，该算法显著提升了平均QoS和计算资源效率。

Conclusion: 该框架能有效维持长期稳定的QoS，适用于动态负载场景。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
leading to a significant increase in user demand for LLM services. However,
cloud-based LLM services often suffer from high latency, unstable
responsiveness, and privacy concerns. Therefore, multiple LLMs are usually
deployed at the network edge to boost real-time responsiveness and protect data
privacy, particularly for many emerging smart mobile and IoT applications.
Given the varying response quality and latency of LLM services, a critical
issue is how to route user requests from mobile and IoT devices to an
appropriate LLM service (i.e., edge LLM expert) to ensure acceptable
quality-of-service (QoS). Existing routing algorithms fail to simultaneously
address the heterogeneity of LLM services, the interference among requests, and
the dynamic workloads necessary for maintaining long-term stable QoS. To meet
these challenges, in this paper we propose a novel deep reinforcement learning
(DRL)-based QoS-aware LLM routing framework for sustained high-quality LLM
services. Due to the dynamic nature of the global state, we propose a dynamic
state abstraction technique to compactly represent global state features with a
heterogeneous graph attention network (HAN). Additionally, we introduce an
action impact estimator and a tailored reward function to guide the DRL agent
in maximizing QoS and preventing latency violations. Extensive experiments on
both Poisson and real-world workloads demonstrate that our proposed algorithm
significantly improves average QoS and computing resource efficiency compared
to existing baselines.

</details>


### [168] [AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks](https://arxiv.org/abs/2508.00011)
*Ahmet Melih Ince,Ayse Elif Canbilen,Halim Yanikomeroglu*

Main category: cs.NI

TL;DR: 论文提出了一种基于深度确定性策略梯度（DDPG）的强化学习方法，用于优化HAPS支持的V2X网络中的信息新鲜度（AoI），提高网络可靠性。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要满足高可靠低延迟通信（HRLLC）需求，特别是在自动驾驶等安全关键应用中。非地面网络（NTN）和高空平台站（HAPS）的引入为网络提供了冗余和覆盖优势。

Method: 采用深度确定性策略梯度（DDPG）的强化学习方法，动态优化HAPS支持的V2X网络中的信息新鲜度（AoI），无需集中协调。

Result: 该方法显著提高了信息新鲜度和网络可靠性，适用于基于车队的自动驾驶系统。

Conclusion: HAPS与DDPG结合的方法在AoI感知资源分配中具有潜力，特别适用于基础设施受限的区域。

Abstract: Sixth-generation (6G) networks are designed to meet the hyper-reliable and
low-latency communication (HRLLC) requirements of safety-critical applications
such as autonomous driving. Integrating non-terrestrial networks (NTN) into the
6G infrastructure brings redundancy to the network, ensuring continuity of
communications even under extreme conditions. In particular, high-altitude
platform stations (HAPS) stand out for their wide coverage and low latency
advantages, supporting communication reliability and enhancing information
freshness, especially in rural areas and regions with infrastructure
constraints. In this paper, we present reinforcement learning-based approaches
using deep deterministic policy gradient (DDPG) to dynamically optimize the
age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks.
The proposed method improves information freshness and overall network
reliability by enabling independent learning without centralized coordination.
The findings reveal the potential of HAPS-supported solutions, combined with
DDPG-based learning, for efficient AoI-aware resource allocation in
platoon-based autonomous vehicle systems.

</details>


### [169] [Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach](https://arxiv.org/abs/2508.00020)
*Ferdaous Tarhouni,Ruibo Wang,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文评估了高空平台（HAPs）在卫星-空中-地面综合网络（SAGIN）中作为中继的性能，提出了三种性能指标，并利用球形随机几何（SSG）进行低复杂度分析。


<details>
  <summary>Details</summary>
Motivation: 满足全球无线通信需求，研究HAPs在SAGIN中的中继作用。

Method: 采用球形随机几何（SSG）工具，提出三种性能指标（平均接入数据率、平均回程数据率、回程率超越概率BREP），并推导其解析表达式。

Result: 提供了BREP的闭式表达式，分析了卫星网络拓扑对性能的影响，并确定了HAPs的最小传输功率需求。

Conclusion: SSG框架在SAGIN中具有优势，HAPs的中继作用显著提升通信性能。

Abstract: In recent years, the satellite-aerial-ground integrated network (SAGIN) has
become essential in meeting the increasing demands for global wireless
communications. In SAGIN, high-altitude platforms (HAPs) can serve as
communication hubs and act as relays to enhance communication performance. In
this paper, we evaluate network performance and analyze the role of HAPs in
SAGIN from the relay perspective. Based on this unique perspective, we
introduce three metrics to evaluate the performance, named the average access
data rate, the average backhaul data rate, and the backhaul rate exceedance
probability (BREP). Considering the need for dynamic topology and interference
analysis, we choose spherical stochastic geometry (SSG) as a tool and derive
analytical expressions for the above metrics to achieve low-complexity
performance evaluation. Specifically, we provide a closed-form expression for
the end-to-end performance metric BREP. Given that there is no existing
literature in the SSG field studying networks from a relay perspective, we
specifically investigate the impact of satellite network topology on
performance in our numerical results to further highlight the advantages of the
SSG framework. Additionally, we analyze the minimum HAP transmission power
required to maintain both short-term and long-term data rate demands.

</details>


### [170] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
*Abir Ray*

Main category: cs.NI

TL;DR: 提出了一种结合马尔可夫链和ITU-R传播模型的可扩展频谱预测框架，用于动态频谱接入。


<details>
  <summary>Details</summary>
Motivation: 频谱资源在时空上常未被充分利用，需动态频谱接入策略以允许次级用户利用空闲频率。

Method: 结合两状态马尔可夫链模型（捕捉时间占用模式）和ITU-R传播模型（考虑路径损耗和杂波效应），预测频谱可用性。

Result: 该方法能高效预测时空频谱机会，计算成本低，适用于实时频谱管理。

Conclusion: 框架灵活，可适应不同频段和场景，为认知无线电网络提供有效解决方案。

Abstract: Spectrum resources are often underutilized across time and space, motivating
dynamic spectrum access strategies that allow secondary users to exploit unused
frequencies. A key challenge is predicting when and where spectrum will be
available (i.e., unused by primary licensed users) in order to enable proactive
and interference-free access. This paper proposes a scalable framework for
spectrum availability prediction that combines a two-state Markov chain model
of primary user activity with high-fidelity propagation models from the ITU-R
(specifically Recommendations P.528 and P.2108). The Markov chain captures
temporal occupancy patterns, while the propagation models incorporate path loss
and clutter effects to determine if primary signals exceed interference
thresholds at secondary user locations. By integrating these components, the
proposed method can predict spectrum opportunities both in time and space with
improved accuracy. We develop the system model and algorithm for the approach,
analyze its scalability and computational efficiency, and discuss assumptions,
limitations, and potential applications. The framework is flexible and can be
adapted to various frequency bands and scenarios. The results and analysis show
that the proposed approach can effectively identify available spectrum with low
computational cost, making it suitable for real-time spectrum management in
cognitive radio networks and other dynamic spectrum sharing systems.

</details>


### [171] [Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network](https://arxiv.org/abs/2508.00042)
*Athanasios Tziouvaras,Carolina Fortuna,George Floros,Kostas Kolomvatsos,Panagiotis Sarigiannidis,Marko Grobelnik,Blaž Bertalanič*

Main category: cs.NI

TL;DR: 论文提出了两种无监督、模型无关的批量概念漂移检测方法，用于AI原生6G网络中模型性能的维护，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 无线环境的非静态性（如基础设施变化、用户移动性等）会导致概念漂移，降低模型准确性，现有方法多为领域特定或对某些漂移类型效果不佳。

Method: 引入两种基于期望效用分数的无监督、模型无关的批量概念漂移检测器，无需部署后的真实标签即可判断是否需要重新训练模型。

Result: 在室外指纹定位和链路异常检测的实际用例中，两种方法比ADWIN、DDM、CUSUM等传统检测器性能提升20-40个百分点，F1分数达0.94和1.00，误报率降低20个百分点。

Conclusion: 提出的方法能有效检测概念漂移并触发模型重训练，显著优于传统方法，适用于动态无线环境。

Abstract: AI-native 6G networks promise unprecedented automation and performance by
embedding machine-learning models throughout the radio access and core segments
of the network. However, the non-stationary nature of wireless environments due
to infrastructure changes, user mobility, and emerging traffic patterns,
induces concept drifts that can quickly degrade these model accuracies.
Existing methods in general are very domain specific, or struggle with certain
type of concept drift. In this paper, we introduce two unsupervised,
model-agnostic, batch concept drift detectors. Both methods compute an
expected-utility score to decide when concept drift occurred and if model
retraining is warranted, without requiring ground-truth labels after
deployment. We validate our framework on two real-world wireless use cases in
outdoor fingerprinting for localization and for link-anomaly detection, and
demonstrate that both methods are outperforming classical detectors such as
ADWIN, DDM, CUSUM by 20-40 percentage points. Additionally, they achieve an
F1-score of 0.94 and 1.00 in correctly triggering retraining alarm, thus
reducing the false alarm rate by up to 20 percentage points compared to the
best classical detectors.

</details>


### [172] [Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies](https://arxiv.org/abs/2508.00228)
*Aashay Arora,Diego Davila,Frank Würthwein,John Graham,Dima Mishin,Justas Balcas,Tom Lehman,Xi Yang,Chin Guok,Harvey Newman*

Main category: cs.NI

TL;DR: 研究探讨了US-CMS Tier-2站点为应对HL-LHC时代400 Gbps带宽需求所需的软硬件改进，重点关注XRootD HTTP第三方复制的性能。


<details>
  <summary>Details</summary>
Motivation: 为应对HL-LHC时代网络流量增长，确保软件和硬件能够支持400 Gbps带宽需求，并解决站点间延迟变化带来的挑战。

Method: 通过系统测试，模拟真实网络条件，包括不同数量的集群起源和CPU分配，以及创建跨广域网的网络“循环”。

Result: 通过实验验证了XRootD HTTP第三方复制在400 Gbps链接下的性能表现。

Conclusion: 研究为US-CMS Tier-2站点在HL-LHC时代的网络优化提供了重要参考。

Abstract: In anticipation of the High Luminosity-LHC era, there is a critical need to
oversee software readiness for upcoming growth in network traffic for
production and user data analysis access. This paper looks into software and
hardware required improvements in US-CMS Tier-2 sites to be able to sustain and
meet the projected 400 Gbps bandwidth demands while tackling the challenge
posed by varying latencies between sites. Specifically, our study focuses on
identifying the performance of XRootD HTTP third-party copies across multiple
400 Gbps links and exploring different host and transfer configurations. Our
approach involves systematic testing with variations in the number of origins
per cluster and CPU allocations for each origin. By replicating real network
conditions and creating network "loops" that traverse multiple switches across
the wide area network, we are able to replicate authentic network conditions

</details>


### [173] [Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study](https://arxiv.org/abs/2508.00256)
*Chuang Zhang,Geng Sun,Jiacheng Wang,Yijing Lin,Weijie Yuan,Sinem Coleri,Dusit Niyato,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 本文探讨了低空无线网络（LAWNs）的安全挑战，并提出了一种基于大型人工智能模型（LAMs）的优化框架，通过增强状态特征和设计内在奖励来提升安全通信任务的强化学习性能。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络（LAWNs）因其低空操作、频繁移动性和对非授权频谱的依赖，面临独特的安全挑战，传统AI方法存在局限性，需要更先进的解决方案。

Method: 提出了一种基于LAMs的优化框架，利用大型语言模型（LLMs）生成增强状态特征，并设计内在奖励，以改进强化学习在安全通信任务中的性能。

Result: 通过案例研究验证了所提框架的有效性，仿真结果表明其能够显著提升安全通信性能。

Conclusion: LAMs在解决LAWNs安全挑战方面具有潜力，未来可进一步探索其在安全应用中的集成。

Abstract: Low-altitude wireless networks (LAWNs) have the potential to revolutionize
communications by supporting a range of applications, including urban parcel
delivery, aerial inspections and air taxis. However, compared with traditional
wireless networks, LAWNs face unique security challenges due to low-altitude
operations, frequent mobility and reliance on unlicensed spectrum, making it
more vulnerable to some malicious attacks. In this paper, we investigate some
large artificial intelligence model (LAM)-enabled solutions for secure
communications in LAWNs. Specifically, we first explore the amplified security
risks and important limitations of traditional AI methods in LAWNs. Then, we
introduce the basic concepts of LAMs and delve into the role of LAMs in
addressing these challenges. To demonstrate the practical benefits of LAMs for
secure communications in LAWNs, we propose a novel LAM-based optimization
framework that leverages large language models (LLMs) to generate enhanced
state features on top of handcrafted representations, and to design intrinsic
rewards accordingly, thereby improving reinforcement learning performance for
secure communication tasks. Through a typical case study, simulation results
validate the effectiveness of the proposed framework. Finally, we outline
future directions for integrating LAMs into secure LAWN applications.

</details>


### [174] [Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning](https://arxiv.org/abs/2508.00261)
*Saichao Liu,Geng Sun,Chuang Zhang,Xuejie Liu,Jiacheng Wang,Changyuan Zhao,Dusit Niyato*

Main category: cs.NI

TL;DR: 论文研究了无人机辅助移动边缘计算（MEC）系统，通过优化无人机轨迹和资源分配，提出了一种增强的深度强化学习算法（DPPOIL），以提高系统性能。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）在物联网（IoT）中具有潜力，但其性能受限于固定位置和服务范围。无人机（UAV）的引入可以扩展MEC的服务能力。

Method: 提出了一种多目标优化问题（TCRAMOP），优化无人机轨迹和资源分配，并开发了分布式近端策略优化与模仿学习（DPPOIL）算法。

Result: 仿真结果表明，DPPOIL算法在性能上优于其他基线方法。

Conclusion: 无人机辅助MEC系统结合DPPOIL算法能有效提升计算卸载数量和减少延迟与能耗。

Abstract: Mobile edge computing (MEC) is a promising technique to improve the
computational capacity of smart devices (SDs) in Internet of Things (IoT).
However, the performance of MEC is restricted due to its fixed location and
limited service scope. Hence, we investigate an unmanned aerial vehicle
(UAV)-assisted MEC system, where multiple UAVs are dispatched and each UAV can
simultaneously provide computing service for multiple SDs. To improve the
performance of system, we formulated a UAV-based trajectory control and
resource allocation multi-objective optimization problem (TCRAMOP) to
simultaneously maximize the offloading number of UAVs and minimize total
offloading delay and total energy consumption of UAVs by optimizing the flight
paths of UAVs as well as the computing resource allocated to served SDs. Then,
consider that the solution of TCRAMOP requires continuous decision-making and
the system is dynamic, we propose an enhanced deep reinforcement learning (DRL)
algorithm, namely, distributed proximal policy optimization with imitation
learning (DPPOIL). This algorithm incorporates the generative adversarial
imitation learning technique to improve the policy performance. Simulation
results demonstrate the effectiveness of our proposed DPPOIL and prove that the
learned strategy of DPPOIL is better compared with other baseline methods.

</details>


### [175] [Mamba for Wireless Communications and Networking: Principles and Opportunities](https://arxiv.org/abs/2508.00403)
*Rongsheng Zhang,Ruichen Zhang,Yang Lu,Wei Chen,Bo Ai,Dusit Niyato*

Main category: cs.NI

TL;DR: Mamba模型在无线通信中展现出潜力，通过平衡计算效率与效果，可能革新无线网络设计。文章综述了Mamba在无线系统中的应用，包括信号处理、资源分配和联合解码，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无线网络的异构性和动态性日益增加，Mamba模型因其在时空数据处理中的高效性，有望为无线通信和网络设计带来突破。

Method: 文章首先分析Mamba在无线信号处理中的潜力，提出两种应用框架：替代传统算法和启用新范式，并通过案例研究验证其效果。

Result: 案例研究表明，Mamba在特征增强和计算效率方面均有显著提升。

Conclusion: 文章总结了Mamba在无线通信中的关键挑战，并提出了未来研究方向。

Abstract: Mamba has emerged as a powerful model for efficiently addressing tasks
involving temporal and spatial data. Regarding the escalating heterogeneity and
dynamics in wireless networks, Mamba holds the potential to revolutionize
wireless communication and networking designs by balancing the trade-off
between computational efficiency and effectiveness. This article presents a
comprehensive overview of Mamba' applications in wireless systems.
Specifically, we first analyze the potentials of Mamba for wireless signal
processing tasks from the perspectives of long-range dependency modeling and
spatial feature extraction. Then we propose two application frameworks for
Mamba in wireless communications, i.e., replacement of traditional algorithms,
and enabler of novel paradigms. Guided by the two frameworks, we conduct case
studies on intelligent resource allocation and joint source and channel
decoding to demonstrate Mamba's improvements in both feature enhancement and
computational efficiency. Finally, we highlight critical challenges and outline
potential research directions for Mamba in wireless communications and
networking.

</details>


### [176] [Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications](https://arxiv.org/abs/2508.00583)
*Yunting Xu,Jiacheng Wang,Ruichen Zhang,Dusit Niyato,Deepu Rajan,Liang Yu,Haibo Zhou,Abbas Jamalipour,Xianbin Wang*

Main category: cs.NI

TL;DR: 该论文探讨了大型视觉模型（LVMs）在视觉智能中的基础作用及其在物联网（IoT）场景中的应用，提出了一种渐进式微调框架，以优化多任务联合性能。


<details>
  <summary>Details</summary>
Motivation: 研究LVMs在无线通信中的应用潜力，解决其模型规模大和重训练困难的问题。

Method: 提出渐进式微调框架，逐步调整预训练的LVMs以适应多任务联合优化。

Result: 在低空经济网络（LAENets）的案例中，该框架在联合波束成形和定位任务中优于传统CNN。

Conclusion: LVMs在智能无线系统中具有广阔的应用前景，渐进式微调是一种有效的适应方法。

Abstract: Large vision models (LVMs) have emerged as a foundational paradigm in visual
intelligence, achieving state-of-the-art performance across diverse visual
tasks. Recent advances in LVMs have facilitated their integration into Internet
of Things (IoT) scenarios, offering superior generalization and adaptability
for vision-assisted network optimization. In this paper, we first investigate
the functionalities and core architectures of LVMs, highlighting their
capabilities across classification, segmentation, generation, and multimodal
visual processing. We then explore a variety of LVM applications in wireless
communications, covering representative tasks across the physical layer,
network layer, and application layer. Furthermore, given the substantial model
size of LVMs and the challenges of model retraining in wireless domains, we
propose a progressive fine-tuning framework that incrementally adapts
pretrained LVMs for joint optimization of multiple IoT tasks. A case study in
low-altitude economy networks (LAENets) demonstrates the effectiveness of the
proposed framework over conventional CNNs in joint beamforming and positioning
tasks for Internet of drones, underscoring a promising direction for
integrating LVMs into intelligent wireless systems.

</details>


### [177] [Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications](https://arxiv.org/abs/2508.00616)
*Mingzhe Fan,Geng Sun,Hongyang Pan,Jiacheng Wang,Jiancheng An,Hongyang Du,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于无人机搭载智能超表面（UAV-SIMs）的通信系统，通过联合优化用户关联、无人机位置和超表面相位，最大化网络容量。


<details>
  <summary>Details</summary>
Motivation: 固定超表面（SIMs）限制了通信性能，而移动超表面（如无人机搭载的SIMs）能灵活部署，提升性能。

Method: 将联合优化问题分解为三个子问题（用户关联、无人机位置、相位优化），采用交替优化策略和CVX工具求解。

Result: 仿真验证了所提策略在不同场景下的有效性。

Conclusion: 无人机搭载超表面能显著提升通信性能，联合优化策略是可行的。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a promising
technology for realizing wave-domain signal processing, while the fixed SIMs
will limit the communication performance of the system compared to the mobile
SIMs. In this work, we consider a UAV-mounted SIMs (UAV-SIMs) assisted
communication system, where UAVs as base stations (BSs) can cache the data
processed by SIMs, and also as mobile vehicles flexibly deploy SIMs to enhance
the communication performance. To this end, we formulate a UAV-SIM-based joint
optimization problem (USBJOP) to comprehensively consider the association
between UAV-SIMs and users, the locations of UAV-SIMs, and the phase shifts of
UAV-SIMs, aiming to maximize the network capacity. Due to the non-convexity and
NP-hardness of USBJOP, we decompose it into three sub-optimization problems,
which are the association between UAV-SIMs and users optimization problem
(AUUOP), the UAV location optimization problem (ULOP), and the UAV-SIM phase
shifts optimization problem (USPSOP). Then, these three sub-optimization
problems are solved by an alternating optimization (AO) strategy. Specifically,
AUUOP and ULOP are transformed to a convex form and then solved by the CVX
tool, while we employ a layer-by-layer iterative optimization method for
USPSOP. Simulation results verify the effectiveness of the proposed strategy
under different simulation setups.

</details>


### [178] [Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach](https://arxiv.org/abs/2508.00629)
*Francisco Crespo,Javier Villegas,Carlos Baena,Eduardo Baena,Sergio Fortes,Raquel Barco*

Main category: cs.NI

TL;DR: 论文提出了一种轻量级、可编程的分布式应用（dApp），用于在Open RAN环境下动态管理CPU资源，提升能效和利用率，无需修改内核或依赖专有硬件。


<details>
  <summary>Details</summary>
Motivation: Open RAN的软硬件解耦和虚拟化带来了CPU资源管理的挑战，现有调度器在实时性要求下表现不佳。

Method: 通过部署在DU层的dApp，利用线程级遥测数据（如上下文切换、IPC、缓存指标）实时调整CPU线程亲和性、核心隔离和频率缩放。

Result: 实验结果显示，在商用srsRAN部署中实现了显著的节能效果，且不影响实时性能。

Conclusion: 该方案展示了低延迟dApp在下一代网络中精细资源控制的潜力。

Abstract: The transition toward softwarized Radio Access Networks (RANs), driven by the
Open RAN (O-RAN) paradigm, enables flexible, vendor-neutral deployments through
disaggregation and virtualization of base station functions. However, this
shift introduces new challenges in managing CPU resources efficiently under
strict real-time constraints. In particular, the interplay between
latency-sensitive RAN workloads and general-purpose Operating System (OS)
schedulers often leads to sub-optimal performance and unnecessary energy
consumption. This work proposes a lightweight, programmable distributed
application (dApp) deployed at the Distributed Unit (DU) level to dynamically
orchestrate CPU usage. The dApp operates in closed loop with the OS, leveraging
thread-level telemetry like context switches, Instructions Per Cycle (IPC), and
cache metrics, to adapt CPU thread affinity, core isolation, and frequency
scaling in real time. Unlike existing solutions, it requires no access to
proprietary RAN software, hardware-specific features, or kernel modifications.
Fully compliant with the O-RAN architecture and agnostic to the underlying RAN
stack, the proposed solution introduces negligible overhead while improving
energy efficiency and CPU utilization. Experimental results using a
commercial-grade srsRAN deployment demonstrate consistent power savings without
compromising real-time processing performance, highlighting the potential of
low-latency dApps for fine-grained resource control in next-generation networks

</details>


### [179] [Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience](https://arxiv.org/abs/2508.00688)
*Ruiyang Huang,Haocheng Wang,Yixuan Shen,Ning Gao,Qiang Ni,Shi Jin,Yifan Wu*

Main category: cs.NI

TL;DR: 该论文提出了一种两步框架，通过节点优先级排序和多目标拓扑优化，增强异构海空群网络的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 异构海空群网络在对抗环境中面临通信中断和结构脆弱性等问题，需要提升其韧性。

Method: 设计了三层架构表示网络结构、通信和任务依赖关系，提出SurBi-Ranking方法动态评估节点和边的重要性，并应用NSGA-III算法优化拓扑。

Result: 实验表明，SurBi-Ranking比传统方法更准确地识别关键节点和边，优化方法减少了30%的连接退化，提高了任务成功率。

Conclusion: 该框架显著提升了网络在对抗环境中的持续连接和任务有效性。

Abstract: Heterogeneous marine-aerial swarm networks encounter substantial difficulties
due to targeted communication disruptions and structural weaknesses in
adversarial environments. This paper proposes a two-step framework to
strengthen the network's resilience. Specifically, our framework combines the
node prioritization based on criticality with multi-objective topology
optimization. First, we design a three-layer architecture to represent
structural, communication, and task dependencies of the swarm networks. Then,
we introduce the SurBi-Ranking method, which utilizes graph convolutional
networks, to dynamically evaluate and rank the criticality of nodes and edges
in real time. Next, we apply the NSGA-III algorithm to optimize the network
topology, aiming to balance communication efficiency, global connectivity, and
mission success rate. Experiments demonstrate that compared to traditional
methods like K-Shell, our SurBi-Ranking method identifies critical nodes and
edges with greater accuracy, as deliberate attacks on these components cause
more significant connectivity degradation. Furthermore, our optimization
approach, when prioritizing SurBi-Ranked critical components under attack,
reduces the natural connectivity degradation by around 30%, achieves higher
mission success rates, and incurs lower communication reconfiguration costs,
ensuring sustained connectivity and mission effectiveness across multi-phase
operations.

</details>


### [180] [Deep Joint Source-Channel Coding for Small Satellite Applications](https://arxiv.org/abs/2508.00715)
*Olga Kondrateva,Grace Li Zhang,Julian Zobel,Björn Scheuermann,Stefan Dietzel*

Main category: cs.NI

TL;DR: 该论文提出了一种针对卫星通信的深度联合源-信道编码（DJSCC）框架，包括基础系统DJSCC-SAT和自适应架构ADJSCC-SAT，通过注意力模块实现单一网络适应多种信道状态，显著减少存储需求并提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决卫星通信中因信道条件复杂多变导致的通信瓶颈问题，探索DJSCC在实际卫星环境中的应用。

Method: 建立DJSCC-SAT基础系统，集成多状态统计信道模型；提出ADJSCC-SAT自适应架构，利用注意力模块实现单一网络适应多种信道状态。

Result: 在Sentinel-2多光谱数据上的实验表明，自适应方法性能接近多专用网络，同时显著减少存储需求，且对信道估计误差更具鲁棒性。

Conclusion: 该框架为实际卫星任务中部署鲁棒、自适应的DJSCC系统提供了实用且高效的解决方案。

Abstract: Small satellites used for Earth observation generate vast amounts of
high-dimensional data, but their operation in low Earth orbit creates a
significant communication bottleneck due to limited contact times and harsh,
varying channel conditions. While deep joint source-channel coding (DJSCC) has
emerged as a promising technique, its practical application to the complex
satellite environment remains an open question. This paper presents a
comprehensive DJSCC framework tailored for satellite communications. We first
establish a basic system, DJSCC-SAT, and integrate a realistic, multi-state
statistical channel model to guide its training and evaluation. To overcome the
impracticality of using separate models for every channel condition, we then
introduce an adaptable architecture, ADJSCC-SAT, which leverages attention
modules to allow a single neural network to adjust to a wide range of channel
states with minimal overhead. Through extensive evaluation on Sentinel-2
multi-spectral data, we demonstrate that our adaptable approach achieves
performance comparable to using multiple specialized networks while
significantly reducing model storage requirements. Furthermore, the adaptable
model shows enhanced robustness to channel estimation errors, outperforming the
non-adaptable baseline. The proposed framework is a practical and efficient
step toward deploying robust, adaptive DJSCC systems for real-world satellite
missions.

</details>


### [181] [Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE](https://arxiv.org/abs/2508.00735)
*Lucas Aubard,Johan Mazel,Gilles Guette,Pierre Chifflier*

Main category: cs.NI

TL;DR: 论文提出了PYROLYSE工具，用于测试和描述IP和TCP实现的重组策略，发现策略多样性远超预期，并报告了多个安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究IP和TCP重组策略的差异及其导致的NIDS与主机OS解释不一致的安全漏洞。

Method: 开发PYROLYSE工具，测试不同实现的重组策略，分析其多样性和潜在错误。

Result: 发现14到20种不同重组行为，报告8个安全漏洞，并指出n=2策略在n>2时不适用。

Conclusion: NIDS等工具应避免在重叠块超过两个时使用n=2策略，需改进重组策略一致性。

Abstract: IP fragmentation and TCP segmentation allow for splitting large data packets
into smaller ones, e.g., for transmission across network links of limited
capacity. These mechanisms permit complete or partial overlaps with different
data on the overlapping portions. IPv4, IPv6, and TCP reassembly policies,
i.e., the data chunk preferences that depend on the overlap types, differ
across protocol implementations. This leads to vulnerabilities, as NIDSes may
interpret the packet differently from the monitored host OSes. Some NIDSes,
such as Suricata or Snort, can be configured so that their policies are
consistent with the monitored OSes. The first contribution of the paper is
PYROLYSE, an audit tool that exhaustively tests and describes the reassembly
policies of various IP and TCP implementation types. This tool ensures that
implementations reassemble overlapping chunk sequences without errors. The
second contribution is the analysis of PYROLYSE artifacts. We first show that
the reassembly policies are much more diverse than previously thought. Indeed,
by testing all the overlap possibilities for n <= 3 test case chunks and
different testing scenarios, we observe from 14 to 20 different behaviors out
of 23 tested implementations depending on the protocol. Second, we report eight
errors impacting one OS, two NIDSes, and two embedded stacks, which can lead to
security issues such as NIDS pattern-matching bypass or DoS attacks. A CVE was
assigned to a NIDS error. Finally, we show that implemented IP and TCP policies
obtained through chunk pair testing are usually inconsistent with the observed
triplet reassemblies. Therefore, contrarily to what they currently do, NIDSes
or other network traffic analysis tools should not apply n = 2 pair policies
when the number of overlapping chunks exceeds two.

</details>


### [182] [Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype](https://arxiv.org/abs/2508.00792)
*Aashay Arora,Diego Davila,Jonathan Guiang,Frank Würthwein,Harvey Newman,Justas Balcas,Tom Lehman,Xi Yang*

Main category: cs.NI

TL;DR: DMM是一个原型接口，连接CERN的Rucio数据管理软件与ESNet的SENSE SDN服务，优化高能物理数据传输的带宽分配和监控。


<details>
  <summary>Details</summary>
Motivation: 通过SDN技术优化全球LHC计算网格基础设施中的高能物理数据传输效率。

Method: 设计并实现DMM，利用主机级和FTS工具级指标进行精细监控和优先级带宽分配。

Result: DMM成功实现了基于优先级的带宽分配和端到端数据流监控。

Conclusion: DMM为高能物理数据传输提供了高效的网络资源管理和监控解决方案。

Abstract: The Data Movement Manager (DMM) is a prototype interface that connects CERN's
data management software, Rucio, with the Sofware-Defined Networking (SDN)
service SENSE by ESNet. It enables SDN-enabled high-energy physics data flows
using the existing worldwide LHC computing grid infrastructure. A key feature
of DMM is transfer priority-based bandwidth allocation, optimizing network
usage. Additionally, it provides fine-grained monitoring of underperforming
flows by leveraging end-to-end data flow monitoring. This is achieved through
access to host-level (network interface) throughput metrics and transfer-tool
(FTS) data transfer job-level metrics. This paper details the design and
implementation of DMM.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [183] [Modelling Program Spaces in Program Synthesis with Constraints](https://arxiv.org/abs/2508.00005)
*Tilman Hinnerichs,Bart Swinkels,Jaap de Jong,Reuben Gardos Reid,Tudor Magirescu,Neil Yorke-Smith,Sebastijan Dumancic*

Main category: cs.PL

TL;DR: 论文提出了一种利用语法约束优化程序合成的方法，通过BART求解器显著减少程序空间。


<details>
  <summary>Details</summary>
Motivation: 程序合成的核心挑战是处理庞大的程序空间，现有方法未充分利用约束来排除无用程序。

Method: 引入语法约束建模程序空间，开发BART求解器高效传播和解决这些约束。

Result: 约束消除了高达99%的程序空间，显著减少枚举时间。

Conclusion: 语法约束是优化程序合成的有效工具，BART求解器展示了其潜力。

Abstract: A core challenge in program synthesis is taming the large space of possible
programs. Since program synthesis is essentially a combinatorial search, the
community has sought to leverage powerful combinatorial constraint solvers.
Here, constraints are used to express the program semantics, but not as a
potentially potent tool to remove unwanted programs. Recent inductive logic
programming approaches introduce constraints on the program's syntax to be
synthesized. These syntactic constraints allow for checking and propagating a
constraint without executing the program, and thus for arbitrary operators. In
this work, we leverage syntactic constraints to model program spaces, defining
not just solutions that are feasible, but also ones that are likely useful. To
demonstrate this idea, we introduce BART, a solver that efficiently propagates
and solves these constraints. We evaluate BART on program space enumeration
tasks, finding that the constraints eliminate up to 99 percent of the program
space, and that modeling program spaces significantly reduces enumeration time.

</details>


### [184] [From Provable Correctness to Probabilistic Generation: A Comparative Review of Program Synthesis Paradigms](https://arxiv.org/abs/2508.00013)
*Zurabi Kobaladze,Anna Arnania,Tamar Sanikidze*

Main category: cs.PL

TL;DR: 该论文综述了程序合成的五种主要范式，从逻辑基础方法到现代神经模型，分析了其原理、系统与应用，并探讨了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 程序合成是计算机科学的核心目标之一，论文旨在比较不同方法，展示领域演变与挑战。

Method: 通过文献回顾，分析五种合成方法：逻辑基础、归纳基础、草图/模式基础、大语言模型基础和神经符号混合方法。

Result: 总结了各方法的优缺点，强调了从符号方法向神经符号混合方法的转变。

Conclusion: 未来程序合成需结合可靠性与可扩展性，神经符号混合方法是重要方向。

Abstract: Program synthesis--the automated generation of executable code from
high-level specifications--has been a central goal of computer science for over
fifty years. This thesis provides a comparative literature review of the main
paradigms that have shaped the field, tracing its evolution from formal logic
based methods to recent advances using large scale neural models. We examine
five key approaches: logic based (deductive) synthesis, inductive (example
based) synthesis, sketch/schema based synthesis, large language model based
synthesis, and neuro-symbolic hybrids. For each, we analyze foundational
principles, notable systems, and practical applications, highlighting trade
offs between correctness guarantees, specification requirements, search
complexity, and expressive power. By reviewing developments from formally
verified synthesis tools such as KIDS and Coq to data driven models generating
probabilistic code from natural language like Codex, we present a comprehensive
narrative of progress and ongoing challenges. This work emphasizes the
transition from symbolic to hybrid neuro-symbolic methods and outlines future
directions for reliable and scalable program synthesis.

</details>


### [185] [Extended Abstract: Mutable Objects with Several Implementations](https://arxiv.org/abs/2508.00016)
*Matt Kaufmann,Yahya Sohail,Warren A. Hunt Jr*

Main category: cs.PL

TL;DR: ACL2的attach-stobj功能支持对抽象stobj的不同可执行操作，无需重新认证相关书籍或定理。


<details>
  <summary>Details</summary>
Motivation: 提供一种灵活的方式，允许用户在不重新认证的情况下为抽象stobj定义不同的可执行操作。

Method: 介绍了attach-stobj功能的背景、用户级概述和实现细节。

Result: 成功实现了attach-stobj功能，支持灵活的操作定义。

Conclusion: 该功能增强了ACL2的灵活性，简化了用户对抽象stobj的操作定义过程。

Abstract: This extended abstract outlines an ACL2 feature, attach-stobj, that first
appeared in ACL2 Version 8.6 (October, 2024). This feature supports different
executable operations for a given abstract stobj, without requiring
recertification of the book that introduces that stobj or theorems about it.
The paper provides background as well as a user-level overview and some
implementation notes.

</details>


### [186] [Automated Type Annotation in Python Using Large Language Models](https://arxiv.org/abs/2508.00422)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.PL

TL;DR: 使用LLMs生成Python类型注释，通过生成-检查-修复流程提高准确性和一致性，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 手动生成Python类型注释易出错且耗时，传统自动化方法存在局限性，探索LLMs的潜力。

Method: 开发生成-检查-修复流程，利用LLMs生成注释并通过静态检查器验证和迭代修复。

Result: GPT 4.1mini和O3Mini表现最佳，精确匹配率达70.5%，基础类型准确率79.1%。

Conclusion: LLMs无需任务特定微调即可高效生成类型注释，适用于其他可选类型语言。

Abstract: Type annotations in Python enhance maintainability and error detection.
However, generating these annotations manually is error prone and requires
extra effort. Traditional automation approaches like static analysis, machine
learning, and deep learning struggle with limited type vocabularies, behavioral
over approximation, and reliance on large labeled datasets. In this work, we
explore the use of LLMs for generating type annotations in Python. We develop a
generate check repair pipeline: the LLM proposes annotations guided by a
Concrete Syntax Tree representation, a static type checker (Mypy) verifies
them, and any errors are fed back for iterative refinement. We evaluate four
LLM variants: GPT 4oMini, GPT 4.1mini (general-purpose), and O3Mini, O4Mini
(reasoning optimized), on 6000 code snippets from the ManyTypes4Py benchmark.
We first measure the proportion of code snippets annotated by LLMs for which
MyPy reported no errors (i.e., consistent results): GPT 4oMini achieved
consistency on 65.9% of cases (34.1% inconsistent), while GPT 4.1mini, O3Mini,
and O4Mini each reached approximately 88.6% consistency (around 11.4%
failures). To measure annotation quality, we then compute exact-match and
base-type match accuracies over all 6000 snippets: GPT 4.1mini and O3Mini
perform the best, achieving up to 70.5% exact match and 79.1% base type
accuracy, requiring under one repair iteration on average. Our results
demonstrate that general-purpose and reasoning optimized LLMs, without any task
specific fine tuning or additional training can be effective in generating
consistent type annotations.They perform competitively with traditional deep
learning techniques which require large labeled dataset for training. While our
work focuses on Python, the pipeline can be extended to other optionally typed
imperative languages like Ruby

</details>


### [187] [Semantic Subtyping for Maps in Erlang](https://arxiv.org/abs/2508.00482)
*Erdem Yildirim,Albert Schimpf,Stefan Wehr,Annette Bieniusa*

Main category: cs.PL

TL;DR: 构建了一个包含类型变量、基础类型、集合类型和映射类型的集合论模型，定义了基于集合包含的语义子类型关系，重点研究了参数化映射类型的子类型定义。


<details>
  <summary>Details</summary>
Motivation: 为Erlang中的映射类型提供一种集合论模型，并定义其子类型关系，以支持更精确的类型系统设计。

Method: 构建类型模型，包括类型变量、基础类型、集合类型和映射类型，基于集合包含定义子类型关系。

Result: 成功定义了参数化映射类型的子类型关系，扩展了类型系统的表达能力。

Conclusion: 该工作为Erlang等语言的类型系统提供了理论基础，特别是在处理参数化映射类型时具有创新性。

Abstract: In this paper we will construct a set-theoretic model of types featuring type
variables, base types, set-theoretic types and map types. Syntax of map types
spans all the map types available in Erlang. The model of types is used to
define a semantic subtyping relation based on set containment. The novelty of
this work is the definition of subtyping over parameteric map types.

</details>


### [188] [Towards a unified framework for programming paradigms: A systematic review of classification formalisms and methodological foundations](https://arxiv.org/abs/2508.00534)
*Mikel Vandeloise*

Main category: cs.PL

TL;DR: 本文通过系统文献综述，探讨了多范式编程语言的分类问题，提出了基于原子原语和数学框架的重构方法。


<details>
  <summary>Details</summary>
Motivation: 多范式语言的兴起挑战了传统分类方法，导致互操作性缺陷等实际问题，需要更强大的理论基础。

Method: 基于74项主要研究的综合分析，评估现有分类形式及其局限性，并提出基于类型理论、范畴论和统一编程理论的重构方法。

Result: 现有分类法缺乏概念粒度与统一形式基础，而重构方法通过原子原语和数学框架解决了这些问题。

Conclusion: 文献显示从分类转向形式重构框架的显著趋势，本文为此提供了研究路线图。

Abstract: The rise of multi-paradigm languages challenges traditional classification
methods, leading to practical software engineering issues like interoperability
defects. This systematic literature review (SLR) maps the formal foundations of
programming paradigms. Our objective is twofold: (1) to assess the state of the
art of classification formalisms and their limitations, and (2) to identify the
conceptual primitives and mathematical frameworks for a more powerful,
reconstructive approach.
  Based on a synthesis of 74 primary studies, we find that existing taxonomies
lack conceptual granularity, a unified formal basis, and struggle with hybrid
languages. In response, our analysis reveals a strong convergence toward a
compositional reconstruction of paradigms. This approach identifies a minimal
set of orthogonal, atomic primitives and leverages mathematical frameworks,
predominantly Type theory, Category theory and Unifying Theories of Programming
(UTP), to formally guarantee their compositional properties.
  We conclude that the literature reflects a significant intellectual shift
away from classification towards these promising formal, reconstructive
frameworks. This review provides a map of this evolution and proposes a
research agenda for their unification.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [189] [Git Context Controller: Manage the Context of LLM-based Agents like Git](https://arxiv.org/abs/2508.00031)
*Junde Wu*

Main category: cs.SE

TL;DR: 论文提出了一种名为GCC的结构化上下文管理框架，用于解决大型语言模型代理在长期任务中的上下文管理瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在长期任务（如大型软件开发）中的部署，上下文管理成为关键瓶颈，需要一种高效的结构化方法。

Method: GCC框架受软件版本控制系统启发，将上下文管理设计为类似Git的版本化内存层次结构，支持COMMIT、BRANCH、MERGE和CONTEXT等操作。

Result: 实验表明，配备GCC的代理在SWE-Bench-Lite基准测试中表现最佳，解决了48.00%的软件错误，并在自复制案例中实现了40.7%的任务解决率。

Conclusion: GCC框架显著提升了LLM代理在长期任务中的上下文管理能力，支持目标管理、实验隔离和跨会话记忆恢复。

Abstract: Large language model (LLM) based agents have shown impressive capabilities by
interleaving internal reasoning with external tool use. However, as these
agents are deployed in long-horizon workflows, such as coding for a big,
long-term project, context management becomes a critical bottleneck. We
introduce Git-Context-Controller (GCC), a structured context management
framework inspired by software version control systems. GCC elevates context as
versioned memory hierarchy like Git. It structures agent memory as a persistent
file system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,
enabling milestone-based checkpointing, exploration of alternative plans, and
structured reflection. Our approach empowers agents to manage long-term goals,
isolate architectural experiments, and recover or hand off memory across
sessions and agents. Empirically, agents equipped with GCC achieve
state-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00
of software bugs, outperforming 26 competitive systems. In a self-replication
case study, a GCC-augmented agent builds a new CLI agent from scratch,
achieving 40.7 task resolution, compared to only 11.7 without GCC. The code is
released at: https://github.com/theworldofagents/GCC

</details>


### [190] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
*Nuno Fachada,Daniel Fernandes,Carlos M. Fernandes,Bruno D. Ferreira-Saraiva,João P. Matos-Carvalho*

Main category: cs.SE

TL;DR: 该研究系统评估了大型语言模型（LLMs）在生成复杂Python代码时的表现，发现仅有少数模型（如GPT-4.1）能稳定生成正确代码，同时揭示了第三方库文档和实现的问题。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在科学自动化中使用陌生Python API的能力，填补现有研究的空白。

Method: 通过零样本提示测试LLMs生成功能代码的能力，定量和定性分析代码的正确性和错误。

Result: 仅少数模型（如GPT-4.1）能稳定生成正确代码，同时发现第三方库文档和实现的问题。

Conclusion: LLMs在科学自动化中仍有局限，需优化提示设计、完善库文档并提升模型能力。

Abstract: Large Language Models (LLMs) have advanced rapidly as tools for automating
code generation in scientific research, yet their ability to interpret and use
unfamiliar Python APIs for complex computational experiments remains poorly
characterized. This study systematically benchmarks a selection of
state-of-the-art LLMs in generating functional Python code for two increasingly
challenging scenarios: conversational data analysis with the \textit{ParShift}
library, and synthetic data generation and clustering using \textit{pyclugen}
and \textit{scikit-learn}. Both experiments use structured, zero-shot prompts
specifying detailed requirements but omitting in-context examples. Model
outputs are evaluated quantitatively for functional correctness and prompt
compliance over multiple runs, and qualitatively by analyzing the errors
produced when code execution fails. Results show that only a small subset of
models consistently generate correct, executable code, with GPT-4.1 standing
out as the only model to always succeed in both tasks. In addition to
benchmarking LLM performance, this approach helps identify shortcomings in
third-party libraries, such as unclear documentation or obscure implementation
bugs. Overall, these findings highlight current limitations of LLMs for
end-to-end scientific automation and emphasize the need for careful prompt
design, comprehensive library documentation, and continued advances in language
model capabilities.

</details>


### [191] [Machine Learning Pipeline for Software Engineering: A Systematic Literature Review](https://arxiv.org/abs/2508.00045)
*Samah Kansab*

Main category: cs.SE

TL;DR: 本文通过系统文献综述（SLR）探讨了机器学习（ML）在软件工程（SE）中的应用，总结了最佳实践、挑战和差距，强调了稳健的ML管道对提升软件质量和效率的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂度的增加，传统方法难以满足质量和效率需求，ML成为自动化缺陷预测、代码审查等任务的关键解决方案。

Method: 通过SLR分析现有ML管道，包括数据预处理、特征工程、算法选择和验证技术。

Result: 发现SMOTE数据平衡、SZZ特征选择、集成方法（如随机森林）和新型评估指标（如BAM）显著提升模型性能。

Conclusion: 稳健的ML管道对解决SE挑战至关重要，研究为优化软件质量和效率提供了实用建议，并为未来创新奠定基础。

Abstract: The rapid advancement of software development practices has introduced
challenges in ensuring quality and efficiency across the software engineering
(SE) lifecycle. As SE systems grow in complexity, traditional approaches often
fail to scale, resulting in longer debugging times, inefficient defect
detection, and resource-heavy development cycles. Machine Learning (ML) has
emerged as a key solution, enabling automation in tasks such as defect
prediction, code review, and release quality estimation. However, the
effectiveness of ML in SE depends on the robustness of its pipeline, including
data collection, preprocessing, feature engineering, algorithm selection,
validation, and evaluation.
  This systematic literature review (SLR) examines state-of-the-art ML
pipelines designed for SE, consolidating best practices, challenges, and gaps.
Our findings show that robust preprocessing, such as SMOTE for data balancing
and SZZ-based algorithms for feature selection, improves model reliability.
Ensemble methods like Random Forest and Gradient Boosting dominate performance
across tasks, while simpler models such as Naive Bayes remain valuable for
efficiency and interpretability. Evaluation metrics including AUC, F1-score,
and precision are most common, with new metrics like Best Arithmetic Mean (BAM)
emerging in niche applications. Validation techniques such as bootstrapping are
widely used to ensure model stability and generalizability.
  This SLR highlights the importance of well-designed ML pipelines for
addressing SE challenges and provides actionable insights for researchers and
practitioners seeking to optimize software quality and efficiency. By
identifying gaps and trends, this study sets a foundation for advancing ML
adoption and fostering innovation in increasingly complex development
environments.

</details>


### [192] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
*Yihong Dong,Xue Jiang,Jiaru Qian,Tian Wang,Kechi Zhang,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: 本文系统综述了基于大语言模型（LLM）的代码生成代理技术，包括其核心特征、发展历程、技术分类、应用场景、评估工具及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨代码生成代理如何通过自主性、任务范围扩展和工程实用性增强，革新软件开发范式。

Method: 通过系统调查和分类，分析LLM代码生成代理的核心技术（单代理与多代理架构）及其在软件开发生命周期（SDLC）中的应用。

Result: 总结了主流评估基准、工具，并展示了该技术的快速发展与应用潜力。

Conclusion: 提出了该领域未来的基础性、长期研究方向，以应对当前挑战。

Abstract: Code generation agents powered by large language models (LLMs) are
revolutionizing the software development paradigm. Distinct from previous code
generation techniques, code generation agents are characterized by three core
features. 1) Autonomy: the ability to independently manage the entire workflow,
from task decomposition to coding and debugging. 2) Expanded task scope:
capabilities that extend beyond generating code snippets to encompass the full
software development lifecycle (SDLC). 3) Enhancement of engineering
practicality: a shift in research emphasis from algorithmic innovation toward
practical engineering challenges, such as system reliability, process
management, and tool integration. This domain has recently witnessed rapid
development and an explosion in research, demonstrating significant application
potential. This paper presents a systematic survey of the field of LLM-based
code generation agents. We trace the technology's developmental trajectory from
its inception and systematically categorize its core techniques, including both
single-agent and multi-agent architectures. Furthermore, this survey details
the applications of LLM-based agents across the full SDLC, summarizes
mainstream evaluation benchmarks and metrics, and catalogs representative
tools. Finally, by analyzing the primary challenges, we identify and propose
several foundational, long-term research directions for the future work of the
field.

</details>


### [193] [How Quantization Impacts Privacy Risk on LLMs for Code?](https://arxiv.org/abs/2508.00128)
*Md Nazmul Haque,Hua Yang,Zhou Yang,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术显著降低代码大语言模型的隐私风险，同时揭示了任务性能与隐私风险之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 研究量化技术对代码大语言模型（LLMs4Code）隐私风险的影响，以解决实际部署中的隐私问题。

Method: 对三种代表性模型家族（Pythia、CodeGen、GPTNeo）应用静态和动态量化技术，评估其对任务性能和隐私风险的影响。

Result: 量化显著降低隐私风险，且任务性能与隐私风险呈正相关；量化大模型可能比小模型更优。

Conclusion: 量化技术为部署压缩LLMs4Code提供了隐私保护指导，且结果适用于不同架构、模型大小和MI方法。

Abstract: Large language models for code (LLMs4Code) rely heavily on massive training
data, including sensitive data, such as cloud service credentials of the
projects and personal identifiable information of the developers, raising
serious privacy concerns. Membership inference (MI) has recently emerged as an
effective tool for assessing privacy risk by identifying whether specific data
belong to a model's training set. In parallel, model compression techniques,
especially quantization, have gained traction for reducing computational costs
and enabling the deployment of large models. However, while quantized models
still retain knowledge learned from the original training data, it remains
unclear whether quantization affects their ability to retain and expose privacy
information. Answering this question is of great importance to understanding
privacy risks in real-world deployments. In this work, we conduct the first
empirical study on how quantization influences task performance and privacy
risk simultaneously in LLMs4Code. To do this, we implement widely used
quantization techniques (static and dynamic) to three representative model
families, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that
quantization has a significant impact on reducing the privacy risk relative to
the original model. We also uncover a positive correlation between task
performance and privacy risk, indicating an underlying tradeoff. Moreover, we
reveal the possibility that quantizing larger models could yield better balance
than using full-precision small models. Finally, we demonstrate that these
findings generalize across different architectures, model sizes and MI methods,
offering practical guidance for safeguarding privacy when deploying compressed
LLMs4Code.

</details>


### [194] [Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems](https://arxiv.org/abs/2508.00198)
*Cleyton Magalhaes,Italo Santos,Brody Stuart-Verner,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 研究探讨了在现实应用开发中如何测试基于大语言模型（LLM）的系统，发现测试策略结合了手动和自动化方法，并面临模型行为不可预测等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着LLM成为日常技术的一部分，研究其在软件开发中的测试方法，填补了现有研究中对集成LLM系统测试的空白。

Method: 通过分析99份学生报告，采用主题分析和结构化编码方法，探索LLM系统的测试实践。

Result: 测试策略包括探索性测试、单元测试和提示迭代，挑战包括集成失败、输出不可预测和提示敏感性。

Conclusion: 测试LLM系统需结合传统验证方法和行为感知评估，为生成式组件测试提供了实践依据。

Abstract: Background: Software systems powered by large language models are becoming a
routine part of everyday technologies, supporting applications across a wide
range of domains. In software engineering, many studies have focused on how
LLMs support tasks such as code generation, debugging, and documentation.
However, there has been limited focus on how full systems that integrate LLMs
are tested during development. Aims: This study explores how LLM-powered
systems are tested in the context of real-world application development.
Method: We conducted an exploratory case study using 99 individual reports
written by students who built and deployed LLM-powered applications as part of
a university course. Each report was independently analyzed using thematic
analysis, supported by a structured coding process. Results: Testing strategies
combined manual and automated methods to evaluate both system logic and model
behavior. Common practices included exploratory testing, unit testing, and
prompt iteration. Reported challenges included integration failures,
unpredictable outputs, prompt sensitivity, hallucinations, and uncertainty
about correctness. Conclusions: Testing LLM-powered systems required
adaptations to traditional verification methods, blending source-level
reasoning with behavior-aware evaluations. These findings provide evidence on
the practical context of testing generative components in software systems.

</details>


### [195] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
*Briza Mel Dias de Sousa,Renato Cordeiro Ferreira,Alfredo Goldman*

Main category: cs.SE

TL;DR: 比较面向对象编程（OOP）和函数式编程（FP）对软件系统架构特性的影响，通过Kotlin（OOP）和Scala（FP）实现数字钱包系统，进行定性和定量分析。


<details>
  <summary>Details</summary>
Motivation: 随着函数式编程在软件行业中的关注度提升，研究OOP和FP对系统架构的影响，为开发者和组织提供更明智的选择依据。

Method: 通过自民族志定性分析和基于调查的定量分析，比较Kotlin和Scala实现的数字钱包系统。

Result: 定性分析揭示了编写代码的视角，定量分析收集了开发者对不同代码风格的反馈。

Conclusion: 研究结果有助于开发者和组织根据项目需求选择更适合的编程范式。

Abstract: After decades of dominance by object-oriented programming (OOP), functional
programming (FP) is gaining increasing attention in the software industry. This
study compares the impact of OOP and FP on the architectural characteristics of
software systems. For that, it examines the design and implementation of a
Digital Wallet system, developed in Kotlin (representing OOP) and Scala
(representing FP). The comparison is made through both qualitative and
quantitative analyses to explore how each paradigm influences the system's
architectural characteristics. The self-ethnographic qualitative analysis
provides a side-by-side comparison of both implementations, revealing the
perspective of those writing such code. The survey-based quantitative analysis
gathers feedback from developers with diverse backgrounds, showing their
impressions of those reading this code. Hopefully, these results may be useful
for developers or organizations seeking to make more informed decisions about
which paradigm is best suited for their next project.

</details>


### [196] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
*Panagiotis Diamantakis,Thanassis Avgerinos,Yannis Smaragdakis*

Main category: cs.SE

TL;DR: Desyan是一个集成值流分析和符号推理的平台，基于Datalog引擎和SMT求解器，提供高效、灵活的分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有的值流分析和符号分析技术缺乏统一的平台，限制了它们的集成与应用。Desyan旨在填补这一空白。

Method: Desyan扩展了Datalog引擎（Soufflé），集成了SMT求解器，支持自动处理程序分析中的常见模式，并提供Datalog原生符号推理。

Result: Desyan在值流分析中表现卓越（速度提升20倍以上），在需要SMT求解的应用中表现优异，同时在轻量级符号推理中速度提升显著（2倍以上）。

Conclusion: Desyan成功实现了值流与符号推理的无缝集成，为程序分析提供了高效、灵活的解决方案。

Abstract: Over the past two decades, two different types of static analyses have
emerged as dominant paradigms both in academia and industry: value-flow
analysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis
(e.g., symbolic execution). Despite their individual successes in numerous
application fields, the two approaches have remained largely separate; an
artifact of the simple reality that there is no broadly adopted unifying
platform for effortless and efficient integration of symbolic techniques with
high-performance data-flow reasoning.
  To bridge this gap, we introduce Desyan: a platform for writing program
analyses with seamless integration of value-flow and symbolic reasoning. Desyan
expands a production-ready Datalog fixpoint engine (Souffl\'e) with
full-fledged SMT solving invoking industry-leading SMT engines. Desyan provides
constructs for automatically (and efficiently!) handling typical patterns that
come up in program analysis. At the same time, the integration is agnostic with
respect to the solving technology, and supports Datalog-native symbolic
reasoning, via a bottom-up algebraic reasoning module.
  The result is an engine that allows blending different kinds of reasoning, as
needed for the underlying analysis. For value-flow analysis, the engine is the
best-in-class Datalog evaluator (often by a factor of over 20x in execution
time); for applications that require full SMT (e.g., a concolic execution
engine or other symbolic evaluator that needs to solve arbitrarily complex
conditions), the engine is leveraging the leading SMT solvers; for lightweight
symbolic evaluation (e.g., solving simple conditionals in the context of a
path-sensitive analysis), the engine can use Datalog-native symbolic reasoning,
achieving large speedups (often of over 2x) compared to eagerly appealing to an
SMT solver.

</details>


### [197] [Leveraging Large Language Model for Information Retrieval-based Bug Localization](https://arxiv.org/abs/2508.00253)
*Moumita Asad,Rafed Muhammad Yasir,Armin Geramirad,Sam Malek*

Main category: cs.SE

TL;DR: GenLoc是一种基于大型语言模型（LLM）的缺陷定位方法，通过代码探索功能和向量嵌入解决词汇不匹配问题，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有缺陷定位方法受限于缺陷报告与源代码之间的词汇不匹配问题，效果有限。

Method: GenLoc利用LLM和代码探索功能迭代分析代码库，并可选择使用向量嵌入检索语义相关文件。

Result: 在6个大型Java项目的9,000多个真实缺陷报告上测试，GenLoc在多个指标上优于5种最先进技术，Accuracy@1平均提升60%以上。

Conclusion: GenLoc通过LLM和上下文增强，显著提高了缺陷定位的准确性和效果。

Abstract: Information Retrieval-based Bug Localization aims to identify buggy source
files for a given bug report. While existing approaches -- ranging from vector
space models to deep learning models -- have shown potential in this domain,
their effectiveness is often limited by the vocabulary mismatch between bug
reports and source code. To address this issue, we propose a novel Large
Language Model (LLM) based bug localization approach, called GenLoc. Given a
bug report, GenLoc leverages an LLM equipped with code-exploration functions to
iteratively analyze the code base and identify potential buggy files. To gather
better context, GenLoc may optionally retrieve semantically relevant files
using vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug
reports from six large-scale Java projects. Experimental results show that
GenLoc outperforms five state-of-the-art bug localization techniques across
multiple metrics, achieving an average improvement of more than 60\% in
Accuracy@1.

</details>


### [198] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
*Md Imranur Rahman Akib,Fathima Binthe Muhammed,Umit Saha,Md Fazlul Karim Patwary,Mehrin Anannya,Md Alomgeer Hussein,Md Biplob Hosen*

Main category: cs.SE

TL;DR: 研究通过Codeforces用户的编程竞赛表现预测其就业潜力，使用随机森林分类器将用户分为四个就业能力等级，模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 快速发展的科技行业需要工具评估程序员的就业准备情况，本研究旨在分析编程竞赛表现与就业机会的关联。

Method: 通过Codeforces API收集用户数据，处理关键性能指标，使用随机森林分类器构建预测模型，并通过Flask部署实时预测系统。

Result: 模型能有效区分不同技能水平的用户，分类为四个就业能力等级。

Conclusion: 研究为机器学习在职业评估中的应用奠定了基础，可扩展至更广泛技术领域的就业预测。

Abstract: In today's fast-paced tech industry, there is a growing need for tools that
evaluate a programmer's job readiness based on their coding performance. This
study focuses on predicting the potential of Codeforces users to secure various
levels of software engineering jobs. The primary objective is to analyze how a
user's competitive programming activity correlates with their chances of
obtaining positions, ranging from entry-level roles to jobs at major tech
companies. We collect user data using the Codeforces API, process key
performance metrics, and build a prediction model using a Random Forest
classifier. The model categorizes users into four levels of employability,
ranging from those needing further development to those ready for top-tier tech
jobs. The system is implemented using Flask and deployed on Render for
real-time predictions. Our evaluation demonstrates that the approach
effectively distinguishes between different skill levels based on coding
proficiency and participation. This work lays a foundation for the use of
machine learning in career assessment and could be extended to predict job
readiness in broader technical fields.

</details>


### [199] [Accurate and Consistent Graph Model Generation from Text with Large Language Models](https://arxiv.org/abs/2508.00255)
*Boqi Chen,Ou Wei,Bingzhou Zheng,Gunter Mussbacher*

Main category: cs.SE

TL;DR: 论文提出了一种基于抽象-具体化框架的方法，通过聚合LLM的多个输出来提高生成图模型的一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成图模型时的语法违规、约束不一致和准确性不足问题。

Method: 采用抽象-具体化框架，先构建概率部分模型，再优化为满足约束的具体模型。

Result: 实验表明，该方法显著提升了生成图模型的一致性和质量。

Conclusion: 提出的框架有效解决了LLM生成图模型的主要问题，具有实际应用价值。

Abstract: Graph model generation from natural language description is an important task
with many applications in software engineering. With the rise of large language
models (LLMs), there is a growing interest in using LLMs for graph model
generation. Nevertheless, LLM-based graph model generation typically produces
partially correct models that suffer from three main issues: (1) syntax
violations: the generated model may not adhere to the syntax defined by its
metamodel, (2) constraint inconsistencies: the structure of the model might not
conform to some domain-specific constraints, and (3) inaccuracy: due to the
inherent uncertainty in LLMs, the models can include inaccurate, hallucinated
elements. While the first issue is often addressed through techniques such as
constraint decoding or filtering, the latter two remain largely unaddressed.
Motivated by recent self-consistency approaches in LLMs, we propose a novel
abstraction-concretization framework that enhances the consistency and quality
of generated graph models by considering multiple outputs from an LLM. Our
approach first constructs a probabilistic partial model that aggregates all
candidate outputs and then refines this partial model into the most appropriate
concrete model that satisfies all constraints. We evaluate our framework on
several popular open-source and closed-source LLMs using diverse datasets for
model generation tasks. The results demonstrate that our approach significantly
improves both the consistency and quality of the generated graph models.

</details>


### [200] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
*Dong Huang,Jie M. Zhang,Mark Harman,Qianru Zhang,Mingzhe Du,See-Kiong Ng*

Main category: cs.SE

TL;DR: 论文提出了ULT（UnLeakedTestbench）和PLT（PreLeakedTestbench）两个新基准，用于更真实地评估大语言模型（LLMs）在单元测试生成中的能力，解决了现有基准的数据污染和结构简单性问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成基准存在数据污染和结构简单性问题，导致科学结论的有效性存疑。

Method: 通过多阶段筛选过程构建ULT，包含3,909个高复杂度的真实Python函数任务，并引入PLT作为对照基准。

Result: ULT的测试生成结果显著低于现有基准（如TestEval和PLT），表明其更具挑战性。

Conclusion: ULT提供了一个更真实和具有挑战性的评估框架，有助于更准确地衡量LLMs的测试生成能力。

Abstract: Recently, large language models (LLMs) have shown great promise in automating
unit test generation, significantly reducing the manual effort required by
developers. To effectively evaluate the capabilities of LLMs in this domain, it
is crucial to have a well-designed benchmark that accurately reflects
real-world scenarios and mitigates common pitfalls. Existing LLM test
generation benchmarks are limited by two critical drawbacks: data contamination
and structurally simple function code. As a result, we often cannot rely on the
validity of scientific conclusions drawn from empirical studies using these
limited benchmarks. The empirical evidence presented may be biased due to
contamination and may fail to generalize beyond toy programs due to structural
simplicity.
  To address these problems, we introduce ULT (UnLeakedTestbench), a new
benchmark specifically designed for function-level unit test generation from
real-world Python functions. ULT is constructed through a multi-stage curation
process that ensures high cyclomatic complexity and mitigates test case
contamination. With 3,909 carefully selected function-level tasks, ULT provides
a more realistic and challenging evaluation of LLMs' test generation
capabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT
with leaked tests designed to enable a controlled analysis of memorization
versus reasoning in test generation. Our evaluation results demonstrate that
ULT is significantly more challenging. For example, test cases generated by
LLMs only achieve 41.32\%, 45.10\%, 30.22\%, and 40.21\% for accuracy,
statement coverage, branch coverage, and mutation score on average for all
LLMs, respectively. These results are substantially lower than the
corresponding metrics on TestEval (91.79\%, 92.18\%, 82.04\%, and 49.69\%) and
PLT (47.07\%, 55.13\%, 40.07\%, and 50.80\%).

</details>


### [201] [Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory](https://arxiv.org/abs/2508.00462)
*Linus Ververs,Lutz Prechelt*

Main category: cs.SE

TL;DR: 研究分析了工业界中结对编程中的权力相关现象，提出了避免权力差距的建议。


<details>
  <summary>Details</summary>
Motivation: 理解结对编程中的权力现象，并为从业者提供改进建议。

Method: 使用扎根理论分析22个工业结对编程会话，并通过292人调查验证理论。

Result: 提出了权力差距理论，揭示了其负面影响，并验证了现象的普遍性。

Conclusion: 避免权力差距是结对编程的重要技能，需减少等级行为，增加平等行为。

Abstract: Context: Pair Programming as a work mode is used (occasionally or frequently)
throughout professional software development. Objective: Understand what
power-related phenomena occur in pair programming as it is used in industry;
give advice to practitioners on how to do better pair programming. Method:
Analyze 22 industrial pair programming sessions using Grounded Theory
Methodology. Formulate a Grounded Theory on power-related behaviors. Run a
survey with 292 participants about that theory. Use it to demonstrate that the
phenomena are common. Results: Our theory describes the phenomenon of Power
Gap: a perceived difference in participation opportunities. The theory shows
the behaviors that create a Power Gap or result from it. Power Gaps tend to
damage knowledge transfer, code quality, and process effi ciency. The survey
results show that all concepts from our theory are frequent in practice. They
also provide more grounding for concepts that are observable only indirectly.
Conclusions: It is a valuable component of pair programming skill to be able to
avoid Power Gaps. Specifically, pair partners need to avoid Hierarchical
Behavior (which tends to create or increase a Power Gap) and should perform
enough Equalizing Behavior (which prevents or reduces a Power Gap).

</details>


### [202] [SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval](https://arxiv.org/abs/2508.00546)
*Wenchao Gu,Zongyi Lyu,Yanlin Wang,Hongyu Zhang,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: 提出了一种名为SPENCER的框架，结合双编码器和交叉编码器以提高代码检索的效率和准确性，并通过模型蒸馏技术减少推理时间。


<details>
  <summary>Details</summary>
Motivation: 现有双编码器模型在代码检索任务中缺乏底层交互，限制了性能。

Method: SPENCER框架结合双编码器和交叉编码器，并提出自适应模型蒸馏技术和教学助理选择策略。

Result: 实验表明，结合双编码器和交叉编码器提升了性能，模型蒸馏技术减少70%推理时间且保留98%性能。

Conclusion: SPENCER框架在效率和准确性上均优于纯双编码器模型。

Abstract: Code retrieval aims to provide users with desired code snippets based on
users' natural language queries. With the development of deep learning
technologies, adopting pre-trained models for this task has become mainstream.
Considering the retrieval efficiency, most of the previous approaches adopt a
dual-encoder for this task, which encodes the description and code snippet into
representation vectors, respectively. However, the model structure of the
dual-encoder tends to limit the model's performance, since it lacks the
interaction between the code snippet and description at the bottom layer of the
model during training. To improve the model's effectiveness while preserving
its efficiency, we propose a framework, which adopts Self-AdaPtive Model
Distillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts
the dual-encoder to narrow the search space and then adopts the cross-encoder
to improve accuracy. To improve the efficiency of SPENCER, we propose a novel
model distillation technique, which can greatly reduce the inference time of
the dual-encoder while maintaining the overall performance. We also propose a
teaching assistant selection strategy for our model distillation, which can
adaptively select the suitable teaching assistant models for different
pre-trained models during the model distillation to ensure the model
performance. Extensive experiments demonstrate that the combination of
dual-encoder and cross-encoder improves overall performance compared to solely
dual-encoder-based models for code retrieval. Besides, our model distillation
technique retains over 98% of the overall performance while reducing the
inference time of the dual-encoder by 70%.

</details>


### [203] [Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System](https://arxiv.org/abs/2508.00593)
*Shuyao Jiang,Jiazhen Gu,Wujie Zheng,Yangfan Zhou,Michael R. Lyu*

Main category: cs.SE

TL;DR: 论文通过实证研究分析了大规模在线服务系统中的用户反馈，发现大部分反馈与系统问题无关，需过滤无关信息，并验证了机器学习方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 理解用户反馈特征以改进基于反馈的问题检测方法。

Method: 对来自6个真实服务的50,378,766条用户反馈进行实证研究，分析反馈内容、特征与问题关联性，并评估机器学习技术的适用性。

Result: 大部分反馈与问题无关，需过滤；某些严重问题难以通过反馈特征检测；反馈主题分布稳定，机器学习方法可行。

Conclusion: 研究结果为大规模服务系统中基于反馈的问题检测提供了实证基础，指导实用检测方法的设计与实现。

Abstract: Background: It has long been suggested that user feedback, typically written
in natural language by end-users, can help issue detection. However, for
large-scale online service systems that receive a tremendous amount of
feedback, it remains a challenging task to identify severe issues from user
feedback. Aims: To develop a better feedback-based issue detection approach, it
is crucial first to gain a comprehensive understanding of the characteristics
of user feedback in real production systems. Method: In this paper, we conduct
an empirical study on 50,378,766 user feedback items from six real-world
services in a one-billion-user online service system. We first study what users
provide in their feedback. We then examine whether certain features of feedback
items can be good indicators of severe issues. Finally, we investigate whether
adopting machine learning techniques to analyze user feedback is reasonable.
Results: Our results show that a large proportion of user feedback provides
irrelevant information about system issues. As a result, it is crucial to
filter out issue-irrelevant information when processing user feedback.
Moreover, we find severe issues that cannot be easily detected based solely on
user feedback characteristics. Finally, we find that the distributions of the
feedback topics in different time intervals are similar. This confirms that
designing machine learning-based approaches is a viable direction for better
analyzing user feedback. Conclusions: We consider that our findings can serve
as an empirical foundation for feedback-based issue detection in large-scale
service systems, which sheds light on the design and implementation of
practical issue detection approaches.

</details>


### [204] [MCeT: Behavioral Model Correctness Evaluation using Large Language Models](https://arxiv.org/abs/2508.00630)
*Khaled Ahmed,Jialing Song,Boqi Chen,Ou Wei,Bingzhou Zheng*

Main category: cs.SE

TL;DR: MCeT是一种自动化工具，用于评估行为模型（如序列图）的正确性，结合LLMs和多视角方法，显著提高了问题检测的准确性和数量。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在模型生成中的广泛应用，需要自动化工具来评估模型的正确性，为工程师提供反馈并帮助AI助手自我改进。

Method: 提出MCeT工具，采用细粒度、多视角方法，将图和需求分解为原子单元进行比较，并结合自一致性检查以减少LLM幻觉问题。

Result: MCeT将直接检查的精度从0.58提升到0.81，检测到比直接方法多90%的问题，并平均每图报告6个新问题。

Conclusion: MCeT通过结合LLMs和多视角方法，显著提升了行为模型正确性评估的效果，为自动化和人工辅助建模提供了有力支持。

Abstract: Behavioral model diagrams, e.g., sequence diagrams, are an essential form of
documentation that are typically designed by system engineers from requirements
documentation, either fully manually or assisted by design tools. With the
growing use of Large Language Models (LLM) as AI modeling assistants, more
automation will be involved in generating diagrams. This necessitates the
advancement of automatic model correctness evaluation tools. Such a tool can be
used to evaluate both manually and AI automatically generated models; to
provide feedback to system engineers, and enable AI assistants to self-evaluate
and self-enhance their generated models.
  In this paper, we propose MCeT, the first fully automated tool to evaluate
the correctness of a behavioral model, sequence diagrams in particular, against
its corresponding requirements text and produce a list of issues that the model
has. We utilize LLMs for the correctness evaluation tasks as they have shown
outstanding natural language understanding ability. However, we show that
directly asking an LLM to compare a diagram to requirements finds less than 35%
of issues that experienced engineers can find. We propose to supplement the
direct check with a fine-grained, multi-perspective approach; we split the
diagram into atomic, non-divisible interactions, and split the requirements
text into atomic, self-contained items. We compare the diagram with atomic
requirements and each diagram-atom with the requirements. We also propose a
self-consistency checking approach that combines perspectives to mitigate LLM
hallucinated issues. Our combined approach improves upon the precision of the
direct approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,
the approach finds 90% more issues that the experienced engineers found than
the direct approach, and reports an average of 6 new issues per diagram.

</details>


### [205] [Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?](https://arxiv.org/abs/2508.00700)
*Alfred Santa Molison,Marcia Moraes,Glaucia Melo,Fabio Santos,Wesley K. G. Assuncao*

Main category: cs.SE

TL;DR: 研究比较了LLM生成代码与人工编写代码的内部质量属性，发现LLM生成的代码整体上缺陷更少且修复成本更低，但在复杂场景下可能引入关键问题。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在代码生成中的表现，尤其是在软件质量方面与人工编写代码的对比。

Method: 通过实证研究，结合编码任务数据集、三种LLM配置（零样本、少样本和微调）以及SonarQube评估软件质量。

Result: LLM生成的代码缺陷更少，修复成本更低；微调模型减少了高严重性问题的出现，但在复杂场景下可能引入结构性问题。

Conclusion: LLM生成的代码在质量上有优势，但在复杂场景下需系统评估和验证，以充分发挥其潜力。

Abstract: Background: The rise of Large Language Models (LLMs) in software development
has opened new possibilities for code generation. Despite the widespread use of
this technology, it remains unclear how well LLMs generate code solutions in
terms of software quality and how they compare to human-written code. Aims:
This study compares the internal quality attributes of LLM-generated and
human-written code. Method: Our empirical study integrates datasets of coding
tasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and
SonarQube to assess software quality. The dataset comprises Python code
solutions across three difficulty levels: introductory, interview, and
competition. We analyzed key code quality metrics, including maintainability
and reliability, and the estimated effort required to resolve code issues.
Results: Our analysis shows that LLM-generated code has fewer bugs and requires
less effort to fix them overall. Interestingly, fine-tuned models reduced the
prevalence of high-severity issues, such as blocker and critical bugs, and
shifted them to lower-severity categories, but decreased the model's
performance. In competition-level problems, the LLM solutions sometimes
introduce structural issues that are not present in human-written code.
Conclusion: Our findings provide valuable insights into the quality of
LLM-generated code; however, the introduction of critical issues in more
complex scenarios highlights the need for a systematic evaluation and
validation of LLM solutions. Our work deepens the understanding of the
strengths and limitations of LLMs for code generation.

</details>


### [206] [Tool-Assisted Conformance Checking to Reference Process Models](https://arxiv.org/abs/2508.00738)
*Bernhard Rumpe,Max Stachon,Sebastian Stüber,Valdes Voufo*

Main category: cs.SE

TL;DR: 本文提出了一种基于因果依赖分析的自动化一致性检查方法，用于验证具体流程模型与参考模型的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的一致性检查方法缺乏语义模型比较的表达能力和自动化能力，无法满足需求。

Method: 通过因果依赖分析任务和事件，提出了一种算法，并将其集成到语义框架中。

Result: 通过案例研究验证了方法的有效性，提高了流程模型一致性验证的准确性和灵活性。

Conclusion: 研究提供了一种工具辅助解决方案，增强了流程模型一致性验证的能力。

Abstract: Reference models convey best practices and standards. The reference
frameworks necessitate conformance checks to ensure adherence to established
guidelines and principles, which is crucial for maintaining quality and
consistency in various processes. This paper explores automated conformance
checks for concrete process models against reference models using causal
dependency analysis of tasks and events. Existing notions of conformance
checking for process models focus on verifying process execution traces and
lack the expressiveness and automation needed for semantic model comparison,
leaving this question unresolved. We integrate our approach into a broader
semantic framework for defining reference model conformance. We outline an
algorithm for reference process model conformance checking, evaluate it through
a case study, and discuss its strengths and limitations. Our research provides
a tool-assisted solution enhancing accuracy and flexibility in process model
conformance verification.

</details>


### [207] [Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures](https://arxiv.org/abs/2508.00749)
*Johanna Grahl,Bernhard Rumpe,Max Stachon,Sebastian Stüber*

Main category: cs.SE

TL;DR: 本文研究了动态符号执行（DSE）在组件-连接器架构语义差异分析中的应用，通过增强MontiArc-to-Java生成器收集运行时数据，评估了DSE的效率和局限性。


<details>
  <summary>Details</summary>
Motivation: 在模型驱动开发中，确保模型正确性和一致性至关重要，因此需要有效的方法来分析语义差异。

Method: 增强MontiArc-to-Java生成器，收集符号和具体执行数据，评估不同执行策略的效率和完整性。

Result: DSE在组件-连接器架构分析中表现出潜力，但可扩展性仍是主要限制。

Conclusion: DSE适用于语义差异分析，但需进一步研究以提升其在大规模系统中的实用性。

Abstract: In the context of model-driven development, ensuring the correctness and
consistency of evolving models is paramount. This paper investigates the
application of Dynamic Symbolic Execution (DSE) for semantic difference
analysis of component-and-connector architectures, specifically utilizing
MontiArc models. We have enhanced the existing MontiArc-to-Java generator to
gather both symbolic and concrete execution data at runtime, encompassing
transition conditions, visited states, and internal variables of automata. This
data facilitates the identification of significant execution traces that
provide critical insights into system behavior. We evaluate various execution
strategies based on the criteria of runtime efficiency, minimality, and
completeness, establishing a framework for assessing the applicability of DSE
in semantic difference analysis. Our findings indicate that while DSE shows
promise for analyzing component and connector architectures, scalability
remains a primary limitation, suggesting further research is needed to enhance
its practical utility in larger systems.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [208] [Robust Econometrics for Growth-at-Risk](https://arxiv.org/abs/2508.00263)
*Tobias Adrian,Yuya Sasaki,Yulong Wang*

Main category: econ.EM

TL;DR: 本文提出了一种新的稳健计量经济学方法，用于估计Growth-at-Risk（GaR）的尾部，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前GaR框架假设帕累托指数恒定，存在局限性。

Method: 基于严格理论框架，引入新的计量经济学方法估计GaR尾部。

Result: 模拟显示新方法在预测准确性上优于现有方法，并能更好地捕捉金融异常。

Conclusion: 新方法为长期GaR分析提供了更准确和深入的预测。

Abstract: The Growth-at-Risk (GaR) framework has garnered attention in recent
econometric literature, yet current approaches implicitly assume a constant
Pareto exponent. We introduce novel and robust econometrics to estimate the
tails of GaR based on a rigorous theoretical framework and establish validity
and effectiveness. Simulations demonstrate consistent outperformance relative
to existing alternatives in terms of predictive accuracy. We perform a
long-term GaR analysis that provides accurate and insightful predictions,
effectively capturing financial anomalies better than current methods.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [209] [Channel Choice and Customer Value](https://arxiv.org/abs/2508.00208)
*Shirsho Biswas,Hema Yoganarasimhan,Haonan Zhang*

Main category: econ.GN

TL;DR: 研究发现，不同原因导致的多渠道客户在采用线上购物后行为差异显著，需根据采用动机调整营销策略。


<details>
  <summary>Details</summary>
Motivation: 探讨传统零售商投资电子商务后，客户采用新渠道的原因如何影响其后续行为。

Method: 利用巴西一家宠物用品零售商的交易数据，分析四种不同采用路径（自然采用、疫情驱动、促销活动、忠诚计划）对客户支出的影响。

Result: 所有采用线上购物的客户支出均增加，但行为因采用原因而异：疫情采用者与自然采用者支出相似但线下粘性更高，促销采用者支出减少且利润较低。

Conclusion: 企业需根据客户采用动机调整渠道和促销投资策略，避免将所有多渠道客户视为同质群体。

Abstract: The rapid growth of digital shopping channels has prompted many traditional
retailers to invest in e-commerce websites and mobile apps. While prior
literature shows that multichannel customers tend to be more valuable, it
overlooks how the reason for adopting a new channel may shape post-adoption
behavior. Using transaction-level data from a major Brazilian pet supplies
retailer, we examine how adoption of online shopping - by previously
offline-only customers - affects post-adoption spend, profitability, and
channel usage. We study four distinct adoption pathways: organic adoption,
adoption due to the COVID-19 pandemic, Black Friday promotions, and a newly
launched loyalty program. We find that although all adopter groups increase
their spending relative to offline-only customers, post-adoption behavior
differs based on the reason for adoption. COVID-19 adopters behave similarly to
organic adopters in terms of spending, but show greater offline stickiness
consistent with consumer inertia and habit theory, yielding higher profits due
to higher offline margins. In contrast, promotion-driven adopters spend less
post-adoption due to forward buying and exhibit lower profitability. Our
findings caution against treating all multichannel customers as equal and
highlight the importance of incorporating behavioral theories into forecasting
and targeting strategies. Firms should account for adoption motives when
evaluating channel and promotional investments.

</details>


### [210] [Assessing the Macroeconomic Impacts of Disasters: an Updated Multi-Regional Impact Assessment (MRIA) model](https://arxiv.org/abs/2508.00510)
*Surender Raj Vanniya Perumal,Mark Thissen,Marleen de Ruiter,Elco E. Koks*

Main category: econ.GN

TL;DR: 该研究提出了一种多区域影响评估（MRIA）模型，用于评估灾害对区域和宏观经济的影响，强调提升区域贸易灵活性对减轻灾害影响的重要性。


<details>
  <summary>Details</summary>
Motivation: 灾害对供应链的破坏会引发跨区域的连锁效应，未受影响区域的补偿能力受限于其生产能力和区域间的物流约束。

Method: 引入MRIA模型，结合区域贸易动态和物流约束，评估灾害后果。

Result: 研究发现，仅提升生产能力不足，需改善区域贸易灵活性；受灾区域负面影响严重，而大型出口导向区域则受益于生产活动增加。

Conclusion: 研究提出了一种结合敏感性、增量中断分析和部门关键性评估的方法，有效识别低冗余部门，并考虑灾后区域替代的可能性。

Abstract: Disasters often impact supply chains, leading to cascading effects across
regions. While unaffected regions may attempt to compensate, their ability is
constrained by their available production capacity and logistical constraints
between regions. This study introduces a Multi-Regional Impact Assessment
(MRIA) model to evaluate the regional and macroeconomic consequences of
disasters, capturing regional post-disaster trade dynamics and logistical
constraints. Our findings emphasize that enhancing production capacity alone is
inadequate; regional trade flexibility must also be improved to mitigate
disaster impacts. At the regional level, disaster-affected areas experience
severe negative impacts, whereas larger, export-oriented regions benefit from
increased production activity. Additionally, we propose a sectoral criticality
assessment alongside the more common sensitivity and incremental disruption
analysis, which effectively identifies sectors with low redundancy while
accounting for the potential for regional substitution in a post-disaster
scenario.

</details>


### [211] [Systemic Trade Risk Suppresses Comparative Advantage in Rare Earth Dependent Industries](https://arxiv.org/abs/2508.00556)
*Peter Klimek,Sophia Baum,Markus Gerschberger,Maximilian Hess*

Main category: econ.GN

TL;DR: 论文分析了全球稀土元素（REEs）贸易网络的分层依赖性，揭示了上游和中间产品依赖性的差异，并提出了针对中游加工和关键输入生产的政策建议。


<details>
  <summary>Details</summary>
Motivation: 稀土元素对清洁和高科技应用至关重要，但全球贸易依赖性使各国在生产网络中面临脆弱性。研究旨在揭示不同层级产品的依赖性差异及其对工业韧性和政策设计的影响。

Method: 使用AI增强的统计框架构建了2007-2023年168种稀土相关产品的多层级投入产出贸易网络，计算网络依赖性指标并进行回归分析。

Result: 发现上游和中间产品的依赖性差异显著，中国在低风险高影响力集群中占主导，而欧盟和美国在中游层级仍脆弱。高系统性贸易风险阻碍比较优势发展。

Conclusion: 战略依赖结构具有层级特异性，政策设计需超越原材料获取，直接解决中游加工和关键输入生产的国别瓶颈。

Abstract: Rare earth elements (REEs) are critical to a wide range of clean and
high-tech applications, yet global trade dependencies expose countries to
vulnerabilities across production networks. Here, we construct a multi-tiered
input-output trade network spanning 168 REE-related product codes from
2007-2023 using a novel AI-augmented statistical framework. We identify
significant differences between dependencies in upstream and intermediate
(input) products, revealing that exposure and supplier concentration are
systematically higher in input products, while systemic trade risk is lower,
suggesting localized vulnerabilities. By computing network-based dependency
indicators across countries and over time, we classify economies into five
distinct clusters that capture structural differences in rare-earth reliance.
China dominates the low-risk, high-influence cluster, while the EU and US
remain vulnerable at intermediate tiers. Regression analyses show that high
exposure across all products predicts future export strength, consistent with
import substitution. However, high systemic trade risk in input products like
magnets, advanced ceramics or phosphors, significantly impedes the development
of comparative advantage. These results demonstrate that the structure of
strategic dependencies is tier-specific, with critical implications for
industrial resilience and policy design. Effective mitigation strategies must
move beyond raw material access and directly address country-specific
chokepoints in midstream processing and critical input production.

</details>


### [212] [Generative AI in Higher Education: Evidence from an Elite College](https://arxiv.org/abs/2508.00717)
*Zara Contractor,Germán Reyes*

Main category: econ.GN

TL;DR: 超过80%的学生在ChatGPT发布后两年内学术使用AI，使用情况因学科、人口统计和成绩水平而异，AI可能重塑教育不平等。学生主要用于辅助学习，但也用于任务自动化。对AI教育益处的积极看法强烈预测使用率，政策可能影响使用模式但可能导致不均等影响。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI在高等教育中的学生采用情况及其对教育不平等的影响。

Method: 使用来自美国一所选择性学院的新调查数据。

Result: 超过80%的学生学术使用AI，使用模式因学科、人口统计和成绩水平不同。

Conclusion: AI在教育中的采用可能加剧不平等，政策需谨慎以避免不均等影响。

Abstract: Generative AI is transforming higher education, yet systematic evidence on
student adoption remains limited. Using novel survey data from a selective U.S.
college, we document over 80 percent of students using AI academically within
two years of ChatGPT's release. Adoption varies across disciplines,
demographics, and achievement levels, highlighting AI's potential to reshape
educational inequalities. Students predominantly use AI for augmenting learning
(e.g., explanations, feedback), but also to automate tasks (e.g., essay
generation). Positive perceptions of AI's educational benefits strongly predict
adoption. Institutional policies can influence usage patterns but risk creating
unintended disparate impacts across student groups due to uneven compliance.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [213] [A Tokenized Sovereign Debt Conversion Mechanism for Dynamic Public Debt Reduction](https://arxiv.org/abs/2508.00019)
*Kiarash Firouzi*

Main category: econ.TH

TL;DR: TSDCM是一种基于智能合约的工具，通过自动化转换主权债务为绩效挂钩代币，实现债务减少。


<details>
  <summary>Details</summary>
Motivation: 解决主权债务管理的可持续性问题，通过透明和激励一致的方式降低债务风险。

Method: 集成两状态制度转换跳跃扩散框架到去中心化协议中，通过数学证明和蒙特卡洛模拟验证。

Result: 十年内预期债务与GDP比率下降20-25%，尾部风险显著降低。

Conclusion: TSDCM为可持续主权债务管理提供了透明且激励一致的解决方案。

Abstract: In this paper, we present the Tokenized Sovereign Debt Conversion Mechanism
(TSDCM), a smart-contracted instrument that, upon meeting both debt-to-GDP and
GDP-growth thresholds, automates the retirement of sovereign debt. TSDCM
initiates the conversion of a portion of outstanding bonds into
performance-linked tokens by integrating a two-state regime-switching
jump-diffusion framework into decentralized protocols. We prove finite-time
activation and expected debt reduction through new propositions, establish the
existence and uniqueness of the underlying stochastic processes, and introduce
a main theorem that ensures a strict decline in expected debt levels. With
significant tail-risk mitigation, calibration using IMF data and MATLAB Monte
Carlo simulations shows a 20-25% decrease in expected debt-to-GDP ratios over a
ten-year period. A transparent and incentive-aligned route to sustainable
sovereign debt management is provided by TSDCM.

</details>


### [214] [A Keynesian Intertemporal Synthesis (KIS) Model: Towards a unified and empirically grounded framework for fiscal policy](https://arxiv.org/abs/2508.00224)
*Ricardo Alonzo Fernández Salguero*

Main category: econ.TH

TL;DR: 本文提出了一种新的凯恩斯跨期综合（KIS）模型，结合了后凯恩斯主义和新凯恩斯主义的优势，采用CES生产函数替代传统的Cobb-Douglas函数，以更符合实证数据。


<details>
  <summary>Details</summary>
Motivation: 传统Cobb-Douglas生产函数的单位替代弹性假设与实证不符，Gechert等人的研究明确否定了这一假设，因此需要更符合现实的模型框架。

Method: 采用CES生产函数，结合家庭异质性、非标准偏好和零利率下限约束，构建KIS-CES模型。

Result: 模型显示替代弹性σ<1时，收入分配和公共投资的挤入效应显著增强，生成非线性财政乘数，公共投资乘数高于消费乘数。

Conclusion: KIS-CES模型提供了一个统一、严谨且基于实证的理论框架，适用于危机时期的政策分析。

Abstract: This paper develops a new generation of the Keynesian Intertemporal Synthesis
(KIS) Model, a macroeconomic framework designed to reconcile the empirical
strengths of the Post-Keynesian (PK) and New Keynesian (NK) traditions. The
central innovation of this work is the abandonment of the traditional
Cobb-Douglas production function in favor of a Constant Elasticity of
Substitution (CES) specification. This modification is directly motivated by
the compelling evidence from the meta-analysis by Gechert et al. (2021), which
emphatically rejects the hypothesis of a unit elasticity of substitution
between capital and labor. We integrate this finding with the conclusions from
a wide range of meta-analyses on the state-dependent heterogeneity of fiscal
multipliers (Gechert and Rannenberg, 2018), the productivity of public capital
(Bom and Ligthart, 2014), the effectiveness hierarchy of spending instruments
(Gechert, 2015), and the empirical failure of Ricardian Equivalence (Stanley,
1998). The resulting KIS-CES model, while based on intertemporal optimization,
incorporates household heterogeneity, non-standard preferences that value
wealth and penalize debt, and a monetary policy constrained by the zero lower
bound. The mathematical derivations reveal that the elasticity of substitution,
calibrated to an empirically plausible value of $\sigma < 1$, becomes a key
parameter that modulates income distribution and magnifies the crowding-in
effect of public investment. The model generates an endogenous MPC, a nonlinear
fiscal multiplier that increases dramatically in crises, and a multiplier for
public investment that is structurally higher than that for consumption, thus
offering a unified, rigorous, and, above all, empirically disciplined
theoretical framework.

</details>


### [215] [Concentration and Markups in International Trade](https://arxiv.org/abs/2508.00345)
*Alviarez Vanessa,Fioretti Michele,Kikkawa Ken,Morlacco Monica*

Main category: econ.TH

TL;DR: 论文通过模型推导出进口投入品加价与集中度的关系，扩展了传统寡头理论，并分析了哥伦比亚进口数据。


<details>
  <summary>Details</summary>
Motivation: 研究企业间贸易中加价与集中度的关系，揭示寡头和寡买力量的平衡。

Method: 建立双边市场力量模型，推导加价与集中度的闭式表达式，并分析哥伦比亚进口数据。

Result: 加价随出口商集中度增加而上升，随进口商集中度增加而下降。

Conclusion: 新的集中度测量方法能更好理解国际贸易中的加价动态。

Abstract: This paper derives a closed-form expression linking aggregate markups on
imported inputs to concentration in a model of firm-to-firm trade with
two-sided market power. Our theory extends standard oligopoly insights in two
dimensions. First, it reveals that markups increase with exporter concentration
and decrease with importer concentration, reflecting the balance of oligopoly
and oligopsony forces. Second, it adapts conventional market definitions to
reflect rigid trading relationships, yielding new concentration measures that
capture competition in firm-to-firm trade. Analysis of Colombian
transaction-level import data shows these differences are key to understanding
markup dynamics in international trade.

</details>
