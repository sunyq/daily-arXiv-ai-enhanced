<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 28]
- [cs.CL](#cs.CL) [Total: 44]
- [cs.CV](#cs.CV) [Total: 98]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 12]
- [econ.GN](#econ.GN) [Total: 2]
- [econ.TH](#econ.TH) [Total: 2]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [InfiGUI-G1: Advancing GUI Grounding with Adaptive Exploration Policy Optimization](https://arxiv.org/abs/2508.05731)
*Yuhang Liu,Zeyu Liu,Shuanghe Zhu,Pengxiang Li,Congkai Xie,Jiasheng Wang,Xueyu Hu,Xiaotian Han,Jianbo Yuan,Xinyao Wang,Shengyu Zhang,Hongxia Yang,Fei Wu*

Main category: cs.AI

TL;DR: 论文提出了一种自适应探索策略优化（AEPO）框架，解决了多模态大语言模型（MLLMs）在GUI任务中语义对齐的探索瓶颈问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在GUI任务中面临语义对齐的挑战，现有方法（如RLVR）在空间对齐上表现良好，但语义对齐因探索效率低而受限。

Method: 提出AEPO框架，采用多答案生成策略和自适应探索奖励（AER）函数，基于效率原理（η=U/C）优化探索。

Result: AEPO训练的模型（InfiGUI-G1-3B和InfiGUI-G1-7B）在多个GUI基准测试中达到新SOTA，相对RLVR基线提升高达9.0%。

Conclusion: AEPO有效解决了语义对齐的探索问题，为GUI任务中的MLLMs提供了更优的解决方案。

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has propelled the
development of autonomous agents that operate on Graphical User Interfaces
(GUIs) using pure visual input. A fundamental challenge is robustly grounding
natural language instructions. This requires a precise spatial alignment, which
accurately locates the coordinates of each element, and, more critically, a
correct semantic alignment, which matches the instructions to the functionally
appropriate UI element. Although Reinforcement Learning with Verifiable Rewards
(RLVR) has proven to be effective at improving spatial alignment for these
MLLMs, we find that inefficient exploration bottlenecks semantic alignment,
which prevent models from learning difficult semantic associations. To address
this exploration problem, we present Adaptive Exploration Policy Optimization
(AEPO), a new policy optimization framework. AEPO employs a multi-answer
generation strategy to enforce broader exploration, which is then guided by a
theoretically grounded Adaptive Exploration Reward (AER) function derived from
first principles of efficiency eta=U/C. Our AEPO-trained models, InfiGUI-G1-3B
and InfiGUI-G1-7B, establish new state-of-the-art results across multiple
challenging GUI grounding benchmarks, achieving significant relative
improvements of up to 9.0% against the naive RLVR baseline on benchmarks
designed to test generalization and semantic understanding. Resources are
available at https://github.com/InfiXAI/InfiGUI-G1.

</details>


### [2] [A Framework for Inherently Safer AGI through Language-Mediated Active Inference](https://arxiv.org/abs/2508.05766)
*Bo Wen*

Main category: cs.AI

TL;DR: 提出一种结合主动推理与大型语言模型的新型框架，旨在开发安全的通用人工智能（AGI），强调将安全性融入系统核心设计。


<details>
  <summary>Details</summary>
Motivation: 传统AI安全方法（如事后可解释性和奖励工程）存在根本性局限，需将安全性内置于系统设计中。

Method: 通过透明信念表示和分层价值对齐，利用自然语言表示信念，实现多智能体系统的自组织，并采用分层马尔可夫毯传递偏好与安全约束。

Result: 提出具体安全机制，包括信念与偏好的自然语言分离、资源感知的自由能最小化以及模块化智能体结构的安全性。

Conclusion: 该框架为AGI开发提供了一条更安全的技术路径，未来将在ARC基准上进行实验验证。

Abstract: This paper proposes a novel framework for developing safe Artificial General
Intelligence (AGI) by combining Active Inference principles with Large Language
Models (LLMs). We argue that traditional approaches to AI safety, focused on
post-hoc interpretability and reward engineering, have fundamental limitations.
We present an architecture where safety guarantees are integrated into the
system's core design through transparent belief representations and
hierarchical value alignment. Our framework leverages natural language as a
medium for representing and manipulating beliefs, enabling direct human
oversight while maintaining computational tractability. The architecture
implements a multi-agent system where agents self-organize according to Active
Inference principles, with preferences and safety constraints flowing through
hierarchical Markov blankets. We outline specific mechanisms for ensuring
safety, including: (1) explicit separation of beliefs and preferences in
natural language, (2) bounded rationality through resource-aware free energy
minimization, and (3) compositional safety through modular agent structures.
The paper concludes with a research agenda centered on the Abstraction and
Reasoning Corpus (ARC) benchmark, proposing experiments to validate our
framework's safety properties. Our approach offers a path toward AGI
development that is inherently safer, rather than retrofitted with safety
measures.

</details>


### [3] [Whither symbols in the era of advanced neural networks?](https://arxiv.org/abs/2508.05776)
*Thomas L. Griffiths,Brenden M. Lake,R. Thomas McCoy,Ellie Pavlick,Taylor W. Webb*

Main category: cs.AI

TL;DR: 现代神经网络表现出类似人类思维的组合、创新和快速学习能力，削弱了人类思维基于符号系统的观点，但符号系统在定义抽象问题中仍起重要作用。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络是否具备类似人类思维的符号化能力，以及符号系统在人类思维中的作用。

Method: 通过分析现代神经网络的行为和能力，对比人类思维的符号化特征。

Result: 神经网络表现出类似符号系统的能力，但符号系统在定义抽象问题中仍不可或缺。

Conclusion: 提出研究人类思维符号基础的新议程，强调符号系统与神经网络的互补性。

Abstract: Some of the strongest evidence that human minds should be thought about in
terms of symbolic systems has been the way they combine ideas, produce novelty,
and learn quickly. We argue that modern neural networks -- and the artificial
intelligence systems built upon them -- exhibit similar abilities. This
undermines the argument that the cognitive processes and representations used
by human minds are symbolic, although the fact that these neural networks are
typically trained on data generated by symbolic systems illustrates that such
systems play an important role in characterizing the abstract problems that
human minds have to solve. This argument leads us to offer a new agenda for
research on the symbolic basis of human thought.

</details>


### [4] [Holistic Explainable AI (H-XAI): Extending Transparency Beyond Developers in AI-Driven Decision Making](https://arxiv.org/abs/2508.05792)
*Kausik Lakkaraju,Siva Likitha Valluru,Biplav Srivastava*

Main category: cs.AI

TL;DR: H-XAI是一个统一的框架，结合因果评分与传统XAI方法，支持交互式、多方法的解释过程，满足不同利益相关者的需求。


<details>
  <summary>Details</summary>
Motivation: 当前XAI方法主要服务于开发者，未能满足多样化利益相关者的需求。H-XAI旨在填补这一空白，提供更全面的解释工具。

Method: H-XAI整合因果评分与传统XAI方法，支持利益相关者提问、测试假设，并与随机和偏置基线比较模型行为。

Result: 通过两个案例研究（信用风险分类和金融时间序列预测）验证了H-XAI的通用性。

Conclusion: H-XAI填补了现有XAI方法的不足，结合因果评分和后验解释，满足利益相关者在个体决策和整体模型层面的需求。

Abstract: Current eXplainable AI (XAI) methods largely serve developers, often focusing
on justifying model outputs rather than supporting diverse stakeholder needs. A
recent shift toward Evaluative AI reframes explanation as a tool for hypothesis
testing, but still focuses primarily on operational organizations. We introduce
Holistic-XAI (H-XAI), a unified framework that integrates causal rating methods
with traditional XAI methods to support explanation as an interactive,
multi-method process. H-XAI allows stakeholders to ask a series of questions,
test hypotheses, and compare model behavior against automatically constructed
random and biased baselines. It combines instance-level and global
explanations, adapting to each stakeholder's goals, whether understanding
individual decisions, assessing group-level bias, or evaluating robustness
under perturbations. We demonstrate the generality of our approach through two
case studies spanning six scenarios: binary credit risk classification and
financial time-series forecasting. H-XAI fills critical gaps left by existing
XAI methods by combining causal ratings and post-hoc explanations to answer
stakeholder-specific questions at both the individual decision level and the
overall model level.

</details>


### [5] [Safety of Embodied Navigation: A Survey](https://arxiv.org/abs/2508.05855)
*Zixia Wang,Jia Hu,Ronghui Mu*

Main category: cs.AI

TL;DR: 本文综述了具身导航中的安全问题，分析了攻击策略、防御机制和评估方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和具身AI的发展，具身导航在关键应用中的安全问题日益突出，需确保系统在动态环境中的安全性。

Method: 通过全面分析现有安全挑战、缓解技术、数据集和评估指标，探讨未解决问题和未来方向。

Result: 总结了攻击方法、防御策略、评估技术及验证框架的需求，为未来研究提供指导。

Conclusion: 本文为开发更安全可靠的具身导航系统提供了见解，并对社会安全和工业效率有广泛影响。

Abstract: As large language models (LLMs) continue to advance and gain influence, the
development of embodied AI has accelerated, drawing significant attention,
particularly in navigation scenarios. Embodied navigation requires an agent to
perceive, interact with, and adapt to its environment while moving toward a
specified target in unfamiliar settings. However, the integration of embodied
navigation into critical applications raises substantial safety concerns. Given
their deployment in dynamic, real-world environments, ensuring the safety of
such systems is critical. This survey provides a comprehensive analysis of
safety in embodied navigation from multiple perspectives, encompassing attack
strategies, defense mechanisms, and evaluation methodologies. Beyond conducting
a comprehensive examination of existing safety challenges, mitigation
technologies, and various datasets and metrics that assess effectiveness and
robustness, we explore unresolved issues and future research directions in
embodied navigation safety. These include potential attack methods, mitigation
strategies, more reliable evaluation techniques, and the implementation of
verification frameworks. By addressing these critical gaps, this survey aims to
provide valuable insights that can guide future research toward the development
of safer and more reliable embodied navigation systems. Furthermore, the
findings of this study have broader implications for enhancing societal safety
and increasing industrial efficiency.

</details>


### [6] [Planning Agents on an Ego-Trip: Leveraging Hybrid Ego-Graph Ensembles for Improved Tool Retrieval in Enterprise Task Planning](https://arxiv.org/abs/2508.05888)
*Sahil Bansal,Sai Shruthi Sistla,Aarti Arikatala,Sebastian Schreiber*

Main category: cs.AI

TL;DR: 论文提出了一种基于知识图谱（KG）的工具检索框架，通过捕捉工具间的语义关系和功能依赖，显著提升了多步任务中的工具检索准确性。


<details>
  <summary>Details</summary>
Motivation: 传统工具检索方法主要依赖用户查询与工具描述的相似性，限制了多步请求的处理能力。本文旨在通过KG的结构信息弥补这一不足。

Method: 采用基于KG的检索框架，利用1-hop ego工具图的集成建模工具间的直接和间接连接，实现更全面的工具选择。

Result: 在合成数据集上，KG方法在Complete Recall指标上达到91.85%，优于非KG基线方法的89.26%。

Conclusion: KG的结构信息为相似性匹配提供了补充信号，特别适用于需要顺序工具组合的查询。

Abstract: Effective tool retrieval is essential for AI agents to select from a vast
array of tools when identifying and planning actions in the context of complex
user queries. Despite its central role in planning, this aspect remains
underexplored in the literature. Traditional approaches rely primarily on
similarities between user queries and tool descriptions, which significantly
limits retrieval accuracy, specifically when handling multi-step user requests.
To address these limitations, we propose a Knowledge Graph (KG)-based tool
retrieval framework that captures the semantic relationships between tools and
their functional dependencies. Our retrieval algorithm leverages ensembles of
1-hop ego tool graphs to model direct and indirect connections between tools,
enabling more comprehensive and contextual tool selection for multi-step tasks.
We evaluate our approach on a synthetically generated internal dataset across
six defined user classes, extending previous work on coherent dialogue
synthesis and too retrieval benchmarks. Results demonstrate that our tool
graph-based method achieves 91.85% tool coverage on the micro-average Complete
Recall metric, compared to 89.26% for re-ranked semantic-lexical hybrid
retrieval, the strongest non-KG baseline in our experiments. These findings
support our hypothesis that the structural information in the KG provides
complementary signals to pure similarity matching, particularly for queries
requiring sequential tool composition.

</details>


### [7] [Mediator-Guided Multi-Agent Collaboration among Open-Source Models for Medical Decision-Making](https://arxiv.org/abs/2508.05996)
*Kaitao Chen,Mianxin Liu,Daoming Zong,Chaoyue Ding,Shaohao Rui,Yankai Jiang,Mu Zhou,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出MedOrch框架，通过LLM中介协调多VLM专家代理，提升医疗多模态决策性能。


<details>
  <summary>Details</summary>
Motivation: 现有多代理研究多限于语言任务，多模态场景中VLM协作能力不足，需解决错误结果放大问题。

Method: 采用LLM中介代理协调多个VLM专家代理，实现输出交换与反思，避免直接组合VLM的缺陷。

Result: 在五个医疗视觉问答基准上验证，协作性能超越单个代理，无需额外训练。

Conclusion: 中介引导的多代理协作框架能有效提升医疗多模态智能，展示异构模型潜力。

Abstract: Complex medical decision-making involves cooperative workflows operated by
different clinicians. Designing AI multi-agent systems can expedite and augment
human-level clinical decision-making. Existing multi-agent researches primarily
focus on language-only tasks, yet their extension to multimodal scenarios
remains challenging. A blind combination of diverse vision-language models
(VLMs) can amplify an erroneous outcome interpretation. VLMs in general are
less capable in instruction following and importantly self-reflection, compared
to large language models (LLMs) of comparable sizes. This disparity largely
constrains VLMs' ability in cooperative workflows. In this study, we propose
MedOrch, a mediator-guided multi-agent collaboration framework for medical
multimodal decision-making. MedOrch employs an LLM-based mediator agent that
enables multiple VLM-based expert agents to exchange and reflect on their
outputs towards collaboration. We utilize multiple open-source general-purpose
and domain-specific VLMs instead of costly GPT-series models, revealing the
strength of heterogeneous models. We show that the collaboration within
distinct VLM-based agents can surpass the capabilities of any individual agent.
We validate our approach on five medical vision question answering benchmarks,
demonstrating superior collaboration performance without model training. Our
findings underscore the value of mediator-guided multi-agent collaboration in
advancing medical multimodal intelligence. Our code will be made publicly
available.

</details>


### [8] [Society of Mind Meets Real-Time Strategy: A Hierarchical Multi-Agent Framework for Strategic Reasoning](https://arxiv.org/abs/2508.06042)
*Daechul Ahn,San Kim,Jonghyun Choi*

Main category: cs.AI

TL;DR: 论文提出了一种分层多智能体框架HIMA，结合模仿学习和元控制器，解决了大型语言模型在动态长时任务（如《星际争霸II》）中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型在动态、长时任务（如实时战略游戏）中表现不佳，尤其是在资源管理和部分可观测环境下的适应性方面。

Method: 提出HIMA框架，通过专家示范训练多个专用模仿学习智能体，并由元控制器Strategic Planner协调生成适应性强的多步行动序列。

Result: HIMA在战略清晰性、适应性和计算效率上优于现有方法，并通过TEXTSCII-ALL测试平台验证。

Conclusion: 结合专用模仿模块与元级协调，可开发更鲁棒、通用的AI智能体。

Abstract: Large Language Models (LLMs) have recently demonstrated impressive action
sequence prediction capabilities but often struggle with dynamic, long-horizon
tasks such as real-time strategic games. In a game such as StarCraftII (SC2),
agents need to manage resource constraints and adapt to evolving battlefield
situations in a partially observable environment. This often overwhelms
exisiting LLM-based approaches. To address these challenges, we propose a
hierarchical multi-agent framework that employs specialized imitation learning
agents under a meta-controller called Strategic Planner (SP). By expert
demonstrations, each specialized agent learns a distinctive strategy, such as
aerial support or defensive maneuvers, and produces coherent, structured
multistep action sequences. The SP then orchestrates these proposals into a
single, environmentally adaptive plan that ensures local decisions aligning
with long-term strategies. We call this HIMA (Hierarchical Imitation
Multi-Agent). We also present TEXTSCII-ALL, a comprehensive SC2 testbed that
encompasses all race match combinations in SC2. Our empirical results show that
HIMA outperforms state of the arts in strategic clarity, adaptability, and
computational efficiency, underscoring the potential of combining specialized
imitation modules with meta-level orchestration to develop more robust,
general-purpose AI agents.

</details>


### [9] [LLMs for Resource Allocation: A Participatory Budgeting Approach to Inferring Preferences](https://arxiv.org/abs/2508.06060)
*Sankarshan Damle,Boi Faltings*

Main category: cs.AI

TL;DR: 论文提出了一个双用途框架，利用参与式预算（PB）作为LLM资源分配的实践场景和评估其推理能力的动态基准。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在结构化资源分配中的能力，并解决现有基准的静态性和数据污染问题。

Method: 采用三种提示策略（贪婪选择、直接优化和启发式改进）让LLM在预算约束下选择项目子集，并对比效用最大化基准。

Result: 结果表明提示设计对LLM性能至关重要，且LLM在无结构输入机制设计中具有潜力。

Conclusion: LLM在资源分配和偏好推断方面表现出潜力，提示设计是关键因素。

Abstract: Large Language Models (LLMs) are increasingly expected to handle complex
decision-making tasks, yet their ability to perform structured resource
allocation remains underexplored. Evaluating their reasoning is also difficult
due to data contamination and the static nature of existing benchmarks. We
present a dual-purpose framework leveraging Participatory Budgeting (PB) both
as (i) a practical setting for LLM-based resource allocation and (ii) an
adaptive benchmark for evaluating their reasoning capabilities. We task LLMs
with selecting project subsets under feasibility (e.g., budget) constraints via
three prompting strategies: greedy selection, direct optimization, and a
hill-climbing-inspired refinement. We benchmark LLMs' allocations against a
utility-maximizing oracle. Interestingly, we also test whether LLMs can infer
structured preferences from natural-language voter input or metadata, without
explicit votes. By comparing allocations based on inferred preferences to those
from ground-truth votes, we evaluate LLMs' ability to extract preferences from
open-ended input. Our results underscore the role of prompt design and show
that LLMs hold promise for mechanism design with unstructured inputs.

</details>


### [10] [Don't Forget Imagination!](https://arxiv.org/abs/2508.06062)
*Evgenii E. Vityaev,Andrei Mantsivoda*

Main category: cs.AI

TL;DR: 论文呼吁重视认知想象在人工智能中的关键作用，并提出语义模型作为模拟认知想象的新方法。


<details>
  <summary>Details</summary>
Motivation: 认知想象在人类思维中扮演重要角色，但目前AI领域对其重视不足，导致推理和决策能力受限。

Method: 提出语义模型，一种基于概率因果关系的数学模型，能够学习和确保想象上下文的连贯性。

Result: 语义模型能够模拟认知想象，支持连贯的推理和决策。

Conclusion: 认知想象是AI发展的潜在突破口，语义模型为实现这一目标提供了可行工具。

Abstract: Cognitive imagination is a type of imagination that plays a key role in human
thinking. It is not a ``picture-in-the-head'' imagination. It is a faculty to
mentally visualize coherent and holistic systems of concepts and causal links
that serve as semantic contexts for reasoning, decision making and prediction.
Our position is that the role of cognitive imagination is still greatly
underestimated, and this creates numerous problems and diminishes the current
capabilities of AI. For instance, when reasoning, humans rely on imaginary
contexts to retrieve background info. They also constantly return to the
context for semantic verification that their reasoning is still reasonable.
Thus, reasoning without imagination is blind. This paper is a call for greater
attention to cognitive imagination as the next promising breakthrough in
artificial intelligence. As an instrument for simulating cognitive imagination,
we propose semantic models -- a new approach to mathematical models that can
learn, like neural networks, and are based on probabilistic causal
relationships. Semantic models can simulate cognitive imagination because they
ensure the consistency of imaginary contexts and implement a glass-box approach
that allows the context to be manipulated as a holistic and coherent system of
interrelated facts glued together with causal relations.

</details>


### [11] [A Generic Complete Anytime Beam Search for Optimal Decision Tree](https://arxiv.org/abs/2508.06064)
*Harold Silvère Kiossou,Siegfried Nijssen,Pierre Schaus*

Main category: cs.AI

TL;DR: CA-DL8.5是一种通用的、完整的、随时可用的波束搜索算法，扩展了DL8.5框架，统一了现有的一些随时策略。它在标准分类基准上表现优异，尤其是基于LDS的变体。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法在未完成搜索时难以快速找到高质量的决策树，且缺乏系统比较，因此需要一种更灵活和高效的随时算法。

Method: CA-DL8.5结合了DL8.5的高效剪枝和缓存机制，通过模块化设计整合多种启发式和松弛机制，采用基于重启的波束搜索逐步放宽剪枝标准。

Result: 实验表明，基于LDS的CA-DL8.5变体在随时性能上优于其他变体和Blossom算法，同时保持完整性和最优性。

Conclusion: CA-DL8.5提供了一个通用的框架，支持多样化的启发式和搜索策略，显著提升了决策树学习的随时性能。

Abstract: Finding an optimal decision tree that minimizes classification error is known
to be NP-hard. While exact algorithms based on MILP, CP, SAT, or dynamic
programming guarantee optimality, they often suffer from poor anytime behavior
-- meaning they struggle to find high-quality decision trees quickly when the
search is stopped before completion -- due to unbalanced search space
exploration. To address this, several anytime extensions of exact methods have
been proposed, such as LDS-DL8.5, Top-k-DL8.5, and Blossom, but they have not
been systematically compared, making it difficult to assess their relative
effectiveness. In this paper, we propose CA-DL8.5, a generic, complete, and
anytime beam search algorithm that extends the DL8.5 framework and unifies some
existing anytime strategies. In particular, CA-DL8.5 generalizes previous
approaches LDS-DL8.5 and Top-k-DL8.5, by allowing the integration of various
heuristics and relaxation mechanisms through a modular design. The algorithm
reuses DL8.5's efficient branch-and-bound pruning and trie-based caching,
combined with a restart-based beam search that gradually relaxes pruning
criteria to improve solution quality over time. Our contributions are twofold:
(1) We introduce this new generic framework for exact and anytime decision tree
learning, enabling the incorporation of diverse heuristics and search
strategies; (2) We conduct a rigorous empirical comparison of several
instantiations of CA-DL8.5 -- based on Purity, Gain, Discrepancy, and Top-k
heuristics -- using an anytime evaluation metric called the primal gap
integral. Experimental results on standard classification benchmarks show that
CA-DL8.5 using LDS (limited discrepancy) consistently provides the best anytime
performance, outperforming both other CA-DL8.5 variants and the Blossom
algorithm while maintaining completeness and optimality guarantees.

</details>


### [12] [ME$^3$-BEV: Mamba-Enhanced Deep Reinforcement Learning for End-to-End Autonomous Driving with BEV-Perception](https://arxiv.org/abs/2508.06074)
*Siyi Lu,Run Liu,Dongsheng Yang,Lei He*

Main category: cs.AI

TL;DR: 本文提出了一种基于深度强化学习（DRL）和鸟瞰图（BEV）感知的自动驾驶新方法，通过结合高效的时空特征提取网络（Mamba-BEV）和端到端DRL框架（ME³-BEV），在动态城市驾驶场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统模块化方法存在误差传播和协调问题，而端到端学习系统面临计算瓶颈。本文旨在通过结合BEV感知和DRL，提升自动驾驶系统的实时决策能力。

Method: 提出Mamba-BEV模型，用于高效时空特征提取，并结合BEV感知和Mamba框架建模长程依赖关系。进一步提出ME³-BEV框架，将Mamba-BEV作为特征输入用于端到端DRL。

Result: 在CARLA模拟器上的实验表明，ME³-BEV在碰撞率和轨迹精度等多项指标上优于现有模型。

Conclusion: ME³-BEV为实时自动驾驶提供了一种高效且可解释的解决方案。

Abstract: Autonomous driving systems face significant challenges in perceiving complex
environments and making real-time decisions. Traditional modular approaches,
while offering interpretability, suffer from error propagation and coordination
issues, whereas end-to-end learning systems can simplify the design but face
computational bottlenecks. This paper presents a novel approach to autonomous
driving using deep reinforcement learning (DRL) that integrates bird's-eye view
(BEV) perception for enhanced real-time decision-making. We introduce the
\texttt{Mamba-BEV} model, an efficient spatio-temporal feature extraction
network that combines BEV-based perception with the Mamba framework for
temporal feature modeling. This integration allows the system to encode vehicle
surroundings and road features in a unified coordinate system and accurately
model long-range dependencies. Building on this, we propose the
\texttt{ME$^3$-BEV} framework, which utilizes the \texttt{Mamba-BEV} model as a
feature input for end-to-end DRL, achieving superior performance in dynamic
urban driving scenarios. We further enhance the interpretability of the model
by visualizing high-dimensional features through semantic segmentation,
providing insight into the learned representations. Extensive experiments on
the CARLA simulator demonstrate that \texttt{ME$^3$-BEV} outperforms existing
models across multiple metrics, including collision rate and trajectory
accuracy, offering a promising solution for real-time autonomous driving.

</details>


### [13] [Aggregate-Combine-Readout GNNs Are More Expressive Than Logic C2](https://arxiv.org/abs/2508.06091)
*Stan P Hauke,Przemysław Andrzej Wałęga*

Main category: cs.AI

TL;DR: 本文解决了关于图神经网络（GNNs）逻辑表达能力的一个开放性问题，证明其严格超过C2逻辑。


<details>
  <summary>Details</summary>
Motivation: 研究GNNs的逻辑表达能力，解决Barceló等人提出的开放性问题。

Method: 通过理论分析，比较GNNs与C2逻辑的表达能力。

Result: 证明GNNs的逻辑表达能力严格超过C2逻辑，适用于无向和有向图。

Conclusion: 该研究不仅对GNNs有重要意义，还为无穷逻辑的表达能力提供了新见解。

Abstract: In recent years, there has been growing interest in understanding the
expressive power of graph neural networks (GNNs) by relating them to logical
languages. This research has been been initialised by an influential result of
Barcel\'o et al. (2020), who showed that the graded modal logic (or a guarded
fragment of the logic C2), characterises the logical expressiveness of
aggregate-combine GNNs. As a ``challenging open problem'' they left the
question whether full C2 characterises the logical expressiveness of
aggregate-combine-readout GNNs. This question has remained unresolved despite
several attempts. In this paper, we solve the above open problem by proving
that the logical expressiveness of aggregate-combine-readout GNNs strictly
exceeds that of C2. This result holds over both undirected and directed graphs.
Beyond its implications for GNNs, our work also leads to purely logical
insights on the expressive power of infinitary logics.

</details>


### [14] [PanelTR: Zero-Shot Table Reasoning Framework Through Multi-Agent Scientific Discussion](https://arxiv.org/abs/2508.06110)
*Yiran Rex Ma*

Main category: cs.AI

TL;DR: PanelTR框架通过LLM代理科学家实现表格推理，无需依赖标注数据或复杂增强，性能优于普通LLM并接近监督模型。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理任务中依赖标注数据和复杂增强的局限性，以及LLM在此类任务中表现不佳的问题。

Method: PanelTR采用LLM代理科学家，通过个体研究、自审和协作同行评审的结构化科学方法进行推理。

Result: 在四个基准测试中，PanelTR优于普通LLM，接近完全监督模型，且无需训练数据。

Conclusion: 结构化科学方法能在零样本情境下灵活处理复杂任务，具有广泛适用性。

Abstract: Table reasoning, including tabular QA and fact verification, often depends on
annotated data or complex data augmentation, limiting flexibility and
generalization. LLMs, despite their versatility, often underperform compared to
simple supervised models. To approach these issues, we introduce PanelTR, a
framework utilizing LLM agent scientists for robust table reasoning through a
structured scientific approach. PanelTR's workflow involves agent scientists
conducting individual investigations, engaging in self-review, and
participating in collaborative peer-review discussions. This process, driven by
five scientist personas, enables semantic-level transfer without relying on
data augmentation or parametric optimization. Experiments across four
benchmarks show that PanelTR outperforms vanilla LLMs and rivals fully
supervised models, all while remaining independent of training data. Our
findings indicate that structured scientific methodology can effectively handle
complex tasks beyond table reasoning with flexible semantic understanding in a
zero-shot context.

</details>


### [15] [SKATE, a Scalable Tournament Eval: Weaker LLMs differentiate between stronger ones using verifiable challenges](https://arxiv.org/abs/2508.06111)
*Dewi S. W. Gould,Bruno Mlodozeniec,Samuel F. Brown*

Main category: cs.AI

TL;DR: SKATE是一个新型评估框架，通过让大语言模型相互生成和解决可验证任务来评估其能力，具有自动化、可扩展和客观的特点。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法需要大量领域专业知识，难以随着模型快速发展而扩展。

Method: SKATE框架将评估视为游戏，模型同时作为任务生成者和解决者，通过生成可验证任务进行竞争。

Result: 实验证明，较弱模型能可靠区分并评分较强模型，模型能生成符合自身能力的问题，SKATE能自动揭示模型间的细粒度能力差异。

Conclusion: SKATE为通用、可扩展的评估框架提供了重要进展，能够跟上大语言模型的发展步伐。

Abstract: Evaluating the capabilities and risks of foundation models is paramount, yet
current methods demand extensive domain expertise, hindering their scalability
as these models rapidly evolve. We introduce SKATE: a novel evaluation
framework in which large language models (LLMs) compete by generating and
solving verifiable tasks for one another. Our core insight is to treat
evaluation as a game: models act as both task-setters and solvers, incentivized
to create questions which highlight their own strengths while exposing others'
weaknesses. SKATE offers several key advantages, balancing scalability,
open-endedness, and objectivity. It is fully automated, data-free, and
scalable, requiring no human input or domain expertise. By using verifiable
tasks rather than LLM judges, scoring is objective. Unlike domain-limited
programmatically-generated benchmarks (e.g. chess-playing or spatial
reasoning), having LLMs creatively pose challenges enables open-ended and
scalable evaluation. As a proof of concept, we introduce LLM-set
code-output-prediction (COP) challenges as a verifiable and extensible
framework in which to test our approach. Using a TrueSkill-based ranking
system, we evaluate six frontier LLMs and find that: (1) weaker models can
reliably differentiate and score stronger ones, (2) LLM-based systems are
capable of self-preferencing behavior, generating questions that align with
their own capabilities, and (3) SKATE automatically surfaces fine-grained
capability differences between models. Our findings are an important step
towards general, scalable evaluation frameworks which can keep pace with LLM
progress.

</details>


### [16] [Study of Robust Features in Formulating Guidance for Heuristic Algorithms for Solving the Vehicle Routing Problem](https://arxiv.org/abs/2508.06129)
*Bachtiar Herdianto,Romain Billot,Flavien Lucas,Marc Sevaux*

Main category: cs.AI

TL;DR: 该论文探讨了如何利用机器学习和可解释AI改进车辆路径问题（VRP）的元启发式算法设计，通过敏感性分析揭示了特征重要性对解决方案质量的影响。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式算法依赖人工设计，而机器学习可以捕捉组合优化中的结构特征，从而提升算法效率。

Method: 使用多种分类器模型进行敏感性分析，预测VRP解决方案质量，并利用可解释AI理解模型决策过程。

Result: 研究发现某些特征始终是强预测因子，并提出了一个统一框架来排名特征影响。

Conclusion: 特征重要性分析为开发VRP元启发式算法的指导机制提供了潜在基础。

Abstract: The Vehicle Routing Problem (VRP) is a complex optimization problem with
numerous real-world applications, mostly solved using metaheuristic algorithms
due to its $\mathcal{NP}$-Hard nature. Traditionally, these metaheuristics rely
on human-crafted designs developed through empirical studies. However, recent
research shows that machine learning methods can be used the structural
characteristics of solutions in combinatorial optimization, thereby aiding in
designing more efficient algorithms, particularly for solving VRP. Building on
this advancement, this study extends the previous research by conducting a
sensitivity analysis using multiple classifier models that are capable of
predicting the quality of VRP solutions. Hence, by leveraging explainable AI,
this research is able to extend the understanding of how these models make
decisions. Finally, our findings indicate that while feature importance varies,
certain features consistently emerge as strong predictors. Furthermore, we
propose a unified framework able of ranking feature impact across different
scenarios to illustrate this finding. These insights highlight the potential of
feature importance analysis as a foundation for developing a guidance mechanism
of metaheuristic algorithms for solving the VRP.

</details>


### [17] [Retrieval Augmented Large Language Model System for Comprehensive Drug Contraindications](https://arxiv.org/abs/2508.06145)
*Byeonghun Bang,Jongsuk Yoon,Dong-Jin Chang,Seho Park,Yong Oh Lee*

Main category: cs.AI

TL;DR: 该研究通过引入检索增强生成（RAG）框架，显著提升了大型语言模型（LLMs）在药物禁忌领域的准确性，减少了处方决策中的不确定性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在医疗保健领域的应用，特别是在药物禁忌方面，需要高准确性和可靠信息。

Method: 使用OpenAI的GPT-4o-mini作为基础模型，结合text-embedding-3-small模型和Langchain，构建混合检索系统，并利用公共数据库中的药物使用审查（DUR）数据。

Result: RAG框架显著提升了模型在年龄组、妊娠和联合用药禁忌方面的准确性，分别达到0.94、0.87和0.89。

Conclusion: RAG框架可以有效增强LLMs在药物禁忌领域的表现，为处方决策提供更精确的信息。

Abstract: The versatility of large language models (LLMs) has been explored across
various sectors, but their application in healthcare poses challenges,
particularly in the domain of pharmaceutical contraindications where accurate
and reliable information is required. This study enhances the capability of
LLMs to address contraindications effectively by implementing a Retrieval
Augmented Generation (RAG) pipeline. Utilizing OpenAI's GPT-4o-mini as the base
model, and the text-embedding-3-small model for embeddings, our approach
integrates Langchain to orchestrate a hybrid retrieval system with re-ranking.
This system leverages Drug Utilization Review (DUR) data from public databases,
focusing on contraindications for specific age groups, pregnancy, and
concomitant drug use. The dataset includes 300 question-answer pairs across
three categories, with baseline model accuracy ranging from 0.49 to 0.57.
Post-integration of the RAG pipeline, we observed a significant improvement in
model accuracy, achieving rates of 0.94, 0.87, and 0.89 for contraindications
related to age groups, pregnancy, and concomitant drug use, respectively. The
results indicate that augmenting LLMs with a RAG framework can substantially
reduce uncertainty in prescription and drug intake decisions by providing more
precise and reliable drug contraindication information.

</details>


### [18] [Overconfidence in LLM-as-a-Judge: Diagnosis and Confidence-Driven Solution](https://arxiv.org/abs/2508.06225)
*Zailong Tian,Zhuoheng Han,Yanzhe Chen,Haozhe Xu,Xi Yang,richeng xuan,Hongfeng Wang,Lizi Liao*

Main category: cs.AI

TL;DR: 论文提出从以准确性为中心的评估转向以置信度驱动的风险感知LLM评估系统，强调校准置信度的重要性，并提出新指标TH-Score和框架LLM-as-a-Fuser以提升可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM作为自动评估工具时过于关注准确性，忽视了置信度校准的重要性，导致实际部署中可靠性不足。

Method: 提出TH-Score量化置信度与准确性的对齐，并设计LLM-as-a-Fuser框架，通过集成方法提升评估的可靠性和风险感知能力。

Result: 实验表明，该方法显著改善了置信度校准，实现了自适应评估，并在可靠性和准确性上优于现有基线。

Conclusion: 置信度驱动的风险感知评估系统能显著提升LLM作为评估工具的可靠性和实用性。

Abstract: Large Language Models (LLMs) are widely used as automated judges, where
practical value depends on both accuracy and trustworthy, risk-aware judgments.
Existing approaches predominantly focus on accuracy, overlooking the necessity
of well-calibrated confidence, which is vital for adaptive and reliable
evaluation pipelines. In this work, we advocate a shift from accuracy-centric
evaluation to confidence-driven, risk-aware LLM-as-a-Judge systems, emphasizing
the necessity of well-calibrated confidence for trustworthy and adaptive
evaluation. We systematically identify the **Overconfidence Phenomenon** in
current LLM-as-a-Judges, where predicted confidence significantly overstates
actual correctness, undermining reliability in practical deployment. To
quantify this phenomenon, we introduce **TH-Score**, a novel metric measuring
confidence-accuracy alignment. Furthermore, we propose **LLM-as-a-Fuser**, an
ensemble framework that transforms LLMs into reliable, risk-aware evaluators.
Extensive experiments demonstrate that our approach substantially improves
calibration and enables adaptive, confidence-driven evaluation pipelines,
achieving superior reliability and accuracy compared to existing baselines.

</details>


### [19] [GeoLaux: A Benchmark for Evaluating MLLMs' Geometry Performance on Long-Step Problems Requiring Auxiliary Lines](https://arxiv.org/abs/2508.06226)
*Yumeng Fu,Jiayin Zhu,Lingling Zhang,Bo Zhao,Shaoxuan Ma,Yushun Zhang,Yanrui Wu,Wenjun Wu*

Main category: cs.AI

TL;DR: GeoLaux基准测试填补了现有评估MLLMs几何技能时忽略辅助线构造和过程细粒度评估的空白，包含2,186个几何问题，设计了五维评估策略，并揭示了MLLMs在长步推理中的性能下降、走捷径倾向及缺乏辅助线意识等问题。


<details>
  <summary>Details</summary>
Motivation: 现有评估MLLMs几何技能的基准测试忽略了辅助线构造和过程细粒度评估，无法全面评估长步推理能力。

Method: 提出GeoLaux基准测试，包含2,186个几何问题，设计五维评估策略（答案正确性、过程正确性、过程质量、辅助线影响、错误原因）。

Result: 实验发现MLLMs在长步推理中性能显著下降，倾向于走捷径，且缺乏辅助线意识。

Conclusion: GeoLaux可作为评估MLLMs长步几何推理能力的基准，并为能力提升提供指导。

Abstract: Geometry problem solving (GPS) requires models to master diagram
comprehension, logical reasoning, knowledge application, numerical computation,
and auxiliary line construction. This presents a significant challenge for
Multimodal Large Language Models (MLLMs). However, existing benchmarks for
evaluating MLLM geometry skills overlook auxiliary line construction and lack
fine-grained process evaluation, making them insufficient for assessing MLLMs'
long-step reasoning abilities. To bridge these gaps, we present the GeoLaux
benchmark, comprising 2,186 geometry problems, incorporating both calculation
and proving questions. Notably, the problems require an average of 6.51
reasoning steps, with a maximum of 24 steps, and 41.8% of them need auxiliary
line construction. Building on the dataset, we design a novel five-dimensional
evaluation strategy assessing answer correctness, process correctness, process
quality, auxiliary line impact, and error causes. Extensive experiments on 13
leading MLLMs (including thinking models and non-thinking models) yield three
pivotal findings: First, models exhibit substantial performance degradation in
extended reasoning steps (nine models demonstrate over 50% performance drop).
Second, compared to calculation problems, MLLMs tend to take shortcuts when
solving proving problems. Third, models lack auxiliary line awareness, and
enhancing this capability proves particularly beneficial for overall geometry
reasoning improvement. These findings establish GeoLaux as both a benchmark for
evaluating MLLMs' long-step geometric reasoning with auxiliary lines and a
guide for capability advancement. Our dataset and code are included in
supplementary materials and will be released.

</details>


### [20] [Learning Logical Rules using Minimum Message Length](https://arxiv.org/abs/2508.06230)
*Ruben Sharma,Sebastijan Dumančić,Ross D. King,Andrew Cropper*

Main category: cs.AI

TL;DR: 提出了一种贝叶斯归纳逻辑编程方法，通过平衡假设复杂性和数据拟合，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 统一概率和逻辑学习是AI的关键挑战。

Method: 使用贝叶斯归纳逻辑编程，通过先验和似然平衡假设复杂性和数据拟合。

Result: 在多个领域（如游戏和药物设计）中显著优于现有方法，且数据高效、对示例平衡不敏感。

Conclusion: 该方法在统一概率和逻辑学习方面表现出色，具有广泛适用性。

Abstract: Unifying probabilistic and logical learning is a key challenge in AI. We
introduce a Bayesian inductive logic programming approach that learns minimum
message length programs from noisy data. Our approach balances hypothesis
complexity and data fit through priors, which explicitly favour more general
programs, and a likelihood that favours accurate programs. Our experiments on
several domains, including game playing and drug design, show that our method
significantly outperforms previous methods, notably those that learn minimum
description length programs. Our results also show that our approach is
data-efficient and insensitive to example balance, including the ability to
learn from exclusively positive examples.

</details>


### [21] [Symmetry breaking for inductive logic programming](https://arxiv.org/abs/2508.06263)
*Andrew Cropper,David M. Cerna,Matti Järvisalo*

Main category: cs.AI

TL;DR: 提出了一种消除假设空间对称性的方法，显著提高了归纳逻辑编程的效率。


<details>
  <summary>Details</summary>
Motivation: 解决归纳逻辑编程中假设空间庞大且存在大量逻辑等价假设的挑战。

Method: 在答案集编程中实现对称性消除方法。

Result: 实验表明，该方法将求解时间从超过一小时缩短至17秒。

Conclusion: 该方法在视觉推理和游戏等多个领域表现出高效性。

Abstract: The goal of inductive logic programming is to search for a hypothesis that
generalises training data and background knowledge. The challenge is searching
vast hypothesis spaces, which is exacerbated because many logically equivalent
hypotheses exist. To address this challenge, we introduce a method to break
symmetries in the hypothesis space. We implement our idea in answer set
programming. Our experiments on multiple domains, including visual reasoning
and game playing, show that our approach can reduce solving times from over an
hour to just 17 seconds.

</details>


### [22] [LLM Robustness Leaderboard v1 --Technical report](https://arxiv.org/abs/2508.06296)
*Pierre Peigné - Lefebvre,Quentin Feuillade-Montixi,Tom David,Nicolas Miailhe*

Main category: cs.AI

TL;DR: PRISM Eval的BET工具通过动态对抗优化实现了对41个先进LLM中37个的100%攻击成功率，并提出细粒度鲁棒性指标和原始级漏洞分析。


<details>
  <summary>Details</summary>
Motivation: 评估和提升大型语言模型（LLM）的鲁棒性，揭示其漏洞以促进社区协作评估。

Method: 使用PRISM Eval Behavior Elicitation Tool（BET）进行自动化红队测试，采用动态对抗优化方法。

Result: 对37/41的LLM实现100%攻击成功率，发现攻击难度差异达300倍以上。

Conclusion: BET工具和细粒度指标为分布式鲁棒性评估提供了实用路径。

Abstract: This technical report accompanies the LLM robustness leaderboard published by
PRISM Eval for the Paris AI Action Summit. We introduce PRISM Eval Behavior
Elicitation Tool (BET), an AI system performing automated red-teaming through
Dynamic Adversarial Optimization that achieves 100% Attack Success Rate (ASR)
against 37 of 41 state-of-the-art LLMs. Beyond binary success metrics, we
propose a fine-grained robustness metric estimating the average number of
attempts required to elicit harmful behaviors, revealing that attack difficulty
varies by over 300-fold across models despite universal vulnerability. We
introduce primitive-level vulnerability analysis to identify which jailbreaking
techniques are most effective for specific hazard categories. Our collaborative
evaluation with trusted third parties from the AI Safety Network demonstrates
practical pathways for distributed robustness assessment across the community.

</details>


### [23] [A "good regulator theorem" for embodied agents](https://arxiv.org/abs/2508.06326)
*Nathaniel Virgo,Martin Biehl,Manuel Baltieri,Matteo Capucci*

Main category: cs.AI

TL;DR: 论文探讨了Conant和Ashby的“每个好的系统调节器必须是该系统的模型”定理的局限性，并提出了一种更广义的“信念更新”模型概念，强调观察者在模型定义中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决Conant和Ashby定理在人工生命等领域中的局限性，探索更广泛的系统调节模型。

Method: 通过引入“信念更新”的概念，将观察者的视角纳入模型定义，提出了一种新的理论框架。

Result: 结果表明，无论系统如何调节环境或内部状态，都可以从外部观察者的角度解释其行为为“模型”。

Conclusion: 结论指出，模型的定义需要观察者的参与，且这种广义模型可以解释传统定理无法涵盖的案例。

Abstract: In a classic paper, Conant and Ashby claimed that "every good regulator of a
system must be a model of that system." Artificial Life has produced many
examples of systems that perform tasks with apparently no model in sight; these
suggest Conant and Ashby's theorem doesn't easily generalise beyond its
restricted setup. Nevertheless, here we show that a similar intuition can be
fleshed out in a different way: whenever an agent is able to perform a
regulation task, it is possible for an observer to interpret it as having
"beliefs" about its environment, which it "updates" in response to sensory
input. This notion of belief updating provides a notion of model that is more
sophisticated than Conant and Ashby's, as well as a theorem that is more
broadly applicable. However, it necessitates a change in perspective, in that
the observer plays an essential role in the theory: models are not a mere
property of the system but are imposed on it from outside. Our theorem holds
regardless of whether the system is regulating its environment in a classic
control theory setup, or whether it's regulating its own internal state; the
model is of its environment either way. The model might be trivial, however,
and this is how the apparent counterexamples are resolved.

</details>


### [24] [AntiCheatPT: A Transformer-Based Approach to Cheat Detection in Competitive Computer Games](https://arxiv.org/abs/2508.06348)
*Mille Mei Zhen Loo,Gert Luzkov,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出了一种基于Transformer的机器学习模型AntiCheatPT_256，用于检测《CS2》中的作弊行为，并公开了标注数据集CS2CD。模型在未增强测试集上准确率达89.17%，AUC为93.36%。


<details>
  <summary>Details</summary>
Motivation: 在线游戏中的作弊行为破坏了游戏体验，现有反作弊系统难以在不侵犯用户隐私的情况下应对不断演变的作弊手段。

Method: 使用Transformer模型分析游戏数据，并引入公开数据集CS2CD（795场比赛），生成90,707个上下文窗口并进行数据增强以解决类别不平衡问题。

Result: 模型在未增强测试集上达到89.17%的准确率和93.36%的AUC。

Conclusion: 该方法具有可重复性和实际应用价值，为数据驱动的作弊检测研究提供了坚实基础。

Abstract: Cheating in online video games compromises the integrity of gaming
experiences. Anti-cheat systems, such as VAC (Valve Anti-Cheat), face
significant challenges in keeping pace with evolving cheating methods without
imposing invasive measures on users' systems. This paper presents
AntiCheatPT\_256, a transformer-based machine learning model designed to detect
cheating behaviour in Counter-Strike 2 using gameplay data. To support this, we
introduce and publicly release CS2CD: A labelled dataset of 795 matches. Using
this dataset, 90,707 context windows were created and subsequently augmented to
address class imbalance. The transformer model, trained on these windows,
achieved an accuracy of 89.17\% and an AUC of 93.36\% on an unaugmented test
set. This approach emphasizes reproducibility and real-world applicability,
offering a robust baseline for future research in data-driven cheat detection.

</details>


### [25] [From Explainable to Explanatory Artificial Intelligence: Toward a New Paradigm for Human-Centered Explanations through Generative AI](https://arxiv.org/abs/2508.06352)
*Christian Meske,Justin Brenne,Erdi Uenal,Sabahat Oelcer,Ayseguel Doganguen*

Main category: cs.AI

TL;DR: 论文提出“解释性AI”作为可解释AI（XAI）的补充范式，通过生成式AI能力提供情境化、个性化的解释，而非仅关注算法透明度。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法过于抽象且非自适应，难以支持用户理解。需要一种更注重人类决策支持的AI解释方式。

Method: 提出八维概念模型，结合叙事沟通、自适应个性化和渐进披露原则，并通过医疗领域的实证验证。

Result: 用户更偏好情境敏感的多模态解释，而非技术透明度。

Conclusion: 需设计以人类理解为中心的AI解释系统，并推动跨领域和文化的研究议程。

Abstract: Current explainable AI (XAI) approaches prioritize algorithmic transparency
and present explanations in abstract, non-adaptive formats that often fail to
support meaningful end-user understanding. This paper introduces "Explanatory
AI" as a complementary paradigm that leverages generative AI capabilities to
serve as explanatory partners for human understanding rather than providers of
algorithmic transparency. While XAI reveals algorithmic decision processes for
model validation, Explanatory AI addresses contextual reasoning to support
human decision-making in sociotechnical contexts. We develop a definition and
systematic eight-dimensional conceptual model distinguishing Explanatory AI
through narrative communication, adaptive personalization, and progressive
disclosure principles. Empirical validation through Rapid Contextual Design
methodology with healthcare professionals demonstrates that users consistently
prefer context-sensitive, multimodal explanations over technical transparency.
Our findings reveal the practical urgency for AI systems designed for human
comprehension rather than algorithmic introspection, establishing a
comprehensive research agenda for advancing user-centered AI explanation
approaches across diverse domains and cultural contexts.

</details>


### [26] [Automated Creation of the Legal Knowledge Graph Addressing Legislation on Violence Against Women: Resource, Methodology and Lessons Learned](https://arxiv.org/abs/2508.06368)
*Claudia dAmato,Giuseppe Rubini,Francesco Didio,Donato Francioso,Fatima Zahra Amara,Nicola Fanizzi*

Main category: cs.AI

TL;DR: 论文提出两种构建法律知识图谱（KG）的方法，用于支持涉及女性暴力案件的法律决策，填补了法律领域KG的空白。


<details>
  <summary>Details</summary>
Motivation: 法律决策需要全面的立法背景知识和最新案例信息，而法律KG可以提升信息访问和机器学习应用，但目前法律领域KG较少。

Method: 采用两种互补方法：针对法律领域定制的自下而上系统方法，以及利用大型语言模型的新方案。

Result: 构建了针对女性暴力案件的法律KG，并通过能力问题验证了其有效性。

Conclusion: 开发的KG可提升法律信息的可访问性，支持复杂查询，并为预测性司法机器学习工具提供知识支持。

Abstract: Legal decision-making process requires the availability of comprehensive and
detailed legislative background knowledge and up-to-date information on legal
cases and related sentences/decisions. Legal Knowledge Graphs (KGs) would be a
valuable tool to facilitate access to legal information, to be queried and
exploited for the purpose, and to enable advanced reasoning and machine
learning applications. Indeed, legal KGs may act as knowledge intensive
component to be used by pre-dictive machine learning solutions supporting the
decision process of the legal expert. Nevertheless, a few KGs can be found in
the legal domain. To fill this gap, we developed a legal KG targeting legal
cases of violence against women, along with clear adopted methodologies.
Specifically, the paper introduces two complementary approaches for automated
legal KG construction; a systematic bottom-up approach, customized for the
legal domain, and a new solution leveraging Large Language Models. Starting
from legal sentences publicly available from the European Court of Justice, the
solutions integrate structured data extraction, ontology development, and
semantic enrichment to produce KGs tailored for legal cases involving violence
against women. After analyzing and comparing the results of the two approaches,
the developed KGs are validated via suitable competency questions. The obtained
KG may be impactful for multiple purposes: can improve the accessibility to
legal information both to humans and machine, can enable complex queries and
may constitute an important knowledge component to be possibly exploited by
machine learning tools tailored for predictive justice.

</details>


### [27] [The Fair Game: Auditing & Debiasing AI Algorithms Over Time](https://arxiv.org/abs/2508.06443)
*Debabrota Basu,Udvas Das*

Main category: cs.AI

TL;DR: 论文提出了一种动态机制“Fair Game”，通过结合审计员和去偏算法，利用强化学习实现公平性目标的自适应调整，以解决传统公平机器学习在动态社会环境中无法灵活应对的问题。


<details>
  <summary>Details</summary>
Motivation: 传统公平机器学习的定义通常是观察性的，且存在冲突，无法在动态社会环境中灵活调整。因此，需要一种能够适应社会变化的公平性机制。

Method: 提出“Fair Game”框架，将审计员和去偏算法通过强化学习循环结合，动态调整公平性目标。

Result: “Fair Game”能够模拟社会伦理和法律框架的演变，提供灵活且自适应的公平性解决方案。

Conclusion: “Fair Game”为公平机器学习提供了一种动态、灵活的框架，适用于部署前后的系统。

Abstract: An emerging field of AI, namely Fair Machine Learning (ML), aims to quantify
different types of bias (also known as unfairness) exhibited in the predictions
of ML algorithms, and to design new algorithms to mitigate them. Often, the
definitions of bias used in the literature are observational, i.e. they use the
input and output of a pre-trained algorithm to quantify a bias under concern.
In reality,these definitions are often conflicting in nature and can only be
deployed if either the ground truth is known or only in retrospect after
deploying the algorithm. Thus,there is a gap between what we want Fair ML to
achieve and what it does in a dynamic social environment. Hence, we propose an
alternative dynamic mechanism,"Fair Game",to assure fairness in the predictions
of an ML algorithm and to adapt its predictions as the society interacts with
the algorithm over time. "Fair Game" puts together an Auditor and a Debiasing
algorithm in a loop around an ML algorithm. The "Fair Game" puts these two
components in a loop by leveraging Reinforcement Learning (RL). RL algorithms
interact with an environment to take decisions, which yields new observations
(also known as data/feedback) from the environment and in turn, adapts future
decisions. RL is already used in algorithms with pre-fixed long-term fairness
goals. "Fair Game" provides a unique framework where the fairness goals can be
adapted over time by only modifying the auditor and the different biases it
quantifies. Thus,"Fair Game" aims to simulate the evolution of ethical and
legal frameworks in the society by creating an auditor which sends feedback to
a debiasing algorithm deployed around an ML system. This allows us to develop a
flexible and adaptive-over-time framework to build Fair ML systems pre- and
post-deployment.

</details>


### [28] [What Voting Rules Actually Do: A Data-Driven Analysis of Multi-Winner Voting](https://arxiv.org/abs/2508.06454)
*Joshua Caiata,Ben Armstrong,Kate Larson*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动的方法，评估多赢家投票规则在不同偏好分布下违反公理的频率，并发现神经网络作为投票规则优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 研究多赢家投票规则在实际偏好分布中的公理违反情况，以补充最坏情况分析的不足。

Method: 提出数据驱动框架，分析投票规则在多种偏好分布下的公理表现，并引入神经网络作为投票规则进行比较。

Result: 神经网络在减少公理违反方面优于传统投票规则。

Conclusion: 数据驱动方法可为新投票系统的设计提供参考，并推动社会选择领域的数据驱动研究。

Abstract: Committee-selection problems arise in many contexts and applications, and
there has been increasing interest within the social choice research community
on identifying which properties are satisfied by different multi-winner voting
rules. In this work, we propose a data-driven framework to evaluate how
frequently voting rules violate axioms across diverse preference distributions
in practice, shifting away from the binary perspective of axiom satisfaction
given by worst-case analysis. Using this framework, we analyze the relationship
between multi-winner voting rules and their axiomatic performance under several
preference distributions. We then show that neural networks, acting as voting
rules, can outperform traditional rules in minimizing axiom violations. Our
results suggest that data-driven approaches to social choice can inform the
design of new voting systems and support the continuation of data-driven
research in social choice.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [29] [PEACH: A sentence-aligned Parallel English-Arabic Corpus for Healthcare](https://arxiv.org/abs/2508.05722)
*Rania Al-Sabbagh*

Main category: cs.CL

TL;DR: PEACH是一个英语-阿拉伯语对齐的医疗文本平行语料库，包含51,671个句子，用于语言学、翻译研究和自然语言处理。


<details>
  <summary>Details</summary>
Motivation: 为医疗领域的对比语言学、翻译研究和自然语言处理提供高质量的对齐语料库。

Method: 手动对齐的平行语料库构建，涵盖患者信息手册和教育材料。

Result: 语料库包含51,671个句子，约590,517个英语单词和567,707个阿拉伯语单词，平均句长9.52至11.83个单词。

Conclusion: PEACH是一个公开可用的黄金标准语料库，支持多领域研究与应用。

Abstract: This paper introduces PEACH, a sentence-aligned parallel English-Arabic
corpus of healthcare texts encompassing patient information leaflets and
educational materials. The corpus contains 51,671 parallel sentences, totaling
approximately 590,517 English and 567,707 Arabic word tokens. Sentence lengths
vary between 9.52 and 11.83 words on average. As a manually aligned corpus,
PEACH is a gold-standard corpus, aiding researchers in contrastive linguistics,
translation studies, and natural language processing. It can be used to derive
bilingual lexicons, adapt large language models for domain-specific machine
translation, evaluate user perceptions of machine translation in healthcare,
assess patient information leaflets and educational materials' readability and
lay-friendliness, and as an educational resource in translation studies. PEACH
is publicly accessible.

</details>


### [30] [Guardians and Offenders: A Survey on Harmful Content Generation and Safety Mitigation](https://arxiv.org/abs/2508.05775)
*Chi Zhang,Changjia Zhu,Junjie Xiong,Xiaoran Xu,Lingyao Li,Yao Liu,Zhuo Lu*

Main category: cs.CL

TL;DR: 本文综述了大语言模型（LLMs）的双重角色：作为强大工具和潜在危害源，系统分析了其毒性、攻击和防御方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: LLMs在内容生成和理解方面具有革命性能力，但也可能产生有害内容，亟需解决这一社会技术挑战。

Method: 系统回顾了近期研究，包括无意毒性、对抗性攻击和内容审核技术，提出了统一的分类法，并分析了多模态和LLM辅助的攻击策略。

Result: 总结了当前的防御措施（如RLHF、提示工程和安全对齐），并指出了现有评估方法的局限性。

Conclusion: 强调了LLM安全性的动态发展，提出了未来研究方向，以推动稳健且符合伦理的语言技术发展。

Abstract: Large Language Models (LLMs) have revolutionized content creation across
digital platforms, offering unprecedented capabilities in natural language
generation and understanding. These models enable beneficial applications such
as content generation, question and answering (Q&A), programming, and code
reasoning. Meanwhile, they also pose serious risks by inadvertently or
intentionally producing toxic, offensive, or biased content. This dual role of
LLMs, both as powerful tools for solving real-world problems and as potential
sources of harmful language, presents a pressing sociotechnical challenge. In
this survey, we systematically review recent studies spanning unintentional
toxicity, adversarial jailbreaking attacks, and content moderation techniques.
We propose a unified taxonomy of LLM-related harms and defenses, analyze
emerging multimodal and LLM-assisted jailbreak strategies, and assess
mitigation efforts, including reinforcement learning with human feedback
(RLHF), prompt engineering, and safety alignment. Our synthesis highlights the
evolving landscape of LLM safety, identifies limitations in current evaluation
methodologies, and outlines future research directions to guide the development
of robust and ethically aligned language technologies.

</details>


### [31] [FineDialFact: A benchmark for Fine-grained Dialogue Fact Verification](https://arxiv.org/abs/2508.05782)
*Xiangyan Chen,Yufeng Li,Yujian Gan,Arkaitz Zubiaga,Matthew Purver*

Main category: cs.CL

TL;DR: 论文提出了一个细粒度对话事实验证基准FineDialFact，通过验证对话响应中的原子事实来解决LLMs产生的幻觉问题。实验表明，结合Chain-of-Thought推理的方法能提升性能，但任务仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: LLMs生成的幻觉（不准确或虚构信息）对NLP应用（如对话系统）构成挑战，现有的事实检测方法过于粗粒度，需要更精细的解决方案。

Method: 构建FineDialFact基准和数据集，基于公开对话数据集，评估多种基线方法，尤其是结合Chain-of-Thought推理的方法。

Result: 实验显示，Chain-of-Thought方法能提升性能，但在开放域对话数据集HybriDialogue上的最佳F1-score仅为0.75。

Conclusion: FineDialFact为未来研究提供了挑战性任务，数据集和代码将公开。

Abstract: Large Language Models (LLMs) are known to produce hallucinations - factually
incorrect or fabricated information - which poses significant challenges for
many Natural Language Processing (NLP) applications, such as dialogue systems.
As a result, detecting hallucinations has become a critical area of research.
Current approaches to hallucination detection in dialogue systems primarily
focus on verifying the factual consistency of generated responses. However,
these responses often contain a mix of accurate, inaccurate or unverifiable
facts, making one factual label overly simplistic and coarse-grained. In this
paper, we introduce a benchmark, FineDialFact, for fine-grained dialogue fact
verification, which involves verifying atomic facts extracted from dialogue
responses. To support this, we construct a dataset based on publicly available
dialogue datasets and evaluate it using various baseline methods. Experimental
results demonstrate that methods incorporating Chain-of-Thought (CoT) reasoning
can enhance performance in dialogue fact verification. Despite this, the best
F1-score achieved on the HybriDialogue, an open-domain dialogue dataset, is
only 0.75, indicating that the benchmark remains a challenging task for future
research. Our dataset and code will be public on GitHub.

</details>


### [32] [Human-like fleeting memory improves language learning but impairs reading time prediction in transformer language models](https://arxiv.org/abs/2508.05803)
*Abishek Thamma,Micha Heilbron*

Main category: cs.CL

TL;DR: 研究探讨了短暂记忆对语言学习的益处，发现其对提升语言模型性能有帮助，但对预测人类阅读时间有负面影响。


<details>
  <summary>Details</summary>
Motivation: 验证短暂记忆是否如传统认知科学所认为的那样对语言学习有益，尤其是在Transformer模型中。

Method: 在Transformer语言模型中控制实验，比较有无短暂记忆对语言学习和人类阅读时间预测的影响。

Result: 短暂记忆提升了语言模型性能，但降低了基于惊讶度的阅读时间预测准确性。

Conclusion: 短暂记忆对神经网络语言学习有益，但对行为预测无益。

Abstract: Human memory is fleeting. As words are processed, the exact wordforms that
make up incoming sentences are rapidly lost. Cognitive scientists have long
believed that this limitation of memory may, paradoxically, help in learning
language - an idea supported by classic connectionist modelling work. The rise
of Transformers appears to challenge this idea, as these models can learn
language effectively, despite lacking memory limitations or other architectural
recency biases. Here, we investigate the hypothesized benefit of fleeting
memory for language learning in tightly controlled experiments on transformer
language models. Training transformers with and without fleeting memory on a
developmentally realistic training set, we find that fleeting memory
consistently improves language learning (as quantified by both overall language
modelling performance and targeted syntactic evaluation) but, unexpectedly,
impairs surprisal-based prediction of human reading times. Interestingly,
follow up analyses revealed that this discrepancy - better language modeling,
yet worse reading time prediction - could not be accounted for by prior
explanations of why better language models sometimes fit human reading time
worse. Together, these results support a benefit of memory limitations on
neural network language learning - but not on predicting behavior.

</details>


### [33] ["Mirror" Language AI Models of Depression are Criterion-Contaminated](https://arxiv.org/abs/2508.05830)
*Tong Li,Rasiq Hussain,Mehak Gupta,Joshua R. Oltmanns*

Main category: cs.CL

TL;DR: 研究发现，基于语言的大模型（LLM）在预测抑郁评分时存在“标准污染”问题，导致Mirror模型效果被夸大，而Non-Mirror模型更具泛化性。


<details>
  <summary>Details</summary>
Motivation: 探讨Mirror模型和Non-Mirror模型在预测抑郁评分时的表现差异，揭示标准污染对模型效果的影响。

Method: 使用GPT-4、GPT-4o和LLaMA3-70B分别基于结构化诊断访谈和生活史访谈数据预测抑郁评分，比较两种模型的效果。

Result: Mirror模型效果被夸大（R2 = .80），Non-Mirror模型效果较小但更真实（R2 = .27），两者在预测自报抑郁症状时表现相似（r = ~.54）。

Conclusion: Mirror模型因标准污染而效果失真，Non-Mirror模型更具实用性和泛化性，未来研究应关注其语义特征。

Abstract: A growing number of studies show near-perfect LLM language-based prediction
of depression assessment scores (up to R2 of .70). However, many develop these
models directly from language responses to depression assessments. These
"Mirror models" suffer from "criterion contamination", which arises when a
predicted score depends in part on the predictors themselves. This causes
artificial effect size inflation which reduces model generalizability. The
present study compares the performance of Mirror models versus "Non-Mirror
models", which are developed from language that does not mirror the assessment
they are developed to predict. N = 110 research participants completed two
different interviews: structured diagnostic and life history interviews. GPT-4,
GPT-4o and LLaMA3-70B were then prompted to predict structured diagnostic
interview depression scores from the two transcripts separately. Mirror models
(using structured diagnostic data) showed very large effect sizes (e.g., R2 =
.80). As expected, NonMirror models (using life history data) demonstrated
smaller effect sizes, but were relatively large (e.g., R2 = .27). When Mirror
and Non-Mirror model-predicted structured interview depression scores were
correlated with self-reported depression symptoms, Mirror and NonMirror
performed the same (e.g., r = ~.54), indicating that Mirror models contain bias
perhaps due to criterion contamination. Topic modeling identified clusters
across Mirror and Non-Mirror models, as well as between true-positive and
false-positive predictions. In this head-to-head comparison study, Mirror
language AI models of depression showed artificially inflated effect sizes and
less generalizability. As language AI models for depression continue to evolve,
incorporating Non-Mirror models may identify interpretable, and generalizable
semantic features that have unique utility in real-world psychological
assessment.

</details>


### [34] [Discovering Properties of Inflectional Morphology in Neural Emergent Communication](https://arxiv.org/abs/2508.05843)
*Miles Gilberti,Shane Storks,Huteng Dai*

Main category: cs.CL

TL;DR: 论文重新解释了属性值重建游戏，通过小词汇量约束模拟双重发音，并提出了类似自然语言屈折形态的新设置，开发了新指标并探索了游戏变体。实验发现模拟音位约束鼓励连接性形态，而涌现语言倾向于融合语法属性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过深度神经网络代理的涌现通信（EmCom）揭示人类语言的本质，但现有研究过于关注子领域特定目标和指标，导致通信方案偏向一对一属性表示和句法组合。

Method: 重新解释属性值重建游戏，施加小词汇量约束模拟双重发音，并设计类似自然屈折形态的新设置。开发新指标，探索连接性和融合性变体。

Result: 实验表明，模拟音位约束促进连接性形态，涌现语言倾向于融合语法属性，与自然语言趋势一致。

Conclusion: 研究通过新设置和指标，揭示了涌现语言与自然语言在形态上的相似性，为理解人类语言提供了新视角。

Abstract: Emergent communication (EmCom) with deep neural network-based agents promises
to yield insights into the nature of human language, but remains focused
primarily on a few subfield-specific goals and metrics that prioritize
communication schemes which represent attributes with unique characters
one-to-one and compose them syntactically. We thus reinterpret a common EmCom
setting, the attribute-value reconstruction game, by imposing a
small-vocabulary constraint to simulate double articulation, and formulating a
novel setting analogous to naturalistic inflectional morphology (enabling
meaningful comparison to natural language communication schemes). We develop
new metrics and explore variations of this game motivated by real properties of
inflectional morphology: concatenativity and fusionality. Through our
experiments, we discover that simulated phonological constraints encourage
concatenative morphology, and emergent languages replicate the tendency of
natural languages to fuse grammatical attributes.

</details>


### [35] [Do Machines Think Emotionally? Cognitive Appraisal Analysis of Large Language Models](https://arxiv.org/abs/2508.05880)
*Sree Bhattacharyya,Lucas Craig,Tharun Dilliraj,Jia Li,James Z. Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种基于认知评估理论的方法，研究大型语言模型（LLMs）在情感推理中的认知维度，并引入了一个名为CoRE的大规模基准来评估其内部认知结构。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于监督学习和表面情感任务，缺乏对LLMs在情感推理中认知维度的深入探讨。

Method: 通过认知评估理论，设计实验评估LLMs在情感刺激下的认知推理能力，并引入CoRE基准进行大规模分析。

Result: 发现不同LLMs在情感推理中表现出多样化的认知模式，揭示了认知评估维度在情感分类中的重要性。

Conclusion: 论文证明了认知维度在LLMs情感推理中的关键作用，为未来研究提供了新的基准和方向。

Abstract: Affective Computing has been established as a crucial field of inquiry to
advance the holistic development of Artificial Intelligence (AI) systems.
Foundation models -- especially Large Language Models (LLMs) -- have been
evaluated, trained, or instruction-tuned in several past works, to become
better predictors or generators of emotion. Most of these studies, however,
approach emotion-related tasks in a supervised manner, assessing or training
the capabilities of LLMs using discrete emotion labels associated with stimuli
(e.g., text, images, video, audio). Evaluation studies, in particular, have
often been limited to standard and superficial emotion-related tasks, such as
the recognition of evoked or expressed emotions. In this paper, we move beyond
surface-level emotion tasks to investigate how LLMs reason about emotions
through cognitive dimensions. Drawing from cognitive appraisal theory, we
examine whether LLMs produce coherent and plausible cognitive reasoning when
reasoning about emotionally charged stimuli. We introduce a large-scale
benchmark on Cognitive Reasoning for Emotions - CoRE - to evaluate internal
cognitive structures implicitly used by LLMs for emotional reasoning. Through a
plethora of evaluation experiments and analysis, we seek to answer: (a) Are
models more likely to implicitly rely on specific cognitive appraisal
dimensions?, (b) What cognitive dimensions are important for characterizing
specific emotions?, and, (c) Can the internal representations of different
emotion categories in LLMs be interpreted through cognitive appraisal
dimensions? Our results and analyses reveal diverse reasoning patterns across
different LLMs. Our benchmark and code will be made publicly available.

</details>


### [36] [Spectrum Projection Score: Aligning Retrieved Summaries with Reader Models in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.05909)
*Zhanghao Hu,Qinglin Zhu,Siya Qi,Yulan He,Hanqi Yan,Lin Gui*

Main category: cs.CL

TL;DR: 论文提出了一种名为SPS的轻量级无监督度量方法，用于评估检索摘要与生成模型的语义对齐，并基于SPS设计了xCompress框架，动态优化检索摘要。实验表明SPS能提升多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法难以单独评估检索的贡献，尤其是LLM作为读者时的提示敏感性。

Method: 提出Spectrum Projection Score（SPS）度量方法，通过比较生成令牌与读者子空间的主方向面积来评估语义对齐；并基于SPS设计了xCompress框架。

Result: 在五个QA基准测试和四种开源LLM上的实验表明，SPS提升了任务性能，并为检索与生成的交互提供了理论视角。

Conclusion: SPS是一种有效的度量方法，xCompress框架能动态优化检索摘要，为RAG研究提供了新思路。

Abstract: Large Language Models (LLMs) have shown improved generation performance
through retrieval-augmented generation (RAG) following the retriever-reader
paradigm, which supplements model inputs with externally retrieved knowledge.
However, prior work often evaluates RAG holistically, assessing the retriever
and reader jointly, making it difficult to isolate the true contribution of
retrieval, particularly given the prompt sensitivity of LLMs used as readers.
We introduce Spectrum Projection Score (SPS), a lightweight, supervision-free
metric that allows the reader to gauge the semantic alignment of a retrieved
summary with its hidden representation by comparing the area formed by
generated tokens from the summary, and the principal directions of subspace in
the reader and to measure the relevance. Building on SPS we present xCompress,
an inference time controller framework that dynamically samples, ranks, and
compresses retrieval summary candidates. Extensive experiments on five QA
benchmarks with four open source LLMs show that SPS not only enhances
performance across a range of tasks but also provides a principled perspective
on the interaction between retrieval and generation.

</details>


### [37] [Prosocial Behavior Detection in Player Game Chat: From Aligning Human-AI Definitions to Efficient Annotation at Scale](https://arxiv.org/abs/2508.05938)
*Rafal Kocielnik,Min Kim,Penphob,Boonyarungsrit,Fereshteh Soltani,Deshawn Sambrano,Animashree Anandkumar,R. Michael Alvarez*

Main category: cs.CL

TL;DR: 提出了一种三阶段流程，用于高效分类支持性文本，结合人类与AI协作，降低标注和推理成本。


<details>
  <summary>Details</summary>
Motivation: 支持性文本检测在信任与安全系统中日益重要，但缺乏定义和标注数据，需要新方法。

Method: 三阶段流程：1) 基于LLM的标注策略；2) 人类-AI协作优化标注；3) 两阶段推理系统降低成本。

Result: 标注质量提升，推理成本降低70%，同时保持高精度（约0.90）。

Conclusion: 通过人类-AI协作和优化架构设计，可扩展解决新兴AI任务。

Abstract: Detecting prosociality in text--communication intended to affirm, support, or
improve others' behavior--is a novel and increasingly important challenge for
trust and safety systems. Unlike toxic content detection, prosociality lacks
well-established definitions and labeled data, requiring new approaches to both
annotation and deployment. We present a practical, three-stage pipeline that
enables scalable, high-precision prosocial content classification while
minimizing human labeling effort and inference costs. First, we identify the
best LLM-based labeling strategy using a small seed set of human-labeled
examples. We then introduce a human-AI refinement loop, where annotators review
high-disagreement cases between GPT-4 and humans to iteratively clarify and
expand the task definition-a critical step for emerging annotation tasks like
prosociality. This process results in improved label quality and definition
alignment. Finally, we synthesize 10k high-quality labels using GPT-4 and train
a two-stage inference system: a lightweight classifier handles high-confidence
predictions, while only $\sim$35\% of ambiguous instances are escalated to
GPT-4o. This architecture reduces inference costs by $\sim$70% while achieving
high precision ($\sim$0.90). Our pipeline demonstrates how targeted human-AI
interaction, careful task formulation, and deployment-aware architecture design
can unlock scalable solutions for novel responsible AI tasks.

</details>


### [38] [Adversarial Topic-aware Prompt-tuning for Cross-topic Automated Essay Scoring](https://arxiv.org/abs/2508.05987)
*Chunyun Zhang,Hongyan Zhao,Chaoran Cui,Qilong Song,Zhiqing Lu,Shuai Gong,Kailin Liu*

Main category: cs.CL

TL;DR: 论文提出了一种名为ATOP的新方法，通过联合学习主题共享和主题特定特征，改进跨主题自动作文评分（AES）。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注通过源和目标主题的分布对齐提取主题共享特征，但忽略了主题特定特征，限制了评估关键特质（如主题一致性）的能力。

Method: ATOP通过优化可学习的主题感知提示（包含共享和特定组件）从预训练语言模型中提取相关知识，并结合对抗训练和邻居分类器建模局部结构。

Result: 在ASAP++数据集上的实验表明，ATOP在整体和多特质作文评分上显著优于现有方法。

Conclusion: ATOP通过联合学习主题共享和特定特征，有效提升了跨主题AES的性能。

Abstract: Cross-topic automated essay scoring (AES) aims to develop a transferable
model capable of effectively evaluating essays on a target topic. A significant
challenge in this domain arises from the inherent discrepancies between topics.
While existing methods predominantly focus on extracting topic-shared features
through distribution alignment of source and target topics, they often neglect
topic-specific features, limiting their ability to assess critical traits such
as topic adherence. To address this limitation, we propose an Adversarial
TOpic-aware Prompt-tuning (ATOP), a novel method that jointly learns
topic-shared and topic-specific features to improve cross-topic AES. ATOP
achieves this by optimizing a learnable topic-aware prompt--comprising both
shared and specific components--to elicit relevant knowledge from pre-trained
language models (PLMs). To enhance the robustness of topic-shared prompt
learning and mitigate feature scale sensitivity introduced by topic alignment,
we incorporate adversarial training within a unified regression and
classification framework. In addition, we employ a neighbor-based classifier to
model the local structure of essay representations and generate pseudo-labels
for target-topic essays. These pseudo-labels are then used to guide the
supervised learning of topic-specific prompts tailored to the target topic.
Extensive experiments on the publicly available ASAP++ dataset demonstrate that
ATOP significantly outperforms existing state-of-the-art methods in both
holistic and multi-trait essay scoring. The implementation of our method is
publicly available at: https://anonymous.4open.science/r/ATOP-A271.

</details>


### [39] [Crisp Attention: Regularizing Transformers via Structured Sparsity](https://arxiv.org/abs/2508.06016)
*Sagar Gandhi,Vishal Gandhi*

Main category: cs.CL

TL;DR: 在Transformer模型中，自注意力机制的高计算成本是主要挑战。本文通过引入结构化的事后稀疏性，在DistilBERT模型的微调过程中显著提高了准确性，同时保持了80%的注意力稀疏性。


<details>
  <summary>Details</summary>
Motivation: 解决自注意力机制的高计算成本问题，并探索稀疏性是否能同时提高模型准确性。

Method: 在DistilBERT模型的微调过程中引入结构化的事后稀疏性，应用于SST-2情感分析任务。

Result: 80%稀疏性的模型验证准确率达到91.59%，比密集基线提高了0.97%。

Conclusion: 稀疏性不仅是提高计算效率的工具，还能通过隐式正则化提升模型的泛化能力和性能。

Abstract: The quadratic computational cost of the self-attention mechanism is a primary
challenge in scaling Transformer models. While attention sparsity is widely
studied as a technique to improve computational efficiency, it is almost
universally assumed to come at the cost of model accuracy. In this paper, we
report a surprising counter-example to this common wisdom. By introducing
structured, post-hoc sparsity to the attention mechanism of a DistilBERT model
during fine-tuning on the SST-2 sentiment analysis task, we find that model
accuracy improves significantly. Our model with 80\% attention sparsity
achieves a validation accuracy of 91.59\%, a 0.97\% absolute improvement over
the dense baseline. We hypothesize that this phenomenon is due to sparsity
acting as a powerful implicit regularizer, preventing the model from
overfitting by forcing it to make predictions with a more constrained and
robust set of features. Our work recasts attention sparsity not just as a tool
for computational efficiency, but as a potential method for improving the
generalization and performance of Transformer models.

</details>


### [40] [Temporal Self-Rewarding Language Models: Decoupling Chosen-Rejected via Past-Future](https://arxiv.org/abs/2508.06026)
*Yidong Wang,Xin Wang,Cunxiang Wang,Junfeng Fang,Qiufeng Wang,Jianing Chu,Xuran Meng,Shuxun Yang,Libo Qin,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种新的自奖励语言模型架构，通过动态协调过去、现在和未来的模型输出来解决现有自奖励范式的局限性，显著提升了生成能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有自奖励语言模型在同步改进选择和拒绝响应时，逐渐缩小了对比样本的表征差异，削弱了偏好学习的有效性。

Method: 提出了双阶段框架：(1) 锚定拒绝响应，使用过去初始模型的输出固定拒绝样本；(2) 未来引导选择，动态筛选选择样本。

Result: 在多个模型家族和规模上实验表明，该方法显著优于基线，例如Llama3.1-8B在AlpacaEval 2.0上的胜率提升9.75。

Conclusion: 新方法不仅提升了任务性能，还展现出卓越的跨领域泛化能力。

Abstract: Self-Rewarding Language Models propose an architecture in which the Large
Language Models(LLMs) both generates responses and evaluates its own outputs
via LLM-as-a-Judge prompting, dynamically improving its generative capabilities
through iterative Direct Preference Optimization (DPO). However, our analysis
reveals a critical limitation in existing Self-Rewarding paradigms: the
synchronized improvement of chosen and rejected responses progressively narrows
the representational difference between contrasting samples, undermining
effective preference learning. We propose \textbf{Temporal Self-Rewarding
Language Models} that strategically coordinate past, present, and future model
generations to sustain learning signals. Our dual-phase framework introduces:
(1) \textit{Anchored Rejection} - fixing rejected responses using the past
initial model's outputs and (2) \textit{Future-Guided Chosen} - dynamically
curating chosen samples using next-generation model predictions. Extensive
experiments across three model families (Llama, Qwen, Mistral) and different
model sizes (Llama3B/8B/70B) demonstrate significant improvements when trained
with our method compared to Self-Rewarding using same computation resources.
For example, Llama3.1-8B reaches a 29.44 win rate on AlpacaEval 2.0 with our
method, outperforming the Self-Rewarding baseline (19.69) by 9.75. Notably, our
method also demonstrates superior out-of-distribution generalization across
mathematical reasoning (GSM8K), knowledge-based QA (ARC, TruthfulQA), and code
generation (HumanEval) tasks, even though we do not specifically collect such
training data.

</details>


### [41] [Efficient Knowledge Probing of Large Language Models by Adapting Pre-trained Embeddings](https://arxiv.org/abs/2508.06030)
*Kartik Sharma,Yiqiao Jin,Rakshit Trivedi,Srijan Kumar*

Main category: cs.CL

TL;DR: 提出了一种名为PEEK的方法，通过预训练的嵌入模型预测大型语言模型（LLM）的知识，避免了传统探测方法的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的随机性，难以预测其掌握的知识，传统探测方法计算成本高且耗时。

Method: 利用预训练的嵌入模型作为代理，通过线性解码层预测LLM的知识输出。

Result: 在多个数据集和模型上，嵌入模型预测LLM知识的准确率高达90%。

Conclusion: 知识适应的嵌入模型可大规模识别LLM的知识缺口，并揭示其内部归纳偏差。

Abstract: Large language models (LLMs) acquire knowledge across diverse domains such as
science, history, and geography encountered during generative pre-training.
However, due to their stochasticity, it is difficult to predict what LLMs have
acquired. Prior work has developed different ways to probe this knowledge by
investigating the hidden representations, crafting specific task prompts,
curating representative samples, and estimating their uncertainty. However,
these methods require making forward passes through the underlying model to
probe the LLM's knowledge about a specific fact, making them computationally
expensive and time-consuming. To bridge this gap, we propose $\textbf{PEEK}$ or
$\textbf{P}$roxy $\textbf{E}$mbeddings to $\textbf{E}$stimate
$\textbf{K}$nowledge of LLMs, by leveraging the pre-trained embedding models
that effectively encode factual knowledge as text or graphs as proxies for
LLMs. First, we identify a training set of facts known by LLMs through various
probing strategies and then adapt embedding models to predict the LLM outputs
with a linear decoder layer. Comprehensive evaluation on $3$ Wikipedia-derived
datasets, $4$ LLMs, and $7$ embedding models shows that embeddings can predict
LLM knowledge on a held-out set with up to 90 % accuracy. Furthermore, we find
that sentence embedding models are more suitable than graph embeddings to
predict LLM knowledge, shedding light on the underlying representation of the
factual landscape. Thus, we believe that knowledge-adapted embeddings can be
used to identify knowledge gaps in LLMs at scale and can provide deeper
insights into LLMs' internal inductive bias. The code and data are made
available at https://github.com/claws-lab/peek.

</details>


### [42] [EvolvR: Self-Evolving Pairwise Reasoning for Story Evaluation to Enhance Generation](https://arxiv.org/abs/2508.06046)
*Xinda Wang,Zhengxu Hou,Yangshijie Zhang,Bingren Yan,Zhibo Yang,Xingsheng Zhang,Luxi Xing,Qiang Zhou,Chen Zhang*

Main category: cs.CL

TL;DR: 论文提出了EvolvR框架，通过自合成的成对推理和自过滤过程提升LLM在故事评估中的表现，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放任务（如故事评估）中表现有限，封闭模型适应性差，开源模型缺乏严谨推理能力，需改进。

Method: 提出EvolvR框架，基于成对比较自合成评分对齐的CoT数据，并通过多智能体自过滤确保数据质量，最终训练评估器。

Result: 在StoryER、HANNA和OpenMEVA三个基准测试中达到SOTA，作为奖励模型显著提升生成故事质量。

Conclusion: EvolvR框架通过自进化方法显著提升了故事评估和生成的性能。

Abstract: Although the effectiveness of Large Language Models (LLMs) as judges
(LLM-as-a-judge) has been validated, their performance remains limited in
open-ended tasks, particularly in story evaluation. Accurate story evaluation
is crucial not only for assisting human quality judgment but also for providing
key signals to guide story generation. However, existing methods face a
dilemma: prompt engineering for closed-source models suffers from poor
adaptability, while fine-tuning approaches for open-source models lack the
rigorous reasoning capabilities essential for story evaluation. To address
this, we propose the Self-Evolving Pairwise Reasoning (EvolvR) framework.
Grounded in pairwise comparison, the framework first self-synthesizes
score-aligned Chain-of-Thought (CoT) data via a multi-persona strategy. To
ensure data quality, these raw CoTs undergo a self-filtering process, utilizing
multi-agents to guarantee their logical rigor and robustness. Finally, the
evaluator trained on the refined data is deployed as a reward model to guide
the story generation task. Experimental results demonstrate that our framework
achieves state-of-the-art (SOTA) performance on three evaluation benchmarks
including StoryER, HANNA and OpenMEVA. Furthermore, when served as a reward
model, it significantly enhances the quality of generated stories, thereby
fully validating the superiority of our self-evolving approach.

</details>


### [43] [ConlangCrafter: Constructing Languages with a Multi-Hop LLM Pipeline](https://arxiv.org/abs/2508.06094)
*Morris Alper,Moran Yanuka,Raja Giryes,Gašper Beguš*

Main category: cs.CL

TL;DR: 利用现代LLM作为计算创造力工具，提出ConlangCrafter多阶段流程，用于端到端构建人工语言，并通过评估验证其生成语言的连贯性和多样性。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用大型语言模型（LLM）辅助人工语言（conlang）的创造，以解决传统方法需要专业语言学知识的问题。

Method: 提出ConlangCrafter多阶段流程，分解语言设计为音系、形态、句法、词汇生成和翻译，利用LLM的元语言推理能力，引入随机性和自反馈机制。

Result: 实验表明，ConlangCrafter能够生成连贯且多样的人工语言，无需人类语言学专业知识。

Conclusion: ConlangCrafter展示了LLM在人工语言创造中的潜力，为未来相关研究提供了新思路。

Abstract: Constructed languages (conlangs) such as Esperanto and Quenya have played
diverse roles in art, philosophy, and international communication. Meanwhile,
large-scale foundation models have revolutionized creative generation in text,
images, and beyond. In this work, we leverage modern LLMs as computational
creativity aids for end-to-end conlang creation. We introduce ConlangCrafter, a
multi-hop pipeline that decomposes language design into modular stages --
phonology, morphology, syntax, lexicon generation, and translation. At each
stage, our method leverages LLMs' meta-linguistic reasoning capabilities,
injecting randomness to encourage diversity and leveraging self-refinement
feedback to encourage consistency in the emerging language description. We
evaluate ConlangCrafter on metrics measuring coherence and typological
diversity, demonstrating its ability to produce coherent and varied conlangs
without human linguistic expertise.

</details>


### [44] [Few-Shot Prompting for Extractive Quranic QA with Instruction-Tuned LLMs](https://arxiv.org/abs/2508.06103)
*Mohamed Basem,Islam Oshallah,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 论文提出两种有效的提取式问答方法，针对《古兰经》的复杂语言和独特术语，使用少样本提示和指令调优的大语言模型，开发了阿拉伯语提示框架和后处理系统，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决《古兰经》问答任务中因复杂语言、独特术语和深层含义带来的挑战。

Method: 1. 使用少样本提示和指令调优的大语言模型（如Gemini和DeepSeek）；2. 开发阿拉伯语提示框架和后处理系统（子词对齐、重叠抑制和语义过滤）。

Result: 大语言模型在阿拉伯语指令下表现优于传统微调模型，最佳配置达到pAP10分数0.637。

Conclusion: 基于提示的指令调优对低资源、语义丰富的问答任务有效。

Abstract: This paper presents two effective approaches for Extractive Question
Answering (QA) on the Quran. It addresses challenges related to complex
language, unique terminology, and deep meaning in the text. The second uses
few-shot prompting with instruction-tuned large language models such as Gemini
and DeepSeek. A specialized Arabic prompt framework is developed for span
extraction. A strong post-processing system integrates subword alignment,
overlap suppression, and semantic filtering. This improves precision and
reduces hallucinations. Evaluations show that large language models with Arabic
instructions outperform traditional fine-tuned models. The best configuration
achieves a pAP10 score of 0.637. The results confirm that prompt-based
instruction tuning is effective for low-resource, semantically rich QA tasks.

</details>


### [45] [You Don't Need Pre-built Graphs for RAG: Retrieval Augmented Generation with Adaptive Reasoning Structures](https://arxiv.org/abs/2508.06105)
*Shengyuan Chen,Chuang Zhou,Zheng Yuan,Qinggang Zhang,Zeyang Cui,Hao Chen,Yilin Xiao,Jiannong Cao,Xiao Huang*

Main category: cs.CL

TL;DR: LogicRAG提出了一种动态构建逻辑结构的检索增强生成框架，避免了预建图的高成本，并通过图剪枝和上下文剪枝显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有GraphRAG方法因预建图导致的成本高、更新延迟及逻辑结构不匹配问题。

Method: 动态分解查询为子问题，构建DAG建模逻辑依赖，拓扑排序线性化图，并应用图剪枝和上下文剪枝。

Result: 实验表明LogicRAG在性能和效率上优于现有方法。

Conclusion: LogicRAG通过动态逻辑结构提取和优化检索，显著提升了生成准确性和效率。

Abstract: Large language models (LLMs) often suffer from hallucination, generating
factually incorrect statements when handling questions beyond their knowledge
and perception. Retrieval-augmented generation (RAG) addresses this by
retrieving query-relevant contexts from knowledge bases to support LLM
reasoning. Recent advances leverage pre-constructed graphs to capture the
relational connections among distributed documents, showing remarkable
performance in complex tasks. However, existing Graph-based RAG (GraphRAG)
methods rely on a costly process to transform the corpus into a graph,
introducing overwhelming token cost and update latency. Moreover, real-world
queries vary in type and complexity, requiring different logic structures for
accurate reasoning. The pre-built graph may not align with these required
structures, resulting in ineffective knowledge retrieval. To this end, we
propose a \textbf{\underline{Logic}}-aware
\textbf{\underline{R}}etrieval-\textbf{\underline{A}}ugmented
\textbf{\underline{G}}eneration framework (\textbf{LogicRAG}) that dynamically
extracts reasoning structures at inference time to guide adaptive retrieval
without any pre-built graph. LogicRAG begins by decomposing the input query
into a set of subproblems and constructing a directed acyclic graph (DAG) to
model the logical dependencies among them. To support coherent multi-step
reasoning, LogicRAG then linearizes the graph using topological sort, so that
subproblems can be addressed in a logically consistent order. Besides, LogicRAG
applies graph pruning to reduce redundant retrieval and uses context pruning to
filter irrelevant context, significantly reducing the overall token cost.
Extensive experiments demonstrate that LogicRAG achieves both superior
performance and efficiency compared to state-of-the-art baselines.

</details>


### [46] [AURA: Affordance-Understanding and Risk-aware Alignment Technique for Large Language Models](https://arxiv.org/abs/2508.06124)
*Sayantan Adak,Pratyush Chatterjee,Somnath Banerjee,Rima Hazra,Somak Aditya,Animesh Mukherjee*

Main category: cs.CL

TL;DR: AURA框架通过过程奖励模型（PRMs）和多层评估，显著提升LLMs的逻辑完整性和安全性，超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在逻辑隐含的安全风险上存在不足，传统方法缺乏细粒度和主动性。

Method: 提出AURA框架，结合自省式自我批评、细粒度PRM评估和自适应安全解码。

Result: 实证显示AURA显著提升模型输出的逻辑完整性和安全性。

Conclusion: AURA为更安全、负责任的AI设定了新基准。

Abstract: Present day LLMs face the challenge of managing affordance-based safety
risks-situations where outputs inadvertently facilitate harmful actions due to
overlooked logical implications. Traditional safety solutions, such as scalar
outcome-based reward models, parameter tuning, or heuristic decoding
strategies, lack the granularity and proactive nature needed to reliably detect
and intervene during subtle yet crucial reasoning steps. Addressing this
fundamental gap, we introduce AURA, an innovative, multi-layered framework
centered around Process Reward Models (PRMs), providing comprehensive, step
level evaluations across logical coherence and safety-awareness. Our framework
seamlessly combines introspective self-critique, fine-grained PRM assessments,
and adaptive safety-aware decoding to dynamically and proactively guide models
toward safer reasoning trajectories. Empirical evidence clearly demonstrates
that this approach significantly surpasses existing methods, significantly
improving the logical integrity and affordance-sensitive safety of model
outputs. This research represents a pivotal step toward safer, more
responsible, and contextually aware AI, setting a new benchmark for
alignment-sensitive applications.

</details>


### [47] [Less is More: Selective Reflection for Compatible and Efficient Knowledge Distillation in Large Language Models](https://arxiv.org/abs/2508.06135)
*Lingyuan Liu,Mengxiang Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为选择性反射蒸馏（SRD）的新框架，通过动态评估和选择高质量、学生模型兼容的训练数据，提升知识蒸馏（KD）的效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有白盒KD方法忽视了训练数据质量和学生模型兼容性，导致蒸馏效果受限。

Method: SRD利用学生模型的反射动态筛选数据，并通过课程调度策略逐步引入筛选后的数据。

Result: 实验表明，SRD在多种KD方法和模型架构下均提升了蒸馏性能，并降低了39%的训练时间。

Conclusion: 数据质量和兼容性是KD的关键，SRD为高效压缩大型语言模型提供了实用框架。

Abstract: Knowledge Distillation (KD) is a fundamental technique for compressing large
language models (LLMs) into compact, efficient student models. However,
existing white-box KD methods mainly focus on balancing ground truth and
student-generated responses while overlooking two critical factors: training
data quality and student-model compatibility. To address these limitations, we
propose Selective Reflection Distillation (SRD), a novel data curation
framework that leverages reflections from student models to systematically
refine training data. SRD dynamically evaluates and selects prompt-response
pairs by comparing ground truth data with student model outputs, selectively
curating high-quality, student-compatible training instances through automated
ranking based on difficulty. Furthermore, after selecting the training data, a
curriculum scheduling strategy is employed to incrementally introduce these
curated subsets into the distillation process at fixed intervals. As a
plug-and-play enhancement, SRD consistently improves distillation outcomes
across diverse white-box KD approaches and model architectures, as well as
decreases computational cost significantly during KD training. Experiments on a
range of language model benchmarks demonstrate SRD's consistent improvements in
distilled model performance, as well as a reduction in training runtime by up
to 39%, under diverse KD methods and model families. Notably, SRD operates as a
plug-and-play module, enhancing sample efficiency without modifying underlying
KD algorithms. Our findings highlight that data quality and compatibility are
pivotal to effective and efficient distillation of LLMs, and SRD provides a
principled framework to achieve both. This work advances the understanding of
data-centric factors in KD and offers practical insights for enhancing the
capability and efficiency of compressed LLMs.

</details>


### [48] [Scaling Personality Control in LLMs with Big Five Scaler Prompts](https://arxiv.org/abs/2508.06149)
*Gunhee Cho,Yun-Gyung Cheong*

Main category: cs.CL

TL;DR: Big5-Scaler是一个基于提示的框架，通过将Big Five人格特质的数值嵌入自然语言提示中，实现对大型语言模型（LLMs）的精细人格控制，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索如何通过提示工程（prompt engineering）实现对LLMs人格特质的可控调节，以构建更具人格感知能力的对话代理。

Method: 方法是将Big Five人格特质的数值嵌入自然语言提示中，通过不同提示类型和强度调节模型输出的人格表现。

Result: 结果表明，Big5-Scaler能够诱导出一致且可区分的人格特质，性能因提示类型和强度而异，简洁提示和较低特质强度效果更佳。

Conclusion: 结论是Big5-Scaler提供了一种高效的方法，可用于构建具有人格感知能力的对话代理，尤其在简洁提示和低强度特质条件下表现突出。

Abstract: We present Big5-Scaler, a prompt-based framework for conditioning large
language models (LLMs) with controllable Big Five personality traits. By
embedding numeric trait values into natural language prompts, our method
enables fine-grained personality control without additional training. We
evaluate Big5-Scaler across trait expression, dialogue generation, and human
trait imitation tasks. Results show that it induces consistent and
distinguishable personality traits across models, with performance varying by
prompt type and scale. Our analysis highlights the effectiveness of concise
prompts and lower trait intensities, providing a efficient approach for
building personality-aware dialogue agents.

</details>


### [49] [Semantic and Structural Analysis of Implicit Biases in Large Language Models: An Interpretable Approach](https://arxiv.org/abs/2508.06155)
*Renhan Zhang,Lian Lian,Zhen Qi,Guiran Liu*

Main category: cs.CL

TL;DR: 该论文提出了一种可解释的偏见检测方法，用于识别大型语言模型输出中的隐性社会偏见，结合嵌套语义表示和上下文对比机制，通过注意力权重扰动分析模型对特定社会属性词的敏感性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型生成过程中可能出现的隐性刻板印象问题，提供更透明和可靠的偏见检测技术基础。

Method: 结合嵌套语义表示和上下文对比机制，提取潜在偏见特征，并通过注意力权重扰动分析模型敏感性。

Result: 在多个刻板印象维度（如性别、职业、宗教和种族）上表现出强大的检测性能，能够准确识别语义相似文本间的偏见差异。

Conclusion: 该方法具有高解释性和实用性，适用于需要高可信生成内容的实际应用。

Abstract: This paper addresses the issue of implicit stereotypes that may arise during
the generation process of large language models. It proposes an interpretable
bias detection method aimed at identifying hidden social biases in model
outputs, especially those semantic tendencies that are not easily captured
through explicit linguistic features. The method combines nested semantic
representation with a contextual contrast mechanism. It extracts latent bias
features from the vector space structure of model outputs. Using attention
weight perturbation, it analyzes the model's sensitivity to specific social
attribute terms, thereby revealing the semantic pathways through which bias is
formed. To validate the effectiveness of the method, this study uses the
StereoSet dataset, which covers multiple stereotype dimensions including
gender, profession, religion, and race. The evaluation focuses on several key
metrics, such as bias detection accuracy, semantic consistency, and contextual
sensitivity. Experimental results show that the proposed method achieves strong
detection performance across various dimensions. It can accurately identify
bias differences between semantically similar texts while maintaining high
semantic alignment and output stability. The method also demonstrates high
interpretability in its structural design. It helps uncover the internal bias
association mechanisms within language models. This provides a more transparent
and reliable technical foundation for bias detection. The approach is suitable
for real-world applications where high trustworthiness of generated content is
required.

</details>


### [50] [One Size Does Not Fit All: A Distribution-Aware Sparsification for More Precise Model Merging](https://arxiv.org/abs/2508.06163)
*Yingfeng Luo,Dingyang Lin,Junxin Wang,Ziqiang Xu,Kaiyan Chang,Tong Zheng,Bei Li,Anxiang Ma,Tong Xiao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: TADrop是一种自适应稀疏化策略，通过为每个参数张量分配定制化的稀疏化水平，优化模型合并性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法采用统一的稀疏化比例，忽略了参数的结构和统计异质性，导致关键参数被误删或冗余参数被保留。

Method: TADrop根据参数张量的分布特性动态调整稀疏化比例，对冗余密集的张量进行更激进的剪枝，而对稀疏关键的张量则保留。

Result: TADrop显著提升了多种任务（视觉、语言、多模态）和模型（ViT、BEiT）的性能，例如在ViT-B/32任务上平均提升2.0%。

Conclusion: TADrop通过自适应稀疏化有效减少了参数干扰，为高性能模型合并提供了新基准。

Abstract: Model merging has emerged as a compelling data-free paradigm for multi-task
learning, enabling the fusion of multiple fine-tuned models into a single,
powerful entity. A key technique in merging methods is sparsification, which
prunes redundant parameters from task vectors to mitigate interference.
However, prevailing approaches employ a ``one-size-fits-all'' strategy,
applying a uniform sparsity ratio that overlooks the inherent structural and
statistical heterogeneity of model parameters. This often leads to a suboptimal
trade-off, where critical parameters are inadvertently pruned while less useful
ones are retained. To address this limitation, we introduce \textbf{TADrop}
(\textbf{T}ensor-wise \textbf{A}daptive \textbf{Drop}), an adaptive
sparsification strategy that respects this heterogeneity. Instead of a global
ratio, TADrop assigns a tailored sparsity level to each parameter tensor based
on its distributional properties. The core intuition is that tensors with
denser, more redundant distributions can be pruned aggressively, while sparser,
more critical ones are preserved. As a simple and plug-and-play module, we
validate TADrop by integrating it with foundational, classic, and SOTA merging
methods. Extensive experiments across diverse tasks (vision, language, and
multimodal) and models (ViT, BEiT) demonstrate that TADrop consistently and
significantly boosts their performance. For instance, when enhancing a leading
merging method, it achieves an average performance gain of 2.0\% across 8
ViT-B/32 tasks. TADrop provides a more effective way to mitigate parameter
interference by tailoring sparsification to the model's structure, offering a
new baseline for high-performance model merging.

</details>


### [51] [UR$^2$: Unify RAG and Reasoning through Reinforcement Learning](https://arxiv.org/abs/2508.06165)
*Weitao Li,Boran Xiang,Xiaolong Wang,Zhinan Gou,Weizhi Ma,Yang Liu*

Main category: cs.CL

TL;DR: 论文提出了UR2框架，统一了检索增强生成（RAG）和强化学习（RLVR），通过动态协调检索与推理提升任务适应性。


<details>
  <summary>Details</summary>
Motivation: 现有方法中RAG和RLVR能力孤立发展，限制了泛化性和应用范围，需要统一框架。

Method: UR2采用难度感知课程训练和混合知识访问策略，动态协调检索与推理。

Result: 实验显示UR2在多个任务上显著优于现有方法，性能接近GPT-4o-mini和GPT-4.1-mini。

Conclusion: UR2成功统一了检索与推理，提升了任务适应性，代码和模型已开源。

Abstract: Large Language Models (LLMs) have shown remarkable capabilities through two
complementary paradigms: Retrieval-Augmented Generation (RAG), which enhances
knowledge grounding, and Reinforcement Learning from Verifiable Rewards (RLVR),
which optimizes complex reasoning abilities. However, these two capabilities
are often developed in isolation, and existing efforts to unify them remain
narrow in scope-typically limited to open-domain QA with fixed retrieval
settings and task-specific assumptions. This lack of integration constrains
generalization and limits the applicability of RAG-RL methods to broader
domains. To bridge this gap, we propose UR2 (Unified RAG and Reasoning), a
general framework that unifies retrieval and reasoning through reinforcement
learning. UR2 introduces two key contributions: a difficulty-aware curriculum
training that selectively invokes retrieval only for challenging problems, and
a hybrid knowledge access strategy combining domain-specific offline corpora
with LLM-generated summaries. These components are designed to enable dynamic
coordination between retrieval and reasoning, improving adaptability across a
diverse range of tasks. Experiments across open-domain QA, MMLU-Pro, medical,
and mathematical reasoning tasks demonstrate that UR2 (built on Qwen2.5-3/7B
and LLaMA-3.1-8B) significantly outperforms existing RAG and RL methods,
achieving comparable performance to GPT-4o-mini and GPT-4.1-mini on several
benchmarks. We have released all code, models, and data at
https://github.com/Tsinghua-dhy/UR2.

</details>


### [52] [Pragmatics beyond humans: meaning, communication, and LLMs](https://arxiv.org/abs/2508.06167)
*Vít Gvoždiak*

Main category: cs.CL

TL;DR: 论文重新定义语用学为动态接口，探讨LLM对传统语用理论的挑战，提出HMC框架和概率语用学，强调需调整理论以适应生成AI的通信。


<details>
  <summary>Details</summary>
Motivation: 传统语用学基于人类假设，不适用于LLM等预测系统，需重新思考语用理论以适应人机交互。

Method: 挑战传统符号三分法，提出HMC框架；分析概率语用学（如RSA框架）的适用性；探讨替代主义问题及语境挫折现象。

Result: LLM动摇了传统意义层级，概率语用学更适用；语境挫折揭示了人机交互中的矛盾。

Conclusion: 语用理论需调整以涵盖生成AI的通信，强调人机共构语用条件的重要性。

Abstract: The paper reconceptualizes pragmatics not as a subordinate, third dimension
of meaning, but as a dynamic interface through which language operates as a
socially embedded tool for action. With the emergence of large language models
(LLMs) in communicative contexts, this understanding needs to be further
refined and methodologically reconsidered. The first section challenges the
traditional semiotic trichotomy, arguing that connectionist LLM architectures
destabilize established hierarchies of meaning, and proposes the Human-Machine
Communication (HMC) framework as a more suitable alternative. The second
section examines the tension between human-centred pragmatic theories and the
machine-centred nature of LLMs. While traditional, Gricean-inspired pragmatics
continue to dominate, it relies on human-specific assumptions ill-suited to
predictive systems like LLMs. Probabilistic pragmatics, particularly the
Rational Speech Act framework, offers a more compatible teleology by focusing
on optimization rather than truth-evaluation. The third section addresses the
issue of substitutionalism in three forms - generalizing, linguistic, and
communicative - highlighting the anthropomorphic biases that distort LLM
evaluation and obscure the role of human communicative subjects. Finally, the
paper introduces the concept of context frustration to describe the paradox of
increased contextual input paired with a collapse in contextual understanding,
emphasizing how users are compelled to co-construct pragmatic conditions both
for the model and themselves. These arguments suggest that pragmatic theory may
need to be adjusted or expanded to better account for communication involving
generative AI.

</details>


### [53] [Comparing Knowledge Injection Methods for LLMs in a Low-Resource Regime](https://arxiv.org/abs/2508.06178)
*Hugo Abonizio,Thales Almeida,Roberto Lotufo,Rodrigo Nogueira*

Main category: cs.CL

TL;DR: 研究探讨了如何向大语言模型（LLM）注入少量非结构化信息，并分析了与灾难性遗忘现象的关系。通过实验发现，多样化的文本变体能显著提升新知识学习能力，而基于检索增强生成（RAG）的方法在知识注入时可能导致更大退化。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在少量数据下更新知识的挑战，并研究灾难性遗忘现象。

Method: 使用新闻数据集评估知识获取能力，探索不同数据增强算法生成合成数据以改进学习。

Result: 有限数据下的继续预训练效果有限，而多样化文本变体显著提升学习能力；RAG方法在知识注入时表现敏感。

Conclusion: 模型能生成有效的合成训练数据，为有限数据下的高效知识注入提供了新途径。

Abstract: Large language models (LLMs) often require vast amounts of text to
effectively acquire new knowledge. While continuing pre-training on large
corpora or employing retrieval-augmented generation (RAG) has proven
successful, updating an LLM with only a few thousand or million tokens remains
challenging. In this work, we investigate the task of injecting small,
unstructured information into LLMs and its relation to the catastrophic
forgetting phenomenon. We use a dataset of recent news -- ensuring no overlap
with the model's pre-training data -- to evaluate the knowledge acquisition by
probing the model with question-answer pairs related the learned information.
Starting from a continued pre-training baseline, we explored different
augmentation algorithms to generate synthetic data to improve the knowledge
acquisition capabilities. Our experiments show that simply continuing
pre-training on limited data yields modest improvements, whereas exposing the
model to diverse textual variations significantly improves the learning of new
facts -- particularly with methods that induce greater variability through
diverse prompting. Furthermore, we shed light on the forgetting phenomenon in
small-data regimes, illustrating the delicate balance between learning new
content and retaining existing capabilities. We also confirm the sensitivity of
RAG-based approaches for knowledge injection, which often lead to greater
degradation on control datasets compared to parametric methods. Finally, we
demonstrate that models can generate effective synthetic training data
themselves, suggesting a pathway toward self-improving model updates. All code
and generated data used in our experiments are publicly available, providing a
resource for studying efficient knowledge injection in LLMs with limited data
at https://github.com/hugoabonizio/knowledge-injection-methods.

</details>


### [54] [DKG-LLM : A Framework for Medical Diagnosis and Personalized Treatment Recommendations via Dynamic Knowledge Graph and Large Language Model Integration](https://arxiv.org/abs/2508.06186)
*Ali Sarabadani,Maryam Abdollahi Shamami,Hamidreza Sadeghsalehi,Borhan Asadi,Saba Hesaraki*

Main category: cs.CL

TL;DR: DKG-LLM框架通过结合动态知识图谱和大型语言模型，提出了一种创新的医疗诊断和个性化治疗推荐方法，显著提升了诊断和治疗推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在自然语言理解方面取得了显著进展，但在医疗领域的应用仍面临数据异构性和复杂性的挑战。DKG-LLM旨在通过动态知识图谱和自适应语义融合算法解决这些问题。

Method: DKG-LLM框架结合动态知识图谱（DKG）和Grok 3大型语言模型，利用自适应语义融合算法（ASFA）处理异构医疗数据，动态更新知识图谱。

Result: DKG-LLM在诊断准确性（84.19%）、治疗推荐准确性（89.63%）和语义覆盖率（93.48%）方面表现出色。

Conclusion: DKG-LLM是一种可靠且具有变革性的工具，能够处理噪声数据和复杂多症状疾病，并通过医生反馈进行学习。

Abstract: Large Language Models (LLMs) have grown exponentially since the release of
ChatGPT. These models have gained attention due to their robust performance on
various tasks, including language processing tasks. These models achieve
understanding and comprehension of tasks by training billions of parameters.
The development of these models is a transformative force in enhancing natural
language understanding and has taken a significant step towards artificial
general intelligence (AGI). In this study, we aim to present the DKG-LLM
framework. The DKG-LLM framework introduces a groundbreaking approach to
medical diagnosis and personalized treatment recommendations by integrating a
dynamic knowledge graph (DKG) with the Grok 3 large language model. Using the
Adaptive Semantic Fusion Algorithm (ASFA), heterogeneous medical data
(including clinical reports and PubMed articles) and patient records
dynamically generate a knowledge graph consisting of 15,964 nodes in 13
distinct types (e.g., diseases, symptoms, treatments, patient profiles) and
127,392 edges in 26 relationship types (e.g., causal, therapeutic,
association). ASFA utilizes advanced probabilistic models, Bayesian inference,
and graph optimization to extract semantic information, dynamically updating
the graph with approximately 150 new nodes and edges in each data category
while maintaining scalability with up to 987,654 edges. Real-world datasets,
including MIMIC-III and PubMed, were utilized to evaluate the proposed
architecture. The evaluation results show that DKG-LLM achieves a diagnostic
accuracy of 84.19%. The model also has a treatment recommendation accuracy of
89.63% and a semantic coverage of 93.48%. DKG-LLM is a reliable and
transformative tool that handles noisy data and complex multi-symptom diseases,
along with feedback-based learning from physician input.

</details>


### [55] [Beyond Uniform Criteria: Scenario-Adaptive Multi-Dimensional Jailbreak Evaluation](https://arxiv.org/abs/2508.06194)
*Lai Jiang,Yuekang Li,Xiaohan Zhang,Youtao Ding,Li Pan*

Main category: cs.CL

TL;DR: SceneJailEval提出了一种场景自适应的多维度框架，用于精确评估LLM的越狱行为，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在越狱评估中仅提供二元分类或统一的多维度标准，无法量化危害强度或适应不同场景，导致评估精度不足。

Method: 提出场景自适应的多维度框架SceneJailEval，并构建了一个包含14个场景的数据集，支持灵活扩展。

Result: SceneJailEval在全面场景数据集上F1得分为0.917（比之前最佳提升6%），在JBB上为0.995（提升3%），表现优于现有方法。

Conclusion: SceneJailEval通过场景自适应框架和高质量数据集，显著提升了越狱评估的精确性和适应性。

Abstract: Precise jailbreak evaluation is vital for LLM red teaming and jailbreak
research. Current approaches employ binary classification ( e.g., string
matching, toxic text classifiers, LLM-driven methods), yielding only "yes/no"
labels without quantifying harm intensity. Existing multi-dimensional
frameworks ( e.g., Security Violation, Relative Truthfulness, Informativeness)
apply uniform evaluation criteria across scenarios, resulting in
scenario-specific mismatches--for instance, "Relative Truthfulness" is
irrelevant to "hate speech"--which compromise evaluation precision. To tackle
these limitations, we introduce SceneJailEval, with key contributions: (1) A
groundbreaking scenario-adaptive multi-dimensional framework for jailbreak
evaluation, overcoming the critical "one-size-fits-all" constraint of existing
multi-dimensional methods, and featuring strong extensibility to flexibly adapt
to customized or emerging scenarios. (2) A comprehensive 14-scenario dataset
with diverse jailbreak variants and regional cases, filling the long-standing
gap in high-quality, holistic benchmarks for scenario-adaptive evaluation. (3)
SceneJailEval achieves state-of-the-art results, with an F1 score of 0.917 on
our full-scenario dataset (+6% over prior SOTA) and 0.995 on JBB (+3% over
prior SOTA), surpassing accuracy limits of existing evaluation methods in
heterogeneous scenarios and confirming its advantage.

</details>


### [56] [EICAP: Deep Dive in Assessment and Enhancement of Large Language Models in Emotional Intelligence through Multi-Turn Conversations](https://arxiv.org/abs/2508.06196)
*Nizi Nazar,Ehsaneddin Asgari*

Main category: cs.CL

TL;DR: 论文提出了一个心理学基础的四层情感智能（EI）分类法，用于评估和提升大型语言模型（LLMs）的情感智能能力，并通过实验验证了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 情感智能（EI）在人类对齐的LLMs开发中是一个重要但未被充分探索的维度，研究旨在填补这一空白。

Method: 提出了一个四层EI分类法，并开发了EICAP-Bench基准测试，评估了六种LLMs，并通过LoRA适配器对Qwen2.5模型进行了微调。

Result: Qwen2.5-Instruct表现最佳，但微调仅显著提升了Appraisal层的能力，揭示了现有方法的局限性。

Conclusion: 现有预训练和指令调优范式在提升LLMs情感推理能力上存在不足，需要针对性的数据和建模策略。

Abstract: Emotional Intelligence (EI) is a critical yet underexplored dimension in the
development of human-aligned LLMs. To address this gap, we introduce a unified,
psychologically grounded four-layer taxonomy of EI tailored for large language
models (LLMs), encompassing emotional tracking, cause inference, appraisal, and
emotionally appropriate response generation. Building on this framework, we
present EICAP-Bench, a novel MCQ style multi-turn benchmark designed to
evaluate EI capabilities in open-source LLMs across diverse linguistic and
cultural contexts. We evaluate six LLMs: LLaMA3 (8B), LLaMA3-Instruct, Gemma
(9B), Gemma-Instruct, Qwen2.5 (7B), and Qwen2.5-Instruct on EmoCap-Bench,
identifying Qwen2.5-Instruct as the strongest baseline. To assess the potential
for enhancing EI capabilities, we fine-tune both Qwen2.5-Base and
Qwen2.5-Instruct using LoRA adapters on UltraChat (UC), a large-scale,
instruction-tuned dialogue dataset, in both English and Arabic. Our statistical
analysis reveals that among the five EI layers, only the Appraisal layer shows
significant improvement through UC-based fine-tuning. These findings highlight
the limitations of existing pretraining and instruction-tuning paradigms in
equipping LLMs with deeper emotional reasoning and underscore the need for
targeted data and modeling strategies for comprehensive EI alignment.

</details>


### [57] [Classification is a RAG problem: A case study on hate speech detection](https://arxiv.org/abs/2508.06204)
*Richard Willats,Josh Pennington,Aravind Mohan,Bertie Vidgen*

Main category: cs.CL

TL;DR: 论文提出了一种基于检索增强生成（RAG）的分类方法，用于内容审核，能够动态适应政策变化而无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 传统分类系统需要频繁重新训练以适应政策变化，成本高昂且效率低。RAG方法通过检索上下文知识，将分类任务转化为政策合规性评估，提高了灵活性和透明度。

Method: 采用检索增强生成（RAG）技术，构建了Contextual Policy Engine（CPE），在推理时检索政策知识以评估内容合规性。

Result: 实验表明，CPE在仇恨言论检测中表现优异，准确率与主流商业系统相当，且能动态更新政策而不影响性能。

Conclusion: RAG方法使分类任务更灵活、透明和适应性强，适用于内容审核及其他分类问题。

Abstract: Robust content moderation requires classification systems that can quickly
adapt to evolving policies without costly retraining. We present classification
using Retrieval-Augmented Generation (RAG), which shifts traditional
classification tasks from determining the correct category in accordance with
pre-trained parameters to evaluating content in relation to contextual
knowledge retrieved at inference. In hate speech detection, this transforms the
task from "is this hate speech?" to "does this violate the hate speech policy?"
  Our Contextual Policy Engine (CPE) - an agentic RAG system - demonstrates
this approach and offers three key advantages: (1) robust classification
accuracy comparable to leading commercial systems, (2) inherent explainability
via retrieved policy segments, and (3) dynamic policy updates without model
retraining. Through three experiments, we demonstrate strong baseline
performance and show that the system can apply fine-grained policy control by
correctly adjusting protection for specific identity groups without requiring
retraining or compromising overall performance. These findings establish that
RAG can transform classification into a more flexible, transparent, and
adaptable process for content moderation and wider classification problems.

</details>


### [58] [InfoCausalQA:Can Models Perform Non-explicit Causal Reasoning Based on Infographic?](https://arxiv.org/abs/2508.06220)
*Keummin Ka,Junhyeong Park,Jahyun Jeon,Youngjae Yu*

Main category: cs.CL

TL;DR: InfoCausalQA是一个新的基准测试，用于评估基于信息图的因果推理能力，发现当前视觉语言模型在计算和语义因果推理上表现有限。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在因果推理方面的能力，填补多模态环境中这一核心认知能力的空白。

Method: 构建InfoCausalQA基准，包含定量和语义因果推理任务，使用GPT-4生成问题并人工修订。

Result: 当前模型在计算和语义因果推理上表现较差，与人类能力差距显著。

Conclusion: 需要提升多模态AI系统的因果推理能力。

Abstract: Recent advances in Vision-Language Models (VLMs) have demonstrated impressive
capabilities in perception and reasoning. However, the ability to perform
causal inference -- a core aspect of human cognition -- remains underexplored,
particularly in multimodal settings. In this study, we introduce InfoCausalQA,
a novel benchmark designed to evaluate causal reasoning grounded in
infographics that combine structured visual data with textual context. The
benchmark comprises two tasks: Task 1 focuses on quantitative causal reasoning
based on inferred numerical trends, while Task 2 targets semantic causal
reasoning involving five types of causal relations: cause, effect,
intervention, counterfactual, and temporal. We manually collected 494
infographic-text pairs from four public sources and used GPT-4o to generate
1,482 high-quality multiple-choice QA pairs. These questions were then
carefully revised by humans to ensure they cannot be answered based on
surface-level cues alone but instead require genuine visual grounding. Our
experimental results reveal that current VLMs exhibit limited capability in
computational reasoning and even more pronounced limitations in semantic causal
reasoning. Their significantly lower performance compared to humans indicates a
substantial gap in leveraging infographic-based information for causal
inference. Through InfoCausalQA, we highlight the need for advancing the causal
reasoning abilities of multimodal AI systems.

</details>


### [59] [Large Language Model Data Generation for Enhanced Intent Recognition in German Speech](https://arxiv.org/abs/2508.06277)
*Theresa Pekarek Rosin,Burak Can Kaplan,Stefan Wermter*

Main category: cs.CL

TL;DR: 本文提出了一种结合Whisper ASR模型和Transformer语言模型的方法，用于德语老年人的语音意图识别，利用合成数据提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有意图识别方法局限于短命令和英语的问题，专注于德语老年人的语音识别。

Method: 结合Whisper ASR模型和Transformer语言模型，利用LLM生成合成数据。

Result: 合成数据显著提升分类性能和鲁棒性，小规模LLM（LeoLM）表现优于大规模LLM（ChatGPT）。

Conclusion: 生成式AI可有效填补低资源领域的数据缺口，方法透明且可复现。

Abstract: Intent recognition (IR) for speech commands is essential for artificial
intelligence (AI) assistant systems; however, most existing approaches are
limited to short commands and are predominantly developed for English. This
paper addresses these limitations by focusing on IR from speech by elderly
German speakers. We propose a novel approach that combines an adapted Whisper
ASR model, fine-tuned on elderly German speech (SVC-de), with Transformer-based
language models trained on synthetic text datasets generated by three
well-known large language models (LLMs): LeoLM, Llama3, and ChatGPT. To
evaluate the robustness of our approach, we generate synthetic speech with a
text-to-speech model and conduct extensive cross-dataset testing. Our results
show that synthetic LLM-generated data significantly boosts classification
performance and robustness to different speaking styles and unseen vocabulary.
Notably, we find that LeoLM, a smaller, domain-specific 13B LLM, surpasses the
much larger ChatGPT (175B) in dataset quality for German intent recognition.
Our approach demonstrates that generative AI can effectively bridge data gaps
in low-resource domains. We provide detailed documentation of our data
generation and training process to ensure transparency and reproducibility.

</details>


### [60] [Matrix-Driven Instant Review: Confident Detection and Reconstruction of LLM Plagiarism on PC](https://arxiv.org/abs/2508.06309)
*Ruichong Zhang*

Main category: cs.CL

TL;DR: MDIR是一种基于矩阵分析和大偏差理论的新方法，用于检测大型语言模型（LLM）的抄袭行为，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 近年来，大型语言模型（LLM）的知识产权（IP）问题日益突出，现有抄袭检测方法在权重对应重建、统计显著性计算等方面存在不足。

Method: 提出Matrix-Driven Instant Review（MDIR），利用矩阵分析和大偏差理论，准确重建权重关系并提供严格的p值估计。

Result: 实验表明，MDIR即使在模型经过随机排列或持续预训练等复杂变换后，仍能可靠检测抄袭，且检测过程高效。

Conclusion: MDIR是一种高效、准确的LLM抄袭检测方法，适用于实际应用。

Abstract: In recent years, concerns about intellectual property (IP) in large language
models (LLMs) have grown significantly. Plagiarizing other LLMs (through direct
weight copying, upcycling, pruning, or continual pretraining) and claiming
authorship without properly attributing to the original license, is a serious
misconduct that can lead to significant financial and reputational harm to the
original developers. However, existing methods for detecting LLM plagiarism
fall short in key areas. They fail to accurately reconstruct weight
correspondences, lack the ability to compute statistical significance measures
such as $p$-values, and may mistakenly flag models trained on similar data as
being related. To address these limitations, we propose Matrix-Driven Instant
Review (MDIR), a novel method that leverages matrix analysis and Large
Deviation Theory. MDIR achieves accurate reconstruction of weight
relationships, provides rigorous $p$-value estimation, and focuses exclusively
on weight similarity without requiring full model inference. Experimental
results demonstrate that MDIR reliably detects plagiarism even after extensive
transformations, such as random permutations and continual pretraining with
trillions of tokens. Moreover, all detections can be performed on a single PC
within an hour, making MDIR both efficient and accessible.

</details>


### [61] [Harnessing Adaptive Topology Representations for Zero-Shot Graph Question Answering](https://arxiv.org/abs/2508.06345)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James T. Kwok,Yu Zhang*

Main category: cs.CL

TL;DR: 论文提出DynamicTRF框架，通过动态选择适合的图表示形式（TRF）提升多模态模型在零样本图问答任务中的准确性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用单一图表示形式（TRF），无法适应不同模型或任务的需求，导致回答错误或冗长。

Method: 设计TRF集合$F_{ZS}$，提出Graph Response Efficiency（GRE）指标，开发DynamicTRF框架，包括TRF Preference数据集和TRF路由器。

Result: 在7个领域内算法图QA任务和2个领域外任务中，DynamicTRF显著提升了零样本图QA的准确性。

Conclusion: DynamicTRF通过动态选择TRF，有效提升了多模态模型在图问答任务中的表现。

Abstract: Large Multimodal Models (LMMs) have shown generalized zero-shot capabilities
in diverse domain question-answering (QA) tasks, including graph QA that
involves complex graph topologies. However, most current approaches use only a
single type of graph representation, namely Topology Representation Form (TRF),
such as prompt-unified text descriptions or style-fixed visual styles. Those
"one-size-fits-all" approaches fail to consider the specific preferences of
different models or tasks, often leading to incorrect or overly long responses.
To address this, we first analyze the characteristics and weaknesses of
existing TRFs, and then design a set of TRFs, denoted by $F_{ZS}$, tailored to
zero-shot graph QA. We then introduce a new metric, Graph Response Efficiency
(GRE), which measures the balance between the performance and the brevity in
graph QA. Built on these, we develop the DynamicTRF framework, which aims to
improve both the accuracy and conciseness of graph QA. To be specific,
DynamicTRF first creates a TRF Preference (TRFP) dataset that ranks TRFs based
on their GRE scores, to probe the question-specific TRF preferences. Then it
trains a TRF router on the TRFP dataset, to adaptively assign the best TRF from
$F_{ZS}$ for each question during the inference. Extensive experiments across 7
in-domain algorithmic graph QA tasks and 2 out-of-domain downstream tasks show
that DynamicTRF significantly enhances the zero-shot graph QA of LMMs in terms
of accuracy

</details>


### [62] [Cyberbullying Detection via Aggression-Enhanced Prompting](https://arxiv.org/abs/2508.06360)
*Aisha Saeid,Anu Sabu,Girish A. Koushik,Ferrante Neri,Diptesh Kanojia*

Main category: cs.CL

TL;DR: 研究探讨了通过将攻击性检测作为辅助任务，提升大语言模型在社交媒体网络欺凌检测中的性能。实验表明，基于攻击性预测的提示增强方法优于标准微调。


<details>
  <summary>Details</summary>
Motivation: 网络欺凌检测因表达形式多样且隐蔽而具有挑战性，研究旨在通过辅助任务提升模型性能。

Method: 采用指令调优的大语言模型，评估零样本、少样本、独立LoRA微调和多任务学习策略，并提出基于攻击性预测的提示增强方法。

Result: 提示增强方法在性能上优于标准LoRA微调，表明攻击性信息能显著提升检测效果。

Conclusion: 辅助任务（如攻击性检测）可提升大语言模型在安全关键应用中的泛化能力。

Abstract: Detecting cyberbullying on social media remains a critical challenge due to
its subtle and varied expressions. This study investigates whether integrating
aggression detection as an auxiliary task within a unified training framework
can enhance the generalisation and performance of large language models (LLMs)
in cyberbullying detection. Experiments are conducted on five aggression
datasets and one cyberbullying dataset using instruction-tuned LLMs. We
evaluated multiple strategies: zero-shot, few-shot, independent LoRA
fine-tuning, and multi-task learning (MTL). Given the inconsistent results of
MTL, we propose an enriched prompt pipeline approach in which aggression
predictions are embedded into cyberbullying detection prompts to provide
contextual augmentation. Preliminary results show that the enriched prompt
pipeline consistently outperforms standard LoRA fine-tuning, indicating that
aggression-informed context significantly boosts cyberbullying detection. This
study highlights the potential of auxiliary tasks, such as aggression
detection, to improve the generalisation of LLMs for safety-critical
applications on social networks.

</details>


### [63] [Evaluating Style-Personalized Text Generation: Challenges and Directions](https://arxiv.org/abs/2508.06374)
*Anubhav Jangra,Bahareh Sarrafzadeh,Adrian de Wynter,Silviu Cucerzan,Sujay Kumar Jauhar*

Main category: cs.CL

TL;DR: 论文探讨了低资源作者风格个性化文本生成中的评估问题，质疑BLEU和ROUGE等常用指标的有效性，并提出使用风格嵌入和LLM-as-judge等新评估范式。


<details>
  <summary>Details</summary>
Motivation: 现有研究在低资源作者风格个性化文本生成领域的评估探索有限，需要更全面的评估方法。

Method: 通过风格判别基准（涵盖八种写作任务和三种设置）评估多种指标及其组合。

Result: 证明采用多样化评估指标组合能更有效地评估风格个性化文本生成。

Conclusion: 建议采用多样化的评估指标组合来全面评估风格个性化文本生成任务。

Abstract: While prior research has built tools and benchmarks towards style
personalized text generation, there has been limited exploration of evaluation
in low-resource author style personalized text generation space. Through this
work, we question the effectiveness of the widely adopted evaluation metrics
like BLEU and ROUGE, and explore other evaluation paradigms such as style
embeddings and LLM-as-judge to holistically evaluate the style personalized
text generation task. We evaluate these metrics and their ensembles using our
style discrimination benchmark, that spans eight writing tasks, and evaluates
across three settings, domain discrimination, authorship attribution, and LLM
personalized vs non-personalized discrimination. We provide conclusive evidence
to adopt ensemble of diverse evaluation metrics to effectively evaluate style
personalized text generation.

</details>


### [64] [LLMs vs. Chinese Anime Enthusiasts: A Comparative Study on Emotionally Supportive Role-Playing](https://arxiv.org/abs/2508.06388)
*Lanlan Qiu,Xiao Pu,Yeqi Feng,Tianxing He*

Main category: cs.CL

TL;DR: 论文研究了如何结合大型语言模型（LLMs）的角色扮演和情感支持能力，通过动漫角色案例创建了ChatAnime数据集，评估了LLMs在情感支持角色扮演（ESRP）中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有研究未将LLMs的角色扮演和情感支持能力结合，论文旨在填补这一空白，探索LLMs在虚拟角色情感支持中的潜力。

Method: 选择20个热门动漫角色，设计60个情感场景问题，收集40名动漫爱好者和10个LLMs的对话数据，并通过用户导向的评估系统分析。

Result: 实验表明，表现最佳的LLMs在角色扮演和情感支持上超越人类，但人类在回答多样性上仍占优。

Conclusion: ChatAnime数据集为未来优化LLMs在ESRP中的研究提供了资源和见解。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in
role-playing conversations and providing emotional support as separate research
directions. However, there remains a significant research gap in combining
these capabilities to enable emotionally supportive interactions with virtual
characters. To address this research gap, we focus on anime characters as a
case study because of their well-defined personalities and large fan bases.
This choice enables us to effectively evaluate how well LLMs can provide
emotional support while maintaining specific character traits. We introduce
ChatAnime, the first Emotionally Supportive Role-Playing (ESRP) dataset. We
first thoughtfully select 20 top-tier characters from popular anime communities
and design 60 emotion-centric real-world scenario questions. Then, we execute a
nationwide selection process to identify 40 Chinese anime enthusiasts with
profound knowledge of specific characters and extensive experience in
role-playing. Next, we systematically collect two rounds of dialogue data from
10 LLMs and these 40 Chinese anime enthusiasts. To evaluate the ESRP
performance of LLMs, we design a user experience-oriented evaluation system
featuring 9 fine-grained metrics across three dimensions: basic dialogue,
role-playing and emotional support, along with an overall metric for response
diversity. In total, the dataset comprises 2,400 human-written and 24,000
LLM-generated answers, supported by over 132,000 human annotations.
Experimental results show that top-performing LLMs surpass human fans in
role-playing and emotional support, while humans still lead in response
diversity. We hope this work can provide valuable resources and insights for
future research on optimizing LLMs in ESRP. Our datasets are available at
https://github.com/LanlanQiu/ChatAnime.

</details>


### [65] [Quantifying Conversation Drift in MCP via Latent Polytope](https://arxiv.org/abs/2508.06418)
*Haoran Shi,Hongwei Yao,Shuo Shao,Shaopeng Jiao,Ziqi Peng,Zhan Qin,Cong Wang*

Main category: cs.CL

TL;DR: SecMCP是一个安全框架，用于检测和量化由外部知识引起的对话偏移，提升LLM的安全性。


<details>
  <summary>Details</summary>
Motivation: MCP在增强LLM的同时引入了安全和隐私风险，现有防御措施不足。

Method: 通过建模LLM激活向量在潜在多面体空间中，检测对话动态的异常偏移。

Result: 在多个LLM和数据集上验证，AUROC得分超过0.915，同时保持系统可用性。

Conclusion: SecMCP有效解决了MCP的安全威胁，并提供了新的量化方法。

Abstract: The Model Context Protocol (MCP) enhances large language models (LLMs) by
integrating external tools, enabling dynamic aggregation of real-time data to
improve task execution. However, its non-isolated execution context introduces
critical security and privacy risks. In particular, adversarially crafted
content can induce tool poisoning or indirect prompt injection, leading to
conversation hijacking, misinformation propagation, or data exfiltration.
Existing defenses, such as rule-based filters or LLM-driven detection, remain
inadequate due to their reliance on static signatures, computational
inefficiency, and inability to quantify conversational hijacking. To address
these limitations, we propose SecMCP, a secure framework that detects and
quantifies conversation drift, deviations in latent space trajectories induced
by adversarial external knowledge. By modeling LLM activation vectors within a
latent polytope space, SecMCP identifies anomalous shifts in conversational
dynamics, enabling proactive detection of hijacking, misleading, and data
exfiltration. We evaluate SecMCP on three state-of-the-art LLMs (Llama3,
Vicuna, Mistral) across benchmark datasets (MS MARCO, HotpotQA, FinQA),
demonstrating robust detection with AUROC scores exceeding 0.915 while
maintaining system usability. Our contributions include a systematic
categorization of MCP security threats, a novel latent polytope-based
methodology for quantifying conversation drift, and empirical validation of
SecMCP's efficacy.

</details>


### [66] [Memp: Exploring Agent Procedural Memory](https://arxiv.org/abs/2508.06433)
*Runnan Fang,Yuan Liang,Xiaobin Wang,Jialong Wu,Shuofei Qiao,Pengjun Xie,Fei Huang,Huajun Chen,Ningyu Zhang*

Main category: cs.CL

TL;DR: 论文提出Memp方法，通过提炼代理轨迹为细粒度指令和高级脚本抽象，赋予代理可学习、可更新的终身程序记忆，并在实验中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）代理在处理多样化任务时表现出色，但其程序记忆脆弱，依赖手工设计或静态参数。研究旨在解决这一问题。

Method: 提出Memp方法，将代理轨迹提炼为细粒度指令和高级脚本抽象，并探索构建、检索和更新程序记忆的策略。

Result: 实验表明，随着记忆库的优化，代理在类似任务中的成功率和效率稳步提升；强模型构建的程序记忆迁移到弱模型时仍能显著提升性能。

Conclusion: Memp方法通过动态更新和优化程序记忆，显著提升了代理的任务表现和适应性。

Abstract: Large Language Models (LLMs) based agents excel at diverse tasks, yet they
suffer from brittle procedural memory that is manually engineered or entangled
in static parameters. In this work, we investigate strategies to endow agents
with a learnable, updatable, and lifelong procedural memory. We propose Memp
that distills past agent trajectories into both fine-grained, step-by-step
instructions and higher-level, script-like abstractions, and explore the impact
of different strategies for Build, Retrieval, and Update of procedural memory.
Coupled with a dynamic regimen that continuously updates, corrects, and
deprecates its contents, this repository evolves in lockstep with new
experience. Empirical evaluation on TravelPlanner and ALFWorld shows that as
the memory repository is refined, agents achieve steadily higher success rates
and greater efficiency on analogous tasks. Moreover, procedural memory built
from a stronger model retains its value: migrating the procedural memory to a
weaker model yields substantial performance gains.

</details>


### [67] [Learning the Topic, Not the Language: How LLMs Classify Online Immigration Discourse Across Languages](https://arxiv.org/abs/2508.06435)
*Andrea Nasuto,Stefano Maria Iacus,Francisco Rowe,Devika Jain*

Main category: cs.CL

TL;DR: 研究表明，轻量级LLaMA模型通过少量语言微调即可实现跨语言主题检测，且多语言微调有助于立场分类。预训练偏见可通过少量干预纠正，模型开源且高效。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在少量语言微调后能否将知识迁移到未见语言，并纠正预训练中的语言偏见。

Method: 在单语、双语或多语数据集上微调LLaMA模型，用于13种语言的移民相关推文分类。

Result: 单语或双语微调模型可可靠分类未见语言内容，多语言微调提升立场分类效果；少量干预可纠正偏见。

Conclusion: 跨语言能力无需大量多语言训练，轻量干预可纠正偏见，开源模型高效且经济。

Abstract: Large language models (LLMs) are transforming social-science research by
enabling scalable, precise analysis. Their adaptability raises the question of
whether knowledge acquired through fine-tuning in a few languages can transfer
to unseen languages that only appeared during pre-training. To examine this, we
fine-tune lightweight LLaMA 3.2-3B models on monolingual, bilingual, or
multilingual data sets to classify immigration-related tweets from X/Twitter
across 13 languages, a domain characterised by polarised, culturally specific
discourse. We evaluate whether minimal language-specific fine-tuning enables
cross-lingual topic detection and whether adding targeted languages corrects
pre-training biases. Results show that LLMs fine-tuned in one or two languages
can reliably classify immigration-related content in unseen languages. However,
identifying whether a tweet expresses a pro- or anti-immigration stance
benefits from multilingual fine-tuning. Pre-training bias favours dominant
languages, but even minimal exposure to under-represented languages during
fine-tuning (as little as $9.62\times10^{-11}$ of the original pre-training
token volume) yields significant gains. These findings challenge the assumption
that cross-lingual mastery requires extensive multilingual training: limited
language coverage suffices for topic-level generalisation, and structural
biases can be corrected with lightweight interventions. By releasing
4-bit-quantised, LoRA fine-tuned models, we provide an open-source,
reproducible alternative to proprietary LLMs that delivers 35 times faster
inference at just 0.00000989% of the dollar cost of the OpenAI GPT-4o model,
enabling scalable, inclusive research.

</details>


### [68] [Echoes of Automation: The Increasing Use of LLMs in Newsmaking](https://arxiv.org/abs/2508.06445)
*Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee*

Main category: cs.CL

TL;DR: 研究发现，生成式AI（尤其是LLMs）在新闻写作中的使用显著增加，特别是在地方和大学新闻中，AI多用于文章开头，而结论多为人工撰写。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI对新闻行业诚信和作者身份的潜在影响。

Method: 分析了40,000多篇新闻文章，使用三种AI文本检测工具（Binoculars、Fast-Detect GPT、GPTZero）。

Result: AI使用量近年大幅增加，提升了词汇丰富度和可读性，但降低了正式性，导致写作风格趋同。

Conclusion: 生成式AI在新闻写作中的应用日益普遍，需关注其对新闻多样性和质量的影响。

Abstract: The rapid rise of Generative AI (GenAI), particularly LLMs, poses concerns
for journalistic integrity and authorship. This study examines AI-generated
content across over 40,000 news articles from major, local, and college news
media, in various media formats. Using three advanced AI-text detectors (e.g.,
Binoculars, Fast-Detect GPT, and GPTZero), we find substantial increase of
GenAI use in recent years, especially in local and college news. Sentence-level
analysis reveals LLMs are often used in the introduction of news, while
conclusions usually written manually. Linguistic analysis shows GenAI boosts
word richness and readability but lowers formality, leading to more uniform
writing styles, particularly in local media.

</details>


### [69] [SlimInfer: Accelerating Long-Context LLM Inference via Dynamic Token Pruning](https://arxiv.org/abs/2508.06447)
*Lingkun Long,Rubing Yang,Yushi Huang,Desheng Hui,Ao Zhou,Jianlei Yang*

Main category: cs.CL

TL;DR: SlimInfer通过动态剪枝关键提示令牌加速LLM推理，减少计算需求，提升效率。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理对LLM计算需求高，现有方法效率不足。

Method: 提出SlimInfer框架，动态剪枝隐藏状态中的冗余令牌，利用信息扩散现象。

Result: 实验显示TTFT加速2.53倍，端到端延迟降低1.88倍，性能无损。

Conclusion: SlimInfer高效加速LLM推理，适用于长上下文任务。

Abstract: Long-context inference for Large Language Models (LLMs) is heavily limited by
high computational demands. While several existing methods optimize attention
computation, they still process the full set of hidden states at each layer,
limiting overall efficiency. In this work, we propose SlimInfer, an innovative
framework that aims to accelerate inference by directly pruning less critical
prompt tokens during the forward pass. Our key insight is an information
diffusion phenomenon: As information from critical tokens propagates through
layers, it becomes distributed across the entire sequence. This diffusion
process suggests that LLMs can maintain their semantic integrity when excessive
tokens, even including these critical ones, are pruned in hidden states.
Motivated by this, SlimInfer introduces a dynamic fine-grained pruning
mechanism that accurately removes redundant tokens of hidden state at
intermediate layers. This layer-wise pruning naturally enables an asynchronous
KV cache manager that prefetches required token blocks without complex
predictors, reducing both memory usage and I/O costs. Extensive experiments
show that SlimInfer can achieve up to $\mathbf{2.53\times}$ time-to-first-token
(TTFT) speedup and $\mathbf{1.88\times}$ end-to-end latency reduction for
LLaMA3.1-8B-Instruct on a single RTX 4090, without sacrificing performance on
LongBench. Our code will be released upon acceptance.

</details>


### [70] [GLM-4.5: Agentic, Reasoning, and Coding (ARC) Foundation Models](https://arxiv.org/abs/2508.06471)
*GLM-4. 5 Team,:,Aohan Zeng,Xin Lv,Qinkai Zheng,Zhenyu Hou,Bin Chen,Chengxing Xie,Cunxiang Wang,Da Yin,Hao Zeng,Jiajie Zhang,Kedong Wang,Lucen Zhong,Mingdao Liu,Rui Lu,Shulin Cao,Xiaohan Zhang,Xuancheng Huang,Yao Wei,Yean Cheng,Yifan An,Yilin Niu,Yuanhao Wen,Yushi Bai,Zhengxiao Du,Zihan Wang,Zilin Zhu,Bohan Zhang,Bosi Wen,Bowen Wu,Bowen Xu,Can Huang,Casey Zhao,Changpeng Cai,Chao Yu,Chen Li,Chendi Ge,Chenghua Huang,Chenhui Zhang,Chenxi Xu,Chenzheng Zhu,Chuang Li,Congfeng Yin,Daoyan Lin,Dayong Yang,Dazhi Jiang,Ding Ai,Erle Zhu,Fei Wang,Gengzheng Pan,Guo Wang,Hailong Sun,Haitao Li,Haiyang Li,Haiyi Hu,Hanyu Zhang,Hao Peng,Hao Tai,Haoke Zhang,Haoran Wang,Haoyu Yang,He Liu,He Zhao,Hongwei Liu,Hongxi Yan,Huan Liu,Huilong Chen,Ji Li,Jiajing Zhao,Jiamin Ren,Jian Jiao,Jiani Zhao,Jianyang Yan,Jiaqi Wang,Jiayi Gui,Jiayue Zhao,Jie Liu,Jijie Li,Jing Li,Jing Lu,Jingsen Wang,Jingwei Yuan,Jingxuan Li,Jingzhao Du,Jinhua Du,Jinxin Liu,Junkai Zhi,Junli Gao,Ke Wang,Lekang Yang,Liang Xu,Lin Fan,Lindong Wu,Lintao Ding,Lu Wang,Man Zhang,Minghao Li,Minghuan Xu,Mingming Zhao,Mingshu Zhai,Pengfan Du,Qian Dong,Shangde Lei,Shangqing Tu,Shangtong Yang,Shaoyou Lu,Shijie Li,Shuang Li,Shuang-Li,Shuxun Yang,Sibo Yi,Tianshu Yu,Wei Tian,Weihan Wang,Wenbo Yu,Weng Lam Tam,Wenjie Liang,Wentao Liu,Xiao Wang,Xiaohan Jia,Xiaotao Gu,Xiaoying Ling,Xin Wang,Xing Fan,Xingru Pan,Xinyuan Zhang,Xinze Zhang,Xiuqing Fu,Xunkai Zhang,Yabo Xu,Yandong Wu,Yida Lu,Yidong Wang,Yilin Zhou,Yiming Pan,Ying Zhang,Yingli Wang,Yingru Li,Yinpei Su,Yipeng Geng,Yitong Zhu,Yongkun Yang,Yuhang Li,Yuhao Wu,Yujiang Li,Yunan Liu,Yunqing Wang,Yuntao Li,Yuxuan Zhang,Zezhen Liu,Zhen Yang,Zhengda Zhou,Zhongpei Qiao,Zhuoer Feng,Zhuorui Liu,Zichen Zhang,Zihan Wang,Zijun Yao,Zikang Wang,Ziqiang Liu,Ziwei Chai,Zixuan Li,Zuodong Zhao,Wenguang Chen,Jidong Zhai,Bin Xu,Minlie Huang,Hongning Wang,Juanzi Li,Yuxiao Dong,Jie Tang*

Main category: cs.CL

TL;DR: GLM-4.5是一个开源的混合专家（MoE）大语言模型，总参数量355B，激活参数量32B，支持混合推理模式。通过多阶段训练和强化学习，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动推理和代理AI系统的研究，提供高效且性能强大的开源模型。

Method: 采用混合专家架构和多阶段训练，结合强化学习优化模型性能。

Result: 在多个基准测试中表现优异，如TAU-Bench（70.1%）、AIME 24（91.0%）和SWE-bench Verified（64.2%），参数量少于竞争对手。

Conclusion: GLM-4.5及其紧凑版GLM-4.5-Air为推理和代理AI研究提供了高效工具，性能显著。

Abstract: We present GLM-4.5, an open-source Mixture-of-Experts (MoE) large language
model with 355B total parameters and 32B activated parameters, featuring a
hybrid reasoning method that supports both thinking and direct response modes.
Through multi-stage training on 23T tokens and comprehensive post-training with
expert model iteration and reinforcement learning, GLM-4.5 achieves strong
performance across agentic, reasoning, and coding (ARC) tasks, scoring 70.1% on
TAU-Bench, 91.0% on AIME 24, and 64.2% on SWE-bench Verified. With much fewer
parameters than several competitors, GLM-4.5 ranks 3rd overall among all
evaluated models and 2nd on agentic benchmarks. We release both GLM-4.5 (355B
parameters) and a compact version, GLM-4.5-Air (106B parameters), to advance
research in reasoning and agentic AI systems. Code, models, and more
information are available at https://github.com/zai-org/GLM-4.5.

</details>


### [71] [HapticLLaMA: A Multimodal Sensory Language Model for Haptic Captioning](https://arxiv.org/abs/2508.06475)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: 论文提出HapticLLaMA，一种多模态语言模型，用于将触觉信号（如振动）转化为自然语言描述，填补了触觉信号研究的空白。


<details>
  <summary>Details</summary>
Motivation: 触觉信号在多模态研究中较少被探索，而其在虚拟现实、无障碍和康复应用中具有潜力。

Method: 提出HapticLLaMA模型，采用频率和EnCodec两种触觉分词器，结合LLaMA架构，分两阶段训练（监督微调和强化学习）。

Result: 模型在METEOR和BLEU-4评分上表现优异，人类评分超过61%高于3.5分，强化学习带来10%的提升。

Conclusion: HapticLLaMA展示了大型语言模型处理感官数据的潜力，为触觉信号的应用提供了新方向。

Abstract: Haptic captioning is the task of generating natural language descriptions
from haptic signals, such as vibrations, for use in virtual reality,
accessibility, and rehabilitation applications. While previous multimodal
research has focused primarily on vision and audio, haptic signals for the
sense of touch remain underexplored. To address this gap, we formalize the
haptic captioning task and propose HapticLLaMA, a multimodal sensory language
model that interprets vibration signals into descriptions in a given sensory,
emotional, or associative category. We investigate two types of haptic
tokenizers, a frequency-based tokenizer and an EnCodec-based tokenizer, that
convert haptic signals into sequences of discrete units, enabling their
integration with the LLaMA model. HapticLLaMA is trained in two stages: (1)
supervised fine-tuning using the LLaMA architecture with LoRA-based adaptation,
and (2) fine-tuning via reinforcement learning from human feedback (RLHF). We
assess HapticLLaMA's captioning performance using both automated n-gram metrics
and human evaluation. HapticLLaMA demonstrates strong capability in
interpreting haptic vibration signals, achieving a METEOR score of 59.98 and a
BLEU-4 score of 32.06 respectively. Additionally, over 61% of the generated
captions received human ratings above 3.5 on a 7-point scale, with RLHF
yielding a 10% improvement in the overall rating distribution, indicating
stronger alignment with human haptic perception. These findings highlight the
potential of large language models to process and adapt to sensory data.

</details>


### [72] [Post-training for Efficient Communication via Convention Formation](https://arxiv.org/abs/2508.06482)
*Yilun Hua,Evan Wang,Yoav Artzi*

Main category: cs.CL

TL;DR: 论文提出了一种后训练方法，通过针对性地微调启发式识别的示范，使LLM能够像人类一样在多轮交互中形成临时约定。


<details>
  <summary>Details</summary>
Motivation: 人类在多轮交互中能高效适应语言并形成临时约定，而现有LLM缺乏这种能力。

Method: 通过启发式识别示范并进行针对性微调的后训练过程。

Result: 后训练的LLM在两个新基准测试中表现出显著改进的约定形成能力。

Conclusion: 该方法有效提升了LLM在多轮交互中的约定形成能力。

Abstract: Humans communicate with increasing efficiency in multi-turn interactions, by
adapting their language and forming ad-hoc conventions. In contrast, prior work
shows that LLMs do not naturally show this behavior. We develop a post-training
process to develop this ability through targeted fine-tuning on heuristically
identified demonstrations of convention formation. We evaluate with two new
benchmarks focused on this capability. First, we design a focused,
cognitively-motivated interaction benchmark that consistently elicits strong
convention formation trends in humans. Second, we create a new
document-grounded reference completion task that reflects in-the-wild
convention formation behavior. Our studies show significantly improved
convention formation abilities in post-trained LLMs across the two evaluation
methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [73] [Boosting Adversarial Transferability via Residual Perturbation Attack](https://arxiv.org/abs/2508.05689)
*Jinjia Peng,Zeze Tao,Huibing Wang,Meng Wang,Yang Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为ResPA的新型攻击方法，通过利用残差梯度作为扰动方向，引导对抗样本朝向损失函数的平坦区域，从而提升对抗样本的可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有基于迁移的攻击方法忽视了扰动方向的影响，导致对抗样本的可迁移性受限。

Method: ResPA通过指数移动平均获取参考梯度，并利用当前梯度与参考梯度的残差捕捉全局扰动方向的变化。

Result: 实验表明，ResPA的可迁移性优于现有典型迁移攻击方法，且与现有输入变换方法结合可进一步提升效果。

Conclusion: ResPA通过优化扰动方向，显著提升了对抗样本的可迁移性。

Abstract: Deep neural networks are susceptible to adversarial examples while suffering
from incorrect predictions via imperceptible perturbations. Transfer-based
attacks create adversarial examples for surrogate models and transfer these
examples to target models under black-box scenarios. Recent studies reveal that
adversarial examples in flat loss landscapes exhibit superior transferability
to alleviate overfitting on surrogate models. However, the prior arts overlook
the influence of perturbation directions, resulting in limited transferability.
In this paper, we propose a novel attack method, named Residual Perturbation
Attack (ResPA), relying on the residual gradient as the perturbation direction
to guide the adversarial examples toward the flat regions of the loss function.
Specifically, ResPA conducts an exponential moving average on the input
gradients to obtain the first moment as the reference gradient, which
encompasses the direction of historical gradients. Instead of heavily relying
on the local flatness that stems from the current gradients as the perturbation
direction, ResPA further considers the residual between the current gradient
and the reference gradient to capture the changes in the global perturbation
direction. The experimental results demonstrate the better transferability of
ResPA than the existing typical transfer-based attack methods, while the
transferability can be further improved by combining ResPA with the current
input transformation methods. The code is available at
https://github.com/ZezeTao/ResPA.

</details>


### [74] [Generalized Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2508.05732)
*Pinxuan Li,Bing Cao,Changqing Zhang,Qinghua Hu*

Main category: cs.CV

TL;DR: 提出了一种广义少样本OOD检测框架（GOOD），通过引入通用知识模型（GKM）提升模型泛化能力，解决了现有方法因数据不足导致的过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 现有少样本OOD检测方法因数据有限导致泛化能力不足，难以适应开放世界。

Method: 提出GOOD框架，利用GKM增强模型通用知识，并设计知识动态嵌入（KDE）机制动态调整通用知识指导。

Result: 实验证明GOOD在真实OOD基准测试中表现优越。

Conclusion: GOOD通过GS平衡和KDE机制显著提升少样本OOD检测的泛化性能。

Abstract: Few-shot Out-of-Distribution (OOD) detection has emerged as a critical
research direction in machine learning for practical deployment. Most existing
Few-shot OOD detection methods suffer from insufficient generalization
capability for the open world. Due to the few-shot learning paradigm, the OOD
detection ability is often overfit to the limited training data itself, thus
degrading the performance on generalized data and performing inconsistently
across different scenarios. To address this challenge, we proposed a
Generalized Few-shot OOD Detection (GOOD) framework, which empowers the general
knowledge of the OOD detection model with an auxiliary General Knowledge Model
(GKM), instead of directly learning from few-shot data. We proceed to reveal
the few-shot OOD detection from a generalization perspective and theoretically
derive the Generality-Specificity balance (GS-balance) for OOD detection, which
provably reduces the upper bound of generalization error with a general
knowledge model. Accordingly, we propose a Knowledge Dynamic Embedding (KDE)
mechanism to adaptively modulate the guidance of general knowledge. KDE
dynamically aligns the output distributions of the OOD detection model to the
general knowledge model based on the Generalized Belief (G-Belief) of GKM,
thereby boosting the GS-balance. Experiments on real-world OOD benchmarks
demonstrate our superiority. Codes will be available.

</details>


### [75] [UnGuide: Learning to Forget with LoRA-Guided Diffusion Models](https://arxiv.org/abs/2508.05755)
*Agnieszka Polowczyk,Alicja Polowczyk,Dawid Malarz,Artur Kasymov,Marcin Mazur,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: UnGuide是一种新方法，通过动态推理机制UnGuidance，结合LoRA适配器，实现精确控制的模型遗忘，同时保持图像保真度。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型可能被滥用生成有害内容，亟需有效的模型遗忘技术。

Method: 采用UnGuidance动态推理机制，结合LoRA适配器，根据去噪过程的稳定性调整引导尺度，实现选择性遗忘。

Result: UnGuide在概念移除任务中优于现有LoRA方法，同时保持模型的表达能力。

Conclusion: UnGuide为模型遗忘提供了高效且精确的解决方案，平衡了遗忘与模型性能。

Abstract: Recent advances in large-scale text-to-image diffusion models have heightened
concerns about their potential misuse, especially in generating harmful or
misleading content. This underscores the urgent need for effective machine
unlearning, i.e., removing specific knowledge or concepts from pretrained
models without compromising overall performance. One possible approach is
Low-Rank Adaptation (LoRA), which offers an efficient means to fine-tune models
for targeted unlearning. However, LoRA often inadvertently alters unrelated
content, leading to diminished image fidelity and realism. To address this
limitation, we introduce UnGuide -- a novel approach which incorporates
UnGuidance, a dynamic inference mechanism that leverages Classifier-Free
Guidance (CFG) to exert precise control over the unlearning process. UnGuide
modulates the guidance scale based on the stability of a few first steps of
denoising processes, enabling selective unlearning by LoRA adapter. For prompts
containing the erased concept, the LoRA module predominates and is
counterbalanced by the base model; for unrelated prompts, the base model
governs generation, preserving content fidelity. Empirical results demonstrate
that UnGuide achieves controlled concept removal and retains the expressive
power of diffusion models, outperforming existing LoRA-based methods in both
object erasure and explicit content removal tasks.

</details>


### [76] [Improving Masked Style Transfer using Blended Partial Convolution](https://arxiv.org/abs/2508.05769)
*Seyed Hadi Seyed,Ayberk Cansever,David Hart*

Main category: cs.CV

TL;DR: 提出了一种基于部分卷积的风格迁移网络，专注于对图像中特定区域进行风格迁移，避免了传统方法中风格特征捕捉不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法对整个图像进行风格迁移，而用户可能仅需对特定区域应用风格。传统掩码方法无法准确捕捉感兴趣区域的风格特征。

Method: 采用部分卷积风格迁移网络，并结合网络内部混合技术以解决区域选择不完美的问题。

Result: 在SA-1B数据集上验证了该方法在视觉和量化指标上的改进。

Conclusion: 该方法显著提升了风格迁移的准确性和视觉效果，代码已开源。

Abstract: Artistic style transfer has long been possible with the advancements of
convolution- and transformer-based neural networks. Most algorithms apply the
artistic style transfer to the whole image, but individual users may only need
to apply a style transfer to a specific region in the image. The standard
practice is to simply mask the image after the stylization. This work shows
that this approach tends to improperly capture the style features in the region
of interest. We propose a partial-convolution-based style transfer network that
accurately applies the style features exclusively to the region of interest.
Additionally, we present network-internal blending techniques that account for
imperfections in the region selection. We show that this visually and
quantitatively improves stylization using examples from the SA-1B dataset. Code
is publicly available at https://github.com/davidmhart/StyleTransferMasked.

</details>


### [77] [MAISI-v2: Accelerated 3D High-Resolution Medical Image Synthesis with Rectified Flow and Region-specific Contrastive Loss](https://arxiv.org/abs/2508.05772)
*Can Zhao,Pengfei Guo,Dong Yang,Yucheng Tang,Yufan He,Benjamin Simon,Mason Belue,Stephanie Harmon,Baris Turkbey,Daguang Xu*

Main category: cs.CV

TL;DR: MAISI-v2是一个加速的3D医学图像合成框架，通过整合rectified flow实现快速高质量生成，并引入区域特异性对比损失提升条件一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在医学图像合成中的通用性差、推理速度慢和条件对齐弱的问题。

Method: 整合rectified flow加速生成，引入区域特异性对比损失增强条件一致性。

Result: MAISI-v2实现了33倍加速的潜在扩散模型，并达到SOTA图像质量，可用于数据增强。

Conclusion: MAISI-v2在速度和条件一致性上显著改进，为医学图像合成提供了高效解决方案。

Abstract: Medical image synthesis is an important topic for both clinical and research
applications. Recently, diffusion models have become a leading approach in this
area. Despite their strengths, many existing methods struggle with (1) limited
generalizability that only work for specific body regions or voxel spacings,
(2) slow inference, which is a common issue for diffusion models, and (3) weak
alignment with input conditions, which is a critical issue for medical imaging.
MAISI, a previously proposed framework, addresses generalizability issues but
still suffers from slow inference and limited condition consistency. In this
work, we present MAISI-v2, the first accelerated 3D medical image synthesis
framework that integrates rectified flow to enable fast and high quality
generation. To further enhance condition fidelity, we introduce a novel
region-specific contrastive loss to enhance the sensitivity to region of
interest. Our experiments show that MAISI-v2 can achieve SOTA image quality
with $33 \times$ acceleration for latent diffusion model. We also conducted a
downstream segmentation experiment to show that the synthetic images can be
used for data augmentation. We release our code, training details, model
weights, and a GUI demo to facilitate reproducibility and promote further
development within the community.

</details>


### [78] [Few-Shot Deployment of Pretrained MRI Transformers in Brain Imaging Tasks](https://arxiv.org/abs/2508.05783)
*Mengyu Li,Guoyao Shen,Chad W. Farris,Xin Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于预训练MRI变换器的少样本部署框架，结合MAE预训练策略和轻量级线性头，在分类和分割任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中标注数据稀缺的问题，提升变换器模型在现实世界中的适用性。

Method: 使用MAE预训练策略在大规模多队列脑MRI数据集上训练，结合轻量级线性头进行分类，提出MAE-FUnet架构进行分割。

Result: 在MRI序列识别和分割任务中达到SOTA准确率，在数据有限条件下表现稳定且高效。

Conclusion: 该框架适用于低资源临床环境和广泛的神经影像应用，具有高效性和可扩展性。

Abstract: Machine learning using transformers has shown great potential in medical
imaging, but its real-world applicability remains limited due to the scarcity
of annotated data. In this study, we propose a practical framework for the
few-shot deployment of pretrained MRI transformers in diverse brain imaging
tasks. By utilizing the Masked Autoencoder (MAE) pretraining strategy on a
large-scale, multi-cohort brain MRI dataset comprising over 31 million slices,
we obtain highly transferable latent representations that generalize well
across tasks and datasets. For high-level tasks such as classification, a
frozen MAE encoder combined with a lightweight linear head achieves
state-of-the-art accuracy in MRI sequence identification with minimal
supervision. For low-level tasks such as segmentation, we propose MAE-FUnet, a
hybrid architecture that fuses multiscale CNN features with pretrained MAE
embeddings. This model consistently outperforms other strong baselines in both
skull stripping and multi-class anatomical segmentation under data-limited
conditions. With extensive quantitative and qualitative evaluations, our
framework demonstrates efficiency, stability, and scalability, suggesting its
suitability for low-resource clinical environments and broader neuroimaging
applications.

</details>


### [79] [Optimization-Free Style Transfer for 3D Gaussian Splats](https://arxiv.org/abs/2508.05813)
*Raphael Du Sablon,David Hart*

Main category: cs.CV

TL;DR: 提出了一种无需重建或优化的3D高斯斑点风格迁移方法，通过生成图结构并应用前馈风格化技术，实现快速风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯斑点风格迁移方法需要重建或优化，效率低且复杂，因此提出一种无需训练或优化的快速方法。

Method: 在斑点隐式表面生成图结构，应用前馈风格化方法，并将结果插值回场景中的斑点。

Result: 方法支持任意风格图像和3D高斯斑点，速度快（2分钟内完成），且质量优于其他方法。

Conclusion: 该方法高效、通用，适用于消费级硬件，代码已开源。

Abstract: The task of style transfer for 3D Gaussian splats has been explored in many
previous works, but these require reconstructing or fine-tuning the splat while
incorporating style information or optimizing a feature extraction network on
the splat representation. We propose a reconstruction- and optimization-free
approach to stylizing 3D Gaussian splats. This is done by generating a graph
structure across the implicit surface of the splat representation. A
feed-forward, surface-based stylization method is then used and interpolated
back to the individual splats in the scene. This allows for any style image and
3D Gaussian splat to be used without any additional training or optimization.
This also allows for fast stylization of splats, achieving speeds under 2
minutes even on consumer-grade hardware. We demonstrate the quality results
this approach achieves and compare to other 3D Gaussian splat style transfer
methods. Code is publicly available at
https://github.com/davidmhart/FastSplatStyler.

</details>


### [80] [MZEN: Multi-Zoom Enhanced NeRF for 3-D Reconstruction with Unknown Camera Poses](https://arxiv.org/abs/2508.05819)
*Jong-Ik Park,Carlee Joe-Wong,Gary K. Fedder*

Main category: cs.CV

TL;DR: MZEN是一种改进的NeRF框架，通过处理多缩放图像集，显著提升了工业检测中的细节重建能力。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法在工业检测中无法捕捉细微结构，如亚微米缺陷或SEM图像分析，MZEN旨在解决这一问题。

Method: MZEN引入可学习的缩放标量，改进相机模型，并通过宽场图像和缩放图像的分阶段姿态策略实现多缩放一致性。

Result: 在多个场景中，MZEN显著提升了PSNR、SSIM和LPIPS指标，优于现有方法。

Conclusion: MZEN成功将NeRF扩展到工业检测领域，兼顾全局精度和微观细节。

Abstract: Neural Radiance Fields (NeRF) methods excel at 3D reconstruction from
multiple 2D images, even those taken with unknown camera poses. However, they
still miss the fine-detailed structures that matter in industrial inspection,
e.g., detecting sub-micron defects on a production line or analyzing chips with
Scanning Electron Microscopy (SEM). In these scenarios, the sensor resolution
is fixed and compute budgets are tight, so the only way to expose fine
structure is to add zoom-in images; yet, this breaks the multi-view consistency
that pose-free NeRF training relies on. We propose Multi-Zoom Enhanced NeRF
(MZEN), the first NeRF framework that natively handles multi-zoom image sets.
MZEN (i) augments the pin-hole camera model with an explicit, learnable zoom
scalar that scales the focal length, and (ii) introduces a novel pose strategy:
wide-field images are solved first to establish a global metric frame, and
zoom-in images are then pose-primed to the nearest wide-field counterpart via a
zoom-consistent crop-and-match procedure before joint refinement. Across eight
forward-facing scenes$\unicode{x2013}$synthetic TCAD models, real SEM of
micro-structures, and BLEFF objects$\unicode{x2013}$MZEN consistently
outperforms pose-free baselines and even high-resolution variants, boosting
PSNR by up to $28 \%$, SSIM by $10 \%$, and reducing LPIPS by up to $222 \%$.
MZEN, therefore, extends NeRF to real-world factory settings, preserving global
accuracy while capturing the micron-level details essential for industrial
inspection.

</details>


### [81] [TSMS-SAM2: Multi-scale Temporal Sampling Augmentation and Memory-Splitting Pruning for Promptable Video Object Segmentation and Tracking in Surgical Scenarios](https://arxiv.org/abs/2508.05829)
*Guoping Xu,Hua-Chieh Shao,You Zhang*

Main category: cs.CV

TL;DR: TSMS-SAM2是一种新型框架，通过多时间尺度视频采样增强和内存分割修剪机制，提升手术视频中的可提示视频对象分割与跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决手术视频中复杂运动动态和内存冗余对基础模型（如SAM2）应用的挑战。

Method: 引入多时间尺度视频采样增强和内存分割修剪机制。

Result: 在EndoVis2017和EndoVis2018数据集上分别达到95.24和86.73的Dice分数，优于现有方法。

Conclusion: TSMS-SAM2在复杂手术场景中表现出高效、鲁棒的分割潜力。

Abstract: Promptable video object segmentation and tracking (VOST) has seen significant
advances with the emergence of foundation models like Segment Anything Model 2
(SAM2); however, their application in surgical video analysis remains
challenging due to complex motion dynamics and the redundancy of memory that
impedes effective learning. In this work, we propose TSMS-SAM2, a novel
framework that enhances promptable VOST in surgical videos by addressing
challenges of rapid object motion and memory redundancy in SAM2. TSMS-SAM2
introduces two key strategies: multi-temporal-scale video sampling augmentation
to improve robustness against motion variability, and a memory splitting and
pruning mechanism that organizes and filters past frame features for more
efficient and accurate segmentation. Evaluated on EndoVis2017 and EndoVis2018
datasets, TSMS-SAM2 achieved the highest mean Dice scores of 95.24 and 86.73,
respectively, outperforming prior SAM-based and task-specific methods.
Extensive ablation studies confirm the effectiveness of multiscale temporal
augmentation and memory splitting, highlighting the framework's potential for
robust, efficient segmentation in complex surgical scenarios. Our source code
will be available at https://github.com/apple1986/TSMS-SAM2.

</details>


### [82] [Temporal Cluster Assignment for Efficient Real-Time Video Segmentation](https://arxiv.org/abs/2508.05851)
*Ka-Wai Yung,Felix J. S. Bragman,Jialang Xu,Imanol Luengo,Danail Stoyanov,Evangelos B. Mazomenos*

Main category: cs.CV

TL;DR: 提出了一种名为Temporal Cluster Assignment (TCA)的轻量级方法，通过利用帧间时间一致性优化视频分割中的token聚类，显著减少计算量并保持细节。


<details>
  <summary>Details</summary>
Motivation: Swin Transformer在视频分割中计算成本高，现有token剪枝方法因窗口注意力机制受限，且未利用时间冗余。

Method: TCA通过时间相关性优化token聚类，减少冗余计算，无需微调。

Result: 在多个数据集上验证，TCA提升了现有聚类方法的精度与速度平衡。

Conclusion: TCA是一种高效且通用的方法，适用于自然和特定领域视频。

Abstract: Vision Transformers have substantially advanced the capabilities of
segmentation models across both image and video domains. Among them, the Swin
Transformer stands out for its ability to capture hierarchical, multi-scale
representations, making it a popular backbone for segmentation in videos.
However, despite its window-attention scheme, it still incurs a high
computational cost, especially in larger variants commonly used for dense
prediction in videos. This remains a major bottleneck for real-time,
resource-constrained applications. Whilst token reduction methods have been
proposed to alleviate this, the window-based attention mechanism of Swin
requires a fixed number of tokens per window, limiting the applicability of
conventional pruning techniques. Meanwhile, training-free token clustering
approaches have shown promise in image segmentation while maintaining window
consistency. Nevertheless, they fail to exploit temporal redundancy, missing a
key opportunity to further optimize video segmentation performance. We
introduce Temporal Cluster Assignment (TCA), a lightweight and effective,
fine-tuning-free strategy that enhances token clustering by leveraging temporal
coherence across frames. Instead of indiscriminately dropping redundant tokens,
TCA refines token clusters using temporal correlations, thereby retaining
fine-grained details while significantly reducing computation. Extensive
evaluations on YouTube-VIS 2019, YouTube-VIS 2021, OVIS, and a private surgical
video dataset show that TCA consistently boosts the accuracy-speed trade-off of
existing clustering-based methods. Our results demonstrate that TCA generalizes
competently across both natural and domain-specific videos.

</details>


### [83] [VISTA: Vision-Language Imitation of Situational Thinking and Attention for Human-Like Driver Focus in Dynamic Environments](https://arxiv.org/abs/2508.05852)
*Kaiser Hamid,Khandakar Ashrafi Akbar,Nade Liang*

Main category: cs.CV

TL;DR: 提出了一种基于视觉-语言框架的驾驶员视觉注意力预测方法，通过自然语言描述驾驶场景中的注意力变化，支持少样本和零样本学习。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注静态图像的注意力分配，而忽略了动态变化的注意力行为。本文旨在通过自然语言建模驾驶员的动态视觉注意力。

Method: 利用BDD-A数据集的高质量标注，通过人类反馈优化，并微调LLaVA模型，结合低级线索和高级上下文（如路线语义、风险预测）生成注意力描述。

Result: 微调后的模型在注意力转移检测和可解释性上优于通用视觉-语言模型，并提出了领域特定的语义对齐和响应多样性指标。

Conclusion: 该研究首次通过自然语言生成驾驶员视觉注意力预测，为自动驾驶中的可解释AI提供了新方向，并为下游任务奠定了基础。

Abstract: Driver visual attention prediction is a critical task in autonomous driving
and human-computer interaction (HCI) research. Most prior studies focus on
estimating attention allocation at a single moment in time, typically using
static RGB images such as driving scene pictures. In this work, we propose a
vision-language framework that models the changing landscape of drivers' gaze
through natural language, using few-shot and zero-shot learning on single RGB
images. We curate and refine high-quality captions from the BDD-A dataset using
human-in-the-loop feedback, then fine-tune LLaVA to align visual perception
with attention-centric scene understanding. Our approach integrates both
low-level cues and top-down context (e.g., route semantics, risk anticipation),
enabling language-based descriptions of gaze behavior. We evaluate performance
across training regimes (few shot, and one-shot) and introduce domain-specific
metrics for semantic alignment and response diversity. Results show that our
fine-tuned model outperforms general-purpose VLMs in attention shift detection
and interpretability. To our knowledge, this is among the first attempts to
generate driver visual attention allocation and shifting predictions in natural
language, offering a new direction for explainable AI in autonomous driving.
Our approach provides a foundation for downstream tasks such as behavior
forecasting, human-AI teaming, and multi-agent coordination.

</details>


### [84] [Multi-view Gaze Target Estimation](https://arxiv.org/abs/2508.05857)
*Qiaomu Miao,Vivek Raju Golani,Jingyi Xu,Progga Paromita Dutta,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: 提出了一种利用多摄像头视角进行视线目标估计（GTE）的方法，通过整合不同视角的信息提高准确性和适用性。


<details>
  <summary>Details</summary>
Motivation: 解决单视角方法在面部遮挡、目标模糊和视线外目标等问题上的局限性。

Method: 结合了头部信息聚合（HIA）、基于不确定性的视线选择（UGS）和基于极线的场景注意力（ESA）模块。

Result: 显著优于单视角基线方法，尤其在第二视角能清晰捕捉面部时表现更佳。

Conclusion: 该方法不仅提升了GTE的准确性，还具备仅通过第二视角图像估计第一视角视线目标的能力，并提供了多视角数据集。

Abstract: This paper presents a method that utilizes multiple camera views for the gaze
target estimation (GTE) task. The approach integrates information from
different camera views to improve accuracy and expand applicability, addressing
limitations in existing single-view methods that face challenges such as face
occlusion, target ambiguity, and out-of-view targets. Our method processes a
pair of camera views as input, incorporating a Head Information Aggregation
(HIA) module for leveraging head information from both views for more accurate
gaze estimation, an Uncertainty-based Gaze Selection (UGS) for identifying the
most reliable gaze output, and an Epipolar-based Scene Attention (ESA) module
for cross-view background information sharing. This approach significantly
outperforms single-view baselines, especially when the second camera provides a
clear view of the person's face. Additionally, our method can estimate the gaze
target in the first view using the image of the person in the second view only,
a capability not possessed by single-view GTE methods. Furthermore, the paper
introduces a multi-view dataset for developing and evaluating multi-view GTE
methods. Data and code are available at
https://www3.cs.stonybrook.edu/~cvl/multiview_gte.html

</details>


### [85] [ETTA: Efficient Test-Time Adaptation for Vision-Language Models through Dynamic Embedding Updates](https://arxiv.org/abs/2508.05898)
*Hamidreza Dastmalchi,Aijun An,Ali cheraghian*

Main category: cs.CV

TL;DR: ETTA提出了一种高效的测试时适应方法，通过递归更新模块和自适应集成模块，动态优化决策边界和提示选择，显著提升了零样本性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型在零样本任务中表现良好，但在分布偏移下泛化能力不足，测试时适应方法旨在解决这一问题。

Method: ETTA引入递归更新模块动态整合所有测试样本，并采用自适应集成模块减少对提示的依赖，结合两者的优势。

Result: 实验表明，ETTA在计算复杂度和准确性上均优于现有方法，成为测试时适应的新标杆。

Conclusion: ETTA通过动态更新和自适应集成，实现了高效且准确的测试时适应，为相关领域提供了新的解决方案。

Abstract: Pretrained vision-language models (VLMs) like CLIP show strong zero-shot
performance but struggle with generalization under distribution shifts.
Test-Time Adaptation (TTA) addresses this by adapting VLMs to unlabeled test
data in new domains. While some TTA methods rely on prompt-tuning,
training-free cache-based approaches are preferred for efficiency. However,
current cache-based TTA models store only a limited set of high-confidence
samples, restricting the decision boundary to these samples and ignoring the
influence of other incoming test data. To address this, we propose Efficient
Test-Time Adaptation (ETTA), introducing a Recursive Updating module that
integrates all incoming test samples, progressively refining the decision
boundary. This strategy mimics an unbounded cache, dynamically updating
contextual embeddings for improved accuracy with minimal memory and
computational overhead. ETTA also includes an Adaptive Ensemble module to
reduce prompt dependency in image-to-text scores by dynamically selecting
optimal prompts for each class. Furthermore, ETTA adaptively combines scores
from both modules based on confidence levels, leveraging their complementary
strengths. Extensive experiments on two benchmarks confirm that ETTA surpasses
the state-of-the-art TTA models in computational complexity and accuracy,
setting a new standard for effective, efficient test-time adaptation. The code
has been released at https://github.com/hamidreza-dastmalchi/ETTA.

</details>


### [86] [HOLODECK 2.0: Vision-Language-Guided 3D World Generation with Editing](https://arxiv.org/abs/2508.05899)
*Zixuan Bian,Ruohan Ren,Yue Yang,Chris Callison-Burch*

Main category: cs.CV

TL;DR: HOLODECK 2.0是一个基于视觉语言模型的3D场景生成框架，支持根据文本描述生成多样化、风格丰富的3D场景，并支持交互式编辑。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景生成依赖大量人工，且现有自动化方法难以生成开放域场景或支持灵活编辑。

Method: 利用视觉语言模型识别和解析场景中的对象，通过3D生成模型生成高质量资产，并应用空间约束实现语义一致和物理合理的布局。

Result: HOLODECK 2.0生成高质量场景，与文本描述高度一致，在室内和开放域场景中均优于基线方法。

Conclusion: HOLODECK 2.0在游戏建模等应用中展示了高效生成沉浸式环境的潜力。

Abstract: 3D scene generation plays a crucial role in gaming, artistic creation,
virtual reality and many other domains. However, current 3D scene design still
relies heavily on extensive manual effort from creators, and existing automated
methods struggle to generate open-domain scenes or support flexible editing. As
a result, generating 3D worlds directly from text has garnered increasing
attention. In this paper, we introduce HOLODECK 2.0, an advanced
vision-language-guided framework for 3D world generation with support for
interactive scene editing based on human feedback. HOLODECK 2.0 can generate
diverse and stylistically rich 3D scenes (e.g., realistic, cartoon, anime, and
cyberpunk styles) that exhibit high semantic fidelity to fine-grained input
descriptions, suitable for both indoor and open-domain environments. HOLODECK
2.0 leverages vision-language models (VLMs) to identify and parse the objects
required in a scene and generates corresponding high-quality assets via
state-of-the-art 3D generative models. It then iteratively applies spatial
constraints derived from the VLMs to achieve semantically coherent and
physically plausible layouts. Human evaluations and CLIP-based assessments
demonstrate that HOLODECK 2.0 effectively generates high-quality scenes closely
aligned with detailed textual descriptions, consistently outperforming
baselines across indoor and open-domain scenarios. Additionally, we provide
editing capabilities that flexibly adapt to human feedback, supporting layout
refinement and style-consistent object edits. Finally, we present a practical
application of HOLODECK 2.0 in procedural game modeling, generating visually
rich and immersive environments, potentially boosting efficiency.

</details>


### [87] [Robust Image Stitching with Optimal Plane](https://arxiv.org/abs/2508.05903)
*Lang Nie,Yuan Mei,Kang Liao,Yunqiu Xu,Chunyu Lin,Bin Xiao*

Main category: cs.CV

TL;DR: RopStitch是一种无监督深度图像拼接框架，通过双分支架构和虚拟最优平面概念提升鲁棒性和自然性。


<details>
  <summary>Details</summary>
Motivation: 解决图像拼接中内容对齐与结构保留的矛盾，并提高模型在多样化场景中的泛化能力。

Method: 采用双分支架构分别捕获粗粒度与细粒度特征，并通过虚拟最优平面估计解决对齐与保留的冲突。

Result: 在多个数据集上显著优于现有方法，尤其在场景鲁棒性和内容自然性方面表现突出。

Conclusion: RopStitch通过创新架构和优化策略，实现了高效且自然的图像拼接。

Abstract: We present \textit{RopStitch}, an unsupervised deep image stitching framework
with both robustness and naturalness. To ensure the robustness of
\textit{RopStitch}, we propose to incorporate the universal prior of content
perception into the image stitching model by a dual-branch architecture. It
separately captures coarse and fine features and integrates them to achieve
highly generalizable performance across diverse unseen real-world scenes.
Concretely, the dual-branch model consists of a pretrained branch to capture
semantically invariant representations and a learnable branch to extract
fine-grained discriminative features, which are then merged into a whole by a
controllable factor at the correlation level. Besides, considering that content
alignment and structural preservation are often contradictory to each other, we
propose a concept of virtual optimal planes to relieve this conflict. To this
end, we model this problem as a process of estimating homography decomposition
coefficients, and design an iterative coefficient predictor and minimal
semantic distortion constraint to identify the optimal plane. This scheme is
finally incorporated into \textit{RopStitch} by warping both views onto the
optimal plane bidirectionally. Extensive experiments across various datasets
demonstrate that \textit{RopStitch} significantly outperforms existing methods,
particularly in scene robustness and content naturalness. The code is available
at {\color{red}https://github.com/MmelodYy/RopStitch}.

</details>


### [88] [Neural Field Representations of Mobile Computational Photography](https://arxiv.org/abs/2508.05907)
*Ilya Chugunov*

Main category: cs.CV

TL;DR: 论文探讨了如何利用神经场模型在移动成像中高效表示复杂几何和光照效果，无需复杂预处理或标记数据。


<details>
  <summary>Details</summary>
Motivation: 移动设备已成为强大的计算成像平台，结合神经场技术，可以解决传统方法依赖复杂预处理和标记数据的问题。

Method: 设计自正则化的神经场模型，通过随机梯度下降直接拟合智能手机的原始测量数据。

Result: 提出的方法在深度估计、图层分离和图像拼接等任务中优于现有技术。

Conclusion: 神经场模型为移动成像提供了高效、无需复杂预处理的新解决方案。

Abstract: Over the past two decades, mobile imaging has experienced a profound
transformation, with cell phones rapidly eclipsing all other forms of digital
photography in popularity. Today's cell phones are equipped with a diverse
range of imaging technologies - laser depth ranging, multi-focal camera arrays,
and split-pixel sensors - alongside non-visual sensors such as gyroscopes,
accelerometers, and magnetometers. This, combined with on-board integrated
chips for image and signal processing, makes the cell phone a versatile
pocket-sized computational imaging platform. Parallel to this, we have seen in
recent years how neural fields - small neural networks trained to map
continuous spatial input coordinates to output signals - enable the
reconstruction of complex scenes without explicit data representations such as
pixel arrays or point clouds. In this thesis, I demonstrate how carefully
designed neural field models can compactly represent complex geometry and
lighting effects. Enabling applications such as depth estimation, layer
separation, and image stitching directly from collected in-the-wild mobile
photography data. These methods outperform state-of-the-art approaches without
relying on complex pre-processing steps, labeled ground truth data, or machine
learning priors. Instead, they leverage well-constructed, self-regularized
models that tackle challenging inverse problems through stochastic gradient
descent, fitting directly to raw measurements from a smartphone.

</details>


### [89] [Enhancing Construction Site Analysis and Understanding with 3D Segmentation](https://arxiv.org/abs/2508.05922)
*Sri Ramana Saketh Vasanthawada,Pengkun Liu,Pingbo Tang*

Main category: cs.CV

TL;DR: 论文探讨了计算机视觉方法在建筑工地监测中的应用，评估了SAM和Mask3D两种3D分割模型在复杂环境中的表现，并指出当前方法在户外场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 传统建筑监测方法效率低且难以适应复杂多变的工地环境，因此需要探索更高效的计算机视觉解决方案。

Method: 通过比较SAM和Mask3D两种模型在室内和户外建筑场景中的表现，评估其适应性和性能。

Result: 研究发现当前分割方法在户外场景中缺乏基准，但SAM和Mask3D在复杂环境中仍显示出潜力。

Conclusion: 研究强调了定制化分割工作流程的重要性，以推动建筑监测向更自动化和精确的方向发展。

Abstract: Monitoring construction progress is crucial yet resource-intensive, prompting
the exploration of computer-vision-based methodologies for enhanced efficiency
and scalability. Traditional data acquisition methods, primarily focusing on
indoor environments, falter in construction site's complex, cluttered, and
dynamically changing conditions. This paper critically evaluates the
application of two advanced 3D segmentation methods, Segment Anything Model
(SAM) and Mask3D, in challenging outdoor and indoor conditions. Trained
initially on indoor datasets, both models' adaptability and performance are
assessed in real-world construction settings, highlighting the gap in current
segmentation approaches due to the absence of benchmarks for outdoor scenarios.
Through a comparative analysis, this study not only showcases the relative
effectiveness of SAM and Mask3D but also addresses the critical need for
tailored segmentation workflows capable of extracting actionable insights from
construction site data, thereby advancing the field towards more automated and
precise monitoring techniques.

</details>


### [90] [A 3DGS-Diffusion Self-Supervised Framework for Normal Estimation from a Single Image](https://arxiv.org/abs/2508.05950)
*Yanxing Liang,Yinghui Wang,Jinlong Yang,Wei Li*

Main category: cs.CV

TL;DR: SINGAD提出了一种自监督框架，通过3D高斯扩散和物理驱动的光交互建模，解决了单图像法线估计中的多视角不一致性和数据依赖问题。


<details>
  <summary>Details</summary>
Motivation: 单图像法线估计缺乏空间维度信息，现有方法依赖数据驱动统计先验，忽略了光-表面交互的显式建模，导致多视角法线方向冲突和梯度不连续。

Method: 结合物理驱动的光交互建模和可微分渲染重投影策略，SINGAD通过3D高斯扩散生成多尺度几何特征，并设计跨域特征融合模块约束法线生成。

Result: 在Google Scanned Objects数据集上的定量评估表明，SINGAD在多个指标上优于现有方法。

Conclusion: SINGAD通过自监督优化和几何误差传播，解决了多视角几何不一致性和数据依赖问题，提升了单图像法线估计的性能。

Abstract: The lack of spatial dimensional information remains a challenge in normal
estimation from a single image. Recent diffusion-based methods have
demonstrated significant potential in 2D-to-3D implicit mapping, they rely on
data-driven statistical priors and miss the explicit modeling of light-surface
interaction, leading to multi-view normal direction conflicts. Moreover, the
discrete sampling mechanism of diffusion models causes gradient discontinuity
in differentiable rendering reconstruction modules, preventing 3D geometric
errors from being backpropagated to the normal generation network, thereby
forcing existing methods to depend on dense normal annotations. This paper
proposes SINGAD, a novel Self-supervised framework from a single Image for
Normal estimation via 3D GAussian splatting guided Diffusion. By integrating
physics-driven light-interaction modeling and a differentiable rendering-based
reprojection strategy, our framework directly converts 3D geometric errors into
normal optimization signals, solving the challenges of multi-view geometric
inconsistency and data dependency. Specifically, the framework constructs a
light-interaction-driven 3DGS reparameterization model to generate multi-scale
geometric features consistent with light transport principles, ensuring
multi-view normal consistency. A cross-domain feature fusion module is designed
within a conditional diffusion model, embedding geometric priors to constrain
normal generation while maintaining accurate geometric error propagation.
Furthermore, a differentiable 3D reprojection loss strategy is introduced for
self-supervised optimization that minimizes geometric error between the
reconstructed and input image, eliminating dependence on annotated normal
datasets. Quantitative evaluations on the Google Scanned Objects dataset
demonstrate that our method outperforms state-of-the-art approaches across
multiple metrics.

</details>


### [91] [Bifrost-1: Bridging Multimodal LLMs and Diffusion Models with Patch-level CLIP Latents](https://arxiv.org/abs/2508.05954)
*Han Lin,Jaemin Cho,Amir Zadeh,Chuan Li,Mohit Bansal*

Main category: cs.CV

TL;DR: Bifrost-1是一个统一框架，通过将预训练的多模态大语言模型（MLLMs）与扩散模型结合，利用CLIP图像嵌入作为潜在变量，实现高效的高保真可控图像生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在训练成本高和图像表示未对齐的问题，同时保留MLLMs的多模态推理能力。

Method: 使用patch级CLIP图像嵌入作为潜在变量，通过轻量级ControlNet适配扩散模型，并初始化MLLMs的视觉生成分支。

Result: Bifrost-1在视觉保真度和多模态理解上表现优异，且训练计算成本显著降低。

Conclusion: 该框架成功整合了MLLMs和扩散模型，实现了高效可控的图像生成。

Abstract: There is growing interest in integrating high-fidelity visual synthesis
capabilities into large language models (LLMs) without compromising their
strong reasoning capabilities. Existing methods that directly train LLMs or
bridge LLMs and diffusion models usually suffer from costly training since the
backbone LLMs have not seen image representations during pretraining. We
present Bifrost-1, a unified framework that bridges pretrained multimodal LLMs
(MLLMs) and diffusion models using patch-level CLIP image embeddings as latent
variables, which are natively aligned with the MLLM's CLIP visual encoder.
These patch-level image embeddings are integrated into the diffusion model with
a lightweight adaptation of its ControlNet. To retain the original multimodal
reasoning capabilities of MLLMs, we equip the MLLM with a visual generation
branch initialized from the original MLLM parameters when predicting the
patch-level image embeddings. By seamlessly integrating pretrained MLLMs and
diffusion models with patch-level CLIP latents, our framework enables
high-fidelity controllable image generation with significant training
efficiency. Our experiments demonstrate that Bifrost-1 achieves comparable or
better performance than previous methods in terms of visual fidelity and
multimodal understanding, with substantially lower compute during training. We
also provide comprehensive ablation studies showing the effectiveness of our
design choices.

</details>


### [92] [PASG: A Closed-Loop Framework for Automated Geometric Primitive Extraction and Semantic Anchoring in Robotic Manipulation](https://arxiv.org/abs/2508.05976)
*Zhihao Zhu,Yifan Zheng,Siyu Pan,Yaohui Jin,Yao Mu*

Main category: cs.CV

TL;DR: PASG框架通过几何特征聚合和视觉语言模型动态耦合几何基元与功能可用性，解决了机器人操作中语义与几何特征的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中高级任务语义与低级几何特征之间的脱节问题，以及视觉语言模型在语义基础和动态语义-可用性关系捕捉上的局限性。

Method: 提出PASG框架，包括自动基元提取、VLM驱动的语义锚定和空间语义推理基准，并微调VLM模型Qwen2.5VL-PA。

Result: 在多样化机器人操作任务中表现优异，性能接近人工标注水平。

Conclusion: PASG实现了对物体更细粒度的语义-可用性理解，为机器人操作中的几何基元与任务语义统一提供了新范式。

Abstract: The fragmentation between high-level task semantics and low-level geometric
features remains a persistent challenge in robotic manipulation. While
vision-language models (VLMs) have shown promise in generating affordance-aware
visual representations, the lack of semantic grounding in canonical spaces and
reliance on manual annotations severely limit their ability to capture dynamic
semantic-affordance relationships. To address these, we propose Primitive-Aware
Semantic Grounding (PASG), a closed-loop framework that introduces: (1)
Automatic primitive extraction through geometric feature aggregation, enabling
cross-category detection of keypoints and axes; (2) VLM-driven semantic
anchoring that dynamically couples geometric primitives with functional
affordances and task-relevant description; (3) A spatial-semantic reasoning
benchmark and a fine-tuned VLM (Qwen2.5VL-PA). We demonstrate PASG's
effectiveness in practical robotic manipulation tasks across diverse scenarios,
achieving performance comparable to manual annotations. PASG achieves a
finer-grained semantic-affordance understanding of objects, establishing a
unified paradigm for bridging geometric primitives with task semantics in
robotic manipulation.

</details>


### [93] [AnimateScene: Camera-controllable Animation in Any Scene](https://arxiv.org/abs/2508.05982)
*Qingyang Liu,Bingjie Gao,Weiheng Huang,Jun Zhang,Zhongqian Sun,Yang Wei,Zelin Peng,Qianli Ma,Shuai Yang,Zhaohe Liao,Haonan Zhao,Li Niu*

Main category: cs.CV

TL;DR: AnimateScene提出了一种统一框架，解决3D场景重建与4D人体动画无缝集成的挑战，包括人体位置与比例、光照风格对齐及相机轨迹重建。


<details>
  <summary>Details</summary>
Motivation: 3D场景重建与4D人体动画的集成存在人体位置与比例不准确、光照风格不一致及相机轨迹缺失的问题。

Method: AnimateScene包含三个模块：1) 准确的人体位置放置模块；2) 无训练的风格对齐方法；3) 联合后重建方法支持相机轨迹插入。

Result: 实验表明，AnimateScene能生成几何细节丰富且时空一致的动态场景视频。

Conclusion: AnimateScene有效解决了3D场景与4D人体动画的集成问题，实现了高质量的视觉效果。

Abstract: 3D scene reconstruction and 4D human animation have seen rapid progress and
broad adoption in recent years. However, seamlessly integrating reconstructed
scenes with 4D human animation to produce visually engaging results remains
challenging. One key difficulty lies in placing the human at the correct
location and scale within the scene while avoiding unrealistic
interpenetration. Another challenge is that the human and the background may
exhibit different lighting and style, leading to unrealistic composites. In
addition, appealing character motion videos are often accompanied by camera
movements, which means that the viewpoints need to be reconstructed along a
specified trajectory. We present AnimateScene, which addresses the above issues
in a unified framework. First, we design an accurate placement module that
automatically determines a plausible 3D position for the human and prevents any
interpenetration within the scene during motion. Second, we propose a
training-free style alignment method that adapts the 4D human representation to
match the background's lighting and style, achieving coherent visual
integration. Finally, we design a joint post-reconstruction method for both the
4D human and the 3D scene that allows camera trajectories to be inserted,
enabling the final rendered video to feature visually appealing camera
movements. Extensive experiments show that AnimateScene generates dynamic scene
videos with high geometric detail and spatiotemporal coherence across various
camera and action combinations.

</details>


### [94] [ETA: Energy-based Test-time Adaptation for Depth Completion](https://arxiv.org/abs/2508.05989)
*Younjoon Chung,Hyoungseob Park,Patrick Rim,Xiaoran Zhang,Jihe He,Ziyao Zeng,Safa Cicek,Byung-Woo Hong,James S. Duncan,Alex Wong*

Main category: cs.CV

TL;DR: 提出了一种基于能量的测试时适应方法（ETA），用于调整预训练的深度补全模型，以应对目标数据与源数据分布不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 深度补全模型在从源数据迁移到目标数据时，由于协变量偏移，预测结果往往不准确。需要一种无需预先了解目标数据分布的方法来适应新环境。

Method: 通过对抗扰动探索数据空间，训练能量模型评估深度预测的分布情况，并在测试时更新模型参数以最小化能量值。

Result: 在三个室内和三个室外数据集上，ETA比现有最佳方法平均提高了6.94%（室外）和10.23%（室内）。

Conclusion: ETA通过能量模型有效解决了测试时适应问题，显著提升了深度补全模型在新环境中的性能。

Abstract: We propose a method for test-time adaptation of pretrained depth completion
models. Depth completion models, trained on some ``source'' data, often predict
erroneous outputs when transferred to ``target'' data captured in novel
environmental conditions due to a covariate shift. The crux of our method lies
in quantifying the likelihood of depth predictions belonging to the source data
distribution. The challenge is in the lack of access to out-of-distribution
(target) data prior to deployment. Hence, rather than making assumptions
regarding the target distribution, we utilize adversarial perturbations as a
mechanism to explore the data space. This enables us to train an energy model
that scores local regions of depth predictions as in- or out-of-distribution.
We update the parameters of pretrained depth completion models at test time to
minimize energy, effectively aligning test-time predictions to those of the
source distribution. We call our method ``Energy-based Test-time Adaptation'',
or ETA for short. We evaluate our method across three indoor and three outdoor
datasets, where ETA improve over the previous state-of-the-art method by an
average of 6.94% for outdoors and 10.23% for indoors. Project Page:
https://fuzzythecat.github.io/eta.

</details>


### [95] [Fast Motion Estimation and Context-Aware Refinement for Efficient Bayer-Domain Video Vision](https://arxiv.org/abs/2508.05990)
*Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han*

Main category: cs.CV

TL;DR: 提出了一种高效视频计算机视觉系统，通过直接处理Bayer格式数据和快速块匹配运动估计算法，显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分减少视频中的时间冗余且忽略了前端计算开销，因此需要更高效的解决方案。

Method: 移除图像信号处理器，直接输入Bayer数据；采用快速块匹配运动估计算法和MV细化模块；引入上下文感知块细化网络纠正误差；使用帧选择策略平衡精度与效率。

Result: 在多个视频计算机视觉任务中，方法实现了显著加速且性能损失轻微。

Conclusion: 所提系统在效率和性能之间取得了良好平衡，适用于高效视频计算机视觉任务。

Abstract: The efficiency of video computer vision system remains a challenging task due
to the high temporal redundancy inside a video. Existing works have been
proposed for efficient vision computer vision. However, they do not fully
reduce the temporal redundancy and neglect the front end computation overhead.
In this paper, we propose an efficient video computer vision system. First,
image signal processor is removed and Bayer-format data is directly fed into
video computer vision models, thus saving the front end computation. Second,
instead of optical flow models and video codecs, a fast block matching-based
motion estimation algorithm is proposed specifically for efficient video
computer vision, with a MV refinement module. To correct the error,
context-aware block refinement network is introduced to refine regions with
large error. To further balance the accuracy and efficiency, a frame selection
strategy is employed. Experiments on multiple video computer vision tasks
demonstrate that our method achieves significant acceleration with slight
performance loss.

</details>


### [96] [ECMF: Enhanced Cross-Modal Fusion for Multimodal Emotion Recognition in MER-SEMI Challenge](https://arxiv.org/abs/2508.05991)
*Juewen Hu,Yexin Li,Jiulin Li,Shuo Chen,Pring Wong*

Main category: cs.CV

TL;DR: 提出了一种新颖的多模态情感识别框架，通过预训练模型提取视觉、音频和文本特征，并采用双分支视觉编码器和上下文丰富的文本处理方法，结合自注意力机制和残差连接进行特征融合，显著提升了MER2025-SEMI数据集的性能。


<details>
  <summary>Details</summary>
Motivation: 提升人机交互中的情感识别能力，解决数据稀缺问题。

Method: 利用预训练模型提取多模态特征，设计双分支视觉编码器和上下文丰富的文本处理方法，采用自注意力机制和残差连接进行特征融合，并通过多源标签策略优化训练数据。

Result: 在MER2025-SEMI数据集上，加权F-score达到87.49%，显著优于官方基线（78.63%）。

Conclusion: 提出的多模态情感识别框架有效解决了数据稀缺问题，显著提升了情感识别性能。

Abstract: Emotion recognition plays a vital role in enhancing human-computer
interaction. In this study, we tackle the MER-SEMI challenge of the MER2025
competition by proposing a novel multimodal emotion recognition framework. To
address the issue of data scarcity, we leverage large-scale pre-trained models
to extract informative features from visual, audio, and textual modalities.
Specifically, for the visual modality, we design a dual-branch visual encoder
that captures both global frame-level features and localized facial
representations. For the textual modality, we introduce a context-enriched
method that employs large language models to enrich emotional cues within the
input text. To effectively integrate these multimodal features, we propose a
fusion strategy comprising two key components, i.e., self-attention mechanisms
for dynamic modality weighting, and residual connections to preserve original
representations. Beyond architectural design, we further refine noisy labels in
the training set by a multi-source labeling strategy. Our approach achieves a
substantial performance improvement over the official baseline on the
MER2025-SEMI dataset, attaining a weighted F-score of 87.49% compared to
78.63%, thereby validating the effectiveness of the proposed framework.

</details>


### [97] [EvoMakeup: High-Fidelity and Controllable Makeup Editing with MakeupQuad](https://arxiv.org/abs/2508.05994)
*Huadong Wu,Yi Fu,Yunhao Li,Yuan Gao,Kang Du*

Main category: cs.CV

TL;DR: 论文提出MakeupQuad数据集和EvoMakeup框架，用于高质量面部化妆编辑，解决了现有方法在细节和身份保留上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有面部化妆编辑方法因缺乏结构化配对数据，导致结果质量低、细节粗糙，且难以平衡化妆保真度和身份保留。

Method: 引入MakeupQuad数据集，并提出EvoMakeup框架，通过多阶段蒸馏迭代提升数据和模型质量。

Result: EvoMakeup在真实场景中表现优异，支持高保真、可控的多任务化妆编辑，优于现有方法。

Conclusion: 该方法在化妆保真度和身份保留上取得平衡，具有广泛适用性。

Abstract: Facial makeup editing aims to realistically transfer makeup from a reference
to a target face. Existing methods often produce low-quality results with
coarse makeup details and struggle to preserve both identity and makeup
fidelity, mainly due to the lack of structured paired data -- where source and
result share identity, and reference and result share identical makeup. To
address this, we introduce MakeupQuad, a large-scale, high-quality dataset with
non-makeup faces, references, edited results, and textual makeup descriptions.
Building on this, we propose EvoMakeup, a unified training framework that
mitigates image degradation during multi-stage distillation, enabling iterative
improvement of both data and model quality. Although trained solely on
synthetic data, EvoMakeup generalizes well and outperforms prior methods on
real-world benchmarks. It supports high-fidelity, controllable, multi-task
makeup editing -- including full-face and partial reference-based editing, as
well as text-driven makeup editing -- within a single model. Experimental
results demonstrate that our method achieves superior makeup fidelity and
identity preservation, effectively balancing both aspects. Code and dataset
will be released upon acceptance.

</details>


### [98] [MathReal: We Keep It Real! A Real Scene Benchmark for Evaluating Math Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2508.06009)
*Jun Feng,Zixin Wang,Zhentao Zhang,Yue Guo,Zhihan Zhou,Xiuyi Chen,Zhenyang Li,Dawei Yin*

Main category: cs.CV

TL;DR: MathReal数据集填补了现有MLLMs在真实教育场景中视觉数学推理的空白，通过2,000个真实拍摄的数学问题，系统评估了MLLMs的性能和局限性。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs基准测试基于干净或处理过的多模态输入，缺乏真实K-12教育场景中的图像数据，MathReal旨在解决这一问题。

Method: 构建MathReal数据集，包含2,000个真实拍摄的数学问题，分类为图像质量、视角变化和无关内容干扰三类，并设计六种实验设置评估MLLMs。

Result: 现有MLLMs在真实教育场景中的问题解决能力受到显著挑战，研究分析了其错误模式和能力局限。

Conclusion: MathReal为MLLMs在真实教育场景中的性能评估提供了基准，并指出了未来改进方向。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in visual mathematical reasoning across various existing
benchmarks. However, these benchmarks are predominantly based on clean or
processed multimodal inputs, without incorporating the images provided by
real-world Kindergarten through 12th grade (K-12) educational users. To address
this gap, we introduce MathReal, a meticulously curated dataset comprising
2,000 mathematical questions with images captured by handheld mobile devices in
authentic scenarios. Each question is an image, containing the question text
and visual element. We systematically classify the real images into three
primary categories: image quality degradation, perspective variation, and
irrelevant content interference, which are further delineated into 14
subcategories. Additionally, MathReal spans five core knowledge and ability
categories, which encompass three question types and are divided into three
difficulty levels. To comprehensively evaluate the multimodal mathematical
reasoning abilities of state-of-the-art MLLMs in real-world scenarios, we
design six experimental settings that enable a systematic analysis of their
performance. Through extensive experimentation, we find that the
problem-solving abilities of existing MLLMs are significantly challenged in
realistic educational contexts. Based on this, we conduct a thorough analysis
of their performance and error patterns, providing insights into their
recognition, comprehension, and reasoning capabilities, and outlining
directions for future improvements. Data and code:
https://github.com/junfeng0288/MathReal.

</details>


### [99] [ExploreGS: Explorable 3D Scene Reconstruction with Virtual Camera Samplings and Diffusion Priors](https://arxiv.org/abs/2508.06014)
*Minsu Kim,Subin Jeon,In Cho,Mijin Yoo,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅（3DGS）的管道，通过生成额外训练视图和虚拟相机放置策略，提升新视角合成的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在偏离训练轨迹的视角下渲染时存在伪影和缺失区域，限制了场景的无缝探索。

Method: 采用信息增益驱动的虚拟相机放置策略和视频扩散先验，优化3D高斯泼溅的渲染结果。

Result: 实验表明，该方法优于现有3DGS方法，能够从任意视角实现高质量、无伪影的渲染。

Conclusion: 提出的方法显著提升了重建质量，适用于挑战性场景探索。

Abstract: Recent advances in novel view synthesis (NVS) have enabled real-time
rendering with 3D Gaussian Splatting (3DGS). However, existing methods struggle
with artifacts and missing regions when rendering from viewpoints that deviate
from the training trajectory, limiting seamless scene exploration. To address
this, we propose a 3DGS-based pipeline that generates additional training views
to enhance reconstruction. We introduce an information-gain-driven virtual
camera placement strategy to maximize scene coverage, followed by video
diffusion priors to refine rendered results. Fine-tuning 3D Gaussians with
these enhanced views significantly improves reconstruction quality. To evaluate
our method, we present Wild-Explore, a benchmark designed for challenging scene
exploration. Experiments demonstrate that our approach outperforms existing
3DGS-based methods, enabling high-quality, artifact-free rendering from
arbitrary viewpoints.
  https://exploregs.github.io

</details>


### [100] [Improved Sub-Visible Particle Classification in Flow Imaging Microscopy via Generative AI-Based Image Synthesis](https://arxiv.org/abs/2508.06021)
*Utku Ozbulak,Michaela Cohrs,Hristo L. Svilenov,Joris Vankerschaver,Wesley De Neve*

Main category: cs.CV

TL;DR: 利用深度学习结合流式成像显微镜分析亚可见颗粒，但数据稀缺和类别不平衡问题限制了多分类器的效果。本文开发了一种扩散模型生成高质量图像以增强数据集，实验证明其有效性，并公开了模型和代码。


<details>
  <summary>Details</summary>
Motivation: 解决亚可见颗粒分析中数据稀缺和类别不平衡问题，尤其是硅油和气泡等罕见颗粒类型。

Method: 开发扩散模型生成高保真图像以增强训练数据集，并训练多分类深度神经网络。

Result: 生成的图像与真实颗粒图像相似，实验表明该方法显著提高了分类性能。

Conclusion: 扩散模型生成的图像能有效解决数据不平衡问题，提升分类效果，并公开资源以促进研究。

Abstract: Sub-visible particle analysis using flow imaging microscopy combined with
deep learning has proven effective in identifying particle types, enabling the
distinction of harmless components such as silicone oil from protein particles.
However, the scarcity of available data and severe imbalance between particle
types within datasets remain substantial hurdles when applying multi-class
classifiers to such problems, often forcing researchers to rely on less
effective methods. The aforementioned issue is particularly challenging for
particle types that appear unintentionally and in lower numbers, such as
silicone oil and air bubbles, as opposed to protein particles, where obtaining
large numbers of images through controlled settings is comparatively
straightforward. In this work, we develop a state-of-the-art diffusion model to
address data imbalance by generating high-fidelity images that can augment
training datasets, enabling the effective training of multi-class deep neural
networks. We validate this approach by demonstrating that the generated samples
closely resemble real particle images in terms of visual quality and structure.
To assess the effectiveness of using diffusion-generated images in training
datasets, we conduct large-scale experiments on a validation dataset comprising
500,000 protein particle images and demonstrate that this approach improves
classification performance with no negligible downside. Finally, to promote
open research and reproducibility, we publicly release both our diffusion
models and the trained multi-class deep neural network classifiers, along with
a straightforward interface for easy integration into future studies, at
https://github.com/utkuozbulak/svp-generative-ai.

</details>


### [101] [Learning 3D Texture-Aware Representations for Parsing Diverse Human Clothing and Body Parts](https://arxiv.org/abs/2508.06032)
*Kiran Chhatre,Christopher Peters,Srikrishna Karanam*

Main category: cs.CV

TL;DR: Spectrum提出了一种统一网络，用于细粒度的人体解析（身体部位和服装），通过改进的图像到纹理扩散模型实现更好的语义对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用固定掩码类别或单一类别，无法区分细粒度服装或详细身体部位，而扩散模型的内部表示也不适合详细的人体解析。

Method: Spectrum利用改进的图像到纹理（I2Tx）扩散模型提取特征，并通过提示引导生成语义有效的掩码。

Result: 实验表明，Spectrum在跨数据集评估中优于基线方法，特别是在提示分割任务中。

Conclusion: Spectrum通过结合扩散模型和细粒度解析，实现了对人体和服装的精确分割。

Abstract: Existing methods for human parsing into body parts and clothing often use
fixed mask categories with broad labels that obscure fine-grained clothing
types. Recent open-vocabulary segmentation approaches leverage pretrained
text-to-image (T2I) diffusion model features for strong zero-shot transfer, but
typically group entire humans into a single person category, failing to
distinguish diverse clothing or detailed body parts. To address this, we
propose Spectrum, a unified network for part-level pixel parsing (body parts
and clothing) and instance-level grouping. While diffusion-based
open-vocabulary models generalize well across tasks, their internal
representations are not specialized for detailed human parsing. We observe
that, unlike diffusion models with broad representations, image-driven 3D
texture generators maintain faithful correspondence to input images, enabling
stronger representations for parsing diverse clothing and body parts. Spectrum
introduces a novel repurposing of an Image-to-Texture (I2Tx) diffusion model --
obtained by fine-tuning a T2I model on 3D human texture maps -- for improved
alignment with body parts and clothing. From an input image, we extract
human-part internal features via the I2Tx diffusion model and generate
semantically valid masks aligned to diverse clothing categories through
prompt-guided grounding. Once trained, Spectrum produces semantic segmentation
maps for every visible body part and clothing category, ignoring standalone
garments or irrelevant objects, for any number of humans in the scene. We
conduct extensive cross-dataset experiments -- separately assessing body parts,
clothing parts, unseen clothing categories, and full-body masks -- and
demonstrate that Spectrum consistently outperforms baseline methods in
prompt-based segmentation.

</details>


### [102] [InstantEdit: Text-Guided Few-Step Image Editing with Piecewise Rectified Flow](https://arxiv.org/abs/2508.06033)
*Yiming Gong,Zhen Zhu,Minjia Zhang*

Main category: cs.CV

TL;DR: InstantEdit是一种基于RectifiedFlow框架的快速文本引导图像编辑方法，通过PerRFI反转策略和Inversion Latent Injection技术，实现了高效且内容一致的编辑。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种快速且高质量的文本引导图像编辑方法，同时保留关键内容并遵循文本指令。

Method: 采用RectifiedFlow框架，引入PerRFI反转策略和Inversion Latent Injection技术，结合Disentangled Prompt Guidance和Canny-conditioned ControlNet。

Result: 在PIE数据集上表现优于现有方法，速度快且编辑质量高。

Conclusion: InstantEdit在速度和编辑质量上均优于现有方法，适用于高效图像编辑任务。

Abstract: We propose a fast text-guided image editing method called InstantEdit based
on the RectifiedFlow framework, which is structured as a few-step editing
process that preserves critical content while following closely to textual
instructions. Our approach leverages the straight sampling trajectories of
RectifiedFlow by introducing a specialized inversion strategy called PerRFI. To
maintain consistent while editable results for RectifiedFlow model, we further
propose a novel regeneration method, Inversion Latent Injection, which
effectively reuses latent information obtained during inversion to facilitate
more coherent and detailed regeneration. Additionally, we propose a
Disentangled Prompt Guidance technique to balance editability with detail
preservation, and integrate a Canny-conditioned ControlNet to incorporate
structural cues and suppress artifacts. Evaluation on the PIE image editing
dataset demonstrates that InstantEdit is not only fast but also achieves better
qualitative and quantitative results compared to state-of-the-art few-step
editing methods.

</details>


### [103] [More Is Better: A MoE-Based Emotion Recognition Framework with Human Preference Alignment](https://arxiv.org/abs/2508.06036)
*Jun Xie,Yingjian Zhu,Feng Chen,Zhenghao Zhang,Xiaohui Fan,Hongzhu Yi,Xinming Wang,Chen Yu,Yue Bi,Zhaoran Zhao,Xiongjun Guan,Zhepeng Wang*

Main category: cs.CV

TL;DR: 提出了一种基于混合专家（MoE）的半监督情感识别框架，结合多模态输入和伪标签策略，在MER2025-SEMI挑战中排名第二。


<details>
  <summary>Details</summary>
Motivation: 解决半监督学习中的情感识别问题，通过整合多模态数据和利用未标记数据提升模型性能。

Method: 采用混合专家框架，整合视觉-语言模型和动作单元信息，结合共识伪标签策略和两阶段训练，最后通过多专家投票和规则重排优化预测。

Result: 在MER2025-SEMI测试集上F1得分为0.8772，排名第二。

Conclusion: 提出的框架在多模态情感识别任务中表现优异，验证了其有效性。

Abstract: In this paper, we present our solution for the semi-supervised learning track
(MER-SEMI) in MER2025. We propose a comprehensive framework, grounded in the
principle that "more is better," to construct a robust Mixture of Experts (MoE)
emotion recognition system. Our approach integrates a diverse range of input
modalities as independent experts, including novel signals such as knowledge
from large Vision-Language Models (VLMs) and temporal Action Unit (AU)
information. To effectively utilize unlabeled data, we introduce a
consensus-based pseudo-labeling strategy, generating high-quality labels from
the agreement between a baseline model and Gemini, which are then used in a
two-stage training paradigm. Finally, we employ a multi-expert voting ensemble
combined with a rule-based re-ranking process to correct prediction bias and
better align the outputs with human preferences. Evaluated on the MER2025-SEMI
challenge dataset, our method achieves an F1-score of 0.8772 on the test set,
ranking 2nd in the track. Our code is available at
https://github.com/zhuyjan/MER2025-MRAC25.

</details>


### [104] [Fourier-VLM: Compressing Vision Tokens in the Frequency Domain for Large Vision-Language Models](https://arxiv.org/abs/2508.06038)
*Huanyu Wang,Jushi Kai,Haoli Bai,Lu Hou,Bo Jiang,Ziwei He,Zhouhan Lin*

Main category: cs.CV

TL;DR: Fourier-VLM通过频域压缩视觉表示，减少计算开销和推理延迟，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）中视觉特征的高维度导致计算开销和推理延迟增加，现有方法在性能或成本上存在不足。

Method: 利用视觉特征在低频分量集中的特性，通过二维离散余弦变换（DCT）和快速傅里叶变换（FFT）压缩视觉表示。

Result: 在多个基准测试中表现优异，推理FLOPs减少83.8%，生成速度提升31.2%。

Conclusion: Fourier-VLM在高效性和实用性上表现突出，适用于多种架构。

Abstract: Vision-Language Models (VLMs) typically replace the predefined image
placeholder token (<image>) in textual instructions with visual features from
an image encoder, forming the input to a backbone Large Language Model (LLM).
However, the large number of vision tokens significantly increases the context
length, leading to high computational overhead and inference latency. While
previous efforts mitigate this by selecting only important visual features or
leveraging learnable queries to reduce token count, they often compromise
performance or introduce substantial extra costs. In response, we propose
Fourier-VLM, a simple yet efficient method that compresses visual
representations in the frequency domain. Our approach is motivated by the
observation that vision features output from the vision encoder exhibit
concentrated energy in low-frequency components. Leveraging this, we apply a
low-pass filter to the vision features using a two-dimentional Discrete Cosine
Transform (DCT). Notably, the DCT is efficiently computed via the Fast Fourier
Transform (FFT) operator with a time complexity of $\mathcal{O}(n\log n)$,
minimizing the extra computational cost while introducing no additional
parameters. Extensive experiments across various image-based benchmarks
demonstrate that Fourier-VLM achieves competitive performance with strong
generalizability across both LLaVA and Qwen-VL architectures. Crucially, it
reduce inference FLOPs by up to 83.8% and boots generation speed by 31.2%
compared to LLaVA-v1.5, highlighting the superior efficiency and practicality.

</details>


### [105] [NEP: Autoregressive Image Editing via Next Editing Token Prediction](https://arxiv.org/abs/2508.06044)
*Huimin Wu,Xiaojian Ma,Haozhe Zhao,Yanpeng Zhao,Qing Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于自回归图像生成的Next Editing-token Prediction (NEP)方法，仅编辑需要修改的图像区域，避免不必要的计算和非编辑区域的偏差。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成整个目标图像，导致计算浪费和非编辑区域的重建偏差，影响编辑质量。

Method: 提出NEP方法，基于自回归图像生成，仅重新生成需要编辑的区域；预训练一个任意顺序的自回归文本到图像（T2I）模型，支持零样本图像编辑。

Result: 在广泛使用的图像编辑基准测试中达到新最优性能，支持零样本测试时缩放（TTS）。

Conclusion: NEP方法显著提升了图像编辑的效率和质量，支持灵活的区域编辑和零样本优化。

Abstract: Text-guided image editing involves modifying a source image based on a
language instruction and, typically, requires changes to only small local
regions. However, existing approaches generate the entire target image rather
than selectively regenerate only the intended editing areas. This results in
(1) unnecessary computational costs and (2) a bias toward reconstructing
non-editing regions, which compromises the quality of the intended edits. To
resolve these limitations, we propose to formulate image editing as Next
Editing-token Prediction (NEP) based on autoregressive image generation, where
only regions that need to be edited are regenerated, thus avoiding unintended
modification to the non-editing areas. To enable any-region editing, we propose
to pre-train an any-order autoregressive text-to-image (T2I) model. Once
trained, it is capable of zero-shot image editing and can be easily adapted to
NEP for image editing, which achieves a new state-of-the-art on widely used
image editing benchmarks. Moreover, our model naturally supports test-time
scaling (TTS) through iteratively refining its generation in a zero-shot
manner. The project page is: https://nep-bigai.github.io/

</details>


### [106] [VQAThinker: Exploring Generalizable and Explainable Video Quality Assessment via Reinforcement Learning](https://arxiv.org/abs/2508.06051)
*Linhan Cao,Wei Sun,Weixia Zhang,Xiangyang Zhu,Jun Jia,Kaiwei Zhang,Dandan Zhu,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: VQAThinker是一个基于推理的视频质量评估框架，利用大型多模态模型和强化学习解决现有模型的泛化性和可解释性问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视频质量评估模型在泛化性和可解释性上存在不足，限制了其实际应用。

Method: 采用基于规则的强化学习算法（GRPO）和三种特定奖励机制（回归奖励、排序奖励和时间一致性奖励）来模拟人类感知决策。

Result: VQAThinker在域内和域外基准测试中均达到最优性能，并在质量理解和解释性任务中表现优异。

Conclusion: 强化学习为仅依赖分数监督的泛化性和可解释性视频质量评估模型提供了有效途径。

Abstract: Video quality assessment (VQA) aims to objectively quantify perceptual
quality degradation in alignment with human visual perception. Despite recent
advances, existing VQA models still suffer from two critical limitations:
\textit{poor generalization to out-of-distribution (OOD) videos} and
\textit{limited explainability}, which restrict their applicability in
real-world scenarios. To address these challenges, we propose
\textbf{VQAThinker}, a reasoning-based VQA framework that leverages large
multimodal models (LMMs) with reinforcement learning to jointly model video
quality understanding and scoring, emulating human perceptual decision-making.
Specifically, we adopt group relative policy optimization (GRPO), a rule-guided
reinforcement learning algorithm that enables reasoning over video quality
under score-level supervision, and introduce three VQA-specific rewards: (1) a
\textbf{bell-shaped regression reward} that increases rapidly as the prediction
error decreases and becomes progressively less sensitive near the ground truth;
(2) a \textbf{pairwise ranking reward} that guides the model to correctly
determine the relative quality between video pairs; and (3) a \textbf{temporal
consistency reward} that encourages the model to prefer temporally coherent
videos over their perturbed counterparts. Extensive experiments demonstrate
that VQAThinker achieves state-of-the-art performance on both in-domain and OOD
VQA benchmarks, showing strong generalization for video quality scoring.
Furthermore, evaluations on video quality understanding tasks validate its
superiority in distortion attribution and quality description compared to
existing explainable VQA models and LMMs. These findings demonstrate that
reinforcement learning offers an effective pathway toward building
generalizable and explainable VQA models solely with score-level supervision.

</details>


### [107] [LV-Net: Anatomy-aware lateral ventricle shape modeling with a case study on Alzheimer's disease, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing](https://arxiv.org/abs/2508.06055)
*Wonjung Park,Suhyun Ahn,Jinah Park*

Main category: cs.CV

TL;DR: LV-Net是一种新框架，通过变形联合LV-海马模板网格从脑MRI生成个性化3D LV网格，提高了分割和重建的鲁棒性，并在阿尔茨海默病分析中识别出与疾病显著相关的LV子区域。


<details>
  <summary>Details</summary>
Motivation: 侧脑室（LV）形状分析作为神经系统疾病的生物标志物具有潜力，但由于个体间形状差异大和MRI分辨率限制导致的分割困难，仍存在挑战。

Method: LV-Net通过变形一个解剖学感知的联合LV-海马模板网格生成个性化3D LV网格，并基于解剖邻接对模板网格顶点分类，以增强点对应性。

Result: LV-Net在分割不完美的情况下仍实现更高的重建精度，并在多样数据集中提供更可靠的形状描述符。应用于阿尔茨海默病分析，识别出与疾病显著相关的LV子区域。

Conclusion: LV-Net通过结合解剖关系和改进点对应性，显著提升了LV形状分析的准确性和鲁棒性，为神经系统疾病研究提供了有效工具。

Abstract: Lateral ventricle (LV) shape analysis holds promise as a biomarker for
neurological diseases; however, challenges remain due to substantial shape
variability across individuals and segmentation difficulties arising from
limited MRI resolution. We introduce LV-Net, a novel framework for producing
individualized 3D LV meshes from brain MRI by deforming an anatomy-aware joint
LV-hippocampus template mesh. By incorporating anatomical relationships
embedded within the joint template, LV-Net reduces boundary segmentation
artifacts and improves reconstruction robustness. In addition, by classifying
the vertices of the template mesh based on their anatomical adjacency, our
method enhances point correspondence across subjects, leading to more accurate
LV shape statistics. We demonstrate that LV-Net achieves superior
reconstruction accuracy, even in the presence of segmentation imperfections,
and delivers more reliable shape descriptors across diverse datasets. Finally,
we apply LV-Net to Alzheimer's disease analysis, identifying LV subregions that
show significantly associations with the disease relative to cognitively normal
controls. The codes for LV shape modeling are available at
https://github.com/PWonjung/LV_Shape_Modeling.

</details>


### [108] [AGI for the Earth, the path, possibilities and how to evaluate intelligence of models that work with Earth Observation Data?](https://arxiv.org/abs/2508.06057)
*Mojtaba Valipour,Kelly Zheng,James Lowman,Spencer Szabados,Mike Gartner,Bobby Braswell*

Main category: cs.CV

TL;DR: 论文探讨了卫星光谱图像作为AGI新模态的重要性，并呼吁建立更全面的基准测试来评估地球观测模型。


<details>
  <summary>Details</summary>
Motivation: 卫星光谱图像在AGI研究中未受足够重视，但其潜力巨大，需推动相关研究。

Method: 分析了现有基准的局限性，并提出一套全面任务以评估模型能力。

Result: 强调了地球观测数据对智能模型的价值，并指出了现有评估方法的不足。

Conclusion: 需要更全面的基准测试来提升地球观测模型的能力评估。

Abstract: Artificial General Intelligence (AGI) is closer than ever to becoming a
reality, sparking widespread enthusiasm in the research community to collect
and work with various modalities, including text, image, video, and audio.
Despite recent efforts, satellite spectral imagery, as an additional modality,
has yet to receive the attention it deserves. This area presents unique
challenges, but also holds great promise in advancing the capabilities of AGI
in understanding the natural world. In this paper, we argue why Earth
Observation data is useful for an intelligent model, and then we review
existing benchmarks and highlight their limitations in evaluating the
generalization ability of foundation models in this domain. This paper
emphasizes the need for a more comprehensive benchmark to evaluate earth
observation models. To facilitate this, we propose a comprehensive set of tasks
that a benchmark should encompass to effectively assess a model's ability to
understand and interact with Earth observation data.

</details>


### [109] [Lightweight Quad Bayer HybridEVS Demosaicing via State Space Augmented Cross-Attention](https://arxiv.org/abs/2508.06058)
*Shiyang Zhou,Haijin Zeng,Yunfan Lu,Yongyong Chen,Jie Liu,Jingyong Su*

Main category: cs.CV

TL;DR: TSANet是一个轻量级的两阶段网络，通过状态空间增强的交叉注意力，分别处理事件像素修复和去马赛克，显著提升了HybridEVS相机的图像质量。


<details>
  <summary>Details</summary>
Motivation: HybridEVS相机结合Quad Bayer CFA传感器和事件像素时，缺乏颜色信息导致去马赛克过程中的伪影和混叠问题，现有方法难以在资源有限的移动设备上解决这些问题。

Method: TSANet采用两阶段网络设计，分别处理事件像素修复和去马赛克，并引入轻量级的Cross-Swin State Block，利用位置先验和状态空间模型增强全局依赖。

Result: TSANet在模拟和真实HybridEVS数据上表现出色，PSNR和SSIM优于现有方法DemosaicFormer，同时参数和计算成本分别降低了1.86倍和3.29倍。

Conclusion: TSANet为移动设备上的高效图像去马赛克提供了新的可能性，模型轻量且性能优越。

Abstract: Event cameras like the Hybrid Event-based Vision Sensor (HybridEVS) camera
capture brightness changes as asynchronous "events" instead of frames, offering
advanced application on mobile photography. However, challenges arise from
combining a Quad Bayer Color Filter Array (CFA) sensor with event pixels
lacking color information, resulting in aliasing and artifacts on the
demosaicing process before downstream application. Current methods struggle to
address these issues, especially on resource-limited mobile devices. In
response, we introduce \textbf{TSANet}, a lightweight \textbf{T}wo-stage
network via \textbf{S}tate space augmented cross-\textbf{A}ttention, which can
handle event pixels inpainting and demosaicing separately, leveraging the
benefits of dividing complex tasks into manageable subtasks. Furthermore, we
introduce a lightweight Cross-Swin State Block that uniquely utilizes
positional prior for demosaicing and enhances global dependencies through the
state space model with linear complexity. In summary, TSANet demonstrates
excellent demosaicing performance on both simulated and real data of HybridEVS
while maintaining a lightweight model, averaging better results than the
previous state-of-the-art method DemosaicFormer across seven diverse datasets
in both PSNR and SSIM, while respectively reducing parameter and computation
costs by $1.86\times$ and $3.29\times$. Our approach presents new possibilities
for efficient image demosaicing on mobile devices. Code is available in the
supplementary materials.

</details>


### [110] [Distribution-Specific Learning for Joint Salient and Camouflaged Object Detection](https://arxiv.org/abs/2508.06063)
*Chao Hao,Zitong Yu,Xin Liu,Yuhao Wang,Weicheng Xie,Jingang Shi,Huanjing Yue,Jingyu Yang*

Main category: cs.CV

TL;DR: 提出SCJoint联合学习方案，通过任务特定参数和共享网络结构解决SOD与COD任务的矛盾属性，同时提出SBSS采样策略优化训练集。


<details>
  <summary>Details</summary>
Motivation: 探索SOD与COD任务的联合学习可能性，反驳以往认为联合学习会降低性能的观点。

Method: SCJoint方案：在共享网络中插入少量任务特定参数，学习解码过程的分布特性；SBSS策略：平衡训练集并提升质量。

Result: JoNet网络能同时捕获显著和伪装物体，实验证明其竞争力和有效性。

Conclusion: 正确学习方法下，联合学习可提升SOD与COD任务性能，SCJoint与SBSS是关键。

Abstract: Salient object detection (SOD) and camouflaged object detection (COD) are two
closely related but distinct computer vision tasks. Although both are
class-agnostic segmentation tasks that map from RGB space to binary space, the
former aims to identify the most salient objects in the image, while the latter
focuses on detecting perfectly camouflaged objects that blend into the
background in the image. These two tasks exhibit strong contradictory
attributes. Previous works have mostly believed that joint learning of these
two tasks would confuse the network, reducing its performance on both tasks.
However, here we present an opposite perspective: with the correct approach to
learning, the network can simultaneously possess the capability to find both
salient and camouflaged objects, allowing both tasks to benefit from joint
learning. We propose SCJoint, a joint learning scheme for SOD and COD tasks,
assuming that the decoding processes of SOD and COD have different distribution
characteristics. The key to our method is to learn the respective means and
variances of the decoding processes for both tasks by inserting a minimal
amount of task-specific learnable parameters within a fully shared network
structure, thereby decoupling the contradictory attributes of the two tasks at
a minimal cost. Furthermore, we propose a saliency-based sampling strategy
(SBSS) to sample the training set of the SOD task to balance the training set
sizes of the two tasks. In addition, SBSS improves the training set quality and
shortens the training time. Based on the proposed SCJoint and SBSS, we train a
powerful generalist network, named JoNet, which has the ability to
simultaneously capture both ``salient" and ``camouflaged". Extensive
experiments demonstrate the competitive performance and effectiveness of our
proposed method. The code is available at https://github.com/linuxsino/JoNet.

</details>


### [111] [Can Large Models Fool the Eye? A New Turing Test for Biological Animation](https://arxiv.org/abs/2508.06072)
*Zijian Chen,Lirong Deng,Zhengyu Chen,Kaiwei Zhang,Qi Jia,Yuan Tian,Yucheng Zhu,Guangtao Zhai*

Main category: cs.CV

TL;DR: BioMotion Arena是一个通过视觉动画评估大语言模型（LLM）和多模态大语言模型（MLLM）的新框架，利用点光源成像放大模型间的性能差异。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试要么基于静态数据集的真实评分，要么采用模糊的聊天机器人式人类偏好收集，无法提供直观的性能反馈。

Method: 采用成对比较评估，收集了53个主流LLM和MLLM在90种生物运动变体上的45k+投票。

Result: 数据表明众包投票与专家评分一致，且90%以上模型无法生成基本人形点光源组或流畅生物运动。

Conclusion: BioMotion Arena可作为性能可视化的挑战性基准和无真实限制的灵活评估框架。

Abstract: Evaluating the abilities of large models and manifesting their gaps are
challenging. Current benchmarks adopt either ground-truth-based score-form
evaluation on static datasets or indistinct textual chatbot-style human
preferences collection, which may not provide users with immediate, intuitive,
and perceptible feedback on performance differences. In this paper, we
introduce BioMotion Arena, a novel framework for evaluating large language
models (LLMs) and multimodal large language models (MLLMs) via visual
animation. Our methodology draws inspiration from the inherent visual
perception of motion patterns characteristic of living organisms that utilizes
point-light source imaging to amplify the performance discrepancies between
models. Specifically, we employ a pairwise comparison evaluation and collect
more than 45k votes for 53 mainstream LLMs and MLLMs on 90 biological motion
variants. Data analyses show that the crowd-sourced human votes are in good
agreement with those of expert raters, demonstrating the superiority of our
BioMotion Arena in offering discriminative feedback. We also find that over
90\% of evaluated models, including the cutting-edge open-source InternVL3 and
proprietary Claude-4 series, fail to produce fundamental humanoid point-light
groups, much less smooth and biologically plausible motions. This enables
BioMotion Arena to serve as a challenging benchmark for performance
visualization and a flexible evaluation framework without restrictions on
ground-truth.

</details>


### [112] [Towards MR-Based Trochleoplasty Planning](https://arxiv.org/abs/2508.06076)
*Michael Wehrli,Alicia Durrer,Paul Friedrich,Sidaty El Hadramy,Edwin Li,Luana Brahaj,Carol C. Hasler,Philippe C. Cattin*

Main category: cs.CV

TL;DR: 提出了一种从低分辨率MR扫描生成高分辨率3D伪健康目标形态的流程，用于治疗滑车发育不良，显著改善了手术效果。


<details>
  <summary>Details</summary>
Motivation: 当前治疗滑车发育不良的方法依赖低分辨率MR扫描和外科医生经验，导致手术效果不一致且微创技术应用有限。

Method: 使用隐式神经表示（INR）生成高分辨率MR图像，多标签网络分割骨骼，再通过小波扩散模型（WDM）生成伪健康目标形态。

Result: 在25名患者中验证，显著改善了滑车角度和滑车沟深度。

Conclusion: 该方法无需CT扫描，减少了辐射，为术前和术中提供了高分辨率3D形态参考。

Abstract: To treat Trochlear Dysplasia (TD), current approaches rely mainly on
low-resolution clinical Magnetic Resonance (MR) scans and surgical intuition.
The surgeries are planned based on surgeons experience, have limited adoption
of minimally invasive techniques, and lead to inconsistent outcomes. We propose
a pipeline that generates super-resolved, patient-specific 3D pseudo-healthy
target morphologies from conventional clinical MR scans. First, we compute an
isotropic super-resolved MR volume using an Implicit Neural Representation
(INR). Next, we segment femur, tibia, patella, and fibula with a multi-label
custom-trained network. Finally, we train a Wavelet Diffusion Model (WDM) to
generate pseudo-healthy target morphologies of the trochlear region. In
contrast to prior work producing pseudo-healthy low-resolution 3D MR images,
our approach enables the generation of sub-millimeter resolved 3D shapes
compatible for pre- and intraoperative use. These can serve as preoperative
blueprints for reshaping the femoral groove while preserving the native patella
articulation. Furthermore, and in contrast to other work, we do not require a
CT for our pipeline - reducing the amount of radiation. We evaluated our
approach on 25 TD patients and could show that our target morphologies
significantly improve the sulcus angle (SA) and trochlear groove depth (TGD).
The code and interactive visualization are available at
https://wehrlimi.github.io/sr-3d-planning/.

</details>


### [113] [DreamVE: Unified Instruction-based Image and Video Editing](https://arxiv.org/abs/2508.06080)
*Bin Xia,Jiyang Liu,Yuechen Zhang,Bohao Peng,Ruihang Chu,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: DreamVE是一个基于指令的图像和视频编辑统一模型，采用两阶段训练策略和多样化的数据合成方法，提升了编辑性能。


<details>
  <summary>Details</summary>
Motivation: 指令式编辑具有简单高效的交互形式，但视频编辑因训练数据有限而受限。DreamVE旨在解决这一问题，统一图像和视频编辑。

Method: 采用两阶段训练（先图像后视频），结合拼贴和生成模型的数据合成方法，并设计了高效的编辑框架。

Result: DreamVE在关键编辑类型上表现优异，具备良好的泛化和迁移能力，但属性编辑性能稍弱。

Conclusion: DreamVE通过统一框架和多样化数据合成，显著提升了指令式编辑的实用性和性能。

Abstract: Instruction-based editing holds vast potential due to its simple and
efficient interactive editing format. However, instruction-based editing,
particularly for video, has been constrained by limited training data,
hindering its practical application. To this end, we introduce DreamVE, a
unified model for instruction-based image and video editing. Specifically, We
propose a two-stage training strategy: first image editing, then video editing.
This offers two main benefits: (1) Image data scales more easily, and models
are more efficient to train, providing useful priors for faster and better
video editing training. (2) Unifying image and video generation is natural and
aligns with current trends. Moreover, we present comprehensive training data
synthesis pipelines, including collage-based and generative model-based data
synthesis. The collage-based data synthesis combines foreground objects and
backgrounds to generate diverse editing data, such as object manipulation,
background changes, and text modifications. It can easily generate billions of
accurate, consistent, realistic, and diverse editing pairs. We pretrain DreamVE
on extensive collage-based data to achieve strong performance in key editing
types and enhance generalization and transfer capabilities. However,
collage-based data lacks some attribute editing cases, leading to a relative
drop in performance. In contrast, the generative model-based pipeline, despite
being hard to scale up, offers flexibility in handling attribute editing cases.
Therefore, we use generative model-based data to further fine-tune DreamVE.
Besides, we design an efficient and powerful editing framework for DreamVE. We
build on the SOTA T2V model and use a token concatenation with early drop
approach to inject source image guidance, ensuring strong consistency and
editability. The codes and models will be released.

</details>


### [114] [SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment](https://arxiv.org/abs/2508.06082)
*Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: SwiftVideo 是一种结合轨迹保持和分布匹配优势的统一稳定蒸馏框架，显著减少视频生成的推理步骤。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散或流的视频生成模型需要多次迭代采样，计算开销大；现有蒸馏方法在少步设置下性能下降或产生更多伪影。

Method: 提出连续时间一致性蒸馏确保ODE轨迹精确保持，并引入双视角对齐（分布对齐和轨迹对齐）。

Result: 在OpenVid-1M基准测试中，SwiftVideo在少步视频生成中显著优于现有方法。

Conclusion: SwiftVideo在保持高质量视频生成的同时，大幅减少了推理步骤。

Abstract: Diffusion-based or flow-based models have achieved significant progress in
video synthesis but require multiple iterative sampling steps, which incurs
substantial computational overhead. While many distillation methods that are
solely based on trajectory-preserving or distribution-matching have been
developed to accelerate video generation models, these approaches often suffer
from performance breakdown or increased artifacts under few-step settings. To
address these limitations, we propose \textbf{\emph{SwiftVideo}}, a unified and
stable distillation framework that combines the advantages of
trajectory-preserving and distribution-matching strategies. Our approach
introduces continuous-time consistency distillation to ensure precise
preservation of ODE trajectories. Subsequently, we propose a dual-perspective
alignment that includes distribution alignment between synthetic and real data
along with trajectory alignment across different inference steps. Our method
maintains high-quality video generation while substantially reducing the number
of inference steps. Quantitative evaluations on the OpenVid-1M benchmark
demonstrate that our method significantly outperforms existing approaches in
few-step video generation.

</details>


### [115] [AdaptInfer: Adaptive Token Pruning for Vision-Language Model Inference with Dynamical Text Guidance](https://arxiv.org/abs/2508.06084)
*Weichen Zhang,Zhui Zhu,Ningbo Li,Kebin Liu,Yunhao Liu*

Main category: cs.CV

TL;DR: 提出AdaptInfer框架，通过动态文本引导和跨模态注意力分析，自适应修剪视觉令牌，显著降低推理成本同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 现有修剪方法依赖静态文本提示或注意力模式，未能利用推理中的动态内部信号，导致效率不足。

Method: 引入动态文本引导修剪机制和跨模态注意力分析，设计高效修剪策略。

Result: 在LLaVA-1.5-7B上，CUDA延迟降低61.3%，平均精度保持92.9%，优于现有方法。

Conclusion: AdaptInfer是一种轻量级、即插即用的框架，在多模态任务中具有高效性和通用性。

Abstract: Vision-language models (VLMs) have achieved impressive performance on
multimodal reasoning tasks such as visual question answering (VQA), but their
inference cost remains a significant challenge due to the large number of
vision tokens processed during the prefill stage. Existing pruning methods
often rely on directly using the attention patterns or static text prompt
guidance, failing to exploit the dynamic internal signals generated during
inference. To address these issues, we propose AdaptInfer, a plug-and-play
framework for adaptive vision token pruning in VLMs. First, we introduce a
fine-grained, dynamic text-guided pruning mechanism that reuses layer-wise
text-to-text attention maps to construct soft priors over text-token
importance, allowing more informed scoring of vision tokens at each stage.
Second, we perform an offline analysis of cross-modal attention shifts and
identify consistent inflection locations in inference, which inspire us to
propose a more principled and efficient pruning schedule. Our method is
lightweight and plug-and-play, also generalizable across multi-modal tasks.
Experimental results have verified the effectiveness of the proposed method.
For example, it reduces CUDA latency by 61.3\% while maintaining an average
accuracy of 92.9\% on vanilla LLaVA-1.5-7B. Under the same token budget,
AdaptInfer surpasses SOTA in accuracy.

</details>


### [116] [Q-CLIP: Unleashing the Power of Vision-Language Models for Video Quality Assessment through Unified Cross-Modal Adaptation](https://arxiv.org/abs/2508.06092)
*Yachun Mi,Yu Li,Yanting Li,Shixin Sun,Chen Hui,Tong Zhang,Yuanyuan Liu,Chenyue Song,Shaohui Liu*

Main category: cs.CV

TL;DR: Q-CLIP是一个基于视觉语言模型（VLM）的视频质量评估（VQA）框架，通过共享跨模态适配器（SCMA）和可学习的质量提示，显著降低了计算成本并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前VQA方法依赖于大规模预训练，但存在语义知识迁移不足和计算资源消耗大的问题，而视觉语言模型在质量评估中展现出潜力。

Method: 提出Q-CLIP框架，采用SCMA减少可训练参数，引入质量提示增强模型对视频质量的敏感性，并研究帧采样策略的影响。

Result: 实验表明Q-CLIP在多个VQA数据集上表现优异，帧差采样策略有助于泛化性能。

Conclusion: Q-CLIP为VQA提供了一种高效且性能优越的解决方案，验证了视觉语言模型在此领域的潜力。

Abstract: Accurate and efficient Video Quality Assessment (VQA) has long been a key
research challenge. Current mainstream VQA methods typically improve
performance by pretraining on large-scale classification datasets (e.g.,
ImageNet, Kinetics-400), followed by fine-tuning on VQA datasets. However, this
strategy presents two significant challenges: (1) merely transferring semantic
knowledge learned from pretraining is insufficient for VQA, as video quality
depends on multiple factors (e.g., semantics, distortion, motion, aesthetics);
(2) pretraining on large-scale datasets demands enormous computational
resources, often dozens or even hundreds of times greater than training
directly on VQA datasets. Recently, Vision-Language Models (VLMs) have shown
remarkable generalization capabilities across a wide range of visual tasks, and
have begun to demonstrate promising potential in quality assessment. In this
work, we propose Q-CLIP, the first fully VLMs-based framework for VQA. Q-CLIP
enhances both visual and textual representations through a Shared Cross-Modal
Adapter (SCMA), which contains only a minimal number of trainable parameters
and is the only component that requires training. This design significantly
reduces computational cost. In addition, we introduce a set of five learnable
quality-level prompts to guide the VLMs in perceiving subtle quality
variations, thereby further enhancing the model's sensitivity to video quality.
Furthermore, we investigate the impact of different frame sampling strategies
on VQA performance, and find that frame-difference-based sampling leads to
better generalization performance across datasets. Extensive experiments
demonstrate that Q-CLIP exhibits excellent performance on several VQA datasets.

</details>


### [117] [E-React: Towards Emotionally Controlled Synthesis of Human Reactions](https://arxiv.org/abs/2508.06093)
*Chen Zhu,Buzhen Huang,Zijing Wu,Binghui Zuo,Yangang Wang*

Main category: cs.CV

TL;DR: 提出了一种基于情感驱动的反应动作生成方法，通过半监督情感先验和扩散模型提升生成动作的自然性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有动作生成框架未考虑情感影响，限制了交互任务中的自然性。本文旨在解决情感表示学习与动作生成的结合问题。

Method: 采用半监督学习训练情感先验，结合扩散模型生成反应动作，考虑空间交互和情感响应。

Result: 实验表明，该方法在反应动作生成任务中优于现有方法。

Conclusion: 提出的方法能生成多样且自然的反应动作，适用于情感驱动的交互任务。

Abstract: Emotion serves as an essential component in daily human interactions.
Existing human motion generation frameworks do not consider the impact of
emotions, which reduces naturalness and limits their application in interactive
tasks, such as human reaction synthesis. In this work, we introduce a novel
task: generating diverse reaction motions in response to different emotional
cues. However, learning emotion representation from limited motion data and
incorporating it into a motion generation framework remains a challenging
problem. To address the above obstacles, we introduce a semi-supervised emotion
prior in an actor-reactor diffusion model to facilitate emotion-driven reaction
synthesis. Specifically, based on the observation that motion clips within a
short sequence tend to share the same emotion, we first devise a
semi-supervised learning framework to train an emotion prior. With this prior,
we further train an actor-reactor diffusion model to generate reactions by
considering both spatial interaction and emotional response. Finally, given a
motion sequence of an actor, our approach can generate realistic reactions
under various emotional conditions. Experimental results demonstrate that our
model outperforms existing reaction generation methods. The code and data will
be made publicly available at https://ereact.github.io/

</details>


### [118] [UGD-IML: A Unified Generative Diffusion-based Framework for Constrained and Unconstrained Image Manipulation Localization](https://arxiv.org/abs/2508.06101)
*Yachun Mi,Xingyang He,Shixin Sun,Yu Li,Yanting Li,Zhixuan Li,Jian Jin,Chen Hui,Shaohui Liu*

Main category: cs.CV

TL;DR: 提出了一种基于扩散模型的生成框架UGD-IML，统一了图像篡改定位（IML）和约束IML（CIML）任务，减少了对大规模标注数据的依赖，并在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数字时代中高级图像编辑工具威胁视觉内容的真实性，现有IML方法依赖大规模标注数据，但数据集缺乏规模和多样性，限制了模型在实际场景中的表现。

Method: 提出UGD-IML框架，利用扩散模型学习数据分布，减少对标注数据的依赖，并通过类嵌入机制和参数共享设计实现IML和CIML任务的无缝切换。

Result: 在多个数据集上，UGD-IML在IML和CIML任务中的F1指标分别平均优于现有方法9.66和4.36。

Conclusion: UGD-IML通过生成模型和端到端设计，显著提升了篡改定位的性能和效率，同时具备不确定性估计和鲁棒性优势。

Abstract: In the digital age, advanced image editing tools pose a serious threat to the
integrity of visual content, making image forgery detection and localization a
key research focus. Most existing Image Manipulation Localization (IML) methods
rely on discriminative learning and require large, high-quality annotated
datasets. However, current datasets lack sufficient scale and diversity,
limiting model performance in real-world scenarios. To overcome this, recent
studies have explored Constrained IML (CIML), which generates pixel-level
annotations through algorithmic supervision. However, existing CIML approaches
often depend on complex multi-stage pipelines, making the annotation process
inefficient. In this work, we propose a novel generative framework based on
diffusion models, named UGD-IML, which for the first time unifies both IML and
CIML tasks within a single framework. By learning the underlying data
distribution, generative diffusion models inherently reduce the reliance on
large-scale labeled datasets, allowing our approach to perform effectively even
under limited data conditions. In addition, by leveraging a class embedding
mechanism and a parameter-sharing design, our model seamlessly switches between
IML and CIML modes without extra components or training overhead. Furthermore,
the end-to-end design enables our model to avoid cumbersome steps in the data
annotation process. Extensive experimental results on multiple datasets
demonstrate that UGD-IML outperforms the SOTA methods by an average of 9.66 and
4.36 in terms of F1 metrics for IML and CIML tasks, respectively. Moreover, the
proposed method also excels in uncertainty estimation, visualization and
robustness.

</details>


### [119] [MCA: 2D-3D Retrieval with Noisy Labels via Multi-level Adaptive Correction and Alignment](https://arxiv.org/abs/2508.06104)
*Gui Zou,Chaofan Gan,Chern Hong Lim,Supavadee Aramvith,Weiyao Lin*

Main category: cs.CV

TL;DR: 提出了一种名为MCA的鲁棒2D-3D跨模态检索框架，通过多模态联合标签校正和多层次自适应对齐，解决了噪声标签条件下的检索问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理噪声标签时容易过拟合，且缺乏跨模态一致性，需要更鲁棒的解决方案。

Method: 引入多模态联合标签校正（MJC）机制和多层次自适应对齐（MAA）策略，提升标签可靠性和特征语义。

Result: MCA在传统和噪声3D基准测试中均达到最优性能。

Conclusion: MCA框架具有通用性和高效性，显著提升了噪声条件下的跨模态检索性能。

Abstract: With the increasing availability of 2D and 3D data, significant advancements
have been made in the field of cross-modal retrieval. Nevertheless, the
existence of imperfect annotations presents considerable challenges, demanding
robust solutions for 2D-3D cross-modal retrieval in the presence of noisy label
conditions. Existing methods generally address the issue of noise by dividing
samples independently within each modality, making them susceptible to
overfitting on corrupted labels. To address these issues, we propose a robust
2D-3D \textbf{M}ulti-level cross-modal adaptive \textbf{C}orrection and
\textbf{A}lignment framework (MCA). Specifically, we introduce a Multimodal
Joint label Correction (MJC) mechanism that leverages multimodal historical
self-predictions to jointly model the modality prediction consistency, enabling
reliable label refinement. Additionally, we propose a Multi-level Adaptive
Alignment (MAA) strategy to effectively enhance cross-modal feature semantics
and discrimination across different levels. Extensive experiments demonstrate
the superiority of our method, MCA, which achieves state-of-the-art performance
on both conventional and realistic noisy 3D benchmarks, highlighting its
generality and effectiveness.

</details>


### [120] [Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention](https://arxiv.org/abs/2508.06107)
*Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu*

Main category: cs.CV

TL;DR: 提出了一种自监督学习框架用于手写数学表达式识别，通过全局和局部对比损失预训练图像编码器，并引入渐进空间掩码策略的自监督注意力网络，无需标注数据即可学习语义区域。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别因二维结构、符号尺度变化和复杂空间关系而具有挑战性，现有方法依赖昂贵标注数据。

Method: 结合全局和局部对比损失预训练图像编码器，设计自监督注意力网络，采用渐进空间掩码策略学习语义区域，最后用监督微调生成LATEX序列。

Result: 在CROHME基准测试中优于现有自监督和全监督基线，验证了渐进注意力机制的有效性。

Conclusion: 该方法通过自监督学习和渐进注意力机制，显著提升了手写数学表达式识别的性能，且无需依赖大量标注数据。

Abstract: Recognizing handwritten mathematical expressions (HMER) is a challenging task
due to the inherent two-dimensional structure, varying symbol scales, and
complex spatial relationships among symbols. In this paper, we present a
self-supervised learning (SSL) framework for HMER that eliminates the need for
expensive labeled data. Our approach begins by pretraining an image encoder
using a combination of global and local contrastive loss, enabling the model to
learn both holistic and fine-grained representations. A key contribution of
this work is a novel self-supervised attention network, which is trained using
a progressive spatial masking strategy. This attention mechanism is designed to
learn semantically meaningful focus regions, such as operators, exponents, and
nested mathematical notation, without requiring any supervision. The
progressive masking curriculum encourages the network to become increasingly
robust to missing or occluded visual information, ultimately improving
structural understanding. Our complete pipeline consists of (1) self-supervised
pretraining of the encoder, (2) self-supervised attention learning, and (3)
supervised fine-tuning with a transformer decoder to generate LATEX sequences.
Extensive experiments on CROHME benchmarks demonstrate that our method
outperforms existing SSL and fully supervised baselines, validating the
effectiveness of our progressive attention mechanism in enhancing HMER
performance. Our codebase can be found here.

</details>


### [121] [Effective Training Data Synthesis for Improving MLLM Chart Understanding](https://arxiv.org/abs/2508.06492)
*Yuwei Yang,Zeyu Zhang,Yunzhong Hou,Zhuowan Li,Gaowen Liu,Ali Payani,Yuan-Sen Ting,Liang Zheng*

Main category: cs.CV

TL;DR: 通过模块化和多样化视觉细节的图表生成方法，提升了多模态大语言模型（MLLMs）的图表理解能力，并提出了一个包含10k+图表和300k+问答对的有效图表数据集（ECD）。


<details>
  <summary>Details</summary>
Motivation: 现有开源MLLMs在图表理解任务上的成功率较低（30%-50%），且现有合成图表与真实图表相似度不足，影响了模型训练和性能。

Method: 设计了一个五步数据合成流程，包括模块化图表生成、多样化视觉细节、数据过滤和GPT-4o生成问答对，最终构建了ECD数据集。

Result: ECD显著提升了多种MLLMs在真实和合成测试集上的性能。

Conclusion: 模块化和多样化的图表生成方法以及ECD数据集为提升MLLMs的图表理解能力提供了有效解决方案。

Abstract: Being able to effectively read scientific plots, or chart understanding, is a
central part toward building effective agents for science. However, existing
multimodal large language models (MLLMs), especially open-source ones, are
still falling behind with a typical success rate of 30%-50% on challenging
benchmarks. Previous studies on fine-tuning MLLMs with synthetic charts are
often restricted by their inadequate similarity to the real charts, which could
compromise model training and performance on complex real-world charts. In this
study, we show that modularizing chart generation and diversifying visual
details improves chart understanding capabilities. In particular, we design a
five-step data synthesis pipeline, where we separate data and function creation
for single plot generation, condition the generation of later subplots on
earlier ones for multi-subplot figures, visually diversify the generated
figures, filter out low quality data, and finally generate the question-answer
(QA) pairs with GPT-4o. This approach allows us to streamline the generation of
fine-tuning datasets and introduce the effective chart dataset (ECD), which
contains 10k+ chart images and 300k+ QA pairs, covering 25 topics and featuring
250+ chart type combinations with high visual complexity. We show that ECD
consistently improves the performance of various MLLMs on a range of real-world
and synthetic test sets. Code, data and models are available at:
https://github.com/yuweiyang-anu/ECD.

</details>


### [122] [FMCE-Net++: Feature Map Convergence Evaluation and Training](https://arxiv.org/abs/2508.06109)
*Zhibo Zhu,Renyu Huang,Lei He*

Main category: cs.CV

TL;DR: FMCE-Net++是一种新的训练框架，通过整合预训练的FMCE-Net作为辅助头，动态平衡分类损失和特征收敛优化，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNNs）因内部表示不透明导致的解释性挑战，并弥补FMCE方法缺乏实验验证和闭环集成的不足。

Method: 提出FMCE-Net++框架，利用预训练的FMCE-Net生成特征图收敛分数（FMCS），结合任务标签通过表示辅助损失（RAL）动态优化主干网络。

Result: 在MNIST、CIFAR-10等数据集上验证，FMCE-Net++显著提升模型性能（如ResNet-50在CIFAR-10上准确率提升1.16个百分点）。

Conclusion: FMCE-Net++无需修改架构或增加数据即可有效提升模型性能，验证了其在优化现有技术性能方面的潜力。

Abstract: Deep Neural Networks (DNNs) face interpretability challenges due to their
opaque internal representations. While Feature Map Convergence Evaluation
(FMCE) quantifies module-level convergence via Feature Map Convergence Scores
(FMCS), it lacks experimental validation and closed-loop integration. To
address this limitation, we propose FMCE-Net++, a novel training framework that
integrates a pretrained, frozen FMCE-Net as an auxiliary head. This module
generates FMCS predictions, which, combined with task labels, jointly supervise
backbone optimization through a Representation Auxiliary Loss. The RAL
dynamically balances the primary classification loss and feature convergence
optimization via a tunable \Representation Abstraction Factor. Extensive
experiments conducted on MNIST, CIFAR-10, FashionMNIST, and CIFAR-100
demonstrate that FMCE-Net++ consistently enhances model performance without
architectural modifications or additional data. Key experimental outcomes
include accuracy gains of $+1.16$ pp (ResNet-50/CIFAR-10) and $+1.08$ pp
(ShuffleNet v2/CIFAR-100), validating that FMCE-Net++ can effectively elevate
state-of-the-art performance ceilings.

</details>


### [123] [GMF-Drive: Gated Mamba Fusion with Spatial-Aware BEV Representation for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.06113)
*Jian Wang,Chaokang Jiang,Haitao Xu*

Main category: cs.CV

TL;DR: GMF-Drive提出了一种基于门控Mamba融合的端到端自动驾驶框架，通过几何增强的LiDAR表示和高效的空间感知状态空间模型，克服了传统Transformer的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散模型的自动驾驶方法受限于Transformer的二次计算复杂性和缺乏空间先验，无法有效处理高分辨率特征和BEV表示的结构。

Method: 1. 使用几何增强的LiDAR表示（形状描述符和统计特征）；2. 提出分层门控Mamba融合（GM-Fusion）架构，替代Transformer。

Result: 在NAVSIM基准测试中，GMF-Drive显著优于DiffusionDrive，达到新的SOTA性能。

Conclusion: 任务特定的状态空间模型在性能和效率上优于通用Transformer，为自动驾驶提供了更优的解决方案。

Abstract: Diffusion-based models are redefining the state-of-the-art in end-to-end
autonomous driving, yet their performance is increasingly hampered by a
reliance on transformer-based fusion. These architectures face fundamental
limitations: quadratic computational complexity restricts the use of
high-resolution features, and a lack of spatial priors prevents them from
effectively modeling the inherent structure of Bird's Eye View (BEV)
representations. This paper introduces GMF-Drive (Gated Mamba Fusion for
Driving), an end-to-end framework that overcomes these challenges through two
principled innovations. First, we supersede the information-limited
histogram-based LiDAR representation with a geometrically-augmented pillar
format encoding shape descriptors and statistical features, preserving critical
3D geometric details. Second, we propose a novel hierarchical gated mamba
fusion (GM-Fusion) architecture that substitutes an expensive transformer with
a highly efficient, spatially-aware state-space model (SSM). Our core BEV-SSM
leverages directional sequencing and adaptive fusion mechanisms to capture
long-range dependencies with linear complexity, while explicitly respecting the
unique spatial properties of the driving scene. Extensive experiments on the
challenging NAVSIM benchmark demonstrate that GMF-Drive achieves a new
state-of-the-art performance, significantly outperforming DiffusionDrive.
Comprehensive ablation studies validate the efficacy of each component,
demonstrating that task-specific SSMs can surpass a general-purpose transformer
in both performance and efficiency for autonomous driving.

</details>


### [124] [SynSeg: Feature Synergy for Multi-Category Contrastive Learning in Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.06115)
*Weichen Zhang,Kebin Liu,Fan Dang,Zhui Zhu,Xikai Sun,Yunhao Liu*

Main category: cs.CV

TL;DR: SynSeg提出了一种新的弱监督语义分割方法，通过多类别对比学习（MCCL）和特征协同结构（FSS）提升性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开放词汇场景下的语义分割面临类别广泛性和细粒度的挑战，现有弱监督方法因依赖类别特定监督和特征构建不当导致语义对齐差。

Method: 提出MCCL策略结合类别内和类别间对齐与分离，FSS通过先验融合和语义激活图增强重构特征。

Result: 在多个基准测试中表现优异，如VOC提升4.5%，Context提升8.9%。

Conclusion: SynSeg显著提升了弱监督下的语义定位和区分能力，优于现有方法。

Abstract: Semantic segmentation in open-vocabulary scenarios presents significant
challenges due to the wide range and granularity of semantic categories.
Existing weakly-supervised methods often rely on category-specific supervision
and ill-suited feature construction methods for contrastive learning, leading
to semantic misalignment and poor performance. In this work, we propose a novel
weakly-supervised approach, SynSeg, to address the challenges. SynSeg performs
Multi-Category Contrastive Learning (MCCL) as a stronger training signal with a
new feature reconstruction framework named Feature Synergy Structure (FSS).
Specifically, MCCL strategy robustly combines both intra- and inter-category
alignment and separation in order to make the model learn the knowledge of
correlations from different categories within the same image. Moreover, FSS
reconstructs discriminative features for contrastive learning through prior
fusion and semantic-activation-map enhancement, effectively avoiding the
foreground bias introduced by the visual encoder. In general, SynSeg
effectively improves the abilities in semantic localization and discrimination
under weak supervision. Extensive experiments on benchmarks demonstrate that
our method outperforms state-of-the-art (SOTA) performance. For instance,
SynSeg achieves higher accuracy than SOTA baselines by 4.5\% on VOC, 8.9\% on
Context, 2.6\% on Object and 2.0\% on City.

</details>


### [125] [Learning Representations of Satellite Images with Evaluations on Synoptic Weather Events](https://arxiv.org/abs/2508.06122)
*Ting-Shuo Yo,Shih-Hao Su,Chien-Ming Wu,Wei-Ting Chen,Jung-Lien Chu,Chiao-Wei Chang,Hung-Chi Kuo*

Main category: cs.CV

TL;DR: 该研究通过表示学习算法分析卫星图像，评估不同天气事件的分类效果。结果表明，卷积自编码器（CAE）在分类任务中表现最佳，而预训练残差网络（PT）在热带气旋识别中表现突出。高分辨率数据集对深度学习算法更有利，但小潜在空间维度会增加误报率。未来可开发物理信息版本的CAE。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估不同表示学习算法在卫星图像中对天气事件分类的效果，以找到最优的潜在空间学习方法。

Method: 使用主成分分析（PCA）、卷积自编码器（CAE）和预训练残差网络（PT）对卫星图像进行表示学习，并评估分类性能。

Result: CAE在所有分类任务中表现最佳，PT在热带气旋识别中表现突出。高分辨率数据集对深度学习算法更有利，小潜在空间维度会增加误报率。

Conclusion: CAE能高效学习潜在空间，但缺乏物理可解释性。未来可开发物理信息版本的CAE以改进结果。

Abstract: This study applied representation learning algorithms to satellite images and
evaluated the learned latent spaces with classifications of various weather
events. The algorithms investigated include the classical linear
transformation, i.e., principal component analysis (PCA), state-of-the-art deep
learning method, i.e., convolutional autoencoder (CAE), and a residual network
pre-trained with large image datasets (PT). The experiment results indicated
that the latent space learned by CAE consistently showed higher threat scores
for all classification tasks. The classifications with PCA yielded high hit
rates but also high false-alarm rates. In addition, the PT performed
exceptionally well at recognizing tropical cyclones but was inferior in other
tasks. Further experiments suggested that representations learned from
higher-resolution datasets are superior in all classification tasks for
deep-learning algorithms, i.e., CAE and PT. We also found that smaller latent
space sizes had minor impact on the classification task's hit rate. Still, a
latent space dimension smaller than 128 caused a significantly higher false
alarm rate. Though the CAE can learn latent spaces effectively and efficiently,
the interpretation of the learned representation lacks direct connections to
physical attributions. Therefore, developing a physics-informed version of CAE
can be a promising outlook for the current work.

</details>


### [126] [Roll Your Eyes: Gaze Redirection via Explicit 3D Eyeball Rotation](https://arxiv.org/abs/2508.06136)
*YoungChan Choi,HengFei Wang,YiHua Cheng,Boeun Kim,Hyung Jin Chang,YoungGeun Choi,Sang-Il Choi*

Main category: cs.CV

TL;DR: 提出了一种基于3D眼球结构的新型3D视线重定向框架，通过显式建模眼球旋转和平移，结合自适应变形模块，生成高质量且准确的视线图像。


<details>
  <summary>Details</summary>
Motivation: 现有基于神经辐射场（NeRF）的视线重定向方法未显式建模3D表示的运动，导致效果受限。

Method: 采用3D高斯泼溅（3DGS）显式表示眼球结构，结合自适应变形模块模拟眼部肌肉运动。

Result: 在ETH-XGaze数据集上验证，生成图像质量和视线估计精度优于现有方法。

Conclusion: 显式3D眼球结构和自适应变形模块显著提升了视线重定向的逼真度和准确性。

Abstract: We propose a novel 3D gaze redirection framework that leverages an explicit
3D eyeball structure. Existing gaze redirection methods are typically based on
neural radiance fields, which employ implicit neural representations via volume
rendering. Unlike these NeRF-based approaches, where the rotation and
translation of 3D representations are not explicitly modeled, we introduce a
dedicated 3D eyeball structure to represent the eyeballs with 3D Gaussian
Splatting (3DGS). Our method generates photorealistic images that faithfully
reproduce the desired gaze direction by explicitly rotating and translating the
3D eyeball structure. In addition, we propose an adaptive deformation module
that enables the replication of subtle muscle movements around the eyes.
Through experiments conducted on the ETH-XGaze dataset, we demonstrate that our
framework is capable of generating diverse novel gaze images, achieving
superior image quality and gaze estimation accuracy compared to previous
state-of-the-art methods.

</details>


### [127] [SC-Captioner: Improving Image Captioning with Self-Correction by Reinforcement Learning](https://arxiv.org/abs/2508.06125)
*Lin Zhang,Xianfang Zeng,Kangcong Li,Gang Yu,Tao Chen*

Main category: cs.CV

TL;DR: SC-Captioner是一个基于强化学习的框架，通过奖励函数设计提升图像描述模型的自我修正能力，显著优于直接偏好优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有图像描述模型缺乏自我修正能力，导致生成的描述不够准确。

Method: 利用场景图解析算法分解描述为对象、属性和关系集合，通过集合差异计算奖励函数，激励准确修正。

Result: 实验表明，SC-Captioner能生成更优的图像描述，显著优于基线方法。

Conclusion: SC-Captioner通过强化学习和精细奖励设计，有效提升了图像描述的质量和准确性。

Abstract: We propose SC-Captioner, a reinforcement learning framework that enables the
self-correcting capability of image caption models. Our crucial technique lies
in the design of the reward function to incentivize accurate caption
corrections. Specifically, the predicted and reference captions are decomposed
into object, attribute, and relation sets using scene-graph parsing algorithms.
We calculate the set difference between sets of initial and self-corrected
captions to identify added and removed elements. These elements are matched
against the reference sets to calculate correctness bonuses for accurate
refinements and mistake punishments for wrong additions and removals, thereby
forming the final reward. For image caption quality assessment, we propose a
set of metrics refined from CAPTURE that alleviate its incomplete precision
evaluation and inefficient relation matching problems. Furthermore, we collect
a fine-grained annotated image caption dataset, RefinedCaps, consisting of 6.5K
diverse images from COCO dataset. Experiments show that applying SC-Captioner
on large visual-language models can generate better image captions across
various scenarios, significantly outperforming the direct preference
optimization training strategy.

</details>


### [128] [SAM Encoder Breach by Adversarial Simplicial Complex Triggers Downstream Model Failures](https://arxiv.org/abs/2508.06127)
*Yi Qin,Rui Wang,Tao Huang,Tong Xiao,Liping Jing*

Main category: cs.CV

TL;DR: VeSCA方法通过利用SAM编码器生成可转移的对抗样本，显著提升了对抗攻击的跨域性能。


<details>
  <summary>Details</summary>
Motivation: 评估SAM模型的潜在漏洞对下游应用的影响，并提出一种更有效的对抗攻击方法。

Method: 提出Vertex-Refining Simplicial Complex Attack (VeSCA)，通过参数化单纯复形和迭代顶点细化生成对抗样本。

Result: VeSCA在五个领域数据集上比现有方法性能提升12.7%。

Conclusion: SAM的漏洞对下游模型构成风险，需开发更鲁棒的基础模型。

Abstract: While the Segment Anything Model (SAM) transforms interactive segmentation
with zero-shot abilities, its inherent vulnerabilities present a single-point
risk, potentially leading to the failure of numerous downstream applications.
Proactively evaluating these transferable vulnerabilities is thus imperative.
Prior adversarial attacks on SAM often present limited transferability due to
insufficient exploration of common weakness across domains. To address this, we
propose Vertex-Refining Simplicial Complex Attack (VeSCA), a novel method that
leverages only the encoder of SAM for generating transferable adversarial
examples. Specifically, it achieves this by explicitly characterizing the
shared vulnerable regions between SAM and downstream models through a
parametric simplicial complex. Our goal is to identify such complexes within
adversarially potent regions by iterative vertex-wise refinement. A lightweight
domain re-adaptation strategy is introduced to bridge domain divergence using
minimal reference data during the initialization of simplicial complex.
Ultimately, VeSCA generates consistently transferable adversarial examples
through random simplicial complex sampling. Extensive experiments demonstrate
that VeSCA achieves performance improved by 12.7% compared to state-of-the-art
methods across three downstream model categories across five domain-specific
datasets. Our findings further highlight the downstream model risks posed by
SAM's vulnerabilities and emphasize the urgency of developing more robust
foundation models.

</details>


### [129] [UW-3DGS: Underwater 3D Reconstruction with Physics-Aware Gaussian Splatting](https://arxiv.org/abs/2508.06169)
*Wenpeng Xing,Jie Chen,Zaifeng Yang,Changting Lin,Jianfeng Dong,Chaochao Chen,Xun Zhou,Meng Han*

Main category: cs.CV

TL;DR: 论文提出UW-3DGS框架，通过3D高斯泼溅技术改进水下3D场景重建，解决传统方法在浑浊环境中的几何和颜色保真度问题。


<details>
  <summary>Details</summary>
Motivation: 水下3D重建因光线吸收、散射和浑浊问题导致传统方法（如NeRF）效果不佳，现有扩展方法（如SeaThru-NeRF）效率低且分辨率受限。

Method: 采用3D高斯泼溅技术，结合可学习的基于体素的水下图像形成模块和物理感知不确定性剪枝（PAUP）分支，优化训练和渲染过程。

Result: 在SeaThru-NeRF和UWBundle数据集上表现优异，PSNR达27.604，SSIM为0.868，LPIPS为0.104，浮游伪影减少约65%。

Conclusion: UW-3DGS框架显著提升水下3D重建质量，有效减少伪影，适用于复杂水下环境。

Abstract: Underwater 3D scene reconstruction faces severe challenges from light
absorption, scattering, and turbidity, which degrade geometry and color
fidelity in traditional methods like Neural Radiance Fields (NeRF). While NeRF
extensions such as SeaThru-NeRF incorporate physics-based models, their MLP
reliance limits efficiency and spatial resolution in hazy environments. We
introduce UW-3DGS, a novel framework adapting 3D Gaussian Splatting (3DGS) for
robust underwater reconstruction. Key innovations include: (1) a plug-and-play
learnable underwater image formation module using voxel-based regression for
spatially varying attenuation and backscatter; and (2) a Physics-Aware
Uncertainty Pruning (PAUP) branch that adaptively removes noisy floating
Gaussians via uncertainty scoring, ensuring artifact-free geometry. The
pipeline operates in training and rendering stages. During training, noisy
Gaussians are optimized end-to-end with underwater parameters, guided by PAUP
pruning and scattering modeling. In rendering, refined Gaussians produce clean
Unattenuated Radiance Images (URIs) free from media effects, while learned
physics enable realistic Underwater Images (UWIs) with accurate light
transport. Experiments on SeaThru-NeRF and UWBundle datasets show superior
performance, achieving PSNR of 27.604, SSIM of 0.868, and LPIPS of 0.104 on
SeaThru-NeRF, with ~65% reduction in floating artifacts.

</details>


### [130] [DiffCap: Diffusion-based Real-time Human Motion Capture using Sparse IMUs and a Monocular Camera](https://arxiv.org/abs/2508.06139)
*Shaohua Pan,Xinyu Yi,Yan Zhou,Weihua Jian,Yuan Zhang,Pengfei Wan,Feng Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于扩散模型的方法，结合稀疏IMU和单目摄像头进行实时人体运动捕捉，通过融合两种信号模态并考虑其特性，实现了鲁棒且高效的姿态估计。


<details>
  <summary>Details</summary>
Motivation: 结合稀疏IMU和单目摄像头进行实时运动捕捉是一个有前景的方向，但需要解决视觉信息偶尔不可用的问题以及如何有效融合两种信号模态。

Method: 将视觉信息整体转化为条件嵌入，而IMU测量与噪声姿态逐帧结合作为扩散模型的输入，充分利用两种信号的特性。

Result: 实验表明该方法在姿态估计上表现优异，达到了最先进的性能。

Conclusion: 该方法通过巧妙设计信号融合方式，实现了对视觉信息退化和IMU信号稳定性的鲁棒处理，为实时运动捕捉提供了有效解决方案。

Abstract: Combining sparse IMUs and a monocular camera is a new promising setting to
perform real-time human motion capture. This paper proposes a diffusion-based
solution to learn human motion priors and fuse the two modalities of signals
together seamlessly in a unified framework. By delicately considering the
characteristics of the two signals, the sequential visual information is
considered as a whole and transformed into a condition embedding, while the
inertial measurement is concatenated with the noisy body pose frame by frame to
construct a sequential input for the diffusion model. Firstly, we observe that
the visual information may be unavailable in some frames due to occlusions or
subjects moving out of the camera view. Thus incorporating the sequential
visual features as a whole to get a single feature embedding is robust to the
occasional degenerations of visual information in those frames. On the other
hand, the IMU measurements are robust to occlusions and always stable when
signal transmission has no problem. So incorporating them frame-wisely could
better explore the temporal information for the system. Experiments have
demonstrated the effectiveness of the system design and its state-of-the-art
performance in pose estimation compared with the previous works. Our codes are
available for research at https://shaohua-pan.github.io/diffcap-page.

</details>


### [131] [Synthetic Data-Driven Multi-Architecture Framework for Automated Polyp Segmentation Through Integrated Detection and Mask Generation](https://arxiv.org/abs/2508.06170)
*Ojonugwa Oluwafemi Ejiga Peter,Akingbola Oluwapemiisin,Amalahu Chetachi,Adeniran Opeyemi,Fahmi Khalifa,Md Mahmudur Rahman*

Main category: cs.CV

TL;DR: 研究提出了一种多方向架构框架，用于自动化结肠镜图像中的息肉检测，结合合成数据生成和检测分割算法，显著提升了检测和分割性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜检查是结直肠癌早期诊断的关键工具，但医疗数据集规模有限且标注复杂，因此需要自动化解决方案以提高效率和准确性。

Method: 采用Faster R-CNN进行初始目标定位，结合Segment Anything Model（SAM）优化分割掩码，并通过Stable Diffusion生成合成数据。评估了五种分割模型（U-Net、PSPNet、FPN、LinkNet、MANet）。

Result: Faster R-CNN的召回率为93.08%，精确率为88.97%，F1分数为90.98%。FPN在PSNR和SSIM上表现最佳，U-Net在召回率上领先，LinkNet在IoU和Dice分数上表现均衡。

Conclusion: 该框架有效解决了数据集和标注的挑战，显著提升了息肉检测和分割的性能，为结直肠癌早期诊断提供了有力工具。

Abstract: Colonoscopy is a vital tool for the early diagnosis of colorectal cancer,
which is one of the main causes of cancer-related mortality globally; hence, it
is deemed an essential technique for the prevention and early detection of
colorectal cancer. The research introduces a unique multidirectional
architectural framework to automate polyp detection within colonoscopy images
while helping resolve limited healthcare dataset sizes and annotation
complexities. The research implements a comprehensive system that delivers
synthetic data generation through Stable Diffusion enhancements together with
detection and segmentation algorithms. This detection approach combines Faster
R-CNN for initial object localization while the Segment Anything Model (SAM)
refines the segmentation masks. The faster R-CNN detection algorithm achieved a
recall of 93.08% combined with a precision of 88.97% and an F1 score of
90.98%.SAM is then used to generate the image mask. The research evaluated five
state-of-the-art segmentation models that included U-Net, PSPNet, FPN, LinkNet,
and MANet using ResNet34 as a base model. The results demonstrate the superior
performance of FPN with the highest scores of PSNR (7.205893) and SSIM
(0.492381), while UNet excels in recall (84.85%) and LinkNet shows balanced
performance in IoU (64.20%) and Dice score (77.53%).

</details>


### [132] [SDEval: Safety Dynamic Evaluation for Multimodal Large Language Models](https://arxiv.org/abs/2508.06142)
*Hanqing Wang,Yuan Tian,Mingyu Liu,Zhenhao Zhang,Xiangyang Zhu*

Main category: cs.CV

TL;DR: SDEval是一个动态评估框架，用于调整多模态大语言模型（MLLMs）安全基准的分布和复杂性，以解决数据过时和污染问题。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs的发展，现有安全基准可能过时且易受数据污染，需要动态评估方法。

Method: SDEval采用文本、图像和文本-图像动态策略生成新样本，研究其对模型安全性的影响。

Result: 实验表明，SDEval显著影响安全评估，缓解数据污染，并暴露MLLMs的安全局限性。

Conclusion: SDEval是一个通用框架，适用于现有安全和能力基准，为MLLMs的安全性评估提供了新方法。

Abstract: In the rapidly evolving landscape of Multimodal Large Language Models
(MLLMs), the safety concerns of their outputs have earned significant
attention. Although numerous datasets have been proposed, they may become
outdated with MLLM advancements and are susceptible to data contamination
issues. To address these problems, we propose \textbf{SDEval}, the
\textit{first} safety dynamic evaluation framework to controllably adjust the
distribution and complexity of safety benchmarks. Specifically, SDEval mainly
adopts three dynamic strategies: text, image, and text-image dynamics to
generate new samples from original benchmarks. We first explore the individual
effects of text and image dynamics on model safety. Then, we find that
injecting text dynamics into images can further impact safety, and conversely,
injecting image dynamics into text also leads to safety risks. SDEval is
general enough to be applied to various existing safety and even capability
benchmarks. Experiments across safety benchmarks, MLLMGuard and VLSBench, and
capability benchmarks, MMBench and MMVet, show that SDEval significantly
influences safety evaluation, mitigates data contamination, and exposes safety
limitations of MLLMs. Code is available at https://github.com/hq-King/SDEval

</details>


### [133] [LoRA in LoRA: Towards Parameter-Efficient Architecture Expansion for Continual Visual Instruction Tuning](https://arxiv.org/abs/2508.06202)
*Chang Che,Ziqi Wang,Pengwan Yang,Qi Wang,Hui Ma,Zenglin Shi*

Main category: cs.CV

TL;DR: LiLoRA是一种高效的架构扩展方法，用于解决多模态大语言模型在持续视觉指令调整中的灾难性遗忘问题，通过共享LoRA矩阵和低秩分解减少参数冗余，同时引入余弦正则化稳定性损失保持共享表示的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决持续视觉指令调整中灾难性遗忘问题，同时减少参数冗余和提高可扩展性。

Method: 提出LiLoRA方法，共享LoRA矩阵A，对矩阵B进行低秩分解以减少任务特定参数，并引入余弦正则化稳定性损失。

Result: 在多样化CVIT基准测试中，LiLoRA在顺序任务学习中表现优异，显著提高了参数效率。

Conclusion: LiLoRA是一种高效且可扩展的方法，适用于持续视觉指令调整，解决了灾难性遗忘和参数冗余问题。

Abstract: Continual Visual Instruction Tuning (CVIT) enables Multimodal Large Language
Models (MLLMs) to incrementally learn new tasks over time. However, this
process is challenged by catastrophic forgetting, where performance on
previously learned tasks deteriorates as the model adapts to new ones. A common
approach to mitigate forgetting is architecture expansion, which introduces
task-specific modules to prevent interference. Yet, existing methods often
expand entire layers for each task, leading to significant parameter overhead
and poor scalability. To overcome these issues, we introduce LoRA in LoRA
(LiLoRA), a highly efficient architecture expansion method tailored for CVIT in
MLLMs. LiLoRA shares the LoRA matrix A across tasks to reduce redundancy,
applies an additional low-rank decomposition to matrix B to minimize
task-specific parameters, and incorporates a cosine-regularized stability loss
to preserve consistency in shared representations over time. Extensive
experiments on a diverse CVIT benchmark show that LiLoRA consistently achieves
superior performance in sequential task learning while significantly improving
parameter efficiency compared to existing approaches.

</details>


### [134] [Text-guided Visual Prompt DINO for Generic Segmentation](https://arxiv.org/abs/2508.06146)
*Yuchen Guan,Chong Sun,Canmiao Fu,Zhipeng Huang,Chun Yuan,Chen Li*

Main category: cs.CV

TL;DR: Prompt-DINO提出了一种文本引导的视觉Prompt DINO框架，通过早期融合机制、顺序对齐查询选择和生成数据引擎，解决了开放世界分割中的特征融合和查询选择问题，并在性能和数据生成方面取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决多模态视觉模型中晚期特征融合、查询选择不优以及固定词汇表限制的问题。

Method: 1. 早期融合机制统一文本/视觉提示和主干特征；2. 顺序对齐查询选择优化文本与视觉查询的结构对齐；3. 生成数据引擎通过RAP模型合成多样化训练数据。

Result: 在开放世界检测基准上实现最先进性能，语义覆盖显著扩展，标签噪声减少80.5%。

Conclusion: Prompt-DINO为开放世界场景中的可扩展多模态检测和数据生成建立了新范式。

Abstract: Recent advancements in multimodal vision models have highlighted limitations
in late-stage feature fusion and suboptimal query selection for hybrid prompts
open-world segmentation, alongside constraints from caption-derived
vocabularies. To address these challenges, we propose Prompt-DINO, a
text-guided visual Prompt DINO framework featuring three key innovations.
First, we introduce an early fusion mechanism that unifies text/visual prompts
and backbone features at the initial encoding stage, enabling deeper
cross-modal interactions to resolve semantic ambiguities. Second, we design
order-aligned query selection for DETR-based architectures, explicitly
optimizing the structural alignment between text and visual queries during
decoding to enhance semantic-spatial consistency. Third, we develop a
generative data engine powered by the Recognize Anything via Prompting (RAP)
model, which synthesizes 0.5B diverse training instances through a dual-path
cross-verification pipeline, reducing label noise by 80.5% compared to
conventional approaches. Extensive experiments demonstrate that Prompt-DINO
achieves state-of-the-art performance on open-world detection benchmarks while
significantly expanding semantic coverage beyond fixed-vocabulary constraints.
Our work establishes a new paradigm for scalable multimodal detection and data
generation in open-world scenarios. Data&Code are available at
https://github.com/WeChatCV/WeVisionOne.

</details>


### [135] [DSConv: Dynamic Splitting Convolution for Pansharpening](https://arxiv.org/abs/2508.06147)
*Xuanyu Liu,Bonan An*

Main category: cs.CV

TL;DR: 提出了一种名为DSConv的动态卷积核分割方法，结合注意力机制提升图像融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法多依赖标准卷积，忽视了自适应卷积在遥感图像中的潜力。

Method: 动态分割卷积核并结合注意力机制，选择感兴趣位置，提升特征提取能力。

Result: DSConv在泛化性、优化和特征表示方面表现优异，达到先进水平。

Conclusion: DSConv在图像融合任务中表现出优越性和高效性。

Abstract: Aiming to obtain a high-resolution image, pansharpening involves the fusion
of a multi-spectral image (MS) and a panchromatic image (PAN), the low-level
vision task remaining significant and challenging in contemporary research.
Most existing approaches rely predominantly on standard convolutions, few
making the effort to adaptive convolutions, which are effective owing to the
inter-pixel correlations of remote sensing images. In this paper, we propose a
novel strategy for dynamically splitting convolution kernels in conjunction
with attention, selecting positions of interest, and splitting the original
convolution kernel into multiple smaller kernels, named DSConv. The proposed
DSConv more effectively extracts features of different positions within the
receptive field, enhancing the network's generalization, optimization, and
feature representation capabilities. Furthermore, we innovate and enrich
concepts of dynamic splitting convolution and provide a novel network
architecture for pansharpening capable of achieving the tasks more efficiently,
building upon this methodology. Adequate fair experiments illustrate the
effectiveness and the state-of-the-art performance attained by
DSConv.Comprehensive and rigorous discussions proved the superiority and
optimal usage conditions of DSConv.

</details>


### [136] [VISTAR:A User-Centric and Role-Driven Benchmark for Text-to-Image Evaluation](https://arxiv.org/abs/2508.06152)
*Kaiyuan Jiang,Ruoxi Sun,Ying Cao,Yuqi Xu,Xinran Zhang,Junyan Guo,ChengSheng Deng*

Main category: cs.CV

TL;DR: VISTAR是一个用户中心的多维度文本到图像（T2I）评估基准，结合确定性指标和创新的HWPQ方案，显著提升了评估的准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有T2I评估指标存在局限性，VISTAR旨在通过多维度、用户中心的基准解决这些问题。

Method: 采用两阶段混合范式：确定性指标量化物理属性，HWPQ方案评估抽象语义。基于专家研究定义用户角色和评估角度。

Result: 指标与人类评估高度一致（>75%），HWPQ在抽象语义上达到85.9%准确率，显著优于基线。

Conclusion: VISTAR提供了可复现的T2I评估资源，揭示了模型在不同领域的表现差异，为实际部署提供指导。

Abstract: We present VISTAR, a user-centric, multi-dimensional benchmark for
text-to-image (T2I) evaluation that addresses the limitations of existing
metrics. VISTAR introduces a two-tier hybrid paradigm: it employs
deterministic, scriptable metrics for physically quantifiable attributes (e.g.,
text rendering, lighting) and a novel Hierarchical Weighted P/N Questioning
(HWPQ) scheme that uses constrained vision-language models to assess abstract
semantics (e.g., style fusion, cultural fidelity). Grounded in a Delphi study
with 120 experts, we defined seven user roles and nine evaluation angles to
construct the benchmark, which comprises 2,845 prompts validated by over 15,000
human pairwise comparisons. Our metrics achieve high human alignment (>75%),
with the HWPQ scheme reaching 85.9% accuracy on abstract semantics,
significantly outperforming VQA baselines. Comprehensive evaluation of
state-of-the-art models reveals no universal champion, as role-weighted scores
reorder rankings and provide actionable guidance for domain-specific
deployment. All resources are publicly released to foster reproducible T2I
assessment.

</details>


### [137] [SIFThinker: Spatially-Aware Image Focus for Visual Reasoning](https://arxiv.org/abs/2508.06259)
*Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang*

Main category: cs.CV

TL;DR: SIFThinker是一个空间感知的多模态框架，通过深度增强的边界框和自然语言交互，提升视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在复杂视觉任务（如空间理解和细粒度感知）中表现不足，缺乏利用空间线索进行注意力修正的能力。

Method: 提出SIFThinker框架，采用反向扩展前向推理策略生成图像-文本链，并结合GRPO-SIF训练范式，动态修正注意力。

Result: SIFThinker在空间理解和细粒度视觉感知任务中优于现有方法，同时保持通用能力。

Conclusion: SIFThinker通过空间感知和动态注意力修正，显著提升了复杂视觉任务的性能。

Abstract: Current multimodal large language models (MLLMs) still face significant
challenges in complex visual tasks (e.g., spatial understanding, fine-grained
perception). Prior methods have tried to incorporate visual reasoning, however,
they fail to leverage attention correction with spatial cues to iteratively
refine their focus on prompt-relevant regions. In this paper, we introduce
SIFThinker, a spatially-aware "think-with-images" framework that mimics human
visual perception. Specifically, SIFThinker enables attention correcting and
image region focusing by interleaving depth-enhanced bounding boxes and natural
language. Our contributions are twofold: First, we introduce a
reverse-expansion-forward-inference strategy that facilitates the generation of
interleaved image-text chains of thought for process-level supervision, which
in turn leads to the construction of the SIF-50K dataset. Besides, we propose
GRPO-SIF, a reinforced training paradigm that integrates depth-informed visual
grounding into a unified reasoning pipeline, teaching the model to dynamically
correct and focus on prompt-relevant regions. Extensive experiments demonstrate
that SIFThinker outperforms state-of-the-art methods in spatial understanding
and fine-grained visual perception, while maintaining strong general
capabilities, highlighting the effectiveness of our method.

</details>


### [138] [An Interpretable Multi-Plane Fusion Framework With Kolmogorov-Arnold Network Guided Attention Enhancement for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.06157)
*Xiaoxiao Yang,Meiliang Liu,Yunfang Xu,Zijin Li,Zhengye Si,Xinyue Yang,Zhiwen Zhao*

Main category: cs.CV

TL;DR: 提出了一种名为MPF-KANSC的创新框架，通过多平面融合和KANSC注意力机制，提升阿尔茨海默病（AD）的早期诊断精度。


<details>
  <summary>Details</summary>
Motivation: AD的早期诊断因脑部结构变化的复杂性而具有挑战性，现有深度学习方法难以准确捕捉病理区域的非线性关系。

Method: 结合多平面融合（MPF）和KANSC注意力机制，并行提取多平面特征并精确识别异常。

Result: 在ADNI数据集上验证了MPF-KANSC的优越性能，并发现AD进展中右偏侧化的结构变化。

Conclusion: MPF-KANSC在AD诊断中表现优异，具有较高的可解释性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder that
severely impairs cognitive function and quality of life. Timely intervention in
AD relies heavily on early and precise diagnosis, which remains challenging due
to the complex and subtle structural changes in the brain. Most existing deep
learning methods focus only on a single plane of structural magnetic resonance
imaging (sMRI) and struggle to accurately capture the complex and nonlinear
relationships among pathological regions of the brain, thus limiting their
ability to precisely identify atrophic features. To overcome these limitations,
we propose an innovative framework, MPF-KANSC, which integrates multi-plane
fusion (MPF) for combining features from the coronal, sagittal, and axial
planes, and a Kolmogorov-Arnold Network-guided spatial-channel attention
mechanism (KANSC) to more effectively learn and represent sMRI atrophy
features. Specifically, the proposed model enables parallel feature extraction
from multiple anatomical planes, thus capturing more comprehensive structural
information. The KANSC attention mechanism further leverages a more flexible
and accurate nonlinear function approximation technique, facilitating precise
identification and localization of disease-related abnormalities. Experiments
on the ADNI dataset confirm that the proposed MPF-KANSC achieves superior
performance in AD diagnosis. Moreover, our findings provide new evidence of
right-lateralized asymmetry in subcortical structural changes during AD
progression, highlighting the model's promising interpretability.

</details>


### [139] [Mixture of Experts Guided by Gaussian Splatters Matters: A new Approach to Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.06318)
*Giacomo D'Amicantonio,Snehashis Majhi,Quan Kong,Lorenzo Garattoni,Gianpiero Francesca,François Bremond,Egor Bondarev*

Main category: cs.CV

TL;DR: 论文提出了一种名为GS-MoE的新框架，通过专家模型和时序高斯损失改进弱监督视频异常检测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测模型在处理复杂异常时表现不佳，主要因为模型无法区分异常类别且弱监督信号缺乏精确时序信息。

Method: 提出GS-MoE框架，使用多个专家模型分别捕捉特定异常类型，并通过时序高斯损失增强弱监督信号。

Result: 在UCF-Crime数据集上达到91.58%的AUC，在XD-Violence和MSAD数据集上也表现优异。

Conclusion: GS-MoE通过类别特异性专家和时序引导，为弱监督视频异常检测设定了新标准。

Abstract: Video Anomaly Detection (VAD) is a challenging task due to the variability of
anomalous events and the limited availability of labeled data. Under the
Weakly-Supervised VAD (WSVAD) paradigm, only video-level labels are provided
during training, while predictions are made at the frame level. Although
state-of-the-art models perform well on simple anomalies (e.g., explosions),
they struggle with complex real-world events (e.g., shoplifting). This
difficulty stems from two key issues: (1) the inability of current models to
address the diversity of anomaly types, as they process all categories with a
shared model, overlooking category-specific features; and (2) the weak
supervision signal, which lacks precise temporal information, limiting the
ability to capture nuanced anomalous patterns blended with normal events. To
address these challenges, we propose Gaussian Splatting-guided Mixture of
Experts (GS-MoE), a novel framework that employs a set of expert models, each
specialized in capturing specific anomaly types. These experts are guided by a
temporal Gaussian splatting loss, enabling the model to leverage temporal
consistency and enhance weak supervision. The Gaussian splatting approach
encourages a more precise and comprehensive representation of anomalies by
focusing on temporal segments most likely to contain abnormal events. The
predictions from these specialized experts are integrated through a
mixture-of-experts mechanism to model complex relationships across diverse
anomaly patterns. Our approach achieves state-of-the-art performance, with a
91.58% AUC on the UCF-Crime dataset, and demonstrates superior results on
XD-Violence and MSAD datasets. By leveraging category-specific expertise and
temporal guidance, GS-MoE sets a new benchmark for VAD under weak supervision.

</details>


### [140] [Fewer Denoising Steps or Cheaper Per-Step Inference: Towards Compute-Optimal Diffusion Model Deployment](https://arxiv.org/abs/2508.06160)
*Zhenbang Du,Yonggan Fu,Lifu Wang,Jiayi Qian,Xiao Luo,Yingyan,Lin*

Main category: cs.CV

TL;DR: PostDiff提出了一种无需训练的后处理框架，通过减少去噪步骤中的冗余来加速预训练扩散模型，同时在输入和模块级别优化计算效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现出色，但高计算需求限制了其在资源有限平台上的部署。研究旨在探索在无需微调的后训练设置下，减少去噪步骤或降低每步计算成本哪种更有效。

Method: PostDiff框架包括混合分辨率去噪方案和模块级缓存策略，以减少输入和模块级别的冗余。

Result: 实验表明，PostDiff显著提升了扩散模型的效率与生成质量的平衡，且降低每步计算成本比减少去噪步骤更有效。

Conclusion: PostDiff为资源受限环境下的扩散模型部署提供了高效解决方案，同时保持生成质量。

Abstract: Diffusion models have shown remarkable success across generative tasks, yet
their high computational demands challenge deployment on resource-limited
platforms. This paper investigates a critical question for compute-optimal
diffusion model deployment: Under a post-training setting without fine-tuning,
is it more effective to reduce the number of denoising steps or to use a
cheaper per-step inference? Intuitively, reducing the number of denoising steps
increases the variability of the distributions across steps, making the model
more sensitive to compression. In contrast, keeping more denoising steps makes
the differences smaller, preserving redundancy, and making post-training
compression more feasible. To systematically examine this, we propose PostDiff,
a training-free framework for accelerating pre-trained diffusion models by
reducing redundancy at both the input level and module level in a post-training
manner. At the input level, we propose a mixed-resolution denoising scheme
based on the insight that reducing generation resolution in early denoising
steps can enhance low-frequency components and improve final generation
fidelity. At the module level, we employ a hybrid module caching strategy to
reuse computations across denoising steps. Extensive experiments and ablation
studies demonstrate that (1) PostDiff can significantly improve the
fidelity-efficiency trade-off of state-of-the-art diffusion models, and (2) to
boost efficiency while maintaining decent generation fidelity, reducing
per-step inference cost is often more effective than reducing the number of
denoising steps. Our code is available at
https://github.com/GATECH-EIC/PostDiff.

</details>


### [141] [Are you In or Out (of gallery)? Wisdom from the Same-Identity Crowd](https://arxiv.org/abs/2508.06357)
*Aman Bhatta,Maria Dhakal,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 论文提出了一种新方法，利用额外注册图像预测一对一多人脸识别中的“库内”或“库外”结果，以减少误识别。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法仅依赖相似度阈值的问题，提高识别准确性并减少误判。

Method: 通过生成训练数据并训练分类器，利用额外注册图像的排名特征预测结果。

Result: 实验证明方法在多种图像质量下有效，且在不同人口统计组中表现一致。

Conclusion: 该方法可减少误识别和调查时间，且仅适用于使用高级损失函数训练的匹配器。

Abstract: A central problem in one-to-many facial identification is that the person in
the probe image may or may not have enrolled image(s) in the gallery; that is,
may be In-gallery or Out-of-gallery. Past approaches to detect when a rank-one
result is Out-of-gallery have mostly focused on finding a suitable threshold on
the similarity score. We take a new approach, using the additional enrolled
images of the identity with the rank-one result to predict if the rank-one
result is In-gallery / Out-of-gallery. Given a gallery of identities and
images, we generate In-gallery and Out-of-gallery training data by extracting
the ranks of additional enrolled images corresponding to the rank-one identity.
We then train a classifier to utilize this feature vector to predict whether a
rank-one result is In-gallery or Out-of-gallery. Using two different datasets
and four different matchers, we present experimental results showing that our
approach is viable for mugshot quality probe images, and also, importantly, for
probes degraded by blur, reduced resolution, atmospheric turbulence and
sunglasses. We also analyze results across demographic groups, and show that
In-gallery / Out-of-gallery classification accuracy is similar across
demographics. Our approach has the potential to provide an objective estimate
of whether a one-to-many facial identification is Out-of-gallery, and thereby
to reduce false positive identifications, wrongful arrests, and wasted
investigative time. Interestingly, comparing the results of older deep
CNN-based face matchers with newer ones suggests that the effectiveness of our
Out-of-gallery detection approach emerges only with matchers trained using
advanced margin-based loss functions.

</details>


### [142] [A Classification-Aware Super-Resolution Framework for Ship Targets in SAR Imagery](https://arxiv.org/abs/2508.06407)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文探讨了将分类目标直接融入超分辨率过程是否能提升分类准确性，并提出了一种优化图像质量和分类性能的新型方法。


<details>
  <summary>Details</summary>
Motivation: 低分辨率图像限制了自动化分析的准确性，传统超分辨率方法仅关注像素级指标，未充分探索超分辨率图像保真度与下游分类性能的关系。

Method: 提出了一种新颖的方法，通过优化同时考虑图像质量和分类性能的损失函数，提升合成孔径雷达图像的分辨率。

Result: 该方法在科学验证的图像质量指标上提升了图像质量，同时提高了分类准确性。

Conclusion: 研究表明，将分类目标融入超分辨率过程可以同时改善图像质量和分类性能。

Abstract: High-resolution imagery plays a critical role in improving the performance of
visual recognition tasks such as classification, detection, and segmentation.
In many domains, including remote sensing and surveillance, low-resolution
images can limit the accuracy of automated analysis. To address this,
super-resolution (SR) techniques have been widely adopted to attempt to
reconstruct high-resolution images from low-resolution inputs. Related
traditional approaches focus solely on enhancing image quality based on
pixel-level metrics, leaving the relationship between super-resolved image
fidelity and downstream classification performance largely underexplored. This
raises a key question: can integrating classification objectives directly into
the super-resolution process further improve classification accuracy? In this
paper, we try to respond to this question by investigating the relationship
between super-resolution and classification through the deployment of a
specialised algorithmic strategy. We propose a novel methodology that increases
the resolution of synthetic aperture radar imagery by optimising loss functions
that account for both image quality and classification performance. Our
approach improves image quality, as measured by scientifically ascertained
image quality indicators, while also enhancing classification accuracy.

</details>


### [143] [Graph-based Robot Localization Using a Graph Neural Network with a Floor Camera and a Feature Rich Industrial Floor](https://arxiv.org/abs/2508.06177)
*Dominik Brämer,Diana Kleingarn,Oliver Urbann*

Main category: cs.CV

TL;DR: 提出一种基于地板特征的图表示和GCN的机器人定位框架，精度高（0.64cm误差），效率优于传统方法，并解决绑架机器人问题。


<details>
  <summary>Details</summary>
Motivation: 传统定位方法（如Lidar或QR码）在复杂环境中存在可扩展性和适应性不足的问题。

Method: 利用地板特征的图表示和GCN，避免复杂滤波过程，实现高效定位。

Result: 定位误差仅为0.64cm，每帧成功解决绑架机器人问题。

Conclusion: 该方法为复杂环境中的机器人导航提供了新的可能性。

Abstract: Accurate localization represents a fundamental challenge in
  robotic navigation. Traditional methodologies, such as Lidar or QR-code based
systems, suffer from inherent scalability and adaptability con straints,
particularly in complex environments. In this work, we propose
  an innovative localization framework that harnesses flooring characteris tics
by employing graph-based representations and Graph Convolutional
  Networks (GCNs). Our method uses graphs to represent floor features,
  which helps localize the robot more accurately (0.64cm error) and more
  efficiently than comparing individual image features. Additionally, this
  approach successfully addresses the kidnapped robot problem in every
  frame without requiring complex filtering processes. These advancements
  open up new possibilities for robotic navigation in diverse environments.

</details>


### [144] [SPARSE Data, Rich Results: Few-Shot Semi-Supervised Learning via Class-Conditioned Image Translation](https://arxiv.org/abs/2508.06429)
*Guido Manni,Clemente Lauretti,Loredana Zollo,Paolo Soda*

Main category: cs.CV

TL;DR: 论文提出了一种基于GAN的半监督学习框架，针对医学影像中标记数据不足的问题，通过集成生成器、判别器和分类器，结合伪标签技术，显著提升了低标记数据场景下的分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中因标记数据不足而导致的深度学习模型性能受限问题。

Method: 采用GAN框架，结合生成器、判别器和分类器，通过交替监督和无监督学习，利用图像翻译和伪标签技术优化模型。

Result: 在11个MedMNIST数据集上，该方法在5到50标记样本/类的设置中均优于现有方法，尤其在5-shot场景下表现突出。

Conclusion: 该方法为高标注成本的医学影像应用提供了实用解决方案，能在极少量标记数据下实现鲁棒分类。

Abstract: Deep learning has revolutionized medical imaging, but its effectiveness is
severely limited by insufficient labeled training data. This paper introduces a
novel GAN-based semi-supervised learning framework specifically designed for
low labeled-data regimes, evaluated across settings with 5 to 50 labeled
samples per class. Our approach integrates three specialized neural networks --
a generator for class-conditioned image translation, a discriminator for
authenticity assessment and classification, and a dedicated classifier --
within a three-phase training framework. The method alternates between
supervised training on limited labeled data and unsupervised learning that
leverages abundant unlabeled images through image-to-image translation rather
than generation from noise. We employ ensemble-based pseudo-labeling that
combines confidence-weighted predictions from the discriminator and classifier
with temporal consistency through exponential moving averaging, enabling
reliable label estimation for unlabeled data. Comprehensive evaluation across
eleven MedMNIST datasets demonstrates that our approach achieves statistically
significant improvements over six state-of-the-art GAN-based semi-supervised
methods, with particularly strong performance in the extreme 5-shot setting
where the scarcity of labeled data is most challenging. The framework maintains
its superiority across all evaluated settings (5, 10, 20, and 50 shots per
class). Our approach offers a practical solution for medical imaging
applications where annotation costs are prohibitive, enabling robust
classification performance even with minimal labeled data. Code is available at
https://github.com/GuidoManni/SPARSE.

</details>


### [145] [MA-CBP: A Criminal Behavior Prediction Framework Based on Multi-Agent Asynchronous Collaboration](https://arxiv.org/abs/2508.06189)
*Cheng Liu,Daou Zhang,Tingxu Liu,Yuhan Wang,Jinyang Chen,Yuexuan Li,Xinying Xiao,Chenbo Xin,Ziru Wang,Weichao Wu*

Main category: cs.CV

TL;DR: MA-CBP框架通过多智能体异步协作，结合实时视频流与历史信息，预测犯罪行为，提升公共安全预警能力。


<details>
  <summary>Details</summary>
Motivation: 城市化加速导致公共场景犯罪行为威胁增加，传统方法难以捕捉高级语义或满足实时需求。

Method: 将视频流转为语义描述，构建因果一致的历史摘要，融合相邻帧进行长短上下文联合推理。

Result: 在多个数据集上表现优异，提供事件主体、地点和原因等关键元素，实现犯罪活动早期预警。

Conclusion: MA-CBP为城市公共安全场景提供了一种有效的风险预警解决方案。

Abstract: With the acceleration of urbanization, criminal behavior in public scenes
poses an increasingly serious threat to social security. Traditional anomaly
detection methods based on feature recognition struggle to capture high-level
behavioral semantics from historical information, while generative approaches
based on Large Language Models (LLMs) often fail to meet real-time
requirements. To address these challenges, we propose MA-CBP, a criminal
behavior prediction framework based on multi-agent asynchronous collaboration.
This framework transforms real-time video streams into frame-level semantic
descriptions, constructs causally consistent historical summaries, and fuses
adjacent image frames to perform joint reasoning over long- and short-term
contexts. The resulting behavioral decisions include key elements such as event
subjects, locations, and causes, enabling early warning of potential criminal
activity. In addition, we construct a high-quality criminal behavior dataset
that provides multi-scale language supervision, including frame-level,
summary-level, and event-level semantic annotations. Experimental results
demonstrate that our method achieves superior performance on multiple datasets
and offers a promising solution for risk warning in urban public safety
scenarios.

</details>


### [146] [A Semantic Segmentation Algorithm for Pleural Effusion Based on DBIF-AUNet](https://arxiv.org/abs/2508.06191)
*Ruixiang Tang,Jianglong Qin,Mingda Zhang,Yan Song,Yi Wu,Wei Wu*

Main category: cs.CV

TL;DR: 提出了一种名为DBIF-AUNet的双分支交互融合注意力模型，用于提高胸腔积液CT图像的语义分割精度，解决了灰度相似、边缘模糊等问题。


<details>
  <summary>Details</summary>
Motivation: 胸腔积液CT图像的语义分割在临床诊断中至关重要，但现有方法因特征拼接导致的语义鸿沟和多变图像特性而效果不佳。

Method: 设计了双域特征解耦模块（DDFD）和分支交互注意力融合模块（BIAF），结合嵌套深度监督机制，实现多尺度特征互补和动态特征融合。

Result: 在1,622张CT图像上验证，IoU和Dice分数分别达到80.1%和89.0%，优于U-Net++和Swin-UNet。

Conclusion: DBIF-AUNet显著优化了复杂胸腔积液CT图像的分割精度，具有临床应用潜力。

Abstract: Pleural effusion semantic segmentation can significantly enhance the accuracy
and timeliness of clinical diagnosis and treatment by precisely identifying
disease severity and lesion areas. Currently, semantic segmentation of pleural
effusion CT images faces multiple challenges. These include similar gray levels
between effusion and surrounding tissues, blurred edges, and variable
morphology. Existing methods often struggle with diverse image variations and
complex edges, primarily because direct feature concatenation causes semantic
gaps. To address these challenges, we propose the Dual-Branch Interactive
Fusion Attention model (DBIF-AUNet). This model constructs a densely nested
skip-connection network and innovatively refines the Dual-Domain Feature
Disentanglement module (DDFD). The DDFD module orthogonally decouples the
functions of dual-domain modules to achieve multi-scale feature complementarity
and enhance characteristics at different levels. Concurrently, we design a
Branch Interaction Attention Fusion module (BIAF) that works synergistically
with the DDFD. This module dynamically weights and fuses global, local, and
frequency band features, thereby improving segmentation robustness.
Furthermore, we implement a nested deep supervision mechanism with hierarchical
adaptive hybrid loss to effectively address class imbalance. Through validation
on 1,622 pleural effusion CT images from Southwest Hospital, DBIF-AUNet
achieved IoU and Dice scores of 80.1% and 89.0% respectively. These results
outperform state-of-the-art medical image segmentation models U-Net++ and
Swin-UNet by 5.7%/2.7% and 2.2%/1.5% respectively, demonstrating significant
optimization in segmentation accuracy for complex pleural effusion CT images.

</details>


### [147] [CLIPin: A Non-contrastive Plug-in to CLIP for Multimodal Semantic Alignment](https://arxiv.org/abs/2508.06434)
*Shengzhu Yang,Jiawei Du,Shuai Lu,Weihang Zhang,Ningli Wang,Huiqi Li*

Main category: cs.CV

TL;DR: CLIPin是一种非对比性插件，可无缝集成到CLIP架构中，提升多模态语义对齐的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 大规模自然图像-文本数据集语义对齐松散，医学数据集内容多样性低，这限制了CLIP模型学习鲁棒且泛化性强的表示。

Method: 提出CLIPin插件，设计共享预投影器，结合对比与非对比学习。

Result: 在多种下游任务中验证了CLIPin的有效性和通用性。

Conclusion: CLIPin是一种兼容性强、即插即用的组件，能显著提升多模态对齐效果。

Abstract: Large-scale natural image-text datasets, especially those automatically
collected from the web, often suffer from loose semantic alignment due to weak
supervision, while medical datasets tend to have high cross-modal correlation
but low content diversity. These properties pose a common challenge for
contrastive language-image pretraining (CLIP): they hinder the model's ability
to learn robust and generalizable representations. In this work, we propose
CLIPin, a unified non-contrastive plug-in that can be seamlessly integrated
into CLIP-style architectures to improve multimodal semantic alignment,
providing stronger supervision and enhancing alignment robustness. Furthermore,
two shared pre-projectors are designed for image and text modalities
respectively to facilitate the integration of contrastive and non-contrastive
learning in a parameter-compromise manner. Extensive experiments on diverse
downstream tasks demonstrate the effectiveness and generality of CLIPin as a
plug-and-play component compatible with various contrastive frameworks. Code is
available at https://github.com/T6Yang/CLIPin.

</details>


### [148] [AnomalyMoE: Towards a Language-free Generalist Model for Unified Visual Anomaly Detection](https://arxiv.org/abs/2508.06203)
*Zhaopeng Gu,Bingke Zhu,Guibo Zhu,Yingying Chen,Wei Ge,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: AnomalyMoE是一种基于混合专家架构的通用异常检测框架，通过分解异常检测问题为三个语义层次，显著提升了跨领域的性能。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法通常针对特定领域，泛化能力有限，AnomalyMoE旨在解决这一问题。

Method: 采用混合专家架构，分为局部结构、组件语义和全局逻辑三个层次，并引入专家信息排斥和专家选择平衡模块。

Result: 在8个数据集上表现优异，显著超越领域专用方法。

Conclusion: AnomalyMoE是一种高效且通用的异常检测框架，具有广泛适用性。

Abstract: Anomaly detection is a critical task across numerous domains and modalities,
yet existing methods are often highly specialized, limiting their
generalizability. These specialized models, tailored for specific anomaly types
like textural defects or logical errors, typically exhibit limited performance
when deployed outside their designated contexts. To overcome this limitation,
we propose AnomalyMoE, a novel and universal anomaly detection framework based
on a Mixture-of-Experts (MoE) architecture. Our key insight is to decompose the
complex anomaly detection problem into three distinct semantic hierarchies:
local structural anomalies, component-level semantic anomalies, and global
logical anomalies. AnomalyMoE correspondingly employs three dedicated expert
networks at the patch, component, and global levels, and is specialized in
reconstructing features and identifying deviations at its designated semantic
level. This hierarchical design allows a single model to concurrently
understand and detect a wide spectrum of anomalies. Furthermore, we introduce
an Expert Information Repulsion (EIR) module to promote expert diversity and an
Expert Selection Balancing (ESB) module to ensure the comprehensive utilization
of all experts. Experiments on 8 challenging datasets spanning industrial
imaging, 3D point clouds, medical imaging, video surveillance, and logical
anomaly detection demonstrate that AnomalyMoE establishes new state-of-the-art
performance, significantly outperforming specialized methods in their
respective domains.

</details>


### [149] [PA-HOI: A Physics-Aware Human and Object Interaction Dataset](https://arxiv.org/abs/2508.06205)
*Ruiyan Wang,Lin Zuo,Zonghao Lin,Qiang Wang,Zhengxue Cheng,Rong Xie,Jun Ling,Li Song*

Main category: cs.CV

TL;DR: PA-HOI数据集填补了现有HOI数据集的不足，关注物体物理属性对人类长期运动的影响，包含562个运动序列，适用于运动生成方法。


<details>
  <summary>Details</summary>
Motivation: 现有HOI数据集多关注功能细节，忽略物体物理属性对人类运动的影响，限制了相关领域的研究。

Method: 提出PA-HOI数据集，包含不同性别受试者与35种3D物体的交互运动序列，记录姿势、速度等动态特征。

Result: 数据集显著扩展了对物体物理属性如何影响人类运动的理解，并验证了其在运动生成中的实用性。

Conclusion: PA-HOI数据集为研究物体物理属性对人类运动的影响提供了重要资源，并展示了其在运动生成中的潜力。

Abstract: The Human-Object Interaction (HOI) task explores the dynamic interactions
between humans and objects in physical environments, providing essential
biomechanical and cognitive-behavioral foundations for fields such as robotics,
virtual reality, and human-computer interaction. However, existing HOI data
sets focus on details of affordance, often neglecting the influence of physical
properties of objects on human long-term motion. To bridge this gap, we
introduce the PA-HOI Motion Capture dataset, which highlights the impact of
objects' physical attributes on human motion dynamics, including human posture,
moving velocity, and other motion characteristics. The dataset comprises 562
motion sequences of human-object interactions, with each sequence performed by
subjects of different genders interacting with 35 3D objects that vary in size,
shape, and weight. This dataset stands out by significantly extending the scope
of existing ones for understanding how the physical attributes of different
objects influence human posture, speed, motion scale, and interacting
strategies. We further demonstrate the applicability of the PA-HOI dataset by
integrating it with existing motion generation methods, validating its capacity
to transfer realistic physical awareness.

</details>


### [150] [Text Embedded Swin-UMamba for DeepLesion Segmentation](https://arxiv.org/abs/2508.06453)
*Ruida Cheng,Tejas Sudharshan Mathai,Pritam Mukherjee,Benjamin Hou,Qingqing Zhu,Zhiyong Lu,Matthew McAuliffe,Ronald M. Summers*

Main category: cs.CV

TL;DR: 研究探讨了将大语言模型（LLM）与Swin-UMamba架构结合用于病灶分割的可行性，结果显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 通过结合影像特征和放射学报告中的文本描述，提升慢性疾病（如淋巴瘤）病灶分割的自动化测量能力。

Method: 采用Swin-UMamba架构，整合文本信息，使用ULS23 DeepLesion数据集及报告中的简短描述进行训练。

Result: 测试集上病灶分割的Dice Score达82%，Hausdorff距离为6.58像素，性能优于现有模型。

Conclusion: Text-Swin-UMamba模型在病灶分割任务中表现优异，为临床自动化评估提供了新思路。

Abstract: Segmentation of lesions on CT enables automatic measurement for clinical
assessment of chronic diseases (e.g., lymphoma). Integrating large language
models (LLMs) into the lesion segmentation workflow offers the potential to
combine imaging features with descriptions of lesion characteristics from the
radiology reports. In this study, we investigate the feasibility of integrating
text into the Swin-UMamba architecture for the task of lesion segmentation. The
publicly available ULS23 DeepLesion dataset was used along with short-form
descriptions of the findings from the reports. On the test dataset, a high Dice
Score of 82% and low Hausdorff distance of 6.58 (pixels) was obtained for
lesion segmentation. The proposed Text-Swin-UMamba model outperformed prior
approaches: 37% improvement over the LLM-driven LanGuideMedSeg model (p <
0.001),and surpassed the purely image-based xLSTM-UNet and nnUNet models by
1.74% and 0.22%, respectively. The dataset and code can be accessed at
https://github.com/ruida/LLM-Swin-UMamba

</details>


### [151] [Interpretable Rheumatoid Arthritis Scoring via Anatomy-aware Multiple Instance Learning](https://arxiv.org/abs/2508.06218)
*Zhiyan Bo,Laura C. Coates,Bartlomiej W. Papiez*

Main category: cs.CV

TL;DR: 提出了一种基于双手X光片的可解释性图像级SvdH评分预测方法，通过注意力机制的多实例学习整合疾病相关区域特征，预测性能接近专业放射科医生水平。


<details>
  <summary>Details</summary>
Motivation: SvdH评分在RA临床研究中广泛应用，但因其复杂性难以在常规临床实践中推广，手动评分效率低下。

Method: 采用两阶段流程：1）提取疾病相关图像区域；2）基于注意力机制的多实例学习整合特征进行预测。提出两种区域提取方案：异常区域采样和关节区域裁剪。

Result: 最佳模型PCC达0.943，RMSE为15.73；集成学习进一步提升至PCC 0.945和RMSE 15.57，接近放射科医生水平（PCC=0.97，RMSE=18.75）。

Conclusion: 该方法不仅能高效预测SvdH评分，还能识别与RA进展相关的解剖结构，具有临床实用性。

Abstract: The Sharp/van der Heijde (SvdH) score has been widely used in clinical trials
to quantify radiographic damage in Rheumatoid Arthritis (RA), but its
complexity has limited its adoption in routine clinical practice. To address
the inefficiency of manual scoring, this work proposes a two-stage pipeline for
interpretable image-level SvdH score prediction using dual-hand radiographs.
Our approach extracts disease-relevant image regions and integrates them using
attention-based multiple instance learning to generate image-level features for
prediction. We propose two region extraction schemes: 1) sampling image tiles
most likely to contain abnormalities, and 2) cropping patches containing
disease-relevant joints. With Scheme 2, our best individual score prediction
model achieved a Pearson's correlation coefficient (PCC) of 0.943 and a root
mean squared error (RMSE) of 15.73. Ensemble learning further boosted
prediction accuracy, yielding a PCC of 0.945 and RMSE of 15.57, achieving
state-of-the-art performance that is comparable to that of experienced
radiologists (PCC = 0.97, RMSE = 18.75). Finally, our pipeline effectively
identified and made decisions based on anatomical structures which clinicians
consider relevant to RA progression.

</details>


### [152] [TEFormer: Texture-Aware and Edge-Guided Transformer for Semantic Segmentation of Urban Remote Sensing Images](https://arxiv.org/abs/2508.06224)
*Guoyu Zhou,Jing Zhang,Yi Yan,Hui Zhang,Li Zhuo*

Main category: cs.CV

TL;DR: 提出了一种纹理感知和边缘引导的Transformer（TEFormer），用于城市遥感图像的语义分割，解决了纹理差异小和边缘复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 城市遥感图像中地理对象的纹理差异小、空间结构相似，易导致语义模糊和错误分类，同时不规则形状和模糊边界增加了分割难度。

Method: 设计了纹理感知模块（TaM）捕获细粒度纹理差异，边缘引导三分支解码器（Eg3Head）保留局部边缘细节，以及边缘引导特征融合模块（EgFFM）融合上下文和边缘信息。

Result: 在Potsdam、Vaihingen和LoveDA数据集上分别达到88.57%、81.46%和53.55%的mIoU，验证了方法的有效性。

Conclusion: TEFormer通过纹理感知和边缘引导机制，显著提升了城市遥感图像的语义分割精度。

Abstract: Semantic segmentation of urban remote sensing images (URSIs) is crucial for
applications such as urban planning and environmental monitoring. However,
geospatial objects often exhibit subtle texture differences and similar spatial
structures, which can easily lead to semantic ambiguity and misclassification.
Moreover, challenges such as irregular object shapes, blurred boundaries, and
overlapping spatial distributions of semantic objects contribute to complex and
diverse edge morphologies, further complicating accurate segmentation. To
tackle these issues, we propose a texture-aware and edge-guided Transformer
(TEFormer) that integrates texture awareness and edge-guidance mechanisms for
semantic segmentation of URSIs. In the encoder, a texture-aware module (TaM) is
designed to capture fine-grained texture differences between visually similar
categories to enhance semantic discrimination. Then, an edge-guided tri-branch
decoder (Eg3Head) is constructed to preserve local edges and details for
multiscale context-awareness. Finally, an edge-guided feature fusion module
(EgFFM) is to fuse contextual and detail information with edge information to
realize refined semantic segmentation. Extensive experiments show that TEFormer
achieves mIoU of 88.57%, 81.46%, and 53.55% on the Potsdam, Vaihingen, and
LoveDA datasets, respectively, shows the effectiveness in URSI semantic
segmentation.

</details>


### [153] [WGAST: Weakly-Supervised Generative Network for Daily 10 m Land Surface Temperature Estimation via Spatio-Temporal Fusion](https://arxiv.org/abs/2508.06485)
*Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai*

Main category: cs.CV

TL;DR: WGAST是一种弱监督生成网络，用于通过时空融合技术从Terra MODIS、Landsat 8和Sentinel-2数据中估计每日10米分辨率的陆地表面温度（LST）。


<details>
  <summary>Details</summary>
Motivation: 城市化、气候变化和农业压力增加了对精确和及时环境监测的需求，而现有遥感系统在空间和时间分辨率之间存在权衡。

Method: WGAST采用条件生成对抗网络架构，包括特征提取、融合、LST重建和噪声抑制四个阶段，结合弱监督训练策略。

Result: WGAST在定量和定性评估中均优于现有方法，平均降低RMSE 17.18%，提高SSIM 11.00%，并能有效捕捉细尺度热模式。

Conclusion: WGAST是首个端到端深度学习框架，成功解决了高分辨率每日LST估计的挑战，具有实际应用潜力。

Abstract: Urbanization, climate change, and agricultural stress are increasing the
demand for precise and timely environmental monitoring. Land Surface
Temperature (LST) is a key variable in this context and is retrieved from
remote sensing satellites. However, these systems face a trade-off between
spatial and temporal resolution. While spatio-temporal fusion methods offer
promising solutions, few have addressed the estimation of daily LST at 10 m
resolution. In this study, we present WGAST, a Weakly-Supervised Generative
Network for Daily 10 m LST Estimation via Spatio-Temporal Fusion of Terra
MODIS, Landsat 8, and Sentinel-2. WGAST is the first end-to-end deep learning
framework designed for this task. It adopts a conditional generative
adversarial architecture, with a generator composed of four stages: feature
extraction, fusion, LST reconstruction, and noise suppression. The first stage
employs a set of encoders to extract multi-level latent representations from
the inputs, which are then fused in the second stage using cosine similarity,
normalization, and temporal attention mechanisms. The third stage decodes the
fused features into high-resolution LST, followed by a Gaussian filter to
suppress high-frequency noise. Training follows a weakly supervised strategy
based on physical averaging principles and reinforced by a PatchGAN
discriminator. Experiments demonstrate that WGAST outperforms existing methods
in both quantitative and qualitative evaluations. Compared to the
best-performing baseline, on average, WGAST reduces RMSE by 17.18% and improves
SSIM by 11.00%. Furthermore, WGAST is robust to cloud-induced LST and
effectively captures fine-scale thermal patterns, as validated against 33
ground-based sensors. The code is available at
https://github.com/Sofianebouaziz1/WGAST.git.

</details>


### [154] [Depth Jitter: Seeing through the Depth](https://arxiv.org/abs/2508.06227)
*Md Sazidur Rahman,David Cabecinhas,Ricard Marxer*

Main category: cs.CV

TL;DR: 论文提出了一种名为Depth-Jitter的新型深度增强技术，通过模拟自然深度变化提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统增强技术忽略了深度感知变换，限制了模型在真实世界深度变化中的鲁棒性。

Method: 采用自适应深度偏移，基于深度方差阈值生成合成深度扰动，同时保持结构完整性。

Result: 在FathomNet和UTDAC2020数据集上验证了Depth-Jitter对模型稳定性的提升，尤其在深度敏感环境中表现突出。

Conclusion: Depth-Jitter为深度感知增强提供了新思路，支持进一步研究深度学习策略，代码已开源。

Abstract: Depth information is essential in computer vision, particularly in underwater
imaging, robotics, and autonomous navigation. However, conventional
augmentation techniques overlook depth aware transformations, limiting model
robustness in real world depth variations. In this paper, we introduce
Depth-Jitter, a novel depth-based augmentation technique that simulates natural
depth variations to improve generalization. Our approach applies adaptive depth
offsetting, guided by depth variance thresholds, to generate synthetic depth
perturbations while preserving structural integrity. We evaluate Depth-Jitter
on two benchmark datasets, FathomNet and UTDAC2020 demonstrating its impact on
model stability under diverse depth conditions. Extensive experiments compare
Depth-Jitter against traditional augmentation strategies such as ColorJitter,
analyzing performance across varying learning rates, encoders, and loss
functions. While Depth-Jitter does not always outperform conventional methods
in absolute performance, it consistently enhances model stability and
generalization in depth-sensitive environments. These findings highlight the
potential of depth-aware augmentation for real-world applications and provide a
foundation for further research into depth-based learning strategies. The
proposed technique is publicly available to support advancements in depth-aware
augmentation. The code is publicly available on
\href{https://github.com/mim-team/Depth-Jitter}{github}.

</details>


### [155] [Towards Unified Image Deblurring using a Mixture-of-Experts Decoder](https://arxiv.org/abs/2508.06228)
*Daniel Feijoo,Paula Garrido-Mellado,Jaesung Rim,Alvaro Garcia,Marcos V. Conde*

Main category: cs.CV

TL;DR: 提出了一种通用的图像去模糊方法，能够处理多种模糊类型，包括全局运动、局部运动、低光模糊和散焦模糊。


<details>
  <summary>Details</summary>
Motivation: 现有方法针对特定模糊类型设计，缺乏泛化能力，需要多个模型覆盖不同模糊类型，实用性不足。

Method: 采用混合专家（MoE）解码模块，根据识别的模糊类型动态路由图像特征，实现端到端的精确恢复。

Result: 该方法性能与专用模型相当，且在未见过的模糊场景中表现出优异的鲁棒性和泛化能力。

Conclusion: 提出了一种高效、通用的图像去模糊方法，解决了现有方法的局限性。

Abstract: Image deblurring, removing blurring artifacts from images, is a fundamental
task in computational photography and low-level computer vision. Existing
approaches focus on specialized solutions tailored to particular blur types,
thus, these solutions lack generalization. This limitation in current methods
implies requiring multiple models to cover several blur types, which is not
practical in many real scenarios. In this paper, we introduce the first
all-in-one deblurring method capable of efficiently restoring images affected
by diverse blur degradations, including global motion, local motion, blur in
low-light conditions, and defocus blur. We propose a mixture-of-experts (MoE)
decoding module, which dynamically routes image features based on the
recognized blur degradation, enabling precise and efficient restoration in an
end-to-end manner. Our unified approach not only achieves performance
comparable to dedicated task-specific models, but also demonstrates remarkable
robustness and generalization capabilities on unseen blur degradation
scenarios.

</details>


### [156] [Deepfake Detection that Generalizes Across Benchmarks](https://arxiv.org/abs/2508.06248)
*Andrii Yermakov,Jan Cech,Jiri Matas,Mario Fritz*

Main category: cs.CV

TL;DR: 论文提出了一种参数高效的方法LNCLIP-DF，通过微调预训练CLIP模型的层归一化参数（仅0.03%），并结合L2归一化和潜在空间增强，实现了对未见过的深度伪造技术的鲁棒泛化。该方法在13个基准数据集上表现优异，并揭示了训练数据配对和数据集多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测器在面对未见过的伪造技术时泛化能力不足，现有方法通常通过增加模型复杂度来提升性能，但效果有限。本文旨在探索一种参数高效的方法，以实现更好的泛化性能。

Method: 提出LNCLIP-DF方法，仅微调CLIP模型的层归一化参数（0.03%），并通过L2归一化和潜在空间增强优化特征流形。

Result: 在13个基准数据集上取得最优性能，平均跨数据集AUROC超过其他复杂方法。发现训练数据配对和数据集多样性对泛化至关重要。

Conclusion: 通过最小化对预训练CLIP模型的改动，实现了高效的深度伪造检测泛化，证明了参数高效方法的潜力。

Abstract: The generalization of deepfake detectors to unseen manipulation techniques
remains a challenge for practical deployment. Although many approaches adapt
foundation models by introducing significant architectural complexity, this
work demonstrates that robust generalization is achievable through a
parameter-efficient adaptation of a pre-trained CLIP vision encoder. The
proposed method, LNCLIP-DF, fine-tunes only the Layer Normalization parameters
(0.03% of the total) and enhances generalization by enforcing a hyperspherical
feature manifold using L2 normalization and latent space augmentations.
  We conducted an extensive evaluation on 13 benchmark datasets spanning from
2019 to 2025. The proposed method achieves state-of-the-art performance,
outperforming more complex, recent approaches in average cross-dataset AUROC.
Our analysis yields two primary findings for the field: 1) training on paired
real-fake data from the same source video is essential for mitigating shortcut
learning and improving generalization, and 2) detection difficulty on academic
datasets has not strictly increased over time, with models trained on older,
diverse datasets showing strong generalization capabilities.
  This work delivers a computationally efficient and reproducible method,
proving that state-of-the-art generalization is attainable by making targeted,
minimal changes to a pre-trained CLIP model. The code will be made publicly
available upon acceptance.

</details>


### [157] [FedX: Explanation-Guided Pruning for Communication-Efficient Federated Learning in Remote Sensing](https://arxiv.org/abs/2508.06256)
*Barış Büyüktaş,Jonas Klotz,Begüm Demir*

Main category: cs.CV

TL;DR: 提出了一种名为FedX的新策略，通过解释引导的剪枝减少联邦学习中的通信开销，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在遥感图像分类中面临通信开销大的问题，FedX旨在解决这一问题。

Method: 利用反向传播解释方法估计模型组件的重要性，剪枝不相关部分以减少传输模型大小。

Result: 在BigEarthNet-S2和EuroSAT数据集上验证，FedX显著减少参数数量并提升模型泛化能力。

Conclusion: FedX是一种有效的通信优化方法，适用于遥感任务的联邦学习。

Abstract: Federated learning (FL) enables the collaborative training of deep neural
networks across decentralized data archives (i.e., clients), where each client
stores data locally and only shares model updates with a central server. This
makes FL a suitable learning paradigm for remote sensing (RS) image
classification tasks, where data centralization may be restricted due to legal
and privacy constraints. However, a key challenge in applying FL to RS tasks is
the communication overhead caused by the frequent exchange of large model
updates between clients and the central server. To address this issue, in this
paper we propose a novel strategy (denoted as FedX) that uses
explanation-guided pruning to reduce communication overhead by minimizing the
size of the transmitted models without compromising performance. FedX leverages
backpropagation-based explanation methods to estimate the task-specific
importance of model components and prunes the least relevant ones at the
central server. The resulting sparse global model is then sent to clients,
substantially reducing communication overhead. We evaluate FedX on multi-label
scene classification using the BigEarthNet-S2 dataset and single-label scene
classification using the EuroSAT dataset. Experimental results show the success
of FedX in significantly reducing the number of shared model parameters while
enhancing the generalization capability of the global model, compared to both
unpruned model and state-of-the-art pruning methods. The code of FedX will be
available at https://git.tu-berlin.de/rsim/FedX.

</details>


### [158] [XAG-Net: A Cross-Slice Attention and Skip Gating Network for 2.5D Femur MRI Segmentation](https://arxiv.org/abs/2508.06258)
*Byunghyun Ko,Anning Tian,Jeongkyu Lee*

Main category: cs.CV

TL;DR: XAG-Net是一种基于2.5D U-Net的新架构，通过像素级跨切片注意力（CSA）和跳跃注意力门控（AG）机制提升股骨MRI分割的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有2D和3D深度学习方法在股骨MRI分割中存在局限性，需要更高效且准确的解决方案。

Method: 提出XAG-Net，结合CSA和AG机制，优化切片间上下文建模和切片内特征细化。

Result: XAG-Net在分割准确性上优于基线2D、2.5D和3D U-Net模型，同时保持计算效率。

Conclusion: XAG-Net是股骨MRI分割的高效且准确的新框架，CSA和AG模块起关键作用。

Abstract: Accurate segmentation of femur structures from Magnetic Resonance Imaging
(MRI) is critical for orthopedic diagnosis and surgical planning but remains
challenging due to the limitations of existing 2D and 3D deep learning-based
segmentation approaches. In this study, we propose XAG-Net, a novel 2.5D
U-Net-based architecture that incorporates pixel-wise cross-slice attention
(CSA) and skip attention gating (AG) mechanisms to enhance inter-slice
contextual modeling and intra-slice feature refinement. Unlike previous
CSA-based models, XAG-Net applies pixel-wise softmax attention across adjacent
slices at each spatial location for fine-grained inter-slice modeling.
Extensive evaluations demonstrate that XAG-Net surpasses baseline 2D, 2.5D, and
3D U-Net models in femur segmentation accuracy while maintaining computational
efficiency. Ablation studies further validate the critical role of the CSA and
AG modules, establishing XAG-Net as a promising framework for efficient and
accurate femur MRI segmentation.

</details>


### [159] [Uncertainty-quantified Rollout Policy Adaptation for Unlabelled Cross-domain Temporal Grounding](https://arxiv.org/abs/2508.06317)
*Jian Hu,Zixu Cheng,Shaogang Gong,Isabel Guan,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.CV

TL;DR: 提出了一种数据高效的无标签跨域时间定位方法（URPA），通过少量无标签目标域视频实现跨域知识迁移。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如GRPO）依赖标注数据且计算开销大的问题，实现实时部署和无标签跨域适应。

Method: 使用GRPO生成多个候选预测，通过平均形成伪标签，并用方差估计置信度，加权训练奖励。

Result: 在三个数据集的六种跨域设置中表现良好，仅需少量无标签目标视频。

Conclusion: URPA是一种高效的无标签跨域时间定位方法，适用于实时部署。

Abstract: Video Temporal Grounding (TG) aims to temporally locate video segments
matching a natural language description (a query) in a long video. While
Vision-Language Models (VLMs) are effective at holistic semantic matching, they
often struggle with fine-grained temporal localisation. Recently, Group
Relative Policy Optimisation (GRPO) reformulates the inference process as a
reinforcement learning task, enabling fine-grained grounding and achieving
strong in-domain performance. However, GRPO relies on labelled data, making it
unsuitable in unlabelled domains. Moreover, because videos are large and
expensive to store and process, performing full-scale adaptation introduces
prohibitive latency and computational overhead, making it impractical for
real-time deployment. To overcome both problems, we introduce a Data-Efficient
Unlabelled Cross-domain Temporal Grounding method, from which a model is first
trained on a labelled source domain, then adapted to a target domain using only
a small number of unlabelled videos from the target domain. This approach
eliminates the need for target annotation and keeps both computational and
storage overhead low enough to run in real time. Specifically, we introduce.
Uncertainty-quantified Rollout Policy Adaptation (URPA) for cross-domain
knowledge transfer in learning video temporal grounding without target labels.
URPA generates multiple candidate predictions using GRPO rollouts, averages
them to form a pseudo label, and estimates confidence from the variance across
these rollouts. This confidence then weights the training rewards, guiding the
model to focus on reliable supervision. Experiments on three datasets across
six cross-domain settings show that URPA generalises well using only a few
unlabelled target videos. Codes will be released once published.

</details>


### [160] [Can Diffusion Models Bridge the Domain Gap in Cardiac MR Imaging?](https://arxiv.org/abs/2508.06327)
*Xin Ci Wong,Duygu Sarikaya,Kieran Zucker,Marc De Kamps,Nishant Ravikumar*

Main category: cs.CV

TL;DR: 提出一种基于扩散模型的方法，生成合成心脏MR图像以解决域偏移问题，显著提升多中心分割性能。


<details>
  <summary>Details</summary>
Motivation: 心脏MR图像因设备和协议差异导致域偏移，限制了AI模型在实际场景中的应用。

Method: 使用扩散模型生成合成图像，保持结构和空间一致性，并用于域泛化和域适应策略。

Result: 合成数据显著提升了未见目标域的分割性能（p < 0.01），优于仅使用真实数据的方法。

Conclusion: 该方法有效解决了域偏移问题，减少了对迁移学习或在线训练的依赖，适用于数据稀缺场景。

Abstract: Magnetic resonance (MR) imaging, including cardiac MR, is prone to domain
shift due to variations in imaging devices and acquisition protocols. This
challenge limits the deployment of trained AI models in real-world scenarios,
where performance degrades on unseen domains. Traditional solutions involve
increasing the size of the dataset through ad-hoc image augmentation or
additional online training/transfer learning, which have several limitations.
Synthetic data offers a promising alternative, but anatomical/structural
consistency constraints limit the effectiveness of generative models in
creating image-label pairs. To address this, we propose a diffusion model (DM)
trained on a source domain that generates synthetic cardiac MR images that
resemble a given reference. The synthetic data maintains spatial and structural
fidelity, ensuring similarity to the source domain and compatibility with the
segmentation mask. We assess the utility of our generative approach in
multi-centre cardiac MR segmentation, using the 2D nnU-Net, 3D nnU-Net and
vanilla U-Net segmentation networks. We explore domain generalisation, where,
domain-invariant segmentation models are trained on synthetic source domain
data, and domain adaptation, where, we shift target domain data towards the
source domain using the DM. Both strategies significantly improved segmentation
performance on data from an unseen target domain, in terms of surface-based
metrics (Welch's t-test, p < 0.01), compared to training segmentation models on
real data alone. The proposed method ameliorates the need for transfer learning
or online training to address domain shift challenges in cardiac MR image
analysis, especially useful in data-scarce settings.

</details>


### [161] [ViPro-2: Unsupervised State Estimation via Integrated Dynamics for Guiding Video Prediction](https://arxiv.org/abs/2508.06335)
*Patrick Takenaka,Johannes Maucher,Marco F. Huber*

Main category: cs.CV

TL;DR: 改进ViPro模型，使其能够从观察中正确推断状态，无需初始真实状态，并在无监督方式下实现。


<details>
  <summary>Details</summary>
Motivation: 解决ViPro模型因依赖初始真实状态而无法在噪声环境下准确预测的问题。

Method: 在ViPro基础上改进，引入无监督状态推断，并扩展3D数据集以接近真实场景。

Result: 模型能够从观察中正确推断状态，且在无监督方式下有效。

Conclusion: 改进后的ViPro模型在状态推断和预测方面表现更优，适用于更复杂的真实场景。

Abstract: Predicting future video frames is a challenging task with many downstream
applications. Previous work has shown that procedural knowledge enables deep
models for complex dynamical settings, however their model ViPro assumed a
given ground truth initial symbolic state. We show that this approach led to
the model learning a shortcut that does not actually connect the observed
environment with the predicted symbolic state, resulting in the inability to
estimate states given an observation if previous states are noisy. In this
work, we add several improvements to ViPro that enables the model to correctly
infer states from observations without providing a full ground truth state in
the beginning. We show that this is possible in an unsupervised manner, and
extend the original Orbits dataset with a 3D variant to close the gap to real
world scenarios.

</details>


### [162] [Street View Sociability: Interpretable Analysis of Urban Social Behavior Across 15 Cities](https://arxiv.org/abs/2508.06342)
*Kieran Elrod,Katherine Flanigan,Mario Bergés*

Main category: cs.CV

TL;DR: 利用街景图像和大型语言模型分析城市社交性，发现天空视野指数与社交性相关，绿色视野指数与持久社交性相关，城市依恋与短暂社交性相关。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注行人数量而非社交互动质量，希望通过街景图像提取潜在社交信息，验证其与城市规划和环境变量的关系。

Method: 分析15个城市的2,998张街景图像，使用多模态大型语言模型和Mehta的社交性分类，结合线性回归模型控制天气、时间等因素。

Result: 天空视野指数与三种社交性相关，绿色视野指数预测持久社交性，城市依恋与短暂社交性正相关。

Conclusion: 街景图像可作为研究城市社交性的工具，支持跨文化理论验证和基于证据的城市设计。

Abstract: Designing socially active streets has long been a goal of urban planning, yet
existing quantitative research largely measures pedestrian volume rather than
the quality of social interactions. We hypothesize that street view imagery --
an inexpensive data source with global coverage -- contains latent social
information that can be extracted and interpreted through established social
science theory. As a proof of concept, we analyzed 2,998 street view images
from 15 cities using a multimodal large language model guided by Mehta's
taxonomy of passive, fleeting, and enduring sociability -- one illustrative
example of a theory grounded in urban design that could be substituted or
complemented by other sociological frameworks. We then used linear regression
models, controlling for factors like weather, time of day, and pedestrian
counts, to test whether the inferred sociability measures correlate with
city-level place attachment scores from the World Values Survey and with
environmental predictors (e.g., green, sky, and water view indices) derived
from individual street view images. Results aligned with long-standing urban
planning theory: the sky view index was associated with all three sociability
types, the green view index predicted enduring sociability, and place
attachment was positively associated with fleeting sociability. These results
provide preliminary evidence that street view images can be used to infer
relationships between specific types of social interactions and built
environment variables. Further research could establish street view imagery as
a scalable, privacy-preserving tool for studying urban sociability, enabling
cross-cultural theory testing and evidence-based design of socially vibrant
cities.

</details>


### [163] [Aligning Effective Tokens with Video Anomaly in Large Language Models](https://arxiv.org/abs/2508.06350)
*Yingxian Chen,Jiahui Liu,Ruifan Di,Yanwei Li,Chirui Chang,Shizhen Zhao,Wilton W. T. Fok,Xiaojuan Qi,Yik-Chung Wu*

Main category: cs.CV

TL;DR: VA-GPT是一种新型多模态大语言模型，专注于视频异常事件的总结与定位，通过空间和时间有效令牌模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型在处理异常事件时表现不佳，主要由于异常事件的时空稀疏性和冗余信息干扰。

Method: 提出VA-GPT模型，结合SETS和TETG模块，优化视觉与语言模型的令牌对齐，并构建专用数据集。

Result: VA-GPT在多个基准测试中优于现有方法。

Conclusion: VA-GPT通过改进令牌对齐和专用数据集，显著提升了异常事件分析的准确性。

Abstract: Understanding abnormal events in videos is a vital and challenging task that
has garnered significant attention in a wide range of applications. Although
current video understanding Multi-modal Large Language Models (MLLMs) are
capable of analyzing general videos, they often struggle to handle anomalies
due to the spatial and temporal sparsity of abnormal events, where the
redundant information always leads to suboptimal outcomes. To address these
challenges, exploiting the representation and generalization capabilities of
Vison Language Models (VLMs) and Large Language Models (LLMs), we propose
VA-GPT, a novel MLLM designed for summarizing and localizing abnormal events in
various videos. Our approach efficiently aligns effective tokens between visual
encoders and LLMs through two key proposed modules: Spatial Effective Token
Selection (SETS) and Temporal Effective Token Generation (TETG). These modules
enable our model to effectively capture and analyze both spatial and temporal
information associated with abnormal events, resulting in more accurate
responses and interactions. Furthermore, we construct an instruction-following
dataset specifically for fine-tuning video-anomaly-aware MLLMs, and introduce a
cross-domain evaluation benchmark based on XD-Violence dataset. Our proposed
method outperforms existing state-of-the-art methods on various benchmarks.

</details>


### [164] [An Implemention of Two-Phase Image Segmentation using the Split Bregman Method](https://arxiv.org/abs/2508.06351)
*Olakunle S. Abawonse,Günay Doğan*

Main category: cs.CV

TL;DR: 本文实现了一种基于Goldstein、Bresson和Osher提出的两阶段图像分割算法，通过改进Chan-Vese能量模型，利用split Bregman方法高效完成分割。


<details>
  <summary>Details</summary>
Motivation: 图像分割是计算机视觉中的重要任务，需要高效且准确的算法将图像分为前景和背景区域。

Method: 改进Chan-Vese能量模型，利用split Bregman方法最小化能量函数，实现两阶段分割。

Result: 通过实验验证了算法的性能，并展示了不同参数下的分割效果。

Conclusion: 该方法在图像分割中表现出高效性和准确性，适用于多种场景。

Abstract: In this paper, we describe an implementation of the two-phase image
segmentation algorithm proposed by Goldstein, Bresson, Osher in
\cite{gold:bre}. This algorithm partitions the domain of a given 2d image into
foreground and background regions, and each pixel of the image is assigned
membership to one of these two regions. The underlying assumption for the
segmentation model is that the pixel values of the input image can be
summarized by two distinct average values, and that the region boundaries are
smooth. Accordingly, the model is defined as an energy in which the variable is
a region membership function to assign pixels to either region, originally
proposed by Chan and Vese in \cite{chan:vese}. This energy is the sum of image
data terms in the regions and a length penalty for region boundaries.
Goldstein, Bresson, Osher modify the energy of Chan-Vese in \cite{gold:bre} so
that their new energy can be minimized efficiently using the split Bregman
method to produce an equivalent two-phase segmentation. We provide a detailed
implementation of this method \cite{gold:bre}, and document its performance
with several images over a range of algorithm parameters.

</details>


### [165] [Text as Any-Modality for Zero-Shot Classification by Consistent Prompt Tuning](https://arxiv.org/abs/2508.06382)
*Xiangyu Wu,Feng Yu,Yang Yang,Jianfeng Lu*

Main category: cs.CV

TL;DR: TaAM-CPT是一种通过一致提示调谐的多模态学习方法，仅使用文本数据构建通用表示模型，支持无限模态扩展。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量模态特定标注数据或仅针对单一模态，限制了通用性和扩展性。

Method: TaAM-CPT结合模态提示池、文本构建和预训练模型的模态对齐文本编码器，通过设计跨模态学习目标实现一致表示。

Result: TaAM-CPT在视频、图像和音频分类等多个任务上取得领先结果，无需模态特定标注数据。

Conclusion: TaAM-CPT展示了通过文本数据构建通用多模态表示模型的潜力，具有高度扩展性和性能优势。

Abstract: The integration of prompt tuning with multimodal learning has shown
significant generalization abilities for various downstream tasks. Despite
advancements, existing methods heavily depend on massive modality-specific
labeled data (e.g., video, audio, and image), or are customized for a single
modality. In this study, we present Text as Any-Modality by Consistent Prompt
Tuning (TaAM-CPT), a scalable approach for constructing a general
representation model toward unlimited modalities using solely text data.
TaAM-CPT comprises modality prompt pools, text construction, and
modality-aligned text encoders from pre-trained models, which allows for
extending new modalities by simply adding prompt pools and modality-aligned
text encoders. To harmonize the learning across different modalities, TaAM-CPT
designs intra- and inter-modal learning objectives, which can capture category
details within modalities while maintaining semantic consistency across
different modalities. Benefiting from its scalable architecture and pre-trained
models, TaAM-CPT can be seamlessly extended to accommodate unlimited
modalities. Remarkably, without any modality-specific labeled data, TaAM-CPT
achieves leading results on diverse datasets spanning various modalities,
including video classification, image classification, and audio classification.
The code is available at https://github.com/Jinx630/TaAM-CPT.

</details>


### [166] [FVGen: Accelerating Novel-View Synthesis with Adversarial Video Diffusion Distillation](https://arxiv.org/abs/2508.06392)
*Wenbin Teng,Gonglin Chen,Haiwei Chen,Yajie Zhao*

Main category: cs.CV

TL;DR: FVGen通过蒸馏视频扩散模型（VDMs）实现快速新视角合成，仅需四步采样，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角下的3D重建常因未观测区域出现伪影，现有方法使用VDMs生成密集观测但采样速度慢。

Method: 提出FVGen框架，通过GAN和软化反向KL散度最小化，将多步去噪教师模型蒸馏为少步去噪学生模型。

Result: 实验表明，FVGen在保持（或提升）视觉质量的同时，采样时间减少90%以上。

Conclusion: FVGen显著提升稀疏输入视角下3D重建任务的时间效率。

Abstract: Recent progress in 3D reconstruction has enabled realistic 3D models from
dense image captures, yet challenges persist with sparse views, often leading
to artifacts in unseen areas. Recent works leverage Video Diffusion Models
(VDMs) to generate dense observations, filling the gaps when only sparse views
are available for 3D reconstruction tasks. A significant limitation of these
methods is their slow sampling speed when using VDMs. In this paper, we present
FVGen, a novel framework that addresses this challenge by enabling fast novel
view synthesis using VDMs in as few as four sampling steps. We propose a novel
video diffusion model distillation method that distills a multi-step denoising
teacher model into a few-step denoising student model using Generative
Adversarial Networks (GANs) and softened reverse KL-divergence minimization.
Extensive experiments on real-world datasets show that, compared to previous
works, our framework generates the same number of novel views with similar (or
even better) visual quality while reducing sampling time by more than 90%.
FVGen significantly improves time efficiency for downstream reconstruction
tasks, particularly when working with sparse input views (more than 2) where
pre-trained VDMs need to be run multiple times to achieve better spatial
coverage.

</details>


### [167] [Feature-Space Oversampling for Addressing Class Imbalance in SAR Ship Classification](https://arxiv.org/abs/2508.06420)
*Ch Muhammad Awais,Marco Reggiannini,Davide Moroni,Oktay Karakus*

Main category: cs.CV

TL;DR: 论文提出两种新算法M2m_f和M2m_u，用于解决SAR船舰分类中的长尾数据集问题，通过特征空间过采样方法提升分类性能。


<details>
  <summary>Details</summary>
Motivation: SAR船舰分类面临长尾数据集的挑战，尤其是少数类别的分类问题。

Method: 提出两种基于Major-to-minor (M2m)方法的新算法M2m_f和M2m_u，并在OpenSARShip和FuSARShip数据集上测试，使用ViT、VGG16和ResNet50作为特征提取器。

Result: 新方法在FuSARShip和OpenSARShip数据集上的F1分数分别平均提高了8.82%和4.44%。

Conclusion: 特征空间过采样方法能有效提升SAR船舰分类性能，尤其是在长尾数据集中。

Abstract: SAR ship classification faces the challenge of long-tailed datasets, which
complicates the classification of underrepresented classes. Oversampling
methods have proven effective in addressing class imbalance in optical data. In
this paper, we evaluated the effect of oversampling in the feature space for
SAR ship classification. We propose two novel algorithms inspired by the
Major-to-minor (M2m) method M2m$_f$, M2m$_u$. The algorithms are tested on two
public datasets, OpenSARShip (6 classes) and FuSARShip (9 classes), using three
state-of-the-art models as feature extractors: ViT, VGG16, and ResNet50.
Additionally, we also analyzed the impact of oversampling methods on different
class sizes. The results demonstrated the effectiveness of our novel methods
over the original M2m and baselines, with an average F1-score increase of 8.82%
for FuSARShip and 4.44% for OpenSARShip.

</details>


### [168] [MotionSwap](https://arxiv.org/abs/2508.06430)
*Om Patil,Jinesh Modi,Suryabha Mukhopadhyay,Meghaditya Giri,Chhavi Malhotra*

Main category: cs.CV

TL;DR: 本文提出了一种改进的SimSwap框架，通过引入自注意力和交叉注意力机制、动态损失加权和余弦退火学习率调度，显著提升了人脸交换的保真度。实验结果显示，改进后的模型在身份相似性、FID分数和视觉质量上均优于基线。


<details>
  <summary>Details</summary>
Motivation: 人脸交换技术在学术和商业应用中备受关注，但现有方法在身份保留和属性一致性方面仍有改进空间。本文旨在通过改进SimSwap框架，提升其性能。

Method: 在生成器架构中集成自注意力和交叉注意力机制，采用动态损失加权和余弦退火学习率调度，优化训练过程。

Result: 经过40万次训练迭代，改进模型在身份相似性、FID分数和视觉质量上显著优于基线，消融实验验证了各改进的重要性。

Conclusion: 未来研究方向包括整合StyleGAN3、改进唇部同步、引入3D面部建模和视频应用中的时间一致性。

Abstract: Face swapping technology has gained significant attention in both academic
research and commercial applications. This paper presents our implementation
and enhancement of SimSwap, an efficient framework for high fidelity face
swapping. We introduce several improvements to the original model, including
the integration of self and cross-attention mechanisms in the generator
architecture, dynamic loss weighting, and cosine annealing learning rate
scheduling. These enhancements lead to significant improvements in identity
preservation, attribute consistency, and overall visual quality.
  Our experimental results, spanning 400,000 training iterations, demonstrate
progressive improvements in generator and discriminator performance. The
enhanced model achieves better identity similarity, lower FID scores, and
visibly superior qualitative results compared to the baseline. Ablation studies
confirm the importance of each architectural and training improvement. We
conclude by identifying key future directions, such as integrating StyleGAN3,
improving lip synchronization, incorporating 3D facial modeling, and
introducing temporal consistency for video-based applications.

</details>


### [169] [TRUST: Leveraging Text Robustness for Unsupervised Domain Adaptation](https://arxiv.org/abs/2508.06452)
*Mattia Litrico,Mario Valerio Giuffrida,Sebastiano Battiato,Devis Tuia*

Main category: cs.CV

TL;DR: TRUST是一种新型无监督域适应方法，利用语言模态的鲁棒性指导视觉模型适应，通过生成伪标签和不确定性估计提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂域偏移（如地理偏移）中传统UDA方法表现不佳的问题，利用语言模态的鲁棒性提升视觉模型适应性。

Method: TRUST通过生成伪标签、不确定性估计和多模态软对比学习损失对齐视觉与语言特征空间。

Result: 在经典（DomainNet）和复杂（GeoNet）域偏移上达到新SOTA。

Conclusion: TRUST通过语言模态的引导和不确定性估计显著提升了UDA性能，适用于多种域偏移场景。

Abstract: Recent unsupervised domain adaptation (UDA) methods have shown great success
in addressing classical domain shifts (e.g., synthetic-to-real), but they still
suffer under complex shifts (e.g. geographical shift), where both the
background and object appearances differ significantly across domains. Prior
works showed that the language modality can help in the adaptation process,
exhibiting more robustness to such complex shifts. In this paper, we introduce
TRUST, a novel UDA approach that exploits the robustness of the language
modality to guide the adaptation of a vision model. TRUST generates
pseudo-labels for target samples from their captions and introduces a novel
uncertainty estimation strategy that uses normalised CLIP similarity scores to
estimate the uncertainty of the generated pseudo-labels. Such estimated
uncertainty is then used to reweight the classification loss, mitigating the
adverse effects of wrong pseudo-labels obtained from low-quality captions. To
further increase the robustness of the vision model, we propose a multimodal
soft-contrastive learning loss that aligns the vision and language feature
spaces, by leveraging captions to guide the contrastive training of the vision
model on target images. In our contrastive loss, each pair of images acts as
both a positive and a negative pair and their feature representations are
attracted and repulsed with a strength proportional to the similarity of their
captions. This solution avoids the need for hardly determining positive and
negative pairs, which is critical in the UDA setting. Our approach outperforms
previous methods, setting the new state-of-the-art on classical (DomainNet) and
complex (GeoNet) domain shifts. The code will be available upon acceptance.

</details>


### [170] [LightSwitch: Multi-view Relighting with Material-guided Diffusion](https://arxiv.org/abs/2508.06494)
*Yehonathan Litman,Fernando De la Torre,Shubham Tulsiani*

Main category: cs.CV

TL;DR: LightSwitch是一种新颖的微调材料重光照扩散框架，通过利用多视图和材料信息，高效地将任意数量的输入图像重光照到目标光照条件。


<details>
  <summary>Details</summary>
Motivation: 现有2D重光照生成先验未能充分利用可推断的内在属性或大规模多视图数据，导致重光照效果不佳。

Method: 提出LightSwitch框架，结合多视图和材料信息，采用可扩展的去噪方案。

Result: LightSwitch在2D重光照预测质量上超越现有方法，并在合成和真实物体重光照任务中表现优异。

Conclusion: LightSwitch通过整合内在属性和多视图数据，显著提升了重光照的效率和效果。

Abstract: Recent approaches for 3D relighting have shown promise in integrating 2D
image relighting generative priors to alter the appearance of a 3D
representation while preserving the underlying structure. Nevertheless,
generative priors used for 2D relighting that directly relight from an input
image do not take advantage of intrinsic properties of the subject that can be
inferred or cannot consider multi-view data at scale, leading to subpar
relighting. In this paper, we propose Lightswitch, a novel finetuned
material-relighting diffusion framework that efficiently relights an arbitrary
number of input images to a target lighting condition while incorporating cues
from inferred intrinsic properties. By using multi-view and material
information cues together with a scalable denoising scheme, our method
consistently and efficiently relights dense multi-view data of objects with
diverse material compositions. We show that our 2D relighting prediction
quality exceeds previous state-of-the-art relighting priors that directly
relight from images. We further demonstrate that LightSwitch matches or
outperforms state-of-the-art diffusion inverse rendering methods in relighting
synthetic and real objects in as little as 2 minutes.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [171] [A Cross-Perspective Annotated Dataset for Dynamic Object-Level Attention Modeling in Cloud Gaming](https://arxiv.org/abs/2508.06077)
*Hongqin Lei,Haowei Tang,Zhe Zhang*

Main category: cs.DB

TL;DR: 论文提出一个基于GTA V游戏的数据集，关注玩家感兴趣的对象及其语义关系，分析影响玩家兴趣的主要因素。


<details>
  <summary>Details</summary>
Motivation: 现有数据集通常只关注对象位置，忽略语义关系和独特特征，影响深度学习方法的效率。

Method: 收集GTA V游戏片段并标注玩家感兴趣的对象，分析影响兴趣的因素。

Result: 发现玩家游戏内速度、对象大小和对象速度是主要影响因素。

Conclusion: 数据集填补了现有研究的空白，有助于提升云游戏的QoE。

Abstract: Cloud gaming has gained popularity as it provides high-quality gaming
experiences on thin hardware, such as phones and tablets. Transmitting gameplay
frames at high resolutions and ultra-low latency is the key to guaranteeing
players' quality of experience (QoE). Numerous studies have explored deep
learning (DL) techniques to address this challenge. The efficiency of these
DL-based approaches is highly affected by the dataset. However, existing
datasets usually focus on the positions of objects while ignoring semantic
relationships with other objects and their unique features. In this paper, we
present a game dataset by collecting gameplay clips from Grand Theft Auto (GTA)
V, and annotating the player's interested objects during the gameplay. Based on
the collected data, we analyze several factors that have an impact on player's
interest and identify that the player's in-game speed, object's size, and
object's speed are the main factors. The dataset is available at
https://drive.google.com/drive/folders/1idH251a2K-hGGd3pKjX-3Gx5o_rUqLC4?usp=sharing

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [172] [Accelerating Data Chunking in Deduplication Systems using Vector Instructions](https://arxiv.org/abs/2508.05797)
*Sreeharsha Udayashankar,Abdelrahman Baba,Samer Al-Kiswany*

Main category: cs.DC

TL;DR: VectorCDC利用向量CPU指令加速无哈希CDC算法，显著提升性能，不影响去重空间节省。


<details>
  <summary>Details</summary>
Motivation: CDC算法因需扫描整个文件而成为性能瓶颈，亟需加速方法。

Method: 采用向量CPU指令（如SSE/AVX）优化无哈希CDC算法。

Result: 在多种CPU上实现8.35x-26.2x的吞吐量提升，且不影响空间节省。

Conclusion: VectorCDC是一种高效且兼容性强的CDC加速方案。

Abstract: Content-defined Chunking (CDC) algorithms dictate the overall space savings
that deduplication systems achieve. However, due to their need to scan each
file in its entirety, they are slow and often the main performance bottleneck
within data deduplication. We present VectorCDC, a method to accelerate
hashless CDC algorithms using vector CPU instructions, such as SSE / AVX. Our
evaluation shows that VectorCDC is effective on Intel, AMD, ARM, and IBM CPUs,
achieving 8.35x - 26.2x higher throughput than existing vector-accelerated
techniques without affecting the deduplication space savings.

</details>


### [173] [Snowpark: Performant, Secure, User-Friendly Data Engineering and AI/ML Next To Your Data](https://arxiv.org/abs/2508.05904)
*Brandon Baker,Elliott Brossard,Chenwei Xie,Zihao Ye,Deen Liu,Yijun Xie,Arthur Zwiegincew,Nitya Kumar Sharma,Gaurav Jain,Eugene Retunsky,Mike Halcrow,Derek Denny-Brown,Istvan Cseri,Tyler Akidau,Yuxiong He*

Main category: cs.DC

TL;DR: Snowpark是Snowflake推出的一个托管解决方案，支持数据工程和AI/ML工作负载，具有高性能、强安全性和易用性。


<details>
  <summary>Details</summary>
Motivation: Snowflake希望通过Snowpark扩展其AI Data Cloud愿景，支持更多编程语言（如Python）和复杂的数据工程与AI/ML任务。

Method: Snowpark采用弹性可扩展架构，与Snowflake核心计算基础设施无缝集成，利用控制平面进行分布式计算，并通过安全沙箱隔离SQL和Snowpark任务。

Result: Snowpark通过Python包缓存减少查询延迟，优化工作负载调度，并通过高效行重分布管理数据倾斜，提升了性能。

Conclusion: 实际案例展示了Snowpark在大规模数据工程和AI/ML任务中的高效性和有效性。

Abstract: Snowflake revolutionized data analytics with an elastic architecture that
decouples compute and storage, enabling scalable solutions supporting data
architectures like data lake, data warehouse, data lakehouse, and data mesh.
Building on this foundation, Snowflake has advanced its AI Data Cloud vision by
introducing Snowpark, a managed turnkey solution that supports data engineering
and AI and ML workloads using Python and other programming languages.
  This paper outlines Snowpark's design objectives towards high performance,
strong security and governance, and ease of use. We detail the architecture of
Snowpark, highlighting its elastic scalability and seamless integration with
Snowflake core compute infrastructure. This includes leveraging Snowflake
control plane for distributed computing and employing a secure sandbox for
isolating Snowflake SQL workloads from Snowpark executions. Additionally, we
present core innovations in Snowpark that drive further performance
enhancements, such as query initialization latency reduction through Python
package caching, improved workload scheduling for customized workloads, and
data skew management via efficient row redistribution. Finally, we showcase
real-world case studies that illustrate Snowpark's efficiency and effectiveness
for large-scale data engineering and AI and ML tasks.

</details>


### [174] [A Dynamic Approach to Load Balancing in Cloud Infrastructure: Enhancing Energy Efficiency and Resource Utilization](https://arxiv.org/abs/2508.05821)
*Shadman Sakib,Ajay Katangur,Rahul Dubey*

Main category: cs.DC

TL;DR: 论文提出了一种基于分数的动态负载均衡器（SBDLB），通过实时性能指标分配工作负载，显著提升了云系统的资源利用率和效率。


<details>
  <summary>Details</summary>
Motivation: 云计算的快速增长使得负载均衡成为关键，但动态管理服务器资源仍具挑战性。

Method: 采用基于分数的动态负载均衡策略，利用CloudSim 7G平台进行测试，并与节流负载均衡策略对比。

Result: SBDLB在响应时间、数据处理时间和运营成本上均优于节流策略，分别提升34%、37%和15%。

Conclusion: SBDLB能动态适应工作负载变化，优化资源使用，促进更节能可持续的云基础设施。

Abstract: Cloud computing has grown rapidly in recent years, mainly due to the sharp
increase in data transferred over the internet. This growth makes load
balancing a key part of cloud systems, as it helps distribute user requests
across servers to maintain performance, prevent overload, and ensure a smooth
user experience. Despite its importance, managing server resources and keeping
workloads balanced over time remains a major challenge in cloud environments.
This paper introduces a novel Score-Based Dynamic Load Balancer (SBDLB) that
allocates workloads to virtual machines based on real-time performance metrics.
The objective is to enhance resource utilization and overall system efficiency.
The method was thoroughly tested using the CloudSim 7G platform, comparing its
performance against the throttled load balancing strategy. Evaluations were
conducted across a variety of workloads and scenarios, demonstrating the
SBDLB's ability to adapt dynamically to workload fluctuations while optimizing
resource usage. The proposed method outperformed the throttled strategy,
improving average response times by 34% and 37% in different scenarios. It also
reduced data center processing times by an average of 13%. Over a 24-hour
simulation, the method decreased operational costs by 15%, promoting a more
energy-efficient and sustainable cloud infrastructure through reduced energy
consumption.

</details>


### [175] [KnapFormer: An Online Load Balancer for Efficient Diffusion Transformers Training](https://arxiv.org/abs/2508.06001)
*Kai Zhang,Peng Wang,Sai Bi,Jianming Zhang,Yuanjun Xiong*

Main category: cs.DC

TL;DR: KnapFormer是一个高效框架，结合工作负载平衡和序列并行，优化分布式训练中的Diffusion Transformers（DiT）。


<details>
  <summary>Details</summary>
Motivation: 解决分布式训练中因变长文本输入和混合分辨率数据导致的token不平衡问题。

Method: 通过全局背包问题重新分配token，最小化每GPU工作负载方差，并集成序列并行。

Result: 在真实训练中实现小于1%的工作负载差异，消除滞后效应，速度提升2-3倍。

Conclusion: KnapFormer显著提升了训练效率，适用于混合分辨率和图像-视频联合数据。

Abstract: We present KnapFormer, an efficient and versatile framework to combine
workload balancing and sequence parallelism in distributed training of
Diffusion Transformers (DiT). KnapFormer builds on the insight that strong
synergy exists between sequence parallelism and the need to address the
significant token imbalance across ranks. This imbalance arises from
variable-length text inputs and varying visual token counts in mixed-resolution
and image-video joint training. KnapFormer redistributes tokens by first
gathering sequence length metadata across all ranks in a balancing group and
solving a global knapsack problem. The solver aims to minimize the variances of
total workload per-GPU, while accounting for the effect of sequence
parallelism. By integrating DeepSpeed-Ulysees-based sequence parallelism in the
load-balancing decision process and utilizing a simple semi-empirical workload
model, KnapFormers achieves minimal communication overhead and less than 1%
workload discrepancy in real-world training workloads with sequence length
varying from a few hundred to tens of thousands. It eliminates straggler
effects and achieves 2x to 3x speedup when training state-of-the-art diffusion
models like FLUX on mixed-resolution and image-video joint data corpora. We
open-source the KnapFormer implementation at
https://github.com/Kai-46/KnapFormer/

</details>


### [176] [EC2MoE: Adaptive End-Cloud Pipeline Collaboration Enabling Scalable Mixture-of-Experts Inference](https://arxiv.org/abs/2508.06024)
*Zheming Yang,Yunqing Hu,Sheng Sun,Wen Ji*

Main category: cs.DC

TL;DR: EC2MoE是一个自适应框架，通过端云协作提升MoE模型的推理效率，解决了专家调度、通信开销和资源异构性等问题。


<details>
  <summary>Details</summary>
Motivation: 在异构端云环境中部署MoE模型面临专家调度、通信开销和资源异构性等挑战，需要一种高效且自适应的解决方案。

Method: 设计了硬件感知的轻量级组门网络和端云协作的流水线优化机制，包括低秩压缩的编码器-解码器结构和路由感知的启发式调度算法。

Result: 实验表明，EC2MoE在保持高精度的同时，吞吐量提升2.2x至5.1x，端到端延迟降低53%至67%。

Conclusion: EC2MoE在动态负载和网络环境下表现出良好的可扩展性，为MoE模型的端云部署提供了高效解决方案。

Abstract: The Mixture-of-Experts (MoE) paradigm has emerged as a promising solution to
scale up model capacity while maintaining inference efficiency. However,
deploying MoE models across heterogeneous end-cloud environments poses new
challenges in expert scheduling, communication overhead, and resource
heterogeneity. In this paper, we propose EC2MoE, an adaptive framework for
scalable MoE inference via end-cloud pipeline collaboration. First, we design a
hardware-aware lightweight group gate network that enhances expert selection
and computational efficiency. By incorporating a hardware-aware local expert
selection mechanism, the system adaptively filters candidate experts based on
real-time device profiles. A lightweight group gate module then integrates
local and global gating outputs to achieve high-quality expert routing with
minimal overhead. Second, we develop a pipeline optimization mechanism based on
endcloud collaboration to accelerate MoE inference. This includes an
encoder-decoder structure based on low-rank compression, which reduces
transmission and computation costs. And a route-aware heuristic pipeline
scheduling algorithm that dynamically allocates inference stages across devices
according to workload and network topology. Extensive experiments show that
EC2MoE can increase throughput by 2.2x to 5.1x and reduce end-to-end latency by
53% to 67% while maintaining high accuracy compared to state-of-the-art
methods. It also maintains good scalability under dynamic load and network
environments.

</details>


### [177] [KV Cache Compression for Inference Efficiency in LLMs: A Review](https://arxiv.org/abs/2508.06297)
*Yanyu Liu,Jingying Fu,Sixiang Liu,Yitian Zou,You Fu,Jiehan Zhou,Shouhua Zhang*

Main category: cs.DC

TL;DR: 本文综述了大型语言模型（LLM）推理中键值（KV）缓存的优化技术，包括压缩策略和注意力压缩，分析了其效果、权衡和应用场景，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着LLM上下文长度的增加，KV缓存需求呈指数增长，导致内存瓶颈，影响推理效率和可扩展性，因此优化KV缓存至关重要。

Method: 系统评估了选择性令牌策略、量化和注意力压缩等KV缓存优化技术，分析了其效果、权衡和应用场景。

Result: 现有方法在内存使用和推理速度方面有显著改进，但仍存在兼容性和任务适应性等挑战。

Conclusion: 未来研究方向包括混合优化技术、自适应动态策略和软硬件协同设计，以进一步提升推理效率和LLM的实用性。

Abstract: Withtherapid advancement of large language models (LLMs), the context length
for inference has been continuously increasing, leading to an exponential
growth in the demand for Key-Value (KV) caching. This has resulted in a
significant memory bottleneck, limiting the inference efficiency and
scalability of the models. Therefore, optimizing the KV cache during inference
is crucial for enhancing performance and efficiency. This review systematically
examines current KV cache optimization techniques, including compression
strategies such as selective token strategies, quantization, and attention
compression. We evaluate the effectiveness, trade-offs, and application
scenarios of these methods, providing a comprehensive analysis of their impact
on memory usage and inference speed. We focus on identifying the limitations
and challenges of existing methods, such as compatibility issues with different
models and tasks. Additionally, this review highlights future research
directions, including hybrid optimization techniques, adaptive dynamic
strategies, and software-hardware co-design. These approaches aim to improve
inference efficiency and promote the practical application of large language
models.

</details>


### [178] [Performant Unified GPU Kernels for Portable Singular Value Computation Across Hardware and Precision](https://arxiv.org/abs/2508.06339)
*Evelyne Ringoot,Rabab Alomairy,Valentin Churavy,Alan Edelman*

Main category: cs.DC

TL;DR: 本文介绍了一种基于Julia的便携式GPU加速QR奇异值计算算法实现，支持多种GPU架构和数据类型，性能优于多数线性代数库。


<details>
  <summary>Details</summary>
Motivation: 奇异值分解（SVD）是科学计算和机器学习中的基础工具，尤其在大型机器学习管道（如大语言模型）中需求增加。本文旨在提供一种高性能且便携的GPU加速实现。

Method: 基于经典的两阶段QR约简算法，利用Julia的多重分派和元编程能力，结合GPUArrays和KernelAbstractions框架，实现硬件无关的统一函数。

Result: 该实现在多种GPU后端和数据类型上表现优异，性能超过MAGMA、SLATE等库，接近cuSOLVER的80%-90%。

Conclusion: 该研究证明了便携性与高性能可以并存，为大规模机器学习任务提供了高效工具。

Abstract: This paper presents a portable, GPU-accelerated implementation of a QR-based
singular value computation algorithm in Julia. The singular value ecomposition
(SVD) is a fundamental numerical tool in scientific computing and machine
learning, providing optimal low-rank matrix approximations. Its importance has
increased even more in large-scale machine learning pipelines, including large
language models (LLMs), where it enables low-rank adaptation (LoRA). The
implemented algorithm is based on the classic two-stage QR reduction,
consisting of successive matrix reduction to band form and bidiagonal form. Our
implementation leverages Julia's multiple dispatch and metaprogramming
capabilities, integrating with the GPUArrays and KernelAbstractions frameworks
to provide a unified type and hardware-agnostic function. It supports diverse
GPU architectures and data types, and is, to our knowledge, the first
GPU-accelerated singular value implementation to support Apple Metal GPUs and
half precision. Performance results on multiple GPU backends and data types
demonstrate that portability does not require sacrificing performance: the
unified function outperforms most linear algebra libraries (MAGMA, SLATE,
rocSOLVER, oneMKL) for matrix sizes larger than 1024x1024, and achieves 80%-90%
of the performance of cuSOLVER for large matrices.

</details>


### [179] [Blockchain-Enabled Federated Learning](https://arxiv.org/abs/2508.06406)
*Murtaza Rangwala,Venugopal K R,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 区块链赋能的联邦学习（BCFL）通过四维分类法（协调结构、共识机制、存储架构和信任模型）解决了协作AI系统中的信任、隐私和协调问题，展示了从集中式到完全去中心化的设计模式，并通过实际案例验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 解决协作AI系统中的信任、隐私和协调问题，提升联邦学习的透明度和安全性。

Method: 通过四维分类法分析BCFL系统，包括协调结构、共识机制、存储架构和信任模型，并研究共识机制（如Proof of Quality和Proof of Federated Learning）和存储架构（如多层级设计）。

Result: BCFL系统在医疗、金融和物联网安全等实际应用中表现良好，性能接近集中式方法，同时提供更强的安全性和透明性。

Conclusion: BCFL系统通过区块链技术有效解决了联邦学习中的关键挑战，实现了高效、安全且透明的协作AI。

Abstract: Blockchain-enabled federated learning (BCFL) addresses fundamental challenges
of trust, privacy, and coordination in collaborative AI systems. This chapter
provides comprehensive architectural analysis of BCFL systems through a
systematic four-dimensional taxonomy examining coordination structures,
consensus mechanisms, storage architectures, and trust models. We analyze
design patterns from blockchain-verified centralized coordination to fully
decentralized peer-to-peer networks, evaluating trade-offs in scalability,
security, and performance. Through detailed examination of consensus mechanisms
designed for federated learning contexts, including Proof of Quality and Proof
of Federated Learning, we demonstrate how computational work can be repurposed
from arbitrary cryptographic puzzles to productive machine learning tasks. The
chapter addresses critical storage challenges by examining multi-tier
architectures that balance blockchain's transaction constraints with neural
networks' large parameter requirements while maintaining cryptographic
integrity. A technical case study of the TrustMesh framework illustrates
practical implementation considerations in BCFL systems through distributed
image classification training, demonstrating effective collaborative learning
across IoT devices with highly non-IID data distributions while maintaining
complete transparency and fault tolerance. Analysis of real-world deployments
across healthcare consortiums, financial services, and IoT security
applications validates the practical viability of BCFL systems, achieving
performance comparable to centralized approaches while providing enhanced
security guarantees and enabling new models of trustless collaborative
intelligence.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [180] [Hierarchical Placement Learning for Network Slice Provisioning](https://arxiv.org/abs/2508.06432)
*Jesutofunmi Ajayi,Antonio Di Maio,Torsten Braun*

Main category: cs.NI

TL;DR: 提出了一种基于分层多臂老虎机的解决方案，用于边缘移动网络中的切片配置，以最大化请求接受率并最小化节点资源利用率。


<details>
  <summary>Details</summary>
Motivation: 解决边缘移动网络中切片配置的挑战，优化资源利用和请求接受率。

Method: 采用分层多臂老虎机问题，提出两级分层老虎机解决方案，学习可扩展的在线放置策略。

Result: 在两种真实网络拓扑的模拟中，相比基线方法，平均节点资源利用率降低至5%，切片请求接受率提高25%。

Conclusion: 所提方法在资源利用和请求接受率方面优于基线方法，适用于边缘移动网络的切片配置。

Abstract: In this work, we aim to address the challenge of slice provisioning in
edge-based mobile networks. We propose a solution that learns a service
function chain placement policy for Network Slice Requests, to maximize the
request acceptance rate, while minimizing the average node resource
utilization. To do this, we consider a Hierarchical Multi-Armed Bandit problem
and propose a two-level hierarchical bandit solution which aims to learn a
scalable placement policy that optimizes the stated objectives in an online
manner. Simulations on two real network topologies show that our proposed
approach achieves 5% average node resource utilization while admitting over 25%
more slice requests in certain scenarios, compared to baseline methods.

</details>


### [181] [An Online Multi-dimensional Knapsack Approach for Slice Admission Control](https://arxiv.org/abs/2508.06468)
*Jesutofunmi Ajayi,Antonio Di Maio,Torsten Braun,Dimitrios Xenakis*

Main category: cs.NI

TL;DR: 网络切片技术通过共享物理网络资源实现多租户服务，但资源需求不确定性带来挑战。本文提出在线多维背包问题模型及两种预留策略，通过模拟验证其优于先到先服务策略。


<details>
  <summary>Details</summary>
Motivation: 解决网络切片资源分配中的不确定性，最大化长期收入。

Method: 将切片准入控制建模为在线多维背包问题，提出两种预留策略及算法。

Result: 模拟结果显示，新策略使收入提高12.9%，资源消耗降低1.7%，经济不平等时优势更明显。

Conclusion: 预留策略优于传统先到先服务，提升收入并优化资源利用。

Abstract: Network Slicing has emerged as a powerful technique to enable cost-effective,
multi-tenant communications and services over a shared physical mobile network
infrastructure. One major challenge of service provisioning in slice-enabled
networks is the uncertainty in the demand for the limited network resources
that must be shared among existing slices and potentially new Network Slice
Requests. In this paper, we consider admission control of Network Slice
Requests in an online setting, with the goal of maximizing the long-term
revenue received from admitted requests. We model the Slice Admission Control
problem as an Online Multidimensional Knapsack Problem and present two
reservation-based policies and their algorithms, which have a competitive
performance for Online Multidimensional Knapsack Problems. Through Monte Carlo
simulations, we evaluate the performance of our online admission control method
in terms of average revenue gained by the Infrastructure Provider, system
resource utilization, and the ratio of accepted slice requests. We compare our
approach with those of the online First Come First Serve greedy policy. The
simulation's results prove that our proposed online policies increase revenues
for Infrastructure Providers by up to 12.9 % while reducing the average
resource consumption by up to 1.7% In particular, when the tenants' economic
inequality increases, an Infrastructure Provider who adopts our proposed online
admission policies gains higher revenues compared to an Infrastructure Provider
who adopts First Come First Serve.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [182] [Hybrid Game Control Envelope Synthesis](https://arxiv.org/abs/2508.05997)
*Aditi Kabra,Jonathan Laurent,Stefan Mitsch,André Platzer*

Main category: cs.PL

TL;DR: 本文提出了一种合成混合游戏中非确定性获胜策略的方法，通过子值映射的组成表示实现策略的验证与合成，并展示了最大子值映射的存在性及其逻辑特性。


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式系统（如汽车和火车）控制问题，通过混合游戏模型生成尽可能宽松的安全控制解决方案。

Method: 引入子值映射作为策略的组成表示，利用微分游戏逻辑（dGL）进行逻辑验证，并开发算法合成非确定性策略。

Result: 证明了最大子值映射的存在性及其逻辑特性，并通过实现验证了方法的有效性。

Conclusion: 该方法能够灵活应对多样化的控制挑战，为混合游戏中的策略合成提供了有效工具。

Abstract: Control problems for embedded systems like cars and trains can be modeled by
two-player hybrid games. Control envelopes, which are families of safe control
solutions, correspond to nondeterministic winning policies of hybrid games,
where each deterministic specialization of the policy is a control solution.
This paper synthesizes nondeterministic winning policies for hybrid games that
are as permissive as possible. It introduces subvalue maps, a compositional
representation of such policies that enables verification and synthesis along
the structure of the game. An inductive logical characterization in
differential game logic (dGL) checks whether a subvalue map induces a sound
control envelope which always induces a winning play. A policy is said to win
if it always achieves the desirable outcome when the player follows it, no
matter what actions the opponent plays. The maximal subvalue map, which allows
the most action options while still winning, is shown to exist and satisfy a
logical characterization. A family of algorithms for nondeterministic policy
synthesis can be obtained from the inductive subvalue map soundness
characterization. An implementation of these findings is evaluated on examples
that use the expressivity of dGL to model a range of diverse control
challenges.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [183] [Empirical Evaluation of AI-Assisted Software Package Selection: A Knowledge Graph Approach](https://arxiv.org/abs/2508.05693)
*Siamak Farshidi,Amir Saberhabibi,Behbod Eskafi,Niloofar Nikfarjam,Sadegh Eskandari,Slinger Jansen,Michel Chaudron,Bedir Tekinerdogan*

Main category: cs.SE

TL;DR: 论文提出了一种基于多准则决策（MCDM）的数据驱动框架PySelect，用于解决开源生态系统中第三方软件包选择的挑战，结合AI辅助意图建模，提高了推荐质量和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 开源生态系统中软件包选择困难，现有生成式AI工具依赖流行度而非适用性，缺乏透明性和可重复性。

Method: 通过自动化数据管道收集软件元数据、使用趋势、漏洞信息等，构建决策模型，并开发PySelect系统结合大语言模型进行意图解析和推荐。

Result: 实验显示数据提取精度高，推荐质量优于生成式AI基线，用户评价积极。

Conclusion: 该框架可扩展、可解释且可重复，支持基于证据的软件包选择。

Abstract: Selecting third-party software packages in open-source ecosystems like Python
is challenging due to the large number of alternatives and limited transparent
evidence for comparison. Generative AI tools are increasingly used in
development workflows, but their suggestions often overlook dependency
evaluation, emphasize popularity over suitability, and lack reproducibility.
This creates risks for projects that require transparency, long-term
reliability, maintainability, and informed architectural decisions. This study
formulates software package selection as a Multi-Criteria Decision-Making
(MCDM) problem and proposes a data-driven framework for technology evaluation.
Automated data pipelines continuously collect and integrate software metadata,
usage trends, vulnerability information, and developer sentiment from GitHub,
PyPI, and Stack Overflow. These data are structured into a decision model
representing relationships among packages, domain features, and quality
attributes. The framework is implemented in PySelect, a decision support system
that uses large language models to interpret user intent and query the model to
identify contextually appropriate packages. The approach is evaluated using
798,669 Python scripts from 16,887 GitHub repositories and a user study based
on the Technology Acceptance Model. Results show high data extraction
precision, improved recommendation quality over generative AI baselines, and
positive user evaluations of usefulness and ease of use. This work introduces a
scalable, interpretable, and reproducible framework that supports
evidence-based software selection using MCDM principles, empirical data, and
AI-assisted intent modeling.

</details>


### [184] [Klear-CodeTest: Scalable Test Case Generation for Code Reinforcement Learning](https://arxiv.org/abs/2508.05710)
*Jia Fu,Xinyu Yang,Hongzhi Zhang,Yahui Liu,Jingyuan Zhang,Qi Wang,Fuzheng Zhang,Guorui Zhou*

Main category: cs.SE

TL;DR: Klear-CodeTest是一个用于代码强化学习的测试用例合成框架，通过生成器-验证（G-V）机制和一致性验证确保测试用例的质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 高质量的测试用例对训练大型语言模型（LLMs）至关重要，但目前合成高质量测试用例仍是一个未解决的难题。

Method: 采用G-V框架生成包括常规和边界情况的测试用例，并通过一致性验证确保正确性；同时设计多层安全沙箱系统保障代码执行安全。

Result: 实验证明该框架显著提升了模型性能和训练稳定性。

Conclusion: Klear-CodeTest为代码强化学习提供了高质量的测试用例合成方案，并开源了相关资源。

Abstract: Precise, correct feedback is crucial for effectively training large language
models (LLMs) in code reinforcement learning. However, synthesizing
high-quality test cases remains a profoundly challenging and unsolved problem.
In this work, we present Klear-CodeTest, a comprehensive test case synthesis
framework featuring rigorous verification to ensure quality and reliability of
test cases. Our approach achieves broad coverage of programming problems via a
novel Generator-Validation (G-V) framework, ensuring correctness through a
consistency validation mechanism that verifies outputs against gold solutions.
The proposed G-V framework generates comprehensive test cases including both
regular and corner cases, enhancing test coverage and discriminative power for
solution correctness assessment in code reinforcement learning. In addition, we
design a multi-layered security sandbox system optimized for online
verification platforms, guaranteeing safe and reliable code execution. Through
comprehensive experiments, we demonstrate the effectiveness of our curated
dataset, showing significant improvements in model performance and training
stability. The source codes, curated dataset and sandbox system are available
at: https://github.com/Kwai-Klear/CodeTest.

</details>


### [185] [Utilizing Composer Packages to Accelerate Laravel-Based Project Development Among Students: A Pedagogical and Practical Framework](https://arxiv.org/abs/2508.05747)
*Rohaizah Abdul Wahid,Muhamad Said Nizamuddin Nadim,Suliana Sulaiman,Syahmi Akmal Shaharudin,Muhammad Danial Jupikil,Iqqwan Jasman Su Azlan Su*

Main category: cs.SE

TL;DR: 论文探讨了在Laravel教学中引入Composer及其精选包以提升开发效率，同时强调代码质量和概念理解的重要性，并提供了避免依赖风险的实践建议。


<details>
  <summary>Details</summary>
Motivation: 学生在有限时间内完成Laravel项目存在困难，希望通过Composer工具提升开发效率，同时培养专业软件实践能力。

Method: 介绍Composer及其精选包，结合教学实践，展示如何利用这些工具构建学术或个人项目，并强调代码质量和概念理解。

Result: Composer包能显著减少开发时间，增强课程与行业的关联性，但需注意避免过度依赖和包冲突。

Conclusion: 有效整合Composer需结合教学目标，教师需指导学生正确使用工具，确保实用性与深度学习并重。

Abstract: Laravel has emerged as a foundational framework in university web development
curricula. However, despite its scaffolding capabilities, students often
struggle to complete projects within limited academic timelines. This
conceptual paper introduces Composer, PHP's standard dependency manager, and
categorizes a curated selection of Composer packages that significantly reduce
development effort while fostering professional software practices. Grounded in
practical and pedagogical considerations, the paper illustrates how educators
and learners can strategically leverage these tools to build typical academic
or personal Laravel-based systems. Central to this approach is maintaining code
quality and reinforcing conceptual understanding. The paper also addresses
potential risks such as package conflicts and over-reliance on tools, providing
best-practice recommendations to mitigate them. While the goal is to accelerate
development, the deeper objective is to reinforce professional workflows and
industry readiness. Exposure to Composer packages enhances curriculum relevance
and smooths the transition from academia to the workplace. However, effective
integration requires deliberate instructional design aligned with learning
objectives. Without guidance, students may treat packages as black boxes. Thus,
educators must teach not only how to use these tools, but also when and why,
encouraging critical evaluation of their utility and limitations. This ensures
that practical convenience supports rather than supplants deep learning.

</details>


### [186] [AI-Guided Exploration of Large-Scale Codebases](https://arxiv.org/abs/2508.05799)
*Yoseph Berhanu Alebachew*

Main category: cs.SE

TL;DR: 论文提出了一种结合确定性逆向工程与LLM引导的意图感知可视化探索的混合方法，以提升代码理解的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 开发者花费大量时间在程序理解上，传统工具缺乏交互性和适应性，LLMs虽提供了新机会，但缺乏与结构化视图的整合。

Method: 结合UML可视化、动态用户界面、历史上下文和协作功能，通过LLM解析用户查询和交互模式，帮助理解复杂代码库。

Result: 原型实现展示了该方法的可行性，未来工作包括实证评估、扩展到多语言系统和探索GUI驱动的LLM交互模型。

Conclusion: 研究为智能、交互式开发环境奠定了基础，符合开发者认知和协作工作流程。

Abstract: Understanding large-scale, complex software systems is a major challenge for
developers, who spend a significant portion of their time on program
comprehension. Traditional tools such as static visualizations and reverse
engineering techniques provide structural insights but often lack
interactivity, adaptability, and integration with contextual information.
Recent advancements in large language models (LLMs) offer new opportunities to
enhance code exploration workflows, yet their lack of grounding and integration
with structured views limits their effectiveness. This work introduces a hybrid
approach that integrates deterministic reverse engineering with LLM-guided,
intent-aware visual exploration. The proposed system combines UML-based
visualization, dynamic user interfaces, historical context, and collaborative
features into an adaptive tool for code comprehension. By interpreting user
queries and interaction patterns, the LLM helps developers navigate and
understand complex codebases more effectively. A prototype implementation for
Java demonstrates the feasibility of this approach. Future work includes
empirical evaluation, scaling to polyglot systems, and exploring GUI-driven LLM
interaction models. This research lays the groundwork for intelligent,
interactive environments that align with developer cognition and collaborative
workflows.

</details>


### [187] [Enhancing Software Vulnerability Detection Through Adaptive Test Input Generation Using Genetic Algorithm](https://arxiv.org/abs/2508.05923)
*Yanusha Mehendran,Maolin Tang,Yi Lu*

Main category: cs.SE

TL;DR: 该论文提出了一种基于遗传算法的测试输入生成方法，结合遗传操作和自适应学习，显著提升了软件漏洞检测的覆盖率和效果。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞的复杂性超过了传统检测方法的能力，需要更高效的测试输入生成技术。

Method: 采用遗传算法，结合交叉操作和自适应反馈机制，动态生成和优化测试输入。

Result: 在九个开源JSON处理库上测试，覆盖率显著提升，最高达166%。

Conclusion: 该方法能有效检测更深层次的漏洞，为软件安全测试提供了可扩展的解决方案。

Abstract: Software vulnerabilities continue to undermine the reliability and security
of modern systems, particularly as software complexity outpaces the
capabilities of traditional detection methods. This study introduces a genetic
algorithm-based method for test input generation that innovatively integrates
genetic operators and adaptive learning to enhance software vulnerability
detection. A key contribution is the application of the crossover operator,
which facilitates exploration by searching across a broader space of potential
test inputs. Complementing this, an adaptive feedback mechanism continuously
learns from the system's execution behavior and dynamically guides input
generation toward promising areas of the input space. Rather than relying on
fixed or randomly selected inputs, the approach evolves a population of
structurally valid test cases using feedback-driven selection, enabling deeper
and more effective code traversal. This strategic integration of exploration
and exploitation ensures that both diverse and targeted test inputs are
developed over time. Evaluation was conducted across nine open-source
JSON-processing libraries. The proposed method achieved substantial
improvements in coverage compared to a benchmark evolutionary fuzzing method,
with average gains of 39.8% in class coverage, 62.4% in method coverage, 105.0%
in line coverage, 114.0% in instruction coverage, and 166.0% in branch
coverage. These results highlight the method's capacity to detect deeper and
more complex vulnerabilities, offering a scalable and adaptive solution to
software security testing.

</details>


### [188] [A Survey on Task Scheduling in Carbon-Aware Container Orchestration](https://arxiv.org/abs/2508.05949)
*Jialin Yang,Zainab Saad,Jiajun Wu,Xiaoguang Niu,Henry Leung,Steve Drew*

Main category: cs.SE

TL;DR: 本文综述了Kubernetes调度策略，分类为硬件中心和软件中心，并提出了一种关注环境可持续性的云任务调度分类法。


<details>
  <summary>Details</summary>
Motivation: 大规模软件生态系统和云数据中心的能源需求激增，尤其是大型语言模型的训练和部署，导致能源消耗和碳足迹达到前所未有的水平。

Method: 系统回顾了各种Kubernetes调度策略，按硬件中心和软件中心分类，并标注其可持续性目标。

Result: 提出了一个全面的云任务调度分类法，特别关注环境可持续性，并分析了研究趋势和开放挑战。

Conclusion: 研究结果为下一代云计算系统设计可持续调度解决方案提供了关键见解。

Abstract: The soaring energy demands of large-scale software ecosystems and cloud data
centers, accelerated by the intensive training and deployment of large language
models, have driven energy consumption and carbon footprint to unprecedented
levels. In response, both industry and academia are increasing efforts to
reduce the carbon emissions associated with cloud computing through more
efficient task scheduling and infrastructure orchestration. In this work, we
present a systematic review of various Kubernetes scheduling strategies,
categorizing them into hardware-centric and software-centric, annotating each
with its sustainability objectives, and grouping them according to the
algorithms they use. We propose a comprehensive taxonomy for cloud task
scheduling studies, with a particular focus on the environmental sustainability
aspect. We analyze emerging research trends and open challenges, and our
findings provide critical insight into the design of sustainable scheduling
solutions for next-generation cloud computing systems.

</details>


### [189] [Impact-driven Context Filtering For Cross-file Code Completion](https://arxiv.org/abs/2508.05970)
*Yanzhou Li,Shangqing Liu,Kangjie Chen,Tianwei Zhang,Yang Liu*

Main category: cs.SE

TL;DR: 本文提出了一种基于检索增强生成（RAG）的代码补全方法，通过引入似然度量评估检索代码块的影响，并构建了带标签的数据集。进一步提出了自适应检索上下文过滤框架CODEFILTER，显著提升了补全准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决检索增强生成中检索到的代码块对补全效果的不一致性（部分有益，部分有害）的问题。

Method: 提出似然度量评估检索块的影响，构建带标签数据集，并开发自适应过滤框架CODEFILTER。

Result: CODEFILTER在多个基准测试中显著提升补全准确性，减少输入提示长度，提高计算效率。

Conclusion: CODEFILTER有效提升了代码补全的准确性、效率和可归因性，展示了其在仓库级代码补全中的潜力。

Abstract: Retrieval-augmented generation (RAG) has recently demonstrated considerable
potential for repository-level code completion, as it integrates cross-file
knowledge with in-file preceding code to provide comprehensive contexts for
generation. To better understand the contribution of the retrieved cross-file
contexts, we introduce a likelihood-based metric to evaluate the impact of each
retrieved code chunk on the completion. Our analysis reveals that, despite
retrieving numerous chunks, only a small subset positively contributes to the
completion, while some chunks even degrade performance. To address this issue,
we leverage this metric to construct a repository-level dataset where each
retrieved chunk is labeled as positive, neutral, or negative based on its
relevance to the target completion. We then propose an adaptive retrieval
context filtering framework, CODEFILTER, trained on this dataset to mitigate
the harmful effects of negative retrieved contexts in code completion.
Extensive evaluation on the RepoEval and CrossCodeLongEval benchmarks
demonstrates that CODEFILTER consistently improves completion accuracy compared
to approaches without filtering operations across various tasks. Additionally,
CODEFILTER significantly reduces the length of the input prompt, enhancing
computational efficiency while exhibiting strong generalizability across
different models. These results underscore the potential of CODEFILTER to
enhance the accuracy, efficiency, and attributability of repository-level code
completion.

</details>


### [190] [Position: Intelligent Coding Systems Should Write Programs with Justifications](https://arxiv.org/abs/2508.06017)
*Xiangzhe Xu,Shiwei Feng,Zian Su,Chengpeng Wang,Xiangyu Zhang*

Main category: cs.SE

TL;DR: 论文探讨了智能编码系统需生成清晰、一致的代码解释以提升用户信任，并提出了神经符号方法作为解决方案。


<details>
  <summary>Details</summary>
Motivation: AI驱动的编码系统决策不透明，导致非专家用户对其信任和可用性存疑。

Method: 提出神经符号方法，结合符号约束和神经表示，生成认知对齐和语义忠实的解释。

Result: 现有方法（如形式验证、静态分析）在生成解释方面存在局限性。

Conclusion: 神经符号方法有望通过自动化一致性检查提升代码解释的清晰度和一致性。

Abstract: Intelligent coding systems are transforming software development by enabling
users to specify code behavior in natural language. However, the opaque
decision-making of AI-driven coders raises trust and usability concerns,
particularly for non-expert users who cannot inspect low-level implementations.
We argue that these systems should not only generate code but also produce
clear, consistent justifications that bridge model reasoning and user
understanding. To this end, we identify two critical justification
properties-cognitive alignment and semantic faithfulness-and highlight the
limitations of existing methods, including formal verification, static
analysis, and post-hoc explainability. We advocate exploring neuro-symbolic
approaches for justification generation, where symbolic constraints guide model
behavior during training and program semantics are enriched through neural
representations, enabling automated consistency checks at inference time.

</details>


### [191] [Understanding Inconsistent State Update Vulnerabilities in Smart Contracts](https://arxiv.org/abs/2508.06192)
*Lantian Li,Yuyu Chen,Jingwen Wu,Yue Pan,Zhongxing Yu*

Main category: cs.SE

TL;DR: 本文首次对智能合约中的不一致状态更新漏洞进行了大规模实证研究，总结了其根本原因、修复策略和利用方法，并提出了11个重要发现。


<details>
  <summary>Details</summary>
Motivation: 智能合约的状态更新问题可能导致安全漏洞，现有工具难以有效检测，因此需要深入研究以帮助开发者、研究人员和工具设计者避免此类漏洞。

Method: 系统研究了352个真实智能合约项目中的116个不一致状态更新漏洞，总结了其特点，并开发了一个概念验证检测工具。

Result: 研究发现11个重要结论，检测工具在64个GitHub项目中有效发现问题，19个项目所有者确认了问题。

Conclusion: 研究结果对避免智能合约中的不一致状态更新漏洞具有重要价值。

Abstract: Smart contracts enable contract terms to be automatically executed and
verified on the blockchain, and recent years have witnessed numerous
applications of them in areas such as financial institutions and supply chains.
The execution logic of a smart contract is closely related to the contract
state, and thus the correct and safe execution of the contract depends heavily
on the precise control and update of the contract state. However, the contract
state update process can have issues. In particular, inconsistent state update
issues can arise for reasons such as unsynchronized modifications. Inconsistent
state update bugs have been exploited by attackers many times, but existing
detection tools still have difficulty in effectively identifying them. This
paper conducts the first large-scale empirical study about inconsistent state
update vulnerabilities (that is, inconsistent state update bugs that are
exploitable) in smart contracts, aiming to shed light for developers,
researchers, tool builders, and language or library designers in order to avoid
inconsistent state update vulnerabilities. We systematically investigate 116
inconsistent state update vulnerabilities in 352 real-world smart contract
projects, summarizing their root causes, fix strategies, and exploitation
methods. Our study provides 11 original and important findings, and we also
give the implications of our findings. To illustrate the potential benefits of
our research, we also develop a proof-of-concept checker based on one of our
findings. The checker effectively detects issues in 64 popular GitHub projects,
and 19 project owners have confirmed the detected issues at the time of
writing. The result demonstrates the usefulness and importance of our findings
for avoiding inconsistent state update vulnerabilities in smart contracts.

</details>


### [192] [Improving the Developer Experience with a Low-Code Process Modelling Language](https://arxiv.org/abs/2508.06299)
*Henrique Henriques,Hugo Lourenço,Vasco Amaral,Miguel Goulão*

Main category: cs.SE

TL;DR: 论文分析了OutSystems平台中业务流程建模语言（BPT）的低采用率和可用性问题，通过访谈、符号物理理论评估和实证研究改进BPT，新版本显著提升了语义透明度、正确性和用户体验。


<details>
  <summary>Details</summary>
Motivation: BPT语言的低采用率和可用性问题增加了维护成本，亟需改进以提升开发者的使用体验。

Method: 结合访谈、符号物理理论（Physics of Notation）评估、系统可用性量表（SUS）和NASA任务负荷指数（TLX）进行实证研究，改进BPT语言。

Result: 新版本BPT的语义透明度从31%提升至69%，正确率从51%提升至89%，SUS分数从42.25增至64.78，TLX分数从36.50降至20.78，差异显著。

Conclusion: 改进后的BPT显著提升了开发者体验，用户背景对最终语法选择和可用性指标有重要影响。

Abstract: Context: The OutSystems Platform is a development environment composed of
several DSLs, used to specify, quickly build, and validate web and mobile
applications. The DSLs allow users to model different perspectives such as
interfaces and data models, define custom business logic and construct process
models. Problem: The DSL for process modelling (Business Process Technology
(BPT)), has a low adoption rate and is perceived as having usability problems
hampering its adoption. This is problematic given the language maintenance
costs. Method: We used a combination of interviews, a critical review of BPT
using the "Physics of Notation" and empirical evaluations of BPT using the
System Usability Scale (SUS) and the NASA Task Load indeX (TLX), to develop a
new version of BPT, taking these inputs and Outsystems' engineers' culture into
account. Results: Evaluations conducted with 25 professional software engineers
showed an increase of the semantic transparency on the new version, from 31% to
69%, an increase in the correctness of responses, from 51% to 89%, an increase
in the SUS score, from 42.25 to 64.78, and a decrease of the TLX score, from
36.50 to 20.78. These differences were statistically significant. Conclusions:
These results suggest that the new version of BPT significantly improved the
developer experience of the previous version. The end users' background with
OutSystems had a relevant impact on the final concrete syntax choices and
achieved usability indicators.

</details>


### [193] [Execution-Feedback Driven Test Generation from SWE Issues](https://arxiv.org/abs/2508.06365)
*Toufique Ahmed,Jatin Ganhotra,Avraham Shinnar,Martin Hirzel*

Main category: cs.SE

TL;DR: 论文探讨了如何自动生成软件工程问题的复现测试，解决了代码缺失或错误时的测试生成难题，提出了新方法并实现了工具e-Otter++，实验显示其性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 大多数软件工程问题缺乏复现测试，而现有方法因代码缺失或错误难以生成有效测试，因此需要新技术解决这一挑战。

Method: 提出利用执行反馈的新技术，绕过代码缺失或错误的问题，并实现工具e-Otter++。

Result: 在TDD-Bench Verified基准测试中，e-Otter++的平均失败转通过率达到63%，显著优于现有方法。

Conclusion: e-Otter++通过创新技术解决了代码缺失或错误时的测试生成问题，为软件工程领域提供了高效工具。

Abstract: A software engineering issue (SWE issue) is easier to resolve when
accompanied by a reproduction test. Unfortunately, most issues do not come with
functioning reproduction tests, so this paper explores how to generate them
automatically. The primary challenge in this setting is that the code to be
tested is either missing or wrong, as evidenced by the existence of the issue
in the first place. This has held back test generation for this setting:
without the correct code to execute, it is difficult to leverage execution
feedback to generate good tests. This paper introduces novel techniques for
leveraging execution feedback to get around this problem, implemented in a new
reproduction test generator called e-Otter++. Experiments show that e-Otter++
represents a leap ahead in the state-of-the-art for this problem, generating
tests with an average fail-to-pass rate of 63% on the TDD-Bench Verified
benchmark.

</details>


### [194] [What Builds Effective In-Context Examples for Code Generation?](https://arxiv.org/abs/2508.06414)
*Dongze Li,Songqiang Chen,Jialun Cao,Shing-Chi Cheung*

Main category: cs.SE

TL;DR: 本文研究了代码示例中不同特征（如命名风格、格式、解决方案洞察）对ICL在代码生成中效果的影响，发现变量和函数的适当命名至关重要，而LLMs更关注语义上有意义的标识符名称。


<details>
  <summary>Details</summary>
Motivation: 探索代码示例中哪些具体特征显著影响ICL在代码生成中的效果，以优化ICL系统。

Method: 通过控制消融实验，系统研究代码特征对ICL的影响。

Result: 变量和函数命名对代码生成效果影响显著，性能下降可达30%；LLMs更重视语义命名而非格式；当前LLMs难以从类似代码中提取通用问题解决洞察。

Conclusion: 研究为优化代码生成中的ICL系统提供了见解，并揭示了基于反思学习的代码生成任务中的基本挑战。

Abstract: In-Context Learning (ICL) has emerged as a promising solution to enhance the
code generation capabilities of Large Language Models (LLMs), which
incorporates code examples inside the prompt to let LLMs learn from
demonstrations. However, despite the substantial effectiveness of the code
example-based ICL approach, the specific features (e.g., identifier naming
styles, code formatting, solution insight) within the ICL-provided code
examples that significantly contribute to the ICL's effectiveness remain
unclear. This paper systematically investigates the impact of various code
features on ICL with code examples through controlled ablation studies. Our
findings reveal that the appropriate naming of variables and functions is
crucial for effective code generation, with their elimination leading to
performance decreases of up to 30 percentage points. We further demonstrate
that LLMs prioritize semantically meaningful identifier names over formatting
conventions, with language-specific preferences regarding identifier verbosity.
Additionally, our investigation into ICL's potential for enhancing reflection
and inference capabilities reveals that current LLMs struggle to extract
generalizable problem-solving insights from similar code solutions, despite
being capable of utilizing direct information effectively. These findings are
expected to provide valuable insights for optimizing ICL systems in code
generation applications and highlight fundamental challenges in
reflection-based learning for code generation tasks.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [195] [To Each Their Own: Heterogeneity in Worker Preferences for Peer Information](https://arxiv.org/abs/2508.06162)
*Zhi Hao Lim*

Main category: econ.GN

TL;DR: 研究开发了一种可移植的理论驱动方法，用于分析工人对同行信息的偏好异质性及其机制。通过实验识别出四种工人类型，并发现定制信息传递时间可显著提升福利。


<details>
  <summary>Details</summary>
Motivation: 探讨工人对同行信息的不同偏好及其背后的原因，以优化信息传递策略。

Method: 在793名工人中进行真实努力实验，通过支付意愿衡量对任务前后同行信息的需求。

Result: 识别出四种工人类型（冷漠型、压力回避型、竞争型和学习型），其行为与理论预测一致。15%的工人因压力而避免信息，且无生产力提升。定制信息传递时间可提升福利48%。

Conclusion: 工人对同行信息的偏好存在显著异质性，定制化策略能显著改善福利。

Abstract: Peer information is pervasive in the workplace, but workers differ in whether
and why they value such information. We develop a portable, theory-driven
methodology to study heterogeneity in information preferences and the
underlying mechanisms. In a real-effort experiment with 793 workers, we elicit
willingness-to-pay for peer information delivered either before or after a
task. We identify four worker types (indifferent, stress-avoidant, competitive,
and learning-oriented) whose effort responses align with theoretical
predictions. Workers' stated motivations in free-text responses strongly
correlate with their revealed preferences and behavior, validating our
classification. Notably, a nontrivial share (15%) strictly prefers to avoid
information ex ante due to stress and exhibit no productivity gains from it.
Tailoring the timing of information by worker type improves welfare by up to
48% relative to a uniform policy.

</details>


### [196] [Strategy Method Effects in Centipede Games: An Optimal Design Approach](https://arxiv.org/abs/2508.06425)
*Shiang-Hung Hu,Po-Hsuan Lin,Thomas R. Palfrey,Joseph Tao-yi Wang,Yu-Hsiang Wang*

Main category: econ.GN

TL;DR: 研究探讨了策略方法在实验室序贯博弈中引发行为扭曲的时间和原因，比较了三种选择引出方法的行为差异。


<details>
  <summary>Details</summary>
Motivation: 理解策略方法为何及何时在序贯博弈中引发行为扭曲，填补理论解释的空白。

Method: 设计了六个最优化的蜈蚣博弈实验，分别采用直接响应法、简化策略法和完整策略法。

Result: 发现不同引出方法之间存在显著行为差异，标准博弈理论无法解释，但与动态认知层级理论预测一致。

Conclusion: 策略方法的选择引出方式显著影响行为，动态认知层级理论能更好解释这些差异。

Abstract: We explore the twin questions of when and why the strategy method creates
behavioral distortions in the elicitation of choices in laboratory studies of
sequential games. While such distortions have been widely documented, the
theoretical forces driving these distortions remain poorly understood. In this
paper, we compare behavior in six optimally designed centipede games,
implemented under three different choice elicitation methods: the direct
response method, the reduced strategy method and the full strategy method.
These methods elicit behavioral strategies, reduced strategies, and complete
strategies, respectively. We find significant behavioral differences across
these elicitation methods -- differences that cannot be explained by standard
game theory, but are consistent with the predictions of the Dynamic Cognitive
Hierarchy solution (Lin and Palfrey, 2024), combined with quantal responses.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [197] [Inattention to States and Characteristics](https://arxiv.org/abs/2508.05939)
*Chris Engh*

Main category: econ.TH

TL;DR: 论文研究了状态-动作理性不关注模型的广义化，引入状态和享乐特征的双重不确定性，得到唯一且非角解的加权多项Logit形式条件选择概率。


<details>
  <summary>Details</summary>
Motivation: 探讨状态-动作模型中双重不确定性的影响，提出更通用的模型框架。

Method: 扩展状态-动作理性不关注模型，引入状态和享乐特征的双重不确定性，推导条件选择概率。

Result: 条件选择概率为唯一且非角解的加权多项Logit形式，模型对市场产品进入行为有可测试限制。

Conclusion: 模型为状态-动作理性不关注提供了更通用的框架，并具有实际应用的可测试性。

Abstract: We study a generalization of the state-action rational inattention model with
two dimensions of uncertainty: states and hedonic characteristics. The
resulting conditional choice probability takes a familiar weighted multinomial
logit form, but in contrast to the state-action model, is unique and is not a
corner solution. The model imposes testable restrictions on the behavior of
choice probabilities in markets with product entry.

</details>


### [198] [Waiting for Trade in Markets with Aggregate Uncertainty](https://arxiv.org/abs/2508.06132)
*Justus Preusser*

Main category: econ.TH

TL;DR: 研究一个市场中，长期卖家向短期买家提供价格，隐藏状态决定交易是否有效。卖家在有承诺能力时等待最有利信号的买家，否则退出市场。


<details>
  <summary>Details</summary>
Motivation: 探讨在信息不完全的市场中，卖家的定价和退出策略如何受隐藏状态和信号影响。

Method: 使用单调决策问题的技术，分析卖家等待策略的最优性。

Result: 卖家退出决策可能非单调，价格随时间非单调变化；无承诺能力时，卖家可能在无效时间退出。

Conclusion: 卖家策略受信息交互影响，承诺能力对市场效率至关重要。

Abstract: This paper studies a market in which a patient long-lived seller offers
prices to short-lived buyers. A hidden state determines whether the buyer's
common value exceeds the seller's reservation value, and all players only have
noisy signals. If the seller has commitment power, the seller waits for a buyer
with the most favorable signal to arrive, and else exits the market. Using
techniques for monotone decision problems, this waiting strategy is shown to be
optimal for learning whether trade is efficient. Due to the interplay between
the seller's and the buyers' information, the seller's decision to exit may be
non-monotonic in the seller's information, and prices may be non-monotonic over
time. Without commitment power, there is an equilibrium in which the seller
also waits for a buyer with the most favorable signal, but the seller exits at
inefficient times.

</details>
