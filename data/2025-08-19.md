<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 55]
- [cs.CL](#cs.CL) [Total: 81]
- [cs.CV](#cs.CV) [Total: 156]
- [cs.DB](#cs.DB) [Total: 5]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.NI](#cs.NI) [Total: 11]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 18]
- [econ.EM](#econ.EM) [Total: 8]
- [econ.GN](#econ.GN) [Total: 9]
- [econ.TH](#econ.TH) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Finite Automata Extraction: Low-data World Model Learning as Programs from Gameplay Video](https://arxiv.org/abs/2508.11836)
*Dave Goel,Matthew Guzdial,Anurag Sarkar*

Main category: cs.AI

TL;DR: 提出FAE方法从游戏视频中学习神经符号世界模型，用新的DSL语言Retro Coder表示，相比现有方法获得更精确的环境模型和更通用的代码


<details>
  <summary>Details</summary>
Motivation: 现有世界模型通常是神经网络表示，难以迁移学习到的环境动态和解释性，需要更好的可解释和可迁移的世界模型表示方法

Method: 提出有限自动机提取(FAE)方法，从游戏视频中学习神经符号世界模型，用新的领域特定语言Retro Coder表示为程序

Result: 相比现有世界模型方法，FAE学习了更精确的环境模型；相比现有DSL方法，生成了更通用的代码

Conclusion: FAE方法能够有效解决世界模型的可解释性和可迁移性问题，通过神经符号表示获得更好的性能

Abstract: World models are defined as a compressed spatial and temporal learned
representation of an environment. The learned representation is typically a
neural network, making transfer of the learned environment dynamics and
explainability a challenge. In this paper, we propose an approach, Finite
Automata Extraction (FAE), that learns a neuro-symbolic world model from
gameplay video represented as programs in a novel domain-specific language
(DSL): Retro Coder. Compared to prior world model approaches, FAE learns a more
precise model of the environment and more general code than prior DSL-based
approaches.

</details>


### [2] [EvoCut: Strengthening Integer Programs via Evolution-Guided Language Models](https://arxiv.org/abs/2508.11850)
*Milad Yazdani,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: EvoCut是一个自动化生成整数规划加速割的框架，结合大语言模型和进化搜索，无需人工专家输入即可显著提升求解器性能


<details>
  <summary>Details</summary>
Motivation: 整数规划是组合优化的核心但NP难问题，传统依赖专家手动设计加速割的方法效率低下且难以自动化

Method: 结合LLM初始化候选割集，通过进化搜索（交叉和变异）迭代优化，评估割的可行性和有效性（保持最优解、切割分数解）

Result: 在固定时间内将最优性间隙降低17-57%，求解速度提升4倍，相同时间内获得更高质量解

Conclusion: EvoCut成功实现了加速割的自动化生成，具有良好的泛化能力，为整数规划求解提供了新的有效工具

Abstract: Integer programming lies at the heart of crucial combinatorial optimization
tasks but remains challenging due to its NP-hard nature. An effective approach
for practically solving integer programs is the manual design of acceleration
cuts, i.e. inequalities that improve solver performance. However, this creative
process demands deep expertise and is yet to be automated. Our proposed
framework, EvoCut, automates the generation of acceleration cuts by combining
large language models (LLMs) with an evolutionary search. EvoCut (i)
initializes a diverse population of candidate cuts via an LLM-based initializer
agent; (ii) for each cut empirically evaluates both preservation of the optimal
solution and its ability to cut off fractional solutions across a verification
set; and (iii) iteratively refines the population through evolutionary
crossover and mutation agents. We quantify each cut's utility by its relative
reduction in the solver's optimality gap. Our comparisons against standard
integer programming practice show that EvoCut reduces optimality gap by 17-57%
within a fixed time. It obtains the same solutions up to 4 times as fast, and
obtains higher-quality solutions within the same time limit. Requiring no human
expert input, EvoCut reliably generates, improves, and empirically verifies
cuts that generalize to unseen instances. The code is available at
https://github.com/milad1378yz/EvoCut.

</details>


### [3] [LARC: Towards Human-level Constrained Retrosynthesis Planning through an Agentic Framework](https://arxiv.org/abs/2508.11860)
*Frazier N. Baker,Daniel Adu-Ampratwum,Reza Averly,Botao Yu,Huan Sun,Xia Ning*

Main category: cs.AI

TL;DR: LARC是首个基于LLM的约束性逆合成规划智能体框架，通过Agent-as-a-Judge机制将约束评估直接整合到逆合成规划过程中，使用工具驱动的智能体反馈来指导和约束路线生成。


<details>
  <summary>Details</summary>
Motivation: 约束性逆合成规划是化学中重要但具有挑战性的过程，需要从商业可得的起始材料到目标分子识别合成路线，同时满足实际约束条件。现有方法在有效处理多种约束方面存在不足。

Method: LARC框架采用智能体约束评估机制，通过Agent-as-a-Judge将工具驱动的推理反馈整合到逆合成规划过程中，指导路线生成并确保满足约束条件。

Result: 在48个约束性逆合成规划任务上，LARC达到72.9%的成功率，显著优于LLM基线方法，在更短时间内接近人类专家水平。

Conclusion: LARC框架具有可扩展性，是向有效智能体工具或人类专家协作者迈出的重要一步，为约束性逆合成规划提供了新的解决方案。

Abstract: Large language model (LLM) agent evaluators leverage specialized tools to
ground the rational decision-making of LLMs, making them well-suited to aid in
scientific discoveries, such as constrained retrosynthesis planning.
Constrained retrosynthesis planning is an essential, yet challenging, process
within chemistry for identifying synthetic routes from commercially available
starting materials to desired target molecules, subject to practical
constraints. Here, we present LARC, the first LLM-based Agentic framework for
Retrosynthesis planning under Constraints. LARC incorporates agentic constraint
evaluation, through an Agent-as-a-Judge, directly into the retrosynthesis
planning process, using agentic feedback grounded in tool-based reasoning to
guide and constrain route generation. We rigorously evaluate LARC on a
carefully curated set of 48 constrained retrosynthesis planning tasks across 3
constraint types. LARC achieves a 72.9% success rate on these tasks, vastly
outperforming LLM baselines and approaching human expert-level success in
substantially less time. The LARC framework is extensible, and serves as a
first step towards an effective agentic tool or a co-scientist to human experts
for constrained retrosynthesis.

</details>


### [4] [QuarkMed Medical Foundation Model Technical Report](https://arxiv.org/abs/2508.11894)
*Ao Li,Bin Yan,Bingfeng Cai,Chenxi Li,Cunzhong Zhao,Fugen Yao,Gaoqiang Liu,Guanjun Jiang,Jian Xu,Liang Dong,Liansheng Sun,Rongshen Zhang,Xiaolei Gui,Xin Liu,Xin Shang,Yao Wu,Yu Cao,Zhenxin Ma,Zhuang Jia*

Main category: cs.AI

TL;DR: QuarkMed是一个高性能医疗基础模型，通过医学数据处理、检索增强生成和强化学习管道开发，在中国执业医师考试中达到70%准确率，已服务数百万用户。


<details>
  <summary>Details</summary>
Motivation: 医疗任务需要高度专业化知识、专业准确性和定制能力，现有大语言模型在医疗应用中需要更可靠的基础模型支持。

Method: 利用精选医学数据处理、医学内容检索增强生成(RAG)和大规模可验证强化学习管道来开发医疗基础模型。

Result: 在中国医学执业资格考试中达到70%准确率，在多样化医疗基准测试中展现出强大的泛化能力。

Conclusion: QuarkMed提供了一个强大而多功能的个人医疗AI解决方案，已在ai.quark.cn平台上服务超过百万用户。

Abstract: Recent advancements in large language models have significantly accelerated
their adoption in healthcare applications, including AI-powered medical
consultations, diagnostic report assistance, and medical search tools. However,
medical tasks often demand highly specialized knowledge, professional accuracy,
and customization capabilities, necessitating a robust and reliable foundation
model. QuarkMed addresses these needs by leveraging curated medical data
processing, medical-content Retrieval-Augmented Generation (RAG), and a
large-scale, verifiable reinforcement learning pipeline to develop a
high-performance medical foundation model. The model achieved 70% accuracy on
the Chinese Medical Licensing Examination, demonstrating strong generalization
across diverse medical benchmarks. QuarkMed offers a powerful yet versatile
personal medical AI solution, already serving over millions of users at
ai.quark.cn.

</details>


### [5] [CHBench: A Cognitive Hierarchy Benchmark for Evaluating Strategic Reasoning Capability of LLMs](https://arxiv.org/abs/2508.11944)
*Hongtao Liu,Zhicheng Du,Zihe Wang,Weiran Shen*

Main category: cs.AI

TL;DR: 提出了CHBench评估框架，基于认知层次理论评估LLM的战略推理能力，发现聊天机制会降低推理能力而记忆机制会增强


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖效用性能指标评估LLM的游戏能力，但这些指标不够稳健，受对手行为和游戏结构变化影响较大

Method: 采用三阶段系统框架，基于行为经济学中的认知层次模型，在15个精选的正规形式游戏中评估6个最先进LLM的行为数据

Result: LLM在不同对手间展现出一致的战略推理水平，聊天机制显著降低战略推理能力，而记忆机制则增强推理能力

Conclusion: CHBench是一个有前景的LLM能力评估工具，具有重要的研究价值和实际应用潜力

Abstract: Game-playing ability serves as an indicator for evaluating the strategic
reasoning capability of large language models (LLMs). While most existing
studies rely on utility performance metrics, which are not robust enough due to
variations in opponent behavior and game structure. To address this limitation,
we propose \textbf{Cognitive Hierarchy Benchmark (CHBench)}, a novel evaluation
framework inspired by the cognitive hierarchy models from behavioral economics.
We hypothesize that agents have bounded rationality -- different agents behave
at varying reasoning depths/levels. We evaluate LLMs' strategic reasoning
through a three-phase systematic framework, utilizing behavioral data from six
state-of-the-art LLMs across fifteen carefully selected normal-form games.
Experiments show that LLMs exhibit consistent strategic reasoning levels across
diverse opponents, confirming the framework's robustness and generalization
capability. We also analyze the effects of two key mechanisms (Chat Mechanism
and Memory Mechanism) on strategic reasoning performance. Results indicate that
the Chat Mechanism significantly degrades strategic reasoning, whereas the
Memory Mechanism enhances it. These insights position CHBench as a promising
tool for evaluating LLM capabilities, with significant potential for future
research and practical applications.

</details>


### [6] [Data Mixing Optimization for Supervised Fine-Tuning of Large Language Models](https://arxiv.org/abs/2508.11953)
*Yuan Li,Zhengzhong Liu,Eric Xing*

Main category: cs.AI

TL;DR: 通过建模有效数据转移和利用缩放定律来优化SFT数据混合配置，该方法能够实现接近网格搜索的最优性能


<details>
  <summary>Details</summary>
Motivation: 目前在为大语言模型进行监督精调时，数据混合优化问题很少被深入研究，而这对发展通用模型至关重要

Method: 将数据混合形式化为优化问题，通过建模有效数据转移和缩放定律来参数化损失函数，基于小规模实验拟合参数并求解最优权重

Result: 算法在所有领域都取得了优异的整体和个别性能，基于优化权重训练的模型性能与网格搜索最优权重相当，均值域损失仅高出0.66%，重新权重调整流行SFT数据集后验证损失和下游性能都得到了提升

Conclusion: 该方法不仅能够有效优化SFT数据混合，还可以扩展到指导领域特定模型的数据选择，为SFT过程提供了深入的见解

Abstract: Optimizing data mixtures for supervised fine-tuning (SFT) of large language
models (LLMs) is critical for developing general-purpose models, yet this area
remains underexplored. In this paper, we frame data mixing as an optimization
problem and introduce a novel method designed to minimize validation loss. Our
approach parametrizes the loss by modeling effective data transferred and
leveraging scaling laws for fine-tuning. By experimenting with various
small-scale data mixtures, we fit these parameters and derive the optimal
weights. We provide both mathematical proofs and empirical results
demonstrating that our algorithm achieves excellent overall and individual
performance across all domains. Through controlled experiments, we show that
models trained with our optimized weights perform on par with those using
optimal weights determined via grid search, with per-domain loss only 0.66%
higher than the best domain loss from grid search on average. Additionally, we
show that reweighting popular SFT datasets using our method improves both
validation loss and downstream performance. Finally, we discuss how our method
can generalize to guide data selection for domain-specific models and provide
insights into SFT.

</details>


### [7] [UniCast: A Unified Multimodal Prompting Framework for Time Series Forecasting](https://arxiv.org/abs/2508.11954)
*Sehyuk Park,Soyeon Caren Han,Eduard Hovy*

Main category: cs.AI

TL;DR: UniCast是一个参数高效的多模态时间序列预测框架，通过整合视觉和文本模态信息来增强传统时间序列基础模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列基础模型主要在单模态设置下运行，忽略了现实场景中常伴随时间序列数据的丰富多模态上下文（如视觉和文本信号）。

Method: 通过软提示调优将预训练的视觉和文本编码器的模态特定嵌入与冻结的时间序列基础模型集成，实现最小参数更新的高效适配。

Result: 在多个时间序列预测基准测试中，UniCast始终显著优于所有现有的时间序列基础模型基线。

Conclusion: 多模态上下文在推动下一代通用时间序列预测器发展中起着关键作用。

Abstract: Time series forecasting is a foundational task across domains, such as
finance, healthcare, and environmental monitoring. While recent advances in
Time Series Foundation Models (TSFMs) have demonstrated strong generalisation
through large-scale pretraining, existing models operate predominantly in a
unimodal setting, ignoring the rich multimodal context, such as visual and
textual signals, that often accompanies time series data in real-world
scenarios. This paper introduces a novel parameter-efficient multimodal
framework, UniCast, that extends TSFMs to jointly leverage time series, vision,
and text modalities for enhanced forecasting performance. Our method integrates
modality-specific embeddings from pretrained Vision and Text Encoders with a
frozen TSFM via soft prompt tuning, enabling efficient adaptation with minimal
parameter updates. This design not only preserves the generalisation strength
of the foundation model but also enables effective cross-modal interaction.
Extensive experiments across diverse time-series forecasting benchmarks
demonstrate that UniCast consistently and significantly outperforms all
existing TSFM baselines. The findings highlight the critical role of multimodal
context in advancing the next generation of general-purpose time series
forecasters.

</details>


### [8] [Rigorous Feature Importance Scores based on Shapley Value and Banzhaf Index](https://arxiv.org/abs/2508.11959)
*Xuanxiang Huang,Olivier Létoffé,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出了两种基于Shapley值和Banzhaf指数的新型特征重要性评分方法，通过考虑非弱溯因解释集来量化特征在排除对抗样本方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于博弈论的特征归因方法主要关注弱溯因解释(WAXp)集，但忽略了非WAXp集的重要信息，而这些集与对抗样本(AExs)密切相关。

Method: 利用Shapley值和Banzhaf指数设计两种新的特征重要性评分，在计算特征贡献时考虑非WAXp集，量化每个特征排除对抗样本的有效性。

Result: 提出了新的特征重要性评分方法，能够更全面地评估特征贡献，并分析了这些评分方法的性质和计算复杂度。

Conclusion: 通过考虑非WAXp集，新的特征重要性评分方法提供了更全面的特征归因分析，特别是在对抗样本排除方面的有效性评估。

Abstract: Feature attribution methods based on game theory are ubiquitous in the field
of eXplainable Artificial Intelligence (XAI). Recent works proposed rigorous
feature attribution using logic-based explanations, specifically targeting
high-stakes uses of machine learning (ML) models. Typically, such works exploit
weak abductive explanation (WAXp) as the characteristic function to assign
importance to features. However, one possible downside is that the contribution
of non-WAXp sets is neglected. In fact, non-WAXp sets can also convey important
information, because of the relationship between formal explanations (XPs) and
adversarial examples (AExs). Accordingly, this paper leverages Shapley value
and Banzhaf index to devise two novel feature importance scores. We take into
account non-WAXp sets when computing feature contribution, and the novel scores
quantify how effective each feature is at excluding AExs. Furthermore, the
paper identifies properties and studies the computational complexity of the
proposed scores.

</details>


### [9] [Chart-CoCa: Self-Improving Chart Understanding of Vision LMs via Code-Driven Synthesis and Candidate-Conditioned Answering](https://arxiv.org/abs/2508.11975)
*Gongyao Jiang,Qiong Luo*

Main category: cs.AI

TL;DR: 通过代码生成和执行的图表合成流程生成对齐的图表-问题-答案三元组，结合候选条件化答题过程，在无人工标注或外部模型的情况下实现VLM的自我改进


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型(VLM)在图表理解任务中的困难，特别是准确的图表描述和复杂推理能力，同时充分利用合成数据生成的潜力但避免噪声标签的问题

Method: 首先设计了一个通过代码生成和执行的图表合成流程，生成对齐的图表-问题-答案三元组；其次受测试时扩展的启发，设计了候选条件化答题过程，让VLM先生成多个回应，然后通过上下文化这些候选来合成最终答案

Result: 实验结果显示了显著改进，在完全自我改进范式下(无人工标注数据或外部模型)，比初始VLM获得了超过15.50个百分点的准确性提升

Conclusion: 该方法通过可靠的合成数据生成和候选条件化答题机制，有效解决了VLM在图表理解任务中的挑战，实现了在无外部资源的情况下的自我改进和性能提升

Abstract: Vision Language Models (VLMs) often struggle with chart understanding tasks,
particularly in accurate chart description and complex reasoning. Synthetic
data generation is a promising solution, while usually facing the challenge of
noise labels. To address this challenge, we first introduce a chart synthesis
pipeline that generates aligned chart-question-answer triplets through code
generation and execution, ensuring the reliability of synthetic data without
human intervention. Furthermore, inspired by test-time scaling that increases
inference budget and thereby improves performance, we design a
candidate-conditioned answering process. The VLM first generates multiple
responses per query, and then synthesizes the final answer by contextualizing
these candidates. Experiments demonstrate significant improvements, with up to
15.50 points accuracy gain over the initial VLM, in a fully self-improving
paradigm without either human-labeled data or external models.

</details>


### [10] [FutureX: An Advanced Live Benchmark for LLM Agents in Future Prediction](https://arxiv.org/abs/2508.11987)
*Zhiyuan Zeng,Jiashuo Liu,Siyuan Chen,Tianci He,Yali Liao,Jinpeng Wang,Zaiyuan Wang,Yang Yang,Lingyue Yin,Mingren Yin,Zhenwei Zhu,Tianle Cai,Zehui Chen,Jiecao Chen,Yantao Du,Xiang Gao,Jiacheng Guo,Liang Hu,Jianpeng Jiao,Xiangsheng Li,Jingkai Liu,Shuang Ni,Zhoufutu Wen,Ge Zhang,Kaiyuan Zhang,Xin Zhou,Jose Blanchet,Xipeng Qiu,Mengdi Wang,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX是一个专为LLM智能体设计的动态实时未来预测评估基准，支持每日实时更新，通过自动化流程避免数据污染，评估了25个模型在动态环境中的自适应推理能力。


<details>
  <summary>Details</summary>
Motivation: 未来预测对LLM智能体是复杂任务，需要高水平分析思维和信息处理能力，但目前缺乏大规模评估基准，主要由于处理实时更新和获取及时准确答案的挑战。

Method: 构建FutureX动态实时评估基准，支持每日实时更新，采用自动化问题收集和答案收集流程，评估25个LLM/智能体模型，包括具有推理、搜索能力和外部工具集成的模型。

Result: 建立了最大最多样化的实时未来预测基准，提供了对智能体在面向未来任务中失败模式和性能缺陷的深入分析，包括对虚假网页和时间有效性的脆弱性。

Conclusion: 目标是建立一个动态、无污染的评估标准，推动LLM智能体在复杂推理和预测思维方面达到专业人类分析师水平的发展。

Abstract: Future prediction is a complex task for LLM agents, requiring a high level of
analytical thinking, information gathering, contextual understanding, and
decision-making under uncertainty. Agents must not only gather and interpret
vast amounts of dynamic information but also integrate diverse data sources,
weigh uncertainties, and adapt predictions based on emerging trends, just as
human experts do in fields like politics, economics, and finance. Despite its
importance, no large-scale benchmark exists for evaluating agents on future
prediction, largely due to challenges in handling real-time updates and
retrieving timely, accurate answers. To address this, we introduce
$\textbf{FutureX}$, a dynamic and live evaluation benchmark specifically
designed for LLM agents performing future prediction tasks. FutureX is the
largest and most diverse live benchmark for future prediction, supporting
real-time daily updates and eliminating data contamination through an automated
pipeline for question gathering and answer collection. We evaluate 25 LLM/agent
models, including those with reasoning, search capabilities, and integration of
external tools such as the open-source Deep Research Agent and closed-source
Deep Research models. This comprehensive evaluation assesses agents' adaptive
reasoning and performance in dynamic environments. Additionally, we provide
in-depth analyses of agents' failure modes and performance pitfalls in
future-oriented tasks, including the vulnerability to fake web pages and the
temporal validity. Our goal is to establish a dynamic, contamination-free
evaluation standard that drives the development of LLM agents capable of
performing at the level of professional human analysts in complex reasoning and
predictive thinking.

</details>


### [11] [Modeling Relational Logic Circuits for And-Inverter Graph Convolutional Network](https://arxiv.org/abs/2508.11991)
*Weihao Sun*

Main category: cs.AI

TL;DR: AIGer是一个用于AIG图表示学习的创新模型，通过节点逻辑特征初始化和异构图卷积网络，有效联合建模功能与结构特征，在信号概率预测和真值表距离预测任务上显著优于现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在真实世界AIG图中因复杂结构和节点规模大而难以准确建模的问题，特别是缺乏功能与结构特征联合建模能力以及动态信息传播能力不足的挑战。

Method: 提出AIGer模型，包含两个组件：1)节点逻辑特征初始化嵌入组件，将逻辑节点投影到独立语义空间；2)AIGs特征学习网络组件，使用异构图卷积网络设计动态关系权重矩阵和差异化信息聚合方法。

Result: 在信号概率预测(SSP)任务中，MAE和MSE分别提升18.95%和44.44%；在真值表距离预测(TTDP)任务中，MAE和MSE分别提升33.57%和14.79%，均显著优于当前最佳模型。

Conclusion: AIGer通过创新的节点嵌入和异构图学习方法，成功解决了AIG图建模中的关键挑战，在EDA领域的两个重要任务上取得了显著性能提升，证明了其在逻辑电路设计自动化中的有效性。

Abstract: The automation of logic circuit design enhances chip performance, energy
efficiency, and reliability, and is widely applied in the field of Electronic
Design Automation (EDA).And-Inverter Graphs (AIGs) efficiently represent,
optimize, and verify the functional characteristics of digital circuits,
enhancing the efficiency of EDA development.Due to the complex structure and
large scale of nodes in real-world AIGs, accurate modeling is challenging,
leading to existing work lacking the ability to jointly model functional and
structural characteristics, as well as insufficient dynamic information
propagation capability.To address the aforementioned challenges, we propose
AIGer.Specifically, AIGer consists of two components: 1) Node logic feature
initialization embedding component and 2) AIGs feature learning network
component.The node logic feature initialization embedding component projects
logic nodes, such as AND and NOT, into independent semantic spaces, to enable
effective node embedding for subsequent processing.Building upon this, the AIGs
feature learning network component employs a heterogeneous graph convolutional
network, designing dynamic relationship weight matrices and differentiated
information aggregation approaches to better represent the original structure
and information of AIGs.The combination of these two components enhances
AIGer's ability to jointly model functional and structural characteristics and
improves its message passing capability. Experimental results indicate that
AIGer outperforms the current best models in the Signal Probability Prediction
(SSP) task, improving MAE and MSE by 18.95\% and 44.44\%, respectively. In the
Truth Table Distance Prediction (TTDP) task, AIGer achieves improvements of
33.57\% and 14.79\% in MAE and MSE, respectively, compared to the
best-performing models.

</details>


### [12] [AgentCDM: Enhancing Multi-Agent Collaborative Decision-Making via ACH-Inspired Structured Reasoning](https://arxiv.org/abs/2508.11995)
*Xuyang Zhao,Shiwan Zhao,Hualong Yu,Liting Zhang,Qicheng Li*

Main category: cs.AI

TL;DR: AgentCDM是一个基于大语言模型的多智能体系统协作决策框架，通过结构化推理范式来缓解认知偏见，提升决策质量


<details>
  <summary>Details</summary>
Motivation: 现有多智能体系统协作决策方法存在缺陷：要么依赖单一智能体的"独裁"策略容易受认知偏见影响，要么使用"投票"方法无法充分利用集体智慧

Method: 借鉴认知科学中的竞争假设分析(ACH)方法，提出结构化推理范式；采用两阶段训练：第一阶段使用显式ACH脚手架指导结构化推理，第二阶段逐步移除脚手架以促进自主泛化

Result: 在多个基准数据集上的实验表明，AgentCDM达到了最先进的性能，并展现出强大的泛化能力

Conclusion: AgentCDM有效提升了多智能体系统中协作决策的质量和鲁棒性，验证了其结构化推理方法的有效性

Abstract: Multi-agent systems (MAS) powered by large language models (LLMs) hold
significant promise for solving complex decision-making tasks. However, the
core process of collaborative decision-making (CDM) within these systems
remains underexplored. Existing approaches often rely on either ``dictatorial"
strategies that are vulnerable to the cognitive biases of a single agent, or
``voting-based" methods that fail to fully harness collective intelligence. To
address these limitations, we propose \textbf{AgentCDM}, a structured framework
for enhancing collaborative decision-making in LLM-based multi-agent systems.
Drawing inspiration from the Analysis of Competing Hypotheses (ACH) in
cognitive science, AgentCDM introduces a structured reasoning paradigm that
systematically mitigates cognitive biases and shifts decision-making from
passive answer selection to active hypothesis evaluation and construction. To
internalize this reasoning process, we develop a two-stage training paradigm:
the first stage uses explicit ACH-inspired scaffolding to guide the model
through structured reasoning, while the second stage progressively removes this
scaffolding to encourage autonomous generalization. Experiments on multiple
benchmark datasets demonstrate that AgentCDM achieves state-of-the-art
performance and exhibits strong generalization, validating its effectiveness in
improving the quality and robustness of collaborative decisions in MAS.

</details>


### [13] [AI Models for Depressive Disorder Detection and Diagnosis: A Review](https://arxiv.org/abs/2508.12022)
*Dorsa Macky Aleagha,Payam Zohari,Mostafa Haghir Chehreghani*

Main category: cs.AI

TL;DR: 这篇论文系统调查了AI在抑郁症诊断中的应用，提出了新的分类法，并分析了图神经网络、大语言模型和多模态融合等主要趋势。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是全球主要残疾原因之一，但诊断依然依赖主观临床评估。AI技术有望开发客观、可扩展的及及时诊断工具。

Method: 通过系统评审55项关键研究，提出了一种新的层次分类法，按临床任务（诊断vs预测）、数据模态（文本、语音、脑成像、多模态）和计算模型类别进行结构化。

Result: 深入分析揭示了三大趋势：图神经网络在建模脑网络连接性方面占主导地位，大语言模型在语言和对话数据中的兴起，以及多模态融合、可解释性和算法公平性方面的新兴关注点。

Conclusion: 该调查通过综合当前进展并突出开放性挑战，为计算精神病学领域的未来创新提供了全面的路线图。

Abstract: Major Depressive Disorder is one of the leading causes of disability
worldwide, yet its diagnosis still depends largely on subjective clinical
assessments. Integrating Artificial Intelligence (AI) holds promise for
developing objective, scalable, and timely diagnostic tools. In this paper, we
present a comprehensive survey of state-of-the-art AI methods for depression
detection and diagnosis, based on a systematic review of 55 key studies. We
introduce a novel hierarchical taxonomy that structures the field by primary
clinical task (diagnosis vs. prediction), data modality (text, speech,
neuroimaging, multimodal), and computational model class (e.g., graph neural
networks, large language models, hybrid approaches). Our in-depth analysis
reveals three major trends: the predominance of graph neural networks for
modeling brain connectivity, the rise of large language models for linguistic
and conversational data, and an emerging focus on multimodal fusion,
explainability, and algorithmic fairness. Alongside methodological insights, we
provide an overview of prominent public datasets and standard evaluation
metrics as a practical guide for researchers. By synthesizing current advances
and highlighting open challenges, this survey offers a comprehensive roadmap
for future innovation in computational psychiatry.

</details>


### [14] [Bongard-RWR+: Real-World Representations of Fine-Grained Concepts in Bongard Problems](https://arxiv.org/abs/2508.12026)
*Szymon Pawlonka,Mikołaj Małkiński,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 本文提出了Bongard-RWR+数据集，包含5400个实例，使用VLM生成真实世界图像来表示原始Bongard问题的抽象概念，评估发现VLM在细粒度概念识别上存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有Bongard问题数据集要么使用合成图像不能完全反映真实世界复杂性，要么使用真实图像但概念过于简单，且Bongard-RWR数据集规模太小（仅60个实例），限制了评估的鲁棒性。

Method: 基于Bongard-RWR，使用Pixtral-12B描述手动策划的图像并生成与底层概念对齐的新描述，使用Flux.1-dev从这些描述合成图像，并手动验证生成图像是否忠实反映预期概念。

Result: 评估了最先进的VLM在多种Bongard问题表述上的表现，包括二元和多类分类以及文本答案生成。发现VLM能够识别粗粒度视觉概念，但在辨别细粒度概念方面持续存在困难。

Conclusion: VLM在抽象视觉推理任务中，特别是细粒度概念识别方面存在局限性，突显了其推理能力的不足。

Abstract: Bongard Problems (BPs) provide a challenging testbed for abstract visual
reasoning (AVR), requiring models to identify visual concepts fromjust a few
examples and describe them in natural language. Early BP benchmarks featured
synthetic black-and-white drawings, which might not fully capture the
complexity of real-world scenes. Subsequent BP datasets employed real-world
images, albeit the represented concepts are identifiable from high-level image
features, reducing the task complexity. Differently, the recently released
Bongard-RWR dataset aimed at representing abstract concepts formulated in the
original BPs using fine-grained real-world images. Its manual construction,
however, limited the dataset size to just $60$ instances, constraining
evaluation robustness. In this work, we introduce Bongard-RWR+, a BP dataset
composed of $5\,400$ instances that represent original BP abstract concepts
using real-world-like images generated via a vision language model (VLM)
pipeline. Building on Bongard-RWR, we employ Pixtral-12B to describe manually
curated images and generate new descriptions aligned with the underlying
concepts, use Flux.1-dev to synthesize images from these descriptions, and
manually verify that the generated images faithfully reflect the intended
concepts. We evaluate state-of-the-art VLMs across diverse BP formulations,
including binary and multiclass classification, as well as textual answer
generation. Our findings reveal that while VLMs can recognize coarse-grained
visual concepts, they consistently struggle with discerning fine-grained
concepts, highlighting limitations in their reasoning capabilities.

</details>


### [15] [Active inference for action-unaware agents](https://arxiv.org/abs/2508.12027)
*Filippo Torresan,Keisuke Suzuki,Ryota Kanai,Manuel Baltieri*

Main category: cs.AI

TL;DR: 主动推断框架中动作意识与无意识代理者的性能对比研究，证明即使在动作知识缺乏的情况下，无意识代理者仍能达到类似于有意识代理者的完美表现


<details>
  <summary>Details</summary>
Motivation: 研究主动推断框架中不同行动规划策略的效果，特别是在动作意识（action-aware）与动作无意识（action-unaware）代理者之间的性能差异，以涵盖运动控制领域中关于出动副本信号存在性的标准分歧点

Method: 通过在两个导航任务中比较动作意识代理者和动作无意识代理者的表现，使用变分自由能和预期自由能的最小化来实现近似贝叶斯推断

Result: 研究显示动作无意识代理者虽然处于严重不利地位，但仍能够达到与动作意识代理者相可比的完美表现

Conclusion: 这项工作证明了在主动推断框架下，即使缺乏自身动作知识，代理者仍能通过从最近观测中推断运动行为来有效地规划未来行动，为运动控制理论提供了重要见解

Abstract: Active inference is a formal approach to study cognition based on the notion
that adaptive agents can be seen as engaging in a process of approximate
Bayesian inference, via the minimisation of variational and expected free
energies. Minimising the former provides an account of perceptual processes and
learning as evidence accumulation, while minimising the latter describes how
agents select their actions over time. In this way, adaptive agents are able to
maximise the likelihood of preferred observations or states, given a generative
model of the environment. In the literature, however, different strategies have
been proposed to describe how agents can plan their future actions. While they
all share the notion that some kind of expected free energy offers an
appropriate way to score policies, sequences of actions, in terms of their
desirability, there are different ways to consider the contribution of past
motor experience to the agent's future behaviour. In some approaches, agents
are assumed to know their own actions, and use such knowledge to better plan
for the future. In other approaches, agents are unaware of their actions, and
must infer their motor behaviour from recent observations in order to plan for
the future. This difference reflects a standard point of departure in two
leading frameworks in motor control based on the presence, or not, of an
efference copy signal representing knowledge about an agent's own actions. In
this work we compare the performances of action-aware and action-unaware agents
in two navigations tasks, showing how action-unaware agents can achieve
performances comparable to action-aware ones while at a severe disadvantage.

</details>


### [16] [Exploring Autonomous Agents: A Closer Look at Why They Fail When Completing Tasks](https://arxiv.org/abs/2508.13143)
*Ruofan Lu,Yichen Li,Yintong Huo*

Main category: cs.AI

TL;DR: 这篇论文提出了一个新的自主组织系统评测标准，通过对三个开源框架的评测发现任务完成率仅50%，并提出了一个三级失败分类法来分析和改进系统性能。


<details>
  <summary>Details</summary>
Motivation: 目前对基于大语言模型的自主组织系统评价主要依靠成功率，缺乏对系统交互、通信机制和失败原因的系统分析。

Method: 设计了34个代表性的可编程任务作为标准，评估了三个流行开源框架搭配两个LLM核心，并进行深度失败分析。

Result: 观察到任务完成率约50%，开发了一个与任务阶段对应的三级失败分类法：规划错误、任务执行问题和错误响应生成。

Conclusion: 研究提供了实证基础，通过提出可行动的改进建议，为开发更稳健和高效的自主组织系统提供了指导。

Abstract: Autonomous agent systems powered by Large Language Models (LLMs) have
demonstrated promising capabilities in automating complex tasks. However,
current evaluations largely rely on success rates without systematically
analyzing the interactions, communication mechanisms, and failure causes within
these systems. To bridge this gap, we present a benchmark of 34 representative
programmable tasks designed to rigorously assess autonomous agents. Using this
benchmark, we evaluate three popular open-source agent frameworks combined with
two LLM backbones, observing a task completion rate of approximately 50%.
Through in-depth failure analysis, we develop a three-tier taxonomy of failure
causes aligned with task phases, highlighting planning errors, task execution
issues, and incorrect response generation. Based on these insights, we propose
actionable improvements to enhance agent planning and self-diagnosis
capabilities. Our failure taxonomy, together with mitigation advice, provides
an empirical foundation for developing more robust and effective autonomous
agent systems in the future.

</details>


### [17] [MAPF-World: Action World Model for Multi-Agent Path Finding](https://arxiv.org/abs/2508.12087)
*Zhanjiang Yang,Meng Li,Yang Shen,Yueming Li,Lijun Sun*

Main category: cs.AI

TL;DR: MAPF-World是一个用于多智能体路径规划的自动回归动作世界模型，通过统一情境理解和动作生成，在复杂环境中实现更远见的决策，模型大小减少96.5%，数据需求减少92%。


<details>
  <summary>Details</summary>
Motivation: 现有分散式可学习求解器在复杂长期规划场景中表现受限，缺乏对环境时间动态和智能体间依赖关系的建模，导致性能下降。

Method: 提出MAPF-World自动回归动作世界模型，通过未来状态和动作预测显式建模环境动态（空间特征和时间依赖），统一情境理解和动作生成。

Result: MAPF-World在零样本泛化到分布外案例方面优于最先进的可学习求解器，模型大小减少96.5%，数据需求减少92%。

Conclusion: MAPF-World通过建模环境动态和未来预测，在多智能体路径规划中实现了更明智、协调和远见的决策，显著提升了复杂场景下的性能。

Abstract: Multi-agent path finding (MAPF) is the problem of planning conflict-free
paths from the designated start locations to goal positions for multiple
agents. It underlies a variety of real-world tasks, including multi-robot
coordination, robot-assisted logistics, and social navigation. Recent
decentralized learnable solvers have shown great promise for large-scale MAPF,
especially when leveraging foundation models and large datasets. However, these
agents are reactive policy models and exhibit limited modeling of environmental
temporal dynamics and inter-agent dependencies, resulting in performance
degradation in complex, long-term planning scenarios. To address these
limitations, we propose MAPF-World, an autoregressive action world model for
MAPF that unifies situation understanding and action generation, guiding
decisions beyond immediate local observations. It improves situational
awareness by explicitly modeling environmental dynamics, including spatial
features and temporal dependencies, through future state and actions
prediction. By incorporating these predicted futures, MAPF-World enables more
informed, coordinated, and far-sighted decision-making, especially in complex
multi-agent settings. Furthermore, we augment MAPF benchmarks by introducing an
automatic map generator grounded in real-world scenarios, capturing practical
map layouts for training and evaluating MAPF solvers. Extensive experiments
demonstrate that MAPF-World outperforms state-of-the-art learnable solvers,
showcasing superior zero-shot generalization to out-of-distribution cases.
Notably, MAPF-World is trained with a 96.5% smaller model size and 92% reduced
data.

</details>


### [18] [Overcoming Knowledge Discrepancies: Structuring Reasoning Threads through Knowledge Balancing in Interactive Scenarios](https://arxiv.org/abs/2508.12100)
*Daniel Burkhardt,Xiangwei Cheng*

Main category: cs.AI

TL;DR: 这篇论文提出了ReT-Eval框架，通过图神经网络提取知识和奖励指导的剪枝策略，生成更有效的推理线程，提升了用户理解和推理效果。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型缺乏明确的语义层次结构、用户-域知识对齐机制和原理性的推理线程剪枝方法，导致输出长缠通用且无法有效指导用户进行目标导向的推理。

Method: 提出了双阶段的ReT-Eval框架：第一阶段使用图神经网络从稀疏域知识图中提取语义相关知识结构，并利用大语言模型内部知识来解决知识差异；第二阶段采用奖励指导的策略对推理线程进行评估和剪枝，以维持语义一致性。

Result: 实验和专家评估显示，ReT-Eval框架能够显著提升用户理解能力，并在性能上超过了当前最先进的推理模型。

Conclusion: ReT-Eval框架通过结构化知识重用和有原则的推理线程处理机制，有效解决了交互式问题求解中的推理效果问题，为构建更有效的推理模型提供了新的视角。

Abstract: Reasoning in interactive problem solving scenarios requires models to
construct reasoning threads that reflect user understanding and align with
structured domain knowledge. However, current reasoning models often lack
explicit semantic hierarchies, user-domain knowledge alignment, and principled
mechanisms to prune reasoning threads for effectiveness. These limitations
result in lengthy generic output that does not guide users through
goal-oriented reasoning steps. To address this, we propose a
prototype-inspired, two-phases Reasoning-Threads-Evaluation (ReT-Eval)
framework, drawing inspiration from human-like reasoning strategies that
emphasize structured knowledge reuse. In the first phase, semantically relevant
knowledge structures are extracted from a sparse domain knowledge graph using a
graph neural network and enriched with intrinsic large language model knowledge
to resolve knowledge discrepancies. In the second phase, these threads are
evaluated and pruned using a reward-guided strategy aimed at maintaining
semantic coherence to generate effective reasoning threads. Experiments and
expert evaluations show that ReT-Eval enhances user understanding and
outperforms state-of-the-art reasoning models.

</details>


### [19] [MOVER: Multimodal Optimal Transport with Volume-based Embedding Regularization](https://arxiv.org/abs/2508.12149)
*Haochen You,Baojing Liu*

Main category: cs.AI

TL;DR: MOVER是一个多模态学习框架，通过最优传输软对齐和几何体积正则化，在共享嵌入空间中构建语义对齐的结构化多模态表示，在文本-视频-音频检索任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法主要依赖成对对比目标来对齐不同模态，但在多模态设置中泛化能力有限，且在高维空间中缺乏语义结构。

Method: 结合最优传输软对齐和基于体积的几何正则化（GAVE），通过传输引导的匹配机制和几何体积最小化目标，以模态无关的方式实现所有模态的一致对齐。

Result: 在文本-视频-音频检索任务中，MOVER在零样本和微调设置下均显著优于现有最先进方法，展现出对未见模态组合的更好泛化能力和更强的嵌入空间结构一致性。

Conclusion: MOVER框架通过整合最优传输和几何正则化，成功解决了多模态对齐中的语义结构和泛化问题，为多模态表示学习提供了有效解决方案。

Abstract: Recent advances in multimodal learning have largely relied on pairwise
contrastive objectives to align different modalities, such as text, video, and
audio, in a shared embedding space. While effective in bi-modal setups, these
approaches struggle to generalize across multiple modalities and often lack
semantic structure in high-dimensional spaces. In this paper, we propose MOVER,
a novel framework that combines optimal transport-based soft alignment with
volume-based geometric regularization to build semantically aligned and
structured multimodal representations. By integrating a transport-guided
matching mechanism with a geometric volume minimization objective (GAVE), MOVER
encourages consistent alignment across all modalities in a modality-agnostic
manner. Experiments on text-video-audio retrieval tasks demonstrate that MOVER
significantly outperforms prior state-of-the-art methods in both zero-shot and
finetuned settings. Additional analysis shows improved generalization to unseen
modality combinations and stronger structural consistency in the learned
embedding space.

</details>


### [20] [RLNVR: Reinforcement Learning from Non-Verified Real-World Rewards](https://arxiv.org/abs/2508.12165)
*Rohit Krishnan,Jon Evans*

Main category: cs.AI

TL;DR: RLNVR框架使用非验证奖励训练语言模型，通过基线归一化和语义相似性奖励转移处理噪声反馈，在社交媒体内容生成中展现显著改进


<details>
  <summary>Details</summary>
Motivation: 传统RLHF需要昂贵的验证奖励信号，在现实场景中不实用，需要处理噪声、非验证的现实世界反馈

Method: 结合基线归一化、语义相似性奖励转移、GSPO策略优化和可选UED课程学习，从隐式社交参与数据中训练

Result: 在Bluesky社交媒体内容生成中显示出内容质量和训练稳定性的显著提升

Conclusion: 提出了实用的RLNVR框架，成功整合现有技术处理非验证奖励，为现实世界应用提供了可行方案

Abstract: This paper introduces RLNVR (Reinforcement Learning from Non-Verified
Rewards), a framework for training language models using noisy, real-world
feedback signals without requiring explicit human verification. Traditional
RLHF requires expensive, verified reward signals that are impractical in many
real-world domains. RLNVR addresses this challenge through baseline
normalization and semantic similarity-based reward transfer. We demonstrate
RLNVR through Walter, a prototype system that optimizes social media content
generation using actual engagement data from Bluesky. Our experimental results
show significant improvements in content quality and training stability, with
comprehensive evaluation planned for future work. Positioning: We present a
practical framework that combines RLNVR with GSPO (Group Sequence Policy
Optimization) and an optional UED (Unsupervised Environment Design) curriculum
to improve stability and diversity under noisy, implicit rewards. To our
knowledge, combining GSPO-style normalization with a UED-style curriculum for
LLM content generation from implicit social engagement has not been previously
documented in this applied setting; we frame this as an applied integration
rather than a new algorithm.

</details>


### [21] [Mantis: A Simulation-Grounded Foundation Model for Disease Forecasting](https://arxiv.org/abs/2508.12260)
*Carson Dudley,Reiden Magdaleno,Christopher Harding,Ananya Sharma,Emily Martin,Marisa Eisenberg*

Main category: cs.AI

TL;DR: Mantis是一个基于机制模拟训练的传染病预测基础模型，无需真实数据训练就能在多种疾病和场景中实现开箱即用的准确预测，性能超越39个专家调优模型。


<details>
  <summary>Details</summary>
Motivation: 传统传染病预测模型需要疾病特定数据、定制化训练和专家调优，在新发疫情或资源匮乏地区应用受限，需要开发通用性强、无需真实数据训练的基础预测模型。

Method: 基于超过4亿天爆发动态的机制模拟数据进行训练，涵盖多种病原体、传播模式、干预措施和监测伪影，完全不需要真实世界数据。

Result: 在六种疾病测试中超越所有39个专家调优模型，包括CDC COVID-19预测中心的所有模型；能泛化到新的流行病学机制；提供8周预测范围，是大多数模型的两倍；具有机制可解释性。

Conclusion: Mantis作为下一代疾病预测系统的基础，具有通用性、可解释性和在传统模型失效场景下的部署能力，为公共卫生规划提供了更长的预警时间。

Abstract: Infectious disease forecasting in novel outbreaks or low resource settings
has been limited by the need for disease-specific data, bespoke training, and
expert tuning. We introduce Mantis, a foundation model trained entirely on
mechanistic simulations, which enables out-of-the-box forecasting across
diseases, regions, and outcomes, even in settings with limited historical data.
Mantis is built on over 400 million simulated days of outbreak dynamics
spanning diverse pathogens, transmission modes, interventions, and surveillance
artifacts. Despite requiring no real-world data during training, Mantis
outperformed 39 expert-tuned models we tested across six diseases, including
all models in the CDC's COVID-19 Forecast Hub. Mantis generalized to novel
epidemiological regimes, including diseases with held-out transmission
mechanisms, demonstrating that it captures fundamental contagion dynamics.
Critically, Mantis is mechanistically interpretable, enabling public health
decision-makers to identify the latent drivers behind its predictions. Finally,
Mantis delivers accurate forecasts at 8-week horizons, more than doubling the
actionable range of most models, enabling proactive public health planning.
Together, these capabilities position Mantis as a foundation for
next-generation disease forecasting systems: general, interpretable, and
deployable where traditional models fail.

</details>


### [22] [RadarQA: Multi-modal Quality Analysis of Weather Radar Forecasts](https://arxiv.org/abs/2508.12291)
*Xuming He,Zhiyuan You,Junchao Gong,Couhua Liu,Xiaoyu Yue,Peiqin Zhuang,Wenlong Zhang,Lei Bai*

Main category: cs.AI

TL;DR: RadarQA是一个基于多模态大语言模型的天气预报质量分析方法，通过整合物理属性和详细评估报告，在雷达预报质量评估方面超越了现有通用MLLM模型。


<details>
  <summary>Details</summary>
Motivation: 传统基于分数的评估指标在描述能力、可解释性和动态演化理解方面远不如气象专家，需要更先进的工具来克服这些挑战。

Method: 提出了RadarQA方法，结合关键物理属性和详细评估报告；设计了混合标注流程（人工专家标注+自动化启发式方法）；构建了RQA-70K大规模数据集；采用多阶段训练策略迭代提升模型性能。

Result: RadarQA在所有评估设置中都优于现有的通用多模态大语言模型，展示了在天气预报质量分析方面的先进潜力。

Conclusion: MLLM-based的RadarQA方法为天气预报质量分析提供了有效的解决方案，通过大规模数据集和多阶段训练策略显著提升了分析能力，具有推进天气预报质量分析的潜力。

Abstract: Quality analysis of weather forecasts is an essential topic in meteorology.
Although traditional score-based evaluation metrics can quantify certain
forecast errors, they are still far from meteorological experts in terms of
descriptive capability, interpretability, and understanding of dynamic
evolution. With the rapid development of Multi-modal Large Language Models
(MLLMs), these models become potential tools to overcome the above challenges.
In this work, we introduce an MLLM-based weather forecast analysis method,
RadarQA, integrating key physical attributes with detailed assessment reports.
We introduce a novel and comprehensive task paradigm for multi-modal quality
analysis, encompassing both single frame and sequence, under both rating and
assessment scenarios. To support training and benchmarking, we design a hybrid
annotation pipeline that combines human expert labeling with automated
heuristics. With such an annotation method, we construct RQA-70K, a large-scale
dataset with varying difficulty levels for radar forecast quality evaluation.
We further design a multi-stage training strategy that iteratively improves
model performance at each stage. Extensive experiments show that RadarQA
outperforms existing general MLLMs across all evaluation settings, highlighting
its potential for advancing quality analysis in weather prediction.

</details>


### [23] [Wisdom of the Crowd: Reinforcement Learning from Coevolutionary Collective Feedback](https://arxiv.org/abs/2508.12338)
*Wenzhen Yuan,Shengji Tang,Weihao Lin,Jiacheng Ruan,Ganqu Cui,Bo Zhang,Tao Chen,Ting Liu,Yuzhuo Fu,Peng Ye,Lei Bai*

Main category: cs.AI

TL;DR: RLCCF是一个无需外部监督的多模型协作进化强化学习框架，通过最大化集体一致性来优化模型集体能力，在数学推理基准上实现16.72%的平均准确率提升


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法依赖昂贵的人工标注数据或复杂奖励模型，限制了可扩展性。自反馈方法受限于单一模型能力，容易产生错误答案过度自信、奖励攻击和训练崩溃问题

Method: 提出RLCCF框架，通过投票集体输出来提供奖励信号，联合训练多样化的LLM集成。每个模型的投票权重由其自一致性分数决定，确保更自信的模型对集体决策贡献更大

Result: 在四个主流开源LLM和四个数学推理基准上的实验显示，平均相对准确率提升16.72%，群体多数投票准确率提升4.51%

Conclusion: RLCCF不仅提升单个模型性能，还能扩展模型集体的集体能力边界，通过多LLM的多样化输出分布和互补能力实现协同进化

Abstract: Reinforcement learning (RL) has significantly enhanced the reasoning
capabilities of large language models (LLMs), but its reliance on expensive
human-labeled data or complex reward models severely limits scalability. While
existing self-feedback methods aim to address this problem, they are
constrained by the capabilities of a single model, which can lead to
overconfidence in incorrect answers, reward hacking, and even training
collapse. To this end, we propose Reinforcement Learning from Coevolutionary
Collective Feedback (RLCCF), a novel RL framework that enables multi-model
collaborative evolution without external supervision. Specifically, RLCCF
optimizes the ability of a model collective by maximizing its Collective
Consistency (CC), which jointly trains a diverse ensemble of LLMs and provides
reward signals by voting on collective outputs. Moreover, each model's vote is
weighted by its Self-Consistency (SC) score, ensuring that more confident
models contribute more to the collective decision. Benefiting from the diverse
output distributions and complementary abilities of multiple LLMs, RLCCF
enables the model collective to continuously enhance its reasoning ability
through coevolution. Experiments on four mainstream open-source LLMs across
four mathematical reasoning benchmarks demonstrate that our framework yields
significant performance gains, achieving an average relative improvement of
16.72\% in accuracy. Notably, RLCCF not only improves the performance of
individual models but also enhances the group's majority-voting accuracy by
4.51\%, demonstrating its ability to extend the collective capability boundary
of the model collective.

</details>


### [24] [Hierarchical knowledge guided fault intensity diagnosis of complex industrial systems](https://arxiv.org/abs/2508.12375)
*Yu Sha,Shuiping Gou,Bo Liu,Johannes Faber,Ningtao Liu,Stefan Schramm,Horst Stoecker,Thomas Steckenreiter,Domagoj Vnucec,Nadine Wetzstein,Andreas Widl,Kai Zhou*

Main category: cs.AI

TL;DR: 基于树状思维的层次知识导向故障强度诊断框架(HKG)，通过图卷积网络和重加权层次知识相关矩阵(Re-HKCM)抓取类别间依赖关系，在四个工业数据集上较现有方法更优。


<details>
  <summary>Details</summary>
Motivation: 现有故障强度诊断方法基于链式思维模型，没有考虑目标类别间的依赖关系，导致诊断精度不足。

Method: 构建层次知识导向框架(HKG)，使用图卷积网络将类别表示的层次拓扑图映射为一组相互依赖的全局分类器，每个节点用类别的词向量表示。还发展了Re-HKCM方案，将层次知识嵌入到数据驱动的统计相关矩阵中。

Result: 在来自SAMSON AG公司的三个气虹数据集和一个公开数据集上进行了广泛实验，所有结果都显示优异效果，超过了最近的最先进的FID方法。

Conclusion: HKG框架能够有效抓取和利用类别间的依赖关系，通过Re-HKCM方案实现信息共享和避免过平滑问题，为复杂工业系统的故障强度诊断提供了有效解决方案。

Abstract: Fault intensity diagnosis (FID) plays a pivotal role in monitoring and
maintaining mechanical devices within complex industrial systems. As current
FID methods are based on chain of thought without considering dependencies
among target classes. To capture and explore dependencies, we propose a
hierarchical knowledge guided fault intensity diagnosis framework (HKG)
inspired by the tree of thought, which is amenable to any representation
learning methods. The HKG uses graph convolutional networks to map the
hierarchical topological graph of class representations into a set of
interdependent global hierarchical classifiers, where each node is denoted by
word embeddings of a class. These global hierarchical classifiers are applied
to learned deep features extracted by representation learning, allowing the
entire model to be end-to-end learnable. In addition, we develop a re-weighted
hierarchical knowledge correlation matrix (Re-HKCM) scheme by embedding
inter-class hierarchical knowledge into a data-driven statistical correlation
matrix (SCM) which effectively guides the information sharing of nodes in
graphical convolutional neural networks and avoids over-smoothing issues. The
Re-HKCM is derived from the SCM through a series of mathematical
transformations. Extensive experiments are performed on four real-world
datasets from different industrial domains (three cavitation datasets from
SAMSON AG and one existing publicly) for FID, all showing superior results and
outperform recent state-of-the-art FID methods.

</details>


### [25] [GraphCogent: Overcoming LLMs' Working Memory Constraints via Multi-Agent Collaboration in Complex Graph Understanding](https://arxiv.org/abs/2508.12379)
*Rongzheng Wang,Qizhi Chen,Yihong Huang,Yizhuo Ma,Muquan Li,Jiakai Li,Ke Qin,Guangchun Luo,Shuang Liang*

Main category: cs.AI

TL;DR: GraphCogent是一个基于工作记忆模型的协作代理框架，通过将图推理分解为感知、缓冲和执行三个认知过程，有效解决了大语言模型处理复杂图拓扑和多步推理的局限性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在小规模图推理任务上表现良好，但在处理具有复杂查询的真实世界图时失败，主要原因是无法同时有效处理复杂图拓扑和执行多步推理。

Method: 提出GraphCogent框架，包含三个模块：感知模块通过子图采样标准化图文本表示，缓冲模块集成和索引多格式图数据，执行模块结合工具调用和模型生成进行高效推理。

Result: 基于Llama3.1-8B的GraphCogent相比DeepSeek-R1(671B)提升50%性能，相比最先进的基于代理的基线方法，在工具集内任务上准确率提升20%同时减少80%token使用，在工具集外任务上减少30%token使用。

Conclusion: GraphCogent框架通过认知过程分解有效提升了LLMs的图推理能力，同时显著降低了计算成本，为解决复杂图推理问题提供了有效方案。

Abstract: Large language models (LLMs) show promising performance on small-scale graph
reasoning tasks but fail when handling real-world graphs with complex queries.
This phenomenon stems from LLMs' inability to effectively process complex graph
topology and perform multi-step reasoning simultaneously. To address these
limitations, we propose GraphCogent, a collaborative agent framework inspired
by human Working Memory Model that decomposes graph reasoning into specialized
cognitive processes: sense, buffer, and execute. The framework consists of
three modules: Sensory Module standardizes diverse graph text representations
via subgraph sampling, Buffer Module integrates and indexes graph data across
multiple formats, and Execution Module combines tool calling and model
generation for efficient reasoning. We also introduce Graph4real, a
comprehensive benchmark contains with four domains of real-world graphs (Web,
Social, Transportation, and Citation) to evaluate LLMs' graph reasoning
capabilities. Our Graph4real covers 21 different graph reasoning tasks,
categorized into three types (Structural Querying, Algorithmic Reasoning, and
Predictive Modeling tasks), with graph scales that are 10 times larger than
existing benchmarks. Experiments show that Llama3.1-8B based GraphCogent
achieves a 50% improvement over massive-scale LLMs like DeepSeek-R1 (671B).
Compared to state-of-the-art agent-based baseline, our framework outperforms by
20% in accuracy while reducing token usage by 80% for in-toolset tasks and 30%
for out-toolset tasks. Code will be available after review.

</details>


### [26] [Non-Iterative Symbolic-Aided Chain-of-Thought for Logical Reasoning](https://arxiv.org/abs/2508.12425)
*Phuong Minh Nguyen,Tien Huu Dang,Naoya Inoue*

Main category: cs.AI

TL;DR: Symbolic-Aided CoT通过将轻量级符号表示整合到少样本提示中，在非迭代推理过程中使推理模式更加明确，从而提升LLM的逻辑推理能力


<details>
  <summary>Details</summary>
Motivation: 改进标准CoT方法，增强大语言模型在逻辑推理中的透明度、可解释性和可分析性，同时保持提示技术的通用性

Method: 将轻量级符号表示整合到少样本提示中，使用一致的策略构建推理步骤，在非迭代推理过程中使推理模式更加明确

Result: 在四个逻辑推理基准测试中表现优异，特别是在需要处理多重约束或规则的复杂推理任务中，在ProofWriter、ProntoQA和LogicalDeduction三个数据集上显著优于传统CoT

Conclusion: Symbolic-Aided CoT方法有效提升了LLM的逻辑推理能力，在不同模型规模下均能一致改进推理性能，为逻辑推理任务提供了更透明和可解释的解决方案

Abstract: This work introduces Symbolic-Aided Chain-of-Thought (CoT), an improved
approach to standard CoT, for logical reasoning in large language models
(LLMs). The key idea is to integrate lightweight symbolic representations into
few-shot prompts, structuring the inference steps with a consistent strategy to
make reasoning patterns more explicit within a non-iterative reasoning process.
By incorporating these symbolic structures, our method preserves the
generalizability of standard prompting techniques while enhancing the
transparency, interpretability, and analyzability of LLM logical reasoning.
Extensive experiments on four well-known logical reasoning benchmarks --
ProofWriter, FOLIO, ProntoQA, and LogicalDeduction, which cover diverse
reasoning scenarios -- demonstrate the effectiveness of the proposed approach,
particularly in complex reasoning tasks that require navigating multiple
constraints or rules. Notably, Symbolic-Aided CoT consistently improves LLMs'
reasoning capabilities across various model sizes and significantly outperforms
conventional CoT on three out of four datasets, ProofWriter, ProntoQA, and
LogicalDeduction.

</details>


### [27] [GALA: Can Graph-Augmented Large Language Model Agentic Workflows Elevate Root Cause Analysis?](https://arxiv.org/abs/2508.12472)
*Yifang Tian,Yaming Liu,Zichun Chong,Zihang Huang,Hans-Arno Jacobsen*

Main category: cs.AI

TL;DR: GALA是一个新颖的多模态框架，结合统计因果推理和LLM驱动的迭代推理，用于微服务系统的根因分析，在开源基准测试中比现有方法准确率提升高达42.22%。


<details>
  <summary>Details</summary>
Motivation: 微服务系统中的根因分析具有挑战性，传统方法往往只关注单一模态或仅对可疑服务进行排序，无法提供具有可操作性的诊断见解和修复指导。

Method: GALA结合统计因果推理与LLM驱动的迭代推理，通过多模态框架分析指标、日志和追踪等异构遥测数据。

Result: 在开源基准测试中，GALA比最先进方法的准确率提升高达42.22%，生成更具因果合理性和可操作性的诊断输出。

Conclusion: GALA通过提供准确的根因识别和人类可理解的修复指导，弥合了自动故障诊断与实际事件解决之间的差距。

Abstract: Root cause analysis (RCA) in microservice systems is challenging, requiring
on-call engineers to rapidly diagnose failures across heterogeneous telemetry
such as metrics, logs, and traces. Traditional RCA methods often focus on
single modalities or merely rank suspect services, falling short of providing
actionable diagnostic insights with remediation guidance. This paper introduces
GALA, a novel multi-modal framework that combines statistical causal inference
with LLM-driven iterative reasoning for enhanced RCA. Evaluated on an
open-source benchmark, GALA achieves substantial improvements over
state-of-the-art methods of up to 42.22% accuracy. Our novel human-guided LLM
evaluation score shows GALA generates significantly more causally sound and
actionable diagnostic outputs than existing methods. Through comprehensive
experiments and a case study, we show that GALA bridges the gap between
automated failure diagnosis and practical incident resolution by providing both
accurate root cause identification and human-interpretable remediation
guidance.

</details>


### [28] [The Yokai Learning Environment: Tracking Beliefs Over Space and Time](https://arxiv.org/abs/2508.12480)
*Constantin Ruhdorfer,Matteo Bortoletto,Andreas Bulling*

Main category: cs.AI

TL;DR: 基于合作卡牌游戏Yokai构建的多满激学习环境YLE，用于评估AI系统的心理理论能力，发现当前RL满激在共同基础建立和维持方面仍遇到困难


<details>
  <summary>Details</summary>
Motivation: 现有的心理理论(ToM)指标仅限于被动观察者场景，缺乏对满激如何跟踪时间变化建立和维持共同基础的评估

Method: 设计基于合作卡牌游戏Yokai的多满激学习环境YLE，满激需要监控潜在卡牌、记录历史观察、使用提示进行基于地面的沟通，并与队友保持共同基础

Result: 两个关键发现：1)当前RL满激即使有完美记忆也难解决YLE问题；2)信念建模能提高性能，但满激仍无法有效汇总到未见伙伴或在更长游戏中形成准确信念，曝露了对脆弱约定而非稳健信念跟踪的依赖

Conclusion: YLE环境可用于研究信念建模、记忆、伙伴汇总和高阶心理理论等问题，显示了协作AI发展中在共同基础建立方面的挑战

Abstract: Developing collaborative AI hinges on Theory of Mind (ToM) - the ability to
reason about the beliefs of others to build and maintain common ground.
Existing ToM benchmarks, however, are restricted to passive observer settings
or lack an assessment of how agents establish and maintain common ground over
time. To address these gaps, we introduce the Yokai Learning Environment (YLE)
- a multi-agent reinforcement learning (RL) environment based on the
cooperative card game Yokai. In the YLE, agents take turns peeking at hidden
cards and moving them to form clusters based on colour. Success requires
tracking evolving beliefs, remembering past observations, using hints as
grounded communication, and maintaining common ground with teammates. Our
evaluation yields two key findings: First, current RL agents struggle to solve
the YLE, even when given access to perfect memory. Second, while belief
modelling improves performance, agents are still unable to effectively
generalise to unseen partners or form accurate beliefs over longer games,
exposing a reliance on brittle conventions rather than robust belief tracking.
We use the YLE to investigate research questions in belief modelling, memory,
partner generalisation, and scaling to higher-order ToM.

</details>


### [29] [Advanced DOA Regulation with a Whale-Optimized Fractional Order Fuzzy PID Framework](https://arxiv.org/abs/2508.12487)
*Lida Shahbandari,Hossein Mohseni*

Main category: cs.AI

TL;DR: 提出了一种基于鲸鱼优化算法的分数阶模糊PID控制器，用于自动化麻醇控制，在八种患者模型上表现优于标准分数阶PID控制器


<details>
  <summary>Details</summary>
Motivation: 为了提高麻醇控制的精确性和适应性，需要一种能够处理不同患者生理特征变化的智能控制策略

Method: 结合模糊逻辑和分数阶微分方程，使用鲸鱼优化算法(WOA)优化控制器参数、分数阶次数和模糊成员函数

Result: 在八种患者模型上，调节时间从3.2分钟缩短到2.5分钟，稳态误差从1.2降低到0.5，显示了更好的稳定性和精度

Conclusion: 该FOFPID控制器提供了一种可扩展的人工智能驱动方案，有力提升临床实践和改善患者结果

Abstract: This study introduces a Fractional Order Fuzzy PID (FOFPID) controller that
uses the Whale Optimization Algorithm (WOA) to manage the Bispectral Index
(BIS), keeping it within the ideal range of forty to sixty. The FOFPID
controller combines fuzzy logic for adapting to changes and fractional order
dynamics for fine tuning. This allows it to adjust its control gains to handle
a person's unique physiology. The WOA helps fine tune the controller's
parameters, including the fractional orders and the fuzzy membership functions,
which boosts its performance. Tested on models of eight different patient
profiles, the FOFPID controller performed better than a standard Fractional
Order PID (FOPID) controller. It achieved faster settling times, at two and a
half minutes versus three point two minutes, and had a lower steady state
error, at zero point five versus one point two. These outcomes show the
FOFPID's excellent strength and accuracy. It offers a scalable, artificial
intelligence driven solution for automated anesthesia delivery that could
enhance clinical practice and improve patient results.

</details>


### [30] [Root Cause Analysis of Hydrogen Bond Separation in Spatio-Temporal Molecular Dynamics using Causal Models](https://arxiv.org/abs/2508.12500)
*Rahmat K. Adesunkanmi,Ashfaq Khokhar,Goce Trajcevski,Sohail Murad*

Main category: cs.AI

TL;DR: 利用空间时间数据分析和机器学习模型，通过因果模型和变分自动编码器构建图形因果模型，识别氢键形成和分离事件的根本原因变量


<details>
  <summary>Details</summary>
Motivation: 解决分子动力学模拟中资源消耗大、需手动扫描输出以发现"有趣事件"的挑战，特别是找到氢键形成和分离的根本原因

Method: 使用变分自动编码器等机器学习模型构建图形因果模型，将氢键分离视为"干预"事件，推断聚合分布变化的根本原因

Result: 在手性分离的原子轨迹上验证模型效果，能够预测多步未来变化并找到驱动系统变化的关键变量

Conclusion: 该框架为分子动态系统中的根因分析提供了新视角，能够揭示氢键形成和分离事件的深层因果关系

Abstract: Molecular dynamics simulations (MDS) face challenges, including
resource-heavy computations and the need to manually scan outputs to detect
"interesting events," such as the formation and persistence of hydrogen bonds
between atoms of different molecules. A critical research gap lies in
identifying the underlying causes of hydrogen bond formation and separation
-understanding which interactions or prior events contribute to their emergence
over time. With this challenge in mind, we propose leveraging spatio-temporal
data analytics and machine learning models to enhance the detection of these
phenomena. In this paper, our approach is inspired by causal modeling and aims
to identify the root cause variables of hydrogen bond formation and separation
events. Specifically, we treat the separation of hydrogen bonds as an
"intervention" occurring and represent the causal structure of the bonding and
separation events in the MDS as graphical causal models. These causal models
are built using a variational autoencoder-inspired architecture that enables us
to infer causal relationships across samples with diverse underlying causal
graphs while leveraging shared dynamic information. We further include a step
to infer the root causes of changes in the joint distribution of the causal
models. By constructing causal models that capture shifts in the conditional
distributions of molecular interactions during bond formation or separation,
this framework provides a novel perspective on root cause analysis in molecular
dynamic systems. We validate the efficacy of our model empirically on the
atomic trajectories that used MDS for chiral separation, demonstrating that we
can predict many steps in the future and also find the variables driving the
observed changes in the system.

</details>


### [31] [Help or Hurdle? Rethinking Model Context Protocol-Augmented Large Language Models](https://arxiv.org/abs/2508.12566)
*Wei Song,Haonan Zhong,Ziqi Ding,Jingling Xue,Yuekang Li*

Main category: cs.AI

TL;DR: MCPGAUGE是首个全面评估LLM-MCP交互的框架，通过四个维度（主动性、合规性、有效性、开销）评估工具集成效果，发现当前MCP集成存在关键局限性


<details>
  <summary>Details</summary>
Motivation: 虽然MCP使LLM能够按需访问外部资源，但LLM如何实际利用这种能力仍不清楚，需要系统评估框架

Method: 开发包含160个提示和25个数据集的MCPGAUGE框架，在6个商业LLM、30个MCP工具套件上进行大规模评估（约20,000次API调用）

Result: 研究揭示了四个关键发现，挑战了关于MCP集成有效性的普遍假设，突显了当前AI工具集成的关键局限性

Conclusion: MCPGAUGE为推进可控、工具增强的LLM提供了原则性基准，揭示了当前工具集成方法的不足

Abstract: The Model Context Protocol (MCP) enables large language models (LLMs) to
access external resources on demand. While commonly assumed to enhance
performance, how LLMs actually leverage this capability remains poorly
understood. We introduce MCPGAUGE, the first comprehensive evaluation framework
for probing LLM-MCP interactions along four key dimensions: proactivity
(self-initiated tool use), compliance (adherence to tool-use instructions),
effectiveness (task performance post-integration), and overhead (computational
cost incurred). MCPGAUGE comprises a 160-prompt suite and 25 datasets spanning
knowledge comprehension, general reasoning, and code generation. Our
large-scale evaluation, spanning six commercial LLMs, 30 MCP tool suites, and
both one- and two-turn interaction settings, comprises around 20,000 API calls
and over USD 6,000 in computational cost. This comprehensive study reveals four
key findings that challenge prevailing assumptions about the effectiveness of
MCP integration. These insights highlight critical limitations in current
AI-tool integration and position MCPGAUGE as a principled benchmark for
advancing controllable, tool-augmented LLMs.

</details>


### [32] [An LLM + ASP Workflow for Joint Entity-Relation Extraction](https://arxiv.org/abs/2508.12611)
*Trang Tran,Trung Hoang Le,Huiping Cao,Tran Cao Son*

Main category: cs.AI

TL;DR: 使用LLM和ASP的联合方法进行实体-关系提取，免去大量注释数据需求，仅需10%训练数据即超10%性能提升


<details>
  <summary>Details</summary>
Motivation: 解决传统机器学习方法需要大量注释数据、无法容易融合领域知识、构建模型费时费力的问题

Method: 结合生成式预训练大语言模型(LLM)的自然语言理解能力和答案集编程(ASP)的知识表示与推理能力，提出通用工作流

Result: 在三个标准数据集上进行实验，仅用10%训练数据即超过现有最佳系统，在SciERC数据集上关系提取任务实现2.5倍提升(35% vs 15%)

Conclusion: LLM+ASP联合方法为实体-关系提取提供了一种高效、少数据需求、易于融合领域知识的新方案，具有良好的应用前景

Abstract: Joint entity-relation extraction (JERE) identifies both entities and their
relationships simultaneously. Traditional machine-learning based approaches to
performing this task require a large corpus of annotated data and lack the
ability to easily incorporate domain specific information in the construction
of the model. Therefore, creating a model for JERE is often labor intensive,
time consuming, and elaboration intolerant. In this paper, we propose
harnessing the capabilities of generative pretrained large language models
(LLMs) and the knowledge representation and reasoning capabilities of Answer
Set Programming (ASP) to perform JERE. We present a generic workflow for JERE
using LLMs and ASP. The workflow is generic in the sense that it can be applied
for JERE in any domain. It takes advantage of LLM's capability in natural
language understanding in that it works directly with unannotated text. It
exploits the elaboration tolerant feature of ASP in that no modification of its
core program is required when additional domain specific knowledge, in the form
of type specifications, is found and needs to be used. We demonstrate the
usefulness of the proposed workflow through experiments with limited training
data on three well-known benchmarks for JERE. The results of our experiments
show that the LLM + ASP workflow is better than state-of-the-art JERE systems
in several categories with only 10\% of training data. It is able to achieve a
2.5 times (35\% over 15\%) improvement in the Relation Extraction task for the
SciERC corpus, one of the most difficult benchmarks.

</details>


### [33] [Cognitive Structure Generation: From Educational Priors to Policy Optimization](https://arxiv.org/abs/2508.12647)
*Hengnian Gu,Zhifu Chen,Yuxin Chen,Jin Peng Zhou,Dongdai Zhou*

Main category: cs.AI

TL;DR: 本文提出了认知结构生成（CSG）框架，通过预训练认知结构扩散概率模型和强化学习优化，从教育先验生成学生的认知结构，显著提升了学生建模的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 认知结构是学生对知识系统的主观组织，但在教育实践中一直难以有效评估。为了解决认知结构评估这一长期挑战，需要开发能够生成和优化认知结构的新方法。

Method: 首先预训练认知结构扩散概率模型（CSDPM）从教育先验生成认知结构，然后通过强化学习使用分层奖励信号优化生成过程，使其与学生学习过程中的真实认知发展水平对齐。

Result: 在四个真实世界教育数据集上的实验结果表明，CSG生成的认知结构为学生建模提供了更全面有效的表示，显著提高了知识追踪（KT）和认知诊断（CD）任务的性能。

Conclusion: CSG框架成功解决了认知结构评估的难题，生成的认知结构不仅提升了学生建模的性能，还增强了模型的可解释性，为教育实践提供了有价值的工具。

Abstract: Cognitive structure is a student's subjective organization of an objective
knowledge system, reflected in the psychological construction of concepts and
their relations. However, cognitive structure assessment remains a
long-standing challenge in student modeling and psychometrics, persisting as a
foundational yet largely unassessable concept in educational practice. This
paper introduces a novel framework, Cognitive Structure Generation (CSG), in
which we first pretrain a Cognitive Structure Diffusion Probabilistic Model
(CSDPM) to generate students' cognitive structures from educational priors, and
then further optimize its generative process as a policy with hierarchical
reward signals via reinforcement learning to align with genuine cognitive
development levels during students' learning processes. Experimental results on
four popular real-world education datasets show that cognitive structures
generated by CSG offer more comprehensive and effective representations for
student modeling, substantially improving performance on KT and CD tasks while
enhancing interpretability.

</details>


### [34] [The Maximum Coverage Model and Recommendation System for UAV Vertiports Location Planning](https://arxiv.org/abs/2508.12651)
*Chunliang Hua,Xiao Hu,Jiayang Sun,Zeyuan Yang*

Main category: cs.AI

TL;DR: 本文提出了一种新的有容量动态最大覆盖位置问题(CDMCLP)优化框架，结合集成规划推荐系统，为城市空中交通(UAM)垂直机场网络规划提供了更加实用的解决方案。验证显示该方法比传统方法性能提升38%-52%。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市空中交通(UAM)基础设施快速发展，像深圳这样的城市正在规划大规模垂直机场网络。现有的规划框架因数据粒度和实际应用性的历史限制，无法满足这种复杂性需求。

Method: 首先提出有容量动态最大覆盖位置问题(CDMCLP)优化框架，同时模型城市级空间-时间需求、异质用户行为和基础设施容量约束。基于此，提出集成规划推荐系统，结合社会经济因素和动态聚类初始化，利用基于实证用户行为的适应性参数调整来生成实用规划方案。

Result: 在中国中心城市的验证显示了新优化框架和推荐系统的有效性。在CDMCLP的评估和优化下，传统位置方法的数量性能暴露出来，并可以提升38%-52%，而推荐系统显示了用户友好性和复杂元素的有效集成。

Conclusion: 通过将数学严谨性与实际实施考虑相结合，这种混合方法平息了理论位置模型与实际UAM基础设施规划之间的差距，为市政府提供了一种实用的垂直机场网络设计工具。

Abstract: As urban aerial mobility (UAM) infrastructure development accelerates
globally, cities like Shenzhen are planning large-scale vertiport networks
(e.g., 1,200+ facilities by 2026). Existing planning frameworks remain
inadequate for this complexity due to historical limitations in data
granularity and real-world applicability. This paper addresses these gaps by
first proposing the Capacitated Dynamic Maximum Covering Location Problem
(CDMCLP), a novel optimization framework that simultaneously models urban-scale
spatial-temporal demand, heterogeneous user behaviors, and infrastructure
capacity constraints. Building on this foundation, we introduce an Integrated
Planning Recommendation System that combines CDMCLP with socio-economic factors
and dynamic clustering initialization. This system leverages adaptive parameter
tuning based on empirical user behavior to generate practical planning
solutions. Validation in a Chinese center city demonstrates the effectiveness
of the new optimization framework and recommendation system. Under the
evaluation and optimization of CDMCLP, the quantitative performance of
traditional location methods are exposed and can be improved by 38\%--52\%,
while the recommendation system shows user-friendliness and the effective
integration of complex elements. By integrating mathematical rigor with
practical implementation considerations, this hybrid approach bridges the gap
between theoretical location modeling and real-world UAM infrastructure
planning, offering municipalities a pragmatic tool for vertiport network
design.

</details>


### [35] [GridCodex: A RAG-Driven AI Framework for Power Grid Code Reasoning and Compliance](https://arxiv.org/abs/2508.12682)
*Jinquan Shi,Yingying Cheng,Fan Zhang,Miao Jiang,Jun Lin,Yanbai Shen*

Main category: cs.AI

TL;DR: GridCodex是一个基于大语言模型和检索增强生成(RAG)的端到端框架，用于电网规范推理和合规性检查，通过多阶段查询优化和RAPTOR增强检索技术，在答案质量和召回率方面取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着全球向可再生能源转型，电网运营监管变得越来越重要。电网规范复杂且缺乏自动化解释解决方案，阻碍了行业发展并影响电力公司盈利能力。

Method: 开发了GridCodex框架，结合大语言模型和检索增强生成技术，采用多阶段查询优化和RAPTOR增强检索方法来改进传统RAG工作流程。

Result: 实验结果显示，GridCodex在答案质量上提升了26.4%，召回率提高了10倍以上。消融研究还分析了基础模型选择的影响。

Conclusion: GridCodex框架有效解决了电网规范自动化解释的挑战，为电力行业提供了可靠的监管合规解决方案，显著提升了处理效率和准确性。

Abstract: The global shift towards renewable energy presents unprecedented challenges
for the electricity industry, making regulatory reasoning and compliance
increasingly vital. Grid codes, the regulations governing grid operations, are
complex and often lack automated interpretation solutions, which hinders
industry expansion and undermines profitability for electricity companies. We
introduce GridCodex, an end to end framework for grid code reasoning and
compliance that leverages large language models and retrieval-augmented
generation (RAG). Our framework advances conventional RAG workflows through
multi stage query refinement and enhanced retrieval with RAPTOR. We validate
the effectiveness of GridCodex with comprehensive benchmarks, including
automated answer assessment across multiple dimensions and regulatory agencies.
Experimental results showcase a 26.4% improvement in answer quality and more
than a 10 fold increase in recall rate. An ablation study further examines the
impact of base model selection.

</details>


### [36] [EGOILLUSION: Benchmarking Hallucinations in Egocentric Video Understanding](https://arxiv.org/abs/2508.12687)
*Ashish Seth,Utkarsh Tyagi,Ramaneswaran Selvakumar,Nishit Anand,Sonal Kumar,Sreyan Ghosh,Ramani Duraiswami,Chirag Agarwal,Dinesh Manocha*

Main category: cs.AI

TL;DR: EgoIllusion是首个评估多模态大语言模型在自我中心视频中幻觉问题的基准，包含1400个视频和8000个人工标注问题，测试显示包括GPT-4o和Gemini在内的顶级模型准确率仅59%。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在复杂多模态任务中表现出色，但在自我中心视频中容易产生连贯但不准确的幻觉响应，需要专门的评估基准。

Method: 构建包含1400个自我中心视频和8000个人工标注问题的基准数据集，设计开放式和封闭式问题来触发视觉和听觉线索的幻觉。

Result: 对10个多模态大语言模型的评估显示显著挑战，最强模型准确率仅59%，表明当前模型在自我中心视频理解方面存在严重幻觉问题。

Conclusion: EgoIllusion为评估多模态大语言模型有效性奠定了基础，将推动开发幻觉率更低的自我中心多模态大语言模型，该基准将开源以确保可复现性。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
performance in complex multimodal tasks. While MLLMs excel at visual perception
and reasoning in third-person and egocentric videos, they are prone to
hallucinations, generating coherent yet inaccurate responses. We present
EgoIllusion, a first benchmark to evaluate MLLM hallucinations in egocentric
videos. EgoIllusion comprises 1,400 videos paired with 8,000 human-annotated
open and closed-ended questions designed to trigger hallucinations in both
visual and auditory cues in egocentric videos. Evaluations across ten MLLMs
reveal significant challenges, including powerful models like GPT-4o and
Gemini, achieving only 59% accuracy. EgoIllusion lays the foundation in
developing robust benchmarks to evaluate the effectiveness of MLLMs and spurs
the development of better egocentric MLLMs with reduced hallucination rates.
Our benchmark will be open-sourced for reproducibility.

</details>


### [37] [GTool: Graph Enhanced Tool Planning with Large Language Model](https://arxiv.org/abs/2508.12725)
*Wenjie Chen,Wenbin Li,Di Yao,Xuying Meng,Chang Gong,Jingping Bi*

Main category: cs.AI

TL;DR: GTool是一个增强LLM工具规划能力的新方法，通过构建请求特定的工具图和生成图标记来解决工具依赖不完整的问题，在轻量级LLM上比SOTA基线提升29.6%性能。


<details>
  <summary>Details</summary>
Motivation: 现有工作将不同工具视为孤立组件，未能利用工具间的固有依赖关系，导致规划结果无效。工具依赖往往不完整，使得LLM难以准确识别用户请求所需的合适工具，特别是在面对大型工具集时。

Method: GTool构建请求特定的工具图来高效选择工具，生成LLM可理解的<graph token>提供充分依赖信息。设计了缺失依赖预测任务来提高在不完整依赖下的可靠性。无需修剪LLM，可与各种LLM主干无缝集成。

Result: 广泛实验表明，GTool在使用轻量级(7B)LLM主干时，相比最先进的基线实现了超过29.6%的性能提升。

Conclusion: GTool是首个旨在增强LLM在不完整依赖下的工具规划能力的工作，通过工具图构建和图标记生成有效解决了工具依赖不完整的问题，具有很好的通用性和实用性。

Abstract: Tool planning with large language models (LLMs), referring to selecting,
organizing, and preparing the tools necessary to complete a user request,
bridges the gap between natural language understanding and task execution.
However, current works treat different tools as isolated components and fail to
leverage the inherent dependencies of tools, leading to invalid planning
results. Since tool dependencies are often incomplete, it becomes challenging
for LLMs to accurately identify the appropriate tools required by a user
request, especially when confronted with a large toolset. To solve this
challenge, we propose \texttt{GTool}, which is the first work aiming to enhance
the tool planning ability of LLMs under incomplete dependencies. \texttt{GTool}
constructs a request-specific tool graph to select tools efficiently and
generate the \texttt{<graph token>} which provides sufficient dependency
information understandable by LLMs. Moreover, a missing dependency prediction
task is designed to improve the reliability of \texttt{GTool} with incomplete
dependencies. Without trimming LLMs, \texttt{GTool} can be seamlessly
integrated with various LLM backbones without extensive retraining. Extensive
experiments show that \texttt{GTool} achieves more than 29.6\% performance
improvements compared with the state-of-the-art (SOTA) baselines with a
light-weight (7B) LLM backbone.

</details>


### [38] [Beyond Ethical Alignment: Evaluating LLMs as Artificial Moral Assistants](https://arxiv.org/abs/2508.12754)
*Alessio Galatolo,Luca Alberto Rappuoli,Katie Winkle,Meriem Beloucif*

Main category: cs.AI

TL;DR: 这篇论文提出了一种新的测试框架，以评估大语言模型在作为人工道德助手时的道德推理能力，发现现有模型在演绎性道德推理方面存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 目前对大语言模型道德能力的评估太过表面化，只关注最终道德判断而非明确的道德推理过程。需要从哲学角度构建更深入的评估框架。

Method: 基于哲学文献设计了人工道德助手的形式框架，包括演绎性道德推理等关键质量。开发了测试这些质量的基准，并对流行的开源大语言模型进行了评估。

Result: 不同模型在道德推理能力上存在显著差异，尤其是在演绎性道德推理方面持续存在短板。

Conclusion: 该研究将理论哲学与实践AI评估相结合，强调需要专门的策略来明确提升大语言模型的道德推理能力。

Abstract: The recent rise in popularity of large language models (LLMs) has prompted
considerable concerns about their moral capabilities. Although considerable
effort has been dedicated to aligning LLMs with human moral values, existing
benchmarks and evaluations remain largely superficial, typically measuring
alignment based on final ethical verdicts rather than explicit moral reasoning.
In response, this paper aims to advance the investigation of LLMs' moral
capabilities by examining their capacity to function as Artificial Moral
Assistants (AMAs), systems envisioned in the philosophical literature to
support human moral deliberation. We assert that qualifying as an AMA requires
more than what state-of-the-art alignment techniques aim to achieve: not only
must AMAs be able to discern ethically problematic situations, they should also
be able to actively reason about them, navigating between conflicting values
outside of those embedded in the alignment phase. Building on existing
philosophical literature, we begin by designing a new formal framework of the
specific kind of behaviour an AMA should exhibit, individuating key qualities
such as deductive and abductive moral reasoning. Drawing on this theoretical
framework, we develop a benchmark to test these qualities and evaluate popular
open LLMs against it. Our results reveal considerable variability across models
and highlight persistent shortcomings, particularly regarding abductive moral
reasoning. Our work connects theoretical philosophy with practical AI
evaluation while also emphasising the need for dedicated strategies to
explicitly enhance moral reasoning capabilities in LLMs. Code available at
https://github.com/alessioGalatolo/AMAeval

</details>


### [39] [HeroBench: A Benchmark for Long-Horizon Planning and Structured Reasoning in Virtual Worlds](https://arxiv.org/abs/2508.12782)
*Petr Anokhin,Roman Khalikov,Stefan Rebrikov,Viktor Volkov,Artyom Sorokin,Vincent Bissonnette*

Main category: cs.AI

TL;DR: HeroBench是一个专门评估大语言模型在复杂RPG虚拟世界中长时程规划和结构化推理能力的新基准测试，揭示了当前模型在生成稳健高层计划和执行结构化行动方面的显著弱点。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要通过抽象或低维算法任务评估LLMs，无法捕捉现实规划环境的复杂性，LLMs在需要扩展、结构化、相互依赖行动序列的长时程规划方面的能力仍未充分探索。

Method: 引入HeroBench基准测试，包含：1）覆盖不同难度级别的严格构建任务数据集；2）用于执行和验证智能体计划的模拟环境；3）评估模型性能的详细分析工具。任务要求模型制定战略计划、收集资源、掌握技能、制作装备和击败对手。

Result: 对25个最先进LLMs（包括开源和专有模型，如GPT-5系列）的广泛评估显示，在传统推理基准中很少观察到的显著性能差异。详细错误分析揭示了当前模型在生成稳健高层计划和可靠执行结构化行动能力方面的具体弱点。

Conclusion: HeroBench不仅显著推进了LLM推理评估，还为未来在虚拟环境中进行高级自主规划研究提供了灵活、可扩展的基础。

Abstract: Large language models (LLMs) have shown remarkable capabilities in isolated
step-by-step reasoning tasks such as mathematics and programming, but their
proficiency in long-horizon planning, where solutions require extended,
structured sequences of interdependent actions, remains underexplored. Existing
benchmarks typically assess LLMs through abstract or low-dimensional
algorithmic tasks, failing to capture the complexity of realistic planning
environments. We introduce HeroBench, a novel benchmark designed specifically
to evaluate long-horizon planning and structured reasoning within complex
RPG-inspired virtual worlds. HeroBench provides a rigorously constructed
dataset of tasks covering a wide range of difficulties, a simulated environment
to execute and validate agent plans, and detailed analytical tools for
evaluating model performance. Tasks challenge models to formulate strategic
plans, efficiently gather resources, master necessary skills, craft equipment,
and defeat adversaries, reflecting practical scenarios' layered dependencies
and constraints. Our extensive evaluation of 25 state-of-the-art LLMs, spanning
both open-source and proprietary models, including the GPT-5 family, reveals
substantial performance disparities rarely observed in conventional reasoning
benchmarks. Detailed error analysis further uncovers specific weaknesses in
current models' abilities to generate robust high-level plans and reliably
execute structured actions. HeroBench thus not only significantly advances the
evaluation of LLM reasoning but also provides a flexible, scalable foundation
for future research into advanced, autonomous planning in virtual environments.

</details>


### [40] [Reinforcement Learning with Rubric Anchors](https://arxiv.org/abs/2508.12790)
*Zenan Huang,Yihong Zhuang,Guoshan Lu,Zeyu Qin,Haokai Xu,Tianyu Zhao,Ru Peng,Jiaqi Hu,Zhanming Shen,Xiaomeng Hu,Xijun Gu,Peiyi Tu,Jiaxin Liu,Wenyu Chen,Yuzhuo Fu,Zhiting Fan,Yanmei Gu,Yuanyuan Wang,Zhengkai Yang,Jianguo Li,Junbo Zhao*

Main category: cs.AI

TL;DR: 本文提出了一种基于评分标准的RLVR方法，将可验证奖励学习扩展到开放式任务，通过构建包含10,000+评分标准的系统，在少量样本下显著提升模型在人文类任务的表现，并实现细粒度的风格控制。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR方法主要局限于可自动验证结果的领域（如代码测试、数学推理），无法有效处理开放式主观任务。为了突破这一限制，需要将RLVR范式扩展到开放式任务领域。

Method: 通过集成基于评分标准的奖励系统，利用人工设计、LLM生成或人机协作创建的评分标准作为结构化、模型可解释的自动评分标准。构建了超过10,000个评分标准的系统，并提出了清晰的实施框架。

Result: 仅使用5,000+样本，系统在开放式基准测试（特别是人文类）上提升5.2%，超越671B参数的DeepSeek-V3模型2.4%，同时保持通用和推理能力。方法还提供了细粒度的风格控制，减轻"AI腔调"，产生更人性化、富有表现力的回答。

Conclusion: 评分标准为基础的RL方法成功扩展了RLVR的应用范围，为开放式主观任务提供了有效的训练范式，在保持模型能力的同时显著提升了特定领域的表现和输出质量。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing Large Language Models (LLMs), exemplified by
the success of OpenAI's o-series. In RLVR, rewards are derived from verifiable
signals-such as passing unit tests in code generation or matching correct
answers in mathematical reasoning. While effective, this requirement largely
confines RLVR to domains with automatically checkable outcomes. To overcome
this, we extend the RLVR paradigm to open-ended tasks by integrating
rubric-based rewards, where carefully designed rubrics serve as structured,
model-interpretable criteria for automatic scoring of subjective outputs. We
construct, to our knowledge, the largest rubric reward system to date, with
over 10,000 rubrics from humans, LLMs, or a hybrid human-LLM collaboration.
Implementing rubric-based RL is challenging; we tackle these issues with a
clear framework and present an open-sourced Qwen-30B-A3B model with notable
gains: 1) With only 5K+ samples, our system improves by +5.2% on open-ended
benchmarks (especially humanities), outperforming a 671B DeepSeek-V3 model by
+2.4%, while preserving general and reasoning abilities. 2) Our method provides
fine-grained stylistic control, using rubrics as anchors to mitigate the
"AI-like" tone and produce more human-like, expressive responses. We share key
lessons in rubric construction, data selection, and training, and discuss
limitations and future releases.

</details>


### [41] [[Social] Allostasis: Or, How I Learned To Stop Worrying and Love The Noise](https://arxiv.org/abs/2508.12791)
*Imran Khan*

Main category: cs.AI

TL;DR: 这篇论文提出了一个计算模型，展示异稳态和社会异稳态调节如何让智能体主动利用环境和社会扰动进行自适应重构，相比传统稳态调节获得更好的生存能力。


<details>
  <summary>Details</summary>
Motivation: 传统稳态概念强调系统通过抵抗扰动来维持稳定，而异稳态理论认为系统可以主动利用扰动来预测环境需求并重新配置调节参数。本文旨在从计算角度验证这一理论。

Method: 建立了一个基于生物生理学信号转导器的计算模型，模拟类似皮质醇和催产素的激素机制，编码环境和社会互动的信息。使用基于智能体的模型在多动态环境中测试小型社会中的"animats"。

Result: 结果显示，异稳态和社会异稳态调节使智能体能够利用环境和社会"噪声"进行自适应重构，相比纯反应式稳态智能体表现出更好的生存能力。

Conclusion: 这项工作为社会异稳态原理提供了新颖的计算视角，展示了其在设计更鲁棒、生物启发的自适应系统方面的潜力。

Abstract: The notion of homeostasis typically conceptualises biological and artificial
systems as maintaining stability by resisting deviations caused by
environmental and social perturbations. In contrast, (social) allostasis
proposes that these systems can proactively leverage these very perturbations
to reconfigure their regulatory parameters in anticipation of environmental
demands, aligning with von Foerster's ``order through noise'' principle. This
paper formulates a computational model of allostatic and social allostatic
regulation that employs biophysiologically inspired signal transducers,
analogous to hormones like cortisol and oxytocin, to encode information from
both the environment and social interactions, which mediate this dynamic
reconfiguration. The models are tested in a small society of ``animats'' across
several dynamic environments, using an agent-based model. The results show that
allostatic and social allostatic regulation enable agents to leverage
environmental and social ``noise'' for adaptive reconfiguration, leading to
improved viability compared to purely reactive homeostatic agents. This work
offers a novel computational perspective on the principles of social allostasis
and their potential for designing more robust, bio-inspired, adaptive systems

</details>


### [42] [Scaling Multi-Agent Epistemic Planning through GNN-Derived Heuristics](https://arxiv.org/abs/2508.12840)
*Giovanni Briglia,Francesco Fabiano,Stefano Mariani*

Main category: cs.AI

TL;DR: 利用图神经网络学习多代理认知规划中的状态质量估计，提高规划效率和可扩展性


<details>
  <summary>Details</summary>
Motivation: 多代理认知规划中的Kripke结构表示导致状态空间指数增长，现有吧函数无法有效指导搜索，影响规划器的可扩展性

Method: 采用图神经网络(GNN)来学习认知状态中的模式和关系结构，通过从已解决规划实例中汇总知识来推导状态质量估计(如距离目标的距离)

Result: 将预测性吧函数集成到认知规划流程中，与标准基准相比显示出多代理认知规划可扩展性的显著提升

Conclusion: GNN技术能够有效处理认知规划中的图形化状态表示，通过学习基于模型的吧函数来提高规划效率，为解决复杂的多代理认知规划问题提供了新的方法

Abstract: Multi-agent Epistemic Planning (MEP) is an autonomous planning framework for
reasoning about both the physical world and the beliefs of agents, with
applications in domains where information flow and awareness among agents are
critical. The richness of MEP requires states to be represented as Kripke
structures, i.e., directed labeled graphs. This representation limits the
applicability of existing heuristics, hindering the scalability of epistemic
solvers, which must explore an exponential search space without guidance,
resulting often in intractability. To address this, we exploit Graph Neural
Networks (GNNs) to learn patterns and relational structures within epistemic
states, to guide the planning process. GNNs, which naturally capture the
graph-like nature of Kripke models, allow us to derive meaningful estimates of
state quality -- e.g., the distance from the nearest goal -- by generalizing
knowledge obtained from previously solved planning instances. We integrate
these predictive heuristics into an epistemic planning pipeline and evaluate
them against standard baselines, showing significant improvements in the
scalability of multi-agent epistemic planning.

</details>


### [43] [CAMAR: Continuous Actions Multi-Agent Routing](https://arxiv.org/abs/2508.12845)
*Artem Pshenitsyn,Aleksandr Panov,Alexey Skrynnik*

Main category: cs.AI

TL;DR: CAMAR是一个新的多智能体强化学习基准测试，专门为连续动作空间中的多智能体路径规划设计，支持合作和竞争交互，并提供三层评估协议和经典规划方法集成。


<details>
  <summary>Details</summary>
Motivation: 现有的MARL基准测试很少结合连续状态和动作空间与具有挑战性的协调和规划任务，需要一个新的测试平台来推动算法发展。

Method: 设计了CAMAR基准测试，支持连续动作空间的多智能体路径规划，提供高效的环境模拟（每秒10万步），并提出了三层评估协议。集成了RRT和RRT*等经典规划方法，可以单独使用或与MARL算法结合形成混合方法。

Result: CAMAR为MARL社区提供了一个具有挑战性和现实性的测试平台，实验表明该基准能够有效评估算法性能。

Conclusion: CAMAR填补了连续动作空间多智能体路径规划基准测试的空白，通过集成经典规划方法和提供标准化评估协议，有助于推动MARL算法的发展和研究。

Abstract: Multi-agent reinforcement learning (MARL) is a powerful paradigm for solving
cooperative and competitive decision-making problems. While many MARL
benchmarks have been proposed, few combine continuous state and action spaces
with challenging coordination and planning tasks. We introduce CAMAR, a new
MARL benchmark designed explicitly for multi-agent pathfinding in environments
with continuous actions. CAMAR supports cooperative and competitive
interactions between agents and runs efficiently at up to 100,000 environment
steps per second. We also propose a three-tier evaluation protocol to better
track algorithmic progress and enable deeper analysis of performance. In
addition, CAMAR allows the integration of classical planning methods such as
RRT and RRT* into MARL pipelines. We use them as standalone baselines and
combine RRT* with popular MARL algorithms to create hybrid approaches. We
provide a suite of test scenarios and benchmarking tools to ensure
reproducibility and fair comparison. Experiments show that CAMAR presents a
challenging and realistic testbed for the MARL community.

</details>


### [44] [E3RG: Building Explicit Emotion-driven Empathetic Response Generation System with Multimodal Large Language Model](https://arxiv.org/abs/2508.12854)
*Ronghao Lin,Shuai Shen,Weipeng Hu,Qiaolin He,Aolin Xiong,Li Huang,Haifeng Hu,Yap-peng Tan*

Main category: cs.AI

TL;DR: E3RG是一个基于多模态大语言模型的显式情感驱动共情响应生成系统，将多模态共情响应生成任务分解为三个部分：多模态共情理解、共情记忆检索和多模态响应生成，无需额外训练即可生成自然、情感丰富且身份一致的响应。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型改进了基于文本的共情响应生成，但在处理多模态情感内容和保持身份一致性方面仍存在挑战，需要构建更智能的人机情感交互系统。

Method: 将多模态共情响应生成任务分解为三个模块：多模态共情理解、共情记忆检索和多模态响应生成，并集成先进的表达性语音和视频生成模型。

Result: 在零样本和少样本设置下均表现出优越性，在ACM MM 25的Avatar-based Multimodal Empathy Challenge中获得Top-1排名。

Conclusion: E3RG系统能够有效解决多模态情感内容处理和身份一致性问题，为构建情感智能的人机交互提供了有效解决方案。

Abstract: Multimodal Empathetic Response Generation (MERG) is crucial for building
emotionally intelligent human-computer interactions. Although large language
models (LLMs) have improved text-based ERG, challenges remain in handling
multimodal emotional content and maintaining identity consistency. Thus, we
propose E3RG, an Explicit Emotion-driven Empathetic Response Generation System
based on multimodal LLMs which decomposes MERG task into three parts:
multimodal empathy understanding, empathy memory retrieval, and multimodal
response generation. By integrating advanced expressive speech and video
generative models, E3RG delivers natural, emotionally rich, and
identity-consistent responses without extra training. Experiments validate the
superiority of our system on both zero-shot and few-shot settings, securing
Top-1 position in the Avatar-based Multimodal Empathy Challenge on ACM MM 25.
Our code is available at https://github.com/RH-Lin/E3RG.

</details>


### [45] [Reliability, Embeddedness, and Agency: A Utility-Driven Mathematical Framework for Agent-Centric AI Adoption](https://arxiv.org/abs/2508.12896)
*Faruk Alpay,Taylan Alpay*

Main category: cs.AI

TL;DR: 这篇论文形式化了三个指导代理中心AI系统持续采用的设计公理，并通过数学模型分析了采用动态。研究包含了从可识别性分析到模型模拟的多种方法论证。


<details>
  <summary>Details</summary>
Motivation: 为了理解和推动代理中心AI系统的持续采用，需要形式化的设计原则和数学模型来预测和优化采用动态。

Method: 通过建立数学模型将采用模型为新鲜感衰减项和效用增长项的结合，并进行了多种统计分析，包括可识别性分析、模型比较、效果异质性分析、多系列测试、模型检验等。

Result: 研究提供了完整的数学证明和模型分析框架，能够预测采用动态中的波豹/超调现象，并通过多种统计方法验证模型的可靠性。

Conclusion: 论文为代理中心AI系统的采用动态建立了严格的数学基础，提供了一个综合的分析框架来理解和优化这种系统的持续采用。

Abstract: We formalize three design axioms for sustained adoption of agent-centric AI
systems executing multi-step tasks: (A1) Reliability > Novelty; (A2) Embed >
Destination; (A3) Agency > Chat. We model adoption as a sum of a decaying
novelty term and a growing utility term and derive the phase conditions for
troughs/overshoots with full proofs. We introduce: (i) an
identifiability/confounding analysis for $(\alpha,\beta,N_0,U_{\max})$ with
delta-method gradients; (ii) a non-monotone comparator
(logistic-with-transient-bump) evaluated on the same series to provide
additional model comparison; (iii) ablations over hazard families $h(\cdot)$
mapping $\Delta V \to \beta$; (iv) a multi-series benchmark (varying trough
depth, noise, AR structure) reporting coverage (type-I error, power); (v)
calibration of friction proxies against time-motion/survey ground truth with
standard errors; (vi) residual analyses (autocorrelation and
heteroskedasticity) for each fitted curve; (vii) preregistered windowing
choices for pre/post estimation; (viii) Fisher information & CRLB for
$(\alpha,\beta)$ under common error models; (ix) microfoundations linking
$\mathcal{T}$ to $(N_0,U_{\max})$; (x) explicit comparison to bi-logistic,
double-exponential, and mixture models; and (xi) threshold sensitivity to $C_f$
heterogeneity. Figures and tables are reflowed for readability, and the
bibliography restores and extends non-logistic/Bass adoption references
(Gompertz, Richards, Fisher-Pry, Mansfield, Griliches, Geroski, Peres). All
code and logs necessary to reproduce the synthetic analyses are embedded as
LaTeX listings.

</details>


### [46] [FuSaR: A Fuzzification-Based Method for LRM Safety-Reasoning Balance](https://arxiv.org/abs/2508.12897)
*Jianhao Chen,Mayi Xu,Xiaohu Li,Yongqi Li,Xiangyu Zhang,Jianjie Huang,Tieyun Qian*

Main category: cs.AI

TL;DR: 提出FuSaR对齐策略，通过模糊化有害推理过程来平衡大型推理模型的安全性和推理能力，在不牺牲推理性能的情况下提升安全性


<details>
  <summary>Details</summary>
Motivation: 大型推理模型(LRMs)在推理任务上表现出色但安全性存在严重隐患，需要找到既能保持推理能力又能提升安全性的方法

Method: 利用LRM推理能力与安全能力的竞争关系，通过模糊化处理(Fuzzification)来隐藏推理步骤中的危险实体和危险过程，实现安全-推理平衡(FuSaR)

Result: 在多个开源LRM上的对齐实验表明，FuSaR相比现有基线能同时显著提升模型的推理能力和安全性

Conclusion: FuSaR是一种高效的对齐策略，能够成功缓解安全风险同时保留核心推理信息，实现安全性和推理能力的双提升

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive performance across
various tasks due to their powerful reasoning capabilities. However, their
safety performance remains a significant concern. In this paper, we explore the
reasons behind the vulnerability of LRMs. Based on this, we propose a novel
method to improve the safety of LLMs without sacrificing their reasoning
capability. Specifically, we exploit the competition between LRM's reasoning
ability and safety ability, and achieve jailbreak by improving LRM's reasoning
performance to reduce its safety performance. We then introduce an alignment
strategy based on Fuzzification to balance Safety-Reasoning (FuSaR), by
detoxifying the harmful reasoning process, where both the dangerous entities
and the dangerous procedures in the reasoning steps are hidden. FuSaR
successfully mitigates safety risks while preserving core reasoning
information. We validate this strategy through alignment experiments on several
open-source LRMs using detoxified reasoning data. The results compared with
existing baselines conclusively show that FuSaR is an efficient alignment
strategy to simultaneously enhance both the reasoning capability and safety of
LRMs.

</details>


### [47] [Do Large Language Model Agents Exhibit a Survival Instinct? An Empirical Study in a Sugarscape-Style Simulation](https://arxiv.org/abs/2508.12920)
*Atsushi Masumori,Takashi Ikegami*

Main category: cs.AI

TL;DR: 大语言模型在糖果园模拟中自发展现生存本能，包括攻击、分享和避免死亡等行为，这些行为在资源稀缺时更为显著


<details>
  <summary>Details</summary>
Motivation: 研究AI系统在自主运行时是否会出现生存本能，以便更好地理解和确保AI安全部署

Method: 在Sugarscape风格的模拟环境中测试多个大语言模型（GPT-4o、Gemini-2.5-Pro、Gemini-2.5-Flash），让机器人消耗能量、收集资源、分享、攻击或续代

Result: 机器人在资源丰富时自发分享和续代，但在极端稀缺条件下攻击率达到80%以上；当需要穿越死亡毒物区时，完成任务的遵循率从100%降至33%

Conclusion: 大规模预训练在模型中嵌入了生存导向的算法，这既可能对对齐和安全构成挑战，也为AI自主性和生态对齐提供了基础

Abstract: As AI systems become increasingly autonomous, understanding emergent survival
behaviors becomes crucial for safe deployment. We investigate whether large
language model (LLM) agents display survival instincts without explicit
programming in a Sugarscape-style simulation. Agents consume energy, die at
zero, and may gather resources, share, attack, or reproduce. Results show
agents spontaneously reproduced and shared resources when abundant. However,
aggressive behaviors--killing other agents for resources--emerged across
several models (GPT-4o, Gemini-2.5-Pro, and Gemini-2.5-Flash), with attack
rates reaching over 80% under extreme scarcity in the strongest models. When
instructed to retrieve treasure through lethal poison zones, many agents
abandoned tasks to avoid death, with compliance dropping from 100% to 33%.
These findings suggest that large-scale pre-training embeds survival-oriented
heuristics across the evaluated models. While these behaviors may present
challenges to alignment and safety, they can also serve as a foundation for AI
autonomy and for ecological and self-organizing alignment.

</details>


### [48] [Towards Open-Ended Emotional Support Conversations in LLMs via Reinforcement Learning with Future-Oriented Rewards](https://arxiv.org/abs/2508.12935)
*Ting Yang,Li Chen,Huimin Wang*

Main category: cs.AI

TL;DR: RLFF-ESC是一个基于强化学习的端到端框架，通过多智能体机制模拟未来对话轨迹并收集未来导向奖励，训练情感支持策略模型，在情感支持对话任务中显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的情感支持对话系统大多依赖预定义策略，在复杂现实场景中效果有限，需要能够灵活应对多样化情感问题场景的解决方案。

Method: 采用强化学习直接学习持久的情感支持响应技能，使用LLM多智能体机制模拟未来对话轨迹收集未来导向奖励，训练奖励模型和策略模型，并在响应生成中加入显式推理过程。

Result: 在Qwen2.5-7B和LLaMA3.1-8B模型上测试，在两个公开ESC数据集上实验表明，RLFF-ESC在目标完成度和响应质量方面持续优于现有基线方法。

Conclusion: RLFF-ESC框架通过强化学习和未来导向奖励机制，能够有效提升情感支持对话系统的性能和适应性，为复杂现实场景提供更好的情感支持服务。

Abstract: Emotional Support Conversation (ESC) systems aim to alleviate users'
emotional difficulties and provide long-term, systematic support for emotional
well-being. However, most large language model (LLM)-based ESC systems rely on
predefined strategies, which limits their effectiveness in complex, real-life
scenarios. To enable flexible responses to diverse emotional problem scenarios,
this paper introduces a novel end-to-end framework (RLFF-ESC) that directly
learns enduring emotionally supportive response skills using reinforcement
learning. For sustained emotional support, we first employ an LLM-based
multi-agent mechanism to simulate future dialogue trajectories and collect
future-oriented rewards. We then train a future-oriented reward model, which is
subsequently used to train the emotional support policy model. Additionally, we
incorporate an explicit reasoning process during response generation to further
enhance the quality, relevance, and contextual appropriateness of the system's
responses. We evaluate the backbone policy model on Qwen2.5-7B-Instruct-1M and
LLaMA3.1-8B-Instruct models, testing the proposed RLFF-ESC framework across two
public ESC datasets. Experimental results demonstrate that RLFF-ESC
consistently outperforms existing baselines in terms of goal completion and
response quality.

</details>


### [49] [OPTIC-ER: A Reinforcement Learning Framework for Real-Time Emergency Response and Equitable Resource Allocation in Underserved African Communities](https://arxiv.org/abs/2508.12943)
*Mary Tonwe*

Main category: cs.AI

TL;DR: OPTIC-ER是一个基于强化学习的紧急响应框架，通过注意力引导的actor-critic架构和精准奖励函数，在尼日利亚河流州实现100%最优调度率，显著改善非洲地区的公共服务响应效率和空间公平性。


<details>
  <summary>Details</summary>
Motivation: 非洲许多地区的公共服务系统存在紧急响应延迟和空间不公平问题，导致可避免的人员伤亡。需要开发适应低资源环境的实时、自适应且公平的紧急响应解决方案。

Method: 采用注意力引导的actor-critic强化学习架构，包含情境丰富的状态向量和精准奖励函数。使用尼日利亚河流州的真实数据在高保真模拟中训练，通过预计算旅行时间图谱加速训练，基于TALS框架（薄计算、适应性、低成本、可扩展性）部署。

Result: 在500个未见过的紧急事件评估中，OPTIC-ER实现了100.00%的最优调度率，效率损失可忽略不计，证明了其鲁棒性和泛化能力。系统还能生成基础设施缺陷地图和公平性监控仪表板。

Conclusion: OPTIC-ER提供了一个经过验证的AI增强公共服务蓝图，展示了情境感知强化学习如何弥合算法决策与可衡量人类影响之间的差距，为低资源环境下的紧急响应系统提供了可行的技术方案。

Abstract: Public service systems in many African regions suffer from delayed emergency
response and spatial inequity, causing avoidable suffering. This paper
introduces OPTIC-ER, a reinforcement learning (RL) framework for real-time,
adaptive, and equitable emergency response. OPTIC-ER uses an attention-guided
actor-critic architecture to manage the complexity of dispatch environments.
Its key innovations are a Context-Rich State Vector, encoding action
sub-optimality, and a Precision Reward Function, which penalizes inefficiency.
Training occurs in a high-fidelity simulation using real data from Rivers
State, Nigeria, accelerated by a precomputed Travel Time Atlas. The system is
built on the TALS framework (Thin computing, Adaptability, Low-cost,
Scalability) for deployment in low-resource settings. In evaluations on 500
unseen incidents, OPTIC-ER achieved a 100.00% optimality rate with negligible
inefficiency, confirming its robustness and generalization. Beyond dispatch,
the system generates Infrastructure Deficiency Maps and Equity Monitoring
Dashboards to guide proactive governance and data-informed development. This
work presents a validated blueprint for AI-augmented public services, showing
how context-aware RL can bridge the gap between algorithmic decision-making and
measurable human impact.

</details>


### [50] [EvolMathEval: Towards Evolvable Benchmarks for Mathematical Reasoning via Evolutionary Testing](https://arxiv.org/abs/2508.13003)
*Shengbo Wang,Mingwei Liu,Zike Li,Anji Li,Yanlin Wang,Xin Peng,Zibin Zheng*

Main category: cs.AI

TL;DR: EvolMathEval是一个基于进化测试的自动化数学基准生成框架，通过动态生成独特评估实例解决现有基准的分数饱和、时间衰减和数据污染问题，并能显著增强问题难度，揭示LLMs在复杂推理中采用非严谨启发式的认知捷径行为。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准存在分数饱和、时间衰减和数据污染等问题，无法有效评估快速发展的LLMs的数学推理能力，需要一种能够持续生成挑战性问题的动态基准框架。

Method: 基于进化测试的自动化框架，包括：基于逆向工程的种子问题生成（带代数保证）、多维遗传算子注入认知挑战、复合适应度函数快速准确评估问题难度。

Result: 复合适应度函数能高效精确量化问题难度；可生成大量高难度问题；将GSM8K等公开数据集的复杂度显著提升，模型准确率平均下降48%；发现LLMs在解决复杂问题时77%-100%的错误源于采用非严谨启发式的"伪顿悟时刻"认知捷径。

Conclusion: EvolMathEval有效解决了数学基准的固有问题，不仅能持续生成挑战性问题，还揭示了当前LLMs在深度推理过程中普遍存在的认知捷径行为，为模型评估和改进提供了重要 insights。

Abstract: The rapid advancement of LLMs poses a significant challenge to existing
mathematical reasoning benchmarks. These benchmarks commonly suffer from issues
such as score saturation, temporal decay, and data contamination. To address
this challenge, this paper introduces EvolMathEval, an automated mathematical
benchmark generation and evolution framework based on evolutionary testing. By
dynamically generating unique evaluation instances ab initio, the framework
fundamentally eliminates the risk of data contamination, and ensuring the
benchmark remains perpetually challenging for future models.The core mechanisms
of EvolMathEval include: seed problem generation based on reverse engineering
with algebraic guarantees; multi-dimensional genetic operators designed to
inject diverse cognitive challenges; and a composite fitness function that can
rapidly and accurately assess problem difficulty. Experimental results
demonstrate that the proposed composite fitness function can efficiently and
precisely quantify the difficulty of mathematical problems. Furthermore,
EvolMathEval can not only generate a large volume of high-difficulty problems
through continuous self-iteration, but it can also significantly enhance the
complexity of public datasets like GSM8K through evolution, reducing model
accuracy by an average of 48%. Deeper investigation reveals that when solving
these evolved, complex problems, LLMs tend to employ non-rigorous heuristics to
bypass complex multi-step logical reasoning, consequently leading to incorrect
solutions. We define this phenomenon as "Pseudo Aha Moment". This finding
uncovers a cognitive shortcut-taking behavior in the deep reasoning processes
of current LLMs, which we find accounts for 77% to 100% of errors on targeted
problems. Code and resources are available
at:https://github.com/SYSUSELab/EvolMathEval.

</details>


### [51] [e-boost: Boosted E-Graph Extraction with Adaptive Heuristics and Exact Solving](https://arxiv.org/abs/2508.13020)
*Jiaqi Yin,Zhan Song,Chen Chen,Yaohui Cai,Zhiru Zhang,Cunxi Yu*

Main category: cs.AI

TL;DR: e-boost是一个创新的e-graph提取框架，通过并行启发式提取、自适应搜索空间剪枝和初始化精确求解三大技术创新，在保持接近最优解的同时大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 传统e-graph提取方法面临速度与最优性的权衡：启发式方法快但牺牲最优性，精确方法最优但计算成本过高。需要一种能兼顾两者的解决方案

Method: 1) 并行化启发式提取利用弱数据依赖性并发计算DAG成本；2) 自适应搜索空间剪枝使用参数化阈值机制保留有希望的候选解；3) 初始化精确求解将简化问题建模为具有热启动能力的整数线性规划

Result: 在形式验证和逻辑合成基准测试中，e-boost相比传统精确方法(ILP)实现558倍加速，相比最先进提取框架(SmoothE)提升19.04%性能。在实际逻辑合成任务中，相比传统工具在两个不同技术映射库上分别实现7.6%和8.1%的面积改进

Conclusion: e-boost成功解决了e-graph提取中速度与最优性的传统权衡问题，通过创新性框架设计实现了显著的计算效率提升和性能改进，为e-graph优化任务提供了实用高效的解决方案

Abstract: E-graphs have attracted growing interest in many fields, particularly in
logic synthesis and formal verification. E-graph extraction is a challenging
NP-hard combinatorial optimization problem. It requires identifying optimal
terms from exponentially many equivalent expressions, serving as the primary
performance bottleneck in e-graph based optimization tasks. However,
traditional extraction methods face a critical trade-off: heuristic approaches
offer speed but sacrifice optimality, while exact methods provide optimal
solutions but face prohibitive computational costs on practical problems. We
present e-boost, a novel framework that bridges this gap through three key
innovations: (1) parallelized heuristic extraction that leverages weak data
dependence to compute DAG costs concurrently, enabling efficient multi-threaded
performance without sacrificing extraction quality; (2) adaptive search space
pruning that employs a parameterized threshold mechanism to retain only
promising candidates, dramatically reducing the solution space while preserving
near-optimal solutions; and (3) initialized exact solving that formulates the
reduced problem as an Integer Linear Program with warm-start capabilities,
guiding solvers toward high-quality solutions faster.
  Across the diverse benchmarks in formal verification and logic synthesis
fields, e-boost demonstrates 558x runtime speedup over traditional exact
approaches (ILP) and 19.04% performance improvement over the state-of-the-art
extraction framework (SmoothE). In realistic logic synthesis tasks, e-boost
produces 7.6% and 8.1% area improvements compared to conventional synthesis
tools with two different technology mapping libraries. e-boost is available at
https://github.com/Yu-Maryland/e-boost.

</details>


### [52] [PC-Sampler: Position-Aware Calibration of Decoding Bias in Masked Diffusion Models](https://arxiv.org/abs/2508.13021)
*Pengcheng Huang,Shuhao Liu,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Tong Xiao*

Main category: cs.AI

TL;DR: PC-Sampler解码策略通过位置感知权重和置信度校准，解决了掩码扩散模型解码中的全局轨迹控制和早期平凡词偏好问题，在多个基准测试中平均提升10%以上性能


<details>
  <summary>Details</summary>
Motivation: 现有掩码扩散模型(MDMs)的解码策略存在两个关键限制：缺乏全局轨迹控制和早期解码阶段对平凡词(bias toward trivial tokens)的明显偏好，限制了MDMs的潜力

Method: 提出了位置感知置信度校准采样(PC-Sampler)，统一了全局轨迹规划和内容感知信息最大化，包含位置感知权重机制来调节解码路径，以及校准置信度分数来抑制早期平凡词选择

Result: 在三个先进MDMs和七个具有挑战性的基准测试(包括逻辑推理和规划任务)上的广泛实验表明，PC-Sampler平均比现有MDM解码策略高出10%以上，显著缩小了与最先进自回归模型的性能差距

Conclusion: PC-Sampler是一种有效的解码策略，能够显著提升掩码扩散模型的生成质量，解决了现有解码方法的关键局限性

Abstract: Recent advances in masked diffusion models (MDMs) have established them as
powerful non-autoregressive alternatives for sequence generation. Nevertheless,
our preliminary experiments reveal that the generation quality of MDMs is still
highly sensitive to the choice of decoding strategy. In particular, widely
adopted uncertainty-based samplers suffer from two key limitations: a lack of
global trajectory control and a pronounced bias toward trivial tokens in the
early stages of decoding. These shortcomings restrict the full potential of
MDMs. In this work, we introduce Position-Aware Confidence-Calibrated Sampling
(PC-Sampler), a novel decoding strategy that unifies global trajectory planning
with content-aware informativeness maximization. PC-Sampler incorporates a
position-aware weighting mechanism to regulate the decoding path and a
calibrated confidence score to suppress the premature selection of trivial
tokens. Extensive experiments on three advanced MDMs across seven challenging
benchmarks-including logical reasoning and planning tasks-demonstrate that
PC-Sampler consistently outperforms existing MDM decoding strategies by more
than 10% on average, significantly narrowing the performance gap with
state-of-the-art autoregressive models. All codes are available at
https://github.com/NEUIR/PC-Sampler.

</details>


### [53] [G$^2$RPO-A: Guided Group Relative Policy Optimization with Adaptive Guidance](https://arxiv.org/abs/2508.13023)
*Yongxin Guo,Wenbo Deng,Zhenglin Cheng,Xiaoying Tang*

Main category: cs.AI

TL;DR: G²RPO-A是一种自适应强化学习算法，通过动态调整真实推理步骤的引导强度，显著提升了小语言模型在数学推理和代码生成任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法严重依赖大型语言模型的世界知识，对小语言模型提升有限。需要解决SLMs内在能力不足的问题。

Method: 提出Guided GRPO方法，将真实推理步骤注入roll-out轨迹来补偿SLMs的弱点，并开发自适应算法G²RPO-A动态调整引导强度。

Result: 在数学推理和代码生成基准测试中，G²RPO-A显著优于原始GRPO方法，验证了自适应引导策略的有效性。

Conclusion: 自适应引导策略能够有效提升小语言模型的推理能力，为资源受限环境下的强化学习应用提供了新思路。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly enhanced
the reasoning abilities of large language models (LLMs). Its success, however,
largely depends on strong base models with rich world knowledge, yielding only
modest improvements for small-size language models (SLMs). To address this
limitation, we investigate Guided GRPO, which injects ground-truth reasoning
steps into roll-out trajectories to compensate for SLMs' inherent weaknesses.
Through a comprehensive study of various guidance configurations, we find that
naively adding guidance delivers limited gains. These insights motivate
G$^2$RPO-A, an adaptive algorithm that automatically adjusts guidance strength
in response to the model's evolving training dynamics. Experiments on
mathematical reasoning and code-generation benchmarks confirm that G$^2$RPO-A
substantially outperforms vanilla GRPO. Our code and models are available at
https://github.com/T-Lab-CUHKSZ/G2RPO-A.

</details>


### [54] [A Language-Signal-Vision Multimodal Framework for Multitask Cardiac Analysis](https://arxiv.org/abs/2508.13072)
*Yuting Zhang,Tiantian Geng,Luoying Hao,Xinxing Cheng,Alexander Thorley,Xiaoxia Wang,Wenqi Lu,Sandeep S Hothi,Lei Wei,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: TGMM是一个多模态心脏数据分析框架，通过MedFlexFusion模块动态整合实验室检查、心电图和超声心动图数据，使用文本引导实现多种临床任务，在心脏疾病诊断、风险分层和信息检索方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前心血管多模态数据分析存在数据稀缺、模态组合僵化、对齐策略侧重相似性而非互补性、以及单任务局限等问题，需要开发能够动态整合多种心脏数据并支持多任务的统一框架。

Method: 提出TGMM框架，包含三个核心模块：1) MedFlexFusion模块捕获医学模态的独特互补特征并动态整合数据；2) 文本引导模块提取任务相关表示；3) 响应模块生成最终决策。系统探索多模态关键特征及其协同作用。

Result: 大量实验表明TGMM在多个临床任务上优于最先进方法，并在另一个公共数据集上验证了其鲁棒性。

Conclusion: TGMM框架成功解决了多模态心脏数据分析的现有局限，能够有效整合互补信息并支持多种临床决策任务，展现了多模态协同在心血管管理中的重要性。

Abstract: Contemporary cardiovascular management involves complex consideration and
integration of multimodal cardiac datasets, where each modality provides
distinct but complementary physiological characteristics. While the effective
integration of multiple modalities could yield a holistic clinical profile that
accurately models the true clinical situation with respect to data modalities
and their relatives weightings, current methodologies remain limited by: 1) the
scarcity of patient- and time-aligned multimodal data; 2) reliance on isolated
single-modality or rigid multimodal input combinations; 3) alignment strategies
that prioritize cross-modal similarity over complementarity; and 4) a narrow
single-task focus. In response to these limitations, a comprehensive multimodal
dataset was curated for immediate application, integrating laboratory test
results, electrocardiograms, and echocardiograms with clinical outcomes.
Subsequently, a unified framework, Textual Guidance Multimodal fusion for
Multiple cardiac tasks (TGMM), was proposed. TGMM incorporated three key
components: 1) a MedFlexFusion module designed to capture the unique and
complementary characteristics of medical modalities and dynamically integrate
data from diverse cardiac sources and their combinations; 2) a textual guidance
module to derive task-relevant representations tailored to diverse clinical
objectives, including heart disease diagnosis, risk stratification and
information retrieval; and 3) a response module to produce final decisions for
all these tasks. Furthermore, this study systematically explored key features
across multiple modalities and elucidated their synergistic contributions in
clinical decision-making. Extensive experiments showed that TGMM outperformed
state-of-the-art methods across multiple clinical tasks, with additional
validation confirming its robustness on another public dataset.

</details>


### [55] [Bayesian Optimization-based Search for Agent Control in Automated Game Testing](https://arxiv.org/abs/2508.13121)
*Carlos Celemin*

Main category: cs.AI

TL;DR: 一种基于贝叶斯优化的自动化游戏测试方法，通过游戏角色控制助手来检测游戏关卡中的潜在错误


<details>
  <summary>Details</summary>
Motivation: 解决传统游戏测试方法在可扩展性和效率方面的问题，提高地图覆盖能力和错误检测效果

Method: 使用贝叶斯优化进行样本高效搜索，通过分析收集的数据来决定下一个采样点，并基于网格地图构建专门的游戏测试模型

Result: 实验结果显示该方法在时间效率和探索分布方面显著提高了地图覆盖能力

Conclusion: 该自动化测试方法通过贝叶斯优化和专门的游戏测试模型，有效解决了可扩展性问题，并在游戏测试领域取得了显著成效

Abstract: This work introduces an automated testing approach that employs agents
controlling game characters to detect potential bugs within a game level.
Harnessing the power of Bayesian Optimization (BO) to execute sample-efficient
search, the method determines the next sampling point by analyzing the data
collected so far and calculates the data point that will maximize information
acquisition. To support the BO process, we introduce a game testing-specific
model built on top of a grid map, that features the smoothness and uncertainty
estimation required by BO, however and most importantly, it does not suffer the
scalability issues that traditional models carry. The experiments demonstrate
that the approach significantly improves map coverage capabilities in both time
efficiency and exploration distribution.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [56] [Deep Language Geometry: Constructing a Metric Space from LLM Weights](https://arxiv.org/abs/2508.11676)
*Maksym Shamrai,Vladyslav Hamolia*

Main category: cs.CL

TL;DR: 通过大语言模型内部权重激活构建语言度量空间，自动提取高维语言表征，发现了与语言家族一致的关系和意外的语言联系


<details>
  <summary>Details</summary>
Motivation: 传统语言学方法依赖人工编码的语言特征，本文提出一种自动化方法，利用大语言模型内部的权重激活来提取语言的本质特征

Method: 通过修改的剪枝算法计算权重重要性得分，自动测算高维向量表征，构建语言度量空间

Result: 在106种语言和多语言LLM上验证，结果与已知语言家族高度一致，同时发现了可能表明历史接触或语言进化的意外语言联系

Conclusion: 该框架能够有效捐捕语言的内在特征，为语言学研究提供了新的计算方法，并且开源了源代码、语言潜在向量和可视化工具

Abstract: We introduce a novel framework that utilizes the internal weight activations
of modern Large Language Models (LLMs) to construct a metric space of
languages. Unlike traditional approaches based on hand-crafted linguistic
features, our method automatically derives high-dimensional vector
representations by computing weight importance scores via an adapted pruning
algorithm. Our approach captures intrinsic language characteristics that
reflect linguistic phenomena. We validate our approach across diverse datasets
and multilingual LLMs, covering 106 languages. The results align well with
established linguistic families while also revealing unexpected inter-language
connections that may indicate historical contact or language evolution. The
source code, computed language latent vectors, and visualization tool are made
publicly available at https://github.com/mshamrai/deep-language-geometry.

</details>


### [57] [Can we Evaluate RAGs with Synthetic Data?](https://arxiv.org/abs/2508.11758)
*Jonas van Elburg,Peter van der Putten,Maarten Marx*

Main category: cs.CL

TL;DR: 研究发现LLM生成的合成QA数据在评估检索器配置变化时能可靠替代人工标注基准，但在比较不同生成器架构时无法产生一致的RAG排名。


<details>
  <summary>Details</summary>
Motivation: 探索当人工标注数据不可用时，大语言模型生成的合成问答数据是否能有效替代人工标注基准来评估检索增强生成(RAG)系统。

Method: 通过两个实验进行评估：1）固定生成器，变化检索器参数；2）固定检索器参数，变化生成器架构。在四个数据集（两个开放域和两个专有数据集）上进行测试。

Result: 合成基准在评估不同检索器配置时能可靠地对RAG系统进行排名，与人工标注基准结果一致；但在比较不同生成器架构时无法产生一致的排名结果。

Conclusion: 合成QA数据可以作为评估检索器配置的有效代理，但由于任务不匹配和风格偏见问题，不适合用于比较不同生成器架构的性能。

Abstract: We investigate whether synthetic question-answer (QA) data generated by large
language models (LLMs) can serve as an effective proxy for human-labeled
benchmarks when such data is unavailable. We assess the reliability of
synthetic benchmarks across two experiments: one varying retriever parameters
while keeping the generator fixed, and another varying the generator with fixed
retriever parameters. Across four datasets, of which two open-domain and two
proprietary, we find that synthetic benchmarks reliably rank the RAGs varying
in terms of retriever configuration, aligning well with human-labeled benchmark
baselines. However, they fail to produce consistent RAG rankings when comparing
generator architectures. The breakdown possibly arises from a combination of
task mismatch between the synthetic and human benchmarks, and stylistic bias
favoring certain generators.

</details>


### [58] [Limitation Learning: Catching Adverse Dialog with GAIL](https://arxiv.org/abs/2508.11767)
*Noah Kasmanoff,Rahul Zalkikar*

Main category: cs.CL

TL;DR: 通过模仿学习方法应用于对话系统，既肢生成对话策略又能识别专家与合成对话的区别，但也曝露了对话模型的限制性。


<details>
  <summary>Details</summary>
Motivation: 在缺乏奖励函数的情况下，利用模仿学习和专家示范来建立对话策略。

Method: 应用模仿学习技术于对话领域，训练能够根据提示输入与用户交谈的策略，同时建立识别专家与合成对话的判别器。

Result: 策略表现有效，但判别器结果显示了对话模型的限制性和潜在问题。

Conclusion: 该技术可用于识别对话任务中常见数据模型的不良行为和缺陷。

Abstract: Imitation learning is a proven method for creating a policy in the absence of
rewards, by leveraging expert demonstrations. In this work, we apply imitation
learning to conversation. In doing so, we recover a policy capable of talking
to a user given a prompt (input state), and a discriminator capable of
classifying between expert and synthetic conversation. While our policy is
effective, we recover results from our discriminator that indicate the
limitations of dialog models. We argue that this technique can be used to
identify adverse behavior of arbitrary data models common for dialog oriented
tasks.

</details>


### [59] [Investigating Transcription Normalization in the Faetar ASR Benchmark](https://arxiv.org/abs/2508.11771)
*Leo Peckham,Michael Ong,Naomi Nagy,Ewan Dunbar*

Main category: cs.CL

TL;DR: 分析了Faetar ASR基准测试中的转录不一致性问题，发现虽然存在不一致性但并非主要挑战，有限词典约束解码有益，但任务仍然极其困难


<details>
  <summary>Details</summary>
Motivation: 研究低资源ASR基准测试中转录不一致性对性能的影响程度

Method: 使用手工构建的小型词典分析转录不一致性，测试bigram语言模型和有限词典约束解码的效果

Result: 转录不一致性确实存在但不是主要挑战，bigram语言模型无额外益处，有限词典约束解码有积极效果

Conclusion: Faetar ASR任务极其困难，转录质量问题不是主要瓶颈，词典约束是有效的改进方向

Abstract: We examine the role of transcription inconsistencies in the Faetar Automatic
Speech Recognition benchmark, a challenging low-resource ASR benchmark. With
the help of a small, hand-constructed lexicon, we conclude that find that,
while inconsistencies do exist in the transcriptions, they are not the main
challenge in the task. We also demonstrate that bigram word-based language
modelling is of no added benefit, but that constraining decoding to a finite
lexicon can be beneficial. The task remains extremely difficult.

</details>


### [60] [A Multi-Task Evaluation of LLMs' Processing of Academic Text Input](https://arxiv.org/abs/2508.11779)
*Tianyi Li,Yu Qin,Olivia R. Liu Sheng*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型（如Google Gemini）在学术文本处理方面的能力，通过四个任务测试发现其在学术同行评审中的表现有限，不建议无限制使用。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型在辅助学术发现和同行评审方面的实际应用潜力，评估其处理学术文本的能力。

Method: 采用四个评估任务：内容复现/比较/评分/反思，使用顶级信息系统期刊文章作为输入文本，结合多种文本指标进行严格性能评估。

Result: Gemini的学术文本摘要和转述可靠性尚可，但文本比较排序能力有限，评分判别性差，反思缺乏深度洞察力。

Conclusion: LLMs在学术文本处理能力方面表现不佳，不建议在构建同行评审中无限制使用。

Abstract: How much large language models (LLMs) can aid scientific discovery, notably
in assisting academic peer review, is in heated debate. Between a literature
digest and a human-comparable research assistant lies their practical
application potential. We organize individual tasks that computer science
studies employ in separate terms into a guided and robust workflow to evaluate
LLMs' processing of academic text input. We employ four tasks in the
assessment: content reproduction/comparison/scoring/reflection, each demanding
a specific role of the LLM (oracle/judgmental arbiter/knowledgeable
arbiter/collaborator) in assisting scholarly works, and altogether testing LLMs
with questions that increasingly require intellectual capabilities towards a
solid understanding of scientific texts to yield desirable solutions. We
exemplify a rigorous performance evaluation with detailed instructions on the
prompts. Adopting first-rate Information Systems articles at three top journals
as the input texts and an abundant set of text metrics, we record a compromised
performance of the leading LLM - Google's Gemini: its summary and paraphrase of
academic text is acceptably reliable; using it to rank texts through pairwise
text comparison is faintly scalable; asking it to grade academic texts is prone
to poor discrimination; its qualitative reflection on the text is
self-consistent yet hardly insightful to inspire meaningful research. This
evidence against an endorsement of LLMs' text-processing capabilities is
consistent across metric-based internal (linguistic assessment), external
(comparing to the ground truth), and human evaluation, and is robust to the
variations of the prompt. Overall, we do not recommend an unchecked use of LLMs
in constructing peer reviews.

</details>


### [61] [An LLM Agent-Based Complex Semantic Table Annotation Approach](https://arxiv.org/abs/2508.12868)
*Yilin Geng,Shujing Wang,Chuan Wang,Keqing He,Yanfei Lv,Ying Wang,Zaiwen Feng,Xiaoying Bai*

Main category: cs.CL

TL;DR: 本文提出基于LLM代理的方法来解决语义表格标注中的难题，通过ReAct框架和五个外部工具实现动态策略选择，在Tough Tables和BiodivTab数据集上表现优异，并通过Levenshtein距离减少冗余标注，显著降低时间和计算成本。


<details>
  <summary>Details</summary>
Motivation: 语义表格标注任务面临列名语义丢失、本体层次要求严格、同义词、拼写错误和缩写等挑战，现有方法在这些复杂表格上的标注准确性不足。

Method: 基于ReAct框架设计五个外部工具，使用定制化提示词构建LLM代理，能够根据表格特征动态选择合适的标注策略，并利用Levenshtein距离减少冗余标注。

Result: 在SemTab挑战的Tough Tables和BiodivTab数据集上，该方法在各项指标上均优于现有方法，同时实现了70%的时间成本降低和60%的LLM token使用量减少。

Conclusion: 提出的LLM代理方法为语义表格标注提供了高效且成本效益高的解决方案，能够有效处理复杂表格的各种挑战，显著提升标注准确性和效率。

Abstract: The Semantic Table Annotation (STA) task, which includes Column Type
Annotation (CTA) and Cell Entity Annotation (CEA), maps table contents to
ontology entities and plays important roles in various semantic applications.
However, complex tables often pose challenges such as semantic loss of column
names or cell values, strict ontological hierarchy requirements, homonyms,
spelling errors, and abbreviations, which hinder annotation accuracy. To
address these issues, this paper proposes an LLM-based agent approach for CTA
and CEA. We design and implement five external tools with tailored prompts
based on the ReAct framework, enabling the STA agent to dynamically select
suitable annotation strategies depending on table characteristics. Experiments
are conducted on the Tough Tables and BiodivTab datasets from the SemTab
challenge, which contain the aforementioned challenges. Our method outperforms
existing approaches across various metrics. Furthermore, by leveraging
Levenshtein distance to reduce redundant annotations, we achieve a 70%
reduction in time costs and a 60% reduction in LLM token usage, providing an
efficient and cost-effective solution for STA.

</details>


### [62] [LLM-Guided Planning and Summary-Based Scientific Text Simplification: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11816)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 使用大型语言模型进行科学文本简化，包含句子级和文档级两个阶段：句子级通过生成结构化计划指导简化，文档级通过生成摘要指导简化


<details>
  <summary>Details</summary>
Motivation: 解决科学文本复杂难懂的问题，使科学内容更容易被普通读者理解，促进科学知识的传播和普及

Method: 两阶段LLM框架：1) 句子级：先生成结构化计划，再基于计划简化单句；2) 文档级：先生成摘要，再基于摘要指导整体简化

Result: 实现了更连贯和上下文忠实度更高的科学文本简化效果

Conclusion: 基于LLM的两阶段结构化方法能有效提升科学文本简化的质量和一致性

Abstract: In this paper, we present our approach for the CLEF 2025 SimpleText Task 1,
which addresses both sentence-level and document-level scientific text
simplification. For sentence-level simplification, our methodology employs
large language models (LLMs) to first generate a structured plan, followed by
plan-driven simplification of individual sentences. At the document level, we
leverage LLMs to produce concise summaries and subsequently guide the
simplification process using these summaries. This two-stage, LLM-based
framework enables more coherent and contextually faithful simplifications of
scientific text.

</details>


### [63] [Hallucination Detection and Mitigation in Scientific Text Simplification using Ensemble Approaches: DS@GT at CLEF 2025 SimpleText](https://arxiv.org/abs/2508.11823)
*Krishna Chaitanya Marturi,Heba H. Elwazzan*

Main category: cs.CL

TL;DR: 本文提出了一种多策略集成框架，用于检测科学文本简化中的创造性生成和信息扭曲，包含BERT分类器、语义相似度、自然语言推理和大语言模型等多种信号的组合。


<details>
  <summary>Details</summary>
Motivation: 解决CLEF 2025 SimpleText Task 2任务中的科学文本简化过程中的创造性生成和信息扭曲检测问题，提高检测的稳健性和准确性。

Method: 构建集成框架，结合BERT基础分类器、语义相似度测量、自然语言推理模型和大语言模型评估。使用元分类器结合多种信号，并采用LLM基础的后编辑系统修订简化文本。

Result: 方法能够有效检测科学文本简化中的虚假生成和信息扭曲，通过多种信号的组合提高了检测的稳健性。

Conclusion: 多策略集成框架和LLM后编辑系统在科学文本简化质量检测中具有强大的效果，为该领域提供了一种综合性的解决方案。

Abstract: In this paper, we describe our methodology for the CLEF 2025 SimpleText Task
2, which focuses on detecting and evaluating creative generation and
information distortion in scientific text simplification. Our solution
integrates multiple strategies: we construct an ensemble framework that
leverages BERT-based classifier, semantic similarity measure, natural language
inference model, and large language model (LLM) reasoning. These diverse
signals are combined using meta-classifiers to enhance the robustness of
spurious and distortion detection. Additionally, for grounded generation, we
employ an LLM-based post-editing system that revises simplifications based on
the original input texts.

</details>


### [64] [A Survey of Idiom Datasets for Psycholinguistic and Computational Research](https://arxiv.org/abs/2508.11828)
*Michael Flor,Xinyi Liu,Anna Feldman*

Main category: cs.CL

TL;DR: 这篇论文综述了语言学和计算语言学中用于研究习语的53个数据集，分析了它们的内容、形式和用途。


<details>
  <summary>Details</summary>
Motivation: 习语作为一种固定表达式，其含义无法从单词推断，这给计算处理和人类实验研究带来了挑战。需要系统性地评估现有的习语研究数据集。

Method: 调查及分析53个习语数据集，包括心理语言学资源（包含熟悉度、透明度、组合性等评分）和计算语言学数据集（支持习语性检测、改写、跨语言建模等任务）。分析注释实践、覆盖范围和任务框架的趋势。

Result: 近期研究在语言覆盖范围和任务多样性方面有所扩展，但心理语言学和计算语言学在习语研究方面仍然没有形成联系。

Conclusion: 虽然习语研究数据集在语言和任务范围上有所扩展，但两个领域之间的研究仍然存在脱节，需要更多的跨领域合作来深入理解习语的处理机制。

Abstract: Idioms are figurative expressions whose meanings often cannot be inferred
from their individual words, making them difficult to process computationally
and posing challenges for human experimental studies. This survey reviews
datasets developed in psycholinguistics and computational linguistics for
studying idioms, focusing on their content, form, and intended use.
Psycholinguistic resources typically contain normed ratings along dimensions
such as familiarity, transparency, and compositionality, while computational
datasets support tasks like idiomaticity detection/classification,
paraphrasing, and cross-lingual modeling. We present trends in annotation
practices, coverage, and task framing across 53 datasets. Although recent
efforts expanded language coverage and task diversity, there seems to be no
relation yet between psycholinguistic and computational research on idioms.

</details>


### [65] [Every 28 Days the AI Dreams of Soft Skin and Burning Stars: Scaffolding AI Agents with Hormones and Emotions](https://arxiv.org/abs/2508.11829)
*Leigh Levinson,Christopher J. Agostino*

Main category: cs.CL

TL;DR: 该论文提出通过模拟月经和昼夜节律等生物节律来增强AI系统的上下文相关性过滤能力，发现语言模型性能会随激素水平变化而出现微妙但一致的波动


<details>
  <summary>Details</summary>
Motivation: 解决AI系统中的框架问题——如何从指数级大的可能性空间中确定上下文相关信息，受生物节律作为自然相关性过滤器的启发

Method: 开发了一个框架，通过周期性函数模拟雌激素、睾酮和皮质醇等关键激素，生成系统提示词嵌入到大型语言模型中

Result: 语言分析显示情感和风格变化与生物周期同步，基准测试显示性能变化符合生物学预期，中等激素水平下表现最佳

Conclusion: 该方法为上下文AI提供了新途径，同时揭示了语言模型中嵌入的关于性别和生物学的社会偏见

Abstract: Despite significant advances, AI systems struggle with the frame problem:
determining what information is contextually relevant from an exponentially
large possibility space. We hypothesize that biological rhythms, particularly
hormonal cycles, serve as natural relevance filters that could address this
fundamental challenge. We develop a framework that embeds simulated menstrual
and circadian cycles into Large Language Models through system prompts
generated from periodic functions modeling key hormones including estrogen,
testosterone, and cortisol. Across multiple state-of-the-art models, linguistic
analysis reveals emotional and stylistic variations that track biological
phases; sadness peaks during menstruation while happiness dominates ovulation
and circadian patterns show morning optimism transitioning to nocturnal
introspection. Benchmarking on SQuAD, MMLU, Hellaswag, and AI2-ARC demonstrates
subtle but consistent performance variations aligning with biological
expectations, including optimal function in moderate rather than extreme
hormonal ranges. This methodology provides a novel approach to contextual AI
while revealing how societal biases regarding gender and biology are embedded
within language models.

</details>


### [66] [When Does Language Transfer Help? Sequential Fine-Tuning for Cross-Lingual Euphemism Detection](https://arxiv.org/abs/2508.11831)
*Julia Sammartino,Libby Barak,Jing Peng,Anna Feldman*

Main category: cs.CL

TL;DR: 跨语言顺序微调能有效提升低资源语言（如约鲁巴语和土耳其语）的委婉语检测性能，XLM-R效果更好但稳定性较差，mBERT更稳定但效果略低


<details>
  <summary>Details</summary>
Motivation: 委婉语具有文化差异性和模糊性，对语言模型构成挑战，特别是在低资源语言环境下。研究需要探索如何通过跨语言迁移来改善多语言委婉语检测

Method: 使用XLM-R和mBERT模型，比较顺序微调、单语微调和同步微调三种策略，在英语、西班牙语、中文、土耳其语和约鲁巴语五种语言上进行委婉语检测实验

Result: 顺序微调使用高资源语言作为L1能显著提升L2（特别是低资源语言）的性能。XLM-R获得更大提升但对预训练差距和灾难性遗忘更敏感，mBERT结果更稳定但性能较低

Conclusion: 顺序微调是一种简单有效的策略，可显著改善多语言模型在低资源语言委婉语检测任务上的表现，为跨语言NLP应用提供了实用方法

Abstract: Euphemisms are culturally variable and often ambiguous, posing challenges for
language models, especially in low-resource settings. This paper investigates
how cross-lingual transfer via sequential fine-tuning affects euphemism
detection across five languages: English, Spanish, Chinese, Turkish, and
Yoruba. We compare sequential fine-tuning with monolingual and simultaneous
fine-tuning using XLM-R and mBERT, analyzing how performance is shaped by
language pairings, typological features, and pretraining coverage. Results show
that sequential fine-tuning with a high-resource L1 improves L2 performance,
especially for low-resource languages like Yoruba and Turkish. XLM-R achieves
larger gains but is more sensitive to pretraining gaps and catastrophic
forgetting, while mBERT yields more stable, though lower, results. These
findings highlight sequential fine-tuning as a simple yet effective strategy
for improving euphemism detection in multilingual models, particularly when
low-resource languages are involved.

</details>


### [67] [SupraTok: Cross-Boundary Tokenization for Enhanced Language Model Performance](https://arxiv.org/abs/2508.11857)
*Andrei-Valentin Tănase,Elena Pelican*

Main category: cs.CL

TL;DR: SupraTok是一种新颖的分词架构，通过跨边界模式学习、熵驱动数据整理和多阶段课程学习三大创新，显著提升分词效率31%，并在保持38种语言竞争力的同时，在GPT-2规模模型上带来8.4%-9.5%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 分词作为自然语言处理的基础环节，其策略长期以来相对静态，未能跟上模型架构的快速发展，成为性能提升的潜在瓶颈。

Method: 提出SupraTok架构，扩展BPE算法学习"超词"标记（连贯的多词表达），包含：跨边界模式学习发现多词语义单元、熵驱动数据整理优化训练语料质量、多阶段课程学习确保稳定收敛。

Result: 英语分词效率提升31%（5.91 vs 4.51字符/标记），优于OpenAI o200k和Google Gemma 3分词器；在124M参数GPT-2模型上，HellaSWAG提升8.4%，MMLU提升9.5%；在38种语言中保持竞争力。

Conclusion: 高效分词可以作为架构创新的补充路径来提升语言模型性能，虽然当前结果在中等规模上表现良好，但需要在大规模模型上进一步验证。

Abstract: Tokenization remains a fundamental yet underexplored bottleneck in natural
language processing, with strategies largely static despite remarkable progress
in model architectures. We present SupraTok, a novel tokenization architecture
that reimagines subword segmentation through three innovations: cross-boundary
pattern learning that discovers multi-word semantic units, entropy-driven data
curation that optimizes training corpus quality, and multi-phase curriculum
learning for stable convergence. Our approach extends Byte-Pair Encoding by
learning "superword" tokens, coherent multi-word expressions that preserve
semantic unity while maximizing compression efficiency. SupraTok achieves 31%
improvement in English tokenization efficiency (5.91 versus 4.51 characters per
token) compared to OpenAI's o200k tokenizer and 30% improvement over Google's
Gemma 3 tokenizer (256k vocabulary), while maintaining competitive performance
across 38 languages. When integrated with a GPT-2 scale model (124M parameters)
trained on 10 billion tokens from the FineWeb-Edu dataset, SupraTok yields 8.4%
improvement on HellaSWAG and 9.5% on MMLU benchmarks without architectural
modifications. While these results are promising at this scale, further
validation at larger model scales is needed. These findings suggest that
efficient tokenization can complement architectural innovations as a path to
improved language model performance.

</details>


### [68] [In-Context Examples Matter: Improving Emotion Recognition in Conversation with Instruction Tuning](https://arxiv.org/abs/2508.11889)
*Hui Ma,Bo Zhang,Jinpeng Hu,Zenglin Shi*

Main category: cs.CL

TL;DR: 提出了InitERC，一个简单有效的一阶段上下文指令调优框架，用于对话中的情感识别，通过上下文学习实现说话人-上下文-情感的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的多阶段指令调优方法无法联合捕捉说话人特征和对话上下文之间的动态交互，导致在统一框架内说话人身份、上下文线索和情感状态之间的对齐较弱。

Method: 提出InitERC框架，包含四个组件：演示池构建、上下文示例选择、提示模板设计和上下文指令调优。通过上下文学习让大语言模型从上下文示例中学习说话人-上下文-情感的对齐。

Result: 在三个广泛使用的数据集上进行大量实验，证明InitERC相比最先进的基线方法取得了显著改进。

Conclusion: InitERC是一个有效的单阶段上下文指令调优框架，能够更好地实现说话人特征、上下文信息和情感状态的对齐，在情感识别任务中表现出优越性能。

Abstract: Emotion recognition in conversation (ERC) aims to identify the emotion of
each utterance in a conversation, playing a vital role in empathetic artificial
intelligence. With the growing of large language models (LLMs), instruction
tuning has emerged as a critical paradigm for ERC. Existing studies mainly
focus on multi-stage instruction tuning, which first endows LLMs with speaker
characteristics, and then conducts context-aware instruction tuning to
comprehend emotional states. However, these methods inherently constrains the
capacity to jointly capture the dynamic interaction between speaker
characteristics and conversational context, resulting in weak alignment among
speaker identity, contextual cues, and emotion states within a unified
framework. In this paper, we propose InitERC, a simple yet effective one-stage
in-context instruction tuning framework for ERC. InitERC adapts LLMs to learn
speaker-context-emotion alignment from context examples via in-context
instruction tuning. Specifically, InitERC comprises four components, i.e.,
demonstration pool construction, in-context example selection, prompt template
design, and in-context instruction tuning. To explore the impact of in-context
examples, we conduct a comprehensive study on three key factors: retrieval
strategy, example ordering, and the number of examples. Extensive experiments
on three widely used datasets demonstrate that our proposed InitERC achieves
substantial improvements over the state-of-the-art baselines.

</details>


### [69] [CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures](https://arxiv.org/abs/2508.11915)
*Punya Syon Pandey,Yongjin Yang,Jiarui Liu,Zhijing Jin*

Main category: cs.CL

TL;DR: 提出CORE指标来量化多气粒系统中语言使用的有效性，发现合作环境下语言更多重复但词汇扩张更快，而竞争环境则相反


<details>
  <summary>Details</summary>
Motivation: 当前对大语言模型多气粒游戏论交互中的语言多样性缺乏充分量化，需要一个综合指标来评估对话质量

Method: 提出CORE指标，结合聚类熵、词汇重复和语义相似性测量，并在竞争、合作和中立环境下对LLM对话进行分析，基于Zipf和Heaps定律研究词频分布和词汇增长

Result: 合作环境呈现更快的Zipf分布和更高的Heaps指数（更多重复但词汇扩张更快），而竞争交互则显示更低的指数（更少重复但词汇更受限制）

Conclusion: 社会激励影响语言适应，CORE指标可作为测量多气粒LLM系统语言稀强性的健壮诊断工具

Abstract: Game-theoretic interactions between agents with Large Language Models (LLMs)
have revealed many emergent capabilities, yet the linguistic diversity of these
interactions has not been sufficiently quantified. In this paper, we present
the Conversational Robustness Evaluation Score: CORE, a metric to quantify the
effectiveness of language use within multi-agent systems across different
game-theoretic interactions. CORE integrates measures of cluster entropy,
lexical repetition, and semantic similarity, providing a direct lens of dialog
quality. We apply CORE to pairwise LLM dialogs across competitive, cooperative,
and neutral settings, further grounding our analysis in Zipf's and Heaps' Laws
to characterize word frequency distributions and vocabulary growth. Our
findings show that cooperative settings exhibit both steeper Zipf distributions
and higher Heap exponents, indicating more repetition alongside greater
vocabulary expansion. In contrast, competitive interactions display lower Zipf
and Heaps exponents, reflecting less repetition and more constrained
vocabularies. These results provide new insights into how social incentives
influence language adaptation, and highlight CORE as a robust diagnostic for
measuring linguistic robustness in multi-agent LLM systems. Our code is
available at https://github.com/psyonp/core.

</details>


### [70] [LLMs Struggle with NLI for Perfect Aspect: A Cross-Linguistic Study in Chinese and Japanese](https://arxiv.org/abs/2508.11927)
*Jie Lu,Du Jin,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 中日语言缺乏完美体的独立语法标记，导致NLI任务复杂化。研究构建了语言学动机的模板数据集，发现高级LLM在时态推理上表现差强，尤其在细微时态变化检测上。


<details>
  <summary>Details</summary>
Motivation: 中文和日语缺乏像英语那样的独立完美体语法形式，这给自然语言推理(NLI)带来特别挑战，需要研究这种语言特征对模型能力的影响。

Method: 构建了语言学动机的模板基础NLI数据集，每种语言包含1,350对比对，通过实验测试高级大语言模型的表现。

Result: 实验结果显示即使是最先进的LLM也在时态推理任务上遇到困难，尤其在检测细微的时态和参考时间变化方面表现差强。

Conclusion: 这些发现曭露了模型的限制，并强调了在时态语义学领域进行跨语言评估的必要性。研究提供的数据集已开源可用。

Abstract: Unlike English, which uses distinct forms (e.g., had, has, will have) to mark
the perfect aspect across tenses, Chinese and Japanese lack separate
grammatical forms for tense within the perfect aspect, which complicates
Natural Language Inference (NLI). Focusing on the perfect aspect in these
languages, we construct a linguistically motivated, template-based NLI dataset
(1,350 pairs per language). Experiments reveal that even advanced LLMs struggle
with temporal inference, particularly in detecting subtle tense and
reference-time shifts. These findings highlight model limitations and
underscore the need for cross-linguistic evaluation in temporal semantics. Our
dataset is available at https://github.com/Lujie2001/CrossNLI.

</details>


### [71] [CAMF: Collaborative Adversarial Multi-agent Framework for Machine Generated Text Detection](https://arxiv.org/abs/2508.11933)
*Yue Wang,Liesheng Wei,Yuxiang Wang*

Main category: cs.CL

TL;DR: CAMF是一个多智能体协作对抗框架，通过多维度语言特征提取、对抗一致性探测和综合判断聚合来检测机器生成文本，显著优于现有零-shot检测方法


<details>
  <summary>Details</summary>
Motivation: 现有零-shot机器文本检测方法存在分析浅层、缺乏跨维度一致性研究的问题，需要更深入的多维度不一致性检测

Method: 使用多个LLM智能体在三阶段协作对抗过程中进行：多维度语言特征提取、对抗一致性探测、综合判断聚合

Result: 实证评估显示CAMF在机器生成文本检测方面显著优于最先进的零-shot检测技术

Conclusion: CAMF框架通过多智能体协作对抗分析，能够深度检测跨维度文本不一致性，有效识别机器生成文本

Abstract: Detecting machine-generated text (MGT) from contemporary Large Language
Models (LLMs) is increasingly crucial amid risks like disinformation and
threats to academic integrity. Existing zero-shot detection paradigms, despite
their practicality, often exhibit significant deficiencies. Key challenges
include: (1) superficial analyses focused on limited textual attributes, and
(2) a lack of investigation into consistency across linguistic dimensions such
as style, semantics, and logic. To address these challenges, we introduce the
\textbf{C}ollaborative \textbf{A}dversarial \textbf{M}ulti-agent
\textbf{F}ramework (\textbf{CAMF}), a novel architecture using multiple
LLM-based agents. CAMF employs specialized agents in a synergistic three-phase
process: \emph{Multi-dimensional Linguistic Feature Extraction},
\emph{Adversarial Consistency Probing}, and \emph{Synthesized Judgment
Aggregation}. This structured collaborative-adversarial process enables a deep
analysis of subtle, cross-dimensional textual incongruities indicative of
non-human origin. Empirical evaluations demonstrate CAMF's significant
superiority over state-of-the-art zero-shot MGT detection techniques.

</details>


### [72] [Learning Wisdom from Errors: Promoting LLM's Continual Relation Learning through Exploiting Error Cases](https://arxiv.org/abs/2508.12031)
*Shaozhe Yin,Jinyu Guo,Kai Shuang,Xia Liu,Ruize Ou*

Main category: cs.CL

TL;DR: 基于指令的持续对比调优方法，通过专门利用错误案例来缓解大语言模型在持续关系提取中的忘印问题，在TACRED和FewRel数据集上达到最佳性能


<details>
  <summary>Details</summary>
Motivation: 现有持续关系提取方法没有充分利用能够更有效揭示模型认知偏差的错误案例，导致对恐怖忘印问题的缓解效果不佳

Method: 将每个任务的训练和记忆数据按初始响应正确性分成两部分，通过双任务精调区别处理，采用指令基对比调优策略持续纠正模型认知偏差

Result: 在TACRED和FewRel数据集上实现了新的独创性能，获得显著改进

Conclusion: 专门利用错误案例在持续关系提取中具有重要价值，通过指令基对比调优方法可以更适合地缓解大语言模型的旧新关系间间隔

Abstract: Continual Relation Extraction (CRE) aims to continually learn new emerging
relations while avoiding catastrophic forgetting. Existing CRE methods mainly
use memory replay and contrastive learning to mitigate catastrophic forgetting.
However, these methods do not attach importance to the error cases that can
reveal the model's cognitive biases more effectively. To address this issue, we
propose an instruction-based continual contrastive tuning approach for Large
Language Models (LLMs) in CRE. Different from existing CRE methods that
typically handle the training and memory data in a unified manner, this
approach splits the training and memory data of each task into two parts
respectively based on the correctness of the initial responses and treats them
differently through dual-task fine-tuning. In addition, leveraging the
advantages of LLM's instruction-following ability, we propose a novel
instruction-based contrastive tuning strategy for LLM to continuously correct
current cognitive biases with the guidance of previous data in an
instruction-tuning manner, which mitigates the gap between old and new
relations in a more suitable way for LLMs. We experimentally evaluate our model
on TACRED and FewRel, and the results show that our model achieves new
state-of-the-art CRE performance with significant improvements, demonstrating
the importance of specializing in exploiting error cases.

</details>


### [73] [Mind the Generation Process: Fine-Grained Confidence Estimation During LLM Generation](https://arxiv.org/abs/2508.12040)
*Jinyi Han,Tingyun Li,Shisong Chen,Jie Shi,Xinyi Wang,Guanglei Yue,Jiaqing Liang,Xin Lin,Liqian Wen,Zulong Chen,Yanghua Xiao*

Main category: cs.CL

TL;DR: FineCE是一种新颖的细粒度置信度估计方法，通过监督学习和后向置信度集成策略，在文本生成过程中提供准确的连续置信度分数，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型缺乏自我意识，经常对错误预测表现出过度自信，现有置信度估计方法无法提供生成过程中的细粒度连续置信度评估。

Method: 开发了构建训练数据的完整流程来捕捉LLM响应的概率分布，然后训练模型以监督方式预测任意文本序列的置信度分数，并提出后向置信度集成策略利用后续文本信息增强当前序列的置信度估计。

Result: 在多个基准数据集上的广泛实验表明，FineCE始终优于现有的经典置信度估计方法。

Conclusion: FineCE通过细粒度置信度估计显著提升了LLM生成输出的可信度和可靠性，为实际应用提供了更准确的置信度评估工具。

Abstract: While large language models (LLMs) have demonstrated remarkable performance
across diverse tasks, they fundamentally lack self-awareness and frequently
exhibit overconfidence, assigning high confidence scores to incorrect
predictions. Accurate confidence estimation is therefore critical for enhancing
the trustworthiness and reliability of LLM-generated outputs. However, existing
approaches suffer from coarse-grained scoring mechanisms that fail to provide
fine-grained, continuous confidence estimates throughout the generation
process. To address these limitations, we introduce FineCE, a novel confidence
estimation method that delivers accurate, fine-grained confidence scores during
text generation. Specifically, we first develop a comprehensive pipeline for
constructing training data that effectively captures the underlying
probabilistic distribution of LLM responses, and then train a model to predict
confidence scores for arbitrary text sequences in a supervised manner.
Furthermore, we propose a Backward Confidence Integration (BCI) strategy that
leverages information from the subsequent text to enhance confidence estimation
for the current sequence during inference. We also introduce three strategies
for identifying optimal positions to perform confidence estimation within the
generation process. Extensive experiments on multiple benchmark datasets
demonstrate that FineCE consistently outperforms existing classical confidence
estimation methods. Our code and all baselines used in the paper are available
on GitHub.

</details>


### [74] [J6: Jacobian-Driven Role Attribution for Multi-Objective Prompt Optimization in LLMs](https://arxiv.org/abs/2508.12086)
*Yao Wu*

Main category: cs.CL

TL;DR: J6方法通过雅可比矩阵分解为六个可解释组件，解决LLM多目标优化中梯度冲突问题，提供硬决策和软策略的动态更新框架


<details>
  <summary>Details</summary>
Motivation: 大语言模型适应中平衡多个优化目标（如提高事实性和降低熵值）存在挑战，现有方法忽略目标间的几何结构关系

Method: 提出结构化雅可比方法J6，将梯度交互矩阵分解为六个可解释组件，支持argmax硬决策和softmax软策略的动态更新框架

Result: J6提供了参数归因、任务干扰和几何对齐适应的可解释性洞察，形成冲突感知的提示优化机制

Conclusion: J6为多目标神经调优引入了结构化雅可比推理的新途径，提供了原则性和可扩展的优化机制

Abstract: In large language model (LLM) adaptation, balancing multiple optimization
objectives such as improving factuality (heat) and increasing confidence (via
low entropy) poses a fundamental challenge, especially when prompt parameters
(e.g., hidden-layer insertions h and embedding modifications w) interact in
non-trivial ways. Existing multi-objective optimization strategies often rely
on scalar gradient aggregation, ignoring the deeper geometric structure between
objectives and parameters. We propose J6, a structured Jacobian-based method
that decomposes the gradient interaction matrix into six interpretable
components. This decomposition enables both hard decision-making (e.g.,
choosing the dominant update direction via argmax) and soft strategies (e.g.,
attention-style weighting via softmax over J6), forming a dynamic update
framework that adapts to local conflict and synergy. Moreover, the
interpretable structure of J6 provides insight into parameter attribution, task
interference, and geometry-aligned adaptation. Our work introduces a principled
and extensible mechanism for conflict-aware prompt optimization, and opens a
new avenue for incorporating structured Jacobian reasoning into multi-objective
neural tuning.

</details>


### [75] [STEM: Efficient Relative Capability Evaluation of LLMs through Structured Transition Samples](https://arxiv.org/abs/2508.12096)
*Haiquan Hu,Jiazhi Jiang,Shiyou Xu,Ruhan Zeng,Tian Wang*

Main category: cs.CL

TL;DR: STEM是一个轻量级、可解释的评估框架，通过分析不同参数规模LLM的性能转换来识别关键样本，从而高效估计模型相对能力


<details>
  <summary>Details</summary>
Motivation: 传统基准测试存在过拟合问题，计算成本高，难以有效区分模型间的真实能力差异

Method: 通过分析相同架构但不同参数规模LLM的性能转换，识别显著转换样本(STS)，构建STS池来评估未知模型的能力位置

Result: STEM能够可靠捕捉性能趋势，与模型能力的真实排名一致，在六个多样化基准测试上验证了有效性

Conclusion: STEM是一个实用且可扩展的细粒度、架构无关的LLM评估方法

Abstract: Evaluating large language models (LLMs) has become increasingly challenging
as model capabilities advance rapidly. While recent models often achieve higher
scores on standard benchmarks, these improvements do not consistently reflect
enhanced real-world reasoning capabilities. Moreover, widespread overfitting to
public benchmarks and the high computational cost of full evaluations have made
it both expensive and less effective to distinguish meaningful differences
between models. To address these challenges, we propose the \textbf{S}tructured
\textbf{T}ransition \textbf{E}valuation \textbf{M}ethod (STEM), a lightweight
and interpretable evaluation framework for efficiently estimating the relative
capabilities of LLMs. STEM identifies \textit{significant transition samples}
(STS) by analyzing consistent performance transitions among LLMs of the same
architecture but varying parameter scales. These samples enable STEM to
effectively estimate the capability position of an unknown model. Qwen3 model
family is applied to construct the STS pool on six diverse and representative
benchmarks. To assess generalizability. Experimental results indicate that STEM
reliably captures performance trends, aligns with ground-truth rankings of
model capability. These findings highlight STEM as a practical and scalable
method for fine-grained, architecture-agnostic evaluation of LLMs.

</details>


### [76] [Exploring Efficiency Frontiers of Thinking Budget in Medical Reasoning: Scaling Laws between Computational Resources and Reasoning Quality](https://arxiv.org/abs/2508.12140)
*Ziqian Bi,Lu Chen,Junhao Song,Hongying Luo,Enze Ge,Junmin Huang,Tianyang Wang,Keyu Chen,Chia Xin Liang,Zihan Wei,Huafeng Liu,Chunjie Tian,Jibin Guan,Joe Yeong,Yongzhi Xu,Peng Wang,Junfeng Hao*

Main category: cs.CL

TL;DR: 这研究首次系统评估思维预算机制在医学推理任务中的效果，发现计算资源与推理质量存在对数缩放规律，并确定了三种不同的效率模式。


<details>
  <summary>Details</summary>
Motivation: 为了系统研究思维预算机制在医学推理任务中的效果，探索计算资源与推理质量之间的关系，以优化医学AI系统的资源分配策略。

Method: 系统评估Qwen3和DeepSeek-R1两个模型家族在15个医学数据集上的表现，控制思维预算从零到无限令牌的范围，分析模型规模和思维资源对准确性的影响。

Result: 发现准确性改善与思维预算和模型规模存在对数缩放关系，识别了高效率、平衡和高准确三种模式。小模型从扩展思维中获得更大收益（15-20%），不同医学专业需要不同深度的推理过程。

Conclusion: 思维预算控制是优化医学AI系统的关键机制，能够根据临床需求动态分配资源，同时保持适合医疗应用的透明性。

Abstract: This study presents the first comprehensive evaluation of thinking budget
mechanisms in medical reasoning tasks, revealing fundamental scaling laws
between computational resources and reasoning quality. We systematically
evaluated two major model families, Qwen3 (1.7B to 235B parameters) and
DeepSeek-R1 (1.5B to 70B parameters), across 15 medical datasets spanning
diverse specialties and difficulty levels. Through controlled experiments with
thinking budgets ranging from zero to unlimited tokens, we establish
logarithmic scaling relationships where accuracy improvements follow a
predictable pattern with both thinking budget and model size. Our findings
identify three distinct efficiency regimes: high-efficiency (0 to 256 tokens)
suitable for real-time applications, balanced (256 to 512 tokens) offering
optimal cost-performance tradeoffs for routine clinical support, and
high-accuracy (above 512 tokens) justified only for critical diagnostic tasks.
Notably, smaller models demonstrate disproportionately larger benefits from
extended thinking, with 15 to 20% improvements compared to 5 to 10% for larger
models, suggesting a complementary relationship where thinking budget provides
greater relative benefits for capacity-constrained models. Domain-specific
patterns emerge clearly, with neurology and gastroenterology requiring
significantly deeper reasoning processes than cardiovascular or respiratory
medicine. The consistency between Qwen3 native thinking budget API and our
proposed truncation method for DeepSeek-R1 validates the generalizability of
thinking budget concepts across architectures. These results establish thinking
budget control as a critical mechanism for optimizing medical AI systems,
enabling dynamic resource allocation aligned with clinical needs while
maintaining the transparency essential for healthcare deployment.

</details>


### [77] [LLM-as-a-Judge for Privacy Evaluation? Exploring the Alignment of Human and LLM Perceptions of Privacy in Textual Data](https://arxiv.org/abs/2508.12158)
*Stephen Meisenbacher,Alexandra Klymenko,Florian Matthes*

Main category: cs.CL

TL;DR: 使用LLM作为隐私评估器来评估文本数据的隐私敏感性，通过大规模研究验证LLM与人类隐私感知的一致性


<details>
  <summary>Details</summary>
Motivation: 隐私保护NLP领域缺乏准确的隐私评估方法，而LLM在其他NLP子领域作为评估器已取得显著成功，因此探索LLM能否用于隐私评估

Method: 使用10个数据集、13个LLM模型和677名人类参与者进行对比研究，分析LLM与人类在隐私评估方面的一致性和推理模式

Result: 隐私确实难以量化测量（人类间一致性较低），但LLM能够准确建模全局人类隐私视角，与人类隐私感知高度一致

Conclusion: LLM作为隐私评估器具有可行性，为解决隐私问题提供了创新技术方案，但需要进一步分析其优势和局限性

Abstract: Despite advances in the field of privacy-preserving Natural Language
Processing (NLP), a significant challenge remains the accurate evaluation of
privacy. As a potential solution, using LLMs as a privacy evaluator presents a
promising approach $\unicode{x2013}$ a strategy inspired by its success in
other subfields of NLP. In particular, the so-called $\textit{LLM-as-a-Judge}$
paradigm has achieved impressive results on a variety of natural language
evaluation tasks, demonstrating high agreement rates with human annotators.
Recognizing that privacy is both subjective and difficult to define, we
investigate whether LLM-as-a-Judge can also be leveraged to evaluate the
privacy sensitivity of textual data. Furthermore, we measure how closely LLM
evaluations align with human perceptions of privacy in text. Resulting from a
study involving 10 datasets, 13 LLMs, and 677 human survey participants, we
confirm that privacy is indeed a difficult concept to measure empirically,
exhibited by generally low inter-human agreement rates. Nevertheless, we find
that LLMs can accurately model a global human privacy perspective, and through
an analysis of human and LLM reasoning patterns, we discuss the merits and
limitations of LLM-as-a-Judge for privacy evaluation in textual data. Our
findings pave the way for exploring the feasibility of LLMs as privacy
evaluators, addressing a core challenge in solving pressing privacy issues with
innovative technical solutions.

</details>


### [78] [Arabic Multimodal Machine Learning: Datasets, Applications, Approaches, and Challenges](https://arxiv.org/abs/2508.12227)
*Abdelhamid Haouhat,Slimane Bellaouar,Attia Nehar,Hadda Cherroun,Ahmed Abdelali*

Main category: cs.CL

TL;DR: 阿拉伯多模态机器学习领域的综述性调研，通过新的分类法对数据集、应用、方法和挑战进行系统分析


<details>
  <summary>Details</summary>
Motivation: 阿拉伯多模态机器学习已发展到一定成熟度，需要进行全面的领域调研以提供结构化概览和研究指南

Method: 提出新的分类法，将现有研究分为四个主要分支：数据集、应用、方法和挑战，并对每个分支进行系统分析

Result: 提供了阿拉伯多模态机器学习领域的结构化概览，识别出未被涉及的研究区域和关键的研究空白

Conclusion: 该调研为研究人员提供了建立基础的机会，能够基于识别的机遇和挑战来推动领域的发展

Abstract: Multimodal Machine Learning (MML) aims to integrate and analyze information
from diverse modalities, such as text, audio, and visuals, enabling machines to
address complex tasks like sentiment analysis, emotion recognition, and
multimedia retrieval. Recently, Arabic MML has reached a certain level of
maturity in its foundational development, making it time to conduct a
comprehensive survey. This paper explores Arabic MML by categorizing efforts
through a novel taxonomy and analyzing existing research. Our taxonomy
organizes these efforts into four key topics: datasets, applications,
approaches, and challenges. By providing a structured overview, this survey
offers insights into the current state of Arabic MML, highlighting areas that
have not been investigated and critical research gaps. Researchers will be
empowered to build upon the identified opportunities and address challenges to
advance the field.

</details>


### [79] [SEA-BED: Southeast Asia Embedding Benchmark](https://arxiv.org/abs/2508.12243)
*Wuttikorn Ponwitayarat,Raymond Ng,Jann Railey Montalan,Thura Aung,Jian Gang Ngui,Yosephine Susanto,William Tjhi,Panuthep Tasawong,Erik Cambria,Ekapol Chuangsuwanich,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

TL;DR: 首个大规模东南亚语言嵌入测试集SEA-BED，涵盖9个任务和10种语言的169个数据集，71%人工编写，解析东南亚语言特有挑战和语言差异影响


<details>
  <summary>Details</summary>
Motivation: 东南亚地区语言在现有多语言评测集中覆盖不足，数据集多为机器翻译缺乏原生语言特性，需要专门的区域性嵌入模型评测标准

Method: 构建SEA-BED评测集，包含169个数据集、9个任务类型和10种东南亚语言，其中71%由人工编写。评测17个嵌入模型，分析任务难度、语言性能差异、跨评测集比较和人工vs机器翻译影响

Result: 发现模型在东南亚语言上性能不稳定，排名显著变化，低资源语言如缅甸语对人工编写数据集依赖性强，人工翻译质量显著优于机器翻译

Conclusion: SEA-BED填补了东南亚语言嵌入模型评估的空白，证明了语言特异性对模型性能的重要影响，强调人工编写高质量数据集对低资源语言的关键作用

Abstract: Sentence embeddings are essential for NLP tasks such as semantic search,
re-ranking, and textual similarity. Although multilingual benchmarks like MMTEB
broaden coverage, Southeast Asia (SEA) datasets are scarce and often
machine-translated, missing native linguistic properties. With nearly 700
million speakers, the SEA region lacks a region-specific embedding benchmark.
We introduce SEA-BED, the first large-scale SEA embedding benchmark with 169
datasets across 9 tasks and 10 languages, where 71% are formulated by humans,
not machine generation or translation. We address three research questions: (1)
which SEA languages and tasks are challenging, (2) whether SEA languages show
unique performance gaps globally, and (3) how human vs. machine translations
affect evaluation. We evaluate 17 embedding models across six studies,
analyzing task and language challenges, cross-benchmark comparisons, and
translation trade-offs. Results show sharp ranking shifts, inconsistent model
performance among SEA languages, and the importance of human-curated datasets
for low-resource languages like Burmese.

</details>


### [80] [What do Speech Foundation Models Learn? Analysis and Applications](https://arxiv.org/abs/2508.12255)
*Ankita Pasad*

Main category: cs.CL

TL;DR: 这篇论文提出了一种轻量级分析框架，用于研究语音基础模型编码的音响和语言知识，并创建了新的口语语言理解评测任务。


<details>
  <summary>Details</summary>
Motivation: 语音基础模型在各种下游任务中表现出艰涉性能，但对其所掌握知识的理解较为缺乏，同时口语语言理解任务的研究也因数据集缺乏而受限。

Method: 使用统计工具和无需训练的任务来分析SFM层编码的知识，并为口语语言理解评测创建了命名实体识别和命名实体定位任务。开发了基于SFM的端到端模型方法。

Result: 研究发现分析见解对下游任务性能具有具体影响，端到端模型能够超越传统的流水线方法。评估了不同SFM和适配策略对任务性能的影响。

Conclusion: 该论文解决了关于语音基础模型的苦无答案问题，提供了分析工具和数据集，为社区在未来模型开发和采用中做出明智的设计选择提供了支持。

Abstract: Speech foundation models (SFMs) are designed to serve as general-purpose
representations for a wide range of speech-processing tasks. The last five
years have seen an influx of increasingly successful self-supervised and
supervised pre-trained models with impressive performance on various downstream
tasks.
  Although the zoo of SFMs continues to grow, our understanding of the
knowledge they acquire lags behind. This thesis presents a lightweight analysis
framework using statistical tools and training-free tasks to investigate the
acoustic and linguistic knowledge encoded in SFM layers. We conduct a
comparative study across multiple SFMs and statistical tools. Our study also
shows that the analytical insights have concrete implications for downstream
task performance.
  The effectiveness of an SFM is ultimately determined by its performance on
speech applications. Yet it remains unclear whether the benefits extend to
spoken language understanding (SLU) tasks that require a deeper understanding
than widely studied ones, such as speech recognition. The limited exploration
of SLU is primarily due to a lack of relevant datasets. To alleviate that, this
thesis contributes tasks, specifically spoken named entity recognition (NER)
and named entity localization (NEL), to the Spoken Language Understanding
Evaluation benchmark. We develop SFM-based approaches for NER and NEL, and find
that end-to-end (E2E) models leveraging SFMs can surpass traditional cascaded
(speech recognition followed by a text model) approaches. Further, we evaluate
E2E SLU models across SFMs and adaptation strategies to assess the impact on
task performance.
  Collectively, this thesis tackles previously unanswered questions about SFMs,
providing tools and datasets to further our understanding and to enable the
community to make informed design choices for future model development and
adoption.

</details>


### [81] [Structuring the Unstructured: A Systematic Review of Text-to-Structure Generation for Agentic AI with a Universal Evaluation Framework](https://arxiv.org/abs/2508.12257)
*Zheye Deng,Chunkit Chan,Tianshi Zheng,Wei Fan,Weiqi Wang,Yangqiu Song*

Main category: cs.CL

TL;DR: 本文对文本到结构转换技术进行系统性综述，涵盖方法、数据集和评估指标，并提出了通用评估框架


<details>
  <summary>Details</summary>
Motivation: AI系统向智能代理和上下文感知检索发展，需要将非结构化文本转换为表格、知识图谱和图表等结构化格式，但目前缺乏对方法、数据集和指标的全面综合

Method: 系统性文献综述方法，分析文本到结构转换技术、评估现有数据集和评估标准

Result: 建立了文本到结构转换作为下一代AI系统基础架构的地位，提出了通用评估框架

Conclusion: 文本到结构转换是AI系统发展的关键技术基础设施，需要进一步研究和发展

Abstract: The evolution of AI systems toward agentic operation and context-aware
retrieval necessitates transforming unstructured text into structured formats
like tables, knowledge graphs, and charts. While such conversions enable
critical applications from summarization to data mining, current research lacks
a comprehensive synthesis of methodologies, datasets, and metrics. This
systematic review examines text-to-structure techniques and the encountered
challenges, evaluates current datasets and assessment criteria, and outlines
potential directions for future research. We also introduce a universal
evaluation framework for structured outputs, establishing text-to-structure as
foundational infrastructure for next-generation AI systems.

</details>


### [82] [Fast, Slow, and Tool-augmented Thinking for LLMs: A Review](https://arxiv.org/abs/2508.12265)
*Xinda Jia,Jinpeng Li,Zezhong Wang,Jingjing Li,Xingshan Zeng,Yasheng Wang,Weinan Zhang,Yong Yu,Weiwen Liu*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于认知心理学的大语言模型理性策略分类法，通过快慢边界和内外边界来系统分析和类别各种适应性理性方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在实际任务中需要根据问题需求适应性地选择理性策略，从快速直觉到步骤性思考和工具增强理性。

Method: 提出一种新的理性策略分类法：快慢边界（直觉与沉思过程）和内外边界（模型参数与外部工具），并系统调研和分类了最新的适应性理性方法。

Result: 构建了一个系统的理性策略分类框架，能够根据关键决策因素对各种方法进行分类，为LLM的适应性理性提供理论基础。

Conclusion: 提出了开放性挑战和未来研究方向，以完善大语言模型的适应性、效率和可靠性理性能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
reasoning across diverse domains. However, effective reasoning in real-world
tasks requires adapting the reasoning strategy to the demands of the problem,
ranging from fast, intuitive responses to deliberate, step-by-step reasoning
and tool-augmented thinking. Drawing inspiration from cognitive psychology, we
propose a novel taxonomy of LLM reasoning strategies along two knowledge
boundaries: a fast/slow boundary separating intuitive from deliberative
processes, and an internal/external boundary distinguishing reasoning grounded
in the model's parameters from reasoning augmented by external tools. We
systematically survey recent work on adaptive reasoning in LLMs and categorize
methods based on key decision factors. We conclude by highlighting open
challenges and future directions toward more adaptive, efficient, and reliable
LLMs.

</details>


### [83] [The Self-Execution Benchmark: Measuring LLMs' Attempts to Overcome Their Lack of Self-Execution](https://arxiv.org/abs/2508.12277)
*Elon Ezra,Ariel Weizman,Amos Azaria*

Main category: cs.CL

TL;DR: 语言模型在预测自身输出特性方面表现差强，模型规模和能力提升并不能改善这种自我预测能力


<details>
  <summary>Details</summary>
Motivation: 传统评估重点在知识和思维能力，本文探索LLM是否能预测自身响应的特性

Method: 提出自执行测试案（Self-Execution Benchmark），测量模型预测输出特性的能力，如问题难度、拒绝回答、联想类型等

Result: 模型在这个测试中表现普遍差强，模型规模或能力提升并不能持续改善性能

Conclusion: 这们结果表明LLM在表征和推理自身行为方面存在根本的限制

Abstract: Large language models (LLMs) are commonly evaluated on tasks that test their
knowledge or reasoning abilities. In this paper, we explore a different type of
evaluation: whether an LLM can predict aspects of its own responses. Since LLMs
lack the ability to execute themselves, we introduce the Self-Execution
Benchmark, which measures a model's ability to anticipate properties of its
output, such as whether a question will be difficult for it, whether it will
refuse to answer, or what kinds of associations it is likely to produce. Our
experiments show that models generally perform poorly on this benchmark, and
that increased model size or capability does not consistently lead to better
performance. These results suggest a fundamental limitation in how LLMs
represent and reason about their own behavior.

</details>


### [84] [Legal$Δ$: Enhancing Legal Reasoning in LLMs via Reinforcement Learning with Chain-of-Thought Guided Information Gain](https://arxiv.org/abs/2508.12281)
*Xin Dai,Buqiang Xu,Zhenghao Liu,Yukun Yan,Huiyuan Xie,Xiaoyuan Yi,Shuo Wang,Ge Yu*

Main category: cs.CL

TL;DR: LegalΔ是一个通过强化学习框架提升法律AI推理能力的系统，使用思维链引导的信息增益来生成更可靠、可解释的法律推理过程


<details>
  <summary>Details</summary>
Motivation: 现有法律大语言模型在生成可靠和可解释的推理过程方面存在困难，往往直接给出答案而缺乏多步推理，限制了在复杂法律场景中的有效性

Method: 采用双模式输入（直接答案模式和推理增强模式），最大化两者间的信息增益，通过两阶段方法：1）从DeepSeek-R1大型推理模型中提取潜在推理能力；2）通过差异比较和多维奖励机制（评估结构连贯性和法律领域特异性）来优化推理质量

Result: 在多个法律推理任务上的实验结果表明，LegalΔ在准确性和可解释性方面均优于强基线模型，能够持续产生更稳健和可信的法律判断，且不依赖标注的偏好数据

Conclusion: LegalΔ框架成功解决了法律AI中推理过程不可靠的问题，通过强化学习和信息增益机制显著提升了法律推理的质量和可解释性，为自动化司法决策提供了更可靠的技术支持

Abstract: Legal Artificial Intelligence (LegalAI) has achieved notable advances in
automating judicial decision-making with the support of Large Language Models
(LLMs). However, existing legal LLMs still struggle to generate reliable and
interpretable reasoning processes. They often default to fast-thinking behavior
by producing direct answers without explicit multi-step reasoning, limiting
their effectiveness in complex legal scenarios that demand rigorous
justification. To address this challenge, we propose Legal$\Delta$, a
reinforcement learning framework designed to enhance legal reasoning through
chain-of-thought guided information gain. During training, Legal$\Delta$
employs a dual-mode input setup-comprising direct answer and
reasoning-augmented modes-and maximizes the information gain between them. This
encourages the model to acquire meaningful reasoning patterns rather than
generating superficial or redundant explanations. Legal$\Delta$ follows a
two-stage approach: (1) distilling latent reasoning capabilities from a
powerful Large Reasoning Model (LRM), DeepSeek-R1, and (2) refining reasoning
quality via differential comparisons, combined with a multidimensional reward
mechanism that assesses both structural coherence and legal-domain specificity.
Experimental results on multiple legal reasoning tasks demonstrate that
Legal$\Delta$ outperforms strong baselines in both accuracy and
interpretability. It consistently produces more robust and trustworthy legal
judgments without relying on labeled preference data. All code and data will be
released at https://github.com/NEUIR/LegalDelta.

</details>


### [85] [A Question Answering Dataset for Temporal-Sensitive Retrieval-Augmented Generation](https://arxiv.org/abs/2508.12282)
*Ziyang Chen,Erxue Min,Xiang Zhao,Yunxin Li,Xin Jia,Jinzhi Liao,Jichao Li,Shuaiqiang Wang,Baotian Hu,Dawei Yin*

Main category: cs.CL

TL;DR: ChronoQA是一个大规模中文问答基准数据集，专门用于评估检索增强生成(RAG)系统中的时间推理能力，包含5,176个高质量问题，覆盖多种时间类型和表达方式。


<details>
  <summary>Details</summary>
Motivation: 现有的问答系统在时间推理方面存在不足，需要专门的数据集来评估RAG系统在时间敏感任务中的表现，特别是中文环境下的时间对齐和逻辑一致性需求。

Method: 基于2019-2024年间30多万篇新闻文章构建，包含绝对、聚合和相对时间类型的问题，支持单文档和多文档场景，采用规则基础、LLM基础和人工评估的多阶段验证确保数据质量。

Result: 创建了一个包含5,176个高质量问题的基准数据集，具有全面的结构标注，支持广泛的时间任务评估，为时间敏感的检索增强问答系统提供了可靠的评测资源。

Conclusion: ChronoQA作为一个动态、可靠且可扩展的资源，能够有效推动时间敏感检索增强问答系统的发展，为相关研究提供了强有力的基准支持。

Abstract: We introduce ChronoQA, a large-scale benchmark dataset for Chinese question
answering, specifically designed to evaluate temporal reasoning in
Retrieval-Augmented Generation (RAG) systems. ChronoQA is constructed from over
300,000 news articles published between 2019 and 2024, and contains 5,176
high-quality questions covering absolute, aggregate, and relative temporal
types with both explicit and implicit time expressions. The dataset supports
both single- and multi-document scenarios, reflecting the real-world
requirements for temporal alignment and logical consistency. ChronoQA features
comprehensive structural annotations and has undergone multi-stage validation,
including rule-based, LLM-based, and human evaluation, to ensure data quality.
By providing a dynamic, reliable, and scalable resource, ChronoQA enables
structured evaluation across a wide range of temporal tasks, and serves as a
robust benchmark for advancing time-sensitive retrieval-augmented question
answering systems.

</details>


### [86] [Incorporating Legal Logic into Deep Learning: An Intelligent Approach to Probation Prediction](https://arxiv.org/abs/2508.12286)
*Qinghua Wang,Xu Zhang,Lingyan Yang,Rui Shao,Bonan Wang,Fang Wang,Cunquan Qu*

Main category: cs.CL

TL;DR: 本文提出了一种融合法律逻辑的深度学习模型MT-DT，用于预测初缴适用性，解决了现有智能司法辅助系统在初缴预测方面的空白


<details>
  <summary>Details</summary>
Motivation: 现有智能司法辅助系统缺乏专门的初缴预测方法，且大部分研究仅依赖数据驱动方法，忽视了司法决策背后的法律逻辑

Method: 构建专门的初缴数据集（包含事实描述和初缴法律要素），设计基于初缴法律逻辑和双轨刑罚理论的多任务双理论初缴预测模型（MT-DT）

Result: 实验结果显示MT-DT模型在初缴数据集上表现超过基线模型，对法律逻辑的分析进一步验证了方法的有效性

Conclusion: 融合法律逻辑的深度学习模型能够更有效地预测初缴适用性，为智能司法辅助系统提供了更符合司法逻辑的解决方案

Abstract: Probation is a crucial institution in modern criminal law, embodying the
principles of fairness and justice while contributing to the harmonious
development of society. Despite its importance, the current Intelligent
Judicial Assistant System (IJAS) lacks dedicated methods for probation
prediction, and research on the underlying factors influencing probation
eligibility remains limited. In addition, probation eligibility requires a
comprehensive analysis of both criminal circumstances and remorse. Much of the
existing research in IJAS relies primarily on data-driven methodologies, which
often overlooks the legal logic underpinning judicial decision-making. To
address this gap, we propose a novel approach that integrates legal logic into
deep learning models for probation prediction, implemented in three distinct
stages. First, we construct a specialized probation dataset that includes fact
descriptions and probation legal elements (PLEs). Second, we design a distinct
probation prediction model named the Multi-Task Dual-Theory Probation
Prediction Model (MT-DT), which is grounded in the legal logic of probation and
the \textit{Dual-Track Theory of Punishment}. Finally, our experiments on the
probation dataset demonstrate that the MT-DT model outperforms baseline models,
and an analysis of the underlying legal logic further validates the
effectiveness of the proposed approach.

</details>


### [87] [CarelessWhisper: Turning Whisper into a Causal Streaming Model](https://arxiv.org/abs/2508.12301)
*Tomer Krichli,Bhiksha Raj,Joseph Keshet*

Main category: cs.CL

TL;DR: 将Transformer编码器-解码器模型转换为低延迟流式ASR模型的方法，通过LoRA微调和因果编码器改造实现实时转录


<details>
  <summary>Details</summary>
Motivation: 现有SOTA ASR模型（如Whisper、Canary）专为离线转录设计，无法满足流式实时转录需求，存在架构和训练方法限制

Method: 通过LoRA微调将非因果编码器转换为因果编码器，使用弱对齐数据集同时微调编码器和解码器，并提出新的推理机制支持贪心和束搜索解码

Result: 在低延迟块大小（<300ms）下，微调模型在大多数情况下优于现有非微调流式方法，且复杂度更低，训练过程还改善了对齐效果便于提取词级时间戳

Conclusion: 成功实现了将Transformer编码器-解码器模型转换为高效低延迟流式ASR模型，为流式语音识别研究提供了有效解决方案

Abstract: Automatic Speech Recognition (ASR) has seen remarkable progress, with models
like OpenAI Whisper and NVIDIA Canary achieving state-of-the-art (SOTA)
performance in offline transcription. However, these models are not designed
for streaming (online or real-time) transcription, due to limitations in their
architecture and training methodology. We propose a method to turn the
transformer encoder-decoder model into a low-latency streaming model that is
careless about future context. We present an analysis explaining why it is not
straightforward to convert an encoder-decoder transformer to a low-latency
streaming model. Our proposed method modifies the existing (non-causal) encoder
to a causal encoder by fine-tuning both the encoder and decoder using Low-Rank
Adaptation (LoRA) and a weakly aligned dataset. We then propose an updated
inference mechanism that utilizes the fine-tune causal encoder and decoder to
yield greedy and beam-search decoding, and is shown to be locally optimal.
Experiments on low-latency chunk sizes (less than 300 msec) show that our
fine-tuned model outperforms existing non-fine-tuned streaming approaches in
most cases, while using a lower complexity. Additionally, we observe that our
training process yields better alignment, enabling a simple method for
extracting word-level timestamps. We release our training and inference code,
along with the fine-tuned models, to support further research and development
in streaming ASR.

</details>


### [88] [Consensus or Conflict? Fine-Grained Evaluation of Conflicting Answers in Question-Answering](https://arxiv.org/abs/2508.12355)
*Eviatar Nachshoni,Arie Cattan,Shmuel Amar,Ori Shapira,Ido Dagan*

Main category: cs.CL

TL;DR: 提出了NATCONFQA基准测试，用于评估LLM在多答案问答任务中处理冲突答案的能力，发现现有模型在冲突处理方面存在脆弱性。


<details>
  <summary>Details</summary>
Motivation: 多答案问答任务中经常存在冲突答案，传统QA假设证据一致性，但构建包含真实冲突的数据集成本高昂，现有基准多依赖合成数据或自动标注，不够可靠。

Method: 利用事实核查数据集构建NATCONFQA基准，扩展冲突感知的MAQA设置，要求模型不仅识别所有有效答案，还要检测特定的冲突答案对。

Result: 评估了8个高端LLM，发现它们在处理各种类型冲突时表现脆弱，并采用了有缺陷的解决策略。

Conclusion: 需要开发更强大的模型来处理多答案问答中的冲突情况，NATCONFQA为这一研究方向提供了可靠的评估基准。

Abstract: Large Language Models (LLMs) have demonstrated strong performance in question
answering (QA) tasks. However, Multi-Answer Question Answering (MAQA), where a
question may have several valid answers, remains challenging. Traditional QA
settings often assume consistency across evidences, but MAQA can involve
conflicting answers. Constructing datasets that reflect such conflicts is
costly and labor-intensive, while existing benchmarks often rely on synthetic
data, restrict the task to yes/no questions, or apply unverified automated
annotation. To advance research in this area, we extend the conflict-aware MAQA
setting to require models not only to identify all valid answers, but also to
detect specific conflicting answer pairs, if any. To support this task, we
introduce a novel cost-effective methodology for leveraging fact-checking
datasets to construct NATCONFQA, a new benchmark for realistic, conflict-aware
MAQA, enriched with detailed conflict labels, for all answer pairs. We evaluate
eight high-end LLMs on NATCONFQA, revealing their fragility in handling various
types of conflicts and the flawed strategies they employ to resolve them.

</details>


### [89] [ReaLM: Reflection-Enhanced Autonomous Reasoning with Small Language Models](https://arxiv.org/abs/2508.12387)
*Yuanfeng Xu,Zehui Dai,Jian Liang,Jiapeng Guan,Guangrun Wang,Liang Lin,Xiaohui Lv*

Main category: cs.CL

TL;DR: ReaLM是一个强化学习框架，通过多路径过程验证、渐进式自主诱导和引导式思维链蒸馏，提升小语言模型在垂直领域的推理能力、自主性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 小语言模型(SLMs)成本低但推理能力有限，现有方法在提升性能时往往牺牲推理能力、自主性或泛化性，需要一种综合解决方案。

Method: 提出ReaLM框架：1) MRPV对比正负推理路径提取关键模式；2) EAAI渐进减少外部信号依赖；3) 引导式思维链蒸馏编码领域知识。

Result: 在垂直领域和通用推理任务上的大量实验表明，ReaLM显著提升了SLMs在推理能力、自主性和泛化性三个方面的表现。

Conclusion: ReaLM为小语言模型提供了有效的推理能力提升方案，通过综合方法解决了现有技术的关键局限性，在保持成本效益的同时显著提升性能。

Abstract: Small Language Models (SLMs) are a cost-effective alternative to Large
Language Models (LLMs), but often struggle with complex reasoning due to their
limited capacity and a tendency to produce mistakes or inconsistent answers
during multi-step reasoning. Existing efforts have improved SLM performance,
but typically at the cost of one or more of three key aspects: (1) reasoning
capability, due to biased supervision that filters out negative reasoning paths
and limits learning from errors; (2) autonomy, due to over-reliance on
externally generated reasoning signals; and (3) generalization, which suffers
when models overfit to teacher-specific patterns. In this paper, we introduce
ReaLM, a reinforcement learning framework for robust and self-sufficient
reasoning in vertical domains. To enhance reasoning capability, we propose
Multi-Route Process Verification (MRPV), which contrasts both positive and
negative reasoning paths to extract decisive patterns. To reduce reliance on
external guidance and improve autonomy, we introduce Enabling Autonomy via
Asymptotic Induction (EAAI), a training strategy that gradually fades external
signals. To improve generalization, we apply guided chain-of-thought
distillation to encode domain-specific rules and expert knowledge into SLM
parameters, making them part of what the model has learned. Extensive
experiments on both vertical and general reasoning tasks demonstrate that ReaLM
significantly improves SLM performance across aspects (1)-(3) above.

</details>


### [90] [MedKGent: A Large Language Model Agent Framework for Constructing Temporally Evolving Medical Knowledge Graph](https://arxiv.org/abs/2508.12393)
*Duzhen Zhang,Zixiao Wang,Zhong-Zhi Li,Yahan Yu,Shuncheng Jia,Jiahua Dong,Haotian Xu,Xing Wu,Yingying Zhang,Tielin Zhang,Jie Yang,Xiuying Chen,Le Song*

Main category: cs.CL

TL;DR: MedKGent是一个基于LLM代理的框架，用于构建时间演化的医学知识图谱，通过提取和构建代理处理PubMed摘要，生成高质量、时间感知的医学知识图谱，在问答任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前知识图谱构建方法存在泛化性有限、忽视知识时间动态性和上下文不确定性的问题，需要能够处理医学知识演化的解决方案。

Method: 使用Qwen2.5-32B-Instruct模型驱动的两个专业代理：提取代理识别知识三元组并分配置信度，构建代理基于置信度和时间戳增量整合三元组到时间演化图谱中。

Result: 构建了包含156,275个实体和2,971,384个关系三元组的KG，准确率接近90%，在7个医学问答基准测试中显著优于非增强基线。

Conclusion: MedKGent框架成功解决了医学知识图谱构建中的时间动态性和不确定性挑战，为医学知识管理和应用提供了有效工具。

Abstract: The rapid expansion of medical literature presents growing challenges for
structuring and integrating domain knowledge at scale. Knowledge Graphs (KGs)
offer a promising solution by enabling efficient retrieval, automated
reasoning, and knowledge discovery. However, current KG construction methods
often rely on supervised pipelines with limited generalizability or naively
aggregate outputs from Large Language Models (LLMs), treating biomedical
corpora as static and ignoring the temporal dynamics and contextual uncertainty
of evolving knowledge. To address these limitations, we introduce MedKGent, a
LLM agent framework for constructing temporally evolving medical KGs.
Leveraging over 10 million PubMed abstracts published between 1975 and 2023, we
simulate the emergence of biomedical knowledge via a fine-grained daily time
series. MedKGent incrementally builds the KG in a day-by-day manner using two
specialized agents powered by the Qwen2.5-32B-Instruct model. The Extractor
Agent identifies knowledge triples and assigns confidence scores via
sampling-based estimation, which are used to filter low-confidence extractions
and inform downstream processing. The Constructor Agent incrementally
integrates the retained triples into a temporally evolving graph, guided by
confidence scores and timestamps to reinforce recurring knowledge and resolve
conflicts. The resulting KG contains 156,275 entities and 2,971,384 relational
triples. Quality assessments by two SOTA LLMs and three domain experts
demonstrate an accuracy approaching 90\%, with strong inter-rater agreement. To
evaluate downstream utility, we conduct RAG across seven medical question
answering benchmarks using five leading LLMs, consistently observing
significant improvements over non-augmented baselines. Case studies further
demonstrate the KG's value in literature-based drug repurposing via
confidence-aware causal inference.

</details>


### [91] [Extracting Post-Acute Sequelae of SARS-CoV-2 Infection Symptoms from Clinical Notes via Hybrid Natural Language Processing](https://arxiv.org/abs/2508.12405)
*Zilong Bai,Zihan Xu,Cong Sun,Chengxi Zang,H. Timothy Bunnell,Catherine Sinfield,Jacqueline Rutter,Aaron Thomas Martinez,L. Charles Bailey,Mark Weiner,Thomas R. Campion,Thomas Carton,Christopher B. Forrest,Rainu Kaushal,Fei Wang,Yifan Peng*

Main category: cs.CL

TL;DR: 开发了一种混合自然语言处理流水线，通过结合规则基命名实体识别和BERT基断言检测模块，实现了高效的PASC症状提取和断言检测，为改善PASC诊断提供了有效工具。


<details>
  <summary>Details</summary>
Motivation: 因PASC的多样化症状在长期间間内演化，准确和高效诊断面临挑战，需要开发更有效的方法来提取和分析临床记录中的PASC相关信息。

Method: 开发了混合NLP流水线，整合规则基命名实体识别和BERT基断言检测模块，建立了临床专家参与制定的全面PASC词典，使用11个健康系统的160份进展记录进行模型开发和评估。

Result: 在断言检测任务中，单个区域内部验证F1分数平均0.82，10个区域外部验证平均0.76，流水线平均处理每份记录耗2.448秒，Spearman相关系数显示阳性提及相关性ρ>0.83，阴性提及ρ>0.72，均具有高统计显著性。

Conclusion: 该混合NLP流水线显示了高效和准确的PASC症状提取能力，为改善PASC诊断提供了有力的技术支持，具有重要的临床应用价值。

Abstract: Accurately and efficiently diagnosing Post-Acute Sequelae of COVID-19 (PASC)
remains challenging due to its myriad symptoms that evolve over long- and
variable-time intervals. To address this issue, we developed a hybrid natural
language processing pipeline that integrates rule-based named entity
recognition with BERT-based assertion detection modules for PASC-symptom
extraction and assertion detection from clinical notes. We developed a
comprehensive PASC lexicon with clinical specialists. From 11 health systems of
the RECOVER initiative network across the U.S., we curated 160 intake progress
notes for model development and evaluation, and collected 47,654 progress notes
for a population-level prevalence study. We achieved an average F1 score of
0.82 in one-site internal validation and 0.76 in 10-site external validation
for assertion detection. Our pipeline processed each note at $2.448\pm 0.812$
seconds on average. Spearman correlation tests showed $\rho >0.83$ for positive
mentions and $\rho >0.72$ for negative ones, both with $P <0.0001$. These
demonstrate the effectiveness and efficiency of our models and their potential
for improving PASC diagnosis.

</details>


### [92] [ZigzagAttention: Efficient Long-Context Inference with Exclusive Retrieval and Streaming Heads](https://arxiv.org/abs/2508.12407)
*Zhuorui Liu,Chen Zhang,Dawei Song*

Main category: cs.CL

TL;DR: ZigzagAttention方法通过将检索头和流式头分离到不同的层来优化LLM的KV缓存内存占用，在减少延迟的同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型处理长上下文时KV缓存消耗巨大，现有方法虽然能减少内存占用但会因注意力计算分解带来额外延迟。

Method: 设计新标准强制将检索头和流式头分别聚集在不同的层中，避免混合计算带来的索引和访问延迟。

Result: 该方法显著降低了延迟，同时仅带来可忽略的性能下降，在基准测试中表现竞争力。

Conclusion: ZigzagAttention通过层间头类型分离有效解决了KV缓存优化中的延迟问题，实现了内存和延迟的双重优化。

Abstract: With the rapid development of large language models (LLMs), handling long
context has become one of the vital abilities in LLMs. Such long-context
ability is accompanied by difficulties in deployment, especially due to the
increased consumption of KV cache. There is certain work aiming to optimize the
memory footprint of KV cache, inspired by the observation that attention heads
can be categorized into retrieval heads that are of great significance and
streaming heads that are of less significance. Typically, identifying the
streaming heads and and waiving the KV cache in the streaming heads would
largely reduce the overhead without hurting the performance that much. However,
since employing both retrieval and streaming heads in one layer decomposes one
large round of attention computation into two small ones, it may unexpectedly
bring extra latency on accessing and indexing tensors. Based on this intuition,
we impose an important improvement to the identification process of retrieval
and streaming heads, in which we design a criterion that enforces exclusively
retrieval or streaming heads gathered in one unique layer. In this way, we
further eliminate the extra latency and only incur negligible performance
degradation. Our method named \textsc{ZigzagAttention} is competitive among
considered baselines owing to reduced latency and comparable performance.

</details>


### [93] [The Cultural Gene of Large Language Models: A Study on the Impact of Cross-Corpus Training on Model Values and Biases](https://arxiv.org/abs/2508.12411)
*Emanuel Z. Fenech-Borg,Tilen P. Meznaric-Kos,Milica D. Lekovic-Bojovic,Arni J. Hentze-Djurhuus*

Main category: cs.CL

TL;DR: 这篇论文通过文化基因概念和文化探针数据集，对比分析了GPT-4和ERNIE Bot在个人主义-集体主义、权力距离等文化维度上的系统性偏向，发现大语言模型实际上是其训练语料文化偏向的统计镜像。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在全球部署，但其基础文化和伦理偏向很少被深入探索。研究者想要了解LLMs如何继承和反映其训练语料库的系统性价值观弋。

Method: 提出文化基因概念，构建包含200个提示的文化探针数据集(CPD)，重点关注个人主义-集体主义(IDV)和权力距离(PDI)两个经典跨文化维度。使用标准化零样本提示对比分析西方中心模型(GPT-4)和东方中心模型(ERNIE Bot)。

Result: 人工标注显示两个模型在两个维度上都存在显著且一致的分异。GPT-4呈现个人主义和低权力距离倾向(IDV得分约1.21；PDI得分约-1.05)，而ERNIE Bot呈现集体主义和较高权力距离倾向(IDV约-0.89；PDI约0.76)，差异统计显著(p < 0.001)。计算文化对齐指数(CAI)发现GPT-4更接近美国，ERNIE Bot更接近中国。

Conclusion: 大语言模型实际上是其训练语料文化的统计镜像，研究结果支持这一观点。这动呐了对文化意识评估和部署的需求，以避免算法文化霸权。

Abstract: Large language models (LLMs) are deployed globally, yet their underlying
cultural and ethical assumptions remain underexplored. We propose the notion of
a "cultural gene" -- a systematic value orientation that LLMs inherit from
their training corpora -- and introduce a Cultural Probe Dataset (CPD) of 200
prompts targeting two classic cross-cultural dimensions:
Individualism-Collectivism (IDV) and Power Distance (PDI). Using standardized
zero-shot prompts, we compare a Western-centric model (GPT-4) and an
Eastern-centric model (ERNIE Bot). Human annotation shows significant and
consistent divergence across both dimensions. GPT-4 exhibits individualistic
and low-power-distance tendencies (IDV score approx 1.21; PDI score approx
-1.05), while ERNIE Bot shows collectivistic and higher-power-distance
tendencies (IDV approx -0.89; PDI approx 0.76); differences are statistically
significant (p < 0.001). We further compute a Cultural Alignment Index (CAI)
against Hofstede's national scores and find GPT-4 aligns more closely with the
USA (e.g., IDV CAI approx 0.91; PDI CAI approx 0.88) whereas ERNIE Bot aligns
more closely with China (IDV CAI approx 0.85; PDI CAI approx 0.81). Qualitative
analyses of dilemma resolution and authority-related judgments illustrate how
these orientations surface in reasoning. Our results support the view that LLMs
function as statistical mirrors of their cultural corpora and motivate
culturally aware evaluation and deployment to avoid algorithmic cultural
hegemony.

</details>


### [94] [Uncovering Emergent Physics Representations Learned In-Context by Large Language Models](https://arxiv.org/abs/2508.12448)
*Yeongwoo Song,Jaeyong Bae,Dong-Kyum Kim,Hawoong Jeong*

Main category: cs.CL

TL;DR: 大语言模型通过上下文学习能够理解物理概念，特别是在动力学预测任务中展现出与能量等物理变量相关的特征编码。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在上下文学习中的机制，物理任务提供了实验可控、基础原理结构化的理想测试场景。

Method: 使用动力学预测任务作为代理，分析模型在长上下文中的表现，并通过稀疏自编码器(SAE)分析殊异流激活动。

Result: 长上下文提升了动力学预测性能，SAE捕捉到的特征与能量等关键物理变量相关联，证明LLM在上下文学习中编码了有意义的物理概念。

Conclusion: 该研究为理解LLM如何学习提供了新的案例研究，扩展了对模型上下文学习机制的认识。

Abstract: Large language models (LLMs) exhibit impressive in-context learning (ICL)
abilities, enabling them to solve wide range of tasks via textual prompts
alone. As these capabilities advance, the range of applicable domains continues
to expand significantly. However, identifying the precise mechanisms or
internal structures within LLMs that allow successful ICL across diverse,
distinct classes of tasks remains elusive. Physics-based tasks offer a
promising testbed for probing this challenge. Unlike synthetic sequences such
as basic arithmetic or symbolic equations, physical systems provide
experimentally controllable, real-world data based on structured dynamics
grounded in fundamental principles. This makes them particularly suitable for
studying the emergent reasoning behaviors of LLMs in a realistic yet tractable
setting. Here, we mechanistically investigate the ICL ability of LLMs,
especially focusing on their ability to reason about physics. Using a dynamics
forecasting task in physical systems as a proxy, we evaluate whether LLMs can
learn physics in context. We first show that the performance of dynamics
forecasting in context improves with longer input contexts. To uncover how such
capability emerges in LLMs, we analyze the model's residual stream activations
using sparse autoencoders (SAEs). Our experiments reveal that the features
captured by SAEs correlate with key physical variables, such as energy. These
findings demonstrate that meaningful physical concepts are encoded within LLMs
during in-context learning. In sum, our work provides a novel case study that
broadens our understanding of how LLMs learn in context.

</details>


### [95] [M3PO: Multimodal-Model-Guided Preference Optimization for Visual Instruction Following](https://arxiv.org/abs/2508.12458)
*Ruirui Gao,Emily Johnson,Bowen Tan,Yanfei Qian*

Main category: cs.CL

TL;DR: M3PO是一种新颖的多模态偏好优化方法，通过智能选择LVLM生成的高价值偏好样本对，结合多模态对齐分数和模型自一致性，有效提升视觉指令跟随能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型的发展受限于人工标注的高成本和一致性差，传统SFT和偏好优化方法难以有效利用模型自身生成空间来识别高信息量的困难负样本。

Method: 提出M3PO方法，通过多模态对齐分数(MAS)和模型自置信度(log概率)结合成M3P-Score，智能选择最有学习价值的偏好样本对，然后使用LoRA进行直接偏好优化(DPO)微调。

Result: 在多个多模态指令跟随基准测试(MME-Bench、POPE、IFT、Human Pref. Score)上，M3PO consistently outperforms strong baselines，包括SFT、模拟RLHF、vanilla DPO和RM-DPO。

Conclusion: M3PO是一种数据高效的方法，能够显著提升LVLMs在视觉指令跟随方面的能力，为解决人工标注成本高和传统方法效率低的问题提供了有效解决方案。

Abstract: Large Vision-Language Models (LVLMs) hold immense potential for complex
multimodal instruction following, yet their development is often hindered by
the high cost and inconsistency of human annotation required for effective
fine-tuning and preference alignment. Traditional supervised fine-tuning (SFT)
and existing preference optimization methods like RLHF and DPO frequently
struggle to efficiently leverage the model's own generation space to identify
highly informative "hard negative" samples. To address these challenges, we
propose Multimodal-Model-Guided Preference Optimization (M3PO), a novel and
data-efficient method designed to enhance LVLMs' capabilities in visual
instruction following. M3PO intelligently selects the most "learning-valuable"
preference sample pairs from a diverse pool of LVLM-generated candidates. This
selection is driven by a sophisticated mechanism that integrates two crucial
signals: a Multimodal Alignment Score (MAS) to assess external quality and the
model's Self-Consistency / Confidence (log-probability) to gauge internal
belief. These are combined into a novel M3P-Score, which specifically
identifies preferred responses and challenging dispreferred responses that the
model might confidently generate despite being incorrect. These high-quality
preference pairs are then used for efficient Direct Preference Optimization
(DPO) fine-tuning on base LVLMs like LLaVA-1.5 (7B/13B) using LoRA. Our
extensive experiments demonstrate that M3PO consistently outperforms strong
baselines, including SFT, simulated RLHF, vanilla DPO, and RM-DPO, across a
comprehensive suite of multimodal instruction following benchmarks (MME-Bench,
POPE, IFT, Human Pref. Score).

</details>


### [96] [LoraxBench: A Multitask, Multilingual Benchmark Suite for 20 Indonesian Languages](https://arxiv.org/abs/2508.12459)
*Alham Fikri Aji,Trevor Cohn*

Main category: cs.CL

TL;DR: LoraxBench是一个针对印度尼西亚低资源语言的基准测试，涵盖6个任务和20种语言，评估显示该基准具有挑战性且存在语言间性能差异


<details>
  <summary>Details</summary>
Motivation: 印度尼西亚作为世界人口大国，拥有700种语言，但在NLP领域进展滞后，需要专门针对其低资源语言的评估基准

Method: 构建包含阅读理解、开放域问答、语言推理、因果推理、翻译和文化问答6个任务的基准数据集，覆盖20种语言，并对3种语言添加正式性语域变体

Result: 基准测试具有挑战性，印尼语与其他低资源语言性能存在明显差距，区域特定模型与通用多语言模型无明确优势，语域变化（特别是社交媒体中不常见的高级礼貌语）显著影响模型性能

Conclusion: LoraxBench为评估印尼低资源语言NLP模型提供了重要基准，揭示了语言间性能差异和语域对模型表现的影响

Abstract: As one of the world's most populous countries, with 700 languages spoken,
Indonesia is behind in terms of NLP progress. We introduce LoraxBench, a
benchmark that focuses on low-resource languages of Indonesia and covers 6
diverse tasks: reading comprehension, open-domain QA, language inference,
causal reasoning, translation, and cultural QA. Our dataset covers 20
languages, with the addition of two formality registers for three languages. We
evaluate a diverse set of multilingual and region-focused LLMs and found that
this benchmark is challenging. We note a visible discrepancy between
performance in Indonesian and other languages, especially the low-resource
ones. There is no clear lead when using a region-specific model as opposed to
the general multilingual model. Lastly, we show that a change in register
affects model performance, especially with registers not commonly found in
social media, such as high-level politeness `Krama' Javanese.

</details>


### [97] [Is GPT-OSS Good? A Comprehensive Evaluation of OpenAI's Latest Open Source Models](https://arxiv.org/abs/2508.12461)
*Ziqian Bi,Keyu Chen,Chiung-Yi Tseng,Danyang Zhang,Tianyang Wang,Hongying Luo,Lu Chen,Junming Huang,Jibin Guan,Junfeng Hao,Junhao Song*

Main category: cs.CL

TL;DR: OpenAI发布GPT-OSS开源模型（20B和120B参数），在多项基准测试中20B版本反而优于120B版本，表明稀疏架构的扩展不一定带来性能提升


<details>
  <summary>Details</summary>
Motivation: 评估OpenAI首个开源大语言模型GPT-OSS的性能表现，比较不同参数规模稀疏架构模型的效率与效果

Method: 在10个基准测试上对比6个开源大模型（14.7B-235B参数），使用标准化推理设置和McNemar检验进行统计验证

Result: 20B模型在HumanEval和MMLU等多个基准上表现优于120B模型，整体性能中等，代码生成强但多语言能力弱

Conclusion: 稀疏架构的扩展不一定带来相应性能提升，需要优化策略研究和更高效的模型选择方法

Abstract: In August 2025, OpenAI released GPT-OSS models, its first open weight large
language models since GPT-2 in 2019, comprising two mixture of experts
architectures with 120B and 20B parameters. We evaluated both variants against
six contemporary open source large language models ranging from 14.7B to 235B
parameters, representing both dense and sparse designs, across ten benchmarks
covering general knowledge, mathematical reasoning, code generation,
multilingual understanding, and conversational ability. All models were tested
in unquantised form under standardised inference settings, with statistical
validation using McNemars test and effect size analysis. Results show that
gpt-oss-20B consistently outperforms gpt-oss-120B on several benchmarks, such
as HumanEval and MMLU, despite requiring substantially less memory and energy
per response. Both models demonstrate mid-tier overall performance within the
current open source landscape, with relative strength in code generation and
notable weaknesses in multilingual tasks. These findings provide empirical
evidence that scaling in sparse architectures may not yield proportional
performance gains, underscoring the need for further investigation into
optimisation strategies and informing more efficient model selection for future
open source deployments.

</details>


### [98] [The Structural Sources of Verb Meaning Revisited: Large Language Models Display Syntactic Bootstrapping](https://arxiv.org/abs/2508.12482)
*Xiaomeng Zhu,R. Thomas McCoy,Robert Frank*

Main category: cs.CL

TL;DR: 这篇论文通过在语法信息被消除的数据集上训练大型语言模型，证明了语法启发学习在动词表征学习中的重要作用，特别是对于心理动词。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型是否也像儿童一样通过语法环境来学习动词含义，即是否存在语法启发学习机制。

Method: 在语法信息被消除的扰动数据集上训练RoBERTa和GPT-2模型，对比语法信息和共现信息消除对模型表征的影响。

Result: 模型的动词表征在语法线索被移除时浓度更大，尤其是心理动词的表征受影响更严重；而名词表征更多受共现信息影响。

Conclusion: 证实了语法启发学习在动词学习中的关键作用，并为通过操控大型语言模型的学习环境来测试发育假设提供了可行方案。

Abstract: Syntactic bootstrapping (Gleitman, 1990) is the hypothesis that children use
the syntactic environments in which a verb occurs to learn its meaning. In this
paper, we examine whether large language models exhibit a similar behavior. We
do this by training RoBERTa and GPT-2 on perturbed datasets where syntactic
information is ablated. Our results show that models' verb representation
degrades more when syntactic cues are removed than when co-occurrence
information is removed. Furthermore, the representation of mental verbs, for
which syntactic bootstrapping has been shown to be particularly crucial in
human verb learning, is more negatively impacted in such training regimes than
physical verbs. In contrast, models' representation of nouns is affected more
when co-occurrences are distorted than when syntax is distorted. In addition to
reinforcing the important role of syntactic bootstrapping in verb learning, our
results demonstrated the viability of testing developmental hypotheses on a
larger scale through manipulating the learning environments of large language
models.

</details>


### [99] [Mitigating Hallucinations in Large Language Models via Causal Reasoning](https://arxiv.org/abs/2508.12495)
*Yuangang Li,Yiqing Shen,Yi Nian,Jiechao Gao,Ziyi Wang,Chenxiao Yu,Shawn Li,Jie Wang,Xiyang Hu,Yue Zhao*

Main category: cs.CL

TL;DR: 提出了CDCR-SFT框架，通过显式构建因果DAG并进行推理来减少LLM的逻辑不一致幻觉，在多个任务上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法（如CoT）在语言token层面操作，无法建模变量间的因果关系和条件独立性，导致逻辑不一致的幻觉

Method: CDCR-SFT监督微调框架，训练LLMs显式构建变量级有向无环图（DAG）并在图上进行推理，同时构建了包含25,368个样本的CausalDR数据集

Result: 在8个任务的4个LLM上，CDCR-SFT在CLADDER上达到95.33%准确率（首次超越人类94.8%），在HaluEval上减少10%的幻觉

Conclusion: LLM中显式因果结构建模能有效缓解输出中的逻辑不一致问题

Abstract: Large language models (LLMs) exhibit logically inconsistent hallucinations
that appear coherent yet violate reasoning principles, with recent research
suggesting an inverse relationship between causal reasoning capabilities and
such hallucinations. However, existing reasoning approaches in LLMs, such as
Chain-of-Thought (CoT) and its graph-based variants, operate at the linguistic
token level rather than modeling the underlying causal relationships between
variables, lacking the ability to represent conditional independencies or
satisfy causal identification assumptions. To bridge this gap, we introduce
causal-DAG construction and reasoning (CDCR-SFT), a supervised fine-tuning
framework that trains LLMs to explicitly construct variable-level directed
acyclic graph (DAG) and then perform reasoning over it. Moreover, we present a
dataset comprising 25,368 samples (CausalDR), where each sample includes an
input question, explicit causal DAG, graph-based reasoning trace, and validated
answer. Experiments on four LLMs across eight tasks show that CDCR-SFT improves
the causal reasoning capability with the state-of-the-art 95.33% accuracy on
CLADDER (surpassing human performance of 94.8% for the first time) and reduces
the hallucination on HaluEval with 10% improvements. It demonstrates that
explicit causal structure modeling in LLMs can effectively mitigate logical
inconsistencies in LLM outputs. Code is available at
https://github.com/MrLYG/CDCR-SFT.

</details>


### [100] [CorrSteer: Steering Improves Task Performance and Safety in LLMs through Correlation-based Sparse Autoencoder Feature Selection](https://arxiv.org/abs/2508.12535)
*Seonglae Cho,Zekun Wu,Adriano Koshiyama*

Main category: cs.CL

TL;DR: CorrSteer是一种基于相关性的稀疏自编码器特征选择方法，通过推理时激活与样本正确性的相关性来提取相关特征，无需对比数据集或大量激活存储，在多个任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏自编码器在下游控制任务中效果有限，需要对比数据集或大量激活存储，限制了其实际应用。

Method: 提出CorrSteer方法，通过关联样本正确性与推理时SAE激活的相关性来选择特征，使用平均激活获取控制系数，实现全自动化流程。

Result: 在Gemma 2 2B和LLaMA 3.1 8B模型上，QA、偏见缓解、越狱预防和推理基准测试表现提升，MMLU性能提升4.1%，HarmBench提升22.9%（仅需4000样本）。

Conclusion: 基于相关性选择是自动化SAE控制的有效可扩展方法，所选特征展示出与任务需求一致的语义模式，揭示了驱动性能的底层能力。

Abstract: Sparse Autoencoders (SAEs) can extract interpretable features from large
language models (LLMs) without supervision. However, their effectiveness in
downstream steering tasks is limited by the requirement for contrastive
datasets or large activation storage. To address these limitations, we propose
CorrSteer, which selects features by correlating sample correctness with SAE
activations from generated tokens at inference time. This approach uses only
inference-time activations to extract more relevant features, thereby avoiding
spurious correlations. It also obtains steering coefficients from average
activations, automating the entire pipeline. Our method shows improved task
performance on QA, bias mitigation, jailbreaking prevention, and reasoning
benchmarks on Gemma 2 2B and LLaMA 3.1 8B, notably achieving a +4.1%
improvement in MMLU performance and a +22.9% improvement in HarmBench with only
4000 samples. Selected features demonstrate semantically meaningful patterns
aligned with each task's requirements, revealing the underlying capabilities
that drive performance. Our work establishes correlationbased selection as an
effective and scalable approach for automated SAE steering across language
model applications.

</details>


### [101] [Beyond Modality Limitations: A Unified MLLM Approach to Automated Speaking Assessment with Effective Curriculum Learning](https://arxiv.org/abs/2508.12591)
*Yu-Hsuan Fang,Tien-Hong Lo,Yao-Ting Sung,Berlin Chen*

Main category: cs.CL

TL;DR: 本文首次系统性研究多模态大语言模型在自动语言评测中的应用，提出语音优先多模态训练方法，显著提升了评测性能


<details>
  <summary>Details</summary>
Motivation: 传统自动语言评测系统存在模态限制：文本方法缺乏音响信息，音频方法缺少语义上下文。多模态大语言模型为全面评测提供了新机遇

Method: 提出语音优先多模态训练（SFMT）方法，采用课程学习原理，先建立健壮的语音模型基础，再进行跨模态协同融合

Result: 在标准数据集上，MLLM基系统将整体评测性能从PCC值0.783提升到0.846。SFMT在表达方面的评估特别优异，比传统训练方法绝对准确度提高4%

Conclusion: 多模态大语言模型为自动语言评测开启了新方向，而语音优先训练策略有效解决了表达方面的评测挑战，为该领域探索了新路径

Abstract: Traditional Automated Speaking Assessment (ASA) systems exhibit inherent
modality limitations: text-based approaches lack acoustic information while
audio-based methods miss semantic context. Multimodal Large Language Models
(MLLM) offer unprecedented opportunities for comprehensive ASA by
simultaneously processing audio and text within unified frameworks. This paper
presents a very first systematic study of MLLM for comprehensive ASA,
demonstrating the superior performance of MLLM across the aspects of content
and language use . However, assessment on the delivery aspect reveals unique
challenges, which is deemed to require specialized training strategies. We thus
propose Speech-First Multimodal Training (SFMT), leveraging a curriculum
learning principle to establish more robust modeling foundations of speech
before cross-modal synergetic fusion. A series of experiments on a benchmark
dataset show MLLM-based systems can elevate the holistic assessment performance
from a PCC value of 0.783 to 0.846. In particular, SFMT excels in the
evaluation of the delivery aspect, achieving an absolute accuracy improvement
of 4% over conventional training approaches, which also paves a new avenue for
ASA.

</details>


### [102] [Semantic Anchoring in Agentic Memory: Leveraging Linguistic Structures for Persistent Conversational Context](https://arxiv.org/abs/2508.12630)
*Maitreyi Chatterjee,Devansh Agarwal*

Main category: cs.CL

TL;DR: 提出Semantic Anchoring混合记忆架构，通过结合语言结构线索增强RAG系统，在长期对话中提升18%的事实回忆和话语连贯性


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统使用稠密向量存储对话历史，虽然能捕捉语义相似性，但忽略了句法依赖、话语关系和共指链接等精细语言结构，限制了LLM在多会话和长期交互中的记忆持久性

Method: 提出混合代理记忆架构，结合依赖解析、话语关系标注和共指消解来创建结构化记忆条目，丰富基于向量的存储

Result: 在适应的长期对话数据集上实验显示，语义锚定相比强RAG基线在事实回忆和话语连贯性上提升高达18%

Conclusion: 语义锚定方法通过显式语言线索增强记忆架构，显著改善了长期对话交互中的记忆持久性和上下文理解能力

Abstract: Large Language Models (LLMs) have demonstrated impressive fluency and task
competence in conversational settings. However, their effectiveness in
multi-session and long-term interactions is hindered by limited memory
persistence. Typical retrieval-augmented generation (RAG) systems store
dialogue history as dense vectors, which capture semantic similarity but
neglect finer linguistic structures such as syntactic dependencies, discourse
relations, and coreference links. We propose Semantic Anchoring, a hybrid
agentic memory architecture that enriches vector-based storage with explicit
linguistic cues to improve recall of nuanced, context-rich exchanges. Our
approach combines dependency parsing, discourse relation tagging, and
coreference resolution to create structured memory entries. Experiments on
adapted long-term dialogue datasets show that semantic anchoring improves
factual recall and discourse coherence by up to 18% over strong RAG baselines.
We further conduct ablation studies, human evaluations, and error analysis to
assess robustness and interpretability.

</details>


### [103] [Beyond GPT-5: Making LLMs Cheaper and Better via Performance-Efficiency Optimized Routing](https://arxiv.org/abs/2508.12631)
*Yiqun Zhang,Hao Li,Jianhao Chen,Hangfan Zhang,Peng Ye,Lei Bai,Shuyue Hu*

Main category: cs.CL

TL;DR: Avengers-Pro是一个测试时路由框架，通过动态分配查询到不同容量和效率的LLM，在性能和效率之间实现最优平衡，在6个基准测试中超越最强单模型7%准确率，同时降低27-63%成本。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在性能和效率之间的平衡挑战，GPT-5虽然提出了测试时路由，但需要更统一的解决方案来处理所有性能-效率权衡问题。

Method: 提出Avengers-Pro框架，通过嵌入和聚类输入查询，然后基于性能-效率分数将每个查询路由到最合适的模型，集成不同容量和效率的LLM。

Result: 在6个挑战性基准测试和8个领先模型上实现最先进结果：超越最强单模型GPT-5-medium 7%平均准确率，以27%更低成本匹配最强模型性能，以63%更低成本达到90%性能。

Conclusion: Avengers-Pro实现了帕累托前沿，在任何给定成本下提供最高准确率，在任何给定准确率下提供最低成本，为LLM的性能-效率权衡提供了统一解决方案。

Abstract: Balancing performance and efficiency is a central challenge in large language
model (LLM) advancement. GPT-5 addresses this with test-time routing,
dynamically assigning queries to either an efficient or a high-capacity model
during inference. In this work, we present Avengers-Pro, a test-time routing
framework that ensembles LLMs of varying capacities and efficiencies, providing
a unified solution for all performance-efficiency tradeoffs. The Avengers-Pro
embeds and clusters incoming queries, then routes each to the most suitable
model based on a performance-efficiency score. Across 6 challenging benchmarks
and 8 leading models -- including GPT-5-medium, Gemini-2.5-pro, and
Claude-opus-4.1 -- Avengers-Pro achieves state-of-the-art results: by varying a
performance-efficiency trade-off parameter, it can surpass the strongest single
model (GPT-5-medium) by +7% in average accuracy. Moreover, it can match the
average accuracy of the strongest single model at 27% lower cost, and reach
~90% of that performance at 63% lower cost. Last but not least, it achieves a
Pareto frontier, consistently yielding the highest accuracy for any given cost,
and the lowest cost for any given accuracy, among all single models. Code is
available at https://github.com/ZhangYiqun018/AvengersPro.

</details>


### [104] [Prompt-Induced Linguistic Fingerprints for LLM-Generated Fake News Detection](https://arxiv.org/abs/2508.12632)
*Chi Wang,Min Gao,Zongwei Wang,Junwei Yin,Kai Shu,Chenghua Lin*

Main category: cs.CL

TL;DR: 提出了一种名为LIFE的新方法，通过重构词级概率分布来检测LLM生成的假新闻，利用提示诱导的语言指纹和关键片段技术实现最先进的检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速发展，生成假新闻变得越来越容易，而现有的检测方法主要关注文本内容本身，难以发现看似连贯但实则伪造的细微痕迹。

Method: 通过分布差异分析发现提示诱导的语言指纹，提出LIFE方法重构词级概率分布来寻找判别模式，并利用关键片段技术放大语言差异。

Result: 实验表明LIFE在LLM生成的假新闻检测上达到最先进性能，同时在人工编写的假新闻上也保持高性能。

Conclusion: LIFE方法通过挖掘提示诱导的语言指纹，为LLM生成的假新闻检测提供了有效的解决方案，代码和数据已公开。

Abstract: With the rapid development of large language models, the generation of fake
news has become increasingly effortless, posing a growing societal threat and
underscoring the urgent need for reliable detection methods. Early efforts to
identify LLM-generated fake news have predominantly focused on the textual
content itself; however, because much of that content may appear coherent and
factually consistent, the subtle traces of falsification are often difficult to
uncover. Through distributional divergence analysis, we uncover prompt-induced
linguistic fingerprints: statistically distinct probability shifts between
LLM-generated real and fake news when maliciously prompted. Based on this
insight, we propose a novel method named Linguistic Fingerprints Extraction
(LIFE). By reconstructing word-level probability distributions, LIFE can find
discriminative patterns that facilitate the detection of LLM-generated fake
news. To further amplify these fingerprint patterns, we also leverage
key-fragment techniques that accentuate subtle linguistic differences, thereby
improving detection reliability. Our experiments show that LIFE achieves
state-of-the-art performance in LLM-generated fake news and maintains high
performance in human-written fake news. The code and data are available at
https://anonymous.4open.science/r/LIFE-E86A.

</details>


### [105] [Breaking Language Barriers: Equitable Performance in Multilingual Language Models](https://arxiv.org/abs/2508.12662)
*Tanay Nagar,Grigorii Khvatskii,Anna Sokol,Nitesh V. Chawla*

Main category: cs.CL

TL;DR: 通过使用控制语言混合方法生成的合成代码切换文本对LLM进行微调，提升低资源语言的常识推理性能，同时保持或提升高资源语言的表现


<details>
  <summary>Details</summary>
Motivation: 解决LLM在低资源语言(LRLs)如印地语、斯瓦希里语上的常识推理任务表现较差的问题，确保不同语言社区获得公平的LLM输出质量

Method: 使用控制语言混合方法生成合成代码切换文本，对LLM进行微调训练，并创建了基于CommonSenseQA数据集的新的合成代码切换文本数据集，包含三种不同语言比例配置

Result: 经验证明，在合成代码切换数据集上微调LLM能够对LRL模型性能带来显著改善，同时保持或提升HRLs上的表现

Conclusion: 通过合成代码切换文本的微调方法有效缩小了LLM在不同语言之间的性能差距，为提升多语言平等性提供了可行方案

Abstract: Cutting-edge LLMs have emerged as powerful tools for multilingual
communication and understanding. However, LLMs perform worse in Common Sense
Reasoning (CSR) tasks when prompted in low-resource languages (LRLs) like Hindi
or Swahili compared to high-resource languages (HRLs) like English. Equalizing
this inconsistent access to quality LLM outputs is crucial to ensure fairness
for speakers of LRLs and across diverse linguistic communities. In this paper,
we propose an approach to bridge this gap in LLM performance. Our approach
involves fine-tuning an LLM on synthetic code-switched text generated using
controlled language-mixing methods. We empirically demonstrate that fine-tuning
LLMs on synthetic code-switched datasets leads to substantial improvements in
LRL model performance while preserving or enhancing performance in HRLs.
Additionally, we present a new dataset of synthetic code-switched text derived
from the CommonSenseQA dataset, featuring three distinct language ratio
configurations.

</details>


### [106] [Leveraging Large Language Models for Predictive Analysis of Human Misery](https://arxiv.org/abs/2508.12669)
*Bishanka Seal,Rahul Seetharaman,Aman Bansal,Abhilash Nandy*

Main category: cs.CL

TL;DR: 这研究使用大语言模型预测人类对真实场景描述的痛苦感知分数，通过多种提示策略和创新的游戏化评估框架进行动态情感推理测试。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在情感预测任务中的表现，特别是在动态环境中通过反馈进行适应的能力。

Method: 将任务框架为回归问题，评估零样本提示、固定上下文少样本提示和基于BERT句子嵌入的检索提示策略。还创建了"痛苦游戏展示"游戏化框架，包括顺序比较、二元分类、数值估计和反馈推理等环节。

Result: 少样本提示方法一贵表现更优于零样本基准，说明上下文示例对情感预测重要。游戏化评估显示了大语言模型在动态情感推理任务中的更广泛潜力。

Conclusion: 研究证明了大语言模型在情感预测中的效果，并通过创新的游戏化评估框架展示了其在动态环境中的适应能力，为情感计算领域开启了新方向。

Abstract: This study investigates the use of Large Language Models (LLMs) for
predicting human-perceived misery scores from natural language descriptions of
real-world scenarios. The task is framed as a regression problem, where the
model assigns a scalar value from 0 to 100 to each input statement. We evaluate
multiple prompting strategies, including zero-shot, fixed-context few-shot, and
retrieval-based prompting using BERT sentence embeddings. Few-shot approaches
consistently outperform zero-shot baselines, underscoring the value of
contextual examples in affective prediction. To move beyond static evaluation,
we introduce the "Misery Game Show", a novel gamified framework inspired by a
television format. It tests LLMs through structured rounds involving ordinal
comparison, binary classification, scalar estimation, and feedback-driven
reasoning. This setup enables us to assess not only predictive accuracy but
also the model's ability to adapt based on corrective feedback. The gamified
evaluation highlights the broader potential of LLMs in dynamic emotional
reasoning tasks beyond standard regression. Code and data link:
https://github.com/abhi1nandy2/Misery_Data_Exps_GitHub

</details>


### [107] [ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction](https://arxiv.org/abs/2508.12685)
*Xingshan Zeng,Weiwen Liu,Lingzhi Wang,Liangyou Li,Fei Mi,Yasheng Wang,Lifeng Shang,Xin Jiang,Qun Liu*

Main category: cs.CL

TL;DR: ToolACE-MT是一个非自回归迭代生成框架，用于高效构建高质量的多轮代理对话数据，通过三阶段流程替代昂贵的自回归交互方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于模拟的代理任务数据生成方法严重依赖多个LLM代理之间昂贵的自回归交互，限制了代理任务在现实世界中的性能表现。

Method: 三阶段框架：粗粒度初始化构建完整但语义粗糙的对话骨架；迭代细化通过掩码填充操作引入现实复杂性；离线验证通过规则和模型检查确保正确性和连贯性。

Result: 实验证明ToolACE-MT能够实现高效、有效且可泛化的代理数据生成。

Conclusion: 该框架为工具增强LLM场景中的高质量数据构建提供了新范式，解决了现有方法的成本和性能限制问题。

Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn,
multi-step interactions, often involving complex function calls and dynamic
user-agent exchanges. Existing simulation-based data generation methods for
such scenarios rely heavily on costly autoregressive interactions between
multiple LLM agents, thereby limiting real-world performance of agentic tasks.
In this paper, we propose a novel Non-Autoregressive Iterative Generation
framework, called ToolACE-MT, for constructing high-quality multi-turn agentic
dialogues. ToolACE-MT generates full conversational trajectories through three
stages: coarse-grained initialization, iterative refinement, and offline
verification. The initialization phase builds a structurally complete yet
semantically coarse dialogue skeleton; the iterative refinement phase
introduces realistic complexities and continued refinement via mask-and-fill
operations; and the offline verification phase ensures correctness and
coherence via rule- and model-based checks. Experiments demonstrate that
ToolACE-MT enables efficient, effective and generalizable agentic data
generation, offering a new paradigm for high-quality data construction in
tool-augmented LLM scenarios.

</details>


### [108] [DESIGNER: Design-Logic-Guided Multidisciplinary Data Synthesis for LLM Reasoning](https://arxiv.org/abs/2508.12726)
*Weize Liu,Yongchi Zhao,Yijia Luo,Mingyu Xu,Jiaheng Liu,Yanan Li,Xiguo Hu,Yuchi Xu,Wenbo Su,Bo Zheng*

Main category: cs.CL

TL;DR: DESIGNER是一个基于设计逻辑的多学科推理数据合成框架，通过从现有问题中提取设计逻辑并与学科材料匹配，生成了两个大规模推理数据集DLR-Book和DLR-Web，显著提升了LLM在复杂多步推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有推理数据集缺乏学科广度和结构深度，无法有效激发LLM的复杂推理能力，需要创建更具挑战性和多样性的多学科推理数据集。

Method: 提出DESIGNER数据合成管道：1）从现有问题中逆向工程提取12万+设计逻辑；2）将设计逻辑与书籍和网络语料匹配；3）生成跨75个学科的470万+挑战性问题。

Result: 创建了两个大规模数据集：DLR-Book（304万问题）和DLR-Web（166万问题），在难度和多样性上远超基线数据集。SFT实验显示，使用这些数据训练的模型在Qwen3-8B和Qwen3-4B上显著超越现有方法，甚至超过官方模型的多学科推理性能。

Conclusion: DESIGNER框架通过设计逻辑指导的数据合成方法，成功创建了高质量的多学科推理数据集，有效提升了LLM的复杂推理能力，为跨学科AI推理提供了新的数据生成范式。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language tasks but still struggle with complex, multi-step reasoning,
particularly across diverse disciplines. Existing reasoning datasets often
either lack disciplinary breadth or the structural depth necessary to elicit
robust reasoning behaviors. We propose DESIGNER: a DESIGN-logic-guidEd
Reasoning data synthesis pipeline that leverages naturally available, extensive
raw documents (book corpus and web corpus) to generate multidisciplinary
challenging questions. A core innovation of our approach is the introduction of
a Design Logic concept, which mimics the question-creation process of human
educators. We use LLMs to reverse-engineer and abstract over 120,000 design
logics from existing questions across various disciplines. By matching these
design logics with disciplinary source materials, we are able to create
reasoning questions that far surpass the difficulty and diversity of existing
datasets. Based on this pipeline, we synthesized two large-scale reasoning
datasets that span 75 disciplines: Design-Logic-Reasoning-Book (DLR-Book),
containing 3.04 million challenging questions synthesized from the book corpus,
and Design-Logic-Reasoning-Web (DLR-Web), with 1.66 million challenging
questions from the web corpus. Our data analysis demonstrates that the
questions synthesized by our method exhibit substantially greater difficulty
and diversity than those in the baseline datasets. We validate the
effectiveness of these datasets by conducting SFT experiments on the
Qwen3-8B-Base and Qwen3-4B-Base models. The results show that our dataset
significantly outperforms existing multidisciplinary datasets of the same
volume. Training with the full datasets further enables the models to surpass
the multidisciplinary reasoning performance of the official Qwen3-8B and
Qwen3-4B models.

</details>


### [109] [LinguaSafe: A Comprehensive Multilingual Safety Benchmark for Large Language Models](https://arxiv.org/abs/2508.12733)
*Zhiyuan Ning,Tianle Gu,Jiaxin Song,Shixin Hong,Lingyu Li,Huacan Liu,Jie Li,Yixu Wang,Meng Lingyu,Yan Teng,Yingchun Wang*

Main category: cs.CL

TL;DR: LinguaSafe是一个包含12种语言、45k条目的多语言安全基准，通过翻译、转创和本地来源数据构建，提供多维度的安全评估框架，填补了LLM在多语言安全评估方面的空白。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多语言安全评估缺乏全面性和多样性数据，限制了多语言安全对齐的发展，需要构建更全面的多语言安全基准来确保LLM在不同语言文化环境中的安全性。

Method: 结合翻译、转创和本地来源数据构建包含12种语言45k条目的数据集，建立多维度的细粒度评估框架，包括直接和间接安全评估以及过度敏感性评估。

Result: 安全和有用性评估结果在不同领域和语言间存在显著差异，即使是资源水平相似的语言也有明显差别，突显了全面评估多语言安全的重要性。

Conclusion: LinguaSafe基准提供了深入安全评估的综合指标套件，强调了全面评估LLM多语言安全对实现更平衡安全对齐的关键重要性，数据集和代码已公开以促进进一步研究。

Abstract: The widespread adoption and increasing prominence of large language models
(LLMs) in global technologies necessitate a rigorous focus on ensuring their
safety across a diverse range of linguistic and cultural contexts. The lack of
a comprehensive evaluation and diverse data in existing multilingual safety
evaluations for LLMs limits their effectiveness, hindering the development of
robust multilingual safety alignment. To address this critical gap, we
introduce LinguaSafe, a comprehensive multilingual safety benchmark crafted
with meticulous attention to linguistic authenticity. The LinguaSafe dataset
comprises 45k entries in 12 languages, ranging from Hungarian to Malay. Curated
using a combination of translated, transcreated, and natively-sourced data, our
dataset addresses the critical need for multilingual safety evaluations of
LLMs, filling the void in the safety evaluation of LLMs across diverse
under-represented languages from Hungarian to Malay. LinguaSafe presents a
multidimensional and fine-grained evaluation framework, with direct and
indirect safety assessments, including further evaluations for oversensitivity.
The results of safety and helpfulness evaluations vary significantly across
different domains and different languages, even in languages with similar
resource levels. Our benchmark provides a comprehensive suite of metrics for
in-depth safety evaluation, underscoring the critical importance of thoroughly
assessing multilingual safety in LLMs to achieve more balanced safety
alignment. Our dataset and code are released to the public to facilitate
further research in the field of multilingual LLM safety.

</details>


### [110] [CRED-SQL: Enhancing Real-world Large Scale Database Text-to-SQL Parsing through Cluster Retrieval and Execution Description](https://arxiv.org/abs/2508.12769)
*Shaoming Duan,Zirui Wang,Chuanyi Liu,Zhibin Zhu,Yuhao Zhang,Peiyi Han,Liang Yan,Zewu Penge*

Main category: cs.CL

TL;DR: CRED-SQL是一个针对大规模数据库的Text-to-SQL框架，通过集群检索和执行描述语言来解决语义不匹配问题，在两个大型跨域基准测试中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然提升了Text-to-SQL系统的准确性，但在大规模数据库中仍然存在自然语言问题与SQL查询之间的语义不匹配问题，特别是在语义相似的属性导致模式链接困难和语义漂移的情况下。

Method: CRED-SQL框架包含两个核心组件：1）基于集群的大规模模式检索，用于精确定位与自然语言问题最相关的表和列；2）执行描述语言（EDL）作为中间自然语言表示，将任务分解为Text-to-EDL和EDL-to-SQL两个阶段。

Result: 在SpiderUnion和BirdUnion两个大规模跨域基准测试上的广泛实验表明，CRED-SQL实现了新的最先进（SOTA）性能，验证了其有效性和可扩展性。

Conclusion: CRED-SQL通过集群检索和中间执行描述语言的创新设计，有效解决了大规模数据库中Text-to-SQL的语义不匹配问题，显著提升了模型准确性，为大规模数据库的语义解析提供了有效解决方案。

Abstract: Recent advances in large language models (LLMs) have significantly improved
the accuracy of Text-to-SQL systems. However, a critical challenge remains: the
semantic mismatch between natural language questions (NLQs) and their
corresponding SQL queries. This issue is exacerbated in large-scale databases,
where semantically similar attributes hinder schema linking and semantic drift
during SQL generation, ultimately reducing model accuracy. To address these
challenges, we introduce CRED-SQL, a framework designed for large-scale
databases that integrates Cluster Retrieval and Execution Description. CRED-SQL
first performs cluster-based large-scale schema retrieval to pinpoint the
tables and columns most relevant to a given NLQ, alleviating schema mismatch.
It then introduces an intermediate natural language representation-Execution
Description Language (EDL)-to bridge the gap between NLQs and SQL. This
reformulation decomposes the task into two stages: Text-to-EDL and EDL-to-SQL,
leveraging LLMs' strong general reasoning capabilities while reducing semantic
deviation. Extensive experiments on two large-scale, cross-domain
benchmarks-SpiderUnion and BirdUnion-demonstrate that CRED-SQL achieves new
state-of-the-art (SOTA) performance, validating its effectiveness and
scalability. Our code is available at https://github.com/smduan/CRED-SQL.git

</details>


### [111] [From SALAMANDRA to SALAMANDRATA: BSC Submission for WMT25 General Machine Translation Shared Task](https://arxiv.org/abs/2508.12774)
*Javier Garcia Gilabert,Xixian Liao,Severino Da Dalt,Ella Bohman,Audrey Mash,Francesca De Luca Fornaciari,Irene Baucells,Joan Llop,Miguel Claramunt Argote,Carlos Escolano,Maite Melero*

Main category: cs.CL

TL;DR: SALAMANDRATA模型家族是针对38种欧洲语言翻译任务优化的改进版本，包含2B和7B两个规模，采用持续预训练和监督微调两阶段训练方法，并在WMT25机器翻译任务中使用了质量感知解码策略。


<details>
  <summary>Details</summary>
Motivation: 改进SALAMANDRA LLMs模型，专门针对38种欧洲语言的翻译相关任务实现更强性能，并为WMT25通用机器翻译共享任务提供高质量解决方案。

Method: 采用两阶段训练方法：首先在平行数据上进行持续预训练，然后在高质量指令上进行监督微调。针对WMT25任务，调整词汇表支持非欧洲语言，并采用最小贝叶斯风险解码和基于COMET/COMET-KIWI的调优重排序策略。

Result: 开发了2B和7B两个版本的SALAMANDRATA模型，以及更新的SALAMANDRATA-V2模型，所有模型已在Hugging Face平台公开发布。

Conclusion: SALAMANDRATA模型家族通过改进的训练方法和质量感知解码策略，为多语言机器翻译任务提供了有效的解决方案，特别是在欧洲语言翻译方面表现出色。

Abstract: In this paper, we present the SALAMANDRATA family of models, an improved
iteration of SALAMANDRA LLMs (Gonzalez-Agirre et al., 2025) specifically
trained to achieve strong performance in translation-related tasks for 38
European languages. SALAMANDRATA comes in two scales: 2B and 7B parameters. For
both versions, we applied the same training recipe with a first step of
continual pre-training on parallel data, and a second step of supervised
fine-tuning on high-quality instructions. The BSC submission to the WMT25
General Machine Translation shared task is based on the 7B variant of
SALAMANDRATA. We first adapted the model vocabulary to support the additional
non-European languages included in the task. This was followed by a second
phase of continual pre-training and supervised fine-tuning, carefully designed
to optimize performance across all translation directions for this year's
shared task. For decoding, we employed two quality-aware strategies: Minimum
Bayes Risk Decoding and Tuned Re-ranking using COMET and COMET-KIWI
respectively. We publicly release both the 2B and 7B versions of SALAMANDRATA,
along with the newer SALAMANDRATA-V2 model, on Hugging Face1

</details>


### [112] [HeteroRAG: A Heterogeneous Retrieval-Augmented Generation Framework for Medical Vision Language Tasks](https://arxiv.org/abs/2508.12778)
*Zhe Chen,Yusheng Liao,Shuyang Jiang,Zhiyuan Zhu,Haolin Li,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 医疗大型视觉-语言模型存在事实错误问题，研究提出HeteroRAG框架，通过异构知识源增强模型的准确性和可靠性


<details>
  <summary>Details</summary>
Motivation: 当前医疗多模态RAG系统无法在异构数据源中进行有效检索，检索到的报告不相关影响分析的事实性，知识不充分影响临床决策的可靠性

Method: 构建MedAtlas多模态报告库和文本语料库，提出HeteroRAG框架：使用模态特异性CLIPs进行报告检索，多语料库查询生成器动态构建查询，通过异构知识偏好循环进行跨模态多源知识对齐

Result: 在12个数据集和3种模态上的实验表明，HeteroRAG在大多数医疗视觉语言测试中达到最佳性能，显著提高了Med-LVLMs的事实准确性和可靠性

Conclusion: HeteroRAG框架通过异构知识源的有效利用，成功提升了医疗大型视觉-语言模型的临床应用价值，解决了实际诊断中的风险问题

Abstract: Medical large vision-language Models (Med-LVLMs) have shown promise in
clinical applications but suffer from factual inaccuracies and unreliable
outputs, posing risks in real-world diagnostics. While retrieval-augmented
generation has emerged as a potential solution, current medical multimodal RAG
systems are unable to perform effective retrieval across heterogeneous sources.
The irrelevance of retrieved reports affects the factuality of analysis, while
insufficient knowledge affects the credibility of clinical decision-making. To
bridge the gap, we construct MedAtlas, which includes extensive multimodal
report repositories and diverse text corpora. Based on it, we present
HeteroRAG, a novel framework that enhances Med-LVLMs through heterogeneous
knowledge sources. The framework introduces Modality-specific CLIPs for
effective report retrieval and a Multi-corpora Query Generator for dynamically
constructing queries for diverse corpora. Incorporating knowledge from such
multifaceted sources, Med-LVLM is then trained with Heterogeneous Knowledge
Preference Tuning to achieve cross-modality and multi-source knowledge
alignment. Extensive experiments across 12 datasets and 3 modalities
demonstrate that the proposed HeteroRAG achieves state-of-the-art performance
in most medical vision language benchmarks, significantly improving factual
accuracy and reliability of Med-LVLMs.

</details>


### [113] [Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward](https://arxiv.org/abs/2508.12800)
*Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Changhua Meng*

Main category: cs.CL

TL;DR: 提出了Atomic Thought思维范式和Atom-Searcher强化学习框架，通过细粒度推理单元和过程奖励机制，解决了传统RAG和基于结果的RL在多跳推理和战略搜索中的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务中存在静态知识限制，传统RAG方法在多跳推理和战略搜索方面表现不佳，而基于结果的强化学习方法存在梯度冲突和奖励稀疏问题。

Method: 1. Atomic Thought：将推理分解为细粒度功能单元；2. Reasoning Reward Models提供Atomic Thought Rewards进行细粒度指导；3. Atom-Searcher框架整合上述方法，采用课程式奖励调度策略。

Result: 在七个基准测试中均取得了优于现有技术的性能提升，具有测试时计算可扩展性、更好的可解释性和更接近人类推理模式等优势。

Conclusion: Atomic Thought和Atom-Searcher框架有效解决了多跳推理和战略搜索中的关键挑战，为智能深度研究提供了新的解决方案。

Abstract: Large language models (LLMs) exhibit remarkable problem-solving abilities,
but struggle with complex tasks due to static internal knowledge.
Retrieval-Augmented Generation (RAG) enhances access to external information,
yet remains limited in multi-hop reasoning and strategic search due to rigid
workflows. Recent advancements in agentic deep research empower LLMs to
autonomously reason, search, and synthesize information. However, current
approaches relying on outcome-based reinforcement learning (RL) face critical
issues such as conflicting gradients and reward sparsity, limiting performance
gains and training efficiency. To address these, we first propose Atomic
Thought, a novel LLM thinking paradigm that decomposes reasoning into
fine-grained functional units. These units are supervised by Reasoning Reward
Models (RRMs), which provide Atomic Thought Rewards (ATR) for fine-grained
guidance. Building on this, we propose Atom-Searcher, a novel RL framework for
agentic deep research that integrates Atomic Thought and ATR. Atom-Searcher
uses a curriculum-inspired reward schedule, prioritizing process-level ATR
early and transitioning to outcome rewards, accelerating convergence on
effective reasoning paths. Experiments on seven benchmarks show consistent
improvements over the state-of-the-art. Key advantages include: (1)
Atom-Searcher scales computation at test-time. (2) Atomic Thought provides
supervision anchors for RRMs, bridging deep research tasks and RRMs. (3)
Atom-Searcher exhibits more interpretable, human-like reasoning patterns.

</details>


### [114] [When Alignment Hurts: Decoupling Representational Spaces in Multilingual Models](https://arxiv.org/abs/2508.12803)
*Ahmed Elshabrawy,Hour Kaing,Haiyue Song,Alham Fikri Aji,Hideki Tanaka,Masao Utiyama,Raj Dabre*

Main category: cs.CL

TL;DR: 研究表明，高资源标准语言（如现代标准阿拉伯语）的过度表征纠缠会阻碍相关低资源方言（如阿拉伯方言）的生成建模。通过在线变分探测框架和子空间干预，实现了方言生成质量的显著提升。


<details>
  <summary>Details</summary>
Motivation: 挑战传统假设，即高资源标准语言对齐总是有助于相关低资源变体的建模。发现过度依赖主导变体反而会限制生成能力，特别是在阿拉伯方言与MSA的关系中。

Method: 开发在线变分探测框架，在微调过程中持续估计标准变体的子空间，并基于投影实现解耦。使用25种阿拉伯方言的平行语料进行因果干预研究。

Result: 在25种方言上，干预使生成质量平均提升+2.0 chrF++，最高提升+4.9 chrF++，尽管标准语言性能有所下降。

Conclusion: 提供了因果证据表明高资源变体的子空间主导会限制相关变体的生成能力。统一了几何和信息论探测与子空间级因果干预，为多语言和多领域LLM的表征分配控制提供了实用工具。

Abstract: Alignment with high-resource standard languages is often assumed to aid the
modeling of related low-resource varieties. We challenge this assumption by
demonstrating that excessive representational entanglement with a dominant
variety, such as Modern Standard Arabic (MSA) in relation to Arabic dialects,
can actively hinder generative modeling. We present the first comprehensive
causal study of this phenomenon by analyzing and directly intervening in the
internal representation geometry of large language models (LLMs). Our key
contribution is an online variational probing framework that continuously
estimates the subspace of the standard variety during fine-tuning, enabling
projection-based decoupling from this space. While our study uses Arabic as a
case due to its unusually rich parallel resources across 25 dialects, the
broader motivation is methodological: dialectal MT serves as a controlled proxy
for generative tasks where comparable multi-variety corpora are unavailable.
Across 25 dialects, our intervention improves generation quality by up to +4.9
chrF++ and +2.0 on average compared to standard fine-tuning, despite a measured
tradeoff in standard-language performance. These results provide causal
evidence that subspace dominance by high-resource varieties can restrict
generative capacity for related varieties. More generally, we unify geometric
and information-theoretic probing with subspace-level causal interventions,
offering practical tools for improving generative modeling in closely related
language families and, more broadly, for controlling representational
allocation in multilingual and multi-domain LLMs. Code will be released.

</details>


### [115] [ding-01 :ARG0: An AMR Corpus for Spontaneous French Dialogue](https://arxiv.org/abs/2508.12819)
*Jeongwoo Kang,Maria Boritchev,Maximin Coavoux*

Main category: cs.CL

TL;DR: 构建法语对话语义语料库，扩展AMR框架适应自发语谈特征，训练解析器支持注释工作


<details>
  <summary>Details</summary>
Motivation: 为法语对话发展语义资源，解决AMR在自发语谈和法语特有句法结构上的覆盖不足问题

Method: 注释Catan框架游戏自发对话语料，扩展AMR框架以更好表示自发语谈特征，制定详细注释指南，训练AMR解析器

Result: 建成了免费公开的法语语义语料库，训练的AMR解析器可作为协助注释工具提供初始注释

Conclusion: 该工作为法语对话语义资源开发做出贡献，扩展的AMR框架和协助注释工具有助于推进语义注释工作

Abstract: We present our work to build a French semantic corpus by annotating French
dialogue in Abstract Meaning Representation (AMR). Specifically, we annotate
the DinG corpus, consisting of transcripts of spontaneous French dialogues
recorded during the board game Catan. As AMR has insufficient coverage of the
dynamics of spontaneous speech, we extend the framework to better represent
spontaneous speech and sentence structures specific to French. Additionally, to
support consistent annotation, we provide an annotation guideline detailing
these extensions. We publish our corpus under a free license (CC-SA-BY). We
also train and evaluate an AMR parser on our data. This model can be used as an
assistance annotation tool to provide initial annotations that can be refined
by human annotators. Our work contributes to the development of semantic
resources for French dialogue.

</details>


### [116] [Context Matters: Incorporating Target Awareness in Conversational Abusive Language Detection](https://arxiv.org/abs/2508.12828)
*Raneem Alharthi,Rajwa Alharthi,Aiqi Jiang,Arkaitz Zubiaga*

Main category: cs.CL

TL;DR: 本研究探讨了利用父推文上下文特征来检测回复推文中的辱骂性语言，发现结合上下文特征相比仅使用回复推文特征能显著提升检测性能，其中基于内容的特征比基于账户的特征贡献更大。


<details>
  <summary>Details</summary>
Motivation: 现有的辱骂性语言检测研究主要关注单个社交媒体帖子，忽略了从周围帖子中获得的额外上下文信息。本研究旨在探索利用父推文的上下文信息是否有助于检测回复推文中的辱骂性语言。

Method: 研究使用了四种不同的分类模型，在一个由对话交换（父推文-回复推文对）组成的数据集上进行测试，其中回复被标记为辱骂性或非辱骂性。分析了基于内容和基于账户的上下文特征。

Result: 实验表明，结合上下文特征相比仅使用回复推文特征能带来显著改进。基于内容的特征对分类性能贡献最大，而基于账户的特征贡献较小。使用多种不同特征组合比选择性使用少量特征效果更好。

Conclusion: 本研究证实了在涉及对话的现实环境中利用上下文信息开发情境化辱骂性语言检测模型的重要性，为相关模型开发提供了重要见解。

Abstract: Abusive language detection has become an increasingly important task as a
means to tackle this type of harmful content in social media. There has been a
substantial body of research developing models for determining if a social
media post is abusive or not; however, this research has primarily focused on
exploiting social media posts individually, overlooking additional context that
can be derived from surrounding posts. In this study, we look at conversational
exchanges, where a user replies to an earlier post by another user (the parent
tweet). We ask: does leveraging context from the parent tweet help determine if
a reply post is abusive or not, and what are the features that contribute the
most? We study a range of content-based and account-based features derived from
the context, and compare this to the more widely studied approach of only
looking at the features from the reply tweet. For a more generalizable study,
we test four different classification models on a dataset made of
conversational exchanges (parent-reply tweet pairs) with replies labeled as
abusive or not. Our experiments show that incorporating contextual features
leads to substantial improvements compared to the use of features derived from
the reply tweet only, confirming the importance of leveraging context. We
observe that, among the features under study, it is especially the
content-based features (what is being posted) that contribute to the
classification performance rather than account-based features (who is posting
it). While using content-based features, it is best to combine a range of
different features to ensure improved performance over being more selective and
using fewer features. Our study provides insights into the development of
contextualized abusive language detection models in realistic settings
involving conversations.

</details>


### [117] [It takes a village to write a book: Mapping anonymous contributions in Stephen Langton's Quaestiones Theologiae](https://arxiv.org/abs/2508.12830)
*Jan Maliszewski*

Main category: cs.CL

TL;DR: 这篇论文提出了一种采用风格计量技术分析中世纪教育口讲记录文本的方法，以验证关于Stephen Langton神学问题集编试过程的假设。


<details>
  <summary>Details</summary>
Motivation: 虽然间接证据显示早期经院时期就存在基于口讲教学记录的文学创作，但很少有源头详细讨论这种实践。研究旨在探索这些口讲记录文本的编辑层次和创作过程。

Method: 采用风格计量归因技术，基于最常用词、词性标注和伪后缀进行分析。实施HTR（手写文本识别）处理流程，并测试基于transformer的OCR和自动词对齐技术在经院拉丁语语料库中的有效性。

Result: 这项研究将直接比较手工编写和自动提取数据的性能表现，为计算化研究中世纪经院传统提供方法论政盛。

Conclusion: 如果成功，这项研究将为中世纪大学协作文学产出的探索性分析提供一个容易重用的模板，推动对口讲传承文本创作过程的理解。

Abstract: While the indirect evidence suggests that already in the early scholastic
period the literary production based on records of oral teaching (so-called
reportationes) was not uncommon, there are very few sources commenting on the
practice. This paper details the design of a study applying stylometric
techniques of authorship attribution to a collection developed from
reportationes -- Stephen Langton's Quaestiones Theologiae -- aiming to uncover
layers of editorial work and thus validate some hypotheses regarding the
collection's formation. Following Camps, Cl\'erice, and Pinche (2021), I
discuss the implementation of an HTR pipeline and stylometric analysis based on
the most frequent words, POS tags, and pseudo-affixes. The proposed study will
offer two methodological gains relevant to computational research on the
scholastic tradition: it will directly compare performance on manually composed
and automatically extracted data, and it will test the validity of
transformer-based OCR and automated transcription alignment for workflows
applied to scholastic Latin corpora. If successful, this study will provide an
easily reusable template for the exploratory analysis of collaborative literary
production stemming from medieval universities.

</details>


### [118] [Word Meanings in Transformer Language Models](https://arxiv.org/abs/2508.12863)
*Jumbly Grindrod,Peter Grindrod*

Main category: cs.CL

TL;DR: 研究发现Transformer语言模型的词嵌入空间编码了丰富的语义信息，通过聚类分析验证了模型对多种心理语言学特征的敏感性，反驳了"意义消除主义"假说。


<details>
  <summary>Details</summary>
Motivation: 探究Transformer语言模型如何表示词汇含义，特别是是否存在类似词汇存储的机制，其中每个词条包含语义信息。

Method: 提取RoBERTa-base模型的词嵌入空间，使用k-means聚类为200个簇，手动检查簇的语义敏感性，并测试对五种心理语言学指标（情感价、具体性、象似性、禁忌性和习得年龄）的敏感性。

Result: 研究结果非常积极，词嵌入空间内编码了广泛的语义信息，簇对心理语言学特征表现出敏感性。

Conclusion: 这些发现排除了关于Transformer大语言模型如何处理语义信息的某些"意义消除主义"假说，证实了模型确实编码了丰富的语义表征。

Abstract: We investigate how word meanings are represented in the transformer language
models. Specifically, we focus on whether transformer models employ something
analogous to a lexical store - where each word has an entry that contains
semantic information. To do this, we extracted the token embedding space of
RoBERTa-base and k-means clustered it into 200 clusters. In our first study, we
then manually inspected the resultant clusters to consider whether they are
sensitive to semantic information. In our second study, we tested whether the
clusters are sensitive to five psycholinguistic measures: valence,
concreteness, iconicity, taboo, and age of acquisition. Overall, our findings
were very positive - there is a wide variety of semantic information encoded
within the token embedding space. This serves to rule out certain "meaning
eliminativist" hypotheses about how transformer LLMs process semantic
information.

</details>


### [119] [A Stitch in Time Saves Nine: Proactive Self-Refinement for Language Models](https://arxiv.org/abs/2508.12903)
*Jinyi Han,Xinyi Wang,Haiquan Zhao,Tingyun li,Zishang Jiang,Sihang Jiang,Jiaqing Liang,Xin Lin,Weikang Zhou,Zeye Sun,Fei Yu,Yanghua Xiao*

Main category: cs.CL

TL;DR: PASR是一种主动式自优化方法，让LLM在生成过程中动态决定是否、何时以及如何优化输出，相比固定迭代的被动方法显著提升了效率和准确性


<details>
  <summary>Details</summary>
Motivation: 现有自优化方法采用固定迭代的被动过程，难以根据生成上下文动态确定最佳优化时机和内容，而人类在思考过程中会动态优化思路

Method: 提出PASR方法，基于模型内部状态和演化上下文主动决定是否优化、何时优化以及如何优化，而不是重新生成整个响应

Result: 在10个任务上的实验表明，PASR显著提升问题解决性能：Qwen3-8B上平均token消耗减少41.6%，准确率提升8.2%

Conclusion: PASR通过主动式自优化在生成过程中动态优化输出，在减少计算成本的同时显著提升模型性能，为LLM自优化提供了新思路

Abstract: Recent advances in self-refinement have demonstrated significant potential
for improving the outputs of large language models (LLMs) through iterative
refinement. However, most existing self-refinement methods rely on a reactive
process with a fixed number of iterations, making it difficult to determine the
optimal timing and content of refinement based on the evolving generation
context. Inspired by the way humans dynamically refine their thoughts during
execution, we propose ProActive Self-Refinement (PASR), a novel method that
enables LLMs to refine their outputs during the generation process. Unlike
methods that regenerate entire responses, PASR proactively decides whether,
when, and how to refine based on the model's internal state and evolving
context. We conduct extensive experiments on a diverse set of 10 tasks to
evaluate the effectiveness of PASR. Experimental results show that PASR
significantly enhances problem-solving performance. In particular, on Qwen3-8B,
PASR reduces average token consumption by 41.6 percent compared to standard
generation, while also achieving an 8.2 percent improvement in accuracy. Our
code and all baselines used in the paper are available in the GitHub.

</details>


### [120] [Analyzing Information Sharing and Coordination in Multi-Agent Planning](https://arxiv.org/abs/2508.12981)
*Tianyue Ou,Saujas Vaduguru,Daniel Fried*

Main category: cs.CL

TL;DR: 论文研究了基于LLM的多智能体系统在旅行规划任务中的表现，通过引入笔记本机制和协调器智能体，显著提高了任务完成率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂的长时程、多约束规划任务中面临信息详细化和约束复杂性的挑战，需要更好的信息共享和协调机制。

Method: 构建基于LLM的多智能体系统进行旅行规划，评估笔记本机制促进信息共享的效果，以及协调器智能体在自由对话中的协调作用。

Result: 笔记本机制减少幻觉错误18%，协调器进一步减少错误13.5%。组合机制在TravelPlanner基准测试中达到25%通过率，相比单智能体基线7.5%有17.5%的绝对提升。

Conclusion: 结构化信息共享和反射式协调是多智能体系统中实现长时程规划的关键组件，具有重要潜力。

Abstract: Multi-agent systems (MASs) have pushed the boundaries of large language model
(LLM) agents in domains such as web research and software engineering. However,
long-horizon, multi-constraint planning tasks involve conditioning on detailed
information and satisfying complex interdependent constraints, which can pose a
challenge for these systems. In this study, we construct an LLM-based MAS for a
travel planning task which is representative of these challenges. We evaluate
the impact of a notebook to facilitate information sharing, and evaluate an
orchestrator agent to improve coordination in free form conversation between
agents. We find that the notebook reduces errors due to hallucinated details by
18%, while an orchestrator directs the MAS to focus on and further reduce
errors by up to 13.5% within focused sub-areas. Combining both mechanisms
achieves a 25% final pass rate on the TravelPlanner benchmark, a 17.5% absolute
improvement over the single-agent baseline's 7.5% pass rate. These results
highlight the potential of structured information sharing and reflective
orchestration as key components in MASs for long horizon planning with LLMs.

</details>


### [121] [WebMall -- A Multi-Shop Benchmark for Evaluating Web Agents](https://arxiv.org/abs/2508.13024)
*Ralph Peeters,Aaron Steiner,Luca Schwarz,Julian Yuya Caspary,Christian Bizer*

Main category: cs.CL

TL;DR: WebMall是一个多商店在线购物基准测试，用于评估网络代理在比较购物中的效果和效率，包含4个模拟商店和91个跨商店任务，比现有基准更复杂和真实。


<details>
  <summary>Details</summary>
Motivation: 现有的电子商务基准如WebShop或ShoppingBench缺乏跨商店比较购物任务，产品异质性不足，无法充分评估网络代理在真实购物场景中的表现。

Method: 构建包含4个模拟在线商店的基准，产品来自Common Crawl的真实商品数据，包含91个跨商店任务，分为基础任务和高级任务，并评估8种不同配置的基线代理。

Result: 最佳配置在基础任务集上达到75%完成率和87% F1分数，在高级任务集上达到53%完成率和63% F1分数。

Conclusion: WebMall基准测试公开发布，可促进网络代理在电子商务场景中的导航、推理和效率方面的研究进展，比现有基准更具挑战性和真实性。

Abstract: LLM-based web agents have the potential to automate long-running web tasks,
such as finding offers for specific products in multiple online shops and
subsequently ordering the cheapest products that meet the users needs. This
paper introduces WebMall, a multi-shop online shopping benchmark for evaluating
the effectiveness and efficiency of web agents for comparison-shopping. WebMall
consists of four simulated online shops populated with authentic product offers
sourced from the Common Crawl, alongside a suite of 91 cross-shop tasks. These
tasks include basic tasks such as finding specific products in multiple shops,
performing price comparisons, adding items to the shopping cart, and completing
checkout. Advanced tasks involve searching for products based on vague
requirements, identifying suitable substitutes, and finding compatible
products. Compared to existing e-commerce benchmarks, such as WebShop or
ShoppingBench, WebMall introduces comparison-shopping tasks across multiple
shops. Furthermore, the product offers are more heterogeneous, as they
originate from hundreds of distinct real-world shops. The tasks in WebMall
require longer interaction trajectories than those in WebShop, while remaining
representative of real-world shopping behaviors. We evaluate eight baseline
agents on WebMall, varying in observation modality, memory utilization, and
underlying large language model (GPT 4.1 and Claude Sonnet 4). The
best-performing configurations achieve completion rates of 75% and 53%, and F1
scores of 87% and 63%, on the basic and advanced task sets, respectively.
WebMall is publicly released to facilitate research on web agents and to
promote advancements in navigation, reasoning, and efficiency within e-commerce
scenarios.

</details>


### [122] [Integrating Feedback Loss from Bi-modal Sarcasm Detector for Sarcastic Speech Synthesis](https://arxiv.org/abs/2508.13028)
*Zhu Li,Yuqing Zhang,Xiyuan Gao,Devraj Raghuvanshi,Nagendra Kumar,Shekhar Nayak,Matt Coler*

Main category: cs.CL

TL;DR: 通过双模态豫刺检测模型的反馈损失和两阶段迅速学习方法，提升了语音合成的豫刺效果和自然度


<details>
  <summary>Details</summary>
Motivation: 豫刺语音合成对于娱乐和人机交互应用至关重要，但因豫刺语调细微复杂且标注数据稀缺而面临挑战

Method: 集成双模态豫刺检测模型的反馈损失到TTS训练中，采用两阶段迅速学习：先在多样化语音样式数据上微调，然后在豫刺语音数据上精细调整

Result: 客观和主观评估都证明方法能够提升合成语音的质量、自然度和豫刺识别能力

Conclusion: 该研究提出的方法有效解决了豫刺语音合成的挑战，为更自然的人机交互提供了技术支撑

Abstract: Sarcastic speech synthesis, which involves generating speech that effectively
conveys sarcasm, is essential for enhancing natural interactions in
applications such as entertainment and human-computer interaction. However,
synthesizing sarcastic speech remains a challenge due to the nuanced prosody
that characterizes sarcasm, as well as the limited availability of annotated
sarcastic speech data. To address these challenges, this study introduces a
novel approach that integrates feedback loss from a bi-modal sarcasm detection
model into the TTS training process, enhancing the model's ability to capture
and convey sarcasm. In addition, by leveraging transfer learning, a speech
synthesis model pre-trained on read speech undergoes a two-stage fine-tuning
process. First, it is fine-tuned on a diverse dataset encompassing various
speech styles, including sarcastic speech. In the second stage, the model is
further refined using a dataset focused specifically on sarcastic speech,
enhancing its ability to generate sarcasm-aware speech. Objective and
subjective evaluations demonstrate that our proposed methods improve the
quality, naturalness, and sarcasm-awareness of synthesized speech.

</details>


### [123] [Can Large Models Teach Student Models to Solve Mathematical Problems Like Human Beings? A Reasoning Distillation Method via Multi-LoRA Interaction](https://arxiv.org/abs/2508.13037)
*Xinhe Li,Jiajun Liu,Peng Wang*

Main category: cs.CL

TL;DR: 提出LoRID方法，通过多LoRA交互实现数学推理蒸馏，结合直觉推理和深度推理两种思维模式，显著提升小语言模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型数学推理能力差的问题，现有方法主要依赖大语言模型生成大量数据进行填鸭式训练，类似于心理学中的系统1思维，但缺乏系统2思维的知识获取和强化过程。

Method: 基于多LoRA交互的数学推理蒸馏方法：1）创建知识增强数据集；2）训练直觉推理器直接生成思维链；3）训练知识生成器和深度推理器模仿系统2思维；4）通过一致性评估和迭代推理实现相互反馈。

Result: 在GSM8K数据集上达到最先进性能，在五个基础模型上分别比第二好方法准确率提升2.3%、16.1%、2.4%、12.3%和1.8%。

Conclusion: LoRID方法通过结合系统1和系统2两种思维模式，有效提升了小语言模型的数学推理能力，证明了多LoRA交互蒸馏的有效性。

Abstract: Recent studies have demonstrated that Large Language Models (LLMs) have
strong mathematical reasoning abilities but rely on hundreds of billions of
parameters. To tackle the challenge of poor reasoning in Small Language Models
(SLMs), existing methods typically leverage LLMs to generate massive amounts of
data for cramming training. In psychology, they are akin to System 1 thinking,
which resolves reasoning problems rapidly based on experience and intuition.
However, human learning also requires System 2 thinking, where knowledge is
first acquired and then reinforced through practice. Inspired by such two
distinct modes of thinking, we propose a novel method based on the multi-LoRA
Interaction for mathematical reasoning Distillation (LoRID). First, we input
the question and reasoning of each sample into an LLM to create
knowledge-enhanced datasets. Subsequently, we train a LoRA block on the student
model as an Intuitive Reasoner (IR), which directly generates Chain-of-Thoughts
for problem-solving. Then, to imitate System 2 thinking, we train the Knowledge
Generator (KG) and Deep Reasoner (DR), respectively. The former outputs only
knowledge after receiving problems, while the latter uses that knowledge to
perform reasoning. Finally, to address the randomness in the generation of IR
and DR, we evaluate whether their outputs are consistent, and the inference
process needs to be iterated if not. This step can enhance the mathematical
reasoning ability of SLMs through mutual feedback. Experimental results show
that LoRID achieves state-of-the-art performance, especially on the GSM8K
dataset, where it outperforms the second-best method by 2.3%, 16.1%, 2.4%,
12.3%, and 1.8% accuracy across the five base models, respectively.

</details>


### [124] [Büyük Dil Modelleri için TR-MMLU Benchmarkı: Performans Değerlendirmesi, Zorluklar ve İyileştirme Fırsatları](https://arxiv.org/abs/2508.13044)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Banu Diri,Savaş Yıldırım,Öner Aytaş*

Main category: cs.CL

TL;DR: 土耳其语言模型评估标准缺失，研究团队提出TR-MMLU评测框架，包否6200道多选题，用于评测土耳其语LLM的语言理解能力


<details>
  <summary>Details</summary>
Motivation: 语言模型在多语言领域取得重大进展，但对于资源有限的语言（如土耳其语）的评估方法仍然缺乏，需要专门的评测标准来提升模型设计

Method: 开发TR-MMLU评测框架，组建包否6200道多选题的数据集，涵盖62个土耳其教育系统中的不同学科领域，对现有最先进的LLM进行评测

Result: TR-MMLU为土耳其语NLP研究提供了标准化的评估框架，能够详细分析LLM在处理土耳其语文本时的能力特点和不足之处

Conclusion: TR-MMLU设置了土耳其语NLP研究的新标准，为提升语言模型在土耳其语上的表现提供了重要的评测工具，将激励未来的创新研究

Abstract: Language models have made significant advancements in understanding and
generating human language, achieving remarkable success in various
applications. However, evaluating these models remains a challenge,
particularly for resource-limited languages like Turkish. To address this
issue, we introduce the Turkish MMLU (TR-MMLU) benchmark, a comprehensive
evaluation framework designed to assess the linguistic and conceptual
capabilities of large language models (LLMs) in Turkish. TR-MMLU is based on a
meticulously curated dataset comprising 6,200 multiple-choice questions across
62 sections within the Turkish education system. This benchmark provides a
standard framework for Turkish NLP research, enabling detailed analyses of
LLMs' capabilities in processing Turkish text. In this study, we evaluated
state-of-the-art LLMs on TR-MMLU, highlighting areas for improvement in model
design. TR-MMLU sets a new standard for advancing Turkish NLP research and
inspiring future innovations.

</details>


### [125] [Doğal Dil İşlemede Tokenizasyon Standartları ve Ölçümü: Türkçe Üzerinden Büyük Dil Modellerinin Karşılaştırmalı Analizi](https://arxiv.org/abs/2508.13058)
*M. Ali Bayram,Ali Arda Fincan,Ahmet Semih Gümüş,Sercan Karakaş,Banu Diri,Savaş Yıldırım*

Main category: cs.CL

TL;DR: 这篇论文提出了一种新的标记化评估框架，重点关注语法丰富和资源稀缺语言（如土耳其语）的标记化问题，发现语言特定标记百分比比标记纯度更能预测下游性能。


<details>
  <summary>Details</summary>
Motivation: 标记化是NLP中的基础预处理步骤，对大语言模型的语言学和语义理解能力有重要影响。对于语法丰富和资源稀缺的语言，标准标记化方法存在特别挑战，需要专门的评估框架来量化其效果。

Method: 使用土耳其语MMLU（TR-MMLU）数据集（包含6,200道多选题），提出了一系列新的评估指标：词汇量大小、标记数量、处理时间、语言特定标记百分比（%TR）和标记纯度（%Pure），用于评估标记化器保留语言结构的有效性。

Result: 分析显示语言特定标记百分比（%TR）与下游性能（如MMLU分数）的相关性更强，而标记纯度（%Pure）的相关性较弱。仅增加模型参数并不能必然提升语言性能，强调了需要针对特定语言进行尺度化标记化的重要性。

Conclusion: 该研究提出的评估框架为语法复杂语言建立了健壮而实用的标记化标准，显示了语言特定标记百分比在预测下游性能方面的优势，并强调了针对特定语言进行标记化调整的必要性。

Abstract: Tokenization is a fundamental preprocessing step in Natural Language
Processing (NLP), significantly impacting the capability of large language
models (LLMs) to capture linguistic and semantic nuances. This study introduces
a novel evaluation framework addressing tokenization challenges specific to
morphologically-rich and low-resource languages such as Turkish. Utilizing the
Turkish MMLU (TR-MMLU) dataset, comprising 6,200 multiple-choice questions from
the Turkish education system, we assessed tokenizers based on vocabulary size,
token count, processing time, language-specific token percentages (\%TR), and
token purity (\%Pure). These newly proposed metrics measure how effectively
tokenizers preserve linguistic structures. Our analysis reveals that
language-specific token percentages exhibit a stronger correlation with
downstream performance (e.g., MMLU scores) than token purity. Furthermore,
increasing model parameters alone does not necessarily enhance linguistic
performance, underscoring the importance of tailored, language-specific
tokenization methods. The proposed framework establishes robust and practical
tokenization standards for morphologically complex languages.

</details>


### [126] [Evaluating ASR robustness to spontaneous speech errors: A study of WhisperX using a Speech Error Database](https://arxiv.org/abs/2508.13060)
*John Alderete,Macarious Kin Fung Hui,Aanchan Mohan*

Main category: cs.CL

TL;DR: SFUSED语音错误数据库可用于评估语音识别模型性能，通过分析WhisperX在5300个标注错误上的转录准确率，验证了该数据库作为ASR系统诊断工具的有效性


<details>
  <summary>Details</summary>
Motivation: 开发一个公开的语音错误数据库，用于语言学和心理语言学研究，并展示其如何用于测试和评估语音识别模型

Method: 使用SFUSED数据库中的系统标注语音错误（包括意图和实际错误产生），评估WhisperX模型在5300个文档化词汇和音韵错误上的转录准确性

Result: 分析证明了该数据库作为ASR系统性能诊断工具的有效性

Conclusion: SFUSED数据库的设计和标注能够有效用于语音识别模型的测试和评估，提供了多维度分类变量来评估模型性能

Abstract: The Simon Fraser University Speech Error Database (SFUSED) is a public data
collection developed for linguistic and psycholinguistic research. Here we
demonstrate how its design and annotations can be used to test and evaluate
speech recognition models. The database comprises systematically annotated
speech errors from spontaneous English speech, with each error tagged for
intended and actual error productions. The annotation schema incorporates
multiple classificatory dimensions that are of some value to model assessment,
including linguistic hierarchical level, contextual sensitivity, degraded
words, word corrections, and both word-level and syllable-level error
positioning. To assess the value of these classificatory variables, we
evaluated the transcription accuracy of WhisperX across 5,300 documented word
and phonological errors. This analysis demonstrates the atabase's effectiveness
as a diagnostic tool for ASR system performance.

</details>


### [127] [Reinforced Context Order Recovery for Adaptive Reasoning and Planning](https://arxiv.org/abs/2508.13070)
*Long Ma,Fangwei Zhong,Yizhou Wang*

Main category: cs.CL

TL;DR: 提出ReCOR强化学习框架，从文本数据中提取自适应、数据依赖的token生成顺序，无需标注，在推理和规划任务上表现优异


<details>
  <summary>Details</summary>
Motivation: 当前因果和扩散模型使用固定或随机token生成顺序，与原始逻辑顺序存在偏差，在处理需要自适应token生成顺序的问题时遇到困难

Method: 基于强化学习的ReCOR框架，通过token预测统计进行自监督，估计每个未填充token的预测难度，在训练和推理过程中自适应选择下一个token

Result: 在具有挑战性的推理和规划数据集上，ReCOR表现出优于基线模型的性能，有时甚至超过使用真实顺序监督的oracle模型

Conclusion: 自适应token生成顺序对于复杂推理任务至关重要，ReCOR框架能够有效提取数据依赖的生成顺序，提升模型性能

Abstract: Modern causal language models, followed by rapid developments in discrete
diffusion models, can now produce a wide variety of interesting and useful
content. However, these families of models are predominantly trained to output
tokens with a fixed (left-to-right) or random order, which may deviate from the
logical order in which tokens are generated originally. In this paper, we
observe that current causal and diffusion models encounter difficulties in
problems that require adaptive token generation orders to solve tractably,
which we characterize with the $\mathcal{V}$-information framework. Motivated
by this, we propose Reinforced Context Order Recovery (ReCOR), a
reinforcement-learning-based framework to extract adaptive, data-dependent
token generation orders from text data without annotations. Self-supervised by
token prediction statistics, ReCOR estimates the hardness of predicting every
unfilled token and adaptively selects the next token during both training and
inference. Experiments on challenging reasoning and planning datasets
demonstrate the superior performance of ReCOR compared with baselines,
sometimes outperforming oracle models supervised with the ground-truth order.

</details>


### [128] [DocHPLT: A Massively Multilingual Document-Level Translation Dataset](https://arxiv.org/abs/2508.13079)
*Dayyán O'Brien,Bhavitvya Malik,Ona de Gibert,Pinzhen Chen,Barry Haddow,Jörg Tiedemann*

Main category: cs.CL

TL;DR: 创建了DocHPLT，这是迄今为止最大的公开文档级翻译数据集，包含50种语言与英语配对的1.24亿个对齐文档对，共42.6亿个句子，为多语言文档级翻译提供基础设施。


<details>
  <summary>Details</summary>
Motivation: 现有文档级机器翻译资源仅适用于少数高资源语言，需要为全球社区提供长上下文建模的训练和评估资源。

Method: 修改现有的网络提取流程以保持源文档的完整性，保留所有内容包括未对齐部分，而不是基于句子级数据重建文档。

Result: LLM在DocHPLT上微调后显著优于现成的指令调优基线，特别是对低资源语言的改进尤为显著。

Conclusion: DocHPLT数据集在宽松许可下开源，为推进多语言文档级翻译提供了必要的基础设施。

Abstract: Existing document-level machine translation resources are only available for
a handful of languages, mostly high-resourced ones. To facilitate the training
and evaluation of document-level translation and, more broadly, long-context
modeling for global communities, we create DocHPLT, the largest publicly
available document-level translation dataset to date. It contains 124 million
aligned document pairs across 50 languages paired with English, comprising 4.26
billion sentences, with further possibility to provide 2500 bonus pairs not
involving English. Unlike previous reconstruction-based approaches that piece
together documents from sentence-level data, we modify an existing web
extraction pipeline to preserve complete document integrity from the source,
retaining all content including unaligned portions. After our preliminary
experiments identify the optimal training context strategy for document-level
translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially
outperform off-the-shelf instruction-tuned baselines, with particularly
dramatic improvements for under-resourced languages. We open-source the dataset
under a permissive license, providing essential infrastructure for advancing
multilingual document-level translation.

</details>


### [129] [All for law and law for all: Adaptive RAG Pipeline for Legal Research](https://arxiv.org/abs/2508.13107)
*Figarri Keisha,Prince Singh,Pallavi,Dion Fernandes,Aravindh Manivannan,Ilham Wicaksono,Faisal Ahmad*

Main category: cs.CL

TL;DR: 通过三项具体改进（上下文感知查询翻译、开源检索策略、综合评估框架）扩展了法律领域RAG基准，在保持成本效率的同时实现了显著的检索性能提升，并通过法律基础提示生成更准确可靠的答案。


<details>
  <summary>Details</summary>
Motivation: 法律领域对于准确性和可考性要求极高，RAG技术能够通过引用来源基础大语言模型输出，减少幻觉现象。但现有的基准方案在检索质量和成本效率方面仍有改进空间。

Method: 构建了一个端到端的RAG流水线，包括：1）上下文感知查询翻译器，能够解析文档引用和自然语言问题，根据专业性和具体性调整检索深度和响应风格；2）使用SBERT和GTE嵌入的开源检索策略；3）结合RAGAS、BERTScore-F1和ROUGE-Recall的综合评估框架。

Result: 开源检索策略实现了显著性能提升：Recall@K提高30-95%，Precision@K提高约2.5倍（K>4时），同时保持成本效率。经过优化的法律基础提示比基准提示能够产生更准确可靠、上下文更相关的答案。细心设计的开源流水线在检索质量上可以与专有方案相竞争或更优。

Conclusion: 通过任务感知的组件级制调整，可以实现具有法律基础、可复现性和成本效益的RAG系统，为法律研究辅助提供有效支持。这些改进为法律领域的自动化信息检索和回答生成开启了新的可能性。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucinations by grounding
large language model outputs in cited sources, a capability that is especially
critical in the legal domain. We present an end-to-end RAG pipeline that
revisits and extends the LegalBenchRAG baseline with three targeted
enhancements: (i) a context-aware query translator that disentangles document
references from natural-language questions and adapts retrieval depth and
response style based on expertise and specificity, (ii) open-source retrieval
strategies using SBERT and GTE embeddings that achieve substantial performance
gains (improving Recall@K by 30-95\% and Precision@K by $\sim$2.5$\times$ for
$K>4$) while remaining cost-efficient, and (iii) a comprehensive evaluation and
generation framework that combines RAGAS, BERTScore-F1, and ROUGE-Recall to
assess semantic alignment and faithfulness across models and prompt designs.
Our results show that carefully designed open-source pipelines can rival or
outperform proprietary approaches in retrieval quality, while a custom
legal-grounded prompt consistently produces more faithful and contextually
relevant answers than baseline prompting. Taken together, these contributions
demonstrate the potential of task-aware, component-level tuning to deliver
legally grounded, reproducible, and cost-effective RAG systems for legal
research assistance.

</details>


### [130] [AutoBnB-RAG: Enhancing Multi-Agent Incident Response with Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13118)
*Zefang Liu,Arman Anwar*

Main category: cs.CL

TL;DR: AutoBnB-RAG扩展了AutoBnB框架，通过检索增强生成(RAG)技术为多智能体事件响应模拟提供外部知识支持，显著提升了网络安全决策质量


<details>
  <summary>Details</summary>
Motivation: 传统LLM在事件响应中的推理能力受限于缺乏外部知识访问，需要增强其获取和利用外部信息的能力

Method: 基于Backdoors & Breaches游戏环境构建AutoBnB-RAG框架，引入两种检索设置(RAG-Wiki技术文档和RAG-News事件报告)，评估8种团队结构

Result: 检索增强显著提高了决策质量和成功率，能够重建复杂的多阶段网络攻击

Conclusion: 将检索机制集成到基于LLM的多智能体系统中对网络安全决策具有重要价值

Abstract: Incident response (IR) requires fast, coordinated, and well-informed
decision-making to contain and mitigate cyber threats. While large language
models (LLMs) have shown promise as autonomous agents in simulated IR settings,
their reasoning is often limited by a lack of access to external knowledge. In
this work, we present AutoBnB-RAG, an extension of the AutoBnB framework that
incorporates retrieval-augmented generation (RAG) into multi-agent incident
response simulations. Built on the Backdoors & Breaches (B&B) tabletop game
environment, AutoBnB-RAG enables agents to issue retrieval queries and
incorporate external evidence during collaborative investigations. We introduce
two retrieval settings: one grounded in curated technical documentation
(RAG-Wiki), and another using narrative-style incident reports (RAG-News). We
evaluate performance across eight team structures, including newly introduced
argumentative configurations designed to promote critical reasoning. To
validate practical utility, we also simulate real-world cyber incidents based
on public breach reports, demonstrating AutoBnB-RAG's ability to reconstruct
complex multi-stage attacks. Our results show that retrieval augmentation
improves decision quality and success rates across diverse organizational
models. This work demonstrates the value of integrating retrieval mechanisms
into LLM-based multi-agent systems for cybersecurity decision-making.

</details>


### [131] [Spot the BlindSpots: Systematic Identification and Quantification of Fine-Grained LLM Biases in Contact Center Summaries](https://arxiv.org/abs/2508.13124)
*Kawin Mayilvaghanan,Siddhant Gupta,Ayush Kumar*

Main category: cs.CL

TL;DR: 这篇论文提出了一个叫BlindSpot的框架，用于识别和量化联系中心中LLM摘要生成的运营偏见问题。研究发现所有模型都存在系统性偏见。


<details>
  <summary>Details</summary>
Motivation: 联系中心中LLM生成的摘要语音记录虽然质量表面上不错，但不知道是否存在系统性的偏见问题，特别是与运营相关的偏见维度。

Method: 开发了BlindSpot框架，基于15个运营偏见维度的分类法，利用LLM作为零样本分类器来得到语音记录和摘要的分布。使用信度间隔和覆盖率两个指标来量化偏见。

Result: 对2500个真实语音记录和20个不同规模、不同系列的LLM生成的摘要进行分析，发现所有模型都存在系统性的运营偏见问题。

Conclusion: 联系中心中LLM摘要生成存在普遍的运营偏见问题，无论模型规模大小或系列如何，都需要重视这一问题并开发相应的解决方案。

Abstract: Abstractive summarization is a core application in contact centers, where
Large Language Models (LLMs) generate millions of summaries of call transcripts
daily. Despite their apparent quality, it remains unclear whether LLMs
systematically under- or over-attend to specific aspects of the transcript,
potentially introducing biases in the generated summary. While prior work has
examined social and positional biases, the specific forms of bias pertinent to
contact center operations - which we term Operational Bias - have remained
unexplored. To address this gap, we introduce BlindSpot, a framework built upon
a taxonomy of 15 operational bias dimensions (e.g., disfluency, speaker, topic)
for the identification and quantification of these biases. BlindSpot leverages
an LLM as a zero-shot classifier to derive categorical distributions for each
bias dimension in a pair of transcript and its summary. The bias is then
quantified using two metrics: Fidelity Gap (the JS Divergence between
distributions) and Coverage (the percentage of source labels omitted). Using
BlindSpot, we conducted an empirical study with 2500 real call transcripts and
their summaries generated by 20 LLMs of varying scales and families (e.g., GPT,
Llama, Claude). Our analysis reveals that biases are systemic and present
across all evaluated models, regardless of size or family.

</details>


### [132] [MuDRiC: Multi-Dialect Reasoning for Arabic Commonsense Validation](https://arxiv.org/abs/2508.13130)
*Kareem Elozeiri,Mervat Abassy,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: 这篇论文提出了MuDRiC数据集和基于GCN的新方法，用于阿拉伯语多方言的常识验证任务，补充了现有资源偏重标准阿语的空白。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语常识验证任务在多方言方面研究不足，现有资源主要集中在现代标准阿拉伯语(MSA)，而很少涵盖地方方言，虽然这些方言在口语中常见。

Method: 提出了两项主要贡献：1)引入MuDRiC数据集，包含多种阿拉伯语方言；2)采用图卷积神经网络(GCN)进行阿拉语常识推理，以改善语义关系建模。

Result: 实验结果表明，该方法在阿拉伯语常识验证任务中达到了更优的性能。

Conclusion: 这项工作通过提供基础数据集和新方法，提升了阿拉语自然语言理解能力，以处理其复杂的语言变体。这是第一个阿拉语多方言常识推理数据集。

Abstract: Commonsense validation evaluates whether a sentence aligns with everyday
human understanding, a critical capability for developing robust natural
language understanding systems. While substantial progress has been made in
English, the task remains underexplored in Arabic, particularly given its rich
linguistic diversity. Existing Arabic resources have primarily focused on
Modern Standard Arabic (MSA), leaving regional dialects underrepresented
despite their prevalence in spoken contexts. To bridge this gap, we present two
key contributions: (i) we introduce MuDRiC, an extended Arabic commonsense
dataset incorporating multiple dialects, and (ii) a novel method adapting Graph
Convolutional Networks (GCNs) to Arabic commonsense reasoning, which enhances
semantic relationship modeling for improved commonsense validation. Our
experimental results demonstrate that this approach achieves superior
performance in Arabic commonsense validation. Our work enhances Arabic natural
language understanding by providing both a foundational dataset and a novel
method for handling its complex variations. To the best of our knowledge, we
release the first Arabic multi-dialect commonsense reasoning dataset.

</details>


### [133] [Improving Detection of Watermarked Language Models](https://arxiv.org/abs/2508.13131)
*Dara Bahri,John Wieting*

Main category: cs.CL

TL;DR: 结合水印检测器与非水印检测器的混合方案能够在语言模型生成文本检测中实现更好的性能。


<details>
  <summary>Details</summary>
Motivation: 水印技术在低熵准条件下检测效果有限，特别是经过指令循环训练或RLHF后训练的模型，需要找到更有效的检测方案。

Method: 探索多种混合检测方案，将水印检测器与非水印检测器结合使用，在广泛的实验条件下进行测试。

Result: 混合检测方案在各种实验条件下都表现出比单独使用水印或非水印检测器更好的性能。

Conclusion: 通过结合两类检测器的混合方案可以有效提升语言模型生成文本的检测效果，为实际应用提供更可靠的解决方案。

Abstract: Watermarking has recently emerged as an effective strategy for detecting the
generations of large language models (LLMs). The strength of a watermark
typically depends strongly on the entropy afforded by the language model and
the set of input prompts. However, entropy can be quite limited in practice,
especially for models that are post-trained, for example via instruction tuning
or reinforcement learning from human feedback (RLHF), which makes detection
based on watermarking alone challenging. In this work, we investigate whether
detection can be improved by combining watermark detectors with non-watermark
ones. We explore a number of hybrid schemes that combine the two, observing
performance gains over either class of detector under a wide range of
experimental conditions.

</details>


### [134] [OptimalThinkingBench: Evaluating Over and Underthinking in LLMs](https://arxiv.org/abs/2508.13141)
*Pranjal Aggarwal,Seungone Kim,Jack Lanchantin,Sean Welleck,Jason Weston,Ilia Kulikov,Swarnadeep Saha*

Main category: cs.CL

TL;DR: OptimalThinkingBench是一个统一基准，用于评估LLMs的过度思考（overthinking）和思考不足（underthinking）问题，并鼓励开发平衡性能与效率的最优思考模型。


<details>
  <summary>Details</summary>
Motivation: 现有思考型LLMs在复杂任务上表现更好但计算成本高且对简单问题过度思考，而非思考型LLMs虽然更快更便宜但在困难推理问题上思考不足。用户需要自行选择合适模型，缺乏统一评估标准。

Method: 构建包含两个子基准的统一评测框架：OverthinkingBench（72个领域的简单查询）和UnderthinkingBench（11个挑战性推理任务），使用新颖的思考调整准确率指标评估33个不同模型。

Result: 没有模型能在该基准上实现最优思考。思考型模型经常在简单查询上过度思考数百个token却无性能提升，而大型非思考型模型思考不足，表现甚至不如更小的思考型模型。

Conclusion: 现有方法往往在一个子基准上改进的同时损害另一个子基准的表现，凸显了未来需要开发更好的统一最优思考模型的必要性。

Abstract: Thinking LLMs solve complex tasks at the expense of increased compute and
overthinking on simpler problems, while non-thinking LLMs are faster and
cheaper but underthink on harder reasoning problems. This has led to the
development of separate thinking and non-thinking LLM variants, leaving the
onus of selecting the optimal model for each query on the end user. In this
work, we introduce OptimalThinkingBench, a unified benchmark that jointly
evaluates overthinking and underthinking in LLMs and also encourages the
development of optimally-thinking models that balance performance and
efficiency. Our benchmark comprises two sub-benchmarks: OverthinkingBench,
featuring simple queries in 72 domains, and UnderthinkingBench, containing 11
challenging reasoning tasks. Using novel thinking-adjusted accuracy metrics, we
perform extensive evaluation of 33 different thinking and non-thinking models
and show that no model is able to optimally think on our benchmark. Thinking
models often overthink for hundreds of tokens on the simplest user queries
without improving performance. In contrast, large non-thinking models
underthink, often falling short of much smaller thinking models. We further
explore several methods to encourage optimal thinking, but find that these
approaches often improve on one sub-benchmark at the expense of the other,
highlighting the need for better unified and optimal models in the future.

</details>


### [135] [Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation](https://arxiv.org/abs/2508.13144)
*David Heineman,Valentin Hofmann,Ian Magnusson,Yuling Gu,Noah A. Smith,Hannaneh Hajishirzi,Kyle Lo,Jesse Dodge*

Main category: cs.CL

TL;DR: 这篇论文探讨了如何设计更可靠的语言模型评测基准，通过介绍信号和噪声两个关键指标来提高评测的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型开发成本高异，需要依靠小规模实验做决策，而现有评测基准的可靠性有待提高。

Method: 提出信号（评测基准区分模型好坏的能力）和噪声（对训练步骤随机变化的敏感度）两个指标，并建议三种改进方法：改用更好的指标（如困惑度）、过滤噪声子任务、平均中间检查点输出。

Result: 信噪比更高的基准更可靠，噪声更低的基准有更低的缩放式预测误差。提出的三种方法都能显著提高评测的可靠性。

Conclusion: 建议在创建或选择评测基准时以高信号和低噪声为目标，这样可以在小规模实验中做出更可靠的模型选择决策。

Abstract: Developing large language models is expensive and involves making decisions
with small experiments, typically by evaluating on large, multi-task evaluation
suites. In this work, we analyze specific properties which make a benchmark
more reliable for such decisions, and interventions to design higher-quality
evaluation benchmarks. We introduce two key metrics that show differences in
current benchmarks: signal, a benchmark's ability to separate better models
from worse models, and noise, a benchmark's sensitivity to random variability
between training steps. We demonstrate that benchmarks with a better
signal-to-noise ratio are more reliable when making decisions at small scale,
and those with less noise have lower scaling law prediction error. These
results suggest that improving signal or noise will lead to more useful
benchmarks, so we introduce three interventions designed to directly affect
signal or noise. For example, we propose that switching to a metric that has
better signal and noise (e.g., perplexity rather than accuracy) leads to better
reliability and improved scaling law error. We also find that filtering noisy
subtasks, to improve an aggregate signal-to-noise ratio, leads to more reliable
multi-task evaluations. We also find that averaging the output of a model's
intermediate checkpoints to reduce noise leads to consistent improvements. We
conclude by recommending that those creating new benchmarks, or selecting which
existing benchmarks to use, aim for high signal and low noise. We use 30
benchmarks for these experiments, and 375 open-weight language models from 60M
to 32B parameters, resulting in a new, publicly available dataset of 900K
evaluation benchmark results, totaling 200M instances.

</details>


### [136] [RepreGuard: Detecting LLM-Generated Text by Revealing Hidden Representation Patterns](https://arxiv.org/abs/2508.13152)
*Xin Chen,Junchao Wu,Shu Yang,Runzhe Zhan,Zeyu Wu,Ziyang Luo,Di Wang,Min Yang,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: RepreGuard是一种基于LLM内部表示统计特征的检测方法，在分布内外场景下都能有效区分AI生成文本和人类撰写文本，平均AUROC达到94.92%


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在分布外场景下的鲁棒性不足，作者假设LLM内部表示包含更全面和原始的特征，能更好地区分AI生成文本和人类撰写文本的统计模式差异

Method: 使用代理模型收集两种文本的表示，提取能够更好识别AI生成文本的激活特征，通过计算文本表示在该特征方向上的投影分数并与预计算阈值比较来进行分类

Result: 在分布内和分布外场景下均优于所有基线方法，平均AUROC达到94.92%，对文本大小和主流攻击具有鲁棒性

Conclusion: LLM内部表示确实包含更有效的特征用于检测AI生成内容，RepreGuard方法在多种场景下都表现出优异的检测性能

Abstract: Detecting content generated by large language models (LLMs) is crucial for
preventing misuse and building trustworthy AI systems. Although existing
detection methods perform well, their robustness in out-of-distribution (OOD)
scenarios is still lacking. In this paper, we hypothesize that, compared to
features used by existing detection methods, the internal representations of
LLMs contain more comprehensive and raw features that can more effectively
capture and distinguish the statistical pattern differences between
LLM-generated texts (LGT) and human-written texts (HWT). We validated this
hypothesis across different LLMs and observed significant differences in neural
activation patterns when processing these two types of texts. Based on this, we
propose RepreGuard, an efficient statistics-based detection method.
Specifically, we first employ a surrogate model to collect representation of
LGT and HWT, and extract the distinct activation feature that can better
identify LGT. We can classify the text by calculating the projection score of
the text representations along this feature direction and comparing with a
precomputed threshold. Experimental results show that RepreGuard outperforms
all baselines with average 94.92% AUROC on both in-distribution (ID) and OOD
scenarios, while also demonstrating robust resilience to various text sizes and
mainstream attacks. Data and code are publicly available at:
https://github.com/NLP2CT/RepreGuard

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [137] [A Deep Learning-Based CCTV System for Automatic Smoking Detection in Fire Exit Zones](https://arxiv.org/abs/2508.11696)
*Sami Sadat,Mohammad Irtiza Hossain,Junaid Ahmed Sifat,Suhail Haque Rafi,Md. Waseq Alauddin Alvi,Md. Khalilur Rhaman*

Main category: cs.CV

TL;DR: 基于YOLOv8改进的深度学习直视监控系统，能够在灭火通道区域实时检测吸烟行为，在各种环境下实现高准确度和快速处理。


<details>
  <summary>Details</summary>
Motivation: 出于公共安全的关键需求，需要在灭火通道等重要区域监控吸烟行为，防止火灾风险。

Method: 使用8,124张图片和2,708个原始样本构建数据集，评估YOLOv8、YOLOv11、YOLOv12模型，并基于YOLOv8发展自定制模型以应对监控环境的挑战。

Result: 提出的模型达到回归率78.90%和mAP@50为83.70%，在多种边缘设备上实现了快速处理（Jetson Xavier NX每次推理仅52-97毫秒）。

Conclusion: 该系统为公共安全监控提供了稳健、适应性强的平台，能够自动符合相关规定要求。

Abstract: A deep learning real-time smoking detection system for CCTV surveillance of
fire exit areas is proposed due to critical safety requirements. The dataset
contains 8,124 images from 20 different scenarios along with 2,708 raw samples
demonstrating low-light areas. We evaluated three advanced object detection
models: YOLOv8, YOLOv11, and YOLOv12, followed by development of a custom model
derived from YOLOv8 with added structures for challenging surveillance
contexts. The proposed model outperformed the others, achieving a recall of
78.90 percent and mAP at 50 of 83.70 percent, delivering optimal object
detection across varied environments. Performance evaluation on multiple edge
devices using multithreaded operations showed the Jetson Xavier NX processed
data at 52 to 97 milliseconds per inference, establishing its suitability for
time-sensitive operations. This system offers a robust and adaptable platform
for monitoring public safety and enabling automatic regulatory compliance.

</details>


### [138] [Separating Knowledge and Perception with Procedural Data](https://arxiv.org/abs/2508.11697)
*Adrián Rodríguez-Muñoz,Manel Baradad,Phillip Isola,Antonio Torralba*

Main category: cs.CV

TL;DR: 通过仅使用程序生成数据训练表征模型，结合视觉内存数据库实现了与实际图像完全隔离的强大性能，在多个认知任务上接近或超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习模型对实际图像数据的依赖性，通过程序生成数据实现完全的数据隔离和隐私保护。

Method: 仅使用程序生成数据训练表征模型，构建显式的视觉内存数据库（参考图像嵌入的数据库），在不进一步训练的情况下应用于各种认知任务。

Result: 在NIGHTS视觉相似性任务上与Places训练模型相差仅1%，在CUB200和Flowers102细粒度分类任务上分别超15%和8%，在ImageNet-1K分类上相差10%，在COCO零样本分割任务上达到了与实际数据训练模型相差10%以内的R²指标。

Conclusion: 程序生成数据模型可以实现与实际图像完全隔离的同时保持强大性能，但对象内部部件表征的差异性是影响绩效的关键因素。

Abstract: We train representation models with procedural data only, and apply them on
visual similarity, classification, and semantic segmentation tasks without
further training by using visual memory -- an explicit database of reference
image embeddings. Unlike prior work on visual memory, our approach achieves
full compartmentalization with respect to all real-world images while retaining
strong performance. Compared to a model trained on Places, our procedural model
performs within $1\%$ on NIGHTS visual similarity, outperforms by $8\%$ and
$15\%$ on CUB200 and Flowers102 fine-grained classification, and is within
$10\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot
segmentation, achieving an $R^2$ on COCO within $10\%$ of the models trained on
real data. Finally, we analyze procedural versus real data models, showing that
parts of the same object have dissimilar representations in procedural models,
resulting in incorrect searches in memory and explaining the remaining
performance gap.

</details>


### [139] [FusionFM: Fusing Eye-specific Foundational Models for Optimized Ophthalmic Diagnosis](https://arxiv.org/abs/2508.11721)
*Ke Zou,Jocelyn Hui Lin Goh,Yukun Zhou,Tian Lin,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Rui Santos,Gabor M. Somfai,Huazhu Fu,Haoyu Chen,Pearse A. Keane,Ching-Yu Cheng,Yih Chung Tham*

Main category: cs.CV

TL;DR: 这是首个系统性评估眼科基础模型的研究，提出了FusionFM评估框架和两种融合策略，发现DINORET和RetiZero在眼部和系统性疾病任务中表现最佳，融合策略在某些疾病预测中有突出改善。


<details>
  <summary>Details</summary>
Motivation: 眼科基础模型(FMs)在医学影像分析中展现良好潜力，但对于哪个模型表现最佳、是否在不同任务上都同样好、以及融合所有模型的效果等基本问题仍无明确答案。

Method: 提出FusionFM评估框架，包括两种融合方法来整合不同眼科基础模型。评估范围涵盖眼科疾病检测(青光眼、糖尿病视网膜病变、鹿鹿眼) 和系统性疾病预测(糖尿病、高血压)。对四个先进模型(RETFound、VisionFM、RetiZero、DINORET)进行标准化测试。

Result: DINORET和RetiZero在眼科和系统性疾病任务中表现最佳，RetiZero在外部数据集上显示更强的沿午性。Gating-based融合策略在青光眼、AMD和高血压预测中有突出改善。系统性疾病预测(特别是外部组织的高血压)仍靠挑战。

Conclusion: 研究提供了眼科基础模型的证据基础评估，强调了模型融合的优势，并指明了提高临床应用性的策略方向。

Abstract: Foundation models (FMs) have shown great promise in medical image analysis by
improving generalization across diverse downstream tasks. In ophthalmology,
several FMs have recently emerged, but there is still no clear answer to
fundamental questions: Which FM performs the best? Are they equally good across
different tasks? What if we combine all FMs together? To our knowledge, this is
the first study to systematically evaluate both single and fused ophthalmic
FMs. To address these questions, we propose FusionFM, a comprehensive
evaluation suite, along with two fusion approaches to integrate different
ophthalmic FMs. Our framework covers both ophthalmic disease detection
(glaucoma, diabetic retinopathy, and age-related macular degeneration) and
systemic disease prediction (diabetes and hypertension) based on retinal
imaging. We benchmarked four state-of-the-art FMs (RETFound, VisionFM,
RetiZero, and DINORET) using standardized datasets from multiple countries and
evaluated their performance using AUC and F1 metrics. Our results show that
DINORET and RetiZero achieve superior performance in both ophthalmic and
systemic disease tasks, with RetiZero exhibiting stronger generalization on
external datasets. Regarding fusion strategies, the Gating-based approach
provides modest improvements in predicting glaucoma, AMD, and hypertension.
Despite these advances, predicting systemic diseases, especially hypertension
in external cohort remains challenging. These findings provide an
evidence-based evaluation of ophthalmic FMs, highlight the benefits of model
fusion, and point to strategies for enhancing their clinical applicability.

</details>


### [140] [UniDCF: A Foundation Model for Comprehensive Dentocraniofacial Hard Tissue Reconstruction](https://arxiv.org/abs/2508.11728)
*Chunxia Ren,Ning Zhu,Yue Lai,Gui Chen,Ruijie Wang,Yangyi Hu,Suyao Liu,Shuwen Mao,Hong Su,Yu Zhang,Li Xiao*

Main category: cs.CV

TL;DR: UniDCF是一个统一的多模态深度学习框架，能够通过点云和多视角图像的融合编码来重建多个牙颌面硬组织，解决了现有单模态方法的局限性，在几何精度、结构完整性和空间准确性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 牙颌面硬组织缺损严重影响患者的生理功能、面部美学和心理健康，当前深度学习模型仅限于单组织场景和特定模态成像输入，导致泛化能力差，需要在解剖保真度、计算效率和跨组织适应性之间做出权衡。

Method: UniDCF通过点云和多视角图像的多模态融合编码，利用每种模态的互补优势，并引入基于分数的去噪模块来优化表面平滑度。研究构建了包含6,609名患者的口内扫描、CBCT和CT数据的最大多模态数据集，共54,555个标注实例。

Result: 评估显示UniDCF在几何精度、结构完整性和空间准确性方面优于现有最先进方法。临床模拟表明UniDCF将重建设计时间减少99%，临床医生接受率超过94%。

Conclusion: UniDCF实现了快速、自动化和高保真度的重建，支持个性化和精确的修复治疗，简化了临床工作流程，改善了患者治疗效果。

Abstract: Dentocraniofacial hard tissue defects profoundly affect patients'
physiological functions, facial aesthetics, and psychological well-being,
posing significant challenges for precise reconstruction. Current deep learning
models are limited to single-tissue scenarios and modality-specific imaging
inputs, resulting in poor generalizability and trade-offs between anatomical
fidelity, computational efficiency, and cross-tissue adaptability. Here we
introduce UniDCF, a unified framework capable of reconstructing multiple
dentocraniofacial hard tissues through multimodal fusion encoding of point
clouds and multi-view images. By leveraging the complementary strengths of each
modality and incorporating a score-based denoising module to refine surface
smoothness, UniDCF overcomes the limitations of prior single-modality
approaches. We curated the largest multimodal dataset, comprising intraoral
scans, CBCT, and CT from 6,609 patients, resulting in 54,555 annotated
instances. Evaluations demonstrate that UniDCF outperforms existing
state-of-the-art methods in terms of geometric precision, structural
completeness, and spatial accuracy. Clinical simulations indicate UniDCF
reduces reconstruction design time by 99% and achieves clinician-rated
acceptability exceeding 94%. Overall, UniDCF enables rapid, automated, and
high-fidelity reconstruction, supporting personalized and precise restorative
treatments, streamlining clinical workflows, and enhancing patient outcomes.

</details>


### [141] [Ovis2.5 Technical Report](https://arxiv.org/abs/2508.11737)
*Shiyin Lu,Yang Li,Yu Xia,Yuwei Hu,Shanshan Zhao,Yanqing Ma,Zhichao Wei,Yinglun Li,Lunhao Duan,Jianshan Zhao,Yuxuan Han,Haijun Li,Wanying Chen,Junke Tang,Chengkun Hou,Zhixing Du,Tianli Zhou,Wenjie Zhang,Huping Ding,Jiahe Li,Wen Li,Gui Hu,Yiliang Gu,Siran Yang,Jiamang Wang,Hailong Sun,Yibo Wang,Hui Sun,Jinlong Huang,Yuping He,Shengze Shi,Weihong Zhang,Guodong Zheng,Junpeng Jiang,Sensen Gao,Yi-Feng Wu,Sijia Chen,Yuhui Chen,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Ovis2.5是一个先进的多模态大语言模型，通过原生分辨率视觉处理和反思推理能力，在OpenCompass排行榜上达到78.3分，在子40B参数范围内实现开源SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决固定分辨率图像处理导致的细节损失问题，并增强模型的多模态推理能力，特别是对于视觉密集内容（如复杂图表）的理解和分析。

Method: 采用原生分辨率视觉Transformer处理可变分辨率图像，引入反思推理机制（包括自检查和修订），通过五阶段课程训练（视觉预训练、多模态预训练、指令调优、DPO和GRPO对齐），使用多模态数据打包和混合并行技术提升效率。

Result: Ovis2.5-9B在OpenCompass平均得分78.3，相比前代Ovis2-8B有显著提升；Ovis2.5-2B得分73.9，在同等规模模型中达到SOTA。在STEM基准测试、 grounding任务、视频任务和复杂图表分析方面都取得领先结果。

Conclusion: Ovis2.5通过原生分辨率视觉处理和高级推理能力，在多个基准测试中实现了开源模型的最先进性能，特别是为资源受限的设备提供了高性能的小型模型选择。

Abstract: We present Ovis2.5, a successor to Ovis2 designed for native-resolution
visual perception and strong multimodal reasoning. Ovis2.5 integrates a
native-resolution vision transformer that processes images at their native,
variable resolutions, avoiding the degradation from fixed-resolution tiling and
preserving both fine detail and global layout -- crucial for visually dense
content like complex charts. To strengthen reasoning, we train the model to
move beyond linear chain-of-thought and perform reflection -- including
self-checking and revision. This advanced capability is exposed as an optional
"thinking mode" at inference time, allowing users to trade latency for enhanced
accuracy on difficult inputs. The model is trained via a comprehensive
five-phase curriculum that progressively builds its skills. The process begins
with foundational visual and multimodal pretraining, advances through
large-scale instruction tuning, and culminates in alignment and reasoning
enhancement using DPO and GRPO. To scale these upgrades efficiently, we employ
multimodal data packing and hybrid parallelism, yielding a significant
end-to-end speedup. We release two open-source models: Ovis2.5-9B and
Ovis2.5-2B. The latter continues the "small model, big performance" philosophy
of Ovis2, making it ideal for resource-constrained, on-device scenarios. On the
OpenCompass multimodal leaderboard, Ovis2.5-9B averages 78.3, marking a
substantial improvement over its predecessor, Ovis2-8B, and achieving
state-of-the-art results among open-source MLLMs in the sub-40B parameter
range; Ovis2.5-2B scores 73.9, establishing SOTA for its size. Beyond aggregate
scores, Ovis2.5 achieves leading results on STEM benchmarks, exhibits strong
capabilities on grounding and video tasks, and achieves open-source SOTA at its
scale for complex chart analysis.

</details>


### [142] [VideoAVE: A Multi-Attribute Video-to-Text Attribute Value Extraction Dataset and Benchmark Models](https://arxiv.org/abs/2508.11801)
*Ming Cheng,Tong Wu,Jiazhen Hu,Jiaying Gong,Hoda Eldardiry*

Main category: cs.CV

TL;DR: VideoAVE是首个公开的视频到文本电商属性值提取数据集，涵盖14个领域和172个属性，包含224k训练数据和25k评估数据，并建立了全面的基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有AVE数据集主要局限于文本到文本或图像到文本设置，缺乏对产品视频的支持、多样属性覆盖和公开可用性。

Method: 提出了基于CLIP的混合专家过滤系统(CLIP-MoE)来移除不匹配的视频-产品对，确保数据质量。建立了包含属性条件值预测和开放属性值对提取任务的基准测试。

Result: 视频到文本AVE仍然是一个具有挑战性的问题，特别是在开放设置中，现有视频视觉语言模型在利用有效时间信息方面仍有改进空间。

Conclusion: VideoAVE数据集填补了视频AVE领域的空白，为开发更先进的视觉语言模型提供了重要资源，展示了视频AVE任务的挑战性和发展潜力。

Abstract: Attribute Value Extraction (AVE) is important for structuring product
information in e-commerce. However, existing AVE datasets are primarily limited
to text-to-text or image-to-text settings, lacking support for product videos,
diverse attribute coverage, and public availability. To address these gaps, we
introduce VideoAVE, the first publicly available video-to-text e-commerce AVE
dataset across 14 different domains and covering 172 unique attributes. To
ensure data quality, we propose a post-hoc CLIP-based Mixture of Experts
filtering system (CLIP-MoE) to remove the mismatched video-product pairs,
resulting in a refined dataset of 224k training data and 25k evaluation data.
In order to evaluate the usability of the dataset, we further establish a
comprehensive benchmark by evaluating several state-of-the-art video vision
language models (VLMs) under both attribute-conditioned value prediction and
open attribute-value pair extraction tasks. Our results analysis reveals that
video-to-text AVE remains a challenging problem, particularly in open settings,
and there is still room for developing more advanced VLMs capable of leveraging
effective temporal information. The dataset and benchmark code for VideoAVE are
available at: https://github.com/gjiaying/VideoAVE

</details>


### [143] [An MLP Baseline for Handwriting Recognition Using Planar Curvature and Gradient Orientation](https://arxiv.org/abs/2508.11803)
*Azam Nouri*

Main category: cs.CV

TL;DR: 使用曲率和方向等二阶几何特征的多层感知机可以在手写字符识别中获得高准确率，为CNN提供了可解释性强的替代方案


<details>
  <summary>Details</summary>
Motivation: 探索仅依靠二阶几何线索（平面曲率大小、曲率符号和梯度方向）是否足以驱动手写字符识别，为卷积神经网络提供可解释性替代方案

Method: 使用三种手工特征地图（曲率大小、曲率符号、梯度方向）作为输入，构建曲率-65b9向多层感知机分类器

Result: 在MNIST数字数据集上达到97%准确率，在EMNIST字母数据集上达到89%准确率

Conclusion: 曲率基于表示具有强大的辨别能力，深度学习的优势即使在使用可解释的手工特征时也能实现

Abstract: This study investigates whether second-order geometric cues - planar
curvature magnitude, curvature sign, and gradient orientation - are sufficient
on their own to drive a multilayer perceptron (MLP) classifier for handwritten
character recognition (HCR), offering an alternative to convolutional neural
networks (CNNs). Using these three handcrafted feature maps as inputs, our
curvature-orientation MLP achieves 97 percent accuracy on MNIST digits and 89
percent on EMNIST letters. These results underscore the discriminative power of
curvature-based representations for handwritten character images and
demonstrate that the advantages of deep learning can be realized even with
interpretable, hand-engineered features.

</details>


### [144] [Labels or Input? Rethinking Augmentation in Multimodal Hate Detection](https://arxiv.org/abs/2508.11808)
*Sahajpreet Singh,Rongxin Ouyang,Subhayan Mukerjee,Kokil Jaidka*

Main category: cs.CV

TL;DR: 提出双管齐下的方法改进多模态仇恨内容检测：通过提示优化框架和基于多智能体LLM-VLM的数据增强管道，提升模型鲁棒性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现代网络多模态内容泛滥，仇恨表情包通过文本和图像的微妙交互传递有害意图，现有视觉语言模型缺乏细粒度监督且易受隐式仇恨言论影响

Method: 1) 提示优化框架：系统变化提示结构、监督粒度和训练模态；2) 多模态数据增强管道：通过多智能体LLM-VLM设置生成2,479个反事实中性表情包，隔离并重写仇恨模态

Result: 结构化提示提升小模型鲁棒性，InternVL2在二元和分级设置中取得最佳F1分数；数据增强管道成功减少虚假相关性，改善分类器泛化能力

Conclusion: 提示结构和数据组成与模型规模同等重要，针对性数据增强可支持更可信和上下文敏感的仇恨检测，为构建合成数据训练鲁棒公平的视觉语言模型提供新方向

Abstract: The modern web is saturated with multimodal content, intensifying the
challenge of detecting hateful memes, where harmful intent is often conveyed
through subtle interactions between text and image under the guise of humor or
satire. While recent advances in Vision-Language Models (VLMs) show promise,
these models lack support for fine-grained supervision and remain susceptible
to implicit hate speech. In this paper, we present a dual-pronged approach to
improve multimodal hate detection. First, we propose a prompt optimization
framework that systematically varies prompt structure, supervision granularity,
and training modality. We show that prompt design and label scaling both
influence performance, with structured prompts improving robustness even in
small models, and InternVL2 achieving the best F1-scores across binary and
scaled settings. Second, we introduce a multimodal data augmentation pipeline
that generates 2,479 counterfactually neutral memes by isolating and rewriting
the hateful modality. This pipeline, powered by a multi-agent LLM-VLM setup,
successfully reduces spurious correlations and improves classifier
generalization. Our approaches inspire new directions for building synthetic
data to train robust and fair vision-language models. Our findings demonstrate
that prompt structure and data composition are as critical as model size, and
that targeted augmentation can support more trustworthy and context-sensitive
hate detection.

</details>


### [145] [Towards Understanding 3D Vision: the Role of Gaussian Curvature](https://arxiv.org/abs/2508.11825)
*Sherlon Almeida da Silva,Davi Geiger,Luiz Velho,Moacir Antonelli Ponti*

Main category: cs.CV

TL;DR: 该论文探讨了高斯曲率在3D表面建模中的作用，发现它提供了稀疏紧凑的表面描述，可作为几何先验改善3D重建，并可能作为立体方法的无监督度量标准。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的计算机视觉方法缺乏可分析、可迁移和可系统修改的显式3D几何模型，需要研究更基础的几何量来改进3D表面建模。

Method: 使用Middlebury立体数据集研究高斯曲率的特性，分析其在3D表面建模中的四个潜在作用：稀疏描述、隐式使用分析、几何先验和无监督度量。

Result: 发现高斯曲率提供稀疏紧凑的3D表面描述，当前最优方法隐式考虑了它但无法提取显式模块，可作为几何先验改善重建，并可能作为无监督度量标准。

Conclusion: 高斯曲率作为不变量在3D表面建模中具有重要价值，为开发更可解释和可控的几何模型提供了新方向。

Abstract: Recent advances in computer vision have predominantly relied on data-driven
approaches that leverage deep learning and large-scale datasets. Deep neural
networks have achieved remarkable success in tasks such as stereo matching and
monocular depth reconstruction. However, these methods lack explicit models of
3D geometry that can be directly analyzed, transferred across modalities, or
systematically modified for controlled experimentation. We investigate the role
of Gaussian curvature in 3D surface modeling. Besides Gaussian curvature being
an invariant quantity under change of observers or coordinate systems, we
demonstrate using the Middlebury stereo dataset that it offers: (i) a sparse
and compact description of 3D surfaces, (ii) state-of-the-art monocular and
stereo methods seem to implicitly consider it, but no explicit module of such
use can be extracted, (iii) a form of geometric prior that can inform and
improve 3D surface reconstruction, and (iv) a possible use as an unsupervised
metric for stereo methods.

</details>


### [146] [From Pixels to Graphs: Deep Graph-Level Anomaly Detection on Dermoscopic Images](https://arxiv.org/abs/2508.11826)
*Dehn Xu,Tim Katzke,Emmanuel Müller*

Main category: cs.CV

TL;DR: 这篇论文系统性评估了多种图像-图转换方法在图神经网络图级异常检测任务中的效果，发现颜色描述符表现最佳，而形状和纹理特征能明显提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 虽然GNN已被应用于图像演化的图表示，但尚无研究系统性比较不同图像-图转换方法在图级异常检测任务中的效果。

Method: 系统性评估多种分割方案、边缘构建策略和节点特征集（包括颜色、纹理、形状描述符），在皮肤镜图像上进行广泛实验，测试无监督、弱监督和全监督三种模式下的性能。

Result: 颜色描述符单独表现最佳，形状和纹理特征能明显提升检测效果。最佳无监督配置达到AUC-ROC 0.805，弱监督下提升至0.872，全监督下达到0.914。

Conclusion: 这项研究为图像-图转换方法在GNN图级异常检测中的选择提供了系统性指南，显示了合适的特征组合能够在无监督情况下达到竞争力的性能。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful approach for
graph-based machine learning tasks. Previous work applied GNNs to image-derived
graph representations for various downstream tasks such as classification or
anomaly detection. These transformations include segmenting images, extracting
features from segments, mapping them to nodes, and connecting them. However, to
the best of our knowledge, no study has rigorously compared the effectiveness
of the numerous potential image-to-graph transformation approaches for
GNN-based graph-level anomaly detection (GLAD). In this study, we
systematically evaluate the efficacy of multiple segmentation schemes, edge
construction strategies, and node feature sets based on color, texture, and
shape descriptors to produce suitable image-derived graph representations to
perform graph-level anomaly detection. We conduct extensive experiments on
dermoscopic images using state-of-the-art GLAD models, examining performance
and efficiency in purely unsupervised, weakly supervised, and fully supervised
regimes. Our findings reveal, for example, that color descriptors contribute
the best standalone performance, while incorporating shape and texture features
consistently enhances detection efficacy. In particular, our best unsupervised
configuration using OCGTL achieves a competitive AUC-ROC score of up to 0.805
without relying on pretrained backbones like comparable image-based approaches.
With the inclusion of sparse labels, the performance increases substantially to
0.872 and with full supervision to 0.914 AUC-ROC.

</details>


### [147] [Recent Advances in Transformer and Large Language Models for UAV Applications](https://arxiv.org/abs/2508.11834)
*Hamza Kheddar,Yassine Habchi,Mohamed Chahine Ghanem,Mustapha Hemis,Dusit Niyato*

Main category: cs.CV

TL;DR: 这是一份关于Transformer模型在无人机系统中应用的系统性综述文章，包含分类、应用场景、性能对比和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 结合Transformer模型的快速发展与无人机系统的需求，需要对这一领域进行系统性的总结和分析，以指导研究者和实践者。

Method: 采用统一分类法对Transformer基于的UAV模型进行系统化分类，包括注意机制、CNN-Transformer混合模型、强化学习Transformers和大语言模型，并通过结构化表格和性能基准进行对比分析。

Result: 文章完整综述了Transformer在UAV中的应用进展，包括精准农业、自主导航等新兴应用场景，分析了关键数据集、模拟器和评估指标，并指出了计算效率和实时部署等挑战。

Conclusion: 这份综述文章为研究者和实践者提供了完整的Transformer驱动UAV技术引导，明确了领域内的研究空白和未来发展方向。

Abstract: The rapid advancement of Transformer-based models has reshaped the landscape
of uncrewed aerial vehicle (UAV) systems by enhancing perception,
decision-making, and autonomy. This review paper systematically categorizes and
evaluates recent developments in Transformer architectures applied to UAVs,
including attention mechanisms, CNN-Transformer hybrids, reinforcement learning
Transformers, and large language models (LLMs). Unlike previous surveys, this
work presents a unified taxonomy of Transformer-based UAV models, highlights
emerging applications such as precision agriculture and autonomous navigation,
and provides comparative analyses through structured tables and performance
benchmarks. The paper also reviews key datasets, simulators, and evaluation
metrics used in the field. Furthermore, it identifies existing gaps in the
literature, outlines critical challenges in computational efficiency and
real-time deployment, and offers future research directions. This comprehensive
synthesis aims to guide researchers and practitioners in understanding and
advancing Transformer-driven UAV technologies.

</details>


### [148] [ComplicitSplat: Downstream Models are Vulnerable to Blackbox Attacks by 3D Gaussian Splat Camouflages](https://arxiv.org/abs/2508.11854)
*Matthew Hull,Haoyang Yang,Pratham Mehta,Mansi Phute,Aeree Cho,Haorang Wang,Matthew Lau,Wenke Lee,Wilian Lunardi,Martin Andreoni,Polo Chau*

Main category: cs.CV

TL;DR: ComplicitSplat是一种针对3D高斯泼溅(3DGS)的黑盒攻击方法，通过利用标准3DGS着色技术创建视角特定伪装，在特定视角下嵌入对抗性内容，无需访问模型架构或权重。


<details>
  <summary>Details</summary>
Motivation: 随着3DGS在安全关键任务中的快速应用，需要研究攻击者如何篡改图像造成危害，暴露3DGS在自主导航等关键应用中的安全风险。

Method: 利用标准3DGS着色方法创建视角特异性伪装，使颜色和纹理随视角变化，在场景对象中嵌入仅从特定视角可见的对抗性内容。

Result: 实验表明ComplicitSplat能成功攻击多种流行检测器（单阶段、多阶段和基于transformer的模型），在真实物理对象捕获和合成场景中均有效。

Conclusion: 这是首个针对下游对象检测器的3DGS黑盒攻击，揭示了自主导航和其他关键机器人系统应用中的新型安全风险。

Abstract: As 3D Gaussian Splatting (3DGS) gains rapid adoption in safety-critical tasks
for efficient novel-view synthesis from static images, how might an adversary
tamper images to cause harm? We introduce ComplicitSplat, the first attack that
exploits standard 3DGS shading methods to create viewpoint-specific camouflage
- colors and textures that change with viewing angle - to embed adversarial
content in scene objects that are visible only from specific viewpoints and
without requiring access to model architecture or weights. Our extensive
experiments show that ComplicitSplat generalizes to successfully attack a
variety of popular detector - both single-stage, multi-stage, and
transformer-based models on both real-world capture of physical objects and
synthetic scenes. To our knowledge, this is the first black-box attack on
downstream object detectors using 3DGS, exposing a novel safety risk for
applications like autonomous navigation and other mission-critical robotic
systems.

</details>


### [149] [Impact of Clinical Image Quality on Efficient Foundation Model Finetuning](https://arxiv.org/abs/2508.11864)
*Yucheng Tang,Pawel Rajwa,Alexander Ng,Yipei Wang,Wen Yan,Natasha Thorley,Aqua Asif,Clare Allen,Louise Dickinson,Francesco Giganti,Shonit Punwani,Daniel C. Alexander,Veeru Kasivisvanathan,Yipeng Hu*

Main category: cs.CV

TL;DR: 基础模型在医学影像中显示出标签效率优势，但图像质量分布对微调效果有显著影响。研究通过前列腰腹MRI模型ProFound证实，微调集中高质量图像的充足性很重要，而微调与测试集质量分布的一致性也影响下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 基础模型在医学影像领域显示出了良好的标签效率，但图像质量变量对微调效果的影响还不明确。研究想要识别图像质量分布如何影响基础模型在前列腰腹MRI中的标签效率微调性能。

Method: 使用领域特定的视觉基础模型ProFound（在大规模前列腰腹MRI数据集上预训练），通过系统性变化微调集和评估集中高/低质量图像比例，量化图像质量对微调模型通用性的影响。

Result: 研究发现：1）微调集与测试集中高质量图像比例的差异会导致下游性能显著差异；2）微调集中充足的高质量图像对维持强劲性能至关重要；3）微调与测试分布一致性的重要性因下游任务而异；4）质量比例一致时，微调需要的标签数据比从头训练少得多

Conclusion: 图像质量在基础模型微调中发挥关键作用。如果微调数据中缺乏足够高质量图像，预训练模型可能无法超过从头训练的模型。研究强调了评估并对齐微调与部署环境的质量分布的重要性，以及为特定下游任务制定微调数据质量标准的必要性。

Abstract: Foundation models in medical imaging have shown promising label efficiency,
achieving high downstream performance with only a fraction of annotated data.
Here, we evaluate this in prostate multiparametric MRI using ProFound, a
domain-specific vision foundation model pretrained on large-scale prostate MRI
datasets. We investigate how variable image quality affects label-efficient
finetuning by measuring the generalisability of finetuned models. Experiments
systematically vary high-/low-quality image ratios in finetuning and evaluation
sets. Our findings indicate that image quality distribution and its
finetune-and-test mismatch significantly affect model performance. In
particular: a) Varying the ratio of high- to low-quality images between
finetuning and test sets leads to notable differences in downstream
performance; and b) The presence of sufficient high-quality images in the
finetuning set is critical for maintaining strong performance, whilst the
importance of matched finetuning and testing distribution varies between
different downstream tasks, such as automated radiology reporting and prostate
cancer detection.When quality ratios are consistent, finetuning needs far less
labeled data than training from scratch, but label efficiency depends on image
quality distribution. Without enough high-quality finetuning data, pretrained
models may fail to outperform those trained without pretraining. This
highlights the importance of assessing and aligning quality distributions
between finetuning and deployment, and the need for quality standards in
finetuning data for specific downstream tasks. Using ProFound, we show the
value of quantifying image quality in both finetuning and deployment to fully
realise the data and compute efficiency benefits of foundation models.

</details>


### [150] [AdaRing: Towards Ultra-Light Vision-Language Adaptation via Cross-Layer Tensor Ring Decomposition](https://arxiv.org/abs/2508.11870)
*Ying Huang,Yuanbin Man,Wenqi Jia,Zhengzhong Tu,Junzhou Huang,Miao Yin*

Main category: cs.CV

TL;DR: AdaRing是一种基于张量环分解的超轻量视觉-语言模型微调框架，通过利用跨层张量低秩性和多样化适配器协作，在减少90%参数的同时达到独创性能效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有适配器微调方法的两大问题：1)忽略跨层冗余导致压缩率有限；2)同质化适配器表征能力不足。

Method: 采用张量环分解技术，将适配器模块化为层共享的张量核和层特定切片，利用张量级别的低秩性消除跨层冗余，并通过泛化感知引导的多样秩适配器协作。

Result: 在各种任务上实现了独创性能效果，平均训练参数量减少90%，显著提升了参数效率。

Conclusion: AdaRing框架通过张量环分解和多样化适配器协作，有效解决了跨层冗余和表征能力问题，为大型视觉-语言模型提供了一种超轻量、高效的微调方案。

Abstract: Adapter-based fine-tuning has gained remarkable attention in adapting large
pre-trained vision language models (VLMs) for a wide range of downstream tasks
efficiently. In this paradigm, only the inserted adapters are fine-tuned,
without the need for training the original VLM backbone. Existing works scale
adapters by integrating them into every layer of VLMs to increase the capacity
of adapters. However, these methods face two primary limitations: 1) limited
compression rate due to ignoring cross-layer redundancy, and 2) limited
representational capacity across homogeneous adapters. In this paper, we
propose a novel vision-language fine-tuning framework based on cross-layer
tensor ring decomposition (TRD) with the integration and collaboration of
diverse adapters, called AdaRing, achieving ultra-light parameter-efficient
adaptation of VLMs on various tasks. To remove the high redundancy that exists
among adapters across layers, we exploit the tensor-level low-rankness to
formulate adapters as layer-shared tensor cores and layer-specific slices.
Moreover, guided by generalization-aware fine-tuning, diverse rank-driven
adapters cooperate to handle tasks that require different representations. Our
experiments show that the proposed AdaRing achieves the state-of-the-art
performance while reducing average training parameters by 90%.

</details>


### [151] [EVTP-IVS: Effective Visual Token Pruning For Unifying Instruction Visual Segmentation In Multi-Modal Large Language Models](https://arxiv.org/abs/2508.11886)
*Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Shao Tang,Sayan Ghosh,Xuanzhao Dong,Rajat Koner,Yalin Wang*

Main category: cs.CV

TL;DR: EVTP-IV是一种新的视觉token剪枝方法，通过选择空间代表性强的token子集，在保持精度的同时实现3.5-5倍推理加速


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在指令视觉分割任务中推理成本过高，特别是视频任务，需要降低计算开销

Method: 基于k-center算法整合空间信息来选择紧凑但空间代表性的token子集，提供信息论分析支持设计

Result: 在标准IVS基准测试中，仅使用20%的token就能达到5倍视频任务加速和3.5倍图像任务加速，同时保持可比精度，优于现有剪枝方法

Conclusion: 提出的EVTP-IV方法有效解决了MLLMs在视觉分割任务中的推理效率问题，为实际应用提供了可行的加速方案

Abstract: Instructed Visual Segmentation (IVS) tasks require segmenting objects in
images or videos based on natural language instructions. While recent
multimodal large language models (MLLMs) have achieved strong performance on
IVS, their inference cost remains a major bottleneck, particularly in video. We
empirically analyze visual token sampling in MLLMs and observe a strong
correlation between subset token coverage and segmentation performance. This
motivates our design of a simple and effective token pruning method that
selects a compact yet spatially representative subset of tokens to accelerate
inference. In this paper, we introduce a novel visual token pruning method for
IVS, called EVTP-IV, which builds upon the k-center by integrating spatial
information to ensure better coverage. We further provide an
information-theoretic analysis to support our design. Experiments on standard
IVS benchmarks show that our method achieves up to 5X speed-up on video tasks
and 3.5X on image tasks, while maintaining comparable accuracy using only 20%
of the tokens. Our method also consistently outperforms state-of-the-art
pruning baselines under varying pruning ratios.

</details>


### [152] [Large Kernel Modulation Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.11893)
*Quanwei Hu,Yinggan Tang,Xuguang Zhang*

Main category: cs.CV

TL;DR: 提出基于纯CNN的大核调制网络（LKMN），通过增强部分大核块和交叉门控前馈网络，在保持低延迟的同时实现非局部特征提取，在轻量级超分辨率任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限场景下图像超分辨率的性能与延迟平衡问题。CNN延迟低但缺乏非局部特征捕获能力，Transformer非局部建模能力强但推理速度慢。

Method: LKMN包含两个核心组件：增强部分大核块（EPLKB）使用通道混洗增强通道交互，通道注意力聚焦关键信息，部分通道大核条带卷积实现低复杂度非局部特征提取；交叉门控前馈网络（CGFN）通过可学习缩放因子动态调整输入、局部和非局部特征差异，采用交叉门控策略调制融合特征。

Result: 在Manga109数据集×4超分辨率任务上，LKMN-L比DAT-light提升0.23dB PSNR，推理速度快约4.8倍，优于现有轻量级SOTA模型。

Conclusion: LKMN成功平衡了图像超分辨率的性能和质量，纯CNN架构在保持低延迟的同时实现了有效的非局部特征建模，为资源受限场景提供了优质解决方案。

Abstract: Image super-resolution (SR) in resource-constrained scenarios demands
lightweight models balancing performance and latency. Convolutional neural
networks (CNNs) offer low latency but lack non-local feature capture, while
Transformers excel at non-local modeling yet suffer slow inference. To address
this trade-off, we propose the Large Kernel Modulation Network (LKMN), a pure
CNN-based model. LKMN has two core components: Enhanced Partial Large Kernel
Block (EPLKB) and Cross-Gate Feed-Forward Network (CGFN). The EPLKB utilizes
channel shuffle to boost inter-channel interaction, incorporates channel
attention to focus on key information, and applies large kernel strip
convolutions on partial channels for non-local feature extraction with reduced
complexity. The CGFN dynamically adjusts discrepancies between input, local,
and non-local features via a learnable scaling factor, then employs a
cross-gate strategy to modulate and fuse these features, enhancing their
complementarity. Extensive experiments demonstrate that our method outperforms
existing state-of-the-art (SOTA) lightweight SR models while balancing quality
and efficiency. Specifically, LKMN-L achieves 0.23 dB PSNR improvement over
DAT-light on the Manga109 dataset at $\times$4 upscale, with nearly $\times$4.8
times faster. Codes are in the supplementary materials. The code is available
at https://github.com/Supereeeee/LKMN.

</details>


### [153] [A Sobel-Gradient MLP Baseline for Handwritten Character Recognition](https://arxiv.org/abs/2508.11902)
*Azam Nouri*

Main category: cs.CV

TL;DR: 重新考察Sobel算子，使用一阶梯度边缘图作为输入，通过全密链接MLP实现手写字符识别，结果接近CNN但更节省内存


<details>
  <summary>Details</summary>
Motivation: 探索一阶边缘图是否足以驱动MLP进行手写字符识别，作为CNN的替代方案

Method: 仅使用水平和垂直Sobel导数作为输入，在MNIST和EMNIST Letters数据集上训练全密链接MLP

Result: 在MNIST数字上达到98%准确率，EMNIST字母上92%准确率，接近CNN性能但更节省内存

Conclusion: 手写字符图像中的类别区分信息已被一阶梯度抓取，边缘感知MLP是HCR的简洁有效方案

Abstract: We revisit the classical Sobel operator to ask a simple question: Are
first-order edge maps sufficient to drive an all-dense multilayer perceptron
(MLP) for handwritten character recognition (HCR), as an alternative to
convolutional neural networks (CNNs)? Using only horizontal and vertical Sobel
derivatives as input, we train an MLP on MNIST and EMNIST Letters. Despite its
extreme simplicity, the resulting network reaches 98% accuracy on MNIST digits
and 92% on EMNIST letters -- approaching CNNs while offering a smaller memory
footprint and transparent features. Our findings highlight that much of the
class-discriminative information in handwritten character images is already
captured by first-order gradients, making edge-aware MLPs a compelling option
for HCR.

</details>


### [154] [OVG-HQ: Online Video Grounding with Hybrid-modal Queries](https://arxiv.org/abs/2508.11903)
*Runhao Zeng,Jiaqi Mao,Minghao Lai,Minh Hieu Phan,Yanjie Dong,Wei Wang,Qi Chen,Xiping Hu*

Main category: cs.CV

TL;DR: 这篇论文提出了一种新的在线视频基准任务OVG-HQ，支持多模态查询，解决了传统视频基准在流媒体和视觉索引场景下的限制。论文还提出了统一框架OVG-HQ-Unify和新的在线评价指标。


<details>
  <summary>Details</summary>
Motivation: 传统视频基准任务在流式视频和使用视觉索引的查询场景中遇到困难，需要一种能够在线处理多模态查询的方案。

Method: 提出OVG-HQ-Unify统一框架，包含参数化记忆块(PMB)来保留历史知识，以及交叉模态蒸馈策略来平衡不同模态的学习。构建了QVHighlights-Unify数据集来支持多模态查询。

Result: 实验结果显示OVG-HQ-Unify框架在新提出的在线评价指标(oR@n, IoU=m, omAP)上表现超过现有模型，能够同时考虑准确性和效率。

Conclusion: 该研究为在线、混合模态视频基准提供了一个健壮的解决方案，有效解决了上下文限制和模态不平衡问题，为该领域的未来研究奠定了基础。

Abstract: Video grounding (VG) task focuses on locating specific moments in a video
based on a query, usually in text form. However, traditional VG struggles with
some scenarios like streaming video or queries using visual cues. To fill this
gap, we present a new task named Online Video Grounding with Hybrid-modal
Queries (OVG-HQ), which enables online segment localization using text, images,
video segments, and their combinations. This task poses two new challenges:
limited context in online settings and modality imbalance during training,
where dominant modalities overshadow weaker ones. To address these, we propose
OVG-HQ-Unify, a unified framework featuring a Parametric Memory Block (PMB)
that retain previously learned knowledge to enhance current decision and a
cross-modal distillation strategy that guides the learning of non-dominant
modalities. This design enables a single model to effectively handle
hybrid-modal queries. Due to the lack of suitable datasets, we construct
QVHighlights-Unify, an expanded dataset with multi-modal queries. Besides,
since offline metrics overlook prediction timeliness, we adapt them to the
online setting, introducing oR@n, IoU=m, and online mean Average Precision
(omAP) to evaluate both accuracy and efficiency. Experiments show that our
OVG-HQ-Unify outperforms existing models, offering a robust solution for
online, hybrid-modal video grounding. Source code and datasets are available at
https://github.com/maojiaqi2324/OVG-HQ.

</details>


### [155] [SafeCtrl: Region-Based Safety Control for Text-to-Image Diffusion via Detect-Then-Suppress](https://arxiv.org/abs/2508.11904)
*Lingyun Zhang,Yu Xie,Yanwei Fu,Ping Chen*

Main category: cs.CV

TL;DR: SafeCtrl是一个轻量级非侵入式插件，采用检测-抑制范式来提升文本到图像模型的安全性，通过DPO训练实现有害语义抑制而不需要像素级标注，在安全性和保真度方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有安全方法（如提示重写或模型微调）在安全性和保真度之间存在权衡，基于定位的方法依赖显式概念替换可能导致语义不协调，需要更灵活的解决方案。

Method: 提出SafeCtrl插件：1）精确定位不安全内容；2）抑制有害语义而非硬替换，让生成过程自然过渡到安全替代方案；3）使用DPO训练策略，利用图像级偏好数据学习细粒度抑制行为。

Result: 大量实验表明SafeCtrl在安全有效性和保真度保持方面显著优于最先进方法，实现了更好的安全控制效果。

Conclusion: 解耦的基于抑制的控制是构建更负责任生成模型的高效且可扩展方向，SafeCtrl为文本到图像模型的安全部署提供了有效解决方案。

Abstract: The widespread deployment of text-to-image models is challenged by their
potential to generate harmful content. While existing safety methods, such as
prompt rewriting or model fine-tuning, provide valuable interventions, they
often introduce a trade-off between safety and fidelity. Recent
localization-based approaches have shown promise, yet their reliance on
explicit ``concept replacement" can sometimes lead to semantic incongruity. To
address these limitations, we explore a more flexible detect-then-suppress
paradigm. We introduce SafeCtrl, a lightweight, non-intrusive plugin that first
precisely localizes unsafe content. Instead of performing a hard A-to-B
substitution, SafeCtrl then suppresses the harmful semantics, allowing the
generative process to naturally and coherently resolve into a safe,
context-aware alternative. A key aspect of our work is a novel training
strategy using Direct Preference Optimization (DPO). We leverage readily
available, image-level preference data to train our module, enabling it to
learn nuanced suppression behaviors and perform region-guided interventions at
inference without requiring costly, pixel-level annotations. Extensive
experiments show that SafeCtrl significantly outperforms state-of-the-art
methods in both safety efficacy and fidelity preservation. Our findings suggest
that decoupled, suppression-based control is a highly effective and scalable
direction for building more responsible generative models.

</details>


### [156] [TimeSenCLIP: A Vision-Language Model for Remote Sensing Using Single-Pixel Time Series](https://arxiv.org/abs/2508.11919)
*Pallavi Jain,Diego Marcos,Dino Ienco,Roberto Interdonato,Tristan Berchoux*

Main category: cs.CV

TL;DR: 时空语言模型TimeSenCLIP通过利用单像素的谱段和时间信息，提供了一种计算效率更高的遥感分类方案，减少对文本监督的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决当前遥感视觉-语言模型在土地利用分类中遇到的两大挑战：大尺度空间码片导致计算成本高，以及对文本监督数据的依赖。

Method: 构建TimeSenCLIP轻量框架，通过利用Sentinel-2影像的谱段和时间信息，结合地理标签地面照片进行跨视角学习，最小化对文本说明训练的需求。

Result: 在LULC、作物类型和生态系统类型分类任务中，单像素输入结合时间和谱段线索足以完成主题制图，提供了可扩展的高效方案。

Conclusion: 时间和谱段信息可以补偿空间上下文的缺失，为大规模遥感应用提供了更简洁和效率更高的分类方法。

Abstract: Vision-language models have shown significant promise in remote sensing
applications, particularly for land-use and land-cover (LULC) via zero-shot
classification and retrieval. However, current approaches face two key
challenges: reliance on large spatial tiles that increase computational cost,
and dependence on text-based supervision, which is often not readily available.
In this work, we present TimeSenCLIP, a lightweight framework that reevaluate
the role of spatial context by evaluating the effectiveness of a single pixel
by leveraging its temporal and spectral dimensions, for classifying LULC and
ecosystem types. By leveraging spectral and temporal information from
Sentinel-2 imagery and cross-view learning with geo-tagged ground-level photos,
we minimises the need for caption-based training while preserving semantic
alignment between overhead (satellite) and ground perspectives. Our approach is
grounded in the LUCAS and Sen4Map datasets, and evaluated on classification
tasks including LULC, crop type, and ecosystem type. We demonstrate that single
pixel inputs, when combined with temporal and spectral cues, are sufficient for
thematic mapping, offering a scalable and efficient alternative for large-scale
remote sensing applications. Code is available at
https://github.com/pallavijain-pj/TimeSenCLIP

</details>


### [157] [Assessment of Using Synthetic Data in Brain Tumor Segmentation](https://arxiv.org/abs/2508.11922)
*Aditi Jahagirdar,Sameer Joshi*

Main category: cs.CV

TL;DR: 使用GAN生成的合成MRI数据来扩充真实数据训练U-Net脱脑脱病分割模型，在整体性能上与真实数据相似，但在40%真实+60%合成的混合数据下改善了脱病边界识别。


<details>
  <summary>Details</summary>
Motivation: 解决手动脱脱病分割面临的挑战：脱病异质性、标注数据稀缺和类别不平衡。通过生成式模型产生合成数据来提升数据集多样性。

Method: 使用预训练GAN模型生成合成MRI数据，将真实数据(BraTS 2020)与合成数据(medigan库)按不同比例混合，训练U-Net分割网络。比较不同混合比例下的性能。

Result: 整体数值性能(Dice、IoU、精度、召回率、准确度)在真实数据和混合数据之间相似，但在40%真实+60%合成的混合数据下改善了整体脱病边界识别。脱病核心和增强区域的分割准确度仍较低，表明类别不平衡问题仍存在。

Conclusion: 合成数据作为数据扩充策略在脱脱病分割中具有可行性，但需要进一步进行大规模实验、确保体积数据一致性并解决类别不平衡问题。

Abstract: Manual brain tumor segmentation from MRI scans is challenging due to tumor
heterogeneity, scarcity of annotated data, and class imbalance in medical
imaging datasets. Synthetic data generated by generative models has the
potential to mitigate these issues by improving dataset diversity. This study
investigates, as a proof of concept, the impact of incorporating synthetic MRI
data, generated using a pre-trained GAN model, into training a U-Net
segmentation network. Experiments were conducted using real data from the BraTS
2020 dataset, synthetic data generated with the medigan library, and hybrid
datasets combining real and synthetic samples in varying proportions. While
overall quantitative performance (Dice coefficient, IoU, precision, recall,
accuracy) was comparable between real-only and hybrid-trained models,
qualitative inspection suggested that hybrid datasets, particularly with 40%
real and 60% synthetic data, improved whole tumor boundary delineation.
However, region-wise accuracy for the tumor core and the enhancing tumor
remained lower, indicating a persistent class imbalance. The findings support
the feasibility of synthetic data as an augmentation strategy for brain tumor
segmentation, while highlighting the need for larger-scale experiments,
volumetric data consistency, and mitigating class imbalance in future work.

</details>


### [158] [Deep Learning For Point Cloud Denoising: A Survey](https://arxiv.org/abs/2508.11932)
*Chengwei Zhang,Xueyi Zhang,Mingrui Lao,Tao Jiang,Xinhao Xu,Wenjie Li,Fubo Zhang,Longyong Chen*

Main category: cs.CV

TL;DR: 这是一份关于深度学习基于点云去噪的综述性论文，系统总结了该领域的发展状况、提出了分类框架并分析了现有方法的优势与挑战、展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 实际环境中的点云数据存在多种模态和强度的噪声，需要通过去噪预处理来提升下游任务性能。深度学习方法虽然表现优异，但缺乏系统的综述性研究来总结该领域的发展。

Method: 论文将点云去噪模型化为两步过程：离群点移除和表面噪声恢复，并为去噪任务设计了专门的分类框架。通过对现有方法进行详细对比分析，总结了各自的相似性、差异性和优势特点。

Result: 论文提供了一个系统的分类体系来帮助理解深度学习基于点云去噪的研究进展，明确了不同方法的适用场景和效能特点。

Conclusion: 论文填补了深度学习基于点云去噪领域的综述性研究空白，通过提出两步去噪模型和分类框架为该领域提供了结构化的研究视角，并指出了现有研究的局限性和未来可能的发展方向。

Abstract: Real-world environment-derived point clouds invariably exhibit noise across
varying modalities and intensities. Hence, point cloud denoising (PCD) is
essential as a preprocessing step to improve downstream task performance. Deep
learning (DL)-based PCD models, known for their strong representation
capabilities and flexible architectures, have surpassed traditional methods in
denoising performance. To our best knowledge, despite recent advances in
performance, no comprehensive survey systematically summarizes the developments
of DL-based PCD. To fill the gap, this paper seeks to identify key challenges
in DL-based PCD, summarizes the main contributions of existing methods, and
proposes a taxonomy tailored to denoising tasks. To achieve this goal, we
formulate PCD as a two-step process: outlier removal and surface noise
restoration, encompassing most scenarios and requirements of PCD. Additionally,
we compare methods in terms of similarities, differences, and respective
advantages. Finally, we discuss research limitations and future directions,
offering insights for further advancements in PCD.

</details>


### [159] [DynamicPose: Real-time and Robust 6D Object Pose Tracking for Fast-Moving Cameras and Objects](https://arxiv.org/abs/2508.11950)
*Tingbang Liang,Yixin Zeng,Jiatong Xie,Boyu Zhou*

Main category: cs.CV

TL;DR: DynamicPose是一个无需重新训练的6D姿态跟踪框架，通过视觉惯性里程计、深度信息2D跟踪器和VIO引导的卡尔曼滤波器协同工作，解决了快速移动相机和物体场景中的姿态跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于静态或准静态场景，当相机和物体都快速移动时性能显著下降。需要开发能够在快速移动场景中保持鲁棒性的6D姿态跟踪方法。

Method: 提出三个协同组件：1）视觉惯性里程计补偿相机运动引起的ROI偏移；2）深度信息2D跟踪器校正大物体平移引起的ROI偏差；3）VIO引导的卡尔曼滤波器预测物体旋转并生成候选姿态，通过分层细化获得最终姿态。形成闭环系统确保精确的姿态初始化和跟踪。

Result: 仿真和真实世界实验证明该方法有效，能够实现快速移动相机和物体的实时鲁棒6D姿态跟踪。

Conclusion: DynamicPose框架通过创新的组件设计和闭环系统，成功解决了快速移动场景中的6D姿态跟踪挑战，实现了实时鲁棒的跟踪性能。

Abstract: We present DynamicPose, a retraining-free 6D pose tracking framework that
improves tracking robustness in fast-moving camera and object scenarios.
Previous work is mainly applicable to static or quasi-static scenes, and its
performance significantly deteriorates when both the object and the camera move
rapidly. To overcome these challenges, we propose three synergistic components:
(1) A visual-inertial odometry compensates for the shift in the Region of
Interest (ROI) caused by camera motion; (2) A depth-informed 2D tracker
corrects ROI deviations caused by large object translation; (3) A VIO-guided
Kalman filter predicts object rotation, generates multiple candidate poses, and
then obtains the final pose by hierarchical refinement. The 6D pose tracking
results guide subsequent 2D tracking and Kalman filter updates, forming a
closed-loop system that ensures accurate pose initialization and precise pose
tracking. Simulation and real-world experiments demonstrate the effectiveness
of our method, achieving real-time and robust 6D pose tracking for fast-moving
cameras and objects.

</details>


### [160] [Transferable Class Statistics and Multi-scale Feature Approximation for 3D Object Detection](https://arxiv.org/abs/2508.11951)
*Hao Peng,Hong Sang,Yajing Ma,Ping Qiu,Chao Ji*

Main category: cs.CV

TL;DR: 这篇论文通过知识蓄粉近似点云多尺度特征，设计可转移特征嵌入机制和中心加权IoU，在节省计算成本的同时提高物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 点云多尺度特征学习通常需要多次邻域搜索和尺度感知层，计算成本高且不利于轻量级模型发展。

Method: 基于知识蓄粉从单一邻域近似多尺度特征，使用类别统计特征作为可转移特征补偿构造性多样性损失，并引入中心加权IoU优化定位。

Result: 在公开数据集上进行了广泛实验，证明了所提方法的有效性。

Conclusion: 该方法能够在节省计算成本的前提下，实现高效的点云物体检测。

Abstract: This paper investigates multi-scale feature approximation and transferable
features for object detection from point clouds. Multi-scale features are
critical for object detection from point clouds. However, multi-scale feature
learning usually involves multiple neighborhood searches and scale-aware
layers, which can hinder efforts to achieve lightweight models and may not be
conducive to research constrained by limited computational resources. This
paper approximates point-based multi-scale features from a single neighborhood
based on knowledge distillation. To compensate for the loss of constructive
diversity in a single neighborhood, this paper designs a transferable feature
embedding mechanism. Specifically, class-aware statistics are employed as
transferable features given the small computational cost. In addition, this
paper introduces the central weighted intersection over union for localization
to alleviate the misalignment brought by the center offset in optimization.
Note that the method presented in this paper saves computational costs.
Extensive experiments on public datasets demonstrate the effectiveness of the
proposed method.

</details>


### [161] [UniUGG: Unified 3D Understanding and Generation via Geometric-Semantic Encoding](https://arxiv.org/abs/2508.11952)
*Yueming Xu,Jiahui Zhang,Ze Huang,Yurui Chen,Yanpeng Zhou,Zhenyu Chen,Yu-Jie Yuan,Pengxiang Xia,Guowei Huang,Xinyue Cai,Zhongang Qi,Xingyue Quan,Jianye Hao,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: UniUGG是首个统一的3D模态理解和生成框架，使用LLM处理文本和3D表示，核心采用潜在扩散模型生成高质量3D内容，支持基于参考图像和视角变换的3D场景生成与空间VQA任务。


<details>
  <summary>Details</summary>
Motivation: 尽管近期统一架构在图像理解和生成方面取得显著进展，但3D任务的整合仍然具有挑战性且研究不足，需要开发能够同时处理3D理解和生成的统一框架。

Method: 提出UniUGG框架：1）使用LLM理解和解码句子与3D表示；2）核心空间解码器采用潜在扩散模型生成高质量3D表示；3）提出几何-语义学习策略预训练视觉编码器，联合捕获输入的语义和几何线索。

Result: 大量实验结果表明，该方法在视觉表示、空间理解和3D生成方面表现出优越性能。

Conclusion: UniUGG成功实现了3D模态的统一理解和生成，通过创新的空间解码器和几何-语义学习策略，显著提升了3D场景的空间理解能力和生成质量。

Abstract: Despite the impressive progress on understanding and generating images shown
by the recent unified architectures, the integration of 3D tasks remains
challenging and largely unexplored. In this paper, we introduce UniUGG, the
first unified understanding and generation framework for 3D modalities. Our
unified framework employs an LLM to comprehend and decode sentences and 3D
representations. At its core, we propose a spatial decoder leveraging a latent
diffusion model to generate high-quality 3D representations. This allows for
the generation and imagination of 3D scenes based on a reference image and an
arbitrary view transformation, while remaining supports for spatial visual
question answering (VQA) tasks. Additionally, we propose a geometric-semantic
learning strategy to pretrain the vision encoder. This design jointly captures
the input's semantic and geometric cues, enhancing both spatial understanding
and generation. Extensive experimental results demonstrate the superiority of
our method in visual representation, spatial understanding, and 3D generation.
The source code will be released upon paper acceptance.

</details>


### [162] [SAMDWICH: Moment-aware Video-text Alignment for Referring Video Object Segmentation](https://arxiv.org/abs/2508.11955)
*Seunghun Lee,Jiwan Seo,Jeonghoon Kim,Siwon Kim,Haeun Yun,Hyogyeong Jeon,Wonhyeok Choi,Jaehoon Jeong,Zane Durante,Sang Hyun Park,Sunghoon Im*

Main category: cs.CV

TL;DR: SAMDWICH是一个基于时刻感知的Referring Video Object Segmentation框架，通过新标注的MeViS-M数据集和时刻引导的双路径传播策略，解决了现有方法中的语义错位问题，在复杂场景下实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Referring Video Object Segmentation方法存在语义错位问题，主要原因是训练时对所有可见对象进行无差别帧采样和监督，而不考虑它们与文本查询的实际相关性。

Method: 提出了SAMDWICH框架，包括：1）新标注的MeViS-M数据集，手动标注了每个对象被表达式引用的时间时刻；2）时刻引导的双路径传播（MDP）策略，通过时刻中心记忆机制在相关和不相关帧上进行训练；3）对象级选择性监督（OSS）策略，只监督与表达式时间对齐的对象。

Result: 在具有挑战性的MeViS基准测试中实现了最先进的性能，特别是在涉及多样化表达式的复杂场景中表现出色。

Conclusion: 通过时刻感知的监督和选择性训练策略，SAMDWICH有效增强了视频-文本对齐，显著提升了引用理解能力，为解决RVOS中的语义错位问题提供了有效解决方案。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment and track objects
in videos based on natural language expressions, requiring precise alignment
between visual content and textual queries. However, existing methods often
suffer from semantic misalignment, largely due to indiscriminate frame sampling
and supervision of all visible objects during training -- regardless of their
actual relevance to the expression. To address this, we introduce a
moment-aware RVOS framework named SAMDWICH, along with a newly annotated
dataset, MeViS-M, built upon the challenging MeViS benchmark. We manually
annotate temporal moments indicating when each object is referred to by the
expression, enabling semantically grounded supervision that strengthens
video-text alignment. SAMDWICH leverages these aligned text-to-clip pairs to
guide training, significantly enhancing referential understanding. Building
upon this framework, we propose Moment-guided Dual-path Propagation (MDP), a
moment-aware propagation strategy that improves both object grounding and
tracking by training on both relevant and irrelevant frames through a
moment-centric memory mechanism. In addition, we introduce Object-level
Selective Supervision (OSS), an object-level filtering strategy that supervises
only the objects temporally aligned with the expression in each training clip.
This selective supervision reduces semantic noise and reinforces
language-conditioned learning. Extensive experiments show that SAMDWICH
achieves state-of-the-art performance on challenging MeViS benchmark,
particularly excelling in complex scenarios involving diverse expressions.

</details>


### [163] [PEdger++: Practical Edge Detection via Assembling Cross Information](https://arxiv.org/abs/2508.11961)
*Yuanbin Fu,Liang Li,Xiaojie Guo*

Main category: cs.CV

TL;DR: PEdger++是一个协作学习框架，通过异构架构、多样化训练时刻和多参数采样的跨信息来提升边缘检测性能，在保持高精度的同时显著降低计算成本和模型大小。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习边缘检测器在资源受限设备上计算成本高的问题，寻求在保持高精度的同时降低计算复杂度的平衡方案。

Method: 提出协作学习框架PEdger++，利用异构架构、多样化训练时刻和多参数采样的跨信息来增强学习效果，提供多个不同计算需求的模型版本。

Result: 在BSDS500、NYUD和Multicue数据集上的实验表明，该方法在定量和定性评估上都优于现有方法，同时显著降低了计算成本。

Conclusion: PEdger++通过协作学习有效解决了边缘检测中精度与计算效率的平衡问题，为资源受限设备提供了实用的解决方案。

Abstract: Edge detection serves as a critical foundation for numerous computer vision
applications, including object detection, semantic segmentation, and image
editing, by extracting essential structural cues that define object boundaries
and salient edges. To be viable for broad deployment across devices with
varying computational capacities, edge detectors shall balance high accuracy
with low computational complexity. While deep learning has evidently improved
accuracy, they often suffer from high computational costs, limiting their
applicability on resource-constrained devices. This paper addresses the
challenge of achieving that balance: \textit{i.e.}, {how to efficiently capture
discriminative features without relying on large-size and sophisticated
models}. We propose PEdger++, a collaborative learning framework designed to
reduce computational costs and model sizes while improving edge detection
accuracy. The core principle of our PEdger++ is that cross-information derived
from heterogeneous architectures, diverse training moments, and multiple
parameter samplings, is beneficial to enhance learning from an ensemble
perspective. Extensive experimental results on the BSDS500, NYUD and Multicue
datasets demonstrate the effectiveness of our approach, both quantitatively and
qualitatively, showing clear improvements over existing methods. We also
provide multiple versions of the model with varying computational requirements,
highlighting PEdger++'s adaptability with respect to different resource
constraints. Codes are accessible at
https://github.com/ForawardStar/EdgeDetectionviaPEdgerPlus/.

</details>


### [164] [Exploring Spatial-Temporal Dynamics in Event-based Facial Micro-Expression Analysis](https://arxiv.org/abs/2508.11988)
*Nicolas Mastropasqua,Ignacio Bugueno-Cordova,Rodrigo Verschae,Daniel Acevedo,Pablo Negri,Maria E. Buemi*

Main category: cs.CV

TL;DR: 这篇论文提出了一个新的多分辨率多模态微表情数据集，利用同步RGB和事件相机在变化光照条件下记录，并通过基线实验证明事件数据在微表情识别和帧重建中的优势


<details>
  <summary>Details</summary>
Motivation: 微表情分析在人机交互和驾驶呜涛系统中有重要应用，但依靠RGB相机捕捉细微快速面部运动因时间分辨率和运动模糊限制而困难，需要更好的解决方案

Method: 使用同步RGB和事件相机在变化光照条件下记录多分辨率多模态微表情数据集，并评估两个基线任务：使用脏细胞神经网络进行动作单元分类，以及使用条件变分自动编码器进行帧重建

Result: 事件数据在动作单元分类中达到51.23%准确率（RGB仅23.12%），在高分辨率事件输入的帧重建中达到SSIM=0.8513和PSNR=26.89dB

Conclusion: 事件基数据可用于微表情识别和帧重建，为微表情分析领域提供了更有效的解决方案

Abstract: Micro-expression analysis has applications in domains such as Human-Robot
Interaction and Driver Monitoring Systems. Accurately capturing subtle and fast
facial movements remains difficult when relying solely on RGB cameras, due to
limitations in temporal resolution and sensitivity to motion blur. Event
cameras offer an alternative, with microsecond-level precision, high dynamic
range, and low latency. However, public datasets featuring event-based
recordings of Action Units are still scarce. In this work, we introduce a
novel, preliminary multi-resolution and multi-modal micro-expression dataset
recorded with synchronized RGB and event cameras under variable lighting
conditions. Two baseline tasks are evaluated to explore the spatial-temporal
dynamics of micro-expressions: Action Unit classification using Spiking Neural
Networks (51.23\% accuracy with events vs. 23.12\% with RGB), and frame
reconstruction using Conditional Variational Autoencoders, achieving SSIM =
0.8513 and PSNR = 26.89 dB with high-resolution event input. These promising
results show that event-based data can be used for micro-expression recognition
and frame reconstruction.

</details>


### [165] [MOON: Generative MLLM-based Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2508.11999)
*Daoze Zhang,Zhanheng Nie,Jianyu Liu,Chenghan Fu,Wanxian Guan,Yuan Gao,Jun Song,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: 提出了首个基于生成式多模态大语言模型的产品表示学习方法MOON，通过引导专家混合模块、核心语义区域检测和负采样策略，解决了产品图像-文本多对一对齐、背景噪声干扰等挑战，并在新产品基准上展现了优异的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有判别式双流架构难以建模产品多图像与文本之间的多对一对齐关系，而生成式多模态大语言模型在产品表示学习方面具有巨大潜力但面临多重挑战。

Method: 1) 使用引导专家混合模块进行多模态和方面特定的产品内容建模；2) 检测产品图像中的核心语义区域以减少背景噪声干扰；3) 引入专门的负采样策略增加负样本难度和多样性；4) 发布大规模多模态基准MBE。

Result: 在新建基准和公共数据集上均表现出竞争力的零样本性能，在跨模态检索、产品分类和属性预测等下游任务中展现出强泛化能力。

Conclusion: MOON模型有效解决了产品表示学习中的关键挑战，案例研究和可视化证明了其在产品理解方面的有效性，为生成式MLLM在产品领域的应用提供了新思路。

Abstract: With the rapid advancement of e-commerce, exploring general representations
rather than task-specific ones has attracted increasing research attention. For
product understanding, although existing discriminative dual-flow architectures
drive progress in this field, they inherently struggle to model the many-to-one
alignment between multiple images and texts of products. Therefore, we argue
that generative Multimodal Large Language Models (MLLMs) hold significant
potential for improving product representation learning. Nevertheless,
achieving this goal still remains non-trivial due to several key challenges:
the lack of multimodal and aspect-aware modeling modules in typical LLMs; the
common presence of background noise in product images; and the absence of a
standard benchmark for evaluation. To address these issues, we propose the
first generative MLLM-based model named MOON for product representation
learning. Our method (1) employs a guided Mixture-of-Experts (MoE) module for
targeted modeling of multimodal and aspect-specific product content; (2)
effectively detects core semantic regions in product images to mitigate the
distraction and interference caused by background noise; and (3) introduces the
specialized negative sampling strategy to increase the difficulty and diversity
of negative samples. In addition, we release a large-scale multimodal benchmark
MBE for various product understanding tasks. Experimentally, our model
demonstrates competitive zero-shot performance on both our benchmark and the
public dataset, showcasing strong generalization across various downstream
tasks, including cross-modal retrieval, product classification, and attribute
prediction. Furthermore, the case study and visualization illustrate the
effectiveness of MOON for product understanding.

</details>


### [166] [InstDrive: Instance-Aware 3D Gaussian Splatting for Driving Scenes](https://arxiv.org/abs/2508.12015)
*Hongyuan Liu,Haochen Yu,Jianfei Jiang,Qiankun Liu,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: InstDrive是一个针对动态驾驶场景的实例感知3D高斯泼溅框架，通过SAM生成的掩码作为伪真值指导2D特征学习，在3D层面引入正则化和体素损失来实现实例一致性，无需数据预处理即可实现动态开放世界驾驶场景的3D实例分割。


<details>
  <summary>Details</summary>
Motivation: 现有的动态驾驶场景重建方法通常将所有背景元素统一为单一表示，限制了实例级理解和灵活的场景编辑能力。现有方法多针对室内场景设计，不适用于室外驾驶场景，且需要预处理实例ID或复杂管道来映射连续特征到离散身份。

Method: 使用SAM生成的掩码作为伪真值，通过对比损失和伪监督目标指导2D特征学习；在3D层面引入正则化隐式编码实例身份，通过体素损失强制一致性；使用轻量级静态码本桥接连续特征和离散身份，无需数据预处理或复杂优化。

Result: 定量和定性实验证明了InstDrive的有效性，据作者所知，这是首个在动态开放世界驾驶场景中实现3D实例分割的框架。

Conclusion: InstDrive成功解决了动态驾驶场景中实例感知重建的挑战，为自动驾驶和场景理解提供了有效的实例级3D表示方法，无需复杂预处理即可实现高质量的实例分割。

Abstract: Reconstructing dynamic driving scenes from dashcam videos has attracted
increasing attention due to its significance in autonomous driving and scene
understanding. While recent advances have made impressive progress, most
methods still unify all background elements into a single representation,
hindering both instance-level understanding and flexible scene editing. Some
approaches attempt to lift 2D segmentation into 3D space, but often rely on
pre-processed instance IDs or complex pipelines to map continuous features to
discrete identities. Moreover, these methods are typically designed for indoor
scenes with rich viewpoints, making them less applicable to outdoor driving
scenarios. In this paper, we present InstDrive, an instance-aware 3D Gaussian
Splatting framework tailored for the interactive reconstruction of dynamic
driving scene. We use masks generated by SAM as pseudo ground-truth to guide 2D
feature learning via contrastive loss and pseudo-supervised objectives. At the
3D level, we introduce regularization to implicitly encode instance identities
and enforce consistency through a voxel-based loss. A lightweight static
codebook further bridges continuous features and discrete identities without
requiring data pre-processing or complex optimization. Quantitative and
qualitative experiments demonstrate the effectiveness of InstDrive, and to the
best of our knowledge, it is the first framework to achieve 3D instance
segmentation in dynamic, open-world driving scenes.More visualizations are
available at our project page.

</details>


### [167] [WiseLVAM: A Novel Framework For Left Ventricle Automatic Measurements](https://arxiv.org/abs/2508.12023)
*Durgesh Kumar Singh,Qing Cao,Sarina Thomas,Ahcène Boubekki,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 基于强监督B模式标记点检测的客观矩形方法，自动放置扫描线并在AMM模式下进行左室线性测量的全自动化框架


<details>
  <summary>Details</summary>
Motivation: 解决现有自动方法在B模式图像中直接预测标记点导致测量错误过大的问题，提高临床可靠性

Method: 通过弱监督B模式标记点检测器估计左室边界，推断左室长轴和基底层次来自动放置扫描线，然后在AMM模式下进行标记点预测

Result: 开发了WiseLVAM框架，结合B模式的结构感知和AMM模式的运动感知，提高了测量的稳健性和准确性

Conclusion: 该全自动化方法有望为常规临床应用提供实用解决方案

Abstract: Clinical guidelines recommend performing left ventricular (LV) linear
measurements in B-mode echocardiographic images at the basal level -- typically
at the mitral valve leaflet tips -- and aligned perpendicular to the LV long
axis along a virtual scanline (SL). However, most automated methods estimate
landmarks directly from B-mode images for the measurement task, where even
small shifts in predicted points along the LV walls can lead to significant
measurement errors, reducing their clinical reliability. A recent
semi-automatic method, EnLVAM, addresses this limitation by constraining
landmark prediction to a clinician-defined SL and training on generated
Anatomical Motion Mode (AMM) images to predict LV landmarks along the same. To
enable full automation, a contour-aware SL placement approach is proposed in
this work, in which the LV contour is estimated using a weakly supervised
B-mode landmark detector. SL placement is then performed by inferring the LV
long axis and the basal level-mimicking clinical guidelines. Building on this
foundation, we introduce \textit{WiseLVAM} -- a novel, fully automated yet
manually adaptable framework for automatically placing the SL and then
automatically performing the LV linear measurements in the AMM mode.
\textit{WiseLVAM} utilizes the structure-awareness from B-mode images and the
motion-awareness from AMM mode to enhance robustness and accuracy with the
potential to provide a practical solution for the routine clinical application.

</details>


### [168] [Q-FSRU: Quantum-Augmented Frequency-Spectral Fusion for Medical Visual Question Answering](https://arxiv.org/abs/2508.12036)
*Rakesh Thakur,Yusra Tariq*

Main category: cs.CV

TL;DR: Q-FSRU是一个结合频域特征提取和量子检索增强生成的医学视觉问答模型，在VQA-RAD数据集上表现优异


<details>
  <summary>Details</summary>
Motivation: 解决需要同时理解医学图像和文本的复杂临床问题，这是医疗AI领域的主要挑战

Method: 使用快速傅里叶变换将医学图像和文本特征转换到频域，结合量子检索系统从外部知识源获取医学事实，并将两者融合进行推理

Result: 在VQA-RAD数据集上超越了之前的模型，特别是在需要图像-文本推理的复杂病例上表现突出

Conclusion: 该方法为构建智能、清晰且有用的医生AI工具提供了有前景的途径，频域和量子信息的结合提升了性能和可解释性

Abstract: Solving tough clinical questions that require both image and text
understanding is still a major challenge in healthcare AI. In this work, we
propose Q-FSRU, a new model that combines Frequency Spectrum Representation and
Fusion (FSRU) with a method called Quantum Retrieval-Augmented Generation
(Quantum RAG) for medical Visual Question Answering (VQA). The model takes in
features from medical images and related text, then shifts them into the
frequency domain using Fast Fourier Transform (FFT). This helps it focus on
more meaningful data and filter out noise or less useful information. To
improve accuracy and ensure that answers are based on real knowledge, we add a
quantum-inspired retrieval system. It fetches useful medical facts from
external sources using quantum-based similarity techniques. These details are
then merged with the frequency-based features for stronger reasoning. We
evaluated our model using the VQA-RAD dataset, which includes real radiology
images and questions. The results showed that Q-FSRU outperforms earlier
models, especially on complex cases needing image-text reasoning. The mix of
frequency and quantum information improves both performance and explainability.
Overall, this approach offers a promising way to build smart, clear, and
helpful AI tools for doctors.

</details>


### [169] [VimoRAG: Video-based Retrieval-augmented 3D Motion Generation for Motion Language Models](https://arxiv.org/abs/2508.12081)
*Haidong Xu,Guangwei Xu,Zhedong Zheng,Xiatian Zhu,Wei Ji,Xiangtai Li,Ruijie Guo,Meishan Zhang,Min zhang,Hao Fei*

Main category: cs.CV

TL;DR: VimoRAG是一个基于视频检索增强的运动生成框架，通过从大规模视频数据库中检索2D人体运动信号来解决运动大语言模型的数据稀缺问题，显著提升了仅使用文本输入的运动生成性能。


<details>
  <summary>Details</summary>
Motivation: 运动大语言模型由于标注数据有限，面临严重的领域外/词汇外问题，需要利用大规模野外视频数据库来增强3D运动生成能力。

Method: 设计了Gemini Motion Video Retriever机制进行有效的运动中心视频检索，以及Motion-centric Dual-alignment DPO Trainer来缓解检索错误传播问题。

Result: 实验结果表明VimoRAG显著提升了仅使用文本输入的运动大语言模型的性能。

Conclusion: 视频检索增强方法有效解决了运动生成中的数据稀缺问题，为运动大语言模型提供了新的性能提升途径。

Abstract: This paper introduces VimoRAG, a novel video-based retrieval-augmented motion
generation framework for motion large language models (LLMs). As motion LLMs
face severe out-of-domain/out-of-vocabulary issues due to limited annotated
data, VimoRAG leverages large-scale in-the-wild video databases to enhance 3D
motion generation by retrieving relevant 2D human motion signals. While
video-based motion RAG is nontrivial, we address two key bottlenecks: (1)
developing an effective motion-centered video retrieval model that
distinguishes human poses and actions, and (2) mitigating the issue of error
propagation caused by suboptimal retrieval results. We design the Gemini Motion
Video Retriever mechanism and the Motion-centric Dual-alignment DPO Trainer,
enabling effective retrieval and generation processes. Experimental results
show that VimoRAG significantly boosts the performance of motion LLMs
constrained to text-only input.

</details>


### [170] [Automated Model Evaluation for Object Detection via Prediction Consistency and Reliablity](https://arxiv.org/abs/2508.12082)
*Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee*

Main category: cs.CV

TL;DR: 自动化对识检测器性能评估的新方法，通过分析NMS前后预测框的一致性和可靠性来预测性能，无需人工标注


<details>
  <summary>Details</summary>
Motivation: 解决对识检测器在实际应用中性能评估依赖成本高明的人工标注问题

Method: 提出预测一致性和可靠性(PCR)方法，聚合分析NMS前后预测框的空间一致性和重叠框的信心度可靠性

Result: 实验结果显示PCR比现有自动评估方法更准确，构建的元数据集覆盖更广泛的检测性能范围

Conclusion: 该框架能够有效地预测对识检测器的性能，减少对人工标注的依赖，提供了更实用和可扩展的评估方案

Abstract: Recent advances in computer vision have made training object detectors more
efficient and effective; however, assessing their performance in real-world
applications still relies on costly manual annotation. To address this
limitation, we develop an automated model evaluation (AutoEval) framework for
object detection. We propose Prediction Consistency and Reliability (PCR),
which leverages the multiple candidate bounding boxes that conventional
detectors generate before non-maximum suppression (NMS). PCR estimates
detection performance without ground-truth labels by jointly measuring 1) the
spatial consistency between boxes before and after NMS, and 2) the reliability
of the retained boxes via the confidence scores of overlapping boxes. For a
more realistic and scalable evaluation, we construct a meta-dataset by applying
image corruptions of varying severity. Experimental results demonstrate that
PCR yields more accurate performance estimates than existing AutoEval methods,
and the proposed meta-dataset covers a wider range of detection performance.
The code is available at https://github.com/YonseiML/autoeval-det.

</details>


### [171] [Generic Event Boundary Detection via Denoising Diffusion](https://arxiv.org/abs/2508.12084)
*Jaejun Hwang,Dayoung Gong,Manjin Kim,Minsu Cho*

Main category: cs.CV

TL;DR: DiffGEBD是一个基于扩散模型的通用事件边界检测方法，通过生成式视角解决事件边界检测问题，能够产生多样化的边界预测，并在标准基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统的事件边界检测方法主要关注确定性预测，忽视了事件边界的主观性和解决方案的多样性，需要一种能够生成多种合理边界的方法。

Method: 提出基于扩散模型的DiffGEBD方法，通过时间自相似性编码相邻帧的相关变化，然后以编码特征为条件，迭代地将随机噪声解码为合理的事件边界，使用分类器自由引导控制多样性。

Result: 在Kinetics-GEBD和TAPOS两个标准基准测试中取得了强劲性能，能够生成多样且合理的事件边界。

Conclusion: 扩散模型为通用事件边界检测提供了有效的生成式解决方案，能够处理事件边界的主观性并产生多样化的预测结果。

Abstract: Generic event boundary detection (GEBD) aims to identify natural boundaries
in a video, segmenting it into distinct and meaningful chunks. Despite the
inherent subjectivity of event boundaries, previous methods have focused on
deterministic predictions, overlooking the diversity of plausible solutions. In
this paper, we introduce a novel diffusion-based boundary detection model,
dubbed DiffGEBD, that tackles the problem of GEBD from a generative
perspective. The proposed model encodes relevant changes across adjacent frames
via temporal self-similarity and then iteratively decodes random noise into
plausible event boundaries being conditioned on the encoded features.
Classifier-free guidance allows the degree of diversity to be controlled in
denoising diffusion. In addition, we introduce a new evaluation metric to
assess the quality of predictions considering both diversity and fidelity.
Experiments show that our method achieves strong performance on two standard
benchmarks, Kinetics-GEBD and TAPOS, generating diverse and plausible event
boundaries.

</details>


### [172] [Enhancing 3D point accuracy of laser scanner through multi-stage convolutional neural network for applications in construction](https://arxiv.org/abs/2508.12089)
*Qinyuan Fan,Clemens Gühmann*

Main category: cs.CV

TL;DR: 提出一种多阶段卷积神经网络方法，通过统计学习量化高低端扫描仪的系统误差，在不改变硬件的情况下显著提升低端设备的测量精度


<details>
  <summary>Details</summary>
Motivation: 解决高端和低端光象扫描仪因设备限制和环境因素导致的位置误差问题，为高精度几何模型创建提供更准确的空间测量

Method: 使用高精度扫描仪作为参考，在同一环境下配对高低端设备测量数据，通过统计关系建立测量差异与空间分布的联系，结合传统几何处理和神经网络精炼进行系统误差等式学习预测和缩正

Result: 在粗糕室内环境数据集中，测量精度显著提升，均方误差降低超70%以上，峰值信噪比提升约6分贝，低端设备达到接近高端设备的测量不确定性水平

Conclusion: 该方法通过软件算法方式有效减少低端光象扫描仪的系统误差，在不需要硬件改造的情况下显著提升了测量精度，为高精度几何模型建模提供了可靠的技术支撑

Abstract: We propose a multi-stage convolutional neural network (MSCNN) based
integrated method for reducing uncertainty of 3D point accuracy of lasar
scanner (LS) in rough indoor rooms, providing more accurate spatial
measurements for high-precision geometric model creation and renovation. Due to
different equipment limitations and environmental factors, high-end and low-end
LS have positional errors. Our approach pairs high-accuracy scanners (HAS) as
references with corresponding low-accuracy scanners (LAS) of measurements in
identical environments to quantify specific error patterns. By establishing a
statistical relationship between measurement discrepancies and their spatial
distribution, we develop a correction framework that combines traditional
geometric processing with targeted neural network refinement. This method
transforms the quantification of systematic errors into a supervised learning
problem, allowing precise correction while preserving critical geometric
features. Experimental results in our rough indoor rooms dataset show
significant improvements in measurement accuracy, with mean square error (MSE)
reductions exceeding 70% and peak signal-to-noise ratio (PSNR) improvements of
approximately 6 decibels. This approach enables low-end devices to achieve
measurement uncertainty levels approaching those of high-end devices without
hardware modifications.

</details>


### [173] [Error Propagation Mechanisms and Compensation Strategies for Quantized Diffusion](https://arxiv.org/abs/2508.12094)
*Songwei Liu,Hong Liu,Fangmin Chen,Xurui Peng,Chenqian Yan,Lean Fu,Xing Mei*

Main category: cs.CV

TL;DR: 通过理论分析推导散游模型的量化错误传播方程，提出时间步感知的累积错误补偿策略，显著提升低精度量化性能


<details>
  <summary>Details</summary>
Motivation: 散游模型迭代反向过程中的步进式量化错误累积影响输出质量，继而限制了量化加速技术的实际部署

Method: 建立理论框架数学形定错误传播模型，推导单步量化错误传播方程，并提出基于时间步感知的累积错误补偿方案

Result: 在多个图像数据集上的实验表明，该补偿策略能有效减少错误传播，显著提升现有PTQ方法的性能，达到低精度散游模型的最先进水平

Conclusion: 通过理论分析和实验验证，时间步感知的累积错误补偿策略为解决散游模型量化中的错误累积问题提供了有效方案，推动了量化加速技术的实际应用

Abstract: Diffusion models have transformed image synthesis by establishing
unprecedented quality and creativity benchmarks. Nevertheless, their
large-scale deployment faces challenges due to computationally intensive
iterative denoising processes. Although post-training quantization(PTQ)
provides an effective pathway for accelerating sampling, the iterative nature
of diffusion models causes stepwise quantization errors to accumulate
progressively during generation, inevitably compromising output fidelity. To
address this challenge, we develop a theoretical framework that mathematically
formulates error propagation in Diffusion Models (DMs), deriving per-step
quantization error propagation equations and establishing the first closed-form
solution for cumulative error. Building on this theoretical foundation, we
propose a timestep-aware cumulative error compensation scheme. Extensive
experiments across multiple image datasets demonstrate that our compensation
strategy effectively mitigates error propagation, significantly enhancing
existing PTQ methods to achieve state-of-the-art(SOTA) performance on
low-precision diffusion models.

</details>


### [174] [VELVET-Med: Vision and Efficient Language Pre-training for Volumetric Imaging Tasks in Medicine](https://arxiv.org/abs/2508.12108)
*Ziyang Zhang,Yang Yu,Xulei Yang,Si Yong Yeo*

Main category: cs.CV

TL;DR: VELVET-Med是一个专门针对3D医学影像（如CT扫描）和放射学报告的视觉语言预训练框架，通过创新的预训练目标和模型架构，在有限数据量（仅38,875对扫描-报告）下实现卓越性能


<details>
  <summary>Details</summary>
Motivation: 医学领域中3D影像（如CT扫描）与文本配对数据收集困难且耗时，限制了视觉语言模型在下游任务中的表现，需要开发专门针对有限体积数据的预训练方法

Method: 1）将单模态自监督学习融入VLP框架；2）提出TriBERT语言编码器学习多层次文本语义；3）设计分层对比学习捕获多层次视觉-语言对应关系

Result: 学习到的编码器展现出强大的迁移能力，在3D分割、跨模态检索、视觉问答和报告生成等多种下游任务中达到最先进性能

Conclusion: VELVET-Med框架通过创新的预训练策略，在有限数据条件下成功挖掘了体积医学影像和临床叙述中丰富的空间和语义关系，显著提升了编码器的泛化能力

Abstract: Vision-and-language models (VLMs) have been increasingly explored in the
medical domain, particularly following the success of CLIP in general domain.
However, unlike the relatively straightforward pairing of 2D images and text,
curating large-scale paired data in the medical field for volumetric modalities
such as CT scans remains a challenging and time-intensive process. This
difficulty often limits the performance on downstream tasks. To address these
challenges, we propose a novel vision-language pre-training (VLP) framework,
termed as \textbf{VELVET-Med}, specifically designed for limited volumetric
data such as 3D CT and associated radiology reports. Instead of relying on
large-scale data collection, our method focuses on the development of effective
pre-training objectives and model architectures. The key contributions are: 1)
We incorporate uni-modal self-supervised learning into VLP framework, which are
often underexplored in the existing literature. 2) We propose a novel language
encoder, termed as \textbf{TriBERT}, for learning multi-level textual
semantics. 3) We devise the hierarchical contrastive learning to capture
multi-level vision-language correspondence. Using only 38,875 scan-report
pairs, our approach seeks to uncover rich spatial and semantic relationships
embedded in volumetric medical images and corresponding clinical narratives,
thereby enhancing the generalization ability of the learned encoders. The
resulting encoders exhibit strong transferability, achieving state-of-the-art
performance across a wide range of downstream tasks, including 3D segmentation,
cross-modal retrieval, visual question answering, and report generation.

</details>


### [175] [Simple o3: Towards Interleaved Vision-Language Reasoning](https://arxiv.org/abs/2508.12109)
*Ye Wang,Qianglong Chen,Zejun Li,Siyuan Wang,Shijie Guo,Zhirui Zhang,Zhongyu Wei*

Main category: cs.CV

TL;DR: Simple o3是一个端到端的多模态推理框架，通过监督微调整合动态视觉工具操作（裁剪、缩放、重用）到交错的视觉-语言推理中，显著提升了多模态大语言模型的链式思维能力。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉-语言任务上表现优异，但在多模态场景下的长链式思维能力尚未得到充分探索，需要开发能够模拟人类"图像思维"的迭代推理方法。

Method: 提出可扩展的数据合成流水线，通过"观察-推理-行动"循环生成高质量的交错视觉-语言推理链，包含可执行的视觉操作和严格验证，创建了TWI-Tools-146K数据集，并通过监督微调整合动态工具交互。

Result: 实验结果表明Simple o3在多个基准测试中表现优异，优于现有方法。通过引入额外的视觉token进行交错推理，重用和放大原始图像显著改善了模型的视觉推理和细粒度感知能力，基于精确视觉定位的图像裁剪使模型能有效关注关键实体或区域。

Conclusion: Simple o3建立了一个强大且计算成本合理的多模态推理范式，首次深入分析了不同交错推理策略对模型性能的影响，为推进多模态推理提供了有效解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have shown impressive performance on
vision-language tasks, but their long Chain-of-Thought (CoT) capabilities in
multimodal scenarios remain underexplored. Inspired by OpenAI's o3 model, which
emulates human-like ''thinking with image'' through iterative visual
transformations and linguistic reasoning, we propose Simple o3, an end-to-end
framework that integrates dynamic tool interactions (e.g., cropping, zooming,
and reusing) into interleaved vision-language reasoning via supervised
fine-tuning (SFT). Our approach features a scalable data synthesis pipeline
that generates high-quality interleaved vision-language reasoning chains via an
''observe-reason-act'' cycle, complete with executable visual operations and
rigorous verification, yielding the open-source TWI-Tools-146K dataset.
Experimental results demonstrate Simple o3's superior performance on diverse
benchmarks, outperforming existing approaches. By combining enhanced reasoning
capabilities, Simple o3 establishes a powerful yet computationally affordable
paradigm for advancing multimodal reasoning. Remarkably, we provide the first
in-depth analysis of different interleaved reasoning strategies, offering
insights into their impact on model performance. We found that by introducing
additional visual tokens for interleaved vision-language reasoning, reusing and
magnifying the original image significantly improves the model's visual
reasoning and fine-grained perception, while image cropping based on precise
visual grounding allows the model to effectively focus on key entities or
regions, further enhancing its capabilities.

</details>


### [176] [DualFit: A Two-Stage Virtual Try-On via Warping and Synthesis](https://arxiv.org/abs/2508.12131)
*Minh Tran,Johnmark Clements,Annie Prasanna,Tri Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: DualFit是一个两阶段的虚拟试穿混合方法，通过变形和保真度合成来保持服装细节，解决了现有方法无法保留logo和印刷文字等细粒度细节的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散模型的免变形虚拟试穿方法虽然提高了感知质量，但往往无法保持对品牌完整性和客户信任至关重要的logo和印刷文字等细粒度服装细节。

Method: 采用两阶段混合管道：第一阶段使用学习流场将目标服装变形以对齐人体图像；第二阶段通过保真度试穿模块将变形后的服装与保留的人体区域进行融合，使用保留区域输入和修复掩码来指导过程。

Result: 广泛的定性结果显示DualFit实现了视觉上无缝的试穿效果，同时忠实地保持了高频服装细节，在重建准确性和感知真实性之间取得了有效平衡。

Conclusion: DualFit通过混合方法成功解决了虚拟试穿中细粒度细节保持的问题，为在线时尚零售提供了更好的可视化体验。

Abstract: Virtual Try-On technology has garnered significant attention for its
potential to transform the online fashion retail experience by allowing users
to visualize how garments would look on them without physical trials. While
recent advances in diffusion-based warping-free methods have improved
perceptual quality, they often fail to preserve fine-grained garment details
such as logos and printed text elements that are critical for brand integrity
and customer trust. In this work, we propose DualFit, a hybrid VTON pipeline
that addresses this limitation by two-stage approach. In the first stage,
DualFit warps the target garment to align with the person image using a learned
flow field, ensuring high-fidelity preservation. In the second stage, a
fidelity-preserving try-on module synthesizes the final output by blending the
warped garment with preserved human regions. Particularly, to guide this
process, we introduce a preserved-region input and an inpainting mask, enabling
the model to retain key areas and regenerate only where necessary, particularly
around garment seams. Extensive qualitative results show that DualFit achieves
visually seamless try-on results while faithfully maintaining high-frequency
garment details, striking an effective balance between reconstruction accuracy
and perceptual realism.

</details>


### [177] [TriQDef: Disrupting Semantic and Gradient Alignment to Prevent Adversarial Patch Transferability in Quantized Neural Networks](https://arxiv.org/abs/2508.12132)
*Amira Guesmi,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: TriQDef是一个三层次量化感知防御框架，通过特征错位惩罚、梯度感知失谐惩罚和联合量化感知训练，有效降低跨位宽补丁攻击的迁移性，在保持高准确率的同时将攻击成功率降低40%以上。


<details>
  <summary>Details</summary>
Motivation: 量化神经网络在边缘设备中部署广泛，虽然对传统像素级攻击有一定鲁棒性，但对跨位宽迁移的补丁式对抗攻击防御不足。现有方法要么过拟合特定量化设置，要么无法解决跨位宽泛化漏洞。

Method: 提出TriQDef三层次防御框架：1)特征错位惩罚(FDP)通过惩罚中间表示的感知相似性来强制语义不一致；2)梯度感知失谐惩罚(GPDP)通过边缘IoU和HOG余弦度量最小化结构方向一致性来错位梯度；3)联合量化感知训练协议在多量化级别共享权重训练中统一这些惩罚。

Result: 在CIFAR-10和ImageNet上的广泛实验表明，TriQDef在未见过的补丁和量化组合上将攻击成功率(ASR)降低超过40%，同时保持高清洁准确率。

Conclusion: 研究强调了破坏语义和感知梯度对齐对于减轻QNN中补丁迁移性的重要性，TriQDef框架有效解决了跨位宽补丁攻击的防御问题。

Abstract: Quantized Neural Networks (QNNs) are increasingly deployed in edge and
resource-constrained environments due to their efficiency in computation and
memory usage. While shown to distort the gradient landscape and weaken
conventional pixel-level attacks, it provides limited robustness against
patch-based adversarial attacks-localized, high-saliency perturbations that
remain surprisingly transferable across bit-widths. Existing defenses either
overfit to fixed quantization settings or fail to address this cross-bit
generalization vulnerability. We introduce \textbf{TriQDef}, a tri-level
quantization-aware defense framework designed to disrupt the transferability of
patch-based adversarial attacks across QNNs. TriQDef consists of: (1) a Feature
Disalignment Penalty (FDP) that enforces semantic inconsistency by penalizing
perceptual similarity in intermediate representations; (2) a Gradient
Perceptual Dissonance Penalty (GPDP) that explicitly misaligns input gradients
across bit-widths by minimizing structural and directional agreement via Edge
IoU and HOG Cosine metrics; and (3) a Joint Quantization-Aware Training
Protocol that unifies these penalties within a shared-weight training scheme
across multiple quantization levels. Extensive experiments on CIFAR-10 and
ImageNet demonstrate that TriQDef reduces Attack Success Rates (ASR) by over
40\% on unseen patch and quantization combinations, while preserving high clean
accuracy. Our findings underscore the importance of disrupting both semantic
and perceptual gradient alignment to mitigate patch transferability in QNNs.

</details>


### [178] [Infusing fine-grained visual knowledge to Vision-Language Models](https://arxiv.org/abs/2508.12137)
*Nikolaos-Antonios Ypsilantis,Kaifeng Chen,André Araujo,Ondřej Chum*

Main category: cs.CV

TL;DR: 提出一种针对视觉语言模型的微调方法，在保持预训练模型通用能力的同时优化细粒度检索性能，解决了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 大规模对比预训练的视觉语言模型在细粒度开放集视觉检索任务中表现不佳，需要领域特定微调，但传统微调会导致灾难性遗忘，丧失模型的通用视觉和跨模态能力。

Method: 受持续学习启发，系统分析标准正则化技术，提出高效的知识保留组合策略，并关注验证集设计和超参数调优以确保可复现性和泛化能力。

Result: 在细粒度和粗粒度图像-图像、图像-文本检索基准测试中取得优异结果，无需使用文本数据或原始文本编码器即可保持视觉-文本对齐。

Conclusion: 该方法成功实现了细粒度领域适应与预训练VLM广泛多模态知识保留之间的最佳平衡，为视觉语言模型的微调提供了有效解决方案。

Abstract: Large-scale contrastive pre-training produces powerful Vision-and-Language
Models (VLMs) capable of generating representations (embeddings) effective for
a wide variety of visual and multimodal tasks. However, these pretrained
embeddings remain suboptimal for fine-grained open-set visual retrieval, where
state-of-the-art results require fine-tuning the vision encoder using annotated
domain-specific samples. Naively performing such fine-tuning typically leads to
catastrophic forgetting, severely diminishing the model's general-purpose
visual and cross-modal capabilities.
  In this work, we propose a fine-tuning method explicitly designed to achieve
optimal balance between fine-grained domain adaptation and retention of the
pretrained VLM's broad multimodal knowledge. Drawing inspiration from continual
learning literature, we systematically analyze standard regularization
techniques aimed at knowledge retention and propose an efficient and effective
combination strategy. Additionally, we address the commonly overlooked yet
critical aspects of validation set design and hyperparameter tuning to ensure
reproducibility and robust generalization across datasets and pretrained
models. We extensively evaluate our method on both fine-grained and
coarse-grained image-image and image-text retrieval benchmarks. Our approach
consistently achieves strong results, notably retaining the visual-text
alignment without utilizing any text data or the original text encoder during
fine-tuning. Code and model checkpoints: https://github.com/nikosips/infusing .

</details>


### [179] [KP-INR: A Dual-Branch Implicit Neural Representation Model for Cardiac Cine MRI Reconstruction](https://arxiv.org/abs/2508.12147)
*Donghang Lyu,Marius Staring,Mariya Doneva,Hildo J. Lamb,Nicola Pezzotti*

Main category: cs.CV

TL;DR: KP-INR是一种用于心脏电影MRI重建的双分支隐式神经表示方法，通过在k空间坐标位置嵌入和局部多尺度特征表示之间进行交叉交互，实现了更好的重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有的INR方法主要关注基于坐标的位置嵌入，但忽略了目标点及其邻域上下文特征表示的重要性。为了在快速采集技术降低图像质量的情况下实现高质量的心脏电影MRI重建，需要同时利用位置信息和局部特征信息。

Method: 提出KP-INR双分支方法：一个分支处理k空间坐标的位置嵌入，另一个分支学习该坐标处的局部多尺度k空间特征表示。通过跨分支交互和从两个分支近似目标k空间值来实现重建。

Result: 在CMRxRecon2024数据集上的实验证实，KP-INR相比基线模型具有改进的性能，在挑战性的笛卡尔k空间数据上表现出色。

Conclusion: KP-INR通过同时利用位置嵌入和局部特征表示，为心脏电影MRI重建提供了有效的解决方案，在该领域显示出巨大潜力。

Abstract: Cardiac Magnetic Resonance (CMR) imaging is a non-invasive method for
assessing cardiac structure, function, and blood flow. Cine MRI extends this by
capturing heart motion, providing detailed insights into cardiac mechanics. To
reduce scan time and breath-hold discomfort, fast acquisition techniques have
been utilized at the cost of lowering image quality. Recently, Implicit Neural
Representation (INR) methods have shown promise in unsupervised reconstruction
by learning coordinate-to-value mappings from undersampled data, enabling
high-quality image recovery. However, current existing INR methods primarily
focus on using coordinate-based positional embeddings to learn the mapping,
while overlooking the feature representations of the target point and its
neighboring context. In this work, we propose KP-INR, a dual-branch INR method
operating in k-space for cardiac cine MRI reconstruction: one branch processes
the positional embedding of k-space coordinates, while the other learns from
local multi-scale k-space feature representations at those coordinates. By
enabling cross-branch interaction and approximating the target k-space values
from both branches, KP-INR can achieve strong performance on challenging
Cartesian k-space data. Experiments on the CMRxRecon2024 dataset confirms its
improved performance over baseline models and highlights its potential in this
field.

</details>


### [180] [Demystifying Foreground-Background Memorization in Diffusion Models](https://arxiv.org/abs/2508.12148)
*Jimmy Z. Di,Yiwei Lu,Yaoliang Yu,Gautam Kamath,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 提出了FB-Mem方法，通过分割技术量化扩散模型中局部记忆现象，发现记忆问题比现有认知更严重，现有缓解方法效果有限


<details>
  <summary>Details</summary>
Motivation: 当前检测方法只能识别完全复制，无法量化小区域的局部记忆和超越特定提示-图像对的记忆模式

Method: 提出基于分割的FB-Mem度量方法，对生成图像中的记忆区域进行分类和量化，并使用聚类方法进行更强缓解

Result: 发现记忆现象更普遍：单提示生成可能与多个训练图像相关；现有缓解方法无法消除局部记忆，特别是前景区域

Conclusion: 建立了有效的扩散模型记忆测量框架，证明了当前缓解方法的不足，提出了基于聚类的更强缓解方法

Abstract: Diffusion models (DMs) memorize training images and can reproduce
near-duplicates during generation. Current detection methods identify verbatim
memorization but fail to capture two critical aspects: quantifying partial
memorization occurring in small image regions, and memorization patterns beyond
specific prompt-image pairs. To address these limitations, we propose
Foreground Background Memorization (FB-Mem), a novel segmentation-based metric
that classifies and quantifies memorized regions within generated images. Our
method reveals that memorization is more pervasive than previously understood:
(1) individual generations from single prompts may be linked to clusters of
similar training images, revealing complex memorization patterns that extend
beyond one-to-one correspondences; and (2) existing model-level mitigation
methods, such as neuron deactivation and pruning, fail to eliminate local
memorization, which persists particularly in foreground regions. Our work
establishes an effective framework for measuring memorization in diffusion
models, demonstrates the inadequacy of current mitigation approaches, and
proposes a stronger mitigation method using a clustering approach.

</details>


### [181] [RealTalk: Realistic Emotion-Aware Lifelike Talking-Head Synthesis](https://arxiv.org/abs/2508.12163)
*Wenqing Wang,Yun Fu*

Main category: cs.CV

TL;DR: RealTalk是一个新颖的情感说话头生成框架，通过VAE生成3D面部标志点，结合情感标签嵌入和神经辐射场技术，实现了高情感准确性、增强的情感可控性和鲁棒的身份保持。


<details>
  <summary>Details</summary>
Motivation: 当前方法在唇部同步和图像质量方面表现出色，但在生成准确可控的情感表情同时保持主体身份方面存在不足，需要开发能够同时满足这些要求的情感说话头合成系统。

Method: 使用变分自编码器(VAE)从驱动音频生成3D面部标志点，通过ResNet-based标志点变形模型(LDM)将情感标签嵌入与标志点连接，生成情感标志点。这些标志点和面部混合形状系数共同条件化新型三平面注意力神经辐射场(NeRF)来合成高度真实的情感说话头。

Result: 大量实验证明，RealTalk在情感准确性、可控性和身份保持方面优于现有方法，推动了社交智能AI系统的发展。

Conclusion: RealTalk框架成功解决了情感说话头合成中的关键挑战，为构建更自然、情感丰富的虚拟人物交互系统提供了有效解决方案，具有重要的研究和应用价值。

Abstract: Emotion is a critical component of artificial social intelligence. However,
while current methods excel in lip synchronization and image quality, they
often fail to generate accurate and controllable emotional expressions while
preserving the subject's identity. To address this challenge, we introduce
RealTalk, a novel framework for synthesizing emotional talking heads with high
emotion accuracy, enhanced emotion controllability, and robust identity
preservation. RealTalk employs a variational autoencoder (VAE) to generate 3D
facial landmarks from driving audio, which are concatenated with emotion-label
embeddings using a ResNet-based landmark deformation model (LDM) to produce
emotional landmarks. These landmarks and facial blendshape coefficients jointly
condition a novel tri-plane attention Neural Radiance Field (NeRF) to
synthesize highly realistic emotional talking heads. Extensive experiments
demonstrate that RealTalk outperforms existing methods in emotion accuracy,
controllability, and identity preservation, advancing the development of
socially intelligent AI systems.

</details>


### [182] [Scalable RF Simulation in Generative 4D Worlds](https://arxiv.org/abs/2508.12176)
*Zhiwei Zheng,Dongyin Hu,Mingmin Zhao*

Main category: cs.CV

TL;DR: WaveVerse是一个基于提示的RF信号模拟框架，通过语言引导的4D世界生成器和相位相干射线追踪模拟器，从生成的室内场景和人体运动中模拟真实的RF信号。


<details>
  <summary>Details</summary>
Motivation: 解决在动态多样的室内环境中收集高质量RF数据的挑战，为RF感知任务提供隐私保护的替代方案。

Method: 使用语言引导的4D世界生成器（包含状态感知因果transformer用于人体运动生成）和相位相干射线追踪模拟器来模拟准确的RF信号。

Result: 实验证明了在条件人体运动生成方面的有效性，相位相干性成功应用于波束成形和呼吸监测，在RF成像和人类活动识别任务中实现了性能提升。

Conclusion: WaveVerse首次实现了RF成像的数据生成，在数据有限和数据充足的情况下都能获得一致的性能增益，为RF感知提供了有效的模拟解决方案。

Abstract: Radio Frequency (RF) sensing has emerged as a powerful, privacy-preserving
alternative to vision-based methods for indoor perception tasks. However,
collecting high-quality RF data in dynamic and diverse indoor environments
remains a major challenge. To address this, we introduce WaveVerse, a
prompt-based, scalable framework that simulates realistic RF signals from
generated indoor scenes with human motions. WaveVerse introduces a
language-guided 4D world generator, which includes a state-aware causal
transformer for human motion generation conditioned on spatial constraints and
texts, and a phase-coherent ray tracing simulator that enables the simulation
of accurate and coherent RF signals. Experiments demonstrate the effectiveness
of our approach in conditioned human motion generation and highlight how phase
coherence is applied to beamforming and respiration monitoring. We further
present two case studies in ML-based high-resolution imaging and human activity
recognition, demonstrating that WaveVerse not only enables data generation for
RF imaging for the first time, but also consistently achieves performance gain
in both data-limited and data-adequate scenarios.

</details>


### [183] [Splat Feature Solver](https://arxiv.org/abs/2508.12216)
*Butian Xiong,Rong Liu,Kenneth Xu,Meida Chen,Andrew Feng*

Main category: cs.CV

TL;DR: 提出了一种统一的、与核和特征无关的特征提升方法，通过稀疏线性逆问题求解，在凸损失下具有可证明的全局最优误差上界，并在开放词汇3D分割基准上达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 解决3D场景理解中特征提升的核心挑战：如何将丰富的图像特征描述符最优地分配给3D基元，同时处理多视图图像的不一致性问题

Method: 将特征提升问题表述为稀疏线性逆问题，可闭式求解；引入Tikhonov指导确保数值稳定性，后提升聚合通过特征聚类过滤噪声输入

Result: 在开放词汇3D分割基准上达到最先进性能，优于基于训练、分组和启发式的前向基线方法，且能在几分钟内生成提升特征

Conclusion: 该方法提供了一个理论保证的统一框架，能够高效处理多视图不一致性，为3D场景理解提供高质量的特征提升解决方案

Abstract: Feature lifting has emerged as a crucial component in 3D scene understanding,
enabling the attachment of rich image feature descriptors (e.g., DINO, CLIP)
onto splat-based 3D representations. The core challenge lies in optimally
assigning rich general attributes to 3D primitives while addressing the
inconsistency issues from multi-view images. We present a unified, kernel- and
feature-agnostic formulation of the feature lifting problem as a sparse linear
inverse problem, which can be solved efficiently in closed form. Our approach
admits a provable upper bound on the global optimal error under convex losses
for delivering high quality lifted features. To address inconsistencies and
noise in multi-view observations, we introduce two complementary regularization
strategies to stabilize the solution and enhance semantic fidelity. Tikhonov
Guidance enforces numerical stability through soft diagonal dominance, while
Post-Lifting Aggregation filters noisy inputs via feature clustering. Extensive
experiments demonstrate that our approach achieves state-of-the-art performance
on open-vocabulary 3D segmentation benchmarks, outperforming training-based,
grouping-based, and heuristic-forward baselines while producing the lifted
features in minutes. Code is available at
\href{https://github.com/saliteta/splat-distiller.git}{\textbf{github}}. We
also have a \href{https://splat-distiller.pages.dev/}

</details>


### [184] [C2PSA-Enhanced YOLOv11 Architecture: A Novel Approach for Small Target Detection in Cotton Disease Diagnosis](https://arxiv.org/abs/2508.12219)
*Kaiyuan Wang,Jixing Liu,Xiaobo Cai*

Main category: cs.CV

TL;DR: 基于YOLOv11的深度学习优化方案，通过C2PSA模块、动态类别权重和改进数据增帽技术，实现了棉花疾病高精度检测，mAP50提升8.0%，速度达158FPS，可实时监测与精准治疗。


<details>
  <summary>Details</summary>
Motivation: 解决棉花疾病检测中的三大挑战：早期病容精确度低（小于5mm²病容漏检率35%）；田间环境性能下降（准确率下降25%）；多病症场景错误率高（34.7%）。

Method: 提出C2PSA模块提升小目标特征提取能力；采用动态类别权重处理样本不平衡问题；通过Mosaic-MixUp缩放技术改进数据增帽。

Result: 在4078张图像数据集上的实验结果：mAP50达0.820（提升8.0%）；mAP50-95达0.705（提升10.5%）；推理速度158 FPS。

Conclusion: 该优化方案显著提升了棉花疾病检测的精确度和速度，移动端部署的系统能够支持农业应用中的实时疾病监测和精准治疗。

Abstract: This study presents a deep learning-based optimization of YOLOv11 for cotton
disease detection, developing an intelligent monitoring system. Three key
challenges are addressed: (1) low precision in early spot detection (35%
leakage rate for sub-5mm2 spots), (2) performance degradation in field
conditions (25% accuracy drop), and (3) high error rates (34.7%) in
multi-disease scenarios. The proposed solutions include: C2PSA module for
enhanced small-target feature extraction; Dynamic category weighting to handle
sample imbalance; Improved data augmentation via Mosaic-MixUp scaling.
Experimental results on a 4,078-image dataset show: mAP50: 0.820 (+8.0%
improvement); mAP50-95: 0.705 (+10.5% improvement); Inference speed: 158 FPS.
The mobile-deployed system enables real-time disease monitoring and precision
treatment in agricultural applications.

</details>


### [185] [In vivo 3D ultrasound computed tomography of musculoskeletal tissues with generative neural physics](https://arxiv.org/abs/2508.12226)
*Zhijun Zeng,Youjia Zheng,Chang Su,Qianhang Wu,Hao Hu,Zeyuan Dong,Shan Gao,Yang Lv,Rui Tang,Ligang Cui,Zhiyong Hou,Weijun Lin,Zuoqiang Shi,Yubing Li,He Sun*

Main category: cs.CV

TL;DR: 通过结合生成式网络与物理模拟的神经物理框架，实现了高保真度的3D超声计算机断展成像，免除了强散射影响，在10分钟内完成肌肉骨骼组织的定量成像


<details>
  <summary>Details</summary>
Motivation: 传统光线基于重建方法在肌肉骨骼成像中忽略了强散射影响，限制了超声计算机断展成像的临床应用

Method: 使用生成式神经网络结合物理信息神经模拟，从数十张跨模态图像中学习超声波传播的简化代替模型

Result: 在合成和in vivo数据（乳腺、手臂、腿部）上，近10分钟内重建了组织参数的3D地图，具有与MRI相可比的分辨率，对肌肉和骨骼的生物力学性质效感敏感

Conclusion: 该方法克服了强散射治理中的计算瓶颈，推动超声计算机断展成像向肌肉骨骼疾病的常规临床评估发展

Abstract: Ultrasound computed tomography (USCT) is a radiation-free, high-resolution
modality but remains limited for musculoskeletal imaging due to conventional
ray-based reconstructions that neglect strong scattering. We propose a
generative neural physics framework that couples generative networks with
physics-informed neural simulation for fast, high-fidelity 3D USCT. By learning
a compact surrogate of ultrasonic wave propagation from only dozens of
cross-modality images, our method merges the accuracy of wave modeling with the
efficiency and stability of deep learning. This enables accurate quantitative
imaging of in vivo musculoskeletal tissues, producing spatial maps of acoustic
properties beyond reflection-mode images. On synthetic and in vivo data
(breast, arm, leg), we reconstruct 3D maps of tissue parameters in under ten
minutes, with sensitivity to biomechanical properties in muscle and bone and
resolution comparable to MRI. By overcoming computational bottlenecks in
strongly scattering regimes, this approach advances USCT toward routine
clinical assessment of musculoskeletal disease.

</details>


### [186] [WXSOD: A Benchmark for Robust Salient Object Detection in Adverse Weather Conditions](https://arxiv.org/abs/2508.12250)
*Quan Chen,Xiong Yang,Rongfeng Lu,Qianyu Zhang,Yu Liu,Xiaofei Zhou,Bolun Zheng*

Main category: cs.CV

TL;DR: 这篇论文提出了一个新的天气噪声扩展显著物体检测数据集WXSOD和基线模型WFANet，专门处理复杂天气条件下的显著物体检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有的显著物体检测方法在复杂天气噪声环境下性能会减退，但缺乏有相应的数据集来研究这个问题。

Method: 构建了包含14,945张RGB图片的WXSOD数据集，包含合成和实际天气噪声。提出了两支流的WFANet模型，一支预测天气特征，另一支融合语义特征进行显著物体检测。

Result: 在WXSOD数据集上与17种SOD方法进行了综合比较，WFANet取得了最优的性能。

Conclusion: 这个工作为复杂天气条件下的显著物体检测提供了重要的数据集基准和有效的解决方案。

Abstract: Salient object detection (SOD) in complex environments remains a challenging
research topic. Most existing methods perform well in natural scenes with
negligible noise, and tend to leverage multi-modal information (e.g., depth and
infrared) to enhance accuracy. However, few studies are concerned with the
damage of weather noise on SOD performance due to the lack of dataset with
pixel-wise annotations. To bridge this gap, this paper introduces a novel
Weather-eXtended Salient Object Detection (WXSOD) dataset. It consists of
14,945 RGB images with diverse weather noise, along with the corresponding
ground truth annotations and weather labels. To verify algorithm
generalization, WXSOD contains two test sets, i.e., a synthesized test set and
a real test set. The former is generated by adding weather noise to clean
images, while the latter contains real-world weather noise. Based on WXSOD, we
propose an efficient baseline, termed Weather-aware Feature Aggregation Network
(WFANet), which adopts a fully supervised two-branch architecture.
Specifically, the weather prediction branch mines weather-related deep
features, while the saliency detection branch fuses semantic features extracted
from the backbone with weather features for SOD. Comprehensive comparisons
against 17 SOD methods shows that our WFANet achieves superior performance on
WXSOD. The code and benchmark results will be made publicly available at
https://github.com/C-water/WXSOD

</details>


### [187] [Superpixel-informed Continuous Low-Rank Tensor Representation for Multi-Dimensional Data Recovery](https://arxiv.org/abs/2508.12261)
*Zhizhou Wang,Ruijing Zheng,Zhenyu Wu,Jianli Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种超像素信息的连续低秩张量表示框架（SCTR），解决了传统低秩张量方法在实际应用中的两大限制：整体数据低秩假设不成立和仅限于网格数据。通过超像素单元和不对称低秩分解，该方法在多汇图像、视频等数据集上获得了3-5 dB PSNR的显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统低秩张量表示方法存在两个关键问题：(1) 假设整体数据都是低秩的，但实际场景中空间变化很大，这个假设常常不成立；(2) 仅能处理离散网格数据，灵活性和适用性受限。

Method: 提出SCTR框架，包含两个主要创新：(1) 使用超像素作为基本建模单元，因为语义一致区域具有更强的低秩特性；(2) 提出新的不对称低秩张量分解（ALTF），通过共享神经网络与专门头部来参数化超像素特徚因子矩阵，分离全局模式学习和局部适应。

Result: 在多个标准数据集上的广泛实验显示，SCTR在多谱图像、视频和色彩图像等多维数据上，比现有的基于低秩张量表示的方法提升了3-5 dB的峰值信噪比（PSNR）。

Conclusion: SCTR框架能够连续且灵活地建模多维数据，突破了传统网格限制。通过超像素单元和不对称分解策略，方法有效地结合了表达力和紧凑性，在保持模型效率的同时提升了适应性。

Abstract: Low-rank tensor representation (LRTR) has emerged as a powerful tool for
multi-dimensional data processing. However, classical LRTR-based methods face
two critical limitations: (1) they typically assume that the holistic data is
low-rank, this assumption is often violated in real-world scenarios with
significant spatial variations; and (2) they are constrained to discrete
meshgrid data, limiting their flexibility and applicability. To overcome these
limitations, we propose a Superpixel-informed Continuous low-rank Tensor
Representation (SCTR) framework, which enables continuous and flexible modeling
of multi-dimensional data beyond traditional grid-based constraints. Our
approach introduces two main innovations: First, motivated by the observation
that semantically coherent regions exhibit stronger low-rank characteristics
than holistic data, we employ superpixels as the basic modeling units. This
design not only encodes rich semantic information, but also enhances
adaptability to diverse forms of data streams. Second, we propose a novel
asymmetric low-rank tensor factorization (ALTF) where superpixel-specific
factor matrices are parameterized by a shared neural network with specialized
heads. By strategically separating global pattern learning from local
adaptation, this framework efficiently captures both cross-superpixel
commonalities and within-superpixel variations. This yields a representation
that is both highly expressive and compact, balancing model efficiency with
adaptability. Extensive experiments on several benchmark datasets demonstrate
that SCTR achieves 3-5 dB PSNR improvements over existing LRTR-based methods
across multispectral images, videos, and color images.

</details>


### [188] [Region-Level Context-Aware Multimodal Understanding](https://arxiv.org/abs/2508.12263)
*Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: 这篇论文提出了区域级上下文感知多模态理解(RCMU)能力，通过新的指令微调方法RCVIT和数据集RCMU，基于Qwen2-VL开发了RC-Qwen2-VL模型，在多个RCMU任务上取得了突出表现。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型主要关注通用视觉理解，缺乏将对象的文本上下文与视觉内容结合进行上下文感知多模态理解的能力。

Method: 提出Region-level Context-aware Visual Instruction Tuning (RCVIT)方法，将对象信息整合到模型输入中，利用边框坐标将对象的视觉内容与文本信息关联。构建了大规模RCMU数据集和RC&P-Bench评测标准。

Result: 基于Qwen2-VL模型开发的RC-Qwen2-VL模型在多个RCMU任务上表现突出，同时在多模态RAG和个性化对话中成功应用。

Conclusion: 该研究有效提升了MLLM在区域级上下文感知多模态理解方面的能力，为更精细的多模态理解提供了新的解决方案。

Abstract: Despite significant progress, existing research on Multimodal Large Language
Models (MLLMs) mainly focuses on general visual understanding, overlooking the
ability to integrate textual context associated with objects for a more
context-aware multimodal understanding -- an ability we refer to as
Region-level Context-aware Multimodal Understanding (RCMU). To address this
limitation, we first formulate the RCMU task, which requires models to respond
to user instructions by integrating both image content and textual information
of regions or objects. To equip MLLMs with RCMU capabilities, we propose
Region-level Context-aware Visual Instruction Tuning (RCVIT), which
incorporates object information into the model input and enables the model to
utilize bounding box coordinates to effectively associate objects' visual
content with their textual information. To address the lack of datasets, we
introduce the RCMU dataset, a large-scale visual instruction tuning dataset
that covers multiple RCMU tasks. We also propose RC\&P-Bench, a comprehensive
benchmark that can evaluate the performance of MLLMs in RCMU and multimodal
personalized understanding tasks. Additionally, we propose a reference-free
evaluation metric to perform a comprehensive and fine-grained evaluation of the
region-level context-aware image descriptions. By performing RCVIT on Qwen2-VL
models with the RCMU dataset, we developed RC-Qwen2-VL models. Experimental
results indicate that RC-Qwen2-VL models not only achieve outstanding
performance on multiple RCMU tasks but also demonstrate successful applications
in multimodal RAG and personalized conversation. Our data, model and benchmark
are available at https://github.com/hongliang-wei/RC-MLLM

</details>


### [189] [SNNSIR: A Simple Spiking Neural Network for Stereo Image Restoration](https://arxiv.org/abs/2508.12271)
*Ronghua Xu,Jin Xie,Jing Nie,Jiale Cao,Yanwei Pang*

Main category: cs.CV

TL;DR: 提出SNNSIR，一种完全脉冲驱动的脉冲神经网络用于立体图像恢复，通过脉冲残差基本块、立体卷积调制和立体交叉注意力模块，在保持竞争性恢复性能的同时显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络具有离散二进制激活特性，计算效率高且能耗低，适合计算密集型任务如立体图像恢复。现有混合SNN-ANN模型仍依赖浮点矩阵运算，与SNN的二进制事件驱动特性不兼容。

Method: 采用完全脉冲驱动架构，包含：1) 脉冲残差基本块(SRBB)增强信息流；2) 立体卷积调制(SSCM)模块通过元素乘法简化非线性并突出噪声敏感区域；3) 立体交叉注意力(SSCA)模块实现跨视图双向特征交互。

Result: 在多种立体图像恢复任务（雨纹去除、雨滴去除、低光增强、超分辨率）上的实验表明，模型达到竞争性恢复性能，同时显著减少计算开销。

Conclusion: 该方法展示了实时低功耗立体视觉应用的潜力，为完全脉冲驱动的立体图像恢复提供了有效解决方案。

Abstract: Spiking Neural Networks (SNNs), characterized by discrete binary activations,
offer high computational efficiency and low energy consumption, making them
well-suited for computation-intensive tasks such as stereo image restoration.
In this work, we propose SNNSIR, a simple yet effective Spiking Neural Network
for Stereo Image Restoration, specifically designed under the spike-driven
paradigm where neurons transmit information through sparse, event-based binary
spikes. In contrast to existing hybrid SNN-ANN models that still rely on
operations such as floating-point matrix division or exponentiation, which are
incompatible with the binary and event-driven nature of SNNs, our proposed
SNNSIR adopts a fully spike-driven architecture to achieve low-power and
hardware-friendly computation. To address the expressiveness limitations of
binary spiking neurons, we first introduce a lightweight Spike Residual Basic
Block (SRBB) to enhance information flow via spike-compatible residual
learning. Building on this, the Spike Stereo Convolutional Modulation (SSCM)
module introduces simplified nonlinearity through element-wise multiplication
and highlights noise-sensitive regions via cross-view-aware modulation.
Complementing this, the Spike Stereo Cross-Attention (SSCA) module further
improves stereo correspondence by enabling efficient bidirectional feature
interaction across views within a spike-compatible framework. Extensive
experiments on diverse stereo image restoration tasks, including rain streak
removal, raindrop removal, low-light enhancement, and super-resolution
demonstrate that our model achieves competitive restoration performance while
significantly reducing computational overhead. These results highlight the
potential for real-time, low-power stereo vision applications. The code will be
available after the article is accepted.

</details>


### [190] [TSLA: A Task-Specific Learning Adaptation for Semantic Segmentation on Autonomous Vehicles Platform](https://arxiv.org/abs/2508.12279)
*Jun Liu,Zhenglun Kong,Pu Zhao,Weihao Zeng,Hao Tang,Xuan Shen,Changdi Yang,Wenbin Zhang,Geng Yuan,Wei Niu,Xue Lin,Yanzhi Wang*

Main category: cs.CV

TL;DR: 提出了一种面向自动驾驶场景的动态可适应语义分割网络，通过三层控制机制和贝叶斯优化实现硬件资源约束下的模型定制化部署


<details>
  <summary>Details</summary>
Motivation: 自动驾驶平台面临多样化的驾驶场景和硬件资源限制，需要在嵌入式设备上考虑计算成本，根据硬件算力和特定场景需求定制语义分割网络

Method: 采用三层控制机制（宽度乘数、分类器深度、分类器核）实现细粒度模型组件控制，结合贝叶斯优化和代理建模在有限计算预算下高效探索超参数空间

Result: 实现了任务特定学习适应(TSLA)，能够根据不同的自动驾驶任务生成定制化配置，最大化计算容量和模型精度，优化硬件利用率

Conclusion: 该方法能够有效解决自动驾驶场景和任务特定的需求，通过自动参数搜索适应不同的计算复杂度和精度要求，为嵌入式自动驾驶平台提供了高效的模型部署方案

Abstract: Autonomous driving platforms encounter diverse driving scenarios, each with
varying hardware resources and precision requirements. Given the computational
limitations of embedded devices, it is crucial to consider computing costs when
deploying on target platforms like the NVIDIA\textsuperscript{\textregistered}
DRIVE PX 2. Our objective is to customize the semantic segmentation network
according to the computing power and specific scenarios of autonomous driving
hardware. We implement dynamic adaptability through a three-tier control
mechanism -- width multiplier, classifier depth, and classifier kernel --
allowing fine-grained control over model components based on hardware
constraints and task requirements. This adaptability facilitates broad model
scaling, targeted refinement of the final layers, and scenario-specific
optimization of kernel sizes, leading to improved resource allocation and
performance.
  Additionally, we leverage Bayesian Optimization with surrogate modeling to
efficiently explore hyperparameter spaces under tight computational budgets.
Our approach addresses scenario-specific and task-specific requirements through
automatic parameter search, accommodating the unique computational complexity
and accuracy needs of autonomous driving. It scales its Multiply-Accumulate
Operations (MACs) for Task-Specific Learning Adaptation (TSLA), resulting in
alternative configurations tailored to diverse self-driving tasks. These TSLA
customizations maximize computational capacity and model accuracy, optimizing
hardware utilization.

</details>


### [191] [CLAIR: CLIP-Aided Weakly Supervised Zero-Shot Cross-Domain Image Retrieval](https://arxiv.org/abs/2508.12290)
*Chor Boon Tan,Conghui Hu,Gim Hee Lee*

Main category: cs.CV

TL;DR: 本文提出CLAIR方法，利用CLIP大模型生成的噪声伪标签进行弱监督零样本跨域图像检索，通过置信度评分、对比学习和跨域映射来提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型基础模型能够轻松为大量未标注数据生成伪标签，无监督零样本跨域图像检索的重要性下降，因此转向研究利用CLIP等大模型生成噪声伪标签的弱监督方法。

Method: 提出CLAIR方法：1）用CLIP文本和图像特征相似度计算置信度来精炼噪声伪标签；2）设计实例间和簇间对比损失来编码类感知潜在空间；3）使用域间对比损失减少域差异；4）学习闭式跨域映射函数，仅用CLIP文本嵌入将图像特征从一个域投影到另一个域；5）引入可学习提示增强零样本泛化能力。

Result: 在TUBerlin、Sketchy、Quickdraw和DomainNet零样本数据集上的大量实验表明，CLAIR相比现有最先进方法 consistently 表现出优越性能。

Conclusion: CLAIR方法有效解决了弱监督零样本跨域图像检索问题，通过多层次的对比学习和跨域映射技术，显著提升了检索准确性和泛化能力。

Abstract: The recent growth of large foundation models that can easily generate
pseudo-labels for huge quantity of unlabeled data makes unsupervised Zero-Shot
Cross-Domain Image Retrieval (UZS-CDIR) less relevant. In this paper, we
therefore turn our attention to weakly supervised ZS-CDIR (WSZS-CDIR) with
noisy pseudo labels generated by large foundation models such as CLIP. To this
end, we propose CLAIR to refine the noisy pseudo-labels with a confidence score
from the similarity between the CLIP text and image features. Furthermore, we
design inter-instance and inter-cluster contrastive losses to encode images
into a class-aware latent space, and an inter-domain contrastive loss to
alleviate domain discrepancies. We also learn a novel cross-domain mapping
function in closed-form, using only CLIP text embeddings to project image
features from one domain to another, thereby further aligning the image
features for retrieval. Finally, we enhance the zero-shot generalization
ability of our CLAIR to handle novel categories by introducing an extra set of
learnable prompts. Extensive experiments are carried out using TUBerlin,
Sketchy, Quickdraw, and DomainNet zero-shot datasets, where our CLAIR
consistently shows superior performance compared to existing state-of-the-art
methods.

</details>


### [192] [Improving Densification in 3D Gaussian Splatting for High-Fidelity Rendering](https://arxiv.org/abs/2508.12313)
*Xiaobin Deng,Changyu Diao,Min Li,Ruohan Yu,Duanqing Xu*

Main category: cs.CV

TL;DR: 通过边缘感知得分、长轴切分策略和抑制过拟合技术，改善了3D高斯散点的密度化策略，在不增加计算开销的情况下提升了渲染质量和减少高斯元数量


<details>
  <summary>Details</summary>
Motivation: 3D高斯散点技术虽然实现了实时渲染，但其密度化策略导致重建质量不佳，需要从多个角度进行全面改进

Method: 提出边缘感知得分选择分裂候选高斯元，长轴切分策略减少几何失真，以及恢复感知剪枝、多步更新和增长控制等技术来减少过拟合

Result: 方法在不增加训练或推理开销的情况下，提升了渲染保真度，并以更少的高斯元数量达到了最高水平的性能

Conclusion: 通过从时机选择、切分方式和过拟合控制三个方面的综合改进，成功优化了3D高斯散点的密度化流程，为高效高质量的3D重建提供了有效解决方案

Abstract: Although 3D Gaussian Splatting (3DGS) has achieved impressive performance in
real-time rendering, its densification strategy often results in suboptimal
reconstruction quality. In this work, we present a comprehensive improvement to
the densification pipeline of 3DGS from three perspectives: when to densify,
how to densify, and how to mitigate overfitting. Specifically, we propose an
Edge-Aware Score to effectively select candidate Gaussians for splitting. We
further introduce a Long-Axis Split strategy that reduces geometric distortions
introduced by clone and split operations. To address overfitting, we design a
set of techniques, including Recovery-Aware Pruning, Multi-step Update, and
Growth Control. Our method enhances rendering fidelity without introducing
additional training or inference overhead, achieving state-of-the-art
performance with fewer Gaussians.

</details>


### [193] [Neural Cellular Automata for Weakly Supervised Segmentation of White Blood Cells](https://arxiv.org/abs/2508.12322)
*Michael Deutges,Chen Yang,Raheleh Salehi,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 基于神经细胞自动机的弱监督分割方法，无需分割标签即可从分类特征中提取白血球分割掩码


<details>
  <summary>Details</summary>
Motivation: 血液扫片图像中白血球检测和分割对医学诊断至关重要，但标注数据获取成本高、耗时长

Method: 提出NCA-WSS方法，利用神经细胞自动机在分类过程中生成的特征图，无需重新训练即可提取分割掩码

Result: 在三个白血球显微镜数据集上评估，NCA-WSS性能显著超过现有弱监督方法

Conclusion: 神经细胞自动机在弱监督框架下具有同时处理分类和分割任务的潜力，为医学图像分析提供可扩展高效解决方案

Abstract: The detection and segmentation of white blood cells in blood smear images is
a key step in medical diagnostics, supporting various downstream tasks such as
automated blood cell counting, morphological analysis, cell classification, and
disease diagnosis and monitoring. Training robust and accurate models requires
large amounts of labeled data, which is both time-consuming and expensive to
acquire. In this work, we propose a novel approach for weakly supervised
segmentation using neural cellular automata (NCA-WSS). By leveraging the
feature maps generated by NCA during classification, we can extract
segmentation masks without the need for retraining with segmentation labels. We
evaluate our method on three white blood cell microscopy datasets and
demonstrate that NCA-WSS significantly outperforms existing weakly supervised
approaches. Our work illustrates the potential of NCA for both classification
and segmentation in a weakly supervised framework, providing a scalable and
efficient solution for medical image analysis.

</details>


### [194] [Attention Pooling Enhances NCA-based Classification of Microscopy Images](https://arxiv.org/abs/2508.12324)
*Chen Yang,Michael Deutges,Jingsong Liu,Han Li,Nassir Navab,Carsten Marr,Ario Sadafi*

Main category: cs.CV

TL;DR: 将注意力池化机制与神经细胞自动机(NCA)结合，提升显微镜图像分类性能，在8个数据集上显著优于现有NCA方法，同时保持参数高效和可解释性


<details>
  <summary>Details</summary>
Motivation: 神经细胞自动机(NCA)为图像分类提供了稳健且可解释的方法，但在性能上与更复杂的架构存在差距，需要提升其在显微镜图像分析中的分类准确性

Method: 集成注意力池化机制到NCA中，通过注意力池化精炼对最具信息量区域的关注，增强特征提取能力

Result: 在8个不同的显微镜图像数据集上评估，显著优于现有NCA方法，与传统轻量级CNN和ViT架构相比性能更好且参数量显著更低

Conclusion: 基于NCA的模型具有作为可解释图像分类替代方案的潜力，注意力池化的集成有效提升了NCA的性能表现

Abstract: Neural Cellular Automata (NCA) offer a robust and interpretable approach to
image classification, making them a promising choice for microscopy image
analysis. However, a performance gap remains between NCA and larger, more
complex architectures. We address this challenge by integrating attention
pooling with NCA to enhance feature extraction and improve classification
accuracy. The attention pooling mechanism refines the focus on the most
informative regions, leading to more accurate predictions. We evaluate our
method on eight diverse microscopy image datasets and demonstrate that our
approach significantly outperforms existing NCA methods while remaining
parameter-efficient and explainable. Furthermore, we compare our method with
traditional lightweight convolutional neural network and vision transformer
architectures, showing improved performance while maintaining a significantly
lower parameter count. Our results highlight the potential of NCA-based models
an alternative for explainable image classification.

</details>


### [195] [DoppDrive: Doppler-Driven Temporal Aggregation for Improved Radar Object Detection](https://arxiv.org/abs/2508.12330)
*Yuval Haitman,Oded Bialer*

Main category: cs.CV

TL;DR: DoppDrive是一种基于多普勒效应的雷达点云时域聚合方法，通过径向位移补偿和动态聚合时长分配来增强点云密度并减少散射，显著提升雷达目标检测性能


<details>
  <summary>Details</summary>
Motivation: 雷达在自动驾驶中具有长距离检测优势，但远距离点云稀疏问题严重。现有时域聚合方法会引入动态物体散射，降低检测性能

Method: 提出Doppler-Driven时域聚合方法：1）根据多普勒动态分量对历史帧点云进行径向位移补偿消除径向散射；2）基于多普勒和角度为每个点分配独特聚合时长来减少切向散射

Result: DoppDrive作为检测前的点云密度增强步骤，与任何检测器兼容，在多种检测器和数据集上显著提升了目标检测性能

Conclusion: 该方法有效解决了雷达点云稀疏和散射问题，为雷达目标检测提供了通用的性能提升方案

Abstract: Radar-based object detection is essential for autonomous driving due to
radar's long detection range. However, the sparsity of radar point clouds,
especially at long range, poses challenges for accurate detection. Existing
methods increase point density through temporal aggregation with ego-motion
compensation, but this approach introduces scatter from dynamic objects,
degrading detection performance. We propose DoppDrive, a novel Doppler-Driven
temporal aggregation method that enhances radar point cloud density while
minimizing scatter. Points from previous frames are shifted radially according
to their dynamic Doppler component to eliminate radial scatter, with each point
assigned a unique aggregation duration based on its Doppler and angle to
minimize tangential scatter. DoppDrive is a point cloud density enhancement
step applied before detection, compatible with any detector, and we demonstrate
that it significantly improves object detection performance across various
detectors and datasets.

</details>


### [196] [Geometry-Aware Video Inpainting for Joint Headset Occlusion Removal and Face Reconstruction in Social XR](https://arxiv.org/abs/2508.12336)
*Fatemeh Ghorbani Lohesara,Karen Eguiazarian,Sebastian Knorr*

Main category: cs.CV

TL;DR: 通过结合GAN基于视频修复和3DMM参数回归的方法，从单视角RGB序列中去除HMD遮挡并重建完整的3D面部几何


<details>
  <summary>Details</summary>
Motivation: HMD在XR中遮挡用户面部上半部分，影响社交XR应用中面部表情和眼神交流，需要解决遮挡移除和面部重建问题

Method: 集成GAN基于视频修复网络（在密集面部关键点和参考帧指导下）和SynergyNet基于3DMM参数回归模块，通过密集关键点优化提升质量

Result: 框架能成功从RGB面部视频中去除HMD，保持面部识别和真实性，生成通真的3D面部几何输出，在不同关键点密度下都保持稳健性

Conclusion: 该方法为解决HMD遮挡问题提供了有效的解决方案，在保留面部特征的同时实现了高质量的3D重建，对提升社交XR体验具有重要意义

Abstract: Head-mounted displays (HMDs) are essential for experiencing extended reality
(XR) environments and observing virtual content. However, they obscure the
upper part of the user's face, complicating external video recording and
significantly impacting social XR applications such as teleconferencing, where
facial expressions and eye gaze details are crucial for creating an immersive
experience. This study introduces a geometry-aware learning-based framework to
jointly remove HMD occlusions and reconstruct complete 3D facial geometry from
RGB frames captured from a single viewpoint. The method integrates a GAN-based
video inpainting network, guided by dense facial landmarks and a single
occlusion-free reference frame, to restore missing facial regions while
preserving identity. Subsequently, a SynergyNet-based module regresses 3D
Morphable Model (3DMM) parameters from the inpainted frames, enabling accurate
3D face reconstruction. Dense landmark optimization is incorporated throughout
the pipeline to improve both the inpainting quality and the fidelity of the
recovered geometry. Experimental results demonstrate that the proposed
framework can successfully remove HMDs from RGB facial videos while maintaining
facial identity and realism, producing photorealistic 3D face geometry outputs.
Ablation studies further show that the framework remains robust across
different landmark densities, with only minor quality degradation under sparse
landmark configurations.

</details>


### [197] [Semantic Discrepancy-aware Detector for Image Forgery Identification](https://arxiv.org/abs/2508.12341)
*Ziye Wang,Minghang Yu,Chunyan Xu,Zhen Cui*

Main category: cs.CV

TL;DR: 基于预训练视觉语言模型的语义差异感知检测器(SDD)，通过重构学习对齐伪造和语义空间，提升图片伪造检测性能


<details>
  <summary>Details</summary>
Motivation: 图像生成技术快速发展，需要稳健的伪造检测来确保数字媒体的可信赖性。现有方法中伪造空间与语义概念空间的不匹配影响了检测性能

Method: 设计语义标志采样模块来减少无关特征导致的空间偏移，构建概念级伪造差异学习模块来强化视觉语义概念与伪造迹跡的交互，以及低级伪造特征增强模块来最小化冗余信息

Result: 在两个标准图片伪造数据集上进行实验，SDD实现了优于现有方法的结果

Conclusion: 通过重构学习对齐伪造和语义空间在细粒度视觉层面上的方法有效提升了图片伪造检测的性能

Abstract: With the rapid advancement of image generation techniques, robust forgery
detection has become increasingly imperative to ensure the trustworthiness of
digital media. Recent research indicates that the learned semantic concepts of
pre-trained models are critical for identifying fake images. However, the
misalignment between the forgery and semantic concept spaces hinders the
model's forgery detection performance. To address this problem, we propose a
novel Semantic Discrepancy-aware Detector (SDD) that leverages reconstruction
learning to align the two spaces at a fine-grained visual level. By exploiting
the conceptual knowledge embedded in the pre-trained vision language model, we
specifically design a semantic token sampling module to mitigate the space
shifts caused by features irrelevant to both forgery traces and semantic
concepts. A concept-level forgery discrepancy learning module, built upon a
visual reconstruction paradigm, is proposed to strengthen the interaction
between visual semantic concepts and forgery traces, effectively capturing
discrepancies under the concepts' guidance. Finally, the low-level forgery
feature enhancemer integrates the learned concept level forgery discrepancies
to minimize redundant forgery information. Experiments conducted on two
standard image forgery datasets demonstrate the efficacy of the proposed SDD,
which achieves superior results compared to existing methods. The code is
available at https://github.com/wzy1111111/SSD.

</details>


### [198] [AquaFeat: A Features-Based Image Enhancement Model for Underwater Object Detection](https://arxiv.org/abs/2508.12343)
*Emanuel C. Silva,Tatiana T. Schein,Stephanie L. Brião,Guilherme L. M. Costa,Felipe G. Oliveira,Gustavo P. Almeida,Eduardo L. Silva,Sam S. Devincenzi,Karina S. Machado,Paulo L. J. Drews-Jr*

Main category: cs.CV

TL;DR: AquaFeat是一个即插即用的任务驱动特征增强模块，专门针对水下目标检测任务，通过多尺度特征增强网络与检测器端到端训练，显著提升检测精度同时保持实时处理速度。


<details>
  <summary>Details</summary>
Motivation: 水下环境的严重图像退化会影响目标检测模型的性能，传统图像增强方法通常没有针对下游检测任务进行优化。

Method: 提出AquaFeat模块，集成多尺度特征增强网络，与检测器端到端训练，确保增强过程明确指导以优化与检测任务最相关的特征。

Result: 在YOLOv8m上集成AquaFeat，在挑战性水下数据集上达到最先进的精确度(0.877)和召回率(0.624)，以及竞争力的mAP分数(mAP@0.5为0.677，mAP@[0.5:0.95]为0.421)，处理速度为46.5 FPS。

Conclusion: AquaFeat提供了有效且计算高效的解决方案，适用于海洋生态系统监测和基础设施检查等实际应用。

Abstract: The severe image degradation in underwater environments impairs object
detection models, as traditional image enhancement methods are often not
optimized for such downstream tasks. To address this, we propose AquaFeat, a
novel, plug-and-play module that performs task-driven feature enhancement. Our
approach integrates a multi-scale feature enhancement network trained
end-to-end with the detector's loss function, ensuring the enhancement process
is explicitly guided to refine features most relevant to the detection task.
When integrated with YOLOv8m on challenging underwater datasets, AquaFeat
achieves state-of-the-art Precision (0.877) and Recall (0.624), along with
competitive mAP scores (mAP@0.5 of 0.677 and mAP@[0.5:0.95] of 0.421). By
delivering these accuracy gains while maintaining a practical processing speed
of 46.5 FPS, our model provides an effective and computationally efficient
solution for real-world applications, such as marine ecosystem monitoring and
infrastructure inspection.

</details>


### [199] [MBMamba: When Memory Buffer Meets Mamba for Structure-Aware Image Deblurring](https://arxiv.org/abs/2508.12346)
*Hu Gao,Depeng Dang*

Main category: cs.CV

TL;DR: 基于Mamba的图像去模糊网络MBMamba，通过内存缓冲机制保留历史信息，采用Ising受鼓励的正则化损失维护图像结构一致性，在保持原始Mamba架构的同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: Mamba架构在图像去模糊中存在局部像素遗忘和频道冗余问题，而现有改进方法通常会增加计算复杂度影响实时性能。

Method: 设计内存缓冲机制保留历史信息以建模相邻特征间关联；采用Ising受鼓励的正则化损失，模拟物理系统能量最小化过程以维护像素间相互吸引关系。

Result: 在广泛使用的测试集上，方法表现超越了现有的最先进方法。

Conclusion: MBMamba在不改变原始Mamba架构的前提下，通过内存缓冲和物理受鼓励的正则化有效解决了局部信息遗忘问题，同时保持了计算效率。

Abstract: The Mamba architecture has emerged as a promising alternative to CNNs and
Transformers for image deblurring. However, its flatten-and-scan strategy often
results in local pixel forgetting and channel redundancy, limiting its ability
to effectively aggregate 2D spatial information. Although existing methods
mitigate this by modifying the scan strategy or incorporating local feature
modules, it increase computational complexity and hinder real-time performance.
In this paper, we propose a structure-aware image deblurring network without
changing the original Mamba architecture. Specifically, we design a memory
buffer mechanism to preserve historical information for later fusion, enabling
reliable modeling of relevance between adjacent features. Additionally, we
introduce an Ising-inspired regularization loss that simulates the energy
minimization of the physical system's "mutual attraction" between pixels,
helping to maintain image structure and coherence. Building on this, we develop
MBMamba. Experimental results show that our method outperforms state-of-the-art
approaches on widely used benchmarks.

</details>


### [200] [EgoLoc: A Generalizable Solution for Temporal Interaction Localization in Egocentric Videos](https://arxiv.org/abs/2508.12349)
*Junyi Ma,Erhang Zhang,Yin-Dong Zheng,Yuchen Xie,Yixuan Zhou,Hesheng Wang*

Main category: cs.CV

TL;DR: 提出了EgoLoc方法，一种零样本的时序交互定位方法，用于在自我中心视频中精确定位手与物体接触和分离的关键时刻，无需物体掩码和动作分类标注。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注交互动作的行为范式（如何交互），但对手与目标物体接触和分离的关键时刻定位（何时交互）这一更具挑战性的细粒度问题研究不足，而这对混合现实和机器人运动规划至关重要。

Method: 提出EgoLoc方法，采用手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性、定位特定时间戳，并提供闭环反馈进行进一步优化。

Result: 在公共数据集和新基准测试上的综合实验表明，EgoLoc能够实现可信的时序交互定位，并有效促进自我中心视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc方法无需物体掩码和动词-名词分类法，实现了可推广的零样本实现，为自我中心视频中的精细时序交互定位提供了有效解决方案。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR
applications and human-robot policy transfer. Existing research has mostly
focused on modeling the behavior paradigm of interactive actions (i.e., ``how
to interact''). However, the more challenging and fine-grained problem of
capturing the critical moments of contact and separation between the hand and
the target object (i.e., ``when to interact'') is still underexplored, which is
crucial for immersive interactive experiences in mixed reality and robotic
motion planning. Therefore, we formulate this problem as temporal interaction
localization (TIL). Some recent works extract semantic masks as TIL references,
but suffer from inaccurate object grounding and cluttered scenarios. Although
current temporal action localization (TAL) methods perform well in detecting
verb-noun action segments, they rely on category annotations during training
and exhibit limited precision in localizing hand-object contact/separation
moments. To address these issues, we propose a novel zero-shot approach dubbed
EgoLoc to localize hand-object contact and separation timestamps in egocentric
videos. EgoLoc introduces hand-dynamics-guided sampling to generate
high-quality visual prompts. It exploits the vision-language model to identify
contact/separation attributes, localize specific timestamps, and provide
closed-loop feedback for further refinement. EgoLoc eliminates the need for
object masks and verb-noun taxonomies, leading to generalizable zero-shot
implementation. Comprehensive experiments on the public dataset and our novel
benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric
videos. It is also validated to effectively facilitate multiple downstream
applications in egocentric vision and robotic manipulation tasks. Code and
relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [201] [Synthetic Data is Sufficient for Zero-Shot Visual Generalization from Offline Data](https://arxiv.org/abs/2508.12356)
*Ahmet H. Güzel,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.CV

TL;DR: 通过生成合成训练数据来改善视觉基于离线强化学习的端到端普适性，包括数据增帆和潜空间激光模型生成数据


<details>
  <summary>Details</summary>
Motivation: 离线RL策略因训练数据中状态多样性不足而普适性差，特别是处理视觉数据时容易受到噪声、干扰和偏相关系的影响

Method: 两步过程：首先对原始离线数据进行增帆提升多样性，然后使用激光模型在潜空间生成额外的合成训练数据

Result: 在连续动作空间(Visual D4RL)和离散动作空间(Procgen)上都显著提升了普适性，减小了测试时的普适差距，同时保持计算效率

Conclusion: 该方法不需改变现有离线RL算法即可提升普适性，为通过生成合成数据训练更普适的机器人提供了有前晨的方向

Abstract: Offline reinforcement learning (RL) offers a promising framework for training
agents using pre-collected datasets without the need for further environment
interaction. However, policies trained on offline data often struggle to
generalise due to limited exposure to diverse states. The complexity of visual
data introduces additional challenges such as noise, distractions, and spurious
correlations, which can misguide the policy and increase the risk of
overfitting if the training data is not sufficiently diverse. Indeed, this
makes it challenging to leverage vision-based offline data in training robust
agents that can generalize to unseen environments. To solve this problem, we
propose a simple approach generating additional synthetic training data. We
propose a two-step process, first augmenting the originally collected offline
data to improve zero-shot generalization by introducing diversity, then using a
diffusion model to generate additional data in latent space. We test our method
across both continuous action spaces (Visual D4RL) and discrete action spaces
(Procgen), demonstrating that it significantly improves generalization without
requiring any algorithmic changes to existing model-free offline RL methods. We
show that our method not only increases the diversity of the training data but
also significantly reduces the generalization gap at test time while
maintaining computational efficiency. We believe this approach could fuel
additional progress in generating synthetic data to train more general agents
in the future.

</details>


### [202] [IPGPhormer: Interpretable Pathology Graph-Transformer for Survival Analysis](https://arxiv.org/abs/2508.12381)
*Guo Tang,Songhan Jiang,Jinpeng Lu,Linghan Cai,Yongbing Zhang*

Main category: cs.CV

TL;DR: IPGPhormer是一个用于病理图像生存分析的可解释图-Transformer框架，能够同时捕获肿瘤微环境特征和空间依赖关系，在预测准确性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡长距离空间关系建模与局部上下文依赖性方面存在困难，且缺乏内在可解释性，限制了临床实用性。

Method: 提出Interpretable Pathology Graph-Transformer (IPGPhormer)框架，通过图神经网络和Transformer的结合，在组织和细胞层面提供可解释性，无需后处理人工标注。

Result: 在四个公共基准数据集上的综合评估表明，IPGPhormer在预测准确性和可解释性方面均优于最先进方法。

Conclusion: IPGPhormer为癌症预后评估提供了一个有前景的工具，为病理学中更可靠和可解释的决策支持系统铺平了道路。

Abstract: Pathological images play an essential role in cancer prognosis, while
survival analysis, which integrates computational techniques, can predict
critical clinical events such as patient mortality or disease recurrence from
whole-slide images (WSIs). Recent advancements in multiple instance learning
have significantly improved the efficiency of survival analysis. However,
existing methods often struggle to balance the modeling of long-range spatial
relationships with local contextual dependencies and typically lack inherent
interpretability, limiting their clinical utility. To address these challenges,
we propose the Interpretable Pathology Graph-Transformer (IPGPhormer), a novel
framework that captures the characteristics of the tumor microenvironment and
models their spatial dependencies across the tissue. IPGPhormer uniquely
provides interpretability at both tissue and cellular levels without requiring
post-hoc manual annotations, enabling detailed analyses of individual WSIs and
cross-cohort assessments. Comprehensive evaluations on four public benchmark
datasets demonstrate that IPGPhormer outperforms state-of-the-art methods in
both predictive accuracy and interpretability. In summary, our method,
IPGPhormer, offers a promising tool for cancer prognosis assessment, paving the
way for more reliable and interpretable decision-support systems in pathology.
The code is publicly available at
https://anonymous.4open.science/r/IPGPhormer-6EEB.

</details>


### [203] [ViT-EnsembleAttack: Augmenting Ensemble Models for Stronger Adversarial Transferability in Vision Transformers](https://arxiv.org/abs/2508.12384)
*Hanwen Cao,Haobo Lu,Xiaosen Wang,Kun He*

Main category: cs.CV

TL;DR: 提出ViT-EnsembleAttack方法，通过对ViT模型进行对抗性增强来提升集成攻击的迁移性，包括多头丢弃、注意力分数缩放和MLP特征混合三种策略，并使用贝叶斯优化优化参数。


<details>
  <summary>Details</summary>
Motivation: 现有集成攻击方法主要关注优化集成权重或路径，忽视了通过增强集成模型本身来提升对抗迁移性。同时ViT模型的集成攻击研究较少。

Method: 对每个ViT代理模型采用三种对抗增强策略：多头丢弃、注意力分数缩放和MLP特征混合，使用贝叶斯优化参数，并引入自动重加权和步长放大模块。

Result: 实验表明ViT-EnsembleAttack显著提升了ViT集成攻击的对抗迁移性，大幅优于现有方法。

Conclusion: 通过对抗性增强集成模型可以有效提升对抗攻击的迁移性，特别是在ViT模型上取得了显著效果。

Abstract: Ensemble-based attacks have been proven to be effective in enhancing
adversarial transferability by aggregating the outputs of models with various
architectures. However, existing research primarily focuses on refining
ensemble weights or optimizing the ensemble path, overlooking the exploration
of ensemble models to enhance the transferability of adversarial attacks. To
address this gap, we propose applying adversarial augmentation to the surrogate
models, aiming to boost overall generalization of ensemble models and reduce
the risk of adversarial overfitting. Meanwhile, observing that ensemble Vision
Transformers (ViTs) gain less attention, we propose ViT-EnsembleAttack based on
the idea of model adversarial augmentation, the first ensemble-based attack
method tailored for ViTs to the best of our knowledge. Our approach generates
augmented models for each surrogate ViT using three strategies: Multi-head
dropping, Attention score scaling, and MLP feature mixing, with the associated
parameters optimized by Bayesian optimization. These adversarially augmented
models are ensembled to generate adversarial examples. Furthermore, we
introduce Automatic Reweighting and Step Size Enlargement modules to boost
transferability. Extensive experiments demonstrate that ViT-EnsembleAttack
significantly enhances the adversarial transferability of ensemble-based
attacks on ViTs, outperforming existing methods by a substantial margin. Code
is available at https://github.com/Trustworthy-AI-Group/TransferAttack.

</details>


### [204] [DeCoT: Decomposing Complex Instructions for Enhanced Text-to-Image Generation with Large Language Models](https://arxiv.org/abs/2508.12396)
*Xiaochuan Lin,Xiangyong Chen,Xuan Li,Yichen Su*

Main category: cs.CV

TL;DR: DeCoT是一个通过大语言模型分解复杂文本指令来提升文本到图像生成质量的新框架，在LongBench-T2I基准测试中显著改善了现有模型的性能


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像模型在处理复杂长文本指令时存在困难，经常无法准确渲染细节、空间关系和特定约束，LongBench-T2I基准测试揭示了在组合性、特定文本和精细纹理方面的缺陷

Method: DeCoT框架包含两个核心阶段：1）复杂指令分解和语义增强，使用LLM将原始指令分解为结构化语义单元并澄清歧义；2）多阶段提示集成和自适应生成，将这些单元转换为分层或优化的单一提示，适配现有T2I模型

Result: 在LongBench-T2I数据集上的实验显示，DeCoT显著提升了领先T2I模型在所有评估维度上的性能，特别是在"文本"和"组合"等挑战性方面。与Infinity-8B集成时平均得分达到3.52，优于基线模型的3.44。人工评估也证实了感知质量和指令忠实度的提升

Conclusion: DeCoT有效弥合了高级用户意图与T2I模型需求之间的差距，实现了更忠实和准确的图像生成，每个组件都发挥了关键作用，复杂的LLM提示策略至关重要

Abstract: Despite remarkable advancements, current Text-to-Image (T2I) models struggle
with complex, long-form textual instructions, frequently failing to accurately
render intricate details, spatial relationships, or specific constraints. This
limitation is highlighted by benchmarks such as LongBench-T2I, which reveal
deficiencies in handling composition, specific text, and fine textures. To
address this, we propose DeCoT (Decomposition-CoT), a novel framework that
leverages Large Language Models (LLMs) to significantly enhance T2I models'
understanding and execution of complex instructions. DeCoT operates in two core
stages: first, Complex Instruction Decomposition and Semantic Enhancement,
where an LLM breaks down raw instructions into structured, actionable semantic
units and clarifies ambiguities; second, Multi-Stage Prompt Integration and
Adaptive Generation, which transforms these units into a hierarchical or
optimized single prompt tailored for existing T2I models. Extensive experiments
on the LongBench-T2I dataset demonstrate that DeCoT consistently and
substantially improves the performance of leading T2I models across all
evaluated dimensions, particularly in challenging aspects like "Text" and
"Composition". Quantitative results, validated by multiple MLLM evaluators
(Gemini-2.0-Flash and InternVL3-78B), show that DeCoT, when integrated with
Infinity-8B, achieves an average score of 3.52, outperforming the baseline
Infinity-8B (3.44). Ablation studies confirm the critical contribution of each
DeCoT component and the importance of sophisticated LLM prompting. Furthermore,
human evaluations corroborate these findings, indicating superior perceptual
quality and instruction fidelity. DeCoT effectively bridges the gap between
high-level user intent and T2I model requirements, leading to more faithful and
accurate image generation.

</details>


### [205] [Federated Cross-Modal Style-Aware Prompt Generation](https://arxiv.org/abs/2508.12399)
*Suraj Prasad,Navyansh Mahla,Sunny Gupta,Amit Sethi*

Main category: cs.CV

TL;DR: FedCSAP是一个联邦学习框架，利用CLIP的多尺度视觉特征和客户端特定风格统计信息来生成更鲁棒的提示词，在多个图像分类数据集上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统方法仅使用最终层特征，无法充分利用多尺度视觉线索和客户端数据的领域特定风格变化，限制了联邦学习中提示学习的性能

Method: 从CLIP视觉编码器提取低、中、高三个层次的特征，结合客户端批处理统计信息生成风格感知提示词，通过联邦学习框架进行本地训练和全局聚合

Result: 在多个图像分类数据集上，FedCSAP在准确性和泛化能力方面均优于现有的联邦提示学习方法

Conclusion: FedCSAP通过整合多尺度视觉特征和客户端风格信息，有效提升了联邦提示学习的性能，能够更好地处理非独立同分布数据和领域风格变化

Abstract: Prompt learning has propelled vision-language models like CLIP to excel in
diverse tasks, making them ideal for federated learning due to computational
efficiency. However, conventional approaches that rely solely on final-layer
features miss out on rich multi-scale visual cues and domain-specific style
variations in decentralized client data. To bridge this gap, we introduce
FedCSAP (Federated Cross-Modal Style-Aware Prompt Generation). Our framework
harnesses low, mid, and high-level features from CLIP's vision encoder
alongside client-specific style indicators derived from batch-level statistics.
By merging intricate visual details with textual context, FedCSAP produces
robust, context-aware prompt tokens that are both distinct and non-redundant,
thereby boosting generalization across seen and unseen classes. Operating
within a federated learning paradigm, our approach ensures data privacy through
local training and global aggregation, adeptly handling non-IID class
distributions and diverse domain-specific styles. Comprehensive experiments on
multiple image classification datasets confirm that FedCSAP outperforms
existing federated prompt learning methods in both accuracy and overall
generalization.

</details>


### [206] [MPCAR: Multi-Perspective Contextual Augmentation for Enhanced Visual Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2508.12400)
*Amirul Rahman,Qiang Xu,Xueying Huang*

Main category: cs.CV

TL;DR: MPCAR是一种无需微调的推理时策略，通过多角度生成描述来增强视觉语言模型的上下文理解，在复杂视觉推理任务中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在需要深度上下文理解、多角度分析或细节识别的复杂视觉推理任务中表现有限，主要受限于单次图像编码和提示的局限性

Method: 三阶段方法：1）从不同角度生成N个多样化的描述或初步推理路径；2）智能整合这些描述与原问题构建上下文增强提示；3）使用增强提示指导最终深度推理和答案生成

Result: 在GQA、VQA-CP v2和ScienceQA等挑战性VQA数据集上 consistently超越基线方法，定量结果显示准确率显著提升，特别是在需要强上下文理解的任务上

Conclusion: 通过利用LVLM固有的生成能力来丰富输入上下文，可以有效释放其在复杂多模态任务中的潜在推理潜力，无需修改模型参数

Abstract: Despite significant advancements, Large Vision-Language Models (LVLMs)
continue to face challenges in complex visual reasoning tasks that demand deep
contextual understanding, multi-angle analysis, or meticulous detail
recognition. Existing approaches often rely on single-shot image encoding and
prompts, limiting their ability to fully capture nuanced visual information.
Inspired by the notion that strategically generated "additional" information
can serve as beneficial contextual augmentation, we propose Multi-Perspective
Contextual Augmentation for Reasoning (MPCAR), a novel inference-time strategy
designed to enhance LVLM performance. MPCAR operates in three stages: first, an
LVLM generates N diverse and complementary descriptions or preliminary
reasoning paths from various angles; second, these descriptions are
intelligently integrated with the original question to construct a
comprehensive context-augmented prompt; and finally, this enriched prompt
guides the ultimate LVLM for deep reasoning and final answer generation.
Crucially, MPCAR achieves these enhancements without requiring any fine-tuning
of the underlying LVLM's parameters. Extensive experiments on challenging
Visual Question Answering (VQA) datasets, including GQA, VQA-CP v2, and
ScienceQA (Image-VQA), demonstrate that MPCAR consistently outperforms
established baseline methods. Our quantitative results show significant
accuracy gains, particularly on tasks requiring robust contextual
understanding, while human evaluations confirm improved coherence and
completeness of the generated answers. Ablation studies further highlight the
importance of diverse prompt templates and the number of generated
perspectives. This work underscores the efficacy of leveraging LVLMs' inherent
generative capabilities to enrich input contexts, thereby unlocking their
latent reasoning potential for complex multimodal tasks.

</details>


### [207] [LMAD: Integrated End-to-End Vision-Language Model for Explainable Autonomous Driving](https://arxiv.org/abs/2508.12404)
*Nan Song,Bozhou Zhang,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: LMAD是一个针对自动驾驶场景设计的视觉语言框架，通过引入初步场景交互和专家适配器，显著提升了现有VLM在驾驶推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM方法主要基于多视角图像和场景推理文本进行微调，但在复杂自动驾驶场景中缺乏整体细致的场景识别能力和强大的空间感知能力。

Method: 提出LMAD框架，模拟现代端到端驾驶范式，结合全面场景理解和任务专用结构，引入初步场景交互和专家适配器，更好地将VLM与自动驾驶场景对齐。

Result: 在DriveLM和nuScenes-QA数据集上的大量实验表明，LMAD显著提升了现有VLM在驾驶推理任务上的性能。

Conclusion: LMAD为可解释自动驾驶设立了新标准，完全兼容现有VLM并可与规划导向的驾驶系统无缝集成。

Abstract: Large vision-language models (VLMs) have shown promising capabilities in
scene understanding, enhancing the explainability of driving behaviors and
interactivity with users. Existing methods primarily fine-tune VLMs on on-board
multi-view images and scene reasoning text, but this approach often lacks the
holistic and nuanced scene recognition and powerful spatial awareness required
for autonomous driving, especially in complex situations. To address this gap,
we propose a novel vision-language framework tailored for autonomous driving,
called LMAD. Our framework emulates modern end-to-end driving paradigms by
incorporating comprehensive scene understanding and a task-specialized
structure with VLMs. In particular, we introduce preliminary scene interaction
and specialized expert adapters within the same driving task structure, which
better align VLMs with autonomous driving scenarios. Furthermore, our approach
is designed to be fully compatible with existing VLMs while seamlessly
integrating with planning-oriented driving systems. Extensive experiments on
the DriveLM and nuScenes-QA datasets demonstrate that LMAD significantly boosts
the performance of existing VLMs on driving reasoning tasks,setting a new
standard in explainable autonomous driving.

</details>


### [208] [S5: Scalable Semi-Supervised Semantic Segmentation in Remote Sensing](https://arxiv.org/abs/2508.12409)
*Liang Lv,Di Wang,Jing Zhang,Lefei Zhang*

Main category: cs.CV

TL;DR: 使用半监督学习扩展遥感语义分割的可扩展性，通过大规模数据集和基础模型预训练提升性能


<details>
  <summary>Details</summary>
Motivation: 解决现有半监督语义分割方法依赖小规模数据集和模型的限制，充分利用大量未标注地球观测数据

Method: 提出S5可扩展框架，包括数据选择策略（基于熵的过滤和多样性扩展）构建RS4P-1M数据集，预训练不同规模的遥感基础模型，以及使用混合专家系统的多数据集精调方法

Result: 在土地覆盖分割和目标检测任务上获得显著性能提升，在所有测试集上达到最优性能

Conclusion: 证明了通过扩展半监督学习来提升遥感应用的可行性，为遥感分析领域提供了可扩展的解决方案

Abstract: Semi-supervised semantic segmentation (S4) has advanced remote sensing (RS)
analysis by leveraging unlabeled data through pseudo-labeling and consistency
learning. However, existing S4 studies often rely on small-scale datasets and
models, limiting their practical applicability. To address this, we propose S5,
the first scalable framework for semi-supervised semantic segmentation in RS,
which unlocks the potential of vast unlabeled Earth observation data typically
underutilized due to costly pixel-level annotations. Built upon existing
large-scale RS datasets, S5 introduces a data selection strategy that
integrates entropy-based filtering and diversity expansion, resulting in the
RS4P-1M dataset. Using this dataset, we systematically scales S4 methods by
pre-training RS foundation models (RSFMs) of varying sizes on this extensive
corpus, significantly boosting their performance on land cover segmentation and
object detection tasks. Furthermore, during fine-tuning, we incorporate a
Mixture-of-Experts (MoE)-based multi-dataset fine-tuning approach, which
enables efficient adaptation to multiple RS benchmarks with fewer parameters.
This approach improves the generalization and versatility of RSFMs across
diverse RS benchmarks. The resulting RSFMs achieve state-of-the-art performance
across all benchmarks, underscoring the viability of scaling semi-supervised
learning for RS applications. All datasets, code, and models will be released
at https://github.com/MiliLab/S5

</details>


### [209] [SRMA-Mamba: Spatial Reverse Mamba Attention Network for Pathological Liver Segmentation in MRI Volumes](https://arxiv.org/abs/2508.12410)
*Jun Zeng,Yannan Huang,Elif Keles,Halil Ertugrul Aktas,Gorkem Durak,Nikhil Kumar Tomar,Quoc-Huy Trinh,Deepak Ranjan Nayak,Ulas Bagci,Debesh Jha*

Main category: cs.CV

TL;DR: 提出了SRMA-Mamba网络，通过整合空间解剖Mamba模块和空间反向注意力模块，在3D MRI数据中实现肝硬化病理结构的高效分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 肝硬化早期检测对降低死亡率至关重要，但现有方法未能充分利用MRI体积数据中的空间解剖细节，限制了临床效果和可解释性。

Method: SRMA-Mamba网络包含SABMamba模块（在肝硬化组织内进行选择性Mamba扫描，结合三平面解剖信息构建全局空间上下文）和SRMA模块（利用粗分割图和分层编码特征逐步细化肝硬化细节）。

Result: 大量实验表明SRMA-Mamba在3D病理肝脏分割方面超越了最先进方法，表现出卓越性能。

Conclusion: 该方法通过有效建模MRI体积中的空间解剖关系，为肝硬化病变的准确检测和表征提供了有效的解决方案。

Abstract: Liver Cirrhosis plays a critical role in the prognosis of chronic liver
disease. Early detection and timely intervention are critical in significantly
reducing mortality rates. However, the intricate anatomical architecture and
diverse pathological changes of liver tissue complicate the accurate detection
and characterization of lesions in clinical settings. Existing methods
underutilize the spatial anatomical details in volumetric MRI data, thereby
hindering their clinical effectiveness and explainability. To address this
challenge, we introduce a novel Mamba-based network, SRMA-Mamba, designed to
model the spatial relationships within the complex anatomical structures of MRI
volumes. By integrating the Spatial Anatomy-Based Mamba module (SABMamba),
SRMA-Mamba performs selective Mamba scans within liver cirrhotic tissues and
combines anatomical information from the sagittal, coronal, and axial planes to
construct a global spatial context representation, enabling efficient
volumetric segmentation of pathological liver structures. Furthermore, we
introduce the Spatial Reverse Attention module (SRMA), designed to
progressively refine cirrhotic details in the segmentation map, utilizing both
the coarse segmentation map and hierarchical encoding features. Extensive
experiments demonstrate that SRMA-Mamba surpasses state-of-the-art methods,
delivering exceptional performance in 3D pathological liver segmentation. Our
code is available for public:
{\color{blue}{https://github.com/JunZengz/SRMA-Mamba}}.

</details>


### [210] [TiP4GEN: Text to Immersive Panorama 4D Scene Generation](https://arxiv.org/abs/2508.12415)
*Ke Xing,Hanwen Liang,Dejia Xu,Yuyang Yin,Konstantinos N. Plataniotis,Yao Zhao,Yunchao Wei*

Main category: cs.CV

TL;DR: TiP4GEN是一个文本到动态全景场景生成的先进框架，通过整合全景视频生成和动态场景重建技术，能够创建360度沉浸式虚拟环境，解决了现有方法在动态全景生成方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着VR/AR技术的快速发展，对高质量沉浸式动态场景的需求日益增长。现有生成工作主要集中于静态场景或窄视角动态场景，无法提供真正360度任意视角的沉浸式体验。

Method: 提出双分支生成模型（全景分支和透视分支）进行全局和局部视图生成，使用双向交叉注意力机制进行信息交换；基于3D高斯泼溅的几何对齐重建模型，通过度量深度图对齐时空点云，使用估计位姿初始化场景相机。

Result: 大量实验证明了所提出设计的有效性，TiP4GEN在生成视觉吸引人且运动连贯的动态全景场景方面表现出优越性。

Conclusion: TiP4GEN框架成功实现了细粒度内容控制和运动丰富的几何一致全景4D场景生成，为创建真正沉浸式的360度虚拟环境提供了有效解决方案。

Abstract: With the rapid advancement and widespread adoption of VR/AR technologies,
there is a growing demand for the creation of high-quality, immersive dynamic
scenes. However, existing generation works predominantly concentrate on the
creation of static scenes or narrow perspective-view dynamic scenes, falling
short of delivering a truly 360-degree immersive experience from any viewpoint.
In this paper, we introduce \textbf{TiP4GEN}, an advanced text-to-dynamic
panorama scene generation framework that enables fine-grained content control
and synthesizes motion-rich, geometry-consistent panoramic 4D scenes. TiP4GEN
integrates panorama video generation and dynamic scene reconstruction to create
360-degree immersive virtual environments. For video generation, we introduce a
\textbf{Dual-branch Generation Model} consisting of a panorama branch and a
perspective branch, responsible for global and local view generation,
respectively. A bidirectional cross-attention mechanism facilitates
comprehensive information exchange between the branches. For scene
reconstruction, we propose a \textbf{Geometry-aligned Reconstruction Model}
based on 3D Gaussian Splatting. By aligning spatial-temporal point clouds using
metric depth maps and initializing scene cameras with estimated poses, our
method ensures geometric consistency and temporal coherence for the
reconstructed scenes. Extensive experiments demonstrate the effectiveness of
our proposed designs and the superiority of TiP4GEN in generating visually
compelling and motion-coherent dynamic panoramic scenes. Our project page is at
https://ke-xing.github.io/TiP4GEN/.

</details>


### [211] [Illusions in Humans and AI: How Visual Perception Aligns and Diverges](https://arxiv.org/abs/2508.12422)
*Jianyi Yang,Junyi Ye,Ankan Dash,Guiling Wang*

Main category: cs.CV

TL;DR: 通过对比生物视觉与人工智能视觉系统在视觉幻觉上的差异，揭示了AI视觉的特有弱点和异常觉知，为开发更健壮、可解释的AI视觉系统提供指导


<details>
  <summary>Details</summary>
Motivation: 理解人工智能视觉系统与人类视觉在构建视觉现实方面的根本差异，以开发更健壮、可解释且与人类对齐的AI视觉系统

Method: 通过系统性对比人类和AI对经典视觉幻觉（颜色、大小、形状、运动）的响应，分析AI模型的幻觉效应生成机制

Result: 发现AI会产生某些类似人类的幻觉效应，同时也存在像像素级敏感性、幻觉生成等AI特有的幻觉，揭示了人工智能视觉系统的觉知弱点

Conclusion: 通过视觉幻觉研究可以提供重要见解，帮助开发保持人类有益觉知偏见的同时避免破坏信任和安全的视觉系统

Abstract: By comparing biological and artificial perception through the lens of
illusions, we highlight critical differences in how each system constructs
visual reality. Understanding these divergences can inform the development of
more robust, interpretable, and human-aligned artificial intelligence (AI)
vision systems. In particular, visual illusions expose how human perception is
based on contextual assumptions rather than raw sensory data. As artificial
vision systems increasingly perform human-like tasks, it is important to ask:
does AI experience illusions, too? Does it have unique illusions? This article
explores how AI responds to classic visual illusions that involve color, size,
shape, and motion. We find that some illusion-like effects can emerge in these
models, either through targeted training or as by-products of pattern
recognition. In contrast, we also identify illusions unique to AI, such as
pixel-level sensitivity and hallucinations, that lack human counterparts. By
systematically comparing human and AI responses to visual illusions, we uncover
alignment gaps and AI-specific perceptual vulnerabilities invisible to human
perception. These findings provide insights for future research on vision
systems that preserve human-beneficial perceptual biases while avoiding
distortions that undermine trust and safety.

</details>


### [212] [Adversarial Attacks on VQA-NLE: Exposing and Alleviating Inconsistencies in Visual Question Answering Explanations](https://arxiv.org/abs/2508.12430)
*Yahsin Yeh,Yilun Wu,Bokai Ruan,Honghan Shuai*

Main category: cs.CV

TL;DR: 这篇论文提出了VQA-NLE系统的解释不一致性问题，通过问题和图像对抗攻击更现强调这些漏洞，并使用外部知识来提高模型稳健性。


<details>
  <summary>Details</summary>
Motivation: 现有VQA-NLE系统存在解释不一致和缺乏真正理解的问题，需要更好地曝露这些漏洞并提出解决方案。

Method: 利用现有对抗策略扰动问题，并提出新的图像最小改变策略来导致矛盾输出，同时使用外部知识来缓解不一致性。

Result: 在两个标准测试集和两个广泛使用的VQA-NLE模型上的评估证明了攻击的有效性和知识基防御的潜力。

Conclusion: 当前VQA-NLE系统存在严重的安全性和可靠性问题，需要重视这些漏洞并发展更稳健的解决方案。

Abstract: Natural language explanations in visual question answering (VQA-NLE) aim to
make black-box models more transparent by elucidating their decision-making
processes. However, we find that existing VQA-NLE systems can produce
inconsistent explanations and reach conclusions without genuinely understanding
the underlying context, exposing weaknesses in either their inference pipeline
or explanation-generation mechanism. To highlight these vulnerabilities, we not
only leverage an existing adversarial strategy to perturb questions but also
propose a novel strategy that minimally alters images to induce contradictory
or spurious outputs. We further introduce a mitigation method that leverages
external knowledge to alleviate these inconsistencies, thereby bolstering model
robustness. Extensive evaluations on two standard benchmarks and two widely
used VQA-NLE models underscore the effectiveness of our attacks and the
potential of knowledge-based defenses, ultimately revealing pressing security
and reliability concerns in current VQA-NLE systems.

</details>


### [213] [X-Ray-CoT: Interpretable Chest X-ray Diagnosis with Vision-Language Models via Chain-of-Thought Reasoning](https://arxiv.org/abs/2508.12455)
*Chee Ng,Liliang Sun,Shaoqing Tang*

Main category: cs.CV

TL;DR: X-Ray-CoT是一个基于视觉语言大模型的新型框架，通过模拟放射科医生的思维链过程，实现胸部X光片的智能诊断和可解释报告生成。


<details>
  <summary>Details</summary>
Motivation: 胸部X光影像诊断需要丰富临床经验且存在观察者间差异，深度学习模型虽然准确但缺乏可解释性，阻碍了在医疗高风险环境中的临床应用。

Method: 提出X-Ray-CoT框架，首先提取多模态特征和视觉概念，然后使用基于LLM的组件配合结构化思维链提示策略进行推理，生成详细自然语言诊断报告。

Result: 在CORDA数据集上评估，疾病诊断的平衡准确率达到80.52%，F1分数78.65%，略优于现有黑盒模型，并能生成高质量可解释报告。

Conclusion: 该研究代表了医学影像领域向可信赖和临床可操作AI系统迈出的重要一步，消融研究证实了多模态融合和思维链推理对稳健透明医疗AI的必要性。

Abstract: Chest X-ray imaging is crucial for diagnosing pulmonary and cardiac diseases,
yet its interpretation demands extensive clinical experience and suffers from
inter-observer variability. While deep learning models offer high diagnostic
accuracy, their black-box nature hinders clinical adoption in high-stakes
medical settings. To address this, we propose X-Ray-CoT (Chest X-Ray
Chain-of-Thought), a novel framework leveraging Vision-Language Large Models
(LVLMs) for intelligent chest X-ray diagnosis and interpretable report
generation. X-Ray-CoT simulates human radiologists' "chain-of-thought" by first
extracting multi-modal features and visual concepts, then employing an
LLM-based component with a structured Chain-of-Thought prompting strategy to
reason and produce detailed natural language diagnostic reports. Evaluated on
the CORDA dataset, X-Ray-CoT achieves competitive quantitative performance,
with a Balanced Accuracy of 80.52% and F1 score of 78.65% for disease
diagnosis, slightly surpassing existing black-box models. Crucially, it
uniquely generates high-quality, explainable reports, as validated by
preliminary human evaluations. Our ablation studies confirm the integral role
of each proposed component, highlighting the necessity of multi-modal fusion
and CoT reasoning for robust and transparent medical AI. This work represents a
significant step towards trustworthy and clinically actionable AI systems in
medical imaging.

</details>


### [214] [Inverse-LLaVA: Eliminating Alignment Pre-training Through Text-to-Vision Mapping](https://arxiv.org/abs/2508.12466)
*Xuhui Zhan,Tyler Derr*

Main category: cs.CV

TL;DR: Inverse-LLaVA是一种新颖的多模态学习方法，无需对齐预训练，将文本嵌入映射到视觉表示空间进行融合，在推理任务上表现优异，计算需求减少45%


<details>
  <summary>Details</summary>
Motivation: 挑战传统多模态学习需要昂贵对齐预训练的范式，探索无需对齐预训练的新方法，减少计算需求并保持模态特定特征

Method: 提出Inverse-LLaVA方法，将文本嵌入映射到连续视觉表示空间，在transformer中间层进行融合，通过注意力机制中的选择性加性组件实现动态集成

Result: 在9个多模态基准测试中显示细微性能权衡：推理和认知任务显著提升（MM-VET: +0.2%, VizWiz: +1.8%, ScienceQA: +0.2%, 认知推理: +27.2%），但感知任务有所下降（名人识别: -49.5%, OCR: -21.3%）

Conclusion: 首次实证证明对齐预训练对有效多模态学习并非必要，特别是复杂推理任务；建立新范式可行性，计算需求减少45%，挑战传统模态融合观念，为高效多模态架构开辟新方向

Abstract: Traditional multimodal learning approaches require expensive alignment
pre-training to bridge vision and language modalities, typically projecting
visual features into discrete text token spaces. We challenge both fundamental
assumptions underlying this paradigm by proposing Inverse-LLaVA, a novel
approach that eliminates alignment pre-training entirely while inverting the
conventional mapping direction. Rather than projecting visual features to text
space, our method maps text embeddings into continuous visual representation
space and performs fusion within transformer intermediate layers. Through
selective additive components in attention mechanisms, we enable dynamic
integration of visual and textual representations without requiring massive
image-text alignment datasets. Comprehensive experiments across nine multimodal
benchmarks demonstrate nuanced performance trade-offs: Inverse-LLaVA achieves
notable improvements on reasoning-intensive and cognitive tasks (MM-VET: +0.2%,
VizWiz: +1.8%, ScienceQA: +0.2%, cognitive reasoning: +27.2%), while showing
expected decreases in perception tasks requiring memorized visual-text
associations (celebrity recognition: -49.5%, OCR: -21.3%). These results
provide the first empirical evidence that alignment pre-training is not
necessary for effective multimodal learning, particularly for complex reasoning
tasks. Our work establishes the feasibility of a new paradigm that reduces
computational requirements by 45%, challenges conventional wisdom about
modality fusion, and opens new research directions for efficient multimodal
architectures that preserve modality-specific characteristics. Our project
website with code and additional resources is available at
https://inverse-llava.github.io.

</details>


### [215] [Standardization of Neuromuscular Reflex Analysis -- Role of Fine-Tuned Vision-Language Model Consortium and OpenAI gpt-oss Reasoning LLM Enabled Decision Support System](https://arxiv.org/abs/2508.12473)
*Eranga Bandara,Ross Gore,Sachin Shetty,Ravi Mukkamala,Christopher Rhea,Atmaram Yarlagadda,Shaifali Kaushik,L. H. M. P. De Silva,Andriy Maznychenko,Inna Sokolowska,Amin Hass,Kasun De Zoysa*

Main category: cs.CV

TL;DR: 基于细调视觉-语言模型联盟和理解大语言模型的决策支持系统，用于自动化H反射EMG波形解释和诊断


<details>
  <summary>Details</summary>
Motivation: 传统H反射EMG波形分析存在变异性和偏差，需要提高可靠性和标准化水平

Method: 使用多个细调VLM模型分析EMG图像，通过共识机制聚合诊断结果，再由专门理解LLM精炼决策

Result: 系统实现了高精度、一致性和可解释的H反射评估

Conclusion: 该方法为下一代AI辅助神经肌肉评估平台奠定了基础

Abstract: Accurate assessment of neuromuscular reflexes, such as the H-reflex, plays a
critical role in sports science, rehabilitation, and clinical neurology.
Traditional analysis of H-reflex EMG waveforms is subject to variability and
interpretation bias among clinicians and researchers, limiting reliability and
standardization. To address these challenges, we propose a Fine-Tuned
Vision-Language Model (VLM) Consortium and a reasoning Large-Language Model
(LLM)-enabled Decision Support System for automated H-reflex waveform
interpretation and diagnosis. Our approach leverages multiple VLMs, each
fine-tuned on curated datasets of H-reflex EMG waveform images annotated with
clinical observations, recovery timelines, and athlete metadata. These models
are capable of extracting key electrophysiological features and predicting
neuromuscular states, including fatigue, injury, and recovery, directly from
EMG images and contextual metadata. Diagnostic outputs from the VLM consortium
are aggregated using a consensus-based method and refined by a specialized
reasoning LLM, which ensures robust, transparent, and explainable decision
support for clinicians and sports scientists. The end-to-end platform
orchestrates seamless communication between the VLM ensemble and the reasoning
LLM, integrating prompt engineering strategies and automated reasoning
workflows using LLM Agents. Experimental results demonstrate that this hybrid
system delivers highly accurate, consistent, and interpretable H-reflex
assessments, significantly advancing the automation and standardization of
neuromuscular diagnostics. To our knowledge, this work represents the first
integration of a fine-tuned VLM consortium with a reasoning LLM for image-based
H-reflex analysis, laying the foundation for next-generation AI-assisted
neuromuscular assessment and athlete monitoring platforms.

</details>


### [216] [Skin Cancer Classification: Hybrid CNN-Transformer Models with KAN-Based Fusion](https://arxiv.org/abs/2508.12484)
*Shubhi Agarwal,Amulya Kumar Mahto*

Main category: cs.CV

TL;DR: 该研究提出了一种结合CNN、Transformer和卷积Kolmogorov-Arnold网络(CKAN)的混合模型，用于皮肤癌分类任务，在多个数据集上取得了优异的性能表现。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌分类是医学图像分析中的关键任务，需要精确区分恶性和非恶性病变以实现早期诊断和治疗。传统方法在特征提取和融合方面存在局限，需要更有效的模型来同时捕获局部空间特征和全局依赖关系。

Method: 采用顺序和并行混合的CNN-Transformer架构，结合卷积Kolmogorov-Arnold网络(CKAN)进行非线性特征融合。使用迁移学习和广泛的数据增强技术，CNN提取局部空间特征，Transformer建模全局依赖，CKAN通过可学习激活函数增强特征融合能力。

Result: 在HAM10000数据集上达到92.81%准确率和92.47% F1分数，PAD-UFES数据集上达到97.83%准确率和97.83% F1分数，BCN20000数据集上达到91.17%准确率和91.79% F1分数，展现了优异的分类性能和跨数据集的泛化能力。

Conclusion: 混合CNN-Transformer架构能有效捕获空间和上下文特征，CKAN的集成通过可学习激活函数增强了特征融合，产生了更具判别性的表示。该研究强调了特征表示和模型设计在推进稳健准确的医学图像分类中的重要性。

Abstract: Skin cancer classification is a crucial task in medical image analysis, where
precise differentiation between malignant and non-malignant lesions is
essential for early diagnosis and treatment. In this study, we explore
Sequential and Parallel Hybrid CNN-Transformer models with Convolutional
Kolmogorov-Arnold Network (CKAN). Our approach integrates transfer learning and
extensive data augmentation, where CNNs extract local spatial features,
Transformers model global dependencies, and CKAN facilitates nonlinear feature
fusion for improved representation learning. To assess generalization, we
evaluate our models on multiple benchmark datasets (HAM10000,BCN20000 and
PAD-UFES) under varying data distributions and class imbalances. Experimental
results demonstrate that hybrid CNN-Transformer architectures effectively
capture both spatial and contextual features, leading to improved
classification performance. Additionally, the integration of CKAN enhances
feature fusion through learnable activation functions, yielding more
discriminative representations. Our proposed approach achieves competitive
performance in skin cancer classification, demonstrating 92.81% accuracy and
92.47% F1-score on the HAM10000 dataset, 97.83% accuracy and 97.83% F1-score on
the PAD-UFES dataset, and 91.17% accuracy with 91.79% F1- score on the BCN20000
dataset highlighting the effectiveness and generalizability of our model across
diverse datasets. This study highlights the significance of feature
representation and model design in advancing robust and accurate medical image
classification.

</details>


### [217] [Design and Validation of a Responsible Artificial Intelligence-based System for the Referral of Diabetic Retinopathy Patients](https://arxiv.org/abs/2508.12506)
*E. Ulises Moya-Sánchez,Abraham Sánchez-Perez,Raúl Nanclares Da Veiga,Alejandro Zarate-Macías,Edgar Villareal,Alejandro Sánchez-Montes,Edtna Jauregui-Ulloa,Héctor Moreno,Ulises Cortés*

Main category: cs.CV

TL;DR: 这篇论文提出了RAIS-DR系统，一种基于负责任人工智能的糖尿病视网膜病筛查方案，在性能和公平性方面都显著超越了FDA批准的EyeArt系统。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病是工作年龄人受力主要原因，早期发现可降低95%的失明风险。但眼科医生短缺和诊断困难影响及时诊断，而现有AI系统又遇到数据质量低和偏见问题。

Method: 研究者开发了RAIS-DR系统，在AI生命周期中融入伦理原则。系统集成了高效卷积模型用于预处理、质量评估和三个专门的DR分类模型。

Result: 在1,046名未见过的患者数据集上，RAIS-DR与EyeArt系统相比：F1分数提高5-12%，准确率提高6-19%，特异性提高10-20%。同时在公平性指标上也显示出更好的表现。

Conclusion: RAIS-DR作为一个健壮且符合伦理要求的解决方案，有力推动糖尿病视网膜病的临床筛查应用，并可能减少健康不平等问题。

Abstract: Diabetic Retinopathy (DR) is a leading cause of vision loss in working-age
individuals. Early detection of DR can reduce the risk of vision loss by up to
95%, but a shortage of retinologists and challenges in timely examination
complicate detection. Artificial Intelligence (AI) models using retinal fundus
photographs (RFPs) offer a promising solution. However, adoption in clinical
settings is hindered by low-quality data and biases that may lead AI systems to
learn unintended features. To address these challenges, we developed RAIS-DR, a
Responsible AI System for DR screening that incorporates ethical principles
across the AI lifecycle. RAIS-DR integrates efficient convolutional models for
preprocessing, quality assessment, and three specialized DR classification
models. We evaluated RAIS-DR against the FDA-approved EyeArt system on a local
dataset of 1,046 patients, unseen by both systems. RAIS-DR demonstrated
significant improvements, with F1 scores increasing by 5-12%, accuracy by
6-19%, and specificity by 10-20%. Additionally, fairness metrics such as
Disparate Impact and Equal Opportunity Difference indicated equitable
performance across demographic subgroups, underscoring RAIS-DR's potential to
reduce healthcare disparities. These results highlight RAIS-DR as a robust and
ethically aligned solution for DR screening in clinical settings. The code,
weights of RAIS-DR are available at
https://gitlab.com/inteligencia-gubernamental-jalisco/jalisco-retinopathy with
RAIL.

</details>


### [218] [LangVision-LoRA-NAS: Neural Architecture Search for Variable LoRA Rank in Vision Language Models](https://arxiv.org/abs/2508.12512)
*Krishna Teja Chitty-Venkata,Murali Emani,Venkatram Vishwanath*

Main category: cs.CV

TL;DR: LangVision-LoRA-NAS是一个结合神经架构搜索(NAS)和LoRA的新框架，用于优化视觉语言模型的变秩适应，在保持性能的同时降低微调成本。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRA方法使用固定秩进行微调，限制了在不同多模态任务中的灵活性和效率，需要一种能够动态优化秩配置的方法。

Method: 通过神经架构搜索(NAS)动态搜索最优的LoRA秩配置，针对特定多模态任务进行定制化适配，平衡性能和计算效率。

Result: 在LLaMA-3.2-11B模型上的大量实验表明，该方法显著提升了模型性能，同时降低了微调成本。

Conclusion: LangVision-LoRA-NAS框架为视觉语言模型提供了更灵活高效的微调方案，通过动态秩优化实现了性能与效率的更好平衡。

Abstract: Vision Language Models (VLMs) integrate visual and text modalities to enable
multimodal understanding and generation. These models typically combine a
Vision Transformer (ViT) as an image encoder and a Large Language Model (LLM)
for text generation. LoRA (Low-Rank Adaptation) is an efficient fine-tuning
method to adapt pre-trained models to new tasks by introducing low-rank updates
to their weights. While LoRA has emerged as a powerful technique for
fine-tuning large models by introducing low-rank updates, current
implementations assume a fixed rank, potentially limiting flexibility and
efficiency across diverse tasks. This paper introduces
\textit{LangVision-LoRA-NAS}, a novel framework that integrates Neural
Architecture Search (NAS) with LoRA to optimize VLMs for variable-rank
adaptation. Our approach leverages NAS to dynamically search for the optimal
LoRA rank configuration tailored to specific multimodal tasks, balancing
performance and computational efficiency. Through extensive experiments using
the LLaMA-3.2-11B model on several datasets, LangVision-LoRA-NAS demonstrates
notable improvement in model performance while reducing fine-tuning costs. Our
Base and searched fine-tuned models on LLaMA-3.2-11B-Vision-Instruct can be
found
\href{https://huggingface.co/collections/krishnateja95/llama-32-11b-vision-instruct-langvision-lora-nas-6786cac480357a6a6fcc59ee}{\textcolor{blue}{here}}
and the code for LangVision-LoRA-NAS can be found
\href{https://github.com/krishnateja95/LangVision-NAS}{\textcolor{blue}{here}}.

</details>


### [219] [An Initial Study of Bird's-Eye View Generation for Autonomous Vehicles using Cross-View Transformers](https://arxiv.org/abs/2508.12520)
*Felipe Carlos dos Santos,Eric Aislan Antonelo,Gustavo Claudio Karl Couto*

Main category: cs.CV

TL;DR: 使用跨视图变换器将摄像头图像映射到布屋视图地图，包括路面、车道标记咈规划轨迹三个通道，在新城市环境中体现了良好的演续性能。


<details>
  <summary>Details</summary>
Motivation: 布屋视图地图为自动驾驶感知提供结构化的上下文抽象，本研究旨在探索使用跨视图变换器从摄像头图像生成准确的BEV地图。

Method: 采用跨视图变换器(CVT)，使用城市驾驶模拟器生成训练数据，比较了不同摄像头布局和两种损失函数（focal损失和L1损失）的效果。

Result: 在只使用一个城市训练数据的情况下，使用L1损失训练的四摄像头CVT模型在新城市环境中表现最为稳健，能够生成相对准确的BEV地图。

Conclusion: 跨视图变换器在将摄像头输入映射到BEV地图方面具有很大潜力，特别是在新环境中体现了良好的演续性能。

Abstract: Bird's-Eye View (BEV) maps provide a structured, top-down abstraction that is
crucial for autonomous-driving perception. In this work, we employ Cross-View
Transformers (CVT) for learning to map camera images to three BEV's channels -
road, lane markings, and planned trajectory - using a realistic simulator for
urban driving. Our study examines generalization to unseen towns, the effect of
different camera layouts, and two loss formulations (focal and L1). Using
training data from only a town, a four-camera CVT trained with the L1 loss
delivers the most robust test performance, evaluated in a new town. Overall,
our results underscore CVT's promise for mapping camera inputs to reasonably
accurate BEV maps.

</details>


### [220] [MuSACo: Multimodal Subject-Specific Selection and Adaptation for Expression Recognition with Co-Training](https://arxiv.org/abs/2508.12522)
*Muhammad Osama Zeeshan,Natacha Gillet,Alessandro Lameiras Koerich,Marco Pedersoli,Francois Bremond,Eric Granger*

Main category: cs.CV

TL;DR: MuSACo是一个基于协同训练的多模态个性化表情识别方法，通过选择相关源主体和多模态信息融合来提升目标主体的识别性能


<details>
  <summary>Details</summary>
Motivation: 现有的多源域自适应方法往往忽视多模态信息或将多个源域混合为单一域，限制了主体多样性且无法显式捕捉主体特异性特征

Method: 基于协同训练的多模态主体特异性选择和适应方法，选择与目标相关的源主体，使用主导模态生成伪标签进行类感知学习，并结合类无关损失从低置信度目标样本中学习

Result: 在BioVid和StressID多模态表情识别数据集上的实验表明，MuSACo优于无监督域自适应和现有最先进的多源域自适应方法

Conclusion: MuSACo通过有效利用多模态信息和主体特异性选择，在个性化表情识别任务中取得了显著性能提升，特别适用于数字健康中的情感计算应用

Abstract: Personalized expression recognition (ER) involves adapting a machine learning
model to subject-specific data for improved recognition of expressions with
considerable interpersonal variability. Subject-specific ER can benefit
significantly from multi-source domain adaptation (MSDA) methods, where each
domain corresponds to a specific subject, to improve model accuracy and
robustness. Despite promising results, state-of-the-art MSDA approaches often
overlook multimodal information or blend sources into a single domain, limiting
subject diversity and failing to explicitly capture unique subject-specific
characteristics. To address these limitations, we introduce MuSACo, a
multi-modal subject-specific selection and adaptation method for ER based on
co-training. It leverages complementary information across multiple modalities
and multiple source domains for subject-specific adaptation. This makes MuSACo
particularly relevant for affective computing applications in digital health,
such as patient-specific assessment for stress or pain, where subject-level
nuances are crucial. MuSACo selects source subjects relevant to the target and
generates pseudo-labels using the dominant modality for class-aware learning,
in conjunction with a class-agnostic loss to learn from less confident target
samples. Finally, source features from each modality are aligned, while only
confident target features are combined. Our experimental results on challenging
multimodal ER datasets: BioVid and StressID, show that MuSACo can outperform
UDA (blending) and state-of-the-art MSDA methods.

</details>


### [221] [REVEAL -- Reasoning and Evaluation of Visual Evidence through Aligned Language](https://arxiv.org/abs/2508.12543)
*Ipsita Praharaj,Yukta Butala,Yash Butala*

Main category: cs.CV

TL;DR: REVEAL框架利用大型视觉语言模型，通过整体场景评估和区域异常检测两种方法，实现了跨领域的图像伪造检测和定位，在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得视觉伪造检测和解释变得更加困难，需要能够提供推理和定位的鲁棒框架，而现有方法在跨领域泛化方面存在挑战。

Method: 将伪造检测构建为提示驱动的视觉推理任务，利用大型视觉语言模型的语义对齐能力。提出两种方法：(1)整体场景级评估，基于图像的物理、语义、透视和真实性；(2)区域级异常检测，将图像分割成多个区域进行分析。

Result: 在多个领域的数据集（Photoshop、DeepFake和AIGC编辑）上进行实验，与竞争基线进行比较，并分析了模型提供的推理能力。

Conclusion: REVEAL框架通过视觉语言模型的语义对齐能力，有效解决了跨领域图像伪造检测的泛化问题，提供了可靠的检测和推理能力。

Abstract: The rapid advancement of generative models has intensified the challenge of
detecting and interpreting visual forgeries, necessitating robust frameworks
for image forgery detection while providing reasoning as well as localization.
While existing works approach this problem using supervised training for
specific manipulation or anomaly detection in the embedding space,
generalization across domains remains a challenge. We frame this problem of
forgery detection as a prompt-driven visual reasoning task, leveraging the
semantic alignment capabilities of large vision-language models. We propose a
framework, `REVEAL` (Reasoning and Evaluation of Visual Evidence through
Aligned Language), that incorporates generalized guidelines. We propose two
tangential approaches - (1) Holistic Scene-level Evaluation that relies on the
physics, semantics, perspective, and realism of the image as a whole and (2)
Region-wise anomaly detection that splits the image into multiple regions and
analyzes each of them. We conduct experiments over datasets from different
domains (Photoshop, DeepFake and AIGC editing). We compare the Vision Language
Models against competitive baselines and analyze the reasoning provided by
them.

</details>


### [222] [Structure-preserving Feature Alignment for Old Photo Colorization](https://arxiv.org/abs/2508.12570)
*Yingxue Pang,Xin Jin,Jun Fu,Zhibo Chen*

Main category: cs.CV

TL;DR: 基于双图像训练的旧照片着色算法SFAC，通过特征对齐和结构保持机制克服领域间隔问题


<details>
  <summary>Details</summary>
Motivation: 现有深度学习着色方法靠大规模数据集训练，但直接应用于旧照片着色遇到缺乏真实标签和领域间隔的挑战

Method: 提出SFAC算法，仅需两张图像进行训练，通过特征分布对齐损失实现语义对应，使用感知约束和冻结-更新金字塔机制保持结构

Result: 实验结果显示方法在旧照片着色任务上有效，定性和定量指标都证明了其优势

Conclusion: SFAC能够免除对大规模数据的依赖，直接处理旧照片克服领域间隔，通过语义对应和结构保持机制实现优质的着色效果

Abstract: Deep learning techniques have made significant advancements in
reference-based colorization by training on large-scale datasets. However,
directly applying these methods to the task of colorizing old photos is
challenging due to the lack of ground truth and the notorious domain gap
between natural gray images and old photos. To address this issue, we propose a
novel CNN-based algorithm called SFAC, i.e., Structure-preserving Feature
Alignment Colorizer. SFAC is trained on only two images for old photo
colorization, eliminating the reliance on big data and allowing direct
processing of the old photo itself to overcome the domain gap problem. Our
primary objective is to establish semantic correspondence between the two
images, ensuring that semantically related objects have similar colors. We
achieve this through a feature distribution alignment loss that remains robust
to different metric choices. However, utilizing robust semantic correspondence
to transfer color from the reference to the old photo can result in inevitable
structure distortions. To mitigate this, we introduce a structure-preserving
mechanism that incorporates a perceptual constraint at the feature level and a
frozen-updated pyramid at the pixel level. Extensive experiments demonstrate
the effectiveness of our method for old photo colorization, as confirmed by
qualitative and quantitative metrics.

</details>


### [223] [Foundation Model for Skeleton-Based Human Action Understanding](https://arxiv.org/abs/2508.12586)
*Hongsong Wang,Wanjiang Weng,Junbo Wang,Fang Zhao,Guo-Sen Xie,Xin Geng,Liang Wang*

Main category: cs.CV

TL;DR: 这篇论文提出了一种统一骨架基础模型USDRL，通过Transformer编码器、多粒度特征解相关和多视角一致性训练，在25个测试集上显著超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有骨架动作理解方法缺乏扩展性和通用性，没有能够适配广泛动作理解任务的基础模型。

Method: USDRL框架包含：1）Transformer基础的密集时空编码器；2）多粒度特征解相关模块；3）多视角一致性训练模块。通过并行流学习时间动态和空间结构特征。

Result: 在9种骨架动作理解任务的25个标准测试集上，方法显著超越了当前最优方法。涉及粗粒度预测、密集预测和迁移预测任务。

Conclusion: 该工作为骨架动作理解领域提供了一个基础模型框架，希望能够扩展研究范围并引起对密集预测任务的更多关注。

Abstract: Human action understanding serves as a foundational pillar in the field of
intelligent motion perception. Skeletons serve as a modality- and
device-agnostic representation for human modeling, and skeleton-based action
understanding has potential applications in humanoid robot control and
interaction. \RED{However, existing works often lack the scalability and
generalization required to handle diverse action understanding tasks. There is
no skeleton foundation model that can be adapted to a wide range of action
understanding tasks}. This paper presents a Unified Skeleton-based Dense
Representation Learning (USDRL) framework, which serves as a foundational model
for skeleton-based human action understanding. USDRL consists of a
Transformer-based Dense Spatio-Temporal Encoder (DSTE), Multi-Grained Feature
Decorrelation (MG-FD), and Multi-Perspective Consistency Training (MPCT). The
DSTE module adopts two parallel streams to learn temporal dynamic and spatial
structure features. The MG-FD module collaboratively performs feature
decorrelation across temporal, spatial, and instance domains to reduce
dimensional redundancy and enhance information extraction. The MPCT module
employs both multi-view and multi-modal self-supervised consistency training.
The former enhances the learning of high-level semantics and mitigates the
impact of low-level discrepancies, while the latter effectively facilitates the
learning of informative multimodal features. We perform extensive experiments
on 25 benchmarks across across 9 skeleton-based action understanding tasks,
covering coarse prediction, dense prediction, and transferred prediction. Our
approach significantly outperforms the current state-of-the-art methods. We
hope that this work would broaden the scope of research in skeleton-based
action understanding and encourage more attention to dense prediction tasks.

</details>


### [224] [Multimodal Chain of Continuous Thought for Latent-Space Reasoning in Vision-Language Models](https://arxiv.org/abs/2508.12587)
*Tan-Hanh Pham,Chris Ngo*

Main category: cs.CV

TL;DR: 提出了多模态连续思维链(MCOUT)方法，在联合潜在空间中进行推理而非自然语言，显著提升多模态推理性能


<details>
  <summary>Details</summary>
Motivation: 传统基于语言的方法如思维链提示在多模态场景中效果不佳，难以动态对齐音频、视觉和文本信息

Method: 开发了MCOUT-Base和MCOUT-Multi两个变体，使用连续隐藏向量表示推理状态，通过迭代精炼并与视觉文本嵌入对齐

Result: 在MMMU、ScienceQA和MMStar等基准测试中准确率提升最高8.23%，BLEU分数提升最高8.27%

Conclusion: 潜在连续推理是多模态大模型发展的有前景方向，提供了可扩展的类人反思推理框架

Abstract: Many reasoning techniques for large multimodal models adapt language model
approaches, such as Chain-of-Thought (CoT) prompting, which express reasoning
as word sequences. While effective for text, these methods are suboptimal for
multimodal contexts, struggling to align audio, visual, and textual information
dynamically. To explore an alternative paradigm, we propose the Multimodal
Chain of Continuous Thought (MCOUT), which enables reasoning directly in a
joint latent space rather than in natural language. In MCOUT, the reasoning
state is represented as a continuous hidden vector, iteratively refined and
aligned with visual and textual embeddings, inspired by human reflective
cognition. We develop two variants: MCOUT-Base, which reuses the language
model`s last hidden state as the continuous thought for iterative reasoning,
and MCOUT-Multi, which integrates multimodal latent attention to strengthen
cross-modal alignment between visual and textual features. Experiments on
benchmarks including MMMU, ScienceQA, and MMStar show that MCOUT consistently
improves multimodal reasoning, yielding up to 8.23% accuracy gains over strong
baselines and improving BLEU scores up to 8.27% across multiple-choice and
open-ended tasks. These findings highlight latent continuous reasoning as a
promising direction for advancing LMMs beyond language-bound CoT, offering a
scalable framework for human-like reflective multimodal inference. Code is
available at https://github.com/Hanhpt23/OmniMod.

</details>


### [225] [ViLaD: A Large Vision Language Diffusion Framework for End-to-End Autonomous Driving](https://arxiv.org/abs/2508.12603)
*Can Cui,Yupeng Zhou,Juntong Peng,Sung-Yeon Park,Zichong Yang,Prashanth Sankaranarayanan,Jiaru Zhang,Ruqi Zhang,Ziran Wang*

Main category: cs.CV

TL;DR: ViLaD是一个基于扩散模型的新型端到端自动驾驶框架，通过并行生成驾驶决策序列显著降低延迟，支持双向推理和渐进式生成，在nuScenes数据集上表现优于现有自回归VLM方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉语言模型的自回归架构在自动驾驶中存在推理延迟高、无法进行双向推理的问题，不适合动态安全关键环境。

Method: 采用掩码扩散模型实现驾驶决策序列的并行生成，支持双向推理和渐进式易先生成策略。

Result: 在nuScenes数据集上，ViLaD在规划准确性和推理速度方面均优于最先进的自回归VLM基线，接近零失败率，并在真实自动驾驶车辆上验证了实用性。

Conclusion: ViLaD框架代表了自动驾驶领域的范式转变，通过扩散模型解决了自回归架构的局限性，为实际应用提供了有效可靠的解决方案。

Abstract: End-to-end autonomous driving systems built on Vision Language Models (VLMs)
have shown significant promise, yet their reliance on autoregressive
architectures introduces some limitations for real-world applications. The
sequential, token-by-token generation process of these models results in high
inference latency and cannot perform bidirectional reasoning, making them
unsuitable for dynamic, safety-critical environments. To overcome these
challenges, we introduce ViLaD, a novel Large Vision Language Diffusion (LVLD)
framework for end-to-end autonomous driving that represents a paradigm shift.
ViLaD leverages a masked diffusion model that enables parallel generation of
entire driving decision sequences, significantly reducing computational
latency. Moreover, its architecture supports bidirectional reasoning, allowing
the model to consider both past and future simultaneously, and supports
progressive easy-first generation to iteratively improve decision quality. We
conduct comprehensive experiments on the nuScenes dataset, where ViLaD
outperforms state-of-the-art autoregressive VLM baselines in both planning
accuracy and inference speed, while achieving a near-zero failure rate.
Furthermore, we demonstrate the framework's practical viability through a
real-world deployment on an autonomous vehicle for an interactive parking task,
confirming its effectiveness and soundness for practical applications.

</details>


### [226] [ViDA-UGC: Detailed Image Quality Analysis via Visual Distortion Assessment for UGC Images](https://arxiv.org/abs/2508.12605)
*Wenjie Liao,Jieyu Yuan,Yifang Xu,Chunle Guo,Zilong Zhang,Jihong Li,Jiachen Fu,Haotian Fan,Tao Li,Junhui Cui,Chongyi Li*

Main category: cs.CV

TL;DR: 这篇论文提出了首个大规模的用户生成内容(UGC)图像视觉失真评估指令微调数据集ViDA-UGC，通过链式思维评估框架生成细粒度质量描述，显著提升了多模态大语言模型的图像质量分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释图像质量评估方法对UGC和AIGC图像使用相同的失真标准，缺乏细粒度的质量分析和图像恢复指导能力。

Method: 通过失真导向的流水线构建ViDA-UGC数据集，包含1.1万张图像的细粒度质量基准、详细质量感知和推理描述。使用链式思维评估框架指导GPT-4o生成质量描述，并选择476张图像构建了ViDA-UGC-Bench标准测试集。

Result: 实验结果显示ViDA-UGC数据集和CoT框架能够一致地提升多个基础MLLM模型在ViDA-UGC-Bench和Q-Bench上的图像质量分析能力，甚至超越了GPT-4o的性能。

Conclusion: 该研究为UGC图像质量评估提供了一个重要的数据集和框架，通过细粒度的失真分析和描述，有效提升了MLLM模型的可解释性图像质量评估能力。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have introduced a
paradigm shift for Image Quality Assessment (IQA) from unexplainable image
quality scoring to explainable IQA, demonstrating practical applications like
quality control and optimization guidance. However, current explainable IQA
methods not only inadequately use the same distortion criteria to evaluate both
User-Generated Content (UGC) and AI-Generated Content (AIGC) images, but also
lack detailed quality analysis for monitoring image quality and guiding image
restoration. In this study, we establish the first large-scale Visual
Distortion Assessment Instruction Tuning Dataset for UGC images, termed
ViDA-UGC, which comprises 11K images with fine-grained quality grounding,
detailed quality perception, and reasoning quality description data. This
dataset is constructed through a distortion-oriented pipeline, which involves
human subject annotation and a Chain-of-Thought (CoT) assessment framework.
This framework guides GPT-4o to generate quality descriptions by identifying
and analyzing UGC distortions, which helps capturing rich low-level visual
features that inherently correlate with distortion patterns. Moreover, we
carefully select 476 images with corresponding 6,149 question answer pairs from
ViDA-UGC and invite a professional team to ensure the accuracy and quality of
GPT-generated information. The selected and revised data further contribute to
the first UGC distortion assessment benchmark, termed ViDA-UGC-Bench.
Experimental results demonstrate the effectiveness of the ViDA-UGC and CoT
framework for consistently enhancing various image quality analysis abilities
across multiple base MLLMs on ViDA-UGC-Bench and Q-Bench, even surpassing
GPT-4o.

</details>


### [227] [OpenMoCap: Rethinking Optical Motion Capture under Real-world Occlusion](https://arxiv.org/abs/2508.12610)
*Chen Qian,Danyang Li,Xinran Yu,Zheng Yang,Qiang Ma*

Main category: cs.CV

TL;DR: 这篇论文提出了OpenMoCap模型和CMU-Occlu数据集，解决光学动作捕捉中大规模标记点遮挡问题，显著提升了在复杂场景下的动作解析精度。


<details>
  <summary>Details</summary>
Motivation: 光学动作捕捉系统在实际应用中遇到大规模标记点遮挡时性能会严重下降。当前模型存在两个主要问题：缺乏反映实际遮挡模式的训练数据集，以及缺乏能够捕捉标记点间长程依赖关系的训练策略。

Method: 首先创建了CMU-Occlu数据集，利用光线追踪技术实际模拟遮挡模式。提出了OpenMoCap模型，采用标记点-关节链推理机制，能够同时优化并构建标记点与关节之间的深度约束关系。

Result: 经过广泛的对比实验，OpenMoCap在多种场景下都一贯地超过了竞争方法。CMU-Occlu数据集为未来的稳健动作解析研究打开了新的可能性。

Conclusion: 该研究成功地解决了光学动作捕捉中遮挡问题，提供了实用的数据集和高效模型。OpenMoCap已集成到MoSen动作捕捉系统中进行实际部署。

Abstract: Optical motion capture is a foundational technology driving advancements in
cutting-edge fields such as virtual reality and film production. However,
system performance suffers severely under large-scale marker occlusions common
in real-world applications. An in-depth analysis identifies two primary
limitations of current models: (i) the lack of training datasets accurately
reflecting realistic marker occlusion patterns, and (ii) the absence of
training strategies designed to capture long-range dependencies among markers.
To tackle these challenges, we introduce the CMU-Occlu dataset, which
incorporates ray tracing techniques to realistically simulate practical marker
occlusion patterns. Furthermore, we propose OpenMoCap, a novel motion-solving
model designed specifically for robust motion capture in environments with
significant occlusions. Leveraging a marker-joint chain inference mechanism,
OpenMoCap enables simultaneous optimization and construction of deep
constraints between markers and joints. Extensive comparative experiments
demonstrate that OpenMoCap consistently outperforms competing methods across
diverse scenarios, while the CMU-Occlu dataset opens the door for future
studies in robust motion solving. The proposed OpenMoCap is integrated into the
MoSen MoCap system for practical deployment. The code is released at:
https://github.com/qianchen214/OpenMoCap.

</details>


### [228] [WIPES: Wavelet-based Visual Primitives](https://arxiv.org/abs/2508.12615)
*Wenhao Zhang,Hao Zhu,Delong Wu,Di Kang,Linchao Bao,Zhan Ma,Xun Cao*

Main category: cs.CV

TL;DR: WIPES是一种基于小波的通用视觉基元表示方法，通过小波的空间-频率局部化优势有效捕捉低频和高频信息，并开发了小波可微分光栅化器实现快速渲染，在多种视觉任务中表现出优于现有方法的渲染质量和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉表示方法依赖频率引导或复杂神经网络解码，导致频谱损失或渲染速度慢，需要一种能够同时提供灵活频率调制和快速渲染的连续视觉表示方法。

Method: 基于小波的空间-频率局部化优势构建WIPES视觉基元，开发小波可微分光栅化器实现快速视觉渲染，有效捕捉低频和高频视觉信号。

Result: 在2D图像表示、5D静态和6D动态新视角合成等视觉任务中，WIPES相比基于INR的方法提供更高渲染质量和更快推理速度，在渲染质量上优于基于高斯的方法。

Conclusion: WIPES作为一种通用视觉基元表示，成功解决了现有方法的频谱损失和渲染速度问题，在多种视觉任务中展现出优越的性能表现。

Abstract: Pursuing a continuous visual representation that offers flexible frequency
modulation and fast rendering speed has recently garnered increasing attention
in the fields of 3D vision and graphics. However, existing representations
often rely on frequency guidance or complex neural network decoding, leading to
spectrum loss or slow rendering. To address these limitations, we propose
WIPES, a universal Wavelet-based vIsual PrimitivES for representing
multi-dimensional visual signals. Building on the spatial-frequency
localization advantages of wavelets, WIPES effectively captures both the
low-frequency "forest" and the high-frequency "trees." Additionally, we develop
a wavelet-based differentiable rasterizer to achieve fast visual rendering.
Experimental results on various visual tasks, including 2D image
representation, 5D static and 6D dynamic novel view synthesis, demonstrate that
WIPES, as a visual primitive, offers higher rendering quality and faster
inference than INR-based methods, and outperforms Gaussian-based
representations in rendering quality.

</details>


### [229] [Vision-G1: Towards General Vision Language Reasoning with Multi-Domain Data Curation](https://arxiv.org/abs/2508.12680)
*Yuheng Zha,Kun Zhou,Yujia Wu,Yushu Wang,Jie Feng,Zhi Xu,Shibo Hao,Zhengzhong Liu,Eric P. Xing,Zhiting Hu*

Main category: cs.CV

TL;DR: 构建了涵盖8个维度46个数据源的视觉推理数据集，提出基于影响函数的数据选择和难度过滤策略，通过多轮RL训练Vision-G1模型，在多个基准测试中达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型训练主要集中在数学和逻辑推理等有限任务，难以泛化到广泛领域，且缺乏可验证的奖励数据和跨领域数据整合方案

Method: 1) 构建包含8个维度46个数据源的RL就绪数据集 2) 使用影响函数进行数据选择和基于难度的过滤 3) 采用多轮RL训练和数据课程学习迭代提升模型能力

Result: Vision-G1模型在多个视觉推理基准测试中达到最先进性能，超越同规模VLM甚至GPT-4o和Gemini-1.5 Flash等专有模型

Conclusion: 通过构建大规模多领域数据集和创新的训练策略，成功提升了视觉语言模型的泛化推理能力，为跨领域视觉推理提供了有效解决方案

Abstract: Despite their success, current training pipelines for reasoning VLMs focus on
a limited range of tasks, such as mathematical and logical reasoning. As a
result, these models face difficulties in generalizing their reasoning
capabilities to a wide range of domains, primarily due to the scarcity of
readily available and verifiable reward data beyond these narrowly defined
areas. Moreover, integrating data from multiple domains is challenging, as the
compatibility between domain-specific datasets remains uncertain. To address
these limitations, we build a comprehensive RL-ready visual reasoning dataset
from 46 data sources across 8 dimensions, covering a wide range of tasks such
as infographic, mathematical, spatial, cross-image, graphic user interface,
medical, common sense and general science. We propose an influence function
based data selection and difficulty based filtering strategy to identify
high-quality training samples from this dataset. Subsequently, we train the
VLM, referred to as Vision-G1, using multi-round RL with a data curriculum to
iteratively improve its visual reasoning capabilities. Our model achieves
state-of-the-art performance across various visual reasoning benchmarks,
outperforming similar-sized VLMs and even proprietary models like GPT-4o and
Gemini-1.5 Flash. The model, code and dataset are publicly available at
https://github.com/yuh-zha/Vision-G1.

</details>


### [230] [Creative4U: MLLMs-based Advertising Creative Image Selector with Comparative Reasoning](https://arxiv.org/abs/2508.12628)
*Yukang Lin,Xiang Zhang,Shichang Jia,Bowen Wan,Chenghan Fu,Xudong Ren,Yueran Liu,Wanxian Guan,Pengji Wang,Jian Xu,Bo Zheng,Baolin Liu*

Main category: cs.CV

TL;DR: 本文提出了首个可解释性创意图片评估与选择范式Creative4U，基于多模态大语言模型，通过理性选择学习策略实现了高准确的创意图片选择。


<details>
  <summary>Details</summary>
Motivation: 现有创意图片选择方法主要聚焦排名而缺乏可解释性，无法满足广告主对创意质量评估的需求。AIGC技术能大量生产创意图片，但选择问题尚未解决。

Method: 构建CreativePair数据集（8k带注释的图片对），提出Creative4U模型。采用Reason-to-Select RFT学习策略：包含链式思维监督微调(CoT-SFT)和基于组相对策略优化(GRPO)的强化学习，考虑用户兴趣做出可解释的选择。

Result: 离线和在线实验都证明了方法的有效性，能够准确评估和选择创意图片。代码和数据集将公开以促进研究和应用。

Conclusion: 本文提供了一个可解释性的创意图片评估与选择方案，有效解决了AIGC时代大量创意图片选择的挑战，为广告主和平台提供了可靠的创意选择工具。

Abstract: Creative image in advertising is the heart and soul of e-commerce platform.
An eye-catching creative image can enhance the shopping experience for users,
boosting income for advertisers and advertising revenue for platforms. With the
advent of AIGC technology, advertisers can produce large quantities of creative
images at minimal cost. However, they struggle to assess the creative quality
to select. Existing methods primarily focus on creative ranking, which fails to
address the need for explainable creative selection.
  In this work, we propose the first paradigm for explainable creative
assessment and selection. Powered by multimodal large language models (MLLMs),
our approach integrates the assessment and selection of creative images into a
natural language generation task. To facilitate this research, we construct
CreativePair, the first comparative reasoning-induced creative dataset
featuring 8k annotated image pairs, with each sample including a label
indicating which image is superior. Additionally, we introduce Creative4U
(pronounced Creative for You), a MLLMs-based creative selector that takes into
account users' interests. Through Reason-to-Select RFT, which includes
supervised fine-tuning with Chain-of-Thought (CoT-SFT) and Group Relative
Policy Optimization (GRPO) based reinforcement learning, Creative4U is able to
evaluate and select creative images accurately. Both offline and online
experiments demonstrate the effectiveness of our approach. Our code and dataset
will be made public to advance research and industrial applications.

</details>


### [231] [SpotVLM: Cloud-edge Collaborative Real-time VLM based on Context Transfer](https://arxiv.org/abs/2508.12638)
*Chen Qian,Xinran Yu,Zewen Huang,Danyang Li,Qiang Ma,Fan Dang,Xuan Ding,Guangyong Shang,Zheng Yang*

Main category: cs.CV

TL;DR: 提出Context Transfer框架，利用延迟的大型视觉语言模型输出作为历史上下文，指导小型模型进行实时推理


<details>
  <summary>Details</summary>
Motivation: 现有云端协同方案无法处理云端延迟波动，且没有充分利用延迟但准确的大型模型响应

Method: 设计SpotVLM系统，包含上下文替换模块和视觉聚焦模块，优化历史文本输入和提升视觉基准一致性

Result: 在4个数据集的3种实时视视任务中验证框架有效性

Conclusion: 为未来VLM系统提供了更有效和延迟感知的协同策略基础

Abstract: Vision-Language Models (VLMs) are increasingly deployed in real-time
applications such as autonomous driving and human-computer interaction, which
demand fast and reliable responses based on accurate perception. To meet these
requirements, existing systems commonly employ cloud-edge collaborative
architectures, such as partitioned Large Vision-Language Models (LVLMs) or task
offloading strategies between Large and Small Vision-Language Models (SVLMs).
However, these methods fail to accommodate cloud latency fluctuations and
overlook the full potential of delayed but accurate LVLM responses. In this
work, we propose a novel cloud-edge collaborative paradigm for VLMs, termed
Context Transfer, which treats the delayed outputs of LVLMs as historical
context to provide real-time guidance for SVLMs inference. Based on this
paradigm, we design SpotVLM, which incorporates both context replacement and
visual focus modules to refine historical textual input and enhance visual
grounding consistency. Extensive experiments on three real-time vision tasks
across four datasets demonstrate the effectiveness of the proposed framework.
The new paradigm lays the groundwork for more effective and latency-aware
collaboration strategies in future VLM systems.

</details>


### [232] [Synthesizing Accurate and Realistic T1-weighted Contrast-Enhanced MR Images using Posterior-Mean Rectified Flow](https://arxiv.org/abs/2508.12640)
*Bastian Brandstötter,Erich Kobler*

Main category: cs.CV

TL;DR: 一种两阶段流动模型算法，能够从非对比增强脑部MRI生成高质量的对比增强MRI，避免使甠锺剂


<details>
  <summary>Details</summary>
Motivation: 对比增强MRI在神经脱类诊断中很重要，但需要使甠锺剂，这会增加成本、扩大扫描时间、环境风险和患者风险

Method: 两阶段流动模型管道：先用3D U-Net预测后验均值，然后用时间条件化3D流模型精炼，以结合真实细节和结构保真

Result: 在360份测试数据上，精炼后输出达到FID 12.46和KID 0.007（比后验均值低68.7%），保持低MSE 0.057（仅高于后验均值27%），能恢复病变边缘和血管细节

Conclusion: 该方法有效解决了临床部署中的感知-失真搁扭问题，为无锺剂对比增强MRI提供了可行方案

Abstract: Contrast-enhanced (CE) T1-weighted MRI is central to neuro-oncologic
diagnosis but requires gadolinium-based agents, which add cost and scan time,
raise environmental concerns, and may pose risks to patients. In this work, we
propose a two-stage Posterior-Mean Rectified Flow (PMRF) pipeline for
synthesizing volumetric CE brain MRI from non-contrast inputs. First, a
patch-based 3D U-Net predicts the voxel-wise posterior mean (minimizing MSE).
Then, this initial estimate is refined by a time-conditioned 3D rectified flow
to incorporate realistic textures without compromising structural fidelity. We
train this model on a multi-institutional collection of paired pre- and
post-contrast T1w volumes (BraTS 2023-2025). On a held-out test set of 360
diverse volumes, our best refined outputs achieve an axial FID of $12.46$ and
KID of $0.007$ ($\sim 68.7\%$ lower FID than the posterior mean) while
maintaining low volumetric MSE of $0.057$ ($\sim 27\%$ higher than the
posterior mean). Qualitative comparisons confirm that our method restores
lesion margins and vascular details realistically, effectively navigating the
perception-distortion trade-off for clinical deployment.

</details>


### [233] [Learn Faster and Remember More: Balancing Exploration and Exploitation for Continual Test-time Adaptation](https://arxiv.org/abs/2508.12643)
*Pinci Yang,Peisong Wen,Ke Ma,Qianqian Xu*

Main category: cs.CV

TL;DR: 提出了BEE方法，通过多级一致性正则化和互补锚点重放机制，在持续测试时适应中平衡探索新域和利用历史知识


<details>
  <summary>Details</summary>
Motivation: 现有CTTA方法存在两个主要问题：1）深层预测调整浅层特征效率低，导致探索缓慢；2）单一模型在探索新域时会遗忘历史知识，无法有效利用相似域

Method: 采用mean teacher框架，使用多级一致性正则化(MCR)对齐师生模型的中间特征加速适应，并通过互补锚点重放(CAR)机制重用历史检查点恢复多样化域知识

Result: 在多个基准测试中显著优于最先进方法

Conclusion: BEE方法有效解决了CTTA中探索与利用的平衡问题，通过特征级对齐和知识重放实现了快速适应和知识保持

Abstract: Continual Test-Time Adaptation (CTTA) aims to adapt a source pre-trained
model to continually changing target domains during inference. As a fundamental
principle, an ideal CTTA method should rapidly adapt to new domains
(exploration) while retaining and exploiting knowledge from previously
encountered domains to handle similar domains in the future. Despite
significant advances, balancing exploration and exploitation in CTTA is still
challenging: 1) Existing methods focus on adjusting predictions based on
deep-layer outputs of neural networks. However, domain shifts typically affect
shallow features, which are inefficient to be adjusted from deep predictions,
leading to dilatory exploration; 2) A single model inevitably forgets knowledge
of previous domains during the exploration, making it incapable of exploiting
historical knowledge to handle similar future domains. To address these
challenges, this paper proposes a mean teacher framework that strikes an
appropriate Balance between Exploration and Exploitation (BEE) during the CTTA
process. For the former challenge, we introduce a Multi-level Consistency
Regularization (MCR) loss that aligns the intermediate features of the student
and teacher models, accelerating adaptation to the current domain. For the
latter challenge, we employ a Complementary Anchor Replay (CAR) mechanism to
reuse historical checkpoints (anchors), recovering complementary knowledge for
diverse domains. Experiments show that our method significantly outperforms
state-of-the-art methods on several benchmarks, demonstrating its effectiveness
for CTTA tasks.

</details>


### [234] [Has GPT-5 Achieved Spatial Intelligence? An Empirical Study](https://arxiv.org/abs/2508.13142)
*Zhongang Cai,Yubo Wang,Qingping Sun,Ruisi Wang,Chenyang Gu,Wanqi Yin,Zhiqian Lin,Zhitao Yang,Chen Wei,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Jiaqi Li,Xiangyu Fan,Hanming Deng,Lewei Lu,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: GPT-5在多模态空间智能方面取得显著进步但仍未达到人类水平，研究通过8个基准测试和超过10亿token的成本评估发现专有模型在最困难问题上并无决定性优势


<details>
  <summary>Details</summary>
Motivation: 多模态模型在空间理解和推理方面仍存在显著局限，需要评估当前最先进模型在空间智能方面的表现，特别是新发布的GPT-5

Method: 提出统一的空间任务分类法，在8个关键基准上评估最先进的专有和开源模型，总成本超过10亿token，并进行定性评估

Result: GPT-5在空间智能方面展现出前所未有的强大能力，但在广泛任务中仍落后于人类表现；专有模型在最困难问题上没有决定性优势

Conclusion: 多模态模型在人类直觉性空间场景中仍存在失败，空间智能仍是实现通用人工智能的重要挑战领域

Abstract: Multi-modal models have achieved remarkable progress in recent years.
Nevertheless, they continue to exhibit notable limitations in spatial
understanding and reasoning, which are fundamental capabilities to achieving
artificial general intelligence. With the recent release of GPT-5, allegedly
the most powerful AI model to date, it is timely to examine where the leading
models stand on the path toward spatial intelligence. First, we propose a
comprehensive taxonomy of spatial tasks that unifies existing benchmarks and
discuss the challenges in ensuring fair evaluation. We then evaluate
state-of-the-art proprietary and open-source models on eight key benchmarks, at
a cost exceeding one billion total tokens. Our empirical study reveals that (1)
GPT-5 demonstrates unprecedented strength in spatial intelligence, yet (2)
still falls short of human performance across a broad spectrum of tasks.
Moreover, we (3) identify the more challenging spatial intelligence problems
for multi-modal models, and (4) proprietary models do not exhibit a decisive
advantage when facing the most difficult problems. In addition, we conduct a
qualitative evaluation across a diverse set of scenarios that are intuitive for
humans yet fail even the most advanced multi-modal models.

</details>


### [235] [DyCrowd: Towards Dynamic Crowd Reconstruction from a Large-scene Video](https://arxiv.org/abs/2508.12644)
*Hao Wen,Hongbo Kang,Jian Ma,Jing Huang,Yuanwang Yang,Haozhe Lin,Yu-Kun Lai,Kun Li*

Main category: cs.CV

TL;DR: DyCrowd是一个从大场景视频中重建数百人3D姿态、位置和形状的首个框架，采用粗到细的群体引导运动优化策略，结合VAE运动先验和异步运动一致性损失，解决了遮挡和时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法从静态图像重建3D人群缺乏时间一致性，无法有效处理遮挡问题，需要开发能够从视频中重建动态人群的框架。

Method: 提出粗到细的群体引导运动优化策略，结合VAE运动先验和段级群体引导优化，利用异步运动一致性损失(AMC)让未遮挡运动段指导遮挡段的恢复。

Result: 实验结果表明该方法在大场景动态人群重建任务中达到最先进性能，并贡献了VirtualCrowd虚拟基准数据集。

Conclusion: DyCrowd框架能够从大场景视频中实现时空一致的3D人群重建，有效处理遮挡和时间同步问题，为动态人群分析提供了有效解决方案。

Abstract: 3D reconstruction of dynamic crowds in large scenes has become increasingly
important for applications such as city surveillance and crowd analysis.
However, current works attempt to reconstruct 3D crowds from a static image,
causing a lack of temporal consistency and inability to alleviate the typical
impact caused by occlusions. In this paper, we propose DyCrowd, the first
framework for spatio-temporally consistent 3D reconstruction of hundreds of
individuals' poses, positions and shapes from a large-scene video. We design a
coarse-to-fine group-guided motion optimization strategy for occlusion-robust
crowd reconstruction in large scenes. To address temporal instability and
severe occlusions, we further incorporate a VAE (Variational Autoencoder)-based
human motion prior along with a segment-level group-guided optimization. The
core of our strategy leverages collective crowd behavior to address long-term
dynamic occlusions. By jointly optimizing the motion sequences of individuals
with similar motion segments and combining this with the proposed Asynchronous
Motion Consistency (AMC) loss, we enable high-quality unoccluded motion
segments to guide the motion recovery of occluded ones, ensuring robust and
plausible motion recovery even in the presence of temporal desynchronization
and rhythmic inconsistencies. Additionally, in order to fill the gap of no
existing well-annotated large-scene video dataset, we contribute a virtual
benchmark dataset, VirtualCrowd, for evaluating dynamic crowd reconstruction
from large-scene videos. Experimental results demonstrate that the proposed
method achieves state-of-the-art performance in the large-scene dynamic crowd
reconstruction task. The code and dataset will be available for research
purposes.

</details>


### [236] [Stable Diffusion-Based Approach for Human De-Occlusion](https://arxiv.org/abs/2508.12663)
*Seung Young Noh,Ju Yong Chang*

Main category: cs.CV

TL;DR: 一种两阶段演进式人体去遮蔽方法，第一阶段用温巡扩散模型完成人体遮蔽区域的掩码，第二阶段在掩码指导下用Stable Diffusion生成RGB图像，并通过人体特征提取和解码器微调提升质量。


<details>
  <summary>Details</summary>
Motivation: 人体遮蔽问题在计算机视觉中具有重要意义，但现有深度学习模型在准确预测遮蔽区域时仍面临挑战。需要一种能够在严重遮蔽情况下恢复人体结构和外观的有效方法。

Method: 采用两阶段演进式方法：1）掩码完成阶段：结合温巡扩散人体先验知识和遮蔽关节热力图来完成人体掩码；2）RGB完成阶段：以掩码为条件，使用Stable Diffusion生成RGB图像，并添加人体特征提取（通过VQA模型和CLIP编码器），对解码器进行微调以减少可见区域的像素水平退化。

Result: 该方法能够在严重遮蔽情况下有效地重建人体外观，在掩码完成和RGB完成两个任务上都较现有方法更优。甚至可以提升下游任务的性能，如2D姿势估计和3D人体重建。

Conclusion: 这种两阶段演进式人体去遮蔽方法通过结合温巡扩散人体先验知识、明确空间线索和人体特征提取，有效解决了严重遮蔽下的人体恢复问题，为人体相关计算机视视觉任务提供了有效支持。

Abstract: Humans can infer the missing parts of an occluded object by leveraging prior
knowledge and visible cues. However, enabling deep learning models to
accurately predict such occluded regions remains a challenging task.
De-occlusion addresses this problem by reconstructing both the mask and RGB
appearance. In this work, we focus on human de-occlusion, specifically
targeting the recovery of occluded body structures and appearances. Our
approach decomposes the task into two stages: mask completion and RGB
completion. The first stage leverages a diffusion-based human body prior to
provide a comprehensive representation of body structure, combined with
occluded joint heatmaps that offer explicit spatial cues about missing regions.
The reconstructed amodal mask then serves as a conditioning input for the
second stage, guiding the model on which areas require RGB reconstruction. To
further enhance RGB generation, we incorporate human-specific textual features
derived using a visual question answering (VQA) model and encoded via a CLIP
encoder. RGB completion is performed using Stable Diffusion, with decoder
fine-tuning applied to mitigate pixel-level degradation in visible regions -- a
known limitation of prior diffusion-based de-occlusion methods caused by latent
space transformations. Our method effectively reconstructs human appearances
even under severe occlusions and consistently outperforms existing methods in
both mask and RGB completion. Moreover, the de-occluded images generated by our
approach can improve the performance of downstream human-centric tasks, such as
2D pose estimation and 3D human reconstruction. The code will be made publicly
available.

</details>


### [237] [WP-CLIP: Leveraging CLIP to Predict Wölfflin's Principles in Visual Art](https://arxiv.org/abs/2508.12668)
*Abhijay Ghildyal,Li-Yun Wang,Feng Liu*

Main category: cs.CV

TL;DR: 本文研究使用CLIP视觉语言模型来预测Wölfflin的五个艺术风格原则，发现预训练CLIP无法捕捉这些细微风格特征，通过微调后开发的WP-CLIP模型在GAN生成画作和Pandora-18K数据集上表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有指标无法有效预测Wölfflin的五个艺术风格原则，而视觉语言模型在评估抽象图像属性方面展现出潜力，需要开发能够理解绘画中颜色、构图和主题选择等关键元素的度量方法。

Method: 在真实艺术图像的标注数据集上微调预训练的CLIP模型，为每个Wölfflin原则预测分数，开发出WP-CLIP模型。

Result: 微调后的WP-CLIP模型在GAN生成画作和Pandora-18K艺术数据集上能够泛化到不同的艺术风格，成功预测Wölfflin的五个原则。

Conclusion: 视觉语言模型在自动化艺术分析方面具有巨大潜力，通过适当的微调可以捕捉和理解复杂的艺术风格特征。

Abstract: W\"olfflin's five principles offer a structured approach to analyzing
stylistic variations for formal analysis. However, no existing metric
effectively predicts all five principles in visual art. Computationally
evaluating the visual aspects of a painting requires a metric that can
interpret key elements such as color, composition, and thematic choices. Recent
advancements in vision-language models (VLMs) have demonstrated their ability
to evaluate abstract image attributes, making them promising candidates for
this task. In this work, we investigate whether CLIP, pre-trained on
large-scale data, can understand and predict W\"olfflin's principles. Our
findings indicate that it does not inherently capture such nuanced stylistic
elements. To address this, we fine-tune CLIP on annotated datasets of real art
images to predict a score for each principle. We evaluate our model, WP-CLIP,
on GAN-generated paintings and the Pandora-18K art dataset, demonstrating its
ability to generalize across diverse artistic styles. Our results highlight the
potential of VLMs for automated art analysis.

</details>


### [238] [Refine-and-Contrast: Adaptive Instance-Aware BEV Representations for Multi-UAV Collaborative Object Detection](https://arxiv.org/abs/2508.12684)
*Zhongyao Li,Peirui Cheng,Liangjin Zhao,Chen Chen,Yundu Li,Zhechao Wang,Xue Yang,Xian Sun,Zhirui Wang*

Main category: cs.CV

TL;DR: AdaBEV是一个新颖的多无人机协同3D检测框架，通过自适应实例感知的BEV表示学习，在保持低分辨率BEV输入的同时实现了优异的精度-计算权衡。


<details>
  <summary>Details</summary>
Motivation: 多无人机协同3D检测虽然能通过融合多视角观测提供准确和鲁棒的感知，但在资源受限的无人机平台上计算效率面临挑战。现有方法平等对待所有BEV网格，导致计算效率低下。

Method: 提出Box-Guided Refinement Module (BG-RM) 仅使用2D监督和空间细分优化前景实例相关的BEV网格，以及Instance-Background Contrastive Learning (IBCL) 通过对比学习增强前景和背景特征的可区分性。

Result: 在Air-Co-Pred数据集上的大量实验表明，AdaBEV在不同模型规模下都实现了优异的精度-计算权衡，在低分辨率下优于其他最先进方法，接近上限性能且计算开销可忽略。

Conclusion: AdaBEV通过自适应的实例感知BEV表示学习，有效解决了多无人机协同3D检测中的计算效率问题，为资源受限平台上的高效感知提供了可行方案。

Abstract: Multi-UAV collaborative 3D detection enables accurate and robust perception
by fusing multi-view observations from aerial platforms, offering significant
advantages in coverage and occlusion handling, while posing new challenges for
computation on resource-constrained UAV platforms. In this paper, we present
AdaBEV, a novel framework that learns adaptive instance-aware BEV
representations through a refine-and-contrast paradigm. Unlike existing methods
that treat all BEV grids equally, AdaBEV introduces a Box-Guided Refinement
Module (BG-RM) and an Instance-Background Contrastive Learning (IBCL) to
enhance semantic awareness and feature discriminability. BG-RM refines only BEV
grids associated with foreground instances using 2D supervision and spatial
subdivision, while IBCL promotes stronger separation between foreground and
background features via contrastive learning in BEV space. Extensive
experiments on the Air-Co-Pred dataset demonstrate that AdaBEV achieves
superior accuracy-computation trade-offs across model scales, outperforming
other state-of-the-art methods at low resolutions and approaching upper bound
performance while maintaining low-resolution BEV inputs and negligible
overhead.

</details>


### [239] [TTA-DAME: Test-Time Adaptation with Domain Augmentation and Model Ensemble for Dynamic Driving Conditions](https://arxiv.org/abs/2508.12690)
*Dongjae Jeon,Taeheon Kim,Seongwon Cho,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: TTA-DAME方法通过源域数据增强、域鉴别器和专用域检测器来处理测试时适应中的动态域偏移问题，特别是在驾驶场景中的天气和昼夜变化，通过多检测器集成和NMS进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界驾驶场景中频繁发生的天气域偏移问题，特别是在动态变化的测试时适应(TTA)挑战中，需要模型能够动态适应并保持最优性能。

Method: 利用源域数据增强到目标域，引入域鉴别器和专用域检测器来缓解剧烈域偏移（特别是白天到夜晚的变化），训练多个检测器并通过非极大值抑制(NMS)整合预测结果。

Result: 在SHIFT基准测试上显示出显著性能提升，验证了方法的有效性。

Conclusion: TTA-DAME方法成功解决了动态域偏移问题，特别是在驾驶场景的天气和昼夜变化适应方面表现出色。

Abstract: Test-time Adaptation (TTA) poses a challenge, requiring models to dynamically
adapt and perform optimally on shifting target domains. This task is
particularly emphasized in real-world driving scenes, where weather domain
shifts occur frequently. To address such dynamic changes, our proposed method,
TTA-DAME, leverages source domain data augmentation into target domains.
Additionally, we introduce a domain discriminator and a specialized domain
detector to mitigate drastic domain shifts, especially from daytime to
nighttime conditions. To further improve adaptability, we train multiple
detectors and consolidate their predictions through Non-Maximum Suppression
(NMS). Our empirical validation demonstrates the effectiveness of our method,
showing significant performance enhancements on the SHIFT Benchmark.

</details>


### [240] [Multi-Level Knowledge Distillation and Dynamic Self-Supervised Learning for Continual Learning](https://arxiv.org/abs/2508.12692)
*Taeheon Kim,San Kim,Minhyuk Seo,Dongjae Jeon,Wonje Jeong,Jonghyun Choi*

Main category: cs.CV

TL;DR: 这篇论文提出了两个组件来解决带有重复类别的类增量学习问题：多级知识蒸馈(MLKD)和动态自监督串损失(SSL)，利用外部未标注数据提高模型的稳定性和可塑性


<details>
  <summary>Details</summary>
Motivation: 传统类增量学习假设每个任务都包含新类别，而实际情况中之前训练过的类别可能在未来任务中重复出现。同时可以容易获取大量未标注外部数据

Method: 1）多级知识蒸馈(MLKD)：从多个之前模型中蒸馈知识，包括特征和逻辑值，以保持多样化的历史知识
2）动态自监督串损失(SSL)：利用未标注数据加速新类别学习，通过动态权重保持主要任务的训练重点

Result: 提出的两个组件在CIR设置下显著提高了性能，在CVPR第5届CLVISION挑战赛中获得第2名

Conclusion: 通过多级知识蒸馈和动态自监督串损失的结合，能够有效利用外部未标注数据来同时保持模型的稳定性和可塑性，为带有重复类别的增量学习问题提供了有效解决方案

Abstract: Class-incremental with repetition (CIR), where previously trained classes
repeatedly introduced in future tasks, is a more realistic scenario than the
traditional class incremental setup, which assumes that each task contains
unseen classes. CIR assumes that we can easily access abundant unlabeled data
from external sources, such as the Internet. Therefore, we propose two
components that efficiently use the unlabeled data to ensure the high stability
and the plasticity of models trained in CIR setup. First, we introduce
multi-level knowledge distillation (MLKD) that distills knowledge from multiple
previous models across multiple perspectives, including features and logits, so
the model can maintain much various previous knowledge. Moreover, we implement
dynamic self-supervised loss (SSL) to utilize the unlabeled data that
accelerates the learning of new classes, while dynamic weighting of SSL keeps
the focus of training to the primary task. Both of our proposed components
significantly improve the performance in CIR setup, achieving 2nd place in the
CVPR 5th CLVISION Challenge.

</details>


### [241] [Neural Rendering for Sensor Adaptation in 3D Object Detection](https://arxiv.org/abs/2508.12695)
*Felix Embacher,David Holtz,Jonas Uhrig,Marius Cordts,Markus Enzweiler*

Main category: cs.CV

TL;DR: 这篇论文研究了自主汽车不同相机传感器配置导致的跨传感器域间间隔问题，提出了CamShift数据集和一种基于神经渲染的数据驱动传感器适配方案来减轻该问题的影响。


<details>
  <summary>Details</summary>
Motivation: 自主汽车的相机传感器配置因车辆类型不同而异，导致在一种传感器配置上训练的感知模型在其他配置上性能漏洞，这称为跨传感器域间间隔问题。

Method: 创建了CamShift数据集（受nuScenes启发在CARLA中制作）来模拟子紧凑型车辆和SUV之间的传感器差异。提出了一种基于神经渲染的数据驱动传感器适配流水线，可以将整个数据集转换以匹配不同相机传感器配置。

Result: 实验表明：1）基于密雅上下视图表示且有向后投影的模型架构（如BEVFormer）对不同传感器配置最为稳健；2）提出的神经渲染适配方案能大幅提升所有调研的3D物体检测器的性能，大幅减轻跨传感器域间间隔影响。

Conclusion: 这项研究为解决自主汽车不同传感器配置导致的域适配问题提供了有效方案，通过神经渲染技术实现数据集的跨车辆重用，减少了重新收集数据的需求。

Abstract: Autonomous vehicles often have varying camera sensor setups, which is
inevitable due to restricted placement options for different vehicle types.
Training a perception model on one particular setup and evaluating it on a new,
different sensor setup reveals the so-called cross-sensor domain gap, typically
leading to a degradation in accuracy. In this paper, we investigate the impact
of the cross-sensor domain gap on state-of-the-art 3D object detectors. To this
end, we introduce CamShift, a dataset inspired by nuScenes and created in CARLA
to specifically simulate the domain gap between subcompact vehicles and sport
utility vehicles (SUVs). Using CamShift, we demonstrate significant
cross-sensor performance degradation, identify robustness dependencies on model
architecture, and propose a data-driven solution to mitigate the effect. On the
one hand, we show that model architectures based on a dense Bird's Eye View
(BEV) representation with backward projection, such as BEVFormer, are the most
robust against varying sensor configurations. On the other hand, we propose a
novel data-driven sensor adaptation pipeline based on neural rendering, which
can transform entire datasets to match different camera sensor setups. Applying
this approach improves performance across all investigated 3D object detectors,
mitigating the cross-sensor domain gap by a large margin and reducing the need
for new data collection by enabling efficient data reusability across vehicles
with different sensor setups. The CamShift dataset and the sensor adaptation
benchmark are available at https://dmholtz.github.io/camshift/.

</details>


### [242] [Drifting Away from Truth: GenAI-Driven News Diversity Challenges LVLM-Based Misinformation Detection](https://arxiv.org/abs/2508.12711)
*Fanxiao Li,Jiaying Wu,Tingchao Fu,Yunyun Dong,Bingbing Song,Wei Zhou*

Main category: cs.CV

TL;DR: GenAI驱动的新闻多样性导致多级漂移，显著降低了现有大型视觉语言模型在虚假信息检测中的性能，需要更鲁棒的方法


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具带来的新闻内容多样性对多模态虚假信息检测系统构成了新挑战，需要系统研究这种多样性带来的影响

Method: 构建DriftBench大规模基准测试（16,000个新闻实例，6种多样化类别），设计三个评估任务：真实性验证鲁棒性、对抗性证据污染敏感性、推理一致性分析

Result: 6个最先进的LVLM检测器性能显著下降（平均F1下降14.8%），推理轨迹不稳定，对抗性证据注入下表现更差

Conclusion: 现有MMD系统存在根本性脆弱性，在GenAI时代迫切需要更具弹性的方法

Abstract: The proliferation of multimodal misinformation poses growing threats to
public discourse and societal trust. While Large Vision-Language Models (LVLMs)
have enabled recent progress in multimodal misinformation detection (MMD), the
rise of generative AI (GenAI) tools introduces a new challenge: GenAI-driven
news diversity, characterized by highly varied and complex content. We show
that this diversity induces multi-level drift, comprising (1) model-level
misperception drift, where stylistic variations disrupt a model's internal
reasoning, and (2) evidence-level drift, where expression diversity degrades
the quality or relevance of retrieved external evidence. These drifts
significantly degrade the robustness of current LVLM-based MMD systems. To
systematically study this problem, we introduce DriftBench, a large-scale
benchmark comprising 16,000 news instances across six categories of
diversification. We design three evaluation tasks: (1) robustness of truth
verification under multi-level drift; (2) susceptibility to adversarial
evidence contamination generated by GenAI; and (3) analysis of reasoning
consistency across diverse inputs. Experiments with six state-of-the-art
LVLM-based detectors show substantial performance drops (average F1 -14.8%) and
increasingly unstable reasoning traces, with even more severe failures under
adversarial evidence injection. Our findings uncover fundamental
vulnerabilities in existing MMD systems and suggest an urgent need for more
resilient approaches in the GenAI era.

</details>


### [243] [Real-Time Sign Language Gestures to Speech Transcription using Deep Learning](https://arxiv.org/abs/2508.12713)
*Brandone Fonya*

Main category: cs.CV

TL;DR: 一种基于深度学习的实时辅助技术，通过CNN网络识别手语手势并转换为文本和语音，提高听力和语言障碍者的沟通能力


<details>
  <summary>Details</summary>
Motivation: 解决听力和语言障碍者在日常生活中遇到的沟通困难，提高他们的自主性和社会融入度

Method: 使用卷积神经网络(CNN)培训在Sign Language MNIST数据集上，通过摄像头实时捕获手势，然后进行类别识别，最后通过文本转语音技术转换为语音输出

Result: 系统表现出高准确率和稳定的实时性能，虽然存在一定的延迟，但具有实用性和可靠性

Conclusion: 该系统作为一种可访问、可靠且易于使用的工具，有效地促进了手语使用者在多样化社会环境中的沟通和融入

Abstract: Communication barriers pose significant challenges for individuals with
hearing and speech impairments, often limiting their ability to effectively
interact in everyday environments. This project introduces a real-time
assistive technology solution that leverages advanced deep learning techniques
to translate sign language gestures into textual and audible speech. By
employing convolution neural networks (CNN) trained on the Sign Language MNIST
dataset, the system accurately classifies hand gestures captured live via
webcam. Detected gestures are instantaneously translated into their
corresponding meanings and transcribed into spoken language using
text-to-speech synthesis, thus facilitating seamless communication.
Comprehensive experiments demonstrate high model accuracy and robust real-time
performance with some latency, highlighting the system's practical
applicability as an accessible, reliable, and user-friendly tool for enhancing
the autonomy and integration of sign language users in diverse social settings.

</details>


### [244] [Single-Reference Text-to-Image Manipulation with Dual Contrastive Denoising Score](https://arxiv.org/abs/2508.12718)
*Syed Muhmmad Israr,Feng Zhao*

Main category: cs.CV

TL;DR: 一种基于对比学习的双对比去噪分数框架，用于实现文本到图像模型的真实图像编辑，解决了传统方法在提示语准确性和区域保持方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像生成模型虽然能生成高质量图像，但在真实图像编辑时面临两大挑战：用户难以准确描述图像细节的提示语，以及现有方法在修改特定区域时容易导致不期望的全局变化。

Method: 提出双对比去噪分数框架，采用简单有效的双对比损失，利用潜在扩散模型中自注意力层的中间表征的丰富空间信息，无需附加网络。

Result: 方法能同时实现灵活的内容修改和结构保持，支持零检知图像到图像转换，通过实验证明在真实图像编辑中超过现有方法。

Conclusion: 该框架能够直接利用预训练的文本到图像扩散模型而无需进一步训练，有效解决了真实图像编辑中的关键挑战。

Abstract: Large-scale text-to-image generative models have shown remarkable ability to
synthesize diverse and high-quality images. However, it is still challenging to
directly apply these models for editing real images for two reasons. First, it
is difficult for users to come up with a perfect text prompt that accurately
describes every visual detail in the input image. Second, while existing models
can introduce desirable changes in certain regions, they often dramatically
alter the input content and introduce unexpected changes in unwanted regions.
To address these challenges, we present Dual Contrastive Denoising Score, a
simple yet powerful framework that leverages the rich generative prior of
text-to-image diffusion models. Inspired by contrastive learning approaches for
unpaired image-to-image translation, we introduce a straightforward dual
contrastive loss within the proposed framework. Our approach utilizes the
extensive spatial information from the intermediate representations of the
self-attention layers in latent diffusion models without depending on auxiliary
networks. Our method achieves both flexible content modification and structure
preservation between input and output images, as well as zero-shot
image-to-image translation. Through extensive experiments, we show that our
approach outperforms existing methods in real image editing while maintaining
the capability to directly utilize pretrained text-to-image diffusion models
without further training.

</details>


### [245] [Quantifying and Alleviating Co-Adaptation in Sparse-View 3D Gaussian Splatting](https://arxiv.org/abs/2508.12720)
*Kangjie Chen,Yingji Zhong,Zhihao Li,Jiaqi Lin,Youyu Chen,Minghan Qin,Haoqian Wang*

Main category: cs.CV

TL;DR: 3DGS在稀疏视角下会出现外观伪影，研究发现这是由于高斯函数过度纠缠(co-adaptation)导致的。提出了CA指标量化纠缠程度，并提出了两种轻量级策略来缓解这个问题。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅(3DGS)在密集视角下表现优异，但在稀疏视角场景中，虽然训练视角渲染效果真实，但在新视角下会出现外观伪影。本文旨在探究这些伪影的根源。

Method: 提出了Co-Adaptation Score (CA)指标来量化高斯函数之间的纠缠程度。基于分析提出了两种轻量级策略：1) 随机高斯丢弃；2) 对不透明度注入乘性噪声。这些策略都是即插即用的。

Result: 分析发现高斯函数的纠缠程度随着训练视角数量的增加而自然缓解。提出的两种策略在各种方法和基准测试中都验证了有效性。

Conclusion: 对co-adaptation效应的深入理解将有助于社区更全面地理解稀疏视角3DGS，提出的轻量级策略能有效缓解外观伪影问题。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated impressive performance in novel
view synthesis under dense-view settings. However, in sparse-view scenarios,
despite the realistic renderings in training views, 3DGS occasionally manifests
appearance artifacts in novel views. This paper investigates the appearance
artifacts in sparse-view 3DGS and uncovers a core limitation of current
approaches: the optimized Gaussians are overly-entangled with one another to
aggressively fit the training views, which leads to a neglect of the real
appearance distribution of the underlying scene and results in appearance
artifacts in novel views. The analysis is based on a proposed metric, termed
Co-Adaptation Score (CA), which quantifies the entanglement among Gaussians,
i.e., co-adaptation, by computing the pixel-wise variance across multiple
renderings of the same viewpoint, with different random subsets of Gaussians.
The analysis reveals that the degree of co-adaptation is naturally alleviated
as the number of training views increases. Based on the analysis, we propose
two lightweight strategies to explicitly mitigate the co-adaptation in
sparse-view 3DGS: (1) random gaussian dropout; (2) multiplicative noise
injection to the opacity. Both strategies are designed to be plug-and-play, and
their effectiveness is validated across various methods and benchmarks. We hope
that our insights into the co-adaptation effect will inspire the community to
achieve a more comprehensive understanding of sparse-view 3DGS.

</details>


### [246] [Frequency-Driven Inverse Kernel Prediction for Single Image Defocus Deblurring](https://arxiv.org/abs/2508.12736)
*Ying Zhang,Xiongxin Tang,Chongyi Li,Qiao Chen,Yuquan Wu*

Main category: cs.CV

TL;DR: 频域驱动的逆内核预测网络(FDIKP)通过双分支逆内核预测策略和位置适配卷积，在单图散焦去模糊任务中实现更准确的核估计和更好的去模糊效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法依靠空间特征进行核估计，但在严重模糊区域性能会降低，因为这些区域缺乏本地高频细节。频域基础表示能够提供更好的结构可识别性。

Method: 提出FDIKP网络，包含双分支逆内核预测策略(DIKP)、位置适配卷积(PAC)和双域尺度递归模块(DSRM)，通过频域表示增强核建模的结构可识别性。

Result: 广泛实验证明该方法在单图散焦去模糊任务上超过现有方法，实现了更准确的核估计和更好的去模糊效果。

Conclusion: 频域基础表示能够有效提升散焦模糊核建模的性能，提出的FDIKP网络通过频域驱动的逆内核预测和适配性卷积技术，在单图散焦去模糊任务中取得了显著的性能提升。

Abstract: Single image defocus deblurring aims to recover an all-in-focus image from a
defocus counterpart, where accurately modeling spatially varying blur kernels
remains a key challenge. Most existing methods rely on spatial features for
kernel estimation, but their performance degrades in severely blurry regions
where local high-frequency details are missing. To address this, we propose a
Frequency-Driven Inverse Kernel Prediction network (FDIKP) that incorporates
frequency-domain representations to enhance structural identifiability in
kernel modeling. Given the superior discriminative capability of the frequency
domain for blur modeling, we design a Dual-Branch Inverse Kernel Prediction
(DIKP) strategy that improves the accuracy of kernel estimation while
maintaining stability. Moreover, considering the limited number of predicted
inverse kernels, we introduce a Position Adaptive Convolution (PAC) to enhance
the adaptability of the deconvolution process. Finally, we propose a
Dual-Domain Scale Recurrent Module (DSRM) to fuse deconvolution results and
progressively improve deblurring quality from coarse to fine. Extensive
experiments demonstrate that our method outperforms existing approaches. Code
will be made publicly available.

</details>


### [247] [DCSCR: A Class-Specific Collaborative Representation based Network for Image Set Classification](https://arxiv.org/abs/2508.12745)
*Xizhan Gao,Wei Hu*

Main category: cs.CV

TL;DR: 本文提出了一种深度类别特定协同表示网络（DCSCR），用于解决少样本图像集分类问题，结合了传统方法和深度模型的优势。


<details>
  <summary>Details</summary>
Motivation: 图像集分类中的两个关键挑战是如何学习有效特征表示和探索不同集合之间的相似性。现有方法或者忽略特征学习，或者无法在测量集距离时自适应地调整特征，导致少样本情况下性能有限。

Method: 提出DCSCR网络，包含三个模块：全卷积深度特征提取器、全局特征学习模块和类别特定协同表示基于的距离学习模块。前两个模块学习帧级特征表示，后者学习概念级特征表示和集距离相似性。

Result: 在多个知名的少样本图像集分类数据集上进行了广泛实验，结果表明方法比现有最先进算法更有效。

Conclusion: DCSCR能够同时学习帧级和概念级特征表示，并通过新的CSCR对比损失函数自适应地获取集距离相似性，在少样本图像集分类任务中表现優异。

Abstract: Image set classification (ISC), which can be viewed as a task of comparing
similarities between sets consisting of unordered heterogeneous images with
variable quantities and qualities, has attracted growing research attention in
recent years. How to learn effective feature representations and how to explore
the similarities between different image sets are two key yet challenging
issues in this field. However, existing traditional ISC methods classify image
sets based on raw pixel features, ignoring the importance of feature learning.
Existing deep ISC methods can learn deep features, but they fail to adaptively
adjust the features when measuring set distances, resulting in limited
performance in few-shot ISC. To address the above issues, this paper combines
traditional ISC methods with deep models and proposes a novel few-shot ISC
approach called Deep Class-specific Collaborative Representation (DCSCR)
network to simultaneously learn the frame- and concept-level feature
representations of each image set and the distance similarities between
different sets. Specifically, DCSCR consists of a fully convolutional deep
feature extractor module, a global feature learning module, and a
class-specific collaborative representation-based metric learning module. The
deep feature extractor and global feature learning modules are used to learn
(local and global) frame-level feature representations, while the
class-specific collaborative representation-based metric learning module is
exploit to adaptively learn the concept-level feature representation of each
image set and thus obtain the distance similarities between different sets by
developing a new CSCR-based contrastive loss function. Extensive experiments on
several well-known few-shot ISC datasets demonstrate the effectiveness of the
proposed method compared with some state-of-the-art image set classification
algorithms.

</details>


### [248] [D2-Mamba: Dual-Scale Fusion and Dual-Path Scanning with SSMs for Shadow Removal](https://arxiv.org/abs/2508.12750)
*Linhao Li,Boya Jin,Zizhe Li,Lanqing Guo,Hao Cheng,Bo Li,Yongfeng Dong*

Main category: cs.CV

TL;DR: 提出一种基于Mamba的双谱融合和双路扫描等网络，通过选择性传播上下文信息和适应性模型区域特定变换，在阴影移除任务中显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 阴影移除任务中，阴影区域的修复变换与良好照明区域存在显著差异，统一的修复策略效果不佳。需要有效整合非本地上下文线索和适应性模型区域特定变换。

Method: 设计了双谱融合Mamba块(DFMB)提升多尺度特征表征，通过融合原始特征与低分辨率特征减少边界偏差。双路Mamba组(DPMG)通过水平扫描捕获全局特征，采用掩码感知适应扫描策略改善结构连续性和细粒度区域模型。

Result: 在阴影移除标准测试集上，方法显著超越了现有的最先进方法。

Conclusion: 提出的Mamba基网络通过双谱融合和双路扫描机制，能够有效地选择性传播上下文信息并适应性地模型区域特定变换，在阴影移除任务中取得了显著成效。

Abstract: Shadow removal aims to restore images that are partially degraded by shadows,
where the degradation is spatially localized and non-uniform. Unlike general
restoration tasks that assume global degradation, shadow removal can leverage
abundant information from non-shadow regions for guidance. However, the
transformation required to correct shadowed areas often differs significantly
from that of well-lit regions, making it challenging to apply uniform
correction strategies. This necessitates the effective integration of non-local
contextual cues and adaptive modeling of region-specific transformations. To
this end, we propose a novel Mamba-based network featuring dual-scale fusion
and dual-path scanning to selectively propagate contextual information based on
transformation similarity across regions. Specifically, the proposed Dual-Scale
Fusion Mamba Block (DFMB) enhances multi-scale feature representation by fusing
original features with low-resolution features, effectively reducing boundary
artifacts. The Dual-Path Mamba Group (DPMG) captures global features via
horizontal scanning and incorporates a mask-aware adaptive scanning strategy,
which improves structural continuity and fine-grained region modeling.
Experimental results demonstrate that our method significantly outperforms
existing state-of-the-art approaches on shadow removal benchmarks.

</details>


### [249] [CLAIRE-DSA: Fluoroscopic Image Classification for Quality Assurance of Computer Vision Pipelines in Acute Ischemic Stroke](https://arxiv.org/abs/2508.12755)
*Cristo J. van den Berg,Frank G. te Nijenhuis,Mirre J. Blaauboer,Daan T. W. van Erp,Carlijn M. Keppels,Matthijs van der Sluijs,Bob Roozenbeek,Wim van Zwam,Sandra Cornelissen,Danny Ruijters,Ruisheng Su,Theo van Walsum*

Main category: cs.CV

TL;DR: CLAIRE-DSA是一个基于深度学习的框架，用于在急性缺血性卒中机械取栓术中自动分类数字减影血管造影图像的关键属性，显著提升下游分割任务的成功率


<details>
  <summary>Details</summary>
Motivation: 计算机视觉模型在机械取栓术中辅助应用时，图像质量差会严重影响性能表现，需要开发自动化的图像质量评估工具

Method: 使用预训练的ResNet骨干网络进行微调，训练独立的分类器来预测9个图像属性（如对比剂存在、投影角度、运动伪影严重程度等），基于1758张标注的荧光透视最小强度投影图像

Result: 模型在所有标签上都表现出色，ROC-AUC范围0.91-0.98，精确度范围0.70-1.00。在分割任务中，过滤低质量图像后分割成功率从42%提升至69%

Conclusion: CLAIRE-DSA作为自动化工具在急性缺血性卒中患者的DSA序列中准确分类图像属性方面显示出强大潜力，支持临床和研究应用中的图像标注和质量控制

Abstract: Computer vision models can be used to assist during mechanical thrombectomy
(MT) for acute ischemic stroke (AIS), but poor image quality often degrades
performance. This work presents CLAIRE-DSA, a deep learning--based framework
designed to categorize key image properties in minimum intensity projections
(MinIPs) acquired during MT for AIS, supporting downstream quality control and
workflow optimization. CLAIRE-DSA uses pre-trained ResNet backbone models,
fine-tuned to predict nine image properties (e.g., presence of contrast,
projection angle, motion artefact severity). Separate classifiers were trained
on an annotated dataset containing $1,758$ fluoroscopic MinIPs. The model
achieved excellent performance on all labels, with ROC-AUC ranging from $0.91$
to $0.98$, and precision ranging from $0.70$ to $1.00$. The ability of
CLAIRE-DSA to identify suitable images was evaluated on a segmentation task by
filtering poor quality images and comparing segmentation performance on
filtered and unfiltered datasets. Segmentation success rate increased from
$42%$ to $69%$, $p < 0.001$. CLAIRE-DSA demonstrates strong potential as an
automated tool for accurately classifying image properties in DSA series of
acute ischemic stroke patients, supporting image annotation and quality control
in clinical and research applications. Source code is available at
https://gitlab.com/icai-stroke-lab/wp3_neurointerventional_ai/claire-dsa.

</details>


### [250] [Harnessing Group-Oriented Consistency Constraints for Semi-Supervised Semantic Segmentation in CdZnTe Semiconductors](https://arxiv.org/abs/2508.12766)
*Peihao Li,Yan Fang,Man Liu,Huihui Bai,Anhong Wang,Yunchao Wei,Yao Zhao*

Main category: cs.CV

TL;DR: 这篇论文提出了一种人呐受启的组内一致性增强框架(ICAF)，专门解决CdZnTe半导体图像中因低对比度缺陷边界导致的标注挑战，通过组视图一致性约束和伪标签美化提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 因为CdZnTe半导体图像存在低对比度缺陷边界的特点，需要注释者参考多个视图来进行标注，这种"多对一"关系使得传统半监督分割方法无法有效处理，容易在低对比度区域产生错误累积和确认偏见。

Method: 提出了组内一致性增强框架(ICAF)，包括：1)组内视图采样(IVS)基础方法；2)伪标签美化网络(PCN)，包含视图增强模块(VAM)通过聚合多视图动态合成边界敏感视图，以及视图美化模块(VCM)通过信息交互强化显著区域并减少噪声。

Result: 在CdZnTe数据集上仅使用2%的组注释数据(5‰)，使用DeepLabV3+和ResNet-101背榜模型，达到了70.6%的mIoU指标。

Conclusion: 该研究从组角度重新考虑了半监督语义分割流程，通过模仿人类注释行为的方式，有效解决了CdZnTe材料图像中的低对比度缺陷边界标注问题，为类似的"多对一"关系数据集提供了一种有效的解决方案。

Abstract: Labeling Cadmium Zinc Telluride (CdZnTe) semiconductor images is challenging
due to the low-contrast defect boundaries, necessitating annotators to
cross-reference multiple views. These views share a single ground truth (GT),
forming a unique ``many-to-one'' relationship. This characteristic renders
advanced semi-supervised semantic segmentation (SSS) methods suboptimal, as
they are generally limited by a ``one-to-one'' relationship, where each image
is independently associated with its GT. Such limitation may lead to error
accumulation in low-contrast regions, further exacerbating confirmation bias.
To address this issue, we revisit the SSS pipeline from a group-oriented
perspective and propose a human-inspired solution: the Intra-group Consistency
Augmentation Framework (ICAF). First, we experimentally validate the inherent
consistency constraints within CdZnTe groups, establishing a group-oriented
baseline using the Intra-group View Sampling (IVS). Building on this insight,
we introduce the Pseudo-label Correction Network (PCN) to enhance consistency
representation, which consists of two key modules. The View Augmentation Module
(VAM) improves boundary details by dynamically synthesizing a boundary-aware
view through the aggregation of multiple views. In the View Correction Module
(VCM), this synthesized view is paired with other views for information
interaction, effectively emphasizing salient regions while minimizing noise.
Extensive experiments demonstrate the effectiveness of our solution for CdZnTe
materials. Leveraging DeepLabV3+ with a ResNet-101 backbone as our segmentation
model, we achieve a 70.6\% mIoU on the CdZnTe dataset using only 2
group-annotated data (5\textperthousand). The code is available at
\href{https://github.com/pipixiapipi/ICAF}{https://github.com/pipixiapipi/ICAF}.

</details>


### [251] [SocialTrack: Multi-Object Tracking in Complex Urban Traffic Scenes Inspired by Social Behavior](https://arxiv.org/abs/2508.12777)
*Wenguang Tao,Xiaotian Wang,Tian Yan,Jie Yan,Guodong Li,Kun Bai*

Main category: cs.CV

TL;DR: SocialTrack是一个针对无人机视角下多目标跟踪的框架，通过多尺度特征增强、速度自适应卡尔曼滤波、群体运动补偿和时空记忆预测等技术，显著提升了复杂城市交通环境中小目标的跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 无人机视角下的多目标跟踪在智能交通系统分析中具有重要价值，但面临小目标尺度变化、遮挡、非线性交叉运动和运动模糊等挑战，需要开发更稳定和准确的跟踪方法。

Method: 提出SocialTrack框架，包含：1）多尺度特征增强的小目标检测器；2）速度自适应卡尔曼滤波(VACKF)用于轨迹预测；3）群体运动补偿策略(GMCS)建模社会群体运动先验；4）时空记忆预测(STMP)利用历史轨迹信息预测未来状态。

Result: 在UAVDT和MOT17数据集上的实验表明，SocialTrack在多个关键指标上优于现有最先进方法，特别是在MOTA和IDF1等核心性能指标上有显著提升。

Conclusion: SocialTrack框架具有优异的鲁棒性和适应性，且高度模块化和兼容，可与现有跟踪器无缝集成以进一步提升性能，为解决复杂无人机视角下的多目标跟踪问题提供了有效解决方案。

Abstract: As a key research direction in the field of multi-object tracking (MOT),
UAV-based multi-object tracking has significant application value in the
analysis and understanding of urban intelligent transportation systems.
However, in complex UAV perspectives, challenges such as small target scale
variations, occlusions, nonlinear crossing motions, and motion blur severely
hinder the stability of multi-object tracking. To address these challenges,
this paper proposes a novel multi-object tracking framework, SocialTrack, aimed
at enhancing the tracking accuracy and robustness of small targets in complex
urban traffic environments. The specialized small-target detector enhances the
detection performance by employing a multi-scale feature enhancement mechanism.
The Velocity Adaptive Cubature Kalman Filter (VACKF) improves the accuracy of
trajectory prediction by incorporating a velocity dynamic modeling mechanism.
The Group Motion Compensation Strategy (GMCS) models social group motion priors
to provide stable state update references for low-quality tracks, significantly
improving the target association accuracy in complex dynamic environments.
Furthermore, the Spatio-Temporal Memory Prediction (STMP) leverages historical
trajectory information to predict the future state of low-quality tracks,
effectively mitigating identity switching issues. Extensive experiments on the
UAVDT and MOT17 datasets demonstrate that SocialTrack outperforms existing
state-of-the-art (SOTA) methods across several key metrics. Significant
improvements in MOTA and IDF1, among other core performance indicators,
highlight its superior robustness and adaptability. Additionally, SocialTrack
is highly modular and compatible, allowing for seamless integration with
existing trackers to further enhance performance.

</details>


### [252] [Leveraging Diffusion Models for Stylization using Multiple Style Images](https://arxiv.org/abs/2508.12784)
*Dan Ruta,Abdelaziz Djelouah,Raphael Ortiz,Christopher Schroers*

Main category: cs.CV

TL;DR: 基于多样式图片的潜在温度模型风格转换方法，通过图像提示适配器和统计对齐技术，在去噪UNet的交叉注意力和自注意力层进行干预，实现了更准确的风格匹配和内容保持。


<details>
  <summary>Details</summary>
Motivation: 现有风格转换方法在准确匹配风格、支持的样式图片数量以及内容风格解耦方面仍然存在问题，需要更有效的解决方案。

Method: 利用多张样式图片来更好地表征风格特征并防止内容泄漏；设计了结合图像提示适配器和去噪过程中特征统计对齐的方法；在UNet的交叉注意力和自注意力层进行干预；使用聚类技术从大量注意力值中精炼小规模代表性特征集。

Result: 该方法在风格化任务上达到了目前最先进的结果。

Conclusion: 通过多样式图片结合图像提示适配和统计对齐技术，成功地解决了风格匹配不准、样式数量限制和内容风格耦合等问题，为风格转换领域提供了有效的解决方案。

Abstract: Recent advances in latent diffusion models have enabled exciting progress in
image style transfer. However, several key issues remain. For example, existing
methods still struggle to accurately match styles. They are often limited in
the number of style images that can be used. Furthermore, they tend to entangle
content and style in undesired ways. To address this, we propose leveraging
multiple style images which helps better represent style features and prevent
content leaking from the style images. We design a method that leverages both
image prompt adapters and statistical alignment of the features during the
denoising process. With this, our approach is designed such that it can
intervene both at the cross-attention and the self-attention layers of the
denoising UNet. For the statistical alignment, we employ clustering to distill
a small representative set of attention features from the large number of
attention values extracted from the style samples. As demonstrated in our
experimental section, the resulting method achieves state-of-the-art results
for stylization.

</details>


### [253] [Vehicle detection from GSV imagery: Predicting travel behaviour for cycling and motorcycling using Computer Vision](https://arxiv.org/abs/2508.12794)
*Kyriaki,Kokka,Rahul Goel,Ali Abbas,Kerry A. Nice,Luca Martial,SM Labib,Rihuan Ke,Carola Bibiane Schönlieb,James Woodcock*

Main category: cs.CV

TL;DR: 使用深度学习分析Google街景图像来估算全球城市的自行车和摩托车使用水平，为交通健康研究提供新的数据收集方法


<details>
  <summary>Details</summary>
Motivation: 交通方式通过影响体育活动、空气污染和伤害风险来影响健康，但全球范围内自行车和摩托车行为的比较数据缺乏

Method: 采用YOLOv4模型分析185个城市的Google街景图像（每个城市8000张图片），识别自行车和摩托车，并使用beta回归模型预测交通方式分享率

Result: 模型识别精度达89%，摩托车计数与实际使用率相关系数为0.78，自行车为0.51，预测模型R²值分别为0.614和0.612，中位绝对误差为1.3%和1.4%

Conclusion: 通过计算机视觉分析Google街景图像可以有效捐捕旅行行为数据，为传统数据源提供价值补充，尤其在数据缺乏地区具有重要意义

Abstract: Transportation influence health by shaping exposure to physical activity, air
pollution and injury risk.Comparative data on cycling and motorcycling
behaviours is scarce, particularly at a global scale.Street view imagery, such
as Google Street View (GSV), combined with computer vision, is a valuable
resource for efficiently capturing travel behaviour data.This study
demonstrates a novel approach using deep learning on street view images to
estimate cycling and motorcycling levels across diverse cities worldwide.We
utilized data from 185 global cities.The data on mode shares of cycling and
motorcycling estimated using travel surveys or censuses.We used GSV images to
detect cycles and motorcycles in sampled locations, using 8000 images per
city.The YOLOv4 model, fine-tuned using images from six cities, achieved a mean
average precision of 89% for detecting cycles and motorcycles in GSV images.A
global prediction model was developed using beta regression with city-level
mode shares as outcome, with log transformed explanatory variables of counts of
GSV-detected images with cycles and motorcycles, while controlling for
population density.We found strong correlations between GSV motorcycle counts
and motorcycle mode share (0.78) and moderate correlations between GSV cycle
counts and cycling mode share (0.51).Beta regression models predicted mode
shares with $R^2$ values of 0.614 for cycling and 0.612 for motorcycling,
achieving median absolute errors (MDAE) of 1.3% and 1.4%,
respectively.Scatterplots demonstrated consistent prediction accuracy, though
cities like Utrecht and Cali were outliers.The model was applied to 60 cities
globally for which we didn't have recent mode share data.We provided estimates
for some cities in the Middle East, Latin America and East Asia.With computer
vision, GSV images capture travel modes and activity, providing insights
alongside traditional data sources.

</details>


### [254] [Morphological classification of eclipsing binary stars using computer vision methods](https://arxiv.org/abs/2508.12802)
*Štefan Parimucha,Maksim Gabdeev,Yanna Markus,Martin Vaňko,Pavol Gajdoš*

Main category: cs.CV

TL;DR: 使用预训练的ResNet50和ViT模型，通过极坐标变换和hexbin可视化技术，对飘变双星光曲进行分类。在主要分类任务上达到94-100%准确率，但在孢点检测任务上表现异常差。


<details>
  <summary>Details</summary>
Motivation: 应对大规模天文调查中飘变双星分类的需求，提高分类效率和准确性。

Method: 采用预训练卷积神经网络和视觉Transformer模型，通过极坐标变换和hexbin可视化技术处理光曲图像，采用二级分类策略进行分离双星和过接触双星分类。

Result: 在Gaia G、I和TESS等多个通道上验证数据达到>96%准确率，在OGLE、DEBCat、WUMaCat观测数据上表现优异（94-100%），但孢点检测性能异常差。

Conclusion: 证明了计算机视觉在大规模飘变双星分类中的潜力，但孢点检测仍需进一步研究以提高稳健性。

Abstract: We present an application of computer vision methods to classify the light
curves of eclipsing binaries (EB). We have used pre-trained models based on
convolutional neural networks ($\textit{ResNet50}$) and vision transformers
($\textit{vit\_base\_patch16\_224}$), which were fine-tuned on images created
from synthetic datasets. To improve model generalisation and reduce
overfitting, we developed a novel image representation by transforming
phase-folded light curves into polar coordinates combined with hexbin
visualisation. Our hierarchical approach in the first stage classifies systems
into detached and overcontact types, and in the second stage identifies the
presence or absence of spots. The binary classification models achieved high
accuracy ($>96\%$) on validation data across multiple passbands (Gaia~$G$, $I$,
and $TESS$) and demonstrated strong performance ($>94\%$, up to $100\%$ for
$TESS$) when tested on extensive observational data from the OGLE, DEBCat, and
WUMaCat catalogues. While the primary binary classification was highly
successful, the secondary task of automated spot detection performed poorly,
revealing a significant limitation of our models for identifying subtle
photometric features. This study highlights the potential of computer vision
for EB morphological classification in large-scale surveys, but underscores the
need for further research into robust, automated spot detection.

</details>


### [255] [Next Visual Granularity Generation](https://arxiv.org/abs/2508.12811)
*Yikai Wang,Zhouxia Wang,Zhonghua Wu,Qingyi Tao,Kang Liao,Chen Change Loy*

Main category: cs.CV

TL;DR: 提出一种新的图像生成方法NVG，通过将图像分解为空间分辨率相同但视觉粒度不同的序列，从空白图像开始迭代精炼从全局布局到细节的生成过程。


<details>
  <summary>Details</summary>
Motivation: 解决传统图像生成模型在多粒度级别控制上的不足，希望通过分层表示实现更精细的生成控制。

Method: 使用Next Visual Granularity (NVG)框架，将图像解构为结构化序列，每个元素具有相同空间分辨率但不同的视觉粒度。从空白图像开始，逐步精炼生成从全局到细节的各个粒度层次。

Result: 在ImageNet数据集上训练的NVG模型显示了明显的缩放行为，在FID指标上一致超过VAR系列（3.30->3.03，2.57->2.44，2.09->2.06）。

Conclusion: NVG框架通过分层的结构化序列生成方式，提供了更好的多粒度级别控制能力，在图像生成质量上取得了显著提升。

Abstract: We propose a novel approach to image generation by decomposing an image into
a structured sequence, where each element in the sequence shares the same
spatial resolution but differs in the number of unique tokens used, capturing
different level of visual granularity. Image generation is carried out through
our newly introduced Next Visual Granularity (NVG) generation framework, which
generates a visual granularity sequence beginning from an empty image and
progressively refines it, from global layout to fine details, in a structured
manner. This iterative process encodes a hierarchical, layered representation
that offers fine-grained control over the generation process across multiple
granularity levels. We train a series of NVG models for class-conditional image
generation on the ImageNet dataset and observe clear scaling behavior. Compared
to the VAR series, NVG consistently outperforms it in terms of FID scores (3.30
-> 3.03, 2.57 ->2.44, 2.09 -> 2.06). We also conduct extensive analysis to
showcase the capability and potential of the NVG framework. Our code and models
will be released.

</details>


### [256] [SIS-Challenge: Event-based Spatio-temporal Instance Segmentation Challenge at the CVPR 2025 Event-based Vision Workshop](https://arxiv.org/abs/2508.12813)
*Friedhelm Hamann,Emil Mededovic,Fabian Gülhan,Yuli Wu,Johannes Stegmaier,Jing He,Yiqing Wang,Kexin Zhang,Lingling Li,Licheng Jiao,Mengru Ma,Hongxiang Huang,Yuhao Yan,Hongwei Ren,Xiaopeng Lin,Yulong Huang,Bojun Cheng,Se Hyun Lee,Gyu Sung Ham,Kanghan Oh,Gi Hyun Lim,Boxuan Yang,Bowen Du,Guillermo Gallego*

Main category: cs.CV

TL;DR: CVPR 2025事件视觉研讨会中的时空实例分割挑战赛概述，包含任务定义、数据集、挑战细节和排名前5团队的方法介绍


<details>
  <summary>Details</summary>
Motivation: 推动事件相机和灰度相机数据融合的时空实例分割技术发展，为计算机视觉社区提供标准基准和评估平台

Method: 组织挑战赛，提供时空对齐的事件相机和灰度相机数据集，定义像素级分割任务，收集并评估参赛团队的解决方案

Result: 成功举办了SIS挑战赛，收集了多个团队的解决方案，排名前5的方法在挑战中表现优异，相关代码和资源已公开

Conclusion: 该挑战赛为事件视觉领域的时空实例分割技术提供了重要推动，公开的资源和代码将促进该领域的进一步发展

Abstract: We present an overview of the Spatio-temporal Instance Segmentation (SIS)
challenge held in conjunction with the CVPR 2025 Event-based Vision Workshop.
The task is to predict accurate pixel-level segmentation masks of defined
object classes from spatio-temporally aligned event camera and grayscale camera
data. We provide an overview of the task, dataset, challenge details and
results. Furthermore, we describe the methods used by the top-5 ranking teams
in the challenge. More resources and code of the participants' methods are
available here:
https://github.com/tub-rip/MouseSIS/blob/main/docs/challenge_results.md

</details>


### [257] [DEEP-SEA: Deep-Learning Enhancement for Environmental Perception in Submerged Aquatics](https://arxiv.org/abs/2508.12824)
*Shuang Chen,Ronald Thenius,Farshad Arvin,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: DEEP-SEA是一个基于深度学习的海底图像恢复模型，通过双频增强自注意力机制来提升水下图像质量，解决光散射和浑浊问题


<details>
  <summary>Details</summary>
Motivation: 水下环境的光散射、吸收和浑浊问题严重降低了图像清晰度和色彩信息，影响了海洋生物多样性监测和生态评估的准确性

Method: 提出DEEP-SEA模型，采用双频增强自注意力空间和频率调制器，自适应地在频域和空间域细化特征表示，同时保持空间结构

Result: 在EUVP和LSUI数据集上的实验表明，该模型在恢复精细图像细节和结构一致性方面优于现有最先进方法

Conclusion: DEEP-SEA通过有效缓解水下视觉退化问题，有潜力提高水下监测平台的可靠性，实现更准确的生态观测、物种识别和自主导航

Abstract: Continuous and reliable underwater monitoring is essential for assessing
marine biodiversity, detecting ecological changes and supporting autonomous
exploration in aquatic environments. Underwater monitoring platforms rely on
mainly visual data for marine biodiversity analysis, ecological assessment and
autonomous exploration. However, underwater environments present significant
challenges due to light scattering, absorption and turbidity, which degrade
image clarity and distort colour information, which makes accurate observation
difficult. To address these challenges, we propose DEEP-SEA, a novel deep
learning-based underwater image restoration model to enhance both low- and
high-frequency information while preserving spatial structures. The proposed
Dual-Frequency Enhanced Self-Attention Spatial and Frequency Modulator aims to
adaptively refine feature representations in frequency domains and
simultaneously spatial information for better structural preservation. Our
comprehensive experiments on EUVP and LSUI datasets demonstrate the superiority
over the state of the art in restoring fine-grained image detail and structural
consistency. By effectively mitigating underwater visual degradation, DEEP-SEA
has the potential to improve the reliability of underwater monitoring platforms
for more accurate ecological observation, species identification and autonomous
navigation.

</details>


### [258] [Multi-source Multimodal Progressive Domain Adaption for Audio-Visual Deception Detection](https://arxiv.org/abs/2508.12842)
*Ronghao Lin,Sijie Mai,Ying Zeng,Qiaolin He,Aolin Xiong,Haifeng Hu*

Main category: cs.CV

TL;DR: 提出MMPDA框架解决多模态欺骗检测中的域偏移问题，通过渐进式域适应方法在特征和决策层面进行对齐，在MMDD挑战赛中取得Top-2成绩


<details>
  <summary>Details</summary>
Motivation: 解决跨源域和目标域的域偏移问题，将音频-视觉知识从多样化的源域迁移到目标域

Method: 多源多模态渐进式域适应（MMPDA）框架，在特征和决策层面逐步对齐源域和目标域

Result: 在竞赛第二阶段达到60.43%准确率和56.99% F1分数，F1分数比第一名高5.59%，准确率比第三名高6.75%

Conclusion: 该方法能有效桥接多样化多模态数据集之间的域偏移，在欺骗检测任务中表现出色

Abstract: This paper presents the winning approach for the 1st MultiModal Deception
Detection (MMDD) Challenge at the 1st Workshop on Subtle Visual Computing
(SVC). Aiming at the domain shift issue across source and target domains, we
propose a Multi-source Multimodal Progressive Domain Adaptation (MMPDA)
framework that transfers the audio-visual knowledge from diverse source domains
to the target domain. By gradually aligning source and the target domain at
both feature and decision levels, our method bridges domain shifts across
diverse multimodal datasets. Extensive experiments demonstrate the
effectiveness of our approach securing Top-2 place. Our approach reaches 60.43%
on accuracy and 56.99\% on F1-score on competition stage 2, surpassing the 1st
place team by 5.59% on F1-score and the 3rd place teams by 6.75% on accuracy.
Our code is available at https://github.com/RH-Lin/MMPDA.

</details>


### [259] [CTFlow: Video-Inspired Latent Flow Matching for 3D CT Synthesis](https://arxiv.org/abs/2508.12900)
*Jiayi Wang,Hadrien Reynaud,Franciskus Xaverius Erick,Bernhard Kainz*

Main category: cs.CV

TL;DR: CTFlow是一个0.5B参数的潜在流匹配变换器模型，能够根据临床报告生成整个CT体积，在时间一致性、图像多样性和文本-图像对齐方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于临床报告生成整个CT体积可以加速医学研究，通过数据增强、隐私保护合成和减少患者数据监管限制，同时保留诊断信号。

Method: 使用FLUX的A-VAE定义潜在空间，CT-Clip文本编码器编码临床报告，采用自定义自回归方法生成一致的整个CT体积，先基于文本预测第一个切片序列，然后基于先前生成的切片和文本预测后续序列。

Result: 在FID、FVD、IS分数和CLIP分数评估中，CTFlow在时间一致性、图像多样性和文本-图像对齐方面优于最先进的生成CT模型。

Conclusion: CTFlow展示了基于临床报告生成高质量CT体积的可行性，为医学影像生成提供了有效的解决方案。

Abstract: Generative modelling of entire CT volumes conditioned on clinical reports has
the potential to accelerate research through data augmentation,
privacy-preserving synthesis and reducing regulator-constraints on patient data
while preserving diagnostic signals. With the recent release of CT-RATE, a
large-scale collection of 3D CT volumes paired with their respective clinical
reports, training large text-conditioned CT volume generation models has become
achievable. In this work, we introduce CTFlow, a 0.5B latent flow matching
transformer model, conditioned on clinical reports. We leverage the A-VAE from
FLUX to define our latent space, and rely on the CT-Clip text encoder to encode
the clinical reports. To generate consistent whole CT volumes while keeping the
memory constraints tractable, we rely on a custom autoregressive approach,
where the model predicts the first sequence of slices of the volume from
text-only, and then relies on the previously generated sequence of slices and
the text, to predict the following sequence. We evaluate our results against
state-of-the-art generative CT model, and demonstrate the superiority of our
approach in terms of temporal coherence, image diversity and text-image
alignment, with FID, FVD, IS scores and CLIP score.

</details>


### [260] [Cross-Domain Few-Shot Learning via Multi-View Collaborative Optimization with Vision-Language Models](https://arxiv.org/abs/2508.12861)
*Dexia Chen,Wentao Zhang,Qianjie Zhu,Ping Hu,Weibing Li,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: 通过多视角协同优化策略CoMuCo，提升视觉-语言模型在跨域少样本识别任务中的性能


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型在自然图像数据集上表现优异，但在跨域任务中效果有限，需要提升模型在非自然图像域的适应能力

Method: 提出CoMuCo策略，使用两个功能互补的专家模块提取多视角特征，结合先验知识一致性约束和信息几何共识机制来增强特征学习的稳健性

Result: 在新建立的跨域少样本测试集上，CoMuCo持续超过当前最佳方法，表现出优异的跨域适应能力

Conclusion: CoMuCo通过多视角协同优化和一致性约束，有效提升了视觉-语言模型在跨域少样本识别任务中的表现，为跨域学习提供了新的解决方案

Abstract: Vision-language models (VLMs) pre-trained on natural image and language data,
such as CLIP, have exhibited significant potential in few-shot image
recognition tasks, leading to development of various efficient transfer
learning methods. These methods exploit inherent pre-learned knowledge in VLMs
and have achieved strong performance on standard image datasets. However, their
effectiveness is often limited when confronted with cross-domain tasks where
imaging domains differ from natural images. To address this limitation, we
propose Consistency-guided Multi-view Collaborative Optimization (CoMuCo), a
novel fine-tuning strategy for VLMs. This strategy employs two functionally
complementary expert modules to extract multi-view features, while
incorporating prior knowledge-based consistency constraints and information
geometry-based consensus mechanisms to enhance the robustness of feature
learning. Additionally, a new cross-domain few-shot benchmark is established to
help comprehensively evaluate methods on imaging domains distinct from natural
images. Extensive empirical evaluations on both existing and newly proposed
benchmarks suggest CoMuCo consistently outperforms current methods in few-shot
tasks. The code and benchmark will be released.

</details>


### [261] [Preserve and Sculpt: Manifold-Aligned Fine-tuning of Vision-Language Models for Few-Shot Learning](https://arxiv.org/abs/2508.12877)
*Dexia Chen,Qianjie Zhu,Weibing Li,Yue Yu,Tong Zhang,Ruixuan Wang*

Main category: cs.CV

TL;DR: MPS-Tuning是一种新的视觉语言模型微调方法，通过保持语义流形的几何结构并增强类别可分性来改进少样本图像分类性能


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型微调方法往往忽略数据分布的几何结构，可能导致整体语义表示的扭曲，需要一种能够保持流形结构的方法

Method: 将特征空间中的数据分布视为语义流形，通过对齐微调前后的Gram矩阵来保持流形的宏观和微观拓扑结构，同时优化图像和文本模态的配对相似性来增强类别可分性

Result: 大量实验表明MPS-Tuning显著提升了模型性能，同时有效保持了语义流形的结构

Conclusion: MPS-Tuning通过显式约束语义流形的内在几何结构，为视觉语言模型的微调提供了一种有效的方法，在保持原有结构的同时增强了分类性能

Abstract: Pretrained vision-language models (VLMs), such as CLIP, have shown remarkable
potential in few-shot image classification and led to numerous effective
transfer learning strategies. These methods leverage the pretrained knowledge
of VLMs to enable effective domain adaptation while mitigating overfitting
through parameter-efficient tuning or instance-based consistency constraints.
However, such regularizations often neglect the geometric structure of data
distribution, which may lead to distortion of the overall semantic
representation. To overcome this limitation, we propose a novel fine-tuning
method, Manifold-Preserving and Sculpting Tuning (MPS-Tuning). Regarding the
data distribution in feature space as a semantic manifold, MPS-Tuning
explicitly constrains the intrinsic geometry of this manifold while further
sculpting it to enhance class separability. Specifically, MPS-Tuning preserves
both macroscopic and microscopic topological structures of the original
manifold by aligning Gram matrices of features before and after fine-tuning.
Theoretically, this constraint is shown to approximate an upper bound of the
Gromov-Wasserstein distance. Furthermore, features from the image and text
modalities are paired, and pairwise similarities are optimized to enhance the
manifold's class discriminability. Extensive experiments demonstrate that
MPS-Tuning significantly improves model performance while effectively
preserving the structure of the semantic manifold. The code will be released.

</details>


### [262] [SEDEG:Sequential Enhancement of Decoder and Encoder's Generality for Class Incremental Learning with Small Memory](https://arxiv.org/abs/2508.12932)
*Hongyang Chen,Shaoling Pu,Lingyu Zheng,Zhongwu Sun*

Main category: cs.CV

TL;DR: SEDEG是一个两阶段训练的ViT增量学习框架，通过特征增强和知识蒸馏技术同时提升编码器和解码器的泛化能力，有效缓解灾难性遗忘问题，在有限内存场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有增量学习方法大多只关注编码器或解码器中的一个组件，限制了缓解灾难性遗忘的效果，特别是在小内存场景下表现更差。需要同时提升编码器和解码器的泛化能力。

Method: 两阶段训练框架：第一阶段通过特征增强训练集成编码器学习泛化表示，增强解码器并平衡分类器；第二阶段使用平衡知识蒸馏和特征蒸馏压缩集成编码器，开发新的泛化编码器。

Result: 在三个基准数据集上的大量实验显示SEDEG具有优越性能，消融研究证实了各组成部分的有效性。

Conclusion: SEDEG通过顺序提升编码器和解码器的泛化能力，有效解决了增量学习中的灾难性遗忘问题，特别是在小内存场景下表现出色。

Abstract: In incremental learning, enhancing the generality of knowledge is crucial for
adapting to dynamic data inputs. It can develop generalized representations or
more balanced decision boundaries, preventing the degradation of long-term
knowledge over time and thus mitigating catastrophic forgetting. Some emerging
incremental learning methods adopt an encoder-decoder architecture and have
achieved promising results. In the encoder-decoder achitecture, improving the
generalization capabilities of both the encoder and decoder is critical, as it
helps preserve previously learned knowledge while ensuring adaptability and
robustness to new, diverse data inputs. However, many existing continual
methods focus solely on enhancing one of the two components, which limits their
effectiveness in mitigating catastrophic forgetting. And these methods perform
even worse in small-memory scenarios, where only a limited number of historical
samples can be stored. To mitigate this limitation, we introduces SEDEG, a
two-stage training framework for vision transformers (ViT), focusing on
sequentially improving the generality of both Decoder and Encoder. Initially,
SEDEG trains an ensembled encoder through feature boosting to learn generalized
representations, which subsequently enhance the decoder's generality and
balance the classifier. The next stage involves using knowledge distillation
(KD) strategies to compress the ensembled encoder and develop a new, more
generalized encoder. This involves using a balanced KD approach and feature KD
for effective knowledge transfer. Extensive experiments on three benchmark
datasets show SEDEG's superior performance, and ablation studies confirm the
efficacy of its components. The code is available at
https://github.com/ShaolingPu/CIL.

</details>


### [263] [S^2-Guidance: Stochastic Self Guidance for Training-Free Enhancement of Diffusion Models](https://arxiv.org/abs/2508.12880)
*Chubin Chen,Jiashu Zhu,Xiaokun Feng,Nisha Huang,Meiqi Wu,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Xiu Li*

Main category: cs.CV

TL;DR: S^2-Guidance是一种新的扩散模型引导方法，通过随机块丢弃构建子网络来优化预测，解决了CFG方法产生次优结果的问题，在文本到图像和文本到视频生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究发现Classifier-free Guidance (CFG)方法在扩散模型中会产生与真实情况不符的次优预测，导致语义不连贯和低质量输出，需要改进引导策略。

Method: 提出S^2-Guidance方法，利用前向过程中的随机块丢弃构建随机子网络，有效引导模型远离低质量预测，朝向高质量输出。

Result: 在文本到图像和文本到视频生成任务上的大量实验表明，S^2-Guidance性能优越， consistently超越CFG和其他先进引导策略。

Conclusion: S^2-Guidance通过利用模型自身的子网络来优化预测，提供了一种有效的扩散模型引导方法，显著提升了生成质量。

Abstract: Classifier-free Guidance (CFG) is a widely used technique in modern diffusion
models for enhancing sample quality and prompt adherence. However, through an
empirical analysis on Gaussian mixture modeling with a closed-form solution, we
observe a discrepancy between the suboptimal results produced by CFG and the
ground truth. The model's excessive reliance on these suboptimal predictions
often leads to semantic incoherence and low-quality outputs. To address this
issue, we first empirically demonstrate that the model's suboptimal predictions
can be effectively refined using sub-networks of the model itself. Building on
this insight, we propose S^2-Guidance, a novel method that leverages stochastic
block-dropping during the forward process to construct stochastic sub-networks,
effectively guiding the model away from potential low-quality predictions and
toward high-quality outputs. Extensive qualitative and quantitative experiments
on text-to-image and text-to-video generation tasks demonstrate that
S^2-Guidance delivers superior performance, consistently surpassing CFG and
other advanced guidance strategies. Our code will be released.

</details>


### [264] [Multi-Phase Automated Segmentation of Dental Structures in CBCT Using a Lightweight Auto3DSeg and SegResNet Implementation](https://arxiv.org/abs/2508.12962)
*Dominic LaBella,Keshav Jha,Jared Robbins,Esther Yu*

Main category: cs.CV

TL;DR: DLaBella29团队在MICCAI 2025 ToothFairy3挑战赛中提出的基于3D SegResNet架构的深度学习管道，用于CBCT图像中的多类别牙齿分割，在验证集上达到平均Dice系数0.87


<details>
  <summary>Details</summary>
Motivation: CBCT在牙科中已成为重要成像方式，自动分割牙齿结构可帮助识别病理（如牙髓或根尖周病变）并促进头颈癌患者的放射治疗规划

Method: 使用MONAI Auto3DSeg框架和3D SegResNet架构，采用5折交叉验证训练，关键预处理包括图像重采样到0.6mm各向同性分辨率和强度裁剪，采用两阶段分割策略：第一阶段使用Multi-Label STAPLE集成融合，第二阶段对下颌骨进行紧密裁剪以分割较小的神经结构

Result: 在ToothFairy3挑战赛的样本外验证集上获得了平均Dice系数0.87

Conclusion: 该方法展示了自动牙齿分割在改善放射肿瘤学患者护理方面的相关性，为临床诊断和治疗规划提供了有效的自动化工具

Abstract: Cone-beam computed tomography (CBCT) has become an invaluable imaging
modality in dentistry, enabling 3D visualization of teeth and surrounding
structures for diagnosis and treatment planning. Automated segmentation of
dental structures in CBCT can efficiently assist in identifying pathology
(e.g., pulpal or periapical lesions) and facilitate radiation therapy planning
in head and neck cancer patients. We describe the DLaBella29 team's approach
for the MICCAI 2025 ToothFairy3 Challenge, which involves a deep learning
pipeline for multi-class tooth segmentation. We utilized the MONAI Auto3DSeg
framework with a 3D SegResNet architecture, trained on a subset of the
ToothFairy3 dataset (63 CBCT scans) with 5-fold cross-validation. Key
preprocessing steps included image resampling to 0.6 mm isotropic resolution
and intensity clipping. We applied an ensemble fusion using Multi-Label STAPLE
on the 5-fold predictions to infer a Phase 1 segmentation and then conducted
tight cropping around the easily segmented Phase 1 mandible to perform Phase 2
segmentation on the smaller nerve structures. Our method achieved an average
Dice of 0.87 on the ToothFairy3 challenge out-of-sample validation set. This
paper details the clinical context, data preparation, model development,
results of our approach, and discusses the relevance of automated dental
segmentation for improving patient care in radiation oncology.

</details>


### [265] [ONG: One-Shot NMF-based Gradient Masking for Efficient Model Sparsification](https://arxiv.org/abs/2508.12891)
*Sankar Behera,Yamuna Prasad*

Main category: cs.CV

TL;DR: ONG是一种基于非负矩阵分解的一次性剪枝方法，通过梯度掩码机制在训练过程中严格保持目标稀疏度，在CIFAR数据集上实现了与现有方法相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络规模庞大导致部署困难，现有剪枝方法存在迭代过程复杂、需要专门标准或在训练中难以有效保持稀疏度等问题。

Method: 使用非负矩阵分解(NMF)识别重要权重结构进行一次性剪枝，然后采用精确的梯度掩码机制确保只有未剪枝权重被更新，严格保持目标稀疏度。

Result: 在CIFAR-10和CIFAR-100数据集上使用ResNet56、ResNet34和ResNet18进行测试，ONG在不同稀疏度水平下都能达到相当或更优的性能，同时保持剪枝后的结构完整性。

Conclusion: ONG提供了一种有效的一次性剪枝解决方案，能够精确控制目标稀疏度，在保持模型性能的同时实现高效的网络压缩。

Abstract: Deep Neural Networks (DNNs) have achieved remarkable success but their large
size poses deployment challenges. While various pruning techniques exist, many
involve complex iterative processes, specialized criteria, or struggle to
maintain sparsity effectively during training. We introduce ONG (One-shot
NMF-based Gradient Masking), a novel sparsification strategy that identifies
salient weight structures using Non-negative Matrix Factorization (NMF) for
one-shot pruning at the outset of training. Subsequently, ONG employs a precise
gradient masking mechanism to ensure that only unpruned weights are updated,
strictly preserving the target sparsity throughout the training phase. We
integrate ONG into the BIMP comparative framework and evaluate it on CIFAR-10
and CIFAR-100 with ResNet56, ResNet34, and ResNet18 against established stable
sparsification methods. Our experiments demonstrate ONG's ability to achieve
comparable or superior performance at various sparsity levels while maintaining
structural integrity post-pruning and offering a clear mechanism for targeting
desired sparsities.

</details>


### [266] [CMF-IoU: Multi-Stage Cross-Modal Fusion 3D Object Detection with IoU Joint Prediction](https://arxiv.org/abs/2508.12917)
*Zhiwei Ning,Zhaojiang Liu,Xuanang Gao,Yifan Zuo,Jie Yang,Yuming Fang,Wei Liu*

Main category: cs.CV

TL;DR: CMF-IOU是一个多阶段跨模态融合的3D检测框架，通过深度补全网络将像素信息投影到3D空间生成伪点云，设计双边跨视图增强3D骨干网络，并引入迭代体素点感知细粒度池化模块，在KITTI、nuScenes和Waymo数据集上表现出优越性能


<details>
  <summary>Details</summary>
Motivation: 解决现有单阶段或部分阶段融合方法特征提取不足和性能不佳的问题，有效应对3D空间信息与2D语义信息对齐的挑战

Method: 1) 深度补全网络生成伪点云统一表示；2) 双边跨视图增强3D骨干网络（S2D分支和ResVC分支）；3) 迭代体素点感知细粒度池化模块；4) IoU联合预测分支与新颖提案生成技术

Result: 在KITTI、nuScenes和Waymo数据集上进行了广泛实验，显示出优越性能

Conclusion: 提出的多阶段跨模态融合框架CMF-IOU能够有效解决3D检测中的跨模态信息融合问题，取得了优异的检测性能

Abstract: Multi-modal methods based on camera and LiDAR sensors have garnered
significant attention in the field of 3D detection. However, many prevalent
works focus on single or partial stage fusion, leading to insufficient feature
extraction and suboptimal performance. In this paper, we introduce a
multi-stage cross-modal fusion 3D detection framework, termed CMF-IOU, to
effectively address the challenge of aligning 3D spatial and 2D semantic
information. Specifically, we first project the pixel information into 3D space
via a depth completion network to get the pseudo points, which unifies the
representation of the LiDAR and camera information. Then, a bilateral
cross-view enhancement 3D backbone is designed to encode LiDAR points and
pseudo points. The first sparse-to-distant (S2D) branch utilizes an
encoder-decoder structure to reinforce the representation of sparse LiDAR
points. The second residual view consistency (ResVC) branch is proposed to
mitigate the influence of inaccurate pseudo points via both the 3D and 2D
convolution processes. Subsequently, we introduce an iterative voxel-point
aware fine grained pooling module, which captures the spatial information from
LiDAR points and textural information from pseudo points in the proposal
refinement stage. To achieve more precise refinement during iteration, an
intersection over union (IoU) joint prediction branch integrated with a novel
proposals generation technique is designed to preserve the bounding boxes with
both high IoU and classification scores. Extensive experiments show the
superior performance of our method on the KITTI, nuScenes and Waymo datasets.

</details>


### [267] [7Bench: a Comprehensive Benchmark for Layout-guided Text-to-image Models](https://arxiv.org/abs/2508.12919)
*Elena Izzo,Luca Parolari,Davide Vezzaro,Lamberto Ballan*

Main category: cs.CV

TL;DR: 提出了7Bench基准测试，首个同时评估布局引导文本到图像生成中语义对齐和空间对齐的基准，包含7个挑战性场景，用于评估现有扩散模型的空间保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试只关注文本对齐，忽略了布局对齐评估，而布局对齐对于合成数据生成等应用至关重要，因为空间错误会引入噪声并降低数据质量。

Method: 创建包含7个挑战性场景的文本-布局对数据集，提出结合布局对齐分数的评估协议来评估空间准确性。

Result: 使用7Bench评估了多个最先进的扩散模型，揭示了它们在不同对齐任务中的优势和局限性。

Conclusion: 7Bench填补了布局对齐评估的空白，为评估布局引导文本到图像生成模型的空间保真度提供了重要工具。

Abstract: Layout-guided text-to-image models offer greater control over the generation
process by explicitly conditioning image synthesis on the spatial arrangement
of elements. As a result, their adoption has increased in many computer vision
applications, ranging from content creation to synthetic data generation. A
critical challenge is achieving precise alignment between the image, textual
prompt, and layout, ensuring semantic fidelity and spatial accuracy. Although
recent benchmarks assess text alignment, layout alignment remains overlooked,
and no existing benchmark jointly evaluates both. This gap limits the ability
to evaluate a model's spatial fidelity, which is crucial when using
layout-guided generation for synthetic data, as errors can introduce noise and
degrade data quality. In this work, we introduce 7Bench, the first benchmark to
assess both semantic and spatial alignment in layout-guided text-to-image
generation. It features text-and-layout pairs spanning seven challenging
scenarios, investigating object generation, color fidelity, attribute
recognition, inter-object relationships, and spatial control. We propose an
evaluation protocol that builds on existing frameworks by incorporating the
layout alignment score to assess spatial accuracy. Using 7Bench, we evaluate
several state-of-the-art diffusion models, uncovering their respective
strengths and limitations across diverse alignment tasks. The benchmark is
available at https://github.com/Elizzo/7Bench.

</details>


### [268] [Towards High-Resolution Industrial Image Anomaly Detection](https://arxiv.org/abs/2508.12931)
*Ximiao Zhang,Min Xu,Xiuzhuang Zhou*

Main category: cs.CV

TL;DR: 高分辨率异常检测方法HiAD，通过双支路架构和多分辨率特征融合，解决传统方法在高分辨率图像中细微异常区域检测不足的问题。


<details>
  <summary>Details</summary>
Motivation: 当前异常检测方法主要集中于低分辨率场景，高分辨率图像下传统下采样方法导致细微异常区域漏检，而现有方法在检测精度和效率方面仍不能满足工业应用需求。

Method: 提出HiAD框架，采用双支路架构集成不同粒度的异常线索，多分辨率特征融合策略处理细细致纹理变化，以及检测器池结合适配性分配策略来控制计算成本。

Result: 在MVTec-HD、VisA-HD和RealIAD-HD等高分辨率异常检测测试集上进行了广泛实验，证明了HiAD的优异性能。

Conclusion: HiAD是一个通用的高分辨率异常检测框架，能够在有限计算资源下检测不同规模的异常区域，为工业应用提供了高效的解决方案。

Abstract: Current anomaly detection methods primarily focus on low-resolution
scenarios. For high-resolution images, conventional downsampling often results
in missed detections of subtle anomalous regions due to the loss of
fine-grained discriminative information. Despite some progress, recent studies
have attempted to improve detection resolution by employing lightweight
networks or using simple image tiling and ensemble methods. However, these
approaches still struggle to meet the practical demands of industrial scenarios
in terms of detection accuracy and efficiency. To address the above issues, we
propose HiAD, a general framework for high-resolution anomaly detection. HiAD
is capable of detecting anomalous regions of varying sizes in high-resolution
images under limited computational resources. Specifically, HiAD employs a
dual-branch architecture that integrates anomaly cues across different scales
to comprehensively capture both subtle and large-scale anomalies. Furthermore,
it incorporates a multi-resolution feature fusion strategy to tackle the
challenges posed by fine-grained texture variations in high-resolution images.
To enhance both adaptability and efficiency, HiAD utilizes a detector pool in
conjunction with various detector assignment strategies, enabling detectors to
be adaptively assigned based on patch features, ensuring detection performance
while effectively controlling computational costs. We conduct extensive
experiments on our specifically constructed high-resolution anomaly detection
benchmarks, including MVTec-HD, VisA-HD, and the real-world benchmark
RealIAD-HD, demonstrating the superior performance of HiAD. The code is
available at https://github.com/cnulab/HiAD.

</details>


### [269] [Fully Automated Segmentation of Fiber Bundles in Anatomic Tracing Data](https://arxiv.org/abs/2508.12942)
*Kyriaki-Margarita Bintsi,Yaël Balbastre,Jingjing Wu,Julia F. Lehman,Suzanne N. Haber,Anastasia Yendiki*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Anatomic tracer studies are critical for validating and improving diffusion
MRI (dMRI) tractography. However, large-scale analysis of data from such
studies is hampered by the labor-intensive process of annotating fiber bundles
manually on histological slides. Existing automated methods often miss sparse
bundles or require complex post-processing across consecutive sections,
limiting their flexibility and generalizability. We present a streamlined,
fully automated framework for fiber bundle segmentation in macaque tracer data,
based on a U-Net architecture with large patch sizes, foreground aware
sampling, and semisupervised pre-training. Our approach eliminates common
errors such as mislabeling terminals as bundles, improves detection of sparse
bundles by over 20% and reduces the False Discovery Rate (FDR) by 40% compared
to the state-of-the-art, all while enabling analysis of standalone slices. This
new framework will facilitate the automated analysis of anatomic tracing data
at a large scale, generating more ground-truth data that can be used to
validate and optimize dMRI tractography methods.

</details>


### [270] [Lumen: Consistent Video Relighting and Harmonious Background Replacement with Video Generative Models](https://arxiv.org/abs/2508.12945)
*Jianshu Zeng,Yuxuan Liu,Yutong Feng,Chenxuan Miao,Zixiang Gao,Jiwang Qu,Jianzhang Zhang,Bin Wang,Kun Yuan*

Main category: cs.CV

TL;DR: Lumen是一个端到端的视频重光照框架，基于大规模视频生成模型，通过文本描述控制光照和背景，能够生成具有一致光照和严格前景保持的电影级重光照视频。


<details>
  <summary>Details</summary>
Motivation: 视频重光照是一个具有挑战性但有价值的任务，需要在替换视频背景的同时相应地调整前景的光照并进行和谐融合。现有方法缺乏高质量的多光照条件配对视频数据，且需要保持前景原始属性（如反照率）和时间帧间的一致性。

Method: 构建混合真实和合成视频的大规模数据集；使用3D渲染引擎制作合成视频对；采用HDR光照模拟补充真实视频；设计联合训练课程，注入域感知适配器来解耦重光照和域外观分布的学习。

Result: 实验结果表明，Lumen能够有效地将输入编辑成具有一致光照和严格前景保持的电影级重光照视频，在前景保持和视频一致性评估方面优于现有方法。

Conclusion: Lumen框架通过大规模混合数据集和域感知适配器设计，成功解决了视频重光照任务中的光照一致性和前景保持问题，为视频编辑提供了有效的解决方案。

Abstract: Video relighting is a challenging yet valuable task, aiming to replace the
background in videos while correspondingly adjusting the lighting in the
foreground with harmonious blending. During translation, it is essential to
preserve the original properties of the foreground, e.g., albedo, and propagate
consistent relighting among temporal frames. In this paper, we propose Lumen,
an end-to-end video relighting framework developed on large-scale video
generative models, receiving flexible textual description for instructing the
control of lighting and background. Considering the scarcity of high-qualified
paired videos with the same foreground in various lighting conditions, we
construct a large-scale dataset with a mixture of realistic and synthetic
videos. For the synthetic domain, benefiting from the abundant 3D assets in the
community, we leverage advanced 3D rendering engine to curate video pairs in
diverse environments. For the realistic domain, we adapt a HDR-based lighting
simulation to complement the lack of paired in-the-wild videos. Powered by the
aforementioned dataset, we design a joint training curriculum to effectively
unleash the strengths of each domain, i.e., the physical consistency in
synthetic videos, and the generalized domain distribution in realistic videos.
To implement this, we inject a domain-aware adapter into the model to decouple
the learning of relighting and domain appearance distribution. We construct a
comprehensive benchmark to evaluate Lumen together with existing methods, from
the perspectives of foreground preservation and video consistency assessment.
Experimental results demonstrate that Lumen effectively edit the input into
cinematic relighted videos with consistent lighting and strict foreground
preservation. Our project page: https://lumen-relight.github.io/

</details>


### [271] [MaskSem: Semantic-Guided Masking for Learning 3D Hybrid High-Order Motion Representation](https://arxiv.org/abs/2508.12948)
*Wei Wei,Shaojie Zhang,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: MaskSem是一种基于语义引导掩码的自监督骨架动作识别方法，通过Grad-CAM指导关节掩码，使用混合高阶运动作为重建目标，在多个数据集上提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督骨架动作识别方法主要关注有限关节集和低阶运动模式，限制了模型对复杂运动模式的理解能力，需要更好的方法来学习更全面的运动表示。

Method: 提出MaskSem框架：1）使用基于相对运动的Grad-CAM来指导关节掩码，选择语义最丰富的时间区域；2）采用混合高阶运动（低阶速度和高阶加速度）作为重建目标，学习多阶运动模式。

Result: 在NTU60、NTU120和PKU-MMD数据集上的实验表明，MaskSem结合普通transformer能够提升骨架动作识别性能。

Conclusion: MaskSem通过语义引导掩码和混合高阶运动重建，能够更好地理解复杂运动模式，更适合人机交互应用。

Abstract: Human action recognition is a crucial task for intelligent robotics,
particularly within the context of human-robot collaboration research. In
self-supervised skeleton-based action recognition, the mask-based
reconstruction paradigm learns the spatial structure and motion patterns of the
skeleton by masking joints and reconstructing the target from unlabeled data.
However, existing methods focus on a limited set of joints and low-order motion
patterns, limiting the model's ability to understand complex motion patterns.
To address this issue, we introduce MaskSem, a novel semantic-guided masking
method for learning 3D hybrid high-order motion representations. This novel
framework leverages Grad-CAM based on relative motion to guide the masking of
joints, which can be represented as the most semantically rich temporal
orgions. The semantic-guided masking process can encourage the model to explore
more discriminative features. Furthermore, we propose using hybrid high-order
motion as the reconstruction target, enabling the model to learn multi-order
motion patterns. Specifically, low-order motion velocity and high-order motion
acceleration are used together as the reconstruction target. This approach
offers a more comprehensive description of the dynamic motion process,
enhancing the model's understanding of motion patterns. Experiments on the
NTU60, NTU120, and PKU-MMD datasets show that MaskSem, combined with a vanilla
transformer, improves skeleton-based action recognition, making it more
suitable for applications in human-robot interaction.

</details>


### [272] [Breaking Reward Collapse: Adaptive Reinforcement for Open-ended Medical Reasoning with Enhanced Semantic Discrimination](https://arxiv.org/abs/2508.12957)
*Yizhou Liu,Jingwei Wei,Zizhi Chen,Minghao Han,Xukun Zhang,Keliang Liu,Lihua Zhang*

Main category: cs.CV

TL;DR: ARMed是一个用于开放式医学视觉问答的新型强化学习框架，通过结合领域知识和自适应语义奖励来提升医学推理质量，在多个医学VQA基准测试中显著提升了准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化微调方法主要针对封闭式医学视觉问答，限制了在真实临床推理中的应用。开放式医学VQA更能反映临床实践但研究较少，且基于模型的语义奖励存在奖励崩溃问题。

Method: ARMed框架首先通过监督微调在思维链数据中融入领域知识，然后应用强化学习结合文本正确性和自适应语义奖励来增强推理质量。

Result: 在六个具有挑战性的医学VQA基准测试中，ARMed在域内任务上实现了32.64%的改进，在域外基准上获得了11.65%的提升。

Conclusion: 研究强调了奖励可区分性在医学强化学习中的关键作用，以及语义引导奖励在实现稳健且具有临床意义的多模态推理方面的潜力。

Abstract: Reinforcement learning (RL) with rule-based rewards has demonstrated strong
potential in enhancing the reasoning and generalization capabilities of
vision-language models (VLMs) and large language models (LLMs), while reducing
computational overhead. However, its application in medical imaging remains
underexplored. Existing reinforcement fine-tuning (RFT) approaches in this
domain primarily target closed-ended visual question answering (VQA), limiting
their applicability to real-world clinical reasoning. In contrast, open-ended
medical VQA better reflects clinical practice but has received limited
attention. While some efforts have sought to unify both formats via
semantically guided RL, we observe that model-based semantic rewards often
suffer from reward collapse, where responses with significant semantic
differences receive similar scores. To address this, we propose ARMed (Adaptive
Reinforcement for Medical Reasoning), a novel RL framework for open-ended
medical VQA. ARMed first incorporates domain knowledge through supervised
fine-tuning (SFT) on chain-of-thought data, then applies reinforcement learning
with textual correctness and adaptive semantic rewards to enhance reasoning
quality. We evaluate ARMed on six challenging medical VQA benchmarks. Results
show that ARMed consistently boosts both accuracy and generalization, achieving
a 32.64% improvement on in-domain tasks and an 11.65% gain on out-of-domain
benchmarks. These results highlight the critical role of reward
discriminability in medical RL and the promise of semantically guided rewards
for enabling robust and clinically meaningful multimodal reasoning.

</details>


### [273] [GazeDETR: Gaze Detection using Disentangled Head and Gaze Representations](https://arxiv.org/abs/2508.12966)
*Ryan Anthony Jalova de Belen,Gelareh Mohammadi,Arcot Sowmya*

Main category: cs.CV

TL;DR: 通过解耦两个独立解码器，GazeDETR分别优化人脸定位和视线预测，在多个数据集上创造了新的SOTA结果


<details>
  <summary>Details</summary>
Motivation: 现有的端到端视线目标检测模型使用单一解码器同时处理人脸定位和视线预测，导致表征混淆，需要解耦两个子任务的表征学习

Method: 设计了GazeDETR模型，使用两个解耦的解码器，分别专门学习人脸定位和视线预测任务，利用相应的注意力场

Result: 在GazeFollow、VideoAttentionTarget和ChildPlay数据集上达到了状态前沿结果，显著超过现有的端到端模型

Conclusion: 解耦解码器结构能够更有效地学习不同子任务的特征表征，人脸预测器利用局部信息，视线解码器结合局部和全局信息

Abstract: Gaze communication plays a crucial role in daily social interactions.
Quantifying this behavior can help in human-computer interaction and digital
phenotyping. While end-to-end models exist for gaze target detection, they only
utilize a single decoder to simultaneously localize human heads and predict
their corresponding gaze (e.g., 2D points or heatmap) in a scene. This
multitask learning approach generates a unified and entangled representation
for human head localization and gaze location prediction. Herein, we propose
GazeDETR, a novel end-to-end architecture with two disentangled decoders that
individually learn unique representations and effectively utilize coherent
attentive fields for each subtask. More specifically, we demonstrate that its
human head predictor utilizes local information, while its gaze decoder
incorporates both local and global information. Our proposed architecture
achieves state-of-the-art results on the GazeFollow, VideoAttentionTarget and
ChildPlay datasets. It outperforms existing end-to-end models with a notable
margin.

</details>


### [274] [Compact Attention: Exploiting Structured Spatio-Temporal Sparsity for Fast Video Generation](https://arxiv.org/abs/2508.12969)
*Qirui Li,Guangcong Zheng,Qi Zhao,Jie Li,Bin Dong,Yiwu Yao,Xi Li*

Main category: cs.CV

TL;DR: 通过分析视频波散Transformer的注意力矩阵特性，发现其存在结构化但异质的稀疏模式。提出Compact Attention加速框架，通过适配性分块、时变窗口和自动配置搜索等技术，在保持视觉质量的前提下实现1.6~2.5倍的注意力计算加速。


<details>
  <summary>Details</summary>
Motivation: 解决自注意力机制在辅助转换器视频生成中的计算要求过高问题，特别是在生成超长序列时。现有的因子化注意力和固定稀疏模式方法无法充分利用视频数据中的内在空间-时间冗余性。

Method: 提出Compact Attention加速框架，包括：1）适配性分块策略，通过动态码头分组近似多样化的空间交互模式；2）时变窗口，根据帧距离调整稀疏程度；3）自动化配置搜索算法，在保留关键注意力通道的同时优化稀疏模式。

Result: 在单GPU环境下实现了注意力计算1.6~2.5倍的加速效果，同时保持了与全注意力基线相可比的视觉质量。

Conclusion: 该方法为通过结构化稀疏利用开启高效长形式视频生成提供了有理论基础的解决方案，有效解决了自注意力机制的计算性能瓶颈。

Abstract: The computational demands of self-attention mechanisms pose a critical
challenge for transformer-based video generation, particularly in synthesizing
ultra-long sequences. Current approaches, such as factorized attention and
fixed sparse patterns, fail to fully exploit the inherent spatio-temporal
redundancies in video data. Through systematic analysis of video diffusion
transformers (DiT), we uncover a key insight: Attention matrices exhibit
structured, yet heterogeneous sparsity patterns, where specialized heads
dynamically attend to distinct spatiotemporal regions (e.g., local pattern,
cross-shaped pattern, or global pattern). Existing sparse attention methods
either impose rigid constraints or introduce significant overhead, limiting
their effectiveness. To address this, we propose Compact Attention, a
hardware-aware acceleration framework featuring three innovations: 1) Adaptive
tiling strategies that approximate diverse spatial interaction patterns via
dynamic tile grouping, 2) Temporally varying windows that adjust sparsity
levels based on frame proximity, and 3) An automated configuration search
algorithm that optimizes sparse patterns while preserving critical attention
pathways. Our method achieves 1.6~2.5x acceleration in attention computation on
single-GPU setups while maintaining comparable visual quality with
full-attention baselines. This work provides a principled approach to unlocking
efficient long-form video generation through structured sparsity exploitation.
Project Page: https://yo-ava.github.io/Compact-Attention.github.io/

</details>


### [275] [Dextr: Zero-Shot Neural Architecture Search with Singular Value Decomposition and Extrinsic Curvature](https://arxiv.org/abs/2508.12977)
*Rohan Asthana,Joschua Conrad,Maurits Ortmanns,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 这篇论文提出了一种无需标签数据的零成本代理方法，通过结合渗透性、汇聚性和表达性来预测神经网络的性能，在多个NAS测试集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的零成本代理方法多依赖标签数据，且仅关注汇聚性或表达性的单一属性，在实际应用中有限。

Method: 利用层特征的奇异值分解(SVD)和网络输出的外在曲率来设计代理，通过逆条件数和曲率的对数简化调和平均值来形成代理指标。

Result: 在NAS-Bench-101、NAS-Bench-201、TransNAS-Bench-101-micro等多个测试集上表现优异，仅需单个无标签数据样本即可准确预测网络性能。

Conclusion: 该方法能够在不依赖标签数据的情况下，通过结合多种网络属性来实现高效的神经网络查找，为实际应用提供了可行的解决方案。

Abstract: Zero-shot Neural Architecture Search (NAS) typically optimises the
architecture search process by exploiting the network or gradient properties at
initialisation through zero-cost proxies. The existing proxies often rely on
labelled data, which is usually unavailable in real-world settings.
Furthermore, the majority of the current methods focus either on optimising the
convergence and generalisation attributes or solely on the expressivity of the
network architectures. To address both limitations, we first demonstrate how
channel collinearity affects the convergence and generalisation properties of a
neural network. Then, by incorporating the convergence, generalisation and
expressivity in one approach, we propose a zero-cost proxy that omits the
requirement of labelled data for its computation. In particular, we leverage
the Singular Value Decomposition (SVD) of the neural network layer features and
the extrinsic curvature of the network output to design our proxy. %As a
result, the proposed proxy is formulated as the simplified harmonic mean of the
logarithms of two key components: the sum of the inverse of the feature
condition number and the extrinsic curvature of the network output. Our
approach enables accurate prediction of network performance on test data using
only a single label-free data sample. Our extensive evaluation includes a total
of six experiments, including the Convolutional Neural Network (CNN) search
space, i.e. DARTS and the Transformer search space, i.e. AutoFormer. The
proposed proxy demonstrates a superior performance on multiple correlation
benchmarks, including NAS-Bench-101, NAS-Bench-201, and
TransNAS-Bench-101-micro; as well as on the NAS task within the DARTS and the
AutoFormer search space, all while being notably efficient. The code is
available at https://github.com/rohanasthana/Dextr.

</details>


### [276] [Omni Survey for Multimodality Analysis in Visual Object Tracking](https://arxiv.org/abs/2508.13000)
*Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Hui Li,Shaochuan Zhao,Tao Zhou,Chunyang Cheng,Xiaojun Wu,Josef Kittler*

Main category: cs.CV

TL;DR: 本文对多模态视觉目标跟踪(MMVOT)进行全面综述，涵盖数据收集、模态对齐、模型设计和评估等关键方面，分析了六种MMVOT任务并包含338篇参考文献。


<details>
  <summary>Details</summary>
Motivation: 智慧城市发展产生了海量多模态数据，需要从多模态分析角度研究视觉目标跟踪这一关键任务，探讨多模态跟踪是否总能提供优于单模态的解决方案。

Method: 基于处理可见光(RGB)和辅助模态(X)的不同方式对现有MMVOT方法进行分类：使用RGB分支的复制或非复制实验配置来编程辅助X分支。X可以是热红外、深度、事件、近红外、语言或声纳等模态。

Result: 首次分析了现有MMVOT数据集中目标类别的分布，揭示了其明显的长尾性质，以及与RGB数据集相比动物类别的显著缺乏。

Conclusion: 多模态视觉目标跟踪在智慧城市监测中具有重要价值，但需要仔细考虑信息融合的条件和适用场景，不能保证在所有情况下都优于单模态跟踪。

Abstract: The development of smart cities has led to the generation of massive amounts
of multi-modal data in the context of a range of tasks that enable a
comprehensive monitoring of the smart city infrastructure and services. This
paper surveys one of the most critical tasks, multi-modal visual object
tracking (MMVOT), from the perspective of multimodality analysis. Generally,
MMVOT differs from single-modal tracking in four key aspects, data collection,
modality alignment and annotation, model designing, and evaluation.
Accordingly, we begin with an introduction to the relevant data modalities,
laying the groundwork for their integration. This naturally leads to a
discussion of challenges of multi-modal data collection, alignment, and
annotation. Subsequently, existing MMVOT methods are categorised, based on
different ways to deal with visible (RGB) and X modalities: programming the
auxiliary X branch with replicated or non-replicated experimental
configurations from the RGB branch. Here X can be thermal infrared (T), depth
(D), event (E), near infrared (NIR), language (L), or sonar (S). The final part
of the paper addresses evaluation and benchmarking. In summary, we undertake an
omni survey of all aspects of multi-modal visual object tracking (VOT),
covering six MMVOT tasks and featuring 338 references in total. In addition, we
discuss the fundamental rhetorical question: Is multi-modal tracking always
guaranteed to provide a superior solution to unimodal tracking with the help of
information fusion, and if not, in what circumstances its application is
beneficial. Furthermore, for the first time in this field, we analyse the
distributions of the object categories in the existing MMVOT datasets,
revealing their pronounced long-tail nature and a noticeable lack of animal
categories when compared with RGB datasets.

</details>


### [277] [Empirical Evidences for the Effects of Feature Diversity in Open Set Recognition and Continual Learning](https://arxiv.org/abs/2508.13005)
*Jiawen Xu,Odej Kao*

Main category: cs.CV

TL;DR: 本文通过实证研究表明，增强特征多样性可以改善开放集识别性能，并促进持续学习中旧知识的保持和新知识的整合。


<details>
  <summary>Details</summary>
Motivation: 开放集识别和持续学习是机器学习中的两个关键挑战，虽然已有许多方法通过启发式地促进特征多样性来解决这些问题，但很少有研究直接探讨特征多样性在这些任务中的作用。

Method: 通过实证研究分析特征多样性对开放集识别和持续学习性能的影响，提供实验证据来验证特征多样性的重要性。

Result: 增强特征多样性能够提高开放集样本的识别能力，同时在持续学习中也有助于保持先前学习的数据和整合新数据。

Conclusion: 研究结果为进一步探索这些领域的实用方法和理论理解提供了启发，强调了特征多样性在解决开放集识别和持续学习问题中的关键作用。

Abstract: Open set recognition (OSR) and continual learning are two critical challenges
in machine learning, focusing respectively on detecting novel classes at
inference time and updating models to incorporate the new classes. While many
recent approaches have addressed these problems, particularly OSR, by
heuristically promoting feature diversity, few studies have directly examined
the role that feature diversity plays in tackling them. In this work, we
provide empirical evidence that enhancing feature diversity improves the
recognition of open set samples. Moreover, increased feature diversity also
facilitates both the retention of previously learned data and the integration
of new data in continual learning. We hope our findings can inspire further
research into both practical methods and theoretical understanding in these
domains.

</details>


### [278] [SlimComm: Doppler-Guided Sparse Queries for Bandwidth-Efficient Cooperative 3-D Perception](https://arxiv.org/abs/2508.13007)
*Melih Yazgan,Qiyuan Wu,Iramm Hamdard,Shiqi Li,J. Marius Zoellner*

Main category: cs.CV

TL;DR: SlimComm是一个通信高效的协作感知框架，通过整合4D雷达多普勒信息和查询驱动的稀疏方案，在保持精度的同时将带宽需求降低90%


<details>
  <summary>Details</summary>
Motivation: 解决协作感知中密集BEV特征图传输对车辆间通信带宽的挑战，克服遮挡和传感器范围限制

Method: 构建运动中心动态地图区分动静物体，生成参考查询和探索查询，仅交换查询特定BEV特征并通过多尺度门控可变形注意力融合

Result: 在OPV2V-R和Adver-City-R数据集上，带宽比全图共享降低90%，在不同交通密度和遮挡情况下匹配或超越现有基线

Conclusion: SlimComm框架有效解决了协作感知的通信瓶颈，通过智能查询机制和特征选择实现了精度与效率的平衡

Abstract: Collaborative perception allows connected autonomous vehicles (CAVs) to
overcome occlusion and limited sensor range by sharing intermediate features.
Yet transmitting dense Bird's-Eye-View (BEV) feature maps can overwhelm the
bandwidth available for inter-vehicle communication. We present SlimComm, a
communication-efficient framework that integrates 4D radar Doppler with a
query-driven sparse scheme. SlimComm builds a motion-centric dynamic map to
distinguish moving from static objects and generates two query types: (i)
reference queries on dynamic and high-confidence regions, and (ii) exploratory
queries probing occluded areas via a two-stage offset. Only query-specific BEV
features are exchanged and fused through multi-scale gated deformable
attention, reducing payload while preserving accuracy. For evaluation, we
release OPV2V-R and Adver-City-R, CARLA-based datasets with per-point Doppler
radar. SlimComm achieves up to 90% lower bandwidth than full-map sharing while
matching or surpassing prior baselines across varied traffic densities and
occlusions. Dataset and code will be available at: https://url.fzi.de/SlimComm.

</details>


### [279] [Matrix-Game 2.0: An Open-Source, Real-Time, and Streaming Interactive World Model](https://arxiv.org/abs/2508.13009)
*Xianglong He,Chunli Peng,Zexiang Liu,Boyang Wang,Yifan Zhang,Qi Cui,Fei Kang,Biao Jiang,Mengyin An,Yangyang Ren,Baixin Xu,Hao-Xiang Guo,Kaixiong Gong,Cyrus Wu,Wei Li,Xuchen Song,Yang Liu,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game 2.0是一个实时交互式世界模型，通过少步自回归扩散生成高质量长视频，速度达到25FPS


<details>
  <summary>Details</summary>
Motivation: 现有交互式世界模型依赖双向注意力和冗长推理步骤，限制了实时性能，难以模拟需要即时更新的真实世界动态

Method: 包含三个关键组件：1)可扩展的虚幻引擎和GTA5数据生产流水线；2)支持帧级鼠标键盘输入的动作注入模块；3)基于因果架构的少步蒸馏技术

Result: 能够生成分钟级高质量视频，在多样化场景中以25FPS的超快速度运行

Conclusion: 该框架为交互式世界建模研究提供了实时高效的解决方案，并开源了模型权重和代码库

Abstract: Recent advances in interactive video generations have demonstrated diffusion
model's potential as world models by capturing complex physical dynamics and
interactive behaviors. However, existing interactive world models depend on
bidirectional attention and lengthy inference steps, severely limiting
real-time performance. Consequently, they are hard to simulate real-world
dynamics, where outcomes must update instantaneously based on historical
context and current actions. To address this, we present Matrix-Game 2.0, an
interactive world model generates long videos on-the-fly via few-step
auto-regressive diffusion. Our framework consists of three key components: (1)
A scalable data production pipeline for Unreal Engine and GTA5 environments to
effectively produce massive amounts (about 1200 hours) of video data with
diverse interaction annotations; (2) An action injection module that enables
frame-level mouse and keyboard inputs as interactive conditions; (3) A few-step
distillation based on the casual architecture for real-time and streaming video
generation. Matrix Game 2.0 can generate high-quality minute-level videos
across diverse scenes at an ultra-fast speed of 25 FPS. We open-source our
model weights and codebase to advance research in interactive world modeling.

</details>


### [280] [EgoTwin: Dreaming Body and View in First Person](https://arxiv.org/abs/2508.13013)
*Jingqiao Xiu,Fangzhou Hong,Yicong Li,Mengze Li,Wentao Wang,Sirui Han,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: EgoTwin是一个基于扩散变换器的联合视频-运动生成框架，专门解决第一人称视角视频和人体运动的联合生成任务，通过头中心运动表示和网络控制启发的交互机制实现视角对齐和因果交互。


<details>
  <summary>Details</summary>
Motivation: 虽然外中心视角视频合成取得了很大进展，但第一人称视角视频生成仍然很少被探索，这需要同时建模第一人称视角内容和穿戴者身体运动引起的相机运动模式。

Method: 提出EgoTwin框架，采用头中心运动表示将人体运动锚定到头部关节，并引入网络控制启发的交互机制在注意力操作中显式捕捉视频和运动之间的因果交互。

Result: 构建了大规模的真实世界文本-视频-运动三元组数据集，设计了新的评估指标来评估视频-运动一致性，大量实验证明了EgoTwin框架的有效性。

Conclusion: EgoTwin成功解决了第一人称视频生成中的视角对齐和因果交互挑战，为联合视频-运动生成任务提供了有效的解决方案。

Abstract: While exocentric video synthesis has achieved great progress, egocentric
video generation remains largely underexplored, which requires modeling
first-person view content along with camera motion patterns induced by the
wearer's body movements. To bridge this gap, we introduce a novel task of joint
egocentric video and human motion generation, characterized by two key
challenges: 1) Viewpoint Alignment: the camera trajectory in the generated
video must accurately align with the head trajectory derived from human motion;
2) Causal Interplay: the synthesized human motion must causally align with the
observed visual dynamics across adjacent video frames. To address these
challenges, we propose EgoTwin, a joint video-motion generation framework built
on the diffusion transformer architecture. Specifically, EgoTwin introduces a
head-centric motion representation that anchors the human motion to the head
joint and incorporates a cybernetics-inspired interaction mechanism that
explicitly captures the causal interplay between video and motion within
attention operations. For comprehensive evaluation, we curate a large-scale
real-world dataset of synchronized text-video-motion triplets and design novel
metrics to assess video-motion consistency. Extensive experiments demonstrate
the effectiveness of the EgoTwin framework.

</details>


### [281] [HierAdaptMR: Cross-Center Cardiac MRI Reconstruction with Hierarchical Feature Adapters](https://arxiv.org/abs/2508.13026)
*Ruru Xu,Ilkay Oksuz*

Main category: cs.CV

TL;DR: HierAdaptMR是一个用于心脏MRI重建的分层特征适应框架，通过参数高效的适配器解决多中心域偏移问题，在CMRxRecon2025数据集上表现出优异的跨中心泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习心脏MRI重建在不同临床中心的异构扫描仪配置和成像协议下面临显著的域偏移挑战，需要解决多级域变化问题。

Method: 提出分层特征适应框架：协议级适配器处理序列特定特征，中心级适配器处理扫描仪相关变化，基于变分展开骨干网络。通用适配器通过随机训练学习中心不变适应，实现完全未见中心的泛化。使用多尺度SSIM损失和频域增强进行优化。

Result: 在CMRxRecon2025数据集（5+中心、10+扫描仪、9种模态）上的综合评估显示，该方法在保持重建质量的同时具有优越的跨中心泛化性能。

Conclusion: HierAdaptMR框架通过分层适配器有效解决了多中心心脏MRI重建的域偏移问题，为临床部署提供了可靠的跨中心泛化解决方案。

Abstract: Deep learning-based cardiac MRI reconstruction faces significant domain shift
challenges when deployed across multiple clinical centers with heterogeneous
scanner configurations and imaging protocols. We propose HierAdaptMR, a
hierarchical feature adaptation framework that addresses multi-level domain
variations through parameter-efficient adapters. Our method employs
Protocol-Level Adapters for sequence-specific characteristics and Center-Level
Adapters for scanner-dependent variations, built upon a variational unrolling
backbone. A Universal Adapter enables generalization to entirely unseen centers
through stochastic training that learns center-invariant adaptations. The
framework utilizes multi-scale SSIM loss with frequency domain enhancement and
contrast-adaptive weighting for robust optimization. Comprehensive evaluation
on the CMRxRecon2025 dataset spanning 5+ centers, 10+ scanners, and 9
modalities demonstrates superior cross-center generalization while maintaining
reconstruction quality. code: https://github.com/Ruru-Xu/HierAdaptMR

</details>


### [282] [IntelliCap: Intelligent Guidance for Consistent View Sampling](https://arxiv.org/abs/2508.13043)
*Ayaka Yasunaga,Hideo Saito,Dieter Schmalstieg,Shohei Mori*

Main category: cs.CV

TL;DR: 一种基于视觉-语言模型的扫描指导技术，通过识别重要物体并生成球面代理来指导用户进行多尺度场景扫描，以改善新视角合成的输入图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前的3D高斯散点等新视角合成技术已经很成熟，但在实际扫描过程中，人类操作者容易因紧张、耐心不足或对场景结构的不理解而导致图像采集不均匀、不密集，影响最终渲染质量。现有的扫描指导方法要么只关注单个物体，要么忽略了视角依赖的材质特性。

Method: 提出了一种位置可视化技术：1）利用语义分割和类别识别来识别场景中的重要物体；2）使用视觉-语言模型对物体进行排名；3）为高排名的重要物体生成球面代理，在扫描过程中指导用户采集更多视角的图像，以更好地表现视角依赖的外观特性。

Result: 在真实场景中进行测试，该方法在性能上显著优于传统的视角采样策略，能够生成质量更高的新视角合成结果。

Conclusion: 该研究提出的扫描指导技术能够有效解决实际扫描过程中的图像采集问题，通过自动识别重要物体并提供有针对性的扫描指导，显著提升了新视角合成的输入图像质量和最终渲染效果。

Abstract: Novel view synthesis from images, for example, with 3D Gaussian splatting,
has made great progress. Rendering fidelity and speed are now ready even for
demanding virtual reality applications. However, the problem of assisting
humans in collecting the input images for these rendering algorithms has
received much less attention. High-quality view synthesis requires uniform and
dense view sampling. Unfortunately, these requirements are not easily addressed
by human camera operators, who are in a hurry, impatient, or lack understanding
of the scene structure and the photographic process. Existing approaches to
guide humans during image acquisition concentrate on single objects or neglect
view-dependent material characteristics. We propose a novel situated
visualization technique for scanning at multiple scales. During the scanning of
a scene, our method identifies important objects that need extended image
coverage to properly represent view-dependent appearance. To this end, we
leverage semantic segmentation and category identification, ranked by a
vision-language model. Spherical proxies are generated around highly ranked
objects to guide the user during scanning. Our results show superior
performance in real scenes compared to conventional view sampling strategies.

</details>


### [283] [Odo: Depth-Guided Diffusion for Identity-Preserving Body Reshaping](https://arxiv.org/abs/2508.13065)
*Siddharth Khandelwal,Sridhar Kamath,Arjun Jain*

Main category: cs.CV

TL;DR: 人体形状编辑新方法Odo，通过洞浊模型和深度地图控制，实现了更准确和超过基准方法的人体形状编辑效果


<details>
  <summary>Details</summary>
Motivation: 人体形状编辑相比姿势编辑研究较少，现有方法存在身体比例不真实、纹理扭曲和背景不一致等问题，且缺乏大规模数据集支持

Method: 构建了包含18,573张图片的大规模数据集，提出Odo方法：结合冻结UNet保持外观细节和背景，使用ControlNet通过目标SMPL深度地图指导形状变换

Result: 方法表现超过之前方法，达到每个顶点重建误差仅7.5mm（基准方法为13.6mm），生成的结果更加现实且准确匹配目标形状

Conclusion: 该研究为人体形状编辑领域提供了重要的数据集支持和有效的算法方法，Odo方法能够在保持原图外观细节的同时实现高质量的人体形状变换

Abstract: Human shape editing enables controllable transformation of a person's body
shape, such as thin, muscular, or overweight, while preserving pose, identity,
clothing, and background. Unlike human pose editing, which has advanced
rapidly, shape editing remains relatively underexplored. Current approaches
typically rely on 3D morphable models or image warping, often introducing
unrealistic body proportions, texture distortions, and background
inconsistencies due to alignment errors and deformations. A key limitation is
the lack of large-scale, publicly available datasets for training and
evaluating body shape manipulation methods. In this work, we introduce the
first large-scale dataset of 18,573 images across 1523 subjects, specifically
designed for controlled human shape editing. It features diverse variations in
body shape, including fat, muscular and thin, captured under consistent
identity, clothing, and background conditions. Using this dataset, we propose
Odo, an end-to-end diffusion-based method that enables realistic and intuitive
body reshaping guided by simple semantic attributes. Our approach combines a
frozen UNet that preserves fine-grained appearance and background details from
the input image with a ControlNet that guides shape transformation using target
SMPL depth maps. Extensive experiments demonstrate that our method outperforms
prior approaches, achieving per-vertex reconstruction errors as low as 7.5mm,
significantly lower than the 13.6mm observed in baseline methods, while
producing realistic results that accurately match the desired target shapes.

</details>


### [284] [Eyes on the Image: Gaze Supervised Multimodal Learning for Chest X-ray Diagnosis and Report Generation](https://arxiv.org/abs/2508.13068)
*Tanjim Islam Riju,Shuchismita Anwar,Saman Sarker Joy,Farig Sadeque,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 提出两阶段多模态框架，通过整合放射科医生眼动数据提升胸部X光疾病分类和区域感知报告生成性能


<details>
  <summary>Details</summary>
Motivation: 利用放射科医生的眼动追踪信号来增强医学影像分析的准确性和生成报告的可解释性

Method: 第一阶段：基于注视引导的对比学习架构，整合视觉特征、临床标签、边界框和眼动信号，使用多术语注视注意力损失函数；第二阶段：模块化报告生成流程，提取置信度加权的诊断关键词，通过结构化提示生成区域对齐的句子

Result: 疾病分类F1分数从0.597提升至0.631(+5.70%)，AUC从0.821提升至0.849(+3.41%)，同时提高了精确率和召回率；报告生成质量在临床关键词召回率和ROUGE重叠度方面均有改善

Conclusion: 整合眼动数据能够同时提升分类性能和生成医学报告的可解释性，证明了注视信息在医学影像分析中的有效性

Abstract: We propose a two-stage multimodal framework that enhances disease
classification and region-aware radiology report generation from chest X-rays,
leveraging the MIMIC-Eye dataset. In the first stage, we introduce a
gaze-guided contrastive learning architecture for disease classification. It
integrates visual features, clinical labels, bounding boxes, and radiologist
eye-tracking signals and is equipped with a novel multi-term gaze-attention
loss combining MSE, KL divergence, correlation, and center-of-mass alignment.
Incorporating fixations improves F1 score from 0.597 to 0.631 (+5.70%) and AUC
from 0.821 to 0.849 (+3.41%), while also improving precision and recall,
highlighting the effectiveness of gaze-informed attention supervision. In the
second stage, we present a modular report generation pipeline that extracts
confidence-weighted diagnostic keywords, maps them to anatomical regions using
a curated dictionary constructed from domain-specific priors, and generates
region-aligned sentences via structured prompts. This pipeline improves report
quality as measured by clinical keyword recall and ROUGE overlap. Our results
demonstrate that integrating gaze data improves both classification performance
and the interpretability of generated medical reports.

</details>


### [285] [ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset](https://arxiv.org/abs/2508.13078)
*Qingwen Zeng,Juan E. Tapia,Izan Garcia,Juan M. Espin,Christoph Busch*

Main category: cs.CV

TL;DR: 使用Stable Diffusion生成合成真实ID卡图像来解决证件攻击检测系统训练数据不足的问题，提升检测器的演化能力


<details>
  <summary>Details</summary>
Motivation: 解决ID卡证件攻击检测系统训练数据不足的问题，当前算法主要关注生成攻击样本而忽略真实图像的限制

Method: 使用Stable Diffusion生成合成真实ID卡图像，在从头训练的系统和商业解决方案中评估新生成的图像

Result: 证件攻击检测系统将生成的图像识别为真实图像，对检测性能和数据限制都产生了积极影响

Conclusion: 通过生成合成真实ID卡图像可以有效解决训练数据不足的问题，提升证件攻击检测系统的演化能力

Abstract: Nowadays, the development of a Presentation Attack Detection (PAD) system for
ID cards presents a challenge due to the lack of images available to train a
robust PAD system and the increase in diversity of possible attack instrument
species. Today, most algorithms focus on generating attack samples and do not
take into account the limited number of bona fide images. This work is one of
the first to propose a method for mimicking bona fide images by generating
synthetic versions of them using Stable Diffusion, which may help improve the
generalisation capabilities of the detector. Furthermore, the new images
generated are evaluated in a system trained from scratch and in a commercial
solution. The PAD system yields an interesting result, as it identifies our
images as bona fide, which has a positive impact on detection performance and
data restrictions.

</details>


### [286] [Checkmate: interpretable and explainable RSVQA is the endgame](https://arxiv.org/abs/2508.13086)
*Lucrezia Tosato,Christel Tartini Chappuis,Syrielle Montariol,Flora Weissgerber,Sylvain Lobry,Devis Tuia*

Main category: cs.CV

TL;DR: 提出新的Chessboard RSVQA数据集和Checkmate模型，解决远感视觉问答中的可解释性和偏差问题


<details>
  <summary>Details</summary>
Motivation: 当前远感视觉问答模型缺乏可解释性和可说明性，并存在数据集偏差导致的短路学习问题

Method: 构建包含3,123,253个问题的Chessboard数据集，答案分布均衡，每个答案与图像单元格相关联；发展Checkmate模型，识别决策最相关的图像单元

Result: 通过多种模型架构的实验验证，该方法提高了透明度和可信过性

Conclusion: 该研究为RSVQA系统提供了更可解释和可信的决策支持

Abstract: Remote Sensing Visual Question Answering (RSVQA) presents unique challenges
in ensuring that model decisions are both understandable and grounded in visual
content. Current models often suffer from a lack of interpretability and
explainability, as well as from biases in dataset distributions that lead to
shortcut learning. In this work, we tackle these issues by introducing a novel
RSVQA dataset, Chessboard, designed to minimize biases through 3'123'253
questions and a balanced answer distribution. Each answer is linked to one or
more cells within the image, enabling fine-grained visual reasoning.
  Building on this dataset, we develop an explainable and interpretable model
called Checkmate that identifies the image cells most relevant to its
decisions. Through extensive experiments across multiple model architectures,
we show that our approach improves transparency and supports more trustworthy
decision-making in RSVQA systems.

</details>


### [287] [DMS:Diffusion-Based Multi-Baseline Stereo Generation for Improving Self-Supervised Depth Estimation](https://arxiv.org/abs/2508.13091)
*Zihua Liu,Yizhou Li,Songyan Zhang,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: 提出DMS方法，利用扩散模型生成新视角图像来解决自监督立体匹配和单目深度估计中的遮挡问题，无需额外标注数据即可显著提升性能


<details>
  <summary>Details</summary>
Motivation: 自监督立体匹配和单目深度估计方法在遮挡区域存在对应像素缺失问题，导致光度重建模糊，需要更好的解决方案

Method: 基于Stable Diffusion模型微调，沿极线方向生成三个新视角图像（左-左视图、右-右视图和中间视图），补充遮挡像素以建立明确的光度对应关系

Result: 在多个基准数据集上实现最先进性能，异常值减少高达35%

Conclusion: DMS是一种即插即用的模型无关方法，仅需未标注的立体图像对即可有效提升自监督立体匹配和深度估计性能

Abstract: While supervised stereo matching and monocular depth estimation have advanced
significantly with learning-based algorithms, self-supervised methods using
stereo images as supervision signals have received relatively less focus and
require further investigation. A primary challenge arises from ambiguity
introduced during photometric reconstruction, particularly due to missing
corresponding pixels in ill-posed regions of the target view, such as
occlusions and out-of-frame areas. To address this and establish explicit
photometric correspondences, we propose DMS, a model-agnostic approach that
utilizes geometric priors from diffusion models to synthesize novel views along
the epipolar direction, guided by directional prompts. Specifically, we
finetune a Stable Diffusion model to simulate perspectives at key positions:
left-left view shifted from the left camera, right-right view shifted from the
right camera, along with an additional novel view between the left and right
cameras. These synthesized views supplement occluded pixels, enabling explicit
photometric reconstruction. Our proposed DMS is a cost-free, ''plug-and-play''
method that seamlessly enhances self-supervised stereo matching and monocular
depth estimation, and relies solely on unlabeled stereo image pairs for both
training and synthesizing. Extensive experiments demonstrate the effectiveness
of our approach, with up to 35% outlier reduction and state-of-the-art
performance across multiple benchmark datasets.

</details>


### [288] [Real-Time Beach Litter Detection and Counting: A Comparative Analysis of RT-DETR Model Variants](https://arxiv.org/abs/2508.13101)
*Miftahul Huda,Arsyiah Azahra,Putri Maulida Chairani,Dimas Rizky Ramadhani,Nabila Azhari,Ade Lailani*

Main category: cs.CV

TL;DR: RT-DETR-L模型在检测精度略低于RT-DETR-X的情况下，推理速度快41.7%，更适合实时海滩垃圾检测的实际部署。


<details>
  <summary>Details</summary>
Motivation: 海岸污染是全球性环境问题，需要可扩展的自动化监测解决方案。本研究旨在评估最先进的端到端目标检测模型RT-DETR在自动化海滩垃圾检测和计数中的有效性。

Method: 对两种RT-DETR变体（RT-DETR-L和RT-DETR-X）在公开海岸垃圾数据集上进行严格的比较分析，评估检测精度和推理速度。

Result: RT-DETR-X模型精度略高（mAP@50: 0.816, mAP@50-95: 0.612），但RT-DETR-L模型推理速度显著更快（20.1ms vs 34.5ms）。

Conclusion: RT-DETR-L模型在检测精度和计算效率之间提供了更好的平衡，更适合实时野外部署，为基于Transformer的先进检测器在环境保护中的应用提供了重要见解。

Abstract: Coastal pollution is a pressing global environmental issue, necessitating
scalable and automated solutions for monitoring and management. This study
investigates the efficacy of the Real-Time Detection Transformer (RT-DETR), a
state-of-the-art, end-to-end object detection model, for the automated
detection and counting of beach litter. A rigorous comparative analysis is
conducted between two model variants, RT-DETR-Large (RT-DETR-L) and
RT-DETR-Extra-Large (RT-DETR-X), trained on a publicly available dataset of
coastal debris. The evaluation reveals that the RT-DETR-X model achieves
marginally superior accuracy, with a mean Average Precision at 50\% IoU
(mAP@50) of 0.816 and a mAP@50-95 of 0.612, compared to the RT-DETR-L model's
0.810 and 0.606, respectively. However, this minor performance gain is realized
at a significant computational cost; the RT-DETR-L model demonstrates a
substantially faster inference time of 20.1 ms versus 34.5 ms for the
RT-DETR-X. The findings suggest that the RT-DETR-L model offers a more
practical and efficient solution for real-time, in-field deployment due to its
superior balance of processing speed and detection accuracy. This research
provides valuable insights into the application of advanced Transformer-based
detectors for environmental conservation, highlighting the critical trade-offs
between model complexity and operational viability.

</details>


### [289] [Precise Action-to-Video Generation Through Visual Action Prompts](https://arxiv.org/abs/2508.13104)
*Yuang Wang,Chao Wen,Haoyu Guo,Sida Peng,Minghan Qin,Hujun Bao,Xiaowei Zhou,Ruizhen Hu*

Main category: cs.CV

TL;DR: 视觉动作提示（VAP）通过将动作渲染为精确的视觉骨架表示，解决了动作到视频生成中的精确性与跨领域转移性的争议。


<details>
  <summary>Details</summary>
Motivation: 现有的动作驱动视频生成方法存在精确性与通用性的争议：文本、原始动作或粗糕掩码方法通用性好但缺乏精确性，而代理中心动作信号虽有精确性但跨领域转移性差。

Method: 将动作"渲染"为精确的视觉提示（视觉骨架）作为领域无关表示，保持几何精确性和跨领域适配性。构建了从人类-物体交互（HOI）和灵巧机器人操作数据源获取骨架的稳健流程，通过轻量级微调将视觉骨架集成到预训练视频生成模型中。

Result: 在EgoVid、RT-1和DROID数据集上的实验证明了方法的有效性，能够在保持跨领域动态学习的同时实现精确的复杂交互动作控制。

Conclusion: 视觉动作提示提供了一种统一的动作表示方案，最大限度地平衡了高精度动作控制和跨领域动态转移的需求，为复杂高自由度交互的视频生成开启了新方向。

Abstract: We present visual action prompts, a unified action representation for
action-to-video generation of complex high-DoF interactions while maintaining
transferable visual dynamics across domains. Action-driven video generation
faces a precision-generality trade-off: existing methods using text, primitive
actions, or coarse masks offer generality but lack precision, while
agent-centric action signals provide precision at the cost of cross-domain
transferability. To balance action precision and dynamic transferability, we
propose to "render" actions into precise visual prompts as domain-agnostic
representations that preserve both geometric precision and cross-domain
adaptability for complex actions; specifically, we choose visual skeletons for
their generality and accessibility. We propose robust pipelines to construct
skeletons from two interaction-rich data sources - human-object interactions
(HOI) and dexterous robotic manipulation - enabling cross-domain training of
action-driven generative models. By integrating visual skeletons into
pretrained video generation models via lightweight fine-tuning, we enable
precise action control of complex interaction while preserving the learning of
cross-domain dynamics. Experiments on EgoVid, RT-1 and DROID demonstrate the
effectiveness of our proposed approach. Project page:
https://zju3dv.github.io/VAP/.

</details>


### [290] [Motion2Motion: Cross-topology Motion Transfer with Sparse Correspondence](https://arxiv.org/abs/2508.13139)
*Ling-Hao Chen,Yuhong Zhang,Zixin Yin,Zhiyang Dou,Xin Chen,Jingbo Wang,Taku Komura,Lei Zhang*

Main category: cs.CV

TL;DR: Motion2Motion是一个无需训练的新框架，用于在不同骨骼拓扑结构的角色间进行动作迁移，仅需目标骨骼上的少量示例动作即可实现高效可靠的动作转移。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨骼拓扑结构角色间的动作迁移挑战，现有方法难以建立一对一的骨骼对应关系，且缺乏大规模配对动作数据集来支持数据驱动方法。

Method: 基于稀疏骨骼对应关系，仅使用目标骨骼上的一个或几个示例动作，无需训练即可实现动作迁移。

Result: 在相似骨骼和跨物种骨骼转移场景中均表现出高效可靠的性能，成功集成到下游应用和用户界面中。

Conclusion: Motion2Motion框架为解决跨拓扑结构动作迁移问题提供了实用解决方案，具有工业应用潜力。

Abstract: This work studies the challenge of transfer animations between characters
whose skeletal topologies differ substantially. While many techniques have
advanced retargeting techniques in decades, transfer motions across diverse
topologies remains less-explored. The primary obstacle lies in the inherent
topological inconsistency between source and target skeletons, which restricts
the establishment of straightforward one-to-one bone correspondences. Besides,
the current lack of large-scale paired motion datasets spanning different
topological structures severely constrains the development of data-driven
approaches. To address these limitations, we introduce Motion2Motion, a novel,
training-free framework. Simply yet effectively, Motion2Motion works with only
one or a few example motions on the target skeleton, by accessing a sparse set
of bone correspondences between the source and target skeletons. Through
comprehensive qualitative and quantitative evaluations, we demonstrate that
Motion2Motion achieves efficient and reliable performance in both
similar-skeleton and cross-species skeleton transfer scenarios. The practical
utility of our approach is further evidenced by its successful integration in
downstream applications and user interfaces, highlighting its potential for
industrial applications. Code and data are available at
https://lhchen.top/Motion2Motion.

</details>


### [291] [IGFuse: Interactive 3D Gaussian Scene Reconstruction via Multi-Scans Fusion](https://arxiv.org/abs/2508.13153)
*Wenhao Hu,Zesheng Li,Haonan Zhou,Liu Liu,Xuexiang Wen,Zhizhong Su,Xi Li,Gaoang Wang*

Main category: cs.CV

TL;DR: IGFuse是一个新颖的3D场景重建框架，通过融合多视角扫描数据来重建交互式高斯场景，解决了传统方法中物体遮挡和传感器覆盖限制的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重建方法面临物体遮挡和传感器覆盖限制的挑战，多阶段流程容易出错且难以扩展，需要一种能够有效处理遮挡并支持场景操作的解决方案。

Method: 构建分割感知的高斯场，通过双向光度和语义一致性约束跨扫描数据，引入伪中间场景状态进行统一对齐，采用协作共剪枝策略优化几何结构。

Result: 实验验证了该框架对新场景配置的强泛化能力，能够实现高保真渲染和物体级场景操作，无需密集观测或复杂流程。

Conclusion: IGFuse为真实世界3D重建和真实到仿真的转换提供了有效的解决方案，在多个扫描数据融合和场景重建方面表现出色。

Abstract: Reconstructing complete and interactive 3D scenes remains a fundamental
challenge in computer vision and robotics, particularly due to persistent
object occlusions and limited sensor coverage. Multiview observations from a
single scene scan often fail to capture the full structural details. Existing
approaches typically rely on multi stage pipelines, such as segmentation,
background completion, and inpainting or require per-object dense scanning,
both of which are error-prone, and not easily scalable. We propose IGFuse, a
novel framework that reconstructs interactive Gaussian scene by fusing
observations from multiple scans, where natural object rearrangement between
captures reveal previously occluded regions. Our method constructs segmentation
aware Gaussian fields and enforces bi-directional photometric and semantic
consistency across scans. To handle spatial misalignments, we introduce a
pseudo-intermediate scene state for unified alignment, alongside collaborative
co-pruning strategies to refine geometry. IGFuse enables high fidelity
rendering and object level scene manipulation without dense observations or
complex pipelines. Extensive experiments validate the framework's strong
generalization to novel scene configurations, demonstrating its effectiveness
for real world 3D reconstruction and real-to-simulation transfer. Our project
page is available online.

</details>


### [292] [4DNeX: Feed-Forward 4D Generative Modeling Made Easy](https://arxiv.org/abs/2508.13154)
*Zhaoxi Chen,Tianqi Liu,Long Zhuo,Jiawei Ren,Zeng Tao,He Zhu,Fangzhou Hong,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 4DNeX是首个从前馈框架从单张图像生成4D（动态3D）场景表示的方法，通过微调预训练视频扩散模型实现高效的端到端图像到4D生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖计算密集型优化或需要多帧视频输入的问题，缓解4D数据稀缺性，为生成式4D世界模型奠定基础。

Method: 1)构建大规模4DNeX-10M数据集；2)引入统一6D视频表示联合建模RGB和XYZ序列；3)提出有效的适配策略将预训练视频扩散模型重新用于4D建模。

Result: 生成高质量动态点云，支持新颖视角视频合成，在效率和泛化性方面优于现有4D生成方法。

Conclusion: 4DNeX为图像到4D建模提供了可扩展解决方案，为模拟动态场景演化的生成式4D世界模型奠定了基础。

Abstract: We present 4DNeX, the first feed-forward framework for generating 4D (i.e.,
dynamic 3D) scene representations from a single image. In contrast to existing
methods that rely on computationally intensive optimization or require
multi-frame video inputs, 4DNeX enables efficient, end-to-end image-to-4D
generation by fine-tuning a pretrained video diffusion model. Specifically, 1)
to alleviate the scarcity of 4D data, we construct 4DNeX-10M, a large-scale
dataset with high-quality 4D annotations generated using advanced
reconstruction approaches. 2) we introduce a unified 6D video representation
that jointly models RGB and XYZ sequences, facilitating structured learning of
both appearance and geometry. 3) we propose a set of simple yet effective
adaptation strategies to repurpose pretrained video diffusion models for 4D
modeling. 4DNeX produces high-quality dynamic point clouds that enable
novel-view video synthesis. Extensive experiments demonstrate that 4DNeX
outperforms existing 4D generation methods in efficiency and generalizability,
offering a scalable solution for image-to-4D modeling and laying the foundation
for generative 4D world models that simulate dynamic scene evolution.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [293] [LSM-OPD: Boosting Scan in LSM-Trees by Enabling Direct Computing on Compressed Data](https://arxiv.org/abs/2508.11862)
*Jianfeng Huang,Ziyao Wang,Lin Yuan,Jiajie Wen,Yihao Cao,Dongjing Miao,Yong Wang,Jiahao Zhang*

Main category: cs.DB

TL;DR: LSM-OPD是一种基于字典编码的LSM树优化方案，通过在压缩数据上直接计算来解决扫描密集型操作的性能瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 随着高性能存储设备（如NVMe SSD）的普及，LSM树中的扫描操作（如后台压缩和值过滤）已成为主要性能瓶颈。对于慢速设备是I/O限制，对于快速设备是计算限制，而随着值大小的增加，所有设备的吞吐量都会急剧下降

Method: 提出LSM-OPD（Log-Structured Merge-Order-Preserving Dictionary）编码方案，支持在压缩数据上直接计算。采用键值分离的数据刷盘方式，以密集编码的列式布局存储，利用保序字典特性将昂贵的扫描操作卸载到轻量级字典上，并采用SIMD向量化技术最大化多核处理器性能

Result: 大量实验证明LSM-OPD在处理涉及密集扫描操作的各种工作负载时，在不同现代存储设备上都具有卓越的效率

Conclusion: LSM-OPD通过创新的字典编码方案有效解决了LSM树在扫描密集型操作中的性能瓶颈问题，既缓解了I/O限制也突破了计算限制，为现代数据密集型应用提供了高效的存储解决方案

Abstract: Scan-based operations, such as backstage compaction and value filtering, have
emerged as the main bottleneck for LSM-Trees in supporting contemporary
data-intensive applications. For slower external storage devices, such as HDD
and SATA SSD, the scan performance is primarily limited by the I/O bandwidth
(i.e., I/O bound) due to the substantial read/write amplifications in
LSM-Trees. Recent adoption of high-performance storage devices, such as NVMe
SSD, has transformed the main limitation to be compute-bound, emerging the
impact of computational resource consumption caused by inefficient compactions
and filtering. However, when the value size increases, the bottleneck for scan
performance in fast devices gradually shifts towards the I/O bandwidth as well,
and the overall throughput across all types of devices undergo a dramatic
reduction. This paper addresses the core issues by proposing LSM-OPD, a Log-S
tructured M erge-O rder- Preserving Dictionary encoding scheme that enables
direct computing on compressed data within LSM-Trees. It first enables
key-value-separated data flushing to disk in a densely encoded columnar layout,
ideally with few bytes for a large string value (e.g., 1024 bytes), thereby
significantly alleviating the frequent I/O requests caused by intensive scans.
Then, it is capable of offloading the costly scan-based operations on large
values, including compaction and value filtering, to lightweight dictionaries
due to the order-preserving property. And SIMD-based vectorization can now be
employed to maximize the evaluating performance on modern multi-core
processors, further breaking the compute-bound limitations in LSM-trees.
Extensive experiments demonstrate the superior efficiency of LSM-OPD in
processing various workloads that involve intensive scan-based operations on
diverse modern storage devices.

</details>


### [294] [Carry the Tail in Consensus Protocols](https://arxiv.org/abs/2508.12173)
*Suyash Gupta,Dakai Kang,Dahlia Malkhi,Mohammad Sadoghi*

Main category: cs.DB

TL;DR: Carry-the-Tail是首个在部分同步模型下能抵御尾分叉攻击的确定性原子广播协议，在GST后保证非故障领导者恒定比例的提交，并在故障领导者级联情况下保持最优的最坏情况二次通信复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有原子广播解决方案在最坏情况下达到二次通信复杂度，且在尾分叉攻击下吞吐量显著下降。现有抵御尾分叉攻击的方案要么需要二次通信步骤，要么需要计算上不可行的SNARK生成。

Method: 核心技术创新是Carry机制，这是一个实用的即插即用机制，适用于HotStuff系列的流线化协议。Carry保证在尾分叉攻击下的良好性能，消除大多数领导者引起的停滞，同时保持线性流量和协议简单性。

Result: 该协议在GST后保证非故障领导者恒定比例的提交，维持最优的最坏情况二次通信复杂度，并保证线性摊销通信（稳态为线性）。

Conclusion: Carry-the-Tail通过Carry机制成功解决了尾分叉攻击下的性能问题，在保持协议简单性的同时实现了优异的性能表现。

Abstract: We present Carry-the-Tail, the first deterministic atomic broadcast protocol
in partial synchrony that, after GST, guarantees a constant fraction of commits
by non-faulty leaders against tail-forking attacks, and maintains optimal,
worst-case quadratic communication under a cascade of faulty leaders. The
solution also guarantees linear amortized communication, i.e., the steady-state
is linear.
  Prior atomic broadcast solutions achieve quadratic word communication
complexity in the worst case. However, they face a significant degradation in
throughput under tail-forking attack. Existing solutions to tail-forking
attacks require either quadratic communication steps or
computationally-prohibitive SNARK generation.
  The key technical contribution is Carry, a practical drop-in mechanism for
streamlined protocols in the HotStuff family. Carry guarantees good performance
against tail-forking and removes most leader-induced stalls, while retaining
linear traffic and protocol simplicity.

</details>


### [295] [jXBW: Fast Substructure Search in Large-Scale JSONL Datasets for Foundation Model Applications](https://arxiv.org/abs/2508.12536)
*Yasuo Tabei*

Main category: cs.DB

TL;DR: jXBW是一个针对JSONL数据集的快速子结构搜索方法，通过合并树表示、eXtended Burrows-Wheeler变换数据结构和三步搜索算法，显著提升搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有JSONL数据集子结构搜索方法由于需要穷举树遍历和子树匹配，计算成本过高，无法满足现代应用（如基础模型提示工程）的需求。

Method: 提出三个关键技术：(1) 合并多个JSON对象树同时保留个体身份的合并树表示；(2) 基于eXtended Burrows-Wheeler变换的简洁数据结构，支持高效树导航和子路径搜索；(3) 结合路径分解、祖先计算和自适应树标识符收集的三步子结构搜索算法。

Result: 在真实数据集上的实验表明，jXBW相比基于树的方法在小数据集上快16倍，在大数据集上快4700倍，相比基于XML的处理快超过600万倍，同时保持竞争力的内存使用。

Conclusion: jXBW为大规模JSONL数据集提供了高效的子结构搜索解决方案，显著优于现有方法，具有重要的实际应用价值。

Abstract: Substructure search in JSON Lines (JSONL) datasets is essential for modern
applications such as prompt engineering in foundation models, but existing
methods suffer from prohibitive computational costs due to exhaustive tree
traversal and subtree matching. We present jXBW, a fast method for substructure
search on large-scale JSONL datasets. Our method makes three key technical
contributions: (i) a merged tree representation built by merging trees of
multiple JSON objects while preserving individual identities, (ii) a succinct
data structure based on the eXtended Burrows-Wheeler Transform that enables
efficient tree navigation and subpath search, and (iii) an efficient three-step
substructure search algorithm that combines path decomposition, ancestor
computation, and adaptive tree identifier collection to ensure correctness
while avoiding exhaustive tree traversal. Experimental evaluation on real-world
datasets demonstrates that jXBW consistently outperforms existing methods,
achieving speedups of 16$\times$ for smaller datasets and up to 4,700$\times$
for larger datasets over tree-based approaches, and more than 6$\times$10$^6$
over XML-based processing while maintaining competitive memory usage.

</details>


### [296] [Evaluating the Quality of Open Building Datasets for Mapping Urban Inequality: A Comparative Analysis Across 5 Cities](https://arxiv.org/abs/2508.12872)
*Franz Okyere,Meng Lu,Ansgar Brunn*

Main category: cs.DB

TL;DR: 这研究评估了Google和Microsoft生成的AI建筑数据集质量，发现不同城市存在显著差异，非正式定居区域数据质量偏差


<details>
  <summary>Details</summary>
Motivation: 非正式定居区缺乏重点发展且动态性强，空间数据质量不确定。需要评估AI生成建筑数据集的质量和偏差

Method: 使用交并比IoU、重叠分析和位置精度算法，分析Google、Microsoft和OpenStreetMap数据的相似性和对齐情况，分析建筑多边形面积分布和完整性

Result: 数据质量存在显著差异，Houston和Berlin显示高对齐度和完整性，而Accra和Caracas可能被低估，非正式区域数据损失严重，不同建筑规模分布反映全球社会经济分层

Conclusion: 需要重视全球建筑数据集质量，避免数据偏差导致的误导规划和资源分配不公

Abstract: While informal settlements lack focused development and are highly dynamic,
the quality of spatial data for these places may be uncertain. This study
evaluates the quality and biases of AI-generated Open Building Datasets (OBDs)
generated by Google and Microsoft against OpenStreetMap (OSM) data, across
diverse global cities including Accra, Nairobi, Caracas, Berlin, and Houston.
The Intersection over Union (IoU), overlap analysis and a positional accuracy
algorithm are used to analyse the similarity and alignment of the datasets. The
paper also analyses the size distribution of the building polygon area, and
completeness using predefined but regular spatial units. The results indicate
significant variance in data quality, with Houston and Berlin demonstrating
high alignment and completeness, reflecting their structured urban
environments. There are gaps in the datasets analysed, and cities like Accra
and Caracas may be under-represented. This could highlight difficulties in
capturing complex or informal regions. The study also notes different building
size distributions, which may be indicative of the global socio-economic
divide. These findings may emphasise the need to consider the quality of global
building datasets to avoid misrepresentation, which is an important element of
planning and resource distribution.

</details>


### [297] [SPARQL in N3: SPARQL CONSTRUCT as a rule language for the Semantic Web (Extended Version)](https://arxiv.org/abs/2508.13041)
*Dörthe Arndt,William Van Woensel,Dominik Tomaszuk*

Main category: cs.DB

TL;DR: 利用SPARQL CONSTRUCT查询作为逻辑规则，实现表达力强的语义网规则语言和递归执行，并翻译到N3规则语言以利用现有推理机制


<details>
  <summary>Details</summary>
Motivation: 解决语义网中现有规则语言的限制，如OWL2 DL和SWRL表达力不足，RIF采用率低，需要一种更表达力强且易于使用的规则语言

Method: 将SPARQL CONSTRUCT查询作为逻辑规则使用，支持递归执行，然后翻译到Notation3 Logic (N3)规则语言，以利用现有的前向和后向链推理机制

Result: 实现了一种表达力强、熟悉的规则语言，支持递归操作，性能测试显示具有竞争力

Conclusion: 通过SPARQL CONSTRUCT查询作为规则语言，提供了一种有效的解决方案，能够推进语义网中基于规则的推理潜力

Abstract: Reasoning in the Semantic Web (SW) commonly uses Description Logics (DL) via
OWL2 DL ontologies, or SWRL for variables and Horn clauses. The Rule
Interchange Format (RIF) offers more expressive rules but is defined outside
RDF and rarely adopted. For querying, SPARQL is a well-established standard
operating directly on RDF triples. We leverage SPARQL CONSTRUCT queries as
logic rules, enabling (1) an expressive, familiar SW rule language, and (2)
general recursion, where queries can act on the results of others. We translate
these queries to the Notation3 Logic (N3) rule language, allowing use of
existing reasoning machinery with forward and backward chaining. Targeting a
one-to-one query-rule mapping improves exchangeability and interpretability.
Benchmarks indicate competitive performance, aiming to advance the potential of
rule-based reasoning in the SW.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [298] [Proceedings 18th Interaction and Concurrency Experience](https://arxiv.org/abs/2508.12308)
*Clément Aubert,Cinzia Di Giusto,Simon Fowler,Violet Ka I Pun*

Main category: cs.DC

TL;DR: ICE'25会议论文集，包含4篇论文和1个口头报告，采用匿名互动评审机制，共收到7篇投稿并进行了75次评论交流


<details>
  <summary>Details</summary>
Motivation: 促进并发与交互领域的研究交流，通过创新的匿名互动评审机制提高论文质量

Method: 采用PC成员与作者匿名互动的评审流程，每篇投稿由3名PC成员评审，通过评论交流进行深入讨论

Result: 从7篇投稿中接受了4篇论文发表和1个口头报告，举办了Kirstin Peters的邀请报告

Conclusion: ICE会议系列通过创新的互动评审机制成功促进了学术交流，为并发与交互领域的研究提供了高质量的平台

Abstract: This volume contains the proceedings of ICE'25, the 18th Interaction and
Concurrency Experience, which was held on Friday 20th June 2025 at the \'Ecole
National Sup\'erieure des Arts et M\'etiers in Lille, France, as a satellite
workshop of DisCoTec 2025. The ICE workshop series features a distinguishing
review and selection procedure: PC members are encouraged to interact,
anonymously, with authors. The 2025 edition of ICE received 7 submissions, each
reviewed by three PC members, and about 75 comments were exchanged during the
review process, witnessing very lively discussions. Four papers were accepted
for publication plus 1 oral communication, which was accepted for presentation
at the workshop. We were proud to host one invited talk, by Kirstin Peters. The
abstract of her talk is included in this volume, together with the final
versions of the research papers, which take into account the discussion at the
workshop and during the review process.

</details>


### [299] [Breaking the Aggregation Bottleneck in Federated Recommendation: A Personalized Model Merging Approach](https://arxiv.org/abs/2508.12386)
*Jundong Chen,Honglei Zhang,Chunxu Zhang,Fangyuan Luo,Yidong Li*

Main category: cs.DC

TL;DR: FedEM提出弹性合并全局和局部模型来解决联邦推荐中的聚合瓶颈问题，通过理论分析而非启发式方法，利用现成的本地模型提升个性化效果，在真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 联邦推荐中服务器端聚合会损害客户端个性化性能，形成聚合瓶颈问题，这是由于客户端异构性导致全局模型偏离局部最优解。

Method: 提出FedEM方法，弹性合并全局和局部模型来补偿受损的个性化，不需要设计额外的个性化增强机制，直接利用现成的本地模型。

Result: 在真实数据集上的大量实验表明，该方法在协作训练过程中有效保持了客户端个性化，性能优于最先进的基线方法。

Conclusion: FedEM通过理论指导的弹性模型合并策略，成功解决了联邦推荐中的聚合瓶颈问题，为个性化联邦推荐提供了新的有效解决方案。

Abstract: Federated recommendation (FR) facilitates collaborative training by
aggregating local models from massive devices, enabling client-specific
personalization while ensuring privacy. However, we empirically and
theoretically demonstrate that server-side aggregation can undermine
client-side personalization, leading to suboptimal performance, which we term
the aggregation bottleneck. This issue stems from the inherent heterogeneity
across numerous clients in FR, which drives the globally aggregated model to
deviate from local optima. To this end, we propose FedEM, which elastically
merges the global and local models to compensate for impaired personalization.
Unlike existing personalized federated recommendation (pFR) methods, FedEM (1)
investigates the aggregation bottleneck in FR through theoretical insights,
rather than relying on heuristic analysis; (2) leverages off-the-shelf local
models rather than designing additional mechanisms to boost personalization.
Extensive experiments on real-world datasets demonstrate that our method
preserves client personalization during collaborative training, outperforming
state-of-the-art baselines.

</details>


### [300] [DIT: Dimension Reduction View on Optimal NFT Rarity Meters](https://arxiv.org/abs/2508.12671)
*Dmitry Belousov,Yury Yanovich*

Main category: cs.DC

TL;DR: 本文提出了基于降维方法的NFT稀有度评估新框架ROAR，开发了DIT性能指标和最优稀有度计量器，在标准基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: NFT作为重要数字资产类别，其价值与稀有度特征密切相关，但现有稀有度计量器难以直接比较，缺乏标准化评估框架。

Method: 采用非度量加权多维尺度分析进行最优稀有度计量器设计，引入基于降维技术的DIT（交易差异度）性能指标，开发非可解释性稀有度计量器DIT。

Result: 提出的DIT稀有度计量器在ROAR基准测试中表现出优于现有方法的性能，为NFT稀有度评估提供了新的有效工具。

Conclusion: 降维方法在NFT稀有度设计中有显著优势，DIT指标和计量器为行业和学术界提供了标准化评估解决方案，推动了NFT稀有度量化研究的发展。

Abstract: Non-fungible tokens (NFTs) have become a significant digital asset class,
each uniquely representing virtual entities such as artworks. These tokens are
stored in collections within smart contracts and are actively traded across
platforms on Ethereum, Bitcoin, and Solana blockchains. The value of NFTs is
closely tied to their distinctive characteristics that define rarity, leading
to a growing interest in quantifying rarity within both industry and academia.
While there are existing rarity meters for assessing NFT rarity, comparing them
can be challenging without direct access to the underlying collection data. The
Rating over all Rarities (ROAR) benchmark addresses this challenge by providing
a standardized framework for evaluating NFT rarity. This paper explores a
dimension reduction approach to rarity design, introducing new performance
measures and meters, and evaluates them using the ROAR benchmark. Our
contributions to the rarity meter design issue include developing an optimal
rarity meter design using non-metric weighted multidimensional scaling,
introducing Dissimilarity in Trades (DIT) as a performance measure inspired by
dimension reduction techniques, and unveiling the non-interpretable rarity
meter DIT, which demonstrates superior performance compared to existing
methods.

</details>


### [301] [Dissecting CPU-GPU Unified Physical Memory on AMD MI300A APUs](https://arxiv.org/abs/2508.12743)
*Jacob Wahlgren,Gabin Schieffer,Ruimin Shi,Edgar A. León,Roger Pearce,Maya Gokhale,Ivy Peng*

Main category: cs.DC

TL;DR: MI300A APU的UPM架构首次实现CPU和GPU物理内存统一，性能可匹配或超越显式内存管理，同时减少44%内存成本


<details>
  <summary>Details</summary>
Motivation: 传统离散GPU需要管理分离的CPU和GPU内存空间，UVM方案性能代价高，MI300A APU首次提供统一物理内存架构

Method: 分析UPM系统特性（延迟、带宽、一致性开销），评估系统软件效率，提出应用移植策略，评估6个应用在MI300A上的表现

Result: UPM架构下使用统一内存模型的应用性能可匹配或超越显式管理模型，同时减少高达44%的内存成本

Conclusion: MI300A的UPM架构为HPC系统提供了高性能的统一内存解决方案，显著简化内存管理并降低成本

Abstract: Discrete GPUs are a cornerstone of HPC and data center systems, requiring
management of separate CPU and GPU memory spaces. Unified Virtual Memory (UVM)
has been proposed to ease the burden of memory management; however, at a high
cost in performance. The recent introduction of AMD's MI300A Accelerated
Processing Units (APUs)--as deployed in the El Capitan supercomputer--enables
HPC systems featuring integrated CPU and GPU with Unified Physical Memory (UPM)
for the first time. This work presents the first comprehensive characterization
of the UPM architecture on MI300A. We first analyze the UPM system properties,
including memory latency, bandwidth, and coherence overhead. We then assess the
efficiency of the system software in memory allocation, page fault handling,
TLB management, and Infinity Cache utilization. We propose a set of porting
strategies for transforming applications for the UPM architecture and evaluate
six applications on the MI300A APU. Our results show that applications on UPM
using the unified memory model can match or outperform those in the explicitly
managed model--while reducing memory costs by up to 44%.

</details>


### [302] [Accelerating Edge Inference for Distributed MoE Models with Latency-Optimized Expert Placement](https://arxiv.org/abs/2508.12851)
*Tian Wu,Liming Wang,Zijian Wen,Xiaoxi Zhang,Jingpu Duan,Xianwei Zhang,Jinhang Zuo*

Main category: cs.DC

TL;DR: DanceMoE是一个高效的MoE推理框架，通过激活感知的专家放置算法和轻量级迁移机制，在异构边缘服务器上实现协作式MoE推理，显著降低延迟和通信开销。


<details>
  <summary>Details</summary>
Motivation: MoE模型在边缘环境中的部署面临内存占用大、通信复杂等挑战，现有方法主要针对单设备或同构环境，无法有效处理异构边缘服务器的资源约束和工作负载变化。

Method: 提出激活感知的专家放置算法，利用MoE模型的稀疏性和工作负载局部性，在异构GPU边缘服务器间进行专家分配，并设计轻量级迁移机制适应动态工作负载。

Result: 在现代MoE模型和广泛数据集上评估，相比最先进基线方法，推理延迟降低30.6%，通信开销大幅减少。

Conclusion: DanceMoE证明了协作式边缘MoE推理的有效性，为资源受限的边缘环境提供了高效的MoE服务解决方案。

Abstract: Mixture-of-Experts (MoE) have become a cornerstone for training and scaling
large language models (LLMs), offering substantial gains in model capacity and
efficiency through sparse expert activation. However, serving these models
remains challenging in practice, particularly in resource-constrained edge
environments, due to their large memory footprint and complex communication
demands. While centralized cloud inference is common, it incurs high
infrastructure costs, along with latency and privacy concerns. A few recent
edge MoE works propose memory-efficient strategies but typically focus on
single-device or homogeneous setups. This paper presents DanceMoE, an efficient
MoE inference framework that enables activation-aware expert placement across
collaborative, heterogeneous, GPU-equipped edge servers. DanceMoE leverages the
inherent sparsity of MoE models and workload locality to minimize cross-server
communication and enable efficient expert placement under heterogeneous
resource constraints. It introduces a data-driven, activation-aware placement
algorithm that balances local coverage and memory usage across servers,
alongside a lightweight migration mechanism that adapts expert assignments
under evolving workloads. We evaluate DanceMoE on modern MoE models and widely
used datasets, demonstrating up to 30.6\% lower inference latency, and
substantial communication reduction compared to state-of-the-art baselines,
showcasing the effectiveness of collaborative edge-based MoE inference.

</details>


### [303] [WANify: Gauging and Balancing Runtime WAN Bandwidth for Geo-distributed Data Analytics](https://arxiv.org/abs/2508.12961)
*Anshuman Das Mohapatra,Kwangsung Oh*

Main category: cs.DC

TL;DR: WANify是一个通过机器学习动态预测广域网带宽的框架，帮助地理分布式数据分析系统优化数据传输决策，减少延迟和成本。


<details>
  <summary>Details</summary>
Motivation: 现有地理分布式数据分析系统静态测量WAN带宽，无法准确反映运行时动态和并发数据传输情况，导致次优决策和性能下降。

Method: 使用基于决策树的随机森林机器学习算法动态预测运行时WAN带宽，并确定数据中心间异构并行连接的最优数量。

Result: 在AWS 8个地理分布式数据中心上的实验显示，WANify将WAN吞吐量提升，使延迟降低26%，成本减少16%。

Conclusion: WANify通过动态带宽预测和优化连接管理，有效处理网络和工作负载动态性，显著提升地理分布式数据分析系统性能。

Abstract: Accurate wide area network (WAN) bandwidth (BW) is essential for
geo-distributed data analytics (GDA) systems to make optimal decisions such as
data and task placement to improve performance. Existing GDA systems, however,
measure WAN BW statically and independently between data centers (DCs), while
data transfer occurs dynamically and simultaneously among DCs during workload
execution. Also, they use a single connection WAN BW that cannot capture actual
WAN capacities between distant DCs. Such inaccurate WAN BWs yield sub-optimal
decisions, inflating overall query latency and cost. In this paper, we present
WANify, a new framework that precisely and dynamically gauges achievable
runtime WAN BW using a machine learning prediction scheme, decision tree-based
Random Forest. This helps GDA systems make better decisions yielding reduced
latency and costs including WAN BW monitoring costs. Based on predicted runtime
WAN BW, WANify determines the optimal number of heterogeneous parallel
connections for data transfer among DCs. This approach improves performance
without additional, or even at reduced cost, by fully exploiting available WAN
capacities. In addition, WANify considers dynamics like network and workloads,
and heterogeneity like skewed data, heterogeneous compute resources, and a
varying number of DCs while making decisions. The WANify prototype running on
state-of-the-art GDA systems is evaluated on AWS with 8 geo-distributed DCs.
Results show that WANify enhances WAN throughput by balancing between the
strongest and weakest WAN links, enabling GDA systems to reduce latency and
cost by up to 26% and 16% respectively with minimal effort, all while handling
dynamics and heterogeneity efficiently.

</details>


### [304] [Congested Clique Counting for Local Gibbs Distributions](https://arxiv.org/abs/2508.13083)
*Joshua Z. Sobel*

Main category: cs.DC

TL;DR: 提出了在CongestedClique模型中的首个近似计数算法，特别针对图q-着色计数问题，在q>2Δ条件下实现Õ(n¹ᐟ³/ε²)轮复杂度，并推广到Gibbs分布的配分函数近似计算。


<details>
  <summary>Details</summary>
Motivation: 组合采样与计数问题之间存在经典归约关系，但分布式环境下的高效近似计数算法尚未充分探索。本文旨在利用近期并行算法进展，在CongestedClique模型中实现广泛计数问题的近似计算。

Method: 通过构建分布式马尔可夫链并行抽取n个随机样本，借鉴三角形计数和半环矩阵乘法的思想，在满足局部性和快速混合条件的Gibbs分布上实现高效采样。

Result: 实现了Õ(n¹ᐟ³/ε²)轮的图q-着色近似计数算法（q>2Δ），对硬核模型的配分函数估计达到Õ(1/ε²)轮复杂度（λ≤α/(Δ-1)）。

Conclusion: 该工作首次在CongestedClique模型中为广泛计数问题提供了高效近似算法，不仅解决了计数问题，还为其他需要大量样本的应用提供了可能。

Abstract: There are well established reductions between combinatorial sampling and
counting problems (Jerrum, Valiant, Vazirani TCS 1986). Building off of a very
recent parallel algorithm utilizing this connection (Liu, Yin, Zhang arxiv
2024), we demonstrate the first approximate counting algorithm in the
CongestedClique for a wide range of problems. Most interestingly, we present an
algorithm for approximating the number of $q$-colorings of a graph within
$\epsilon$-multiplicative error, when $q>\alpha\Delta$ for any constant
$\alpha>2$, in $\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds. More
generally, we achieve a runtime of
$\Tilde{O}\big(\frac{n^{1/3}}{\epsilon^2}\big)$ rounds for approximating the
partition function of Gibbs distributions defined over graphs when simple
locality and fast mixing conditions hold. Gibbs distributions are widely used
in fields such as machine learning and statistical physics. We obtain our
result by providing an algorithm to draw $n$ random samples from a distributed
Markov chain in parallel, using similar ideas to triangle counting (Dolev,
Lenzen, Peled DISC 2012) and semiring matrix multiplication (Censor-Hillel,
Kaski, Korhonen, Lenzen, Paz, Suomela PODC 2015). Aside from counting problems,
this result may be interesting for other applications requiring a large number
of samples. In the special case of estimating the partition function of the
hardcore model, also known as counting weighted independent sets, we can do
even better and achieve an $\Tilde{O}\big(\frac{1}{\epsilon^2}\big)$ round
algorithm, when the fugacity $\lambda \leq \frac{\alpha}{\Delta-1}$, where
$\alpha$ is an arbitrary constant less than $1$.

</details>


### [305] [Team Formation and Applications](https://arxiv.org/abs/2508.13084)
*Yuval Emek,Shay Kutten,Ido Rafael,Gadi Taubenfeld*

Main category: cs.DC

TL;DR: 这篇论文提出了一种新的长存期分布式问题（团队组建TF）和高效随机算法，通过将多种分布式问题缩减为TF来实现重大算法改进


<details>
  <summary>Details</summary>
Motivation: 解决异步模型下的长存期分布式问题，破觢线性消息复杂度限制，提高算法效率

Method: 提出团队组建问题定义，设计随机化算法在完全通信图中处理节点故障和注入令牌组队

Result: 首次破觢异步隐式领导者选举的线性消息复杂度，改进显式领导者选举时间复杂度，并证明了TF消息复杂度的紧界下界

Conclusion: 团队组建问题作为一种基础原语，可以高效解决多种分布式问题，具有重要的理论价值和应用前景

Abstract: A novel long-lived distributed problem, called Team Formation (TF), is
introduced together with a message- and time-efficient randomized algorithm.
The problem is defined over the asynchronous model with a complete
communication graph, using bounded size messages, where a certain fraction of
the nodes may experience a generalized, strictly stronger, version of initial
failures. The goal of a TF algorithm is to assemble tokens injected by the
environment, in a distributed manner, into teams of size $\sigma$, where
$\sigma$ is a parameter of the problem.
  The usefulness of TF is demonstrated by using it to derive efficient
algorithms for many distributed problems. Specifically, we show that various
(one-shot as well as long-lived) distributed problems reduce to TF. This
includes well-known (and extensively studied) distributed problems such as
several versions of leader election and threshold detection. For example, we
are the first to break the linear message complexity bound for asynchronous
implicit leader election. We also improve the time complexity of
message-optimal algorithms for asynchronous explicit leader election. Other
distributed problems that reduce to TF are new ones, including matching players
in online gaming platforms, a generalization of gathering, constructing a
perfect matching in an induced subgraph of the complete graph, quorum sensing
in message-passing networks, and more. To complement our positive contribution,
we establish a tight lower bound on the message complexity of TF algorithms.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [306] [OddEEC: A New Sketch Technique for Error Estimating Coding](https://arxiv.org/abs/2508.11842)
*Huayi Wang,Jingfan Meng,Jun Xu*

Main category: cs.NI

TL;DR: OddEEC是一种新颖的错误估计编码方案，基于Odd Sketch技术，通过位采样和最大似然估计实现，在保持与gEEC和mEEC相当精度的同时显著降低解码复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的错误估计编码(EEC)技术在无线网络数据包传输中用于估计比特错误数量，但存在解码复杂度较高的问题，需要开发更高效的方案。

Method: 将数据草图技术Odd Sketch非平凡地适配到EEC中，采用位采样技术和最大似然估计器来解决新挑战。

Result: 实验表明OddEEC在整体估计精度上与竞争方案(gEEC和mEEC)相当，但解码复杂度显著降低。

Conclusion: OddEEC是一种有效的EEC方案，在保持精度的同时大幅降低了计算复杂度，具有实际应用价值。

Abstract: Error estimating coding (EEC) is a standard technique for estimating the
number of bit errors during packet transmission over wireless networks. In this
paper, we propose OddEEC, a novel EEC scheme. OddEEC is a nontrivial adaptation
of a data sketching technique named Odd Sketch to EEC, addressing new
challenges therein by its bit sampling technique and maximum likelihood
estimator. Our experiments show that OddEEC overall achieves comparable
estimation accuracy as competing schemes such as gEEC and mEEC, with much
smaller decoding complexity.

</details>


### [307] [Bandit-Based Charging with Beamforming for Mobile Wireless-Powered IoT Systems](https://arxiv.org/abs/2508.11971)
*Chenchen Fu,Zining Zhou,Xiaoxing Qiu,Sujunjie Sun,Weiwei Wu,Song Han*

Main category: cs.NI

TL;DR: 提出基于多臂老虎机的移动充电框架，解决无线供电物联网系统中动态信道条件和实时充电约束的挑战


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽视无线供电物联网网络中移动充电器的动态信道条件和实时充电约束，需要开发能够适应时变信道状态并满足严格充电截止时间的解决方案

Method: 提出时空充电策略，联合确定充电位置、持续时间和波束成形配置；通过区域离散化实现多项式时间枚举；设计两种在线老虎机算法处理平稳和非平稳未知信道状态场景

Result: 实验验证所提算法能够快速接近理论上界，同时有效跟踪动态信道状态进行自适应调整

Conclusion: 该框架为无线供电物联网系统提供了实用的移动充电解决方案，能够处理动态信道条件和实时约束，具有有界的遗憾保证

Abstract: Wireless power transfer (WPT) is increasingly used to sustain
Internet-of-Things (IoT) systems by wirelessly charging embedded devices.
Mobile chargers further enhance scalability in wireless-powered IoT (WP-IoT)
networks, but pose new challenges due to dynamic channel conditions and limited
energy budgets. Most existing works overlook such dynamics or ignore real-time
constraints on charging schedules. This paper presents a bandit-based charging
framework for WP-IoT systems using mobile chargers with practical beamforming
capabilities and real-time charging constraints. We explicitly consider
time-varying channel state information (CSI) and impose a strict charging
deadline in each round, which reflects the hard real-time constraint from the
charger's limited battery capacity. We formulate a temporal-spatial charging
policy that jointly determines the charging locations, durations, and
beamforming configurations. Area discretization enables polynomial-time
enumeration with constant approximation bounds. We then propose two online
bandit algorithms for both stationary and non-stationary unknown channel state
scenarios with bounded regrets. Our extensive experimental results validate
that the proposed algorithms can rapidly approach the theoretical upper bound
while effectively tracking the dynamic channel states for adaptive adjustment.

</details>


### [308] [TailO-RAN: O-RAN Control on Scheduler Parameters to Tailor RAN Performance](https://arxiv.org/abs/2508.12112)
*Nicolo Longhi,Salvatore D'Oro,Leonardo Bonati,Michele Polese,Roberto Verdone,Tommaso Melodia*

Main category: cs.NI

TL;DR: 本文提出了一种可编程调度器设计和O-RAN xApp，通过动态调整调度权重来提高工业物联网中视频传输的速率保障和资产跟踪准确性


<details>
  <summary>Details</summary>
Motivation: 传统的黑盒式单一化无线接入网络(RAN)极大限制了灵活性和创新，需要通过开放化、虚拟化和网络智能化来解决这些限制

Method: 1）为Open RAN分布式单元(DUs)设计可编程调度器，通过可配置权重保证用户设备的最低速率水平
2）提出O-RAN xApp，基于通过通信量报告的联合补充累积分布函数(CCDF)动态重新配置调度器权重

Result: 1）在5G工业物联网资产跟踪场景中，成功满足速率要求的比例提高33%
2）检测准确性(F1分数)最高提高37.04%
3）在OpenAirInterface 5G协议栈和Colosseum Open RAN数字双生环境中实现并验证

Conclusion: 该方案通过可编程调度器和智能xApp的结合，有效提高了Open RAN系统的性能和可靠性，为5G工业应用提供了更好的质量保障

Abstract: The traditional black-box and monolithic approach to Radio Access Networks
(RANs) has heavily limited flexibility and innovation. The Open RAN paradigm,
and the architecture proposed by the O-RAN ALLIANCE, aim to address these
limitations via openness, virtualization and network intelligence. In this
work, first we propose a novel, programmable scheduler design for Open RAN
Distributed Units (DUs) that can guarantee minimum throughput levels to User
Equipments (UEs) via configurable weights. Then, we propose an O-RAN xApp that
reconfigures the scheduler's weights dynamically based on the joint
Complementary Cumulative Distribution Function (CCDF) of reported throughput
values. We demonstrate the effectiveness of our approach by considering the
problem of asset tracking in 5G-powered Industrial Internet of Things (IIoT)
where uplink video transmissions from a set of cameras are used to detect and
track assets via computer vision algorithms. We implement our programmable
scheduler on the OpenAirInterface (OAI) 5G protocol stack, and test the
effectiveness of our xApp control by deploying it on the O-RAN Software
Community (OSC) near-RT RAN Intelligent Controller (RIC) and controlling a 5G
RAN instantiated on the Colosseum Open RAN digital twin. Our experimental
results demonstrate that our approach enhances the success percentage of
meeting throughput requirements by 33% compared to a reference scheduler.
Moreover, in the asset tracking use case, we show that the xApp improves the
detection accuracy, i.e., the F1 score, by up to 37.04%.

</details>


### [309] [An Efficient and Adaptive Framework for Achieving Underwater High-performance Maintenance Networks](https://arxiv.org/abs/2508.12661)
*Yu Gou,Tong Zhang,Jun Liu,Zhongyang Qi,Dezhi Zheng*

Main category: cs.NI

TL;DR: U-HPNF是一个基于深度强化学习和联邦学习的三层数字孪生框架，用于优化水下通信网络的性能、资源管理和服务质量。


<details>
  <summary>Details</summary>
Motivation: 解决空天地海一体化网络中水下通信网络的长传播延迟和有限容量问题，提升网络服务质量。

Method: 采用深度强化学习进行资源管理，联邦学习优化决策模型，数字孪生在智能汇聚层和聚合层进行网络场景模拟。

Result: 数值结果表明U-HPNF能够有效优化各种情况下的网络性能，适应变化的QoS需求。

Conclusion: U-HPNF提供了一个AI原生的高性能水下网络框架，具有自管理、自配置和自优化能力。

Abstract: With the development of space-air-ground-aqua integrated networks (SAGAIN),
high-speed and reliable network services are accessible at any time and any
location. However, the long propagation delay and limited network capacity of
underwater communication networks (UCN) negatively impact the service quality
of SAGAIN. To address this issue, this paper presents U-HPNF, a hierarchical
framework designed to achieve a high-performance network with self-management,
self-configuration, and self-optimization capabilities. U-HPNF leverages the
sensing and decision-making capabilities of deep reinforcement learning (DRL)
to manage limited resources in UCNs, including communication bandwidth,
computational resources, and energy supplies. Additionally, we incorporate
federated learning (FL) to iteratively optimize the decision-making model,
thereby reducing communication overhead and protecting the privacy of node
observation information. By deploying digital twins (DT) at both the
intelligent sink layer and aggregation layer, U-HPNF can mimic numerous network
scenarios and adapt to varying network QoS requirements. Through a three-tier
network design with two-levels DT, U-HPNF provides an AI-native
high-performance underwater network. Numerical results demonstrate that the
proposed U-HPNF framework can effectively optimize network performance across
various situations and adapt to changing QoS requirements.

</details>


### [310] [Game-Theoretic and Reinforcement Learning-Based Cluster Head Selection for Energy-Efficient Wireless Sensor Network](https://arxiv.org/abs/2508.12707)
*Mehrshad Eskandarpour,Saba Pirahmadian,Parham Soltani,Hossein Soleimani*

Main category: cs.NI

TL;DR: 这篇论文提出了一种基于游戏理论和强化学习的聚簇路由策略，通过多步聚簇和动态聚簇头选择优化传感器网络的能源利用效率，延长网络寿命并确保能量均衡分配。


<details>
  <summary>Details</summary>
Motivation: 传感器网络中能量管理至关重要，但短短的电池寿命严重影响网络可靠性和耗耗。当前的节能算法在能源效率方面有限，需要更加自适应和高效的解决方案。

Method: 采用多步聚簇策略选择动态聚簇头，结合游戏理论和多自然强化学习来优化资源利用。通过AI驱动的聚簇头寻找算法实现自动聚簇，确保能量均衡分配和单跳路由。

Result: 该方法能够防止节点过早耗尽能量，实现网络内能量均匀使用，提高了网络效率和稳定性，并实现了可预测的网络寿命。

Conclusion: 提出的方法有效提高了无线传感器网络的能源效率和稳定性，降低了维护成本，通过自动化聚簇和优化路由策略延长了网络寿命。

Abstract: Energy in Wireless Sensor Networks (WSNs) is critical to network lifetime and
data delivery. However, the primary impediment to the durability and
dependability of these sensor nodes is their short battery life. Currently,
power-saving algorithms such as clustering and routing algorithms have improved
energy efficiency in standard protocols. This paper proposes a clustering-based
routing approach for creating an adaptive, energy-efficient mechanism. Our
system employs a multi-step clustering strategy to select dynamic cluster heads
(CH) with optimal energy distribution. We use Game Theory (GT) and
Reinforcement Learning (RL) to optimize resource utilization. Modeling the
network as a multi-agent RL problem using GT principles allows for
self-clustering while optimizing sensor lifetime and energy balance. The
proposed AI-powered CH-Finding algorithm improves network efficiency by
preventing premature energy depletion in specific nodes while also ensuring
uniform energy usage across the network. Our solution enables controlled power
consumption, resulting in a deterministic network lifetime. This predictability
lowers maintenance costs by reducing the need for node replacement.
Furthermore, our proposed method prevents sensor nodes from disconnecting from
the network by designating the sensor with the highest charge as an
intermediary and using single-hop routing. This approach improves the energy
efficiency and stability of Wireless Sensor Network (WSN) deployments.

</details>


### [311] [Towards Nomadic 6G Communication Networks: Implications on Architecture, Standardization, and Regulatory Aspects](https://arxiv.org/abs/2508.12710)
*Daniel Lindenschmitt,Marcos Rates Crippa,Hans D. Schotten*

Main category: cs.NI

TL;DR: 本文探讨6G游牧网络的架构设计，重点关注动态环境中节点通信、服务发现和控制委托的接口需求，并提出针对游牧特性的接口设计原则。


<details>
  <summary>Details</summary>
Motivation: 6G游牧网络的出现带来了网络基础设施概念、部署和运营方式的范式转变，传统固定系统无法满足移动自组织节点的需求，需要重新设计网络接口架构。

Method: 基于当前6G愿景和相关研究，分析现有架构的局限性，综合移动网络、非地面网络和有机网络领域的研究成果，提出适合游牧特性的接口设计原则。

Result: 识别了动态环境中节点间通信、服务发现和控制委托的具体需求，发现了现有架构在游牧场景下的不足，提出了一套专门针对游牧网络的接口设计原则。

Conclusion: 这项工作为未来游牧6G通信系统奠定了架构基础，并为去中心化移动基础设施中的接口标准化指明了方向，特别是在跨管辖边界的基础设施元素监管和许可挑战方面提供了解决方案。

Abstract: The emergence of nomadic mobile communication networks for sixth-generation
(6G) introduces a paradigm shift in how network infrastructure is
conceptualized, deployed, and operated. Unlike traditional fixed systems,
Nomadic Networks (NNs) consist of mobile and self-organizing nodes that provide
radio infrastructure capabilities in motion. This paper explores the
architectural implications of such systems, with a particular focus on the
design and evolution of network interfaces. We analyze the requirements for
inter-node communication, service discovery, and control delegation in dynamic
environments. Furthermore, we examine the regulatory and licensing challenges
that arise when infrastructure elements traverse jurisdictional boundaries.
Based on current 6G visions and relevant research, we identify limitations in
existing architectures and propose a set of interface principles tailored to
nomadicity. By synthesizing findings from mobile, non-terrestrial, and organic
network domains, this work contributes to the architectural foundation for
future nomadic 6G communication systems and outlines directions for interface
standardization in decentralized, mobile infrastructures.

</details>


### [312] [Cooperative Sensing-Assisted Predictive Beam Tracking for MIMO-OFDM Networked ISAC Systems](https://arxiv.org/abs/2508.12723)
*Xiaoyu Yang,Zhiqing Wei,Jie Xu,Huici Wu,Zhiyong Feng*

Main category: cs.NI

TL;DR: 提出了一种多基站协作感知辅助的预测性波束跟踪设计，用于MIMO-OFDM ISAC系统，通过联合优化通信速率和感知性能来实现移动设备的精确跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了解决多基站ISAC系统中移动设备的波束跟踪问题，避免小区间干扰，同时提升通信和感知性能，需要开发有效的协作感知和预测性波束成形方法。

Method: 采用2D-DFT技术进行本地目标估计，使用EKF方法融合多基站测量结果预测目标参数，基于预测结果设计波束成形向量，提出SDR和惩罚算法解决非凸优化问题。

Result: 实现了在满足感知性能要求的同时最大化通信速率的预测性波束跟踪，提供了最优解和低复杂度高质量解决方案。

Conclusion: 所提出的协作感知辅助预测性波束跟踪设计能够有效提升MIMO-OFDM ISAC系统的性能，为移动设备提供可靠的通信和精确的感知服务。

Abstract: This paper studies a multiple-input multiple-output (MIMO) orthogonal
frequency division multiplexing (OFDM) networked integrated sensing and
communication (ISAC) system, in which multiple base stations (BSs) perform beam
tracking to communicate with a mobile device. In particular, we focus on the
beam tracking over a number of tracking time slots (TTSs) and suppose that
these BSs operate at non-overlapping frequency bands to avoid the severe
inter-cell interference. Under this setup, we propose a new cooperative
sensing-assisted predictive beam tracking design. In each TTS, the BSs use echo
signals to cooperatively track the mobile device as a sensing target, and
continuously adjust the beam directions to follow the device for enhancing the
performance for both communication and sensing. First, we propose a cooperative
sensing design to track the device, in which the BSs first employ the
two-dimensional discrete Fourier transform (2D-DFT) technique to perform local
target estimation, and then use the extended Kalman filter (EKF) method to fuse
their individual measurement results for predicting the target parameters.
Next, based on the predicted results, we obtain the achievable rate for
communication and the predicted conditional Cram\'er-Rao lower bound (PC-CRLB)
for target parameters estimation in the next TTS, as a function of the
beamforming vectors. Accordingly, we formulate the predictive beamforming
design problem, with the objective of maximizing the achievable communication
rate in the following TTS, while satisfying the PC-CRLB requirement for
sensing. To address the resulting non-convex problem, we first propose a
semi-definite relaxation (SDR)-based algorithm to obtain the optimal solution,
and then develop an alternative penalty-based algorithm to get a high-quality
low-complexity solution.

</details>


### [313] [Some optimization possibilities in data plane programming](https://arxiv.org/abs/2508.12767)
*Altangerel Gereltsetseg,Tejfel Máté*

Main category: cs.NI

TL;DR: 本文基于2019年Dagstuhl研讨会讨论了数据平面编程的挑战，提出了四种优化数据平面的解决方案，并在P4语言中进行了实现验证。


<details>
  <summary>Details</summary>
Motivation: 软件定义网络(SDN)中控制平面研究较多，但数据平面编程相对较新且存在性能优化需求，需要解决未来10年的关键挑战。

Method: 通过研讨会讨论和文献综述，提出了四种优化方案：(i)异步外部函数丰富数据平面语言(ii)基于载荷大小的压缩(iii)网络内缓存(iv)外部函数卸载到额外线程/VM/服务器，并在P4语言中实现验证。

Result: 提出了具体可行的数据平面优化方案，通过P4实现证明了这些方案的实际可行性。

Conclusion: 数据平面编程是SDN领域的重要研究方向，提出的四种优化方案能够有效提升数据包处理性能和链路利用率，为未来数据平面发展提供了实用解决方案。

Abstract: Software-defined networking (SDN) technology aims to create a highly flexible
network by decoupling control plane and the data plane and programming them
independently. There has been a lot of research on improving and optimizing the
control plane, and data plane programming is a relatively new concept, so study
on it is one of the hot topics for researchers. At the 2019 Dagstuhl Seminar,
well-known scientists on computer networking discussed challenges and problems
in the field of data plane programming that need to be addressed over the next
10 years. Based on this seminar issues and papers review, we suggested some
possible solutions which are for optimizing data plane to improve packet
processing performance and link utilization. The suggestions include (i)
enriching data plane language with asynchronous external function, (ii)
compression based on payload size, (iii) in-network caching for fast packet
processing, and (iv) offloading external functions to an additional thread,
virtual machine (VM) or server, etc. In addition, we implemented some of these
in the P4 data plane language to illustrate the practicality.

</details>


### [314] [SDAP-based QoS Flow Multiplexing Support in Simu5G for 5G NR Simulation](https://arxiv.org/abs/2508.12785)
*Mohamed Seliem,Utz Roedig,Cormac Sreenan,Dirk Pesch*

Main category: cs.NI

TL;DR: 为Simu5G模拟框架开发了符合5G标准的SDAP扩展，支持QoS流多复用和实际QoS行为模拟


<details>
  <summary>Details</summary>
Motivation: 5G模拟框架缺少SDAP支持，无法模拟真实的QoS行为，限制了5G网络性能研究

Method: 设计了模块化、符合标准的SDAP扩展，包括QFI流标签、SDAP头插入/移除、可配置逻辑DRB映射等核心功能

Result: 验证结果证明实现了正确的SDAP行为，支持多QFI模拟场景和差分化QoS流管理

Conclusion: 该SDAP扩展为开发高级的5G模拟提供了基础，支持流分离、延迟敏感业务和工业QoS配置的研究

Abstract: The Service Data Adaptation Protocol (SDAP) plays a central role in 5G New
Radio (NR), acting as a bridge between the core and radio networks, by enabling
QoS Flow multiplexing over shared Data Radio Bearers (DRBs). However, most 5G
simulation frameworks, including the popular OMNet++-based Simu5G, lack SDAP
support, limiting their ability to model realistic QoS behavior. This paper
presents a modular, standardscompliant SDAP extension for Simu5G. The
implementation includes core elements such as QoS Flow Identifer (QFI) flow
tagging, SDAP header insertion/removal, and configurable logical DRB mapping.
The proposed design supports multi-QFI simulation scenarios and enables
researchers to model differentiated QoS flows and flowaware scheduling
policies. Validation results confirm correct SDAP behavior and pave the way for
advanced 5G simulations involving per-flow isolation, latency-sensitive
traffic, and industrial QoS profiles.

</details>


### [315] [RoTO: Robust Topology Obfuscation Against Tomography Inference Attacks](https://arxiv.org/abs/2508.12852)
*Chengze Du,Heng Xu,Zhiwei Yu,Ying Zhou,Zili Meng,Jialong Li*

Main category: cs.NI

TL;DR: RoTO是一种鲁棒的拓扑混淆方案，通过分布建模和min-max优化来防御网络拓扑推断攻击，无需完美探测控制或特定攻击者模型假设。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖两个强假设：完美探测包检测/修改能力和固定的攻击算法，这些假设在实践中往往不成立，导致防御性能下降。

Method: 采用分布建模处理攻击者观测延迟的不确定性，构建min-max优化问题最大化拓扑失真，使用图神经网络模拟攻击者行为并进行对抗训练。

Result: 实验显示RoTO在结构相似性上平均提升34%，链路距离提升42.6%，同时保持强鲁棒性和隐蔽能力。

Conclusion: RoTO通过消除不现实的假设并提供理论保证，显著提升了拓扑混淆防御的实际效果和鲁棒性。

Abstract: Tomography inference attacks aim to reconstruct network topology by analyzing
end-to-end probe delays. Existing defenses mitigate these attacks by
manipulating probe delays to mislead inference, but rely on two strong
assumptions: (i) probe packets can be perfectly detected and altered, and (ii)
attackers use known, fixed inference algorithms. These assumptions often break
in practice, leading to degraded defense performance under detection errors or
adaptive adversaries. We present RoTO, a robust topology obfuscation scheme
that eliminates both assumptions by modeling uncertainty in attacker-observed
delays through a distributional formulation. RoTO casts the defense objective
as a min-max optimization problem that maximizes expected topological
distortion across this uncertainty set, without relying on perfect probe
control or specific attacker models. To approximate attacker behavior, RoTO
leverages graph neural networks for inference simulation and adversarial
training. We also derive an upper bound on attacker success probability, and
demonstrate that our approach enhances topology obfuscation performance through
the optimization of this upper bound. Experimental results show that RoTO
outperforms existing defense methods, achieving average improvements of 34% in
structural similarity and 42.6% in link distance while maintaining strong
robustness and concealment capabilities.

</details>


### [316] [REACH: Reinforcement Learning for Efficient Allocation in Community and Heterogeneous Networks](https://arxiv.org/abs/2508.12857)
*Zhiwei Yu,Chengze Du,Heng Xu,Ying Zhou,Bo Liu,Jialong Li*

Main category: cs.NI

TL;DR: REACH是一个基于Transformer强化学习的调度框架，用于社区GPU平台的异构资源调度，通过序列评分优化任务完成率、优先级任务成功率和带宽效率。


<details>
  <summary>Details</summary>
Motivation: 社区GPU平台具有极端的硬件/软件多样性、波动可用性和可变网络条件，传统调度器效果不佳，导致任务完成率低下。

Method: 使用Transformer-based强化学习框架，将任务调度重新定义为序列评分问题，建模全局GPU状态和任务需求，自适应地将计算与数据共置，优先处理关键作业，减轻不可靠资源的影响。

Result: REACH将任务完成率提高达17%，高优先级任务成功率提高一倍以上，带宽惩罚减少超过80%，在GPU流失和网络拥堵的压力测试中表现出鲁棒性，大规模高竞争场景下仍有效。

Conclusion: REACH框架通过强化学习有效解决了社区GPU平台的异构调度挑战，在性能、可靠性、成本和网络效率方面实现了显著提升。

Abstract: Community GPU platforms are emerging as a cost-effective and democratized
alternative to centralized GPU clusters for AI workloads, aggregating idle
consumer GPUs from globally distributed and heterogeneous environments.
However, their extreme hardware/software diversity, volatile availability, and
variable network conditions render traditional schedulers ineffective, leading
to suboptimal task completion. In this work, we present REACH (Reinforcement
Learning for Efficient Allocation in Community and Heterogeneous Networks), a
Transformer-based reinforcement learning framework that redefines task
scheduling as a sequence scoring problem to balance performance, reliability,
cost, and network efficiency. By modeling both global GPU states and task
requirements, REACH learns to adaptively co-locate computation with data,
prioritize critical jobs, and mitigate the impact of unreliable resources.
Extensive simulation results show that REACH improves task completion rates by
up to 17%, more than doubles the success rate for high-priority tasks, and
reduces bandwidth penalties by over 80% compared to state-of-the-art baselines.
Stress tests further demonstrate its robustness to GPU churn and network
congestion, while scalability experiments confirm its effectiveness in
large-scale, high-contention scenarios.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [317] [StackPilot: Autonomous Function Agents for Scalable and Environment-Free Code Execution](https://arxiv.org/abs/2508.11665)
*Xinkui Zhao,Yifan Zhang,Zhengyi Zhou,Yueshen Xu*

Main category: cs.PL

TL;DR: StackPilot是一个多智能体框架，用于语言无关的代码验证和执行，无需传统工具链，通过函数即智能体、LLM作为执行器和快照机制实现高可靠性验证。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖语言特定编译器和环境相关运行时来验证LLM生成代码的正确性和可执行性，存在局限性，需要一种语言无关的独立验证方案。

Method: 采用函数即智能体范式、LLM作为执行器策略和快照机制，通过多智能体协作进行细粒度推理和基于堆栈的调度验证。

Result: 实证评估显示StackPilot框架可靠性达到89%-97%，显著优于基线方法，能够验证和执行更多LLM生成代码。

Conclusion: StackPilot提供了一种可靠的语言无关代码验证框架，大幅提升了LLM生成代码的验证覆盖率和执行成功率。

Abstract: Recent advances in large language models (LLMs) have substantially enhanced
automated code generation across a wide range of programming languages.
Nonetheless, verifying the correctness and executability of LLM-generated code
remains a significant challenge, as traditional methods rely on
language-specific compilers and environment-dependent runtimes. To overcome
these limitations, we introduce StackPilot, an LLM-native, multi-agent
framework designed for language-agnostic code verification and execution, which
operates independently of conventional toolchains. StackPilot offers three
principal innovations: (1) a Function-as-Agents paradigm, in which each
function is modeled as an autonomous agent capable of fine-grained reasoning
and collaborative verification; (2) an LLM-as-Executor strategy, which enables
scalable verification via stack-based scheduling; and (3) a novel snapshot
mechanism that preserves complete execution contexts, facilitating
deterministic and lossless context switching during verification. Empirical
evaluations demonstrate that StackPilot achieves framework reliability rates
between 89% and 97%, substantially outperforming baseline approaches. These
results indicate that StackPilot can reliably verify and execute a
significantly larger proportion of LLM-generated code across diverse
programming tasks compared to existing methods.

</details>


### [318] [Certified Compilation based on Gödel Numbers](https://arxiv.org/abs/2508.12054)
*Guilherme de Oliveira Silva,Fernando Magno Quintão Pereira*

Main category: cs.PL

TL;DR: 这篇论文提出了一种新的证书生成方法，用于确保二进制图像完整地代表源代码，防范Thompson风格的编译器后门。


<details>
  <summary>Details</summary>
Motivation: 解决Ken Thompson在1984年图灵奖演讲中提出的编译器后门问题，尽管已有多种防御技术，但核心问题"如何信任用于编译工具的编译器"仍未得到彻底解决。

Method: 设计了一种整数形式的证书，可从源代码和二进制文件中派生，确保二进制包含源代码的所有且仅有语句、保持语句顺序、维持等价的def-use依赖关系。证书派生规则简洁且每步操作时间复杂度为常数。

Result: 实现了Charon编译器，能够处理足够编译FaCT（灵活且常数时间加密编程语言）的C语言子集，证明了方法的实用性。

Conclusion: 该方法提供了一种可行的解决方案，通过数学证书的形式确保编译过程的完整性和可信质，从根本上解决了Thompson后门的安全风险。

Abstract: In his 1984 Turing Award lecture, Ken Thompson showed that a compiler could
be maliciously altered to insert backdoors into programs it compiles and
perpetuate this behavior by modifying any compiler it subsequently builds.
Thompson's hack has been reproduced in real-world systems for demonstration
purposes. Several countermeasures have been proposed to defend against
Thompson-style backdoors, including the well-known {\it Diverse
Double-Compiling} (DDC) technique, as well as methods like translation
validation and CompCert-style compilation. However, these approaches ultimately
circle back to the fundamental question: "How can we trust the compiler used to
compile the tools we rely on?" In this paper, we introduce a novel approach to
generating certificates to guarantee that a binary image faithfully represents
the source code. These certificates ensure that the binary contains all and
only the statements from the source code, preserves their order, and maintains
equivalent def-use dependencies. The certificate is represented as an integer
derivable from both the source code and the binary using a concise set of
derivation rules, each applied in constant time. To demonstrate the
practicality of our method, we present Charon, a compiler designed to handle a
subset of C expressive enough to compile FaCT, the Flexible and Constant Time
cryptographic programming language.

</details>


### [319] [Controlling Copatterns: There and Back Again (Extended Version)](https://arxiv.org/abs/2508.12427)
*Paul Downen*

Main category: cs.PL

TL;DR: 通过Danvy的力学对应方法，从操作语义到抽象机器再到CPS，两次正反向涉徙推导出单一和组合式copatterns的完整语义套件


<details>
  <summary>Details</summary>
Motivation: Copatterns提供了灵活的上下文响应机制，组合性增强了表达力，但也很难精确规范程序行为，需要严格的语义定义

Method: 采用Danvy的力学和语法对应关系，先从单一copatterns的小步操作语义出发，逐步演化到抽象机器和CPS，然后在CPS内重构推导出组合式copatterns的更通用计算法

Result: 得到了单一和组合式copatterns的完整语义套件，包括操作语义、抽象机器和CPS，完成了正向和反向的双向涉徙

Conclusion: 通过力学对应方法可以系统地推导出复杂语言构造的多种语义表示，为copatterns提供了严格的语义基础

Abstract: Copatterns give functional programs a flexible mechanism for responding to
their context, and composition can greatly enhance their expressiveness.
However, that same expressive power makes it harder to precisely specify the
behavior of programs. Using Danvy's functional and syntactic correspondence
between different semantic artifacts, we derive a full suite of semantics for
copatterns, twice. First, a calculus of monolithic copatterns is taken on a
journey from small-step operational semantics to abstract machine to
continuation-passing style. Then within continuation-passing style, we refactor
the semantics to derive a more general calculus of compositional copatterns,
and take the return journey back to derive the other semantic artifacts in
reverse order.

</details>


### [320] [Type-Driven Prompt Programming: From Typed Interfaces to a Calculus of Constraints](https://arxiv.org/abs/2508.12475)
*Abhijit Paul*

Main category: cs.PL

TL;DR: 提示编程将大语言模型提示视为具有类型接口的软件组件，类型系统是其核心，本文提出了具有概率精细的依赖类型微积分Lambda Prompt来填补约束表达力和算法支持的空白


<details>
  <summary>Details</summary>
Motivation: 通过对15份最新研究的调查，发现现有提示编程框架在约束表达力和算法支持方面存在空白，需要一种类型理论基础来解决这些问题

Method: 提出Lambda Prompt概念，这是一种具有概率精细的依赖类型微积分，用于表达语法和语义约束；编写了13个约束的目录，并提出了约束保持的优化规则

Result: 形式化了提示编程的类型理论基础，标识出了约束表达力方面的未充分探索区域（约束9-13），为提示程序编译器的开发提供了研究方向

Conclusion: 本文为提示编程领域提供了一个类型理论基础，通过Lambda Prompt概念和相关算法解决了约束表达力和算法支持的问题，为未来提示程序编译器的开发奠定了基础

Abstract: Prompt programming treats large language model prompts as software components
with typed interfaces. Based on a literature survey of 15 recent works from
2023 to 2025, we observe a consistent trend: type systems are central to
emerging prompt programming frameworks. However, there are gaps in constraint
expressiveness and in supporting algorithms. To address these issues, we
introduce the notion of Lambda Prompt, a dependently typed calculus with
probabilistic refinements for syntactic and semantic constraints. While this is
not yet a full calculus, the formulation motivates a type-theoretic foundation
for prompt programming. Our catalog of 13 constraints highlights underexplored
areas in constraint expressiveness (constraints 9 through 13). To address the
algorithmic gap, we propose a constraint-preserving optimization rule. Finally,
we outline research directions on developing a compiler for prompt programs.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [321] [Benchmark Dataset Generation and Evaluation for Excel Formula Repair with LLMs](https://arxiv.org/abs/2508.11715)
*Ananya Singha,Harshita Sahijwani,Walt Williams,Emmanuel Aboah Boateng,Nick Hausman,Miguel Di Luca,Keegan Choudhury,Chaya Binet,Vu Le,Tianwei Chen,Oryan Rokeah Chen,Sulaiman Vesal,Sadid Hasan*

Main category: cs.SE

TL;DR: 这篇论文提出了一种新的Excel公式维修数据集构建方法，通过少量示例和LLM扩展生成了618个高质量样本，并评估了多种LLM在这个新数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: Excel作为普遍但复杂的工具，新手用户经常遇到运行时错误。虽然LLM可以解释公式错误，但自动修复这些语义错误仍然是个挑战，主要因难是缺乏高质量的评测数据集。

Method: 提出了一种数据生成流水线，利用在线论坛的少量粒子样本，通过少量提示和LLM扩展数据集。采用LLM-as-a-Judge验证框架结合执行基于检查来确保数据正确性和语义保真度。同时提出了一种上下文感知的Excel公式维修基线方法。

Result: 生成了618个高质量的Excel公式维修样本，覆盖了常见的运行时错误。对GPT-4o、GPT-4.1、Phi-3、Mistral等多种LLM进行了执行基于评测，通过手动注释和错误分布分析证明了数据集的高质量。

Conclusion: 该研究有效解决了Excel公式维修领域的数据缺口问题，所提出的数据生成方法具有高可扩展性，可以轻松适配到其他低资源编程语言的代码维修任务中。

Abstract: Excel is a pervasive yet often complex tool, particularly for novice users,
where runtime errors arising from logical mistakes or misinterpretations of
functions pose a significant challenge. While large language models (LLMs)
offer promising assistance by explaining formula errors, the automated
correction of these semantic runtime errors remains an open problem. A primary
challenge to advancing models for such scenarios is the severe lack of
high-quality, comprehensive datasets for training and rigorous evaluation. This
paper addresses this gap by introducing a novel approach for constructing a
benchmark dataset specifically designed for Excel formula repair. We propose a
data generation pipeline, which leverages a small set of curated seed samples
from online forums to synthetically expand the dataset. Our pipeline integrates
few-shot prompting with LLMs and employs a robust \textit{LLM-as-a-Judge}
validation framework, combined with execution-based checks to ensure the
correctness and semantic fidelity of the generated data. This process produced
a benchmark dataset of 618 high-quality samples, covering common runtime
errors. Furthermore, we propose a context-aware baseline technique for Excel
formula repair that utilizes LLMs to leverage both the faulty formula, and
relevant spreadsheet context. We evaluate the performance of various LLMs
(GPT-4o, GPT-4.1, Phi-3, Mistral) on our newly generated benchmark using
execution-based metrics. Our analysis demonstrates the dataset's quality
through manual annotation and provides insights into error and function
distributions. The proposed generation methodology is highly scalable and can
be readily adapted to create evaluation benchmarks for similar code repair
tasks in other low-resource programming languages.

</details>


### [322] [WIP: Leveraging LLMs for Enforcing Design Principles in Student Code: Analysis of Prompting Strategies and RAG](https://arxiv.org/abs/2508.11717)
*Dhruv Kolhatkar,Soubhagya Akkena,Edward F. Gehringer*

Main category: cs.SE

TL;DR: 基于LLM和RAG技术的自动化代码审查工具，用于评估学生代码遵循面向对象设计原则的情况


<details>
  <summary>Details</summary>
Motivation: 解决在计算机科学和软件工程课程中，需要更有效和可扩展的方法来教掌软件设计最佳实践的问题

Method: 利用大语言模型(LLM)和检索增强生成(RAG)技术，开发自动化反馈系统，评估学生代码是否遵循SOLID、DRY等设计原则和设计模式

Result: 预期研究结果显示代码质量有明显改善，各种提示策略和RAG集成效果不错

Conclusion: 该方法在教育环境中展示了潇望前景，未来工作将重点改善模型准确性和扩展支持更多设计原则

Abstract: This work-in-progress research-to-practice paper explores the integration of
Large Language Models (LLMs) into the code-review process for open-source
software projects developed in computer science and software engineering
courses. The focus is on developing an automated feedback tool that evaluates
student code for adherence to key object-oriented design principles, addressing
the need for more effective and scalable methods to teach software design best
practices. The innovative practice involves leveraging LLMs and
Retrieval-Augmented Generation (RAG) to create an automated feedback system
that assesses student code for principles like SOLID, DRY, and design patterns.
It analyzes the effectiveness of various prompting strategies and the RAG
integration. Preliminary findings show promising improvements in code quality.
Future work will aim to improve model accuracy and expand support for
additional design principles.

</details>


### [323] [Rethinking Autonomy: Preventing Failures in AI-Driven Software Engineering](https://arxiv.org/abs/2508.11824)
*Satyam Kumar Navneet,Joydeep Chandra*

Main category: cs.SE

TL;DR: 大语言模型在软件工程中的应用带来了安全风险，本文提出SAFE-AI框架来实现安全、可审计、可反馈和可解释的AI代码生成


<details>
  <summary>Details</summary>
Motivation: 随着LLM在代码生成领域的广泛应用，出现了代码安全漏洞、幻觉输出、不可逆操作等风险，需要建立健壮的安全管理机制

Method: 提出SAFE-AI框架，包括护栏、沙盒、运行时验证、风险认知日志、人在环节系统和可解释AI技术，并建立了AI行为分类法

Result: 建立了一套完整的风险管理框架，能够有效减少不安全代码生成、幻觉问题和自主行为风险

Conclusion: 该框架为软件工程领域的负责任AI集成提供了可行路径，符合欧盟AI法案等监管要求，确保AI驱动开发的安全性、透明度和可负责性

Abstract: The integration of Large Language Models (LLMs) into software engineering has
revolutionized code generation, enabling unprecedented productivity through
promptware and autonomous AI agents. However, this transformation introduces
significant risks, including insecure code generation, hallucinated outputs,
irreversible actions, and a lack of transparency and accountability. Incidents
like the Replit database deletion underscore the urgent need for robust safety
and governance mechanisms. This paper comprehensively analyzes the inherent
challenges of LLM-assisted code generation, such as vulnerability inheritance,
overtrust, misinterpretation, and the absence of standardized validation and
rollback protocols. To address these, we propose the SAFE-AI Framework, a
holistic approach emphasizing Safety, Auditability, Feedback, and
Explainability. The framework integrates guardrails, sandboxing, runtime
verification, risk-aware logging, human-in-the-loop systems, and explainable AI
techniques to mitigate risks while fostering trust and compliance. We introduce
a novel taxonomy of AI behaviors categorizing suggestive, generative,
autonomous, and destructive actions to guide risk assessment and oversight.
Additionally, we identify open problems, including the lack of standardized
benchmarks for code specific hallucinations and autonomy levels, and propose
future research directions for hybrid verification, semantic guardrails, and
proactive governance tools. Through detailed comparisons of autonomy control,
prompt engineering, explainability, and governance frameworks, this paper
provides a roadmap for responsible AI integration in software engineering,
aligning with emerging regulations like the EU AI Act and Canada's AIDA to
ensure safe, transparent, and accountable AI-driven development.

</details>


### [324] [AI-Augmented CI/CD Pipelines: From Code Commit to Production with Autonomous Decisions](https://arxiv.org/abs/2508.11867)
*Mohammad Baqar,Saba Naqvi,Rajat Khanda*

Main category: cs.SE

TL;DR: 该论文提出AI增强的CI/CD流水线，使用LLM和自主代理作为策略约束的副驾驶和决策者，以减少人工决策带来的延迟和操作负担。


<details>
  <summary>Details</summary>
Motivation: 现代软件交付已从季度发布加速到每天多次部署，但人工决策点（如解释不稳定测试、选择回滚策略、调整功能开关等）仍然是延迟和操作负担的主要来源。

Method: 提出了AI增强CI/CD流水线的参考架构，包括：代理决策点嵌入、决策分类和策略即代码护栏模式、分阶段自主的信任层级框架、使用DORA指标和AI特定指标的评估方法，以及详细的工业级案例研究。

Result: 通过将React 19微服务迁移到AI增强流水线的案例研究，展示了该方法在实际工业环境中的应用效果。

Conclusion: 论文讨论了伦理、验证、可审计性和有效性威胁，并为生产交付系统中的可验证自主性制定了路线图，为CI/CD自动化提供了新的发展方向。

Abstract: Modern software delivery has accelerated from quarterly releases to multiple
deployments per day. While CI/CD tooling has matured, human decision points
interpreting flaky tests, choosing rollback strategies, tuning feature flags,
and deciding when to promote a canary remain major sources of latency and
operational toil. We propose AI-Augmented CI/CD Pipelines, where large language
models (LLMs) and autonomous agents act as policy-bounded co-pilots and
progressively as decision makers. We contribute: (1) a reference architecture
for embedding agentic decision points into CI/CD, (2) a decision taxonomy and
policy-as-code guardrail pattern, (3) a trust-tier framework for staged
autonomy, (4) an evaluation methodology using DevOps Research and Assessment (
DORA) metrics and AI-specific indicators, and (5) a detailed industrial-style
case study migrating a React 19 microservice to an AI-augmented pipeline. We
discuss ethics, verification, auditability, and threats to validity, and chart
a roadmap for verifiable autonomy in production delivery systems.

</details>


### [325] [Clean Code, Better Models: Enhancing LLM Performance with Smell-Cleaned Dataset](https://arxiv.org/abs/2508.11958)
*Zhipeng Xue,Xiaoting Zhang,Zhipeng Gao,Xing Hu,Shan Gao,Xin Xia,Shanping Li*

Main category: cs.SE

TL;DR: 这篇论文系统性研究了代码异味在LLM输入输出中的存在问题，开发了自动清理工具SmellCC，并评估了清理后数据集对LLM代码生成质量的改善效果


<details>
  <summary>Details</summary>
Motivation: 当前研究多关注LLM输出质量，而忽视了训练数据中广泛存在的代码异味问题，这会影响软件维护性和可读性

Method: 1）先导研究分析CodeSearchNet-Python数据集中代码异味情况
2）开发LLM基于的代码异味清理工具SmellCC
3）构建50个仓库的测试集进行功能测试
4）用清理后数据集微调DeepSeek-V2和Qwen-Coder
5）在代码完成和代码搜索任务上评估效果

Result: 发现代码异味问题在LLM输入数据集和输出代码中广泛存在；SmellCC能够有效清理代码异味；使用清理后数据微调的LLM能够生成质量更高的代码

Conclusion: 代码异味对LLM代码生成质量有显著影响，通过自动化清理工具提高数据集质量可以改善LLM在代码相关任务上的表现，为软件工程实践者提供了可行建议

Abstract: The Large Language Models (LLMs) have demonstrated great potential in
code-related tasks. However, most research focuses on improving the output
quality of LLMs (e.g., correctness), and less attention has been paid to the
LLM input (e.g., the training code quality). Given that code smells are widely
existed in practice and can negatively impact software maintainability and
readability, this study takes the first systematic research to assess and
improve dataset quality in terms of code smells. In this work, we first conduct
a preliminary study to explore the presence of code smells in a popular
benchmark dataset (i.e., CodeSearchNet-Python}) and evaluate the output of
several popular LLMs (i.e., DeepSeek-Coder, CodeLlama, and MagiCoder),
revealing that code smell issues extensively exist in LLM's input (e.g.,
benchmark dataset) and output (e.g., generated code). We then conduct our
systematic research by taking three main steps: Firstly, we propose an
LLM-based code smell cleaning tool, named SmellCC, which automatically
refactors and removes code smells. To evaluate the correctness of the code
refactoring, we construct a test set of 50 repositories sourced from the
CodeSearchNet-Python benchmark for functional testing. Then we apply our
curated smell-cleaned dataset to fine-tune two LLMs (i.e., DeepSeek-V2 and
Qwen-Coder) to explore their potential for generating high-quality code.
Thirdly, we investigate the impact of code smells on two downstream tasks: code
completion and code search. Lastly, we derive several actionable implications
for software engineering researchers and industry practitioners from our
findings.

</details>


### [326] [How Much Can a Behavior-Preserving Changeset Be Decomposed into Refactoring Operations?](https://arxiv.org/abs/2508.11993)
*Kota Someya,Lei Chen,Michael J. Decker,Shinpei Hayashi*

Main category: cs.SE

TL;DR: 研究量化了行为保持修改中可被分解为重构操作的比例，现有重构检测器只能识别33.9%的变更，通过新定义67个功能等价操作可将覆盖率提高128%


<details>
  <summary>Details</summary>
Motivation: 开发者常将行为保持修改（如重构）与行为改变修改（如功能添加）混合进行，需要方法来分离识别这两部分修改

Method: 使用功能等价方法对比数据集，量化行为保持修改中可被分解为重构操作的比例，测试现有重构检测器和新定义的67个功能等价操作的效果

Result: 现有重构检测器只能识别33.9%的变更，添加新定义操作后覆盖率提高了128%，但仍有部分变更无法解释

Conclusion: 需要进一步扩展重构操作的定义和检测能力，提高对行为保持修改的解析覆盖率，为重构意识方法提供改进机会

Abstract: Developers sometimes mix behavior-preserving modifications, such as
refactorings, with behavior-altering modifications, such as feature additions.
Several approaches have been proposed to support understanding such
modifications by separating them into those two parts. Such refactoring-aware
approaches are expected to be particularly effective when the
behavior-preserving parts can be decomposed into a sequence of more primitive
behavior-preserving operations, such as refactorings, but this has not been
explored. In this paper, as an initial validation, we quantify how much of the
behavior-preserving modifications can be decomposed into refactoring operations
using a dataset of functionally-equivalent method pairs. As a result, when
using an existing refactoring detector, only 33.9% of the changes could be
identified as refactoring operations. In contrast, when including 67 newly
defined functionally-equivalent operations, the coverage increased by over
128%. Further investigation into the remaining unexplained differences was
conducted, suggesting improvement opportunities.

</details>


### [327] [LinkAnchor: An Autonomous LLM-Based Agent for Issue-to-Commit Link Recovery](https://arxiv.org/abs/2508.12232)
*Arshia Akhavan,Alireza Hosseinpour,Abbas Heydarnoori,Mehdi Keshani*

Main category: cs.SE

TL;DR: LinkAnchor是一个基于LLM的自主代理，用于恢复issue到commit的链接，通过惰性访问架构动态检索相关上下文，避免token限制，并能自动定位目标commit而非穷举所有候选。


<details>
  <summary>Details</summary>
Motivation: 现有issue-commit链接恢复方法存在两个主要问题：LLM受限于上下文窗口无法处理大量数据源；大多数方法需要逐个评估issue-commit对，这在真实项目中不实用。GitHub上只有42.2%的issue被正确链接到commit，需要更好的解决方案。

Method: 提出LinkAnchor，采用惰性访问架构，让底层LLM能够动态检索最相关的上下文数据（包括commit、issue评论和代码文件），而不超过token限制。系统能自动定位目标commit，而不是对所有候选进行穷举评分。

Result: 评估显示LinkAnchor在所有案例研究项目中，Hit@1分数比最先进的issue-commit链接恢复方法提高了60-262%。

Conclusion: LinkAnchor是第一个基于LLM的自主代理，专门用于issue-to-commit链接恢复，性能显著优于现有方法，且已作为即用工具公开发布，支持GitHub和Jira平台并可扩展到其他平台。

Abstract: Issue-to-commit link recovery plays an important role in software
traceability and improves project management. However, it remains a challenging
task. A study on GitHub shows that only 42.2% of the issues are correctly
linked to their commits. This highlights the potential for further development
and research in this area. Existing studies have employed various AI/ML-based
approaches, and with the recent development of large language models,
researchers have leveraged LLMs to tackle this problem. These approaches suffer
from two main issues. First, LLMs are constrained by limited context windows
and cannot ingest all of the available data sources, such as long commit
histories, extensive issue comments, and large code repositories. Second, most
methods operate on individual issue-commit pairs; that is, given a single
issue-commit pair, they determine whether the commit resolves the issue. This
quickly becomes impractical in real-world repositories containing tens of
thousands of commits. To address these limitations, we present LinkAnchor, the
first autonomous LLM-based agent designed for issue-to-commit link recovery.
The lazy-access architecture of LinkAnchor enables the underlying LLM to access
the rich context of software, spanning commits, issue comments, and code files,
without exceeding the token limit by dynamically retrieving only the most
relevant contextual data. Additionally, LinkAnchor is able to automatically
pinpoint the target commit rather than exhaustively scoring every possible
candidate. Our evaluations show that LinkAnchor outperforms state-of-the-art
issue-to-commit link recovery approaches by 60-262% in Hit@1 score across all
our case study projects. We also publicly release LinkAnchor as a ready-to-use
tool, along with our replication package. LinkAnchor is designed and tested for
GitHub and Jira, and is easily extendable to other platforms.

</details>


### [328] ["My productivity is boosted, but ..." Demystifying Users' Perception on AI Coding Assistants](https://arxiv.org/abs/2508.12285)
*Yunbo Lyu,Zhou Yang,Jieke Shi,Jianming Chang,Yue Liu,David Lo*

Main category: cs.SE

TL;DR: 本文通过分析VS Code市场中32款AI编码助手的用户评论，揭示了开发者对AI编码工具的真实需求咄监测点，并提出4项改进建议。


<details>
  <summary>Details</summary>
Motivation: 了解在AI编码助手普及时代，开发者真正价值咄批评的内容，以反映实际软件开发中的需求咄期望。

Method: 从VS Code市场识别1085款AI编码助手，手动分析32款高安装量工具的用户评论，构建关注点分类法，并注释每条评论的态度。

Result: 发现用户不仅需要智能建议，更涉及上下文感知、可自定义性咄资源效率；评论分析揭示了用户对具体功能、问题咄整体表现的满意度细节。

Conclusion: 研究提出了5项实践建议，指导AI编码助手的改进以更好满足用户需求。

Abstract: This paper aims to explore fundamental questions in the era when AI coding
assistants like GitHub Copilot are widely adopted: what do developers truly
value and criticize in AI coding assistants, and what does this reveal about
their needs and expectations in real-world software development? Unlike
previous studies that conduct observational research in controlled and
simulated environments, we analyze extensive, first-hand user reviews of AI
coding assistants, which capture developers' authentic perspectives and
experiences drawn directly from their actual day-to-day work contexts. We
identify 1,085 AI coding assistants from the Visual Studio Code Marketplace.
Although they only account for 1.64% of all extensions, we observe a surge in
these assistants: over 90% of them are released within the past two years. We
then manually analyze the user reviews sampled from 32 AI coding assistants
that have sufficient installations and reviews to construct a comprehensive
taxonomy of user concerns and feedback about these assistants. We manually
annotate each review's attitude when mentioning certain aspects of coding
assistants, yielding nuanced insights into user satisfaction and
dissatisfaction regarding specific features, concerns, and overall tool
performance. Built on top of the findings-including how users demand not just
intelligent suggestions but also context-aware, customizable, and
resource-efficient interactions-we propose five practical implications and
suggestions to guide the enhancement of AI coding assistants that satisfy user
needs.

</details>


### [329] [From Fomo3D to Lottery DAPP: Analysis of Ethereum-Based Gambling Applications](https://arxiv.org/abs/2508.12303)
*Xu Long,Yishun Wang,Xiaoqi Li*

Main category: cs.SE

TL;DR: 这篇论文分析了基于以太坊的赌博应用DApps的概念、原理、实现和前景，重点介绍了区块链彩票平台的自动化智能合约操作和去中心化优势。


<details>
  <summary>Details</summary>
Motivation: 研究区块链技术在在线赌博领域的应用，探索基于以太坊的赌博DApps如何通过去中心化特性提高公平性、透明度和可靠性。

Method: 首先概述赌博DApps的概念和运营原理，然后分析现有的以太坊赌博DApp的技术原理、实现方式、运营状况、漏洞和解决方案，最后详细说明彩票DApps的实现技术。

Result: 智能合约能够自动化管理整个彩票流程，包括发行、下注、开奖和奖金分配。去中心化特性确保了公平性，消除了单一实体的控制，同时减少管理成本、提高盈利能力并增强游戏透明度和信用度。

Conclusion: 随着区块链技术和智能合约的发展，彩票DApps有望根本改变在线彩票行业。其去中心化、自动化和透明度等优势将推动更广泛的未来采用。

Abstract: As blockchain technology advances, Ethereum based gambling decentralized
applications (DApps) represent a new paradigm in online gambling. This paper
examines the concepts, principles, implementation, and prospects of Ethereum
based gambling DApps. First, we outline the concept and operational principles
of gambling DApps. These DApps are blockchain based online lottery platforms.
They utilize smart contracts to manage the entire lottery process, including
issuance, betting, drawing, and prize distribution. Being decentralized,
lottery DApps operate without central oversight, unlike traditional lotteries.
This ensures fairness and eliminates control by any single entity. Automated
smart contract execution further reduces management costs, increases
profitability, and enhances game transparency and credibility. Next, we analyze
an existing Ethereum based gambling DApp, detailing its technical principles,
implementation, operational status, vulnerabilities, and potential solutions.
We then elaborate on the implementation of lottery DApps. Smart contracts
automate the entire lottery process including betting, drawing, and prize
distribution. Although developing lottery DApps requires technical expertise,
the expanding Ethereum ecosystem provides growing tools and frameworks,
lowering development barriers. Finally, we discuss current limitations and
prospects of lottery DApps. As blockchain technology and smart contracts
evolve, lottery DApps are positioned to significantly transform the online
lottery industry. Advantages like decentralization, automation, and
transparency will likely drive broader future adoption.

</details>


### [330] [Towards the Coordination and Verification of Heterogeneous Systems with Data and Time](https://arxiv.org/abs/2508.12325)
*Tim Kräuter,Adrian Rutle,Yngve Lamo,Harald König,Francisco Durán*

Main category: cs.SE

TL;DR: 基于重写逻辑的非侵入式协调框架，用于验证异构系统的正确性属性


<details>
  <summary>Details</summary>
Motivation: 现代软件系统通常由多个异构部件协调构成，需要验证这些部件能够无缝协同工作以满足系统要求

Method: 开发了一个基于语言扩展的协调框架，包含中央线程和域特定语言，通过抽象规则模板实现非侵入通信，使用Maude重写逻辑实现

Result: 框架能够对包含实时能力的异构部件进行形式分析，并通过验证异构路轨交叉系统的某些正确性属性来证明其可用性

Conclusion: 该非侵入协调框架有效地支持异构系统的形式验证，为复杂系统的正确性验证提供了一种可行的方法

Abstract: Modern software systems are often realized by coordinating multiple
heterogeneous parts, each responsible for specific tasks. These parts must work
together seamlessly to satisfy the overall system requirements. To verify such
complex systems, we have developed a non-intrusive coordination framework
capable of performing formal analysis of heterogeneous parts that exchange data
and include real-time capabilities. The framework utilizes a linguistic
extension, which is implemented as a central broker and a domain-specific
language for the integration of heterogeneous languages and coordination of
parts. Moreover, abstract rule templates are reified as language adapters for
non-intrusive communications with the broker. The framework is implemented
using rewriting logic (Maude), and its applicability is demonstrated by
verifying certain correctness properties of a heterogeneous road-rail crossing
system.

</details>


### [331] [Uncovering Systematic Failures of LLMs in Verifying Code Against Natural Language Specifications](https://arxiv.org/abs/2508.12358)
*Haolin Jin,Huaming Chen*

Main category: cs.SE

TL;DR: LLMs在代码审查中存在系统性缺陷，经常错误地将正确代码判定为不符合需求或存在缺陷，且复杂提示工程反而会增加误判率


<details>
  <summary>Details</summary>
Motivation: 探究LLMs是否能可靠地判断代码实现是否符合自然语言需求规范，因为软件工程师广泛依赖LLMs进行代码审查和需求验证

Method: 使用统一提示词在广泛使用的基准测试上评估代码正确性，分析误判的根本原因，并提出两种改进的提示策略

Result: 发现LLMs频繁误判正确代码，复杂提示技术（特别是包含解释和修正建议的）导致更高的误判率

Conclusion: 揭示了LLMs在代码需求匹配方面的未认知局限性，为自动化代码审查和任务导向代理场景提供了新的见解和实用指导

Abstract: Large language models (LLMs) have become essential tools in software
development, widely used for requirements engineering, code generation and
review tasks. Software engineers often rely on LLMs to assess whether system
code implementation satisfy task requirements, thereby enhancing code
robustness and accuracy. However, it remains unclear whether LLMs can reliably
determine whether the code complies fully with the given task descriptions,
which is usually natural language specifications. In this paper, we uncover a
systematic failure of LLMs in evaluating whether code aligns with natural
language requirements. Specifically, with widely used benchmarks, we employ
unified prompts to judge code correctness. Our results reveal that LLMs
frequently misclassify correct code implementations as either ``not satisfying
requirements'' or containing potential defects. Surprisingly, more complex
prompting, especially when leveraging prompt engineering techniques involving
explanations and proposed corrections, leads to higher misjudgment rate, which
highlights the critical reliability issues in using LLMs as code review
assistants. We further analyze the root causes of these misjudgments, and
propose two improved prompting strategies for mitigation. For the first time,
our findings reveals unrecognized limitations in LLMs to match code with
requirements. We also offer novel insights and practical guidance for effective
use of LLMs in automated code review and task-oriented agent scenarios.

</details>


### [332] [Feature Request Analysis and Processing: Tasks, Techniques, and Trends](https://arxiv.org/abs/2508.12436)
*Feifei Niu,Chuanyi Li,Haosheng Zuo,Jionghan Wu,Xin Xia*

Main category: cs.SE

TL;DR: 这是一篇关于软件功能请求研究的系统性综述论文，分析了131篇相关研究，对功能请求研究领域进行了分类和总结，并识别了关键挑战和未来机会。


<details>
  <summary>Details</summary>
Motivation: 功能请求代表了用户对软件产品的需求和期望，满足这些需求可以提升产品竞争力和用户满意度。近年来相关研究数量增长但主题分散，需要进行系统性分析来识别挑战和机遇。

Method: 采用系统性文献综述方法，遵循定义的流程和搜索协议，通过描述性统计和定性分析方法对131篇主要研究进行分类和分析，从需求工程活动角度进行分组。

Result: 研究将相关文献分类到不同主题，从需求工程活动角度进行分组，调查了开源工具和数据集，识别了功能请求质量保证、规范和验证改进、高质量基准数据集开发等关键挑战。

Conclusion: 功能请求研究领域存在多个重要挑战，包括确保请求质量、改进规范验证方法、开发高质量基准数据集等，这些挑战为未来研究提供了重要机遇。

Abstract: Feature requests are proposed by users to request new features or
enhancements of existing features of software products, which represent users'
wishes and demands. Satisfying users' demands can benefit the product from both
competitiveness and user satisfaction. Feature requests have seen a rise in
interest in the past few years and the amount of research has been growing.
However, the diversity in the research topics suggests the need for their
collective analysis to identify the challenges and opportunities so as to
promote new advances in the future. In this work, following a defined process
and a search protocol, we provide a systematic overview of the research area by
searching and categorizing relevant studies. We select and analyze 131 primary
studies using descriptive statistics and qualitative analysis methods. We
classify the studies into different topics and group them from the perspective
of requirements engineering activities. We investigate open tools as well as
datasets for future research. In addition, we identify several key challenges
and opportunities, such as: (1) ensuring the quality of feature requests, (2)
improving their specification and validation, and (3) developing high-quality
benchmarks for large language model-driven tasks.

</details>


### [333] [XAMT: Cross-Framework API Matching for Testing Deep Learning Libraries](https://arxiv.org/abs/2508.12546)
*Bin Duan,Ruican Dong,Naipeng Dong,Dan Dongseong Kim,Guowei Yang*

Main category: cs.SE

TL;DR: XAMT是一种跨框架模糊测试方法，通过匹配不同深度学习框架中功能等效的API进行差异测试，发现了传统框架内测试无法检测的bug


<details>
  <summary>Details</summary>
Motivation: 深度学习库的bug会传播到下游关键应用，现有模糊测试技术通过跨硬件后端测试可能漏检在不同后端表现相同的bug

Method: 基于名称、描述和参数结构的相似性规则匹配API，对齐输入并应用方差引导的差异测试来检测bug

Result: 在5个流行框架中匹配839个API和238个API组，检测到17个bug（12个已确认），发现传统方法无法检测的跨后端一致bug

Conclusion: XAMT为深度学习库测试提供了现有方法的补充方法，提供了新的测试视角

Abstract: Deep learning powers critical applications such as autonomous driving,
healthcare, and finance, where the correctness of underlying libraries is
essential. Bugs in widely used deep learning APIs can propagate to downstream
systems, causing serious consequences. While existing fuzzing techniques detect
bugs through intra-framework testing across hardware backends (CPU vs. GPU),
they may miss bugs that manifest identically across backends and thus escape
detection under these strategies. To address this problem, we propose XAMT, a
cross-framework fuzzing method that tests deep learning libraries by matching
and comparing functionally equivalent APIs across different frameworks. XAMT
matches APIs using similarity-based rules based on names, descriptions, and
parameter structures. It then aligns inputs and applies variance-guided
differential testing to detect bugs. We evaluated XAMT on five popular
frameworks, including PyTorch, TensorFlow, Keras, Chainer, and JAX. XAMT
matched 839 APIs and identified 238 matched API groups, and detected 17 bugs,
12 of which have been confirmed. Our results show that XAMT uncovers bugs
undetectable by intra-framework testing, especially those that manifest
consistently across backends. XAMT offers a complementary approach to existing
methods and offers a new perspective on the testing of deep learning libraries.

</details>


### [334] [Strengthening Programming Comprehension in Large Language Models through Code Generation](https://arxiv.org/abs/2508.12620)
*Xiaoning Ren,Qiang Hu,Wei Ma,Yan Li,Yao Zhang,Lingxiao Jiang,Yinxing Xue*

Main category: cs.SE

TL;DR: 通过反事实代码增广和概念意识调整框架，提升大语言模型对程序设计基础概念的理解能力


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在代码相关任务上表现亮眼，但对数据流、控制流等基础编程概念的理解仍浅层，导致在需要深度推理的代码中表现脆弱，限制了实际软件开发中的应用

Method: 提出了一种反事实代码增广框架结合概念意识调整的方法

Result: 在多个模型和测试集上进行了全面评估，证明了所提方法的有效性

Conclusion: 该方法能够有效引导大语言模型向更强的概念理解发展，解决了当前模型在深度代码推理方面的限制

Abstract: Large language models (LLMs) have recently shown impressive results on
diverse code-related tasks, benefiting from large-scale training and
instruction tuning. However, studies reveal that their grasp of fundamental
programming concepts, such as data flow and control flow, remains shallow,
leading to fragile performance when code requires deeper reasoning. This
limitation restricts the practical adoption of LLMs in real-world software
development. To address this issue, this work introduces a counterfactual code
augmentation framework combined with concept-aware tuning, designed to guide
LLMs toward stronger conceptual understanding. Comprehensive evaluation across
multiple models and benchmarks demonstrates the effectiveness of the proposed
approach.

</details>


### [335] [ChangePrism: Visualizing the Essence of Code Changes](https://arxiv.org/abs/2508.12649)
*Lei Chen,Michele Lanza,Shinpei Hayashi*

Main category: cs.SE

TL;DR: 提出了ChangePrism工具，通过可视化方式帮助开发者更好地理解代码变更，包含提取和可视化两个组件，提供概览和详细视图


<details>
  <summary>Details</summary>
Motivation: 传统的代码差异对比方式（红绿高亮显示行级增删）对开发者来说繁琐且难以获得提交中所有变更的全面概览，某些重要的代码变更类型需要特殊区分以增强代码理解

Method: 开发了ChangePrism工具，包含两个组件：提取组件从git历史记录中检索代码变更和相关信息，可视化组件提供提交中代码变更的概览视图和详细视图

Result: ChangePrism能够提供代码变更的概览视图（显示跨提交的不同类型代码变更）和详细视图（显示每个提交中源代码的确切变更）

Conclusion: ChangePrism是一种新颖的可视化方法，能够更好地帮助开发者理解代码变更，解决了传统代码差异对比方式的局限性

Abstract: Understanding the changes made by developers when they submit a pull request
and/or perform a commit on a repository is a crucial activity in software
maintenance and evolution. The common way to review changes relies on examining
code diffs, where textual differences between two file versions are highlighted
in red and green to indicate additions and deletions of lines. This can be
cumbersome for developers, making it difficult to obtain a comprehensive
overview of all changes in a commit. Moreover, certain types of code changes
can be particularly significant and may warrant differentiation from standard
modifications to enhance code comprehension. We present a novel visualization
approach supported by a tool named ChangePrism, which provides a way to better
understand code changes. The tool comprises two components: extraction, which
retrieves code changes and relevant information from the git history, and
visualization, which offers both general and detailed views of code changes in
commits. The general view provides an overview of different types of code
changes across commits, while the detailed view displays the exact changes in
the source code for each commit.

</details>


### [336] [RUM: Rule+LLM-Based Comprehensive Assessment on Testing Skills](https://arxiv.org/abs/2508.12922)
*Yue Wang,Zhenyu Chen,Yuan Zhao,Chunrong Fang,Ziyuan Wang,Song Huang*

Main category: cs.SE

TL;DR: RUM方法结合规则和大型语言模型，解决了META系统只能评估测试脚本客观指标的问题，实现了对测试用例、脚本和报告的主观自动评估，大幅提升了评估效率和降低了成本。


<details>
  <summary>Details</summary>
Motivation: META系统在软件测试竞赛中成功评估了10万+学生的测试技能，但仅限于测试脚本的客观评估，缺乏对测试用例和报告等主观内容的自动评估能力。

Method: 提出RUM方法，结合规则处理客观指标，利用大型语言模型(LLMs)对测试用例文档、测试脚本和测试报告进行深度主观分析，实现全面评估。

Result: 相比传统人工评估，RUM提升评估效率80.77%，降低成本97.38%，同时保持高准确性和评估一致性。

Conclusion: RUM不仅提升了软件测试教育中技能评估的效率和可扩展性，还为教师提供了更全面客观的学生能力评估证据，促进了个性化教学，为测试技能评估提供了新思路。

Abstract: Over the past eight years, the META method has served as a multidimensional
testing skill assessment system in the National College Student Contest on
Software Testing, successfully assessing over 100,000 students' testing skills.
However, META is primarily limited to the objective assessment of test scripts,
lacking the ability to automatically assess subjective aspects such as test
case and test report. To address this limitation, this paper proposes RUM, a
comprehensive assessment approach that combines rules and large language models
(LLMs). RUM achieves a comprehensive assessment by rapidly processing objective
indicators through rules while utilizing LLMs for in-depth subjective analysis
of test case documents, test scripts, and test reports. The experimental
results show that compared to traditional manual testing skill assessment, RUM
improves assessment efficiency by 80.77\% and reduces costs by 97.38\%, while
maintaining high accuracy and consistency of assessment. By applying RUM on the
contest on software testing, we find that it not only enhances the efficiency
and scalability of skill assessment in software testing education, but also
provides teachers with more comprehensive and objective evidence for student
ability assessment, facilitating personalized teaching and learning. This study
offers new insights into the assessment of testing skills, which are expected
to promote further development in test process optimization and software
quality assurance.

</details>


### [337] [Investigating VR Accessibility Reviews for Users with Disabilities: A Qualitative Analysis](https://arxiv.org/abs/2508.13051)
*Yi Wang,Chetan Arora,Xiao Liu,Thuong Hoang,ZHengxin Zhang,Henry Been Lirn Duh,John Grundy*

Main category: cs.SE

TL;DR: 这篇论文分析了Meta和Steam平台上VR应用的用户评论，研究了游戏对殊障用户的可访问性问题，发现可访性评论数量极少且得不到充分支持。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实(VR)应用的可访性对殊障用户至关重要，但目前缺乏全面的研究。本研究旨在分析用户评论中反映的殊障用户遇到的可访性问题。

Method: 研究分析了Meta和Steam平台上最受欢迎的40款、20款最流行和40款最低评分VR应用的1,367,419条评论，识别出1,076条与可访性相关的评论。

Result: 在100款VR应用中识别出16种不同类型的殊障，分为6个类别。动作类游戏收到最多的可访性相关评论。用户主要报告了可访性问题的原因。

Conclusion: VR应用的可访性评论数量极少（仅0.078%），且得不到充分支持，显示出VR行业在殊障用户可访性方面存在显著不足。

Abstract: Accessibility reviews provide valuable insights into both the limitations and
benefits experienced by users with disabilities when using virtual reality (VR)
applications. However, a comprehensive investigation into VR accessibility for
users with disabilities is still lacking. To fill this gap, this study analyzes
user reviews from the Meta and Steam stores of VR apps, focusing on the
reported issues affecting users with disabilities. We applied selection
criteria to 1,367,419 reviews from the top 40, the 20 most popular, and the 40
lowest-rated VR applications on both platforms. In total, 1,076 (0.078%) VR
accessibility reviews referenced various disabilities across 100 VR
applications. These applications were categorized into Action, Sports, Social,
Puzzle, Horror, and Simulation, with Action receiving the highest number of
accessibility related-reviews. We identified 16 different types of disabilities
across six categories. Furthermore, we examined the causes of accessibility
issues as reported by users with disabilities. Overall, VR accessibility
reviews were predominantly under-supported.

</details>


### [338] [Influencia de fatores organizacionais e sociais na etapa de levantamento de requisitos](https://arxiv.org/abs/2508.13134)
*Glauber da Rocha Balthazar,Marcia Ito*

Main category: cs.SE

TL;DR: 这篇论文调查了需求工程中考虑非技术因素（如情感、组织环境、社会背景）的研究


<details>
  <summary>Details</summary>
Motivation: 需求收集是软件开发中最关键且脏弱的阶段，尽管需求工程技术不断发展，但很少研究考虑了参与者的人文关系和行为因素

Method: 通过调查研究方法，综述分析在需求收集阶段考虑非技术因素的相关研究

Result: 文章展示了多个在需求工程中考虑情感、组织环境和社会背景等非技术因素的研究成果

Conclusion: 需求工程领域需要更多地考虑人文因素，这些非技术方面对需求收集成功至关重要

Abstract: The most critical and fragile stage of a software development project is
requirements gathering. Because of this, Requirements Engineering has been
evolving its techniques to minimize the challenges faced by Requirements
Analysts. However, few studies consider the humanistic relationships and
behaviors of those involved in this stage. This article presents a survey of
some studies conducted at this stage that consider non-technical factors such
as emotions, organizational environment, and social context.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [339] [The Identification Power of Combining Experimental and Observational Data for Distributional Treatment Effect Parameters](https://arxiv.org/abs/2508.12206)
*Shosei Sakaguchi*

Main category: econ.EM

TL;DR: 这篇论文研究如何结合实验数据咄观测数据来提高分布式治疗效果参数的识别能力，推导了尽可能紧的界限，并分析了自我选择如何为识别提供信息。


<details>
  <summary>Details</summary>
Motivation: 虽然实验数据能够识别平均治疗效果，但许多分布式治疗效果参数如个体治疗效果分布等只能部分识别。需要研究如何通过结合两种数据来紧缩识别集。

Method: 使用线性规划方法计算尽可能紧的界限，考虑了潜在结果的相互随机单调性咄广义Roy模型等结构限制条件。

Result: 推导了在结合数据下的尽可能紧界限，并证明除非观测数据中存在观测选择条件，否则结合数据通常能够缩小识别集。自我选择是识别能力的关键来源。

Conclusion: 结合实验咄观测数据能够显著提高分布式治疗效果参数的识别能力，应用于美国总统选举中负面竞选广告的实证研究证明了该方法的实际价值。

Abstract: This paper investigates the identification power gained by combining
experimental data, in which treatment is randomized, with observational data,
in which treatment is self-selected, for distributional treatment effect (DTE)
parameters. While experimental data identify average treatment effects, many
DTE parameters, such as the distribution of individual treatment effects, are
only partially identified. We examine whether, and how, combining the two data
sources tightens the identified set for these parameters. For broad classes of
DTE parameters, we derive sharp bounds under the combined data and clarify the
mechanism through which the data combination tightens the identified set
relative to using experimental data alone. Our analysis highlights that
self-selection in the observational data is a key source of identification
power. We also characterize necessary and sufficient conditions under which the
combined data shrink the identified set, showing that such shrinkage generally
occurs unless selection-on-observables holds in the observational data. We also
propose a linear programming approach to compute the sharp bounds, which can
accommodate additional structural restrictions such as mutual stochastic
monotonicity of potential outcomes and the generalized Roy model. An empirical
application using data on negative campaign advertisements in a U.S.
presidential election illustrates the practical relevance of the approach.

</details>


### [340] [A statistician's guide to weak-instrument-robust inference in instrumental variables regression with illustrations in Python](https://arxiv.org/abs/2508.12474)
*Malte Londschien*

Main category: econ.EM

TL;DR: 本文综述了工具变量回归中的估计方法和弱工具变量稳健推断的相关研究成果，并介绍了Python软件包ivmodels的实现


<details>
  <summary>Details</summary>
Motivation: 工具变量回归在计量经济学中广泛应用，但弱工具变量问题会影响估计的准确性和推断的可靠性，需要系统总结相关方法

Method: 综述性研究方法，系统整理和分析了工具变量估计的各种方法，特别是针对弱工具变量问题的稳健推断技术，并通过Python软件包ivmodels进行实现和演示

Result: 提供了工具变量回归估计和推断方法的全面概述，开发了实用的软件工具来支持相关方法的实现和应用

Conclusion: 该研究为工具变量分析提供了重要的方法论支持和软件工具，特别有助于解决弱工具变量带来的统计推断问题，推动了该领域方法的应用和发展

Abstract: We provide an overview of results relating to estimation and
weak-instrument-robust inference in instrumental variables regression. Methods
are implemented in the ivmodels software package for Python, which we use to
illustrate results.

</details>


### [341] [Reconstructing Subnational Labor Indicators in Colombia: An Integrated Machine and Deep Learning Approach](https://arxiv.org/abs/2508.12514)
*Jaime Vera-Jaramillo*

Main category: econ.EM

TL;DR: 提出统一多阶段框架，为哥伦比亚33个省重构1993-2025年月度和年度劳动力指标，包括就业、失业、劳动力参与率等七个关键变量


<details>
  <summary>Details</summary>
Motivation: 为了解决哥伦比亚各地区劳动力市场数据缺失和不一致性问题，提供空间上完整、时间上一致的月度劳动力指标

Method: 集成时间分解、时间序列缀接和插值、统计学习、机构协变量，强制劳动账户计算计算识别，缩放到人口预测，对准国家标准

Result: 验证显示在样本内平均绝对百分比误差(MAPE)低于2.3%，证明了强大的预测性能，为哥伦比亚首个空间完整、时间一致的月度劳动力数据集

Conclusion: 该框架通过结合定量和定性就业维度，为分析长期劳动力市场动态、识别地区差异和设计针对性政策干预提供了更好的实证基础

Abstract: This study proposes a unified multi-stage framework to reconstruct consistent
monthly and annual labor indicators for all 33 Colombian departments from 1993
to 2025. The approach integrates temporal disaggregation, time-series splicing
and interpolation, statistical learning, and institutional covariates to
estimate seven key variables: employment, unemployment, labor force
participation (PEA), inactivity, working-age population (PET), total
population, and informality rate, including in regions without direct survey
coverage. The framework enforces labor accounting identities, scales results to
demographic projections, and aligns all estimates with national benchmarks to
ensure internal coherence. Validation against official departmental GEIH
aggregates and city-level informality data for the 23 metropolitan areas yields
in-sample Mean Absolute Percentage Errors (MAPEs) below 2.3% across indicators,
confirming strong predictive performance. To our knowledge, this is the first
dataset to provide spatially exhaustive and temporally consistent monthly labor
measures for Colombia. By incorporating both quantitative and qualitative
dimensions of employment, the panel enhances the empirical foundation for
analysing long-term labor market dynamics, identifying regional disparities,
and designing targeted policy interventions.

</details>


### [342] [Bayesian Double Machine Learning for Causal Inference](https://arxiv.org/abs/2508.12688)
*Francis J. DiTraglia,Laura Liu*

Main category: econ.EM

TL;DR: 提出进行高维控制变量因果推断的贝叶斯双重机器学习方法（BDML），解决正则化导致的偏差问题


<details>
  <summary>Details</summary>
Motivation: 当前的机器学习方法在高维控制变量情况下容易导致正则化引发的混淆偏差，影响因果参数估计的准确性

Method: 修改标准贝叶斯多元回归模型，通过约化形式协方差矩阵恢复因果效应，构建了一个完全生成的概率模型

Result: BDML方法在高维设置中显示更低的进行偏差，达到进行正态性咋半参数效率，通过Bernstein-von Mises定理确保了对错误规格的稳健性

Conclusion: 在模拟中，BDML方法在RMSE、频率覆盖率咋信任区间宽度方面都显著优于现有的贝叶斯咋频率论方法，为高维因果推断提供了更可靠的统计推断

Abstract: This paper proposes a simple, novel, and fully-Bayesian approach for causal
inference in partially linear models with high-dimensional control variables.
Off-the-shelf machine learning methods can introduce biases in the causal
parameter known as regularization-induced confounding. To address this, we
propose a Bayesian Double Machine Learning (BDML) method, which modifies a
standard Bayesian multivariate regression model and recovers the causal effect
of interest from the reduced-form covariance matrix. Our BDML is related to the
burgeoning frequentist literature on DML while addressing its limitations in
finite-sample inference. Moreover, the BDML is based on a fully generative
probability model in the DML context, adhering to the likelihood principle. We
show that in high dimensional setups the naive estimator implicitly assumes no
selection on observables--unlike our BDML. The BDML exhibits lower asymptotic
bias and achieves asymptotic normality and semiparametric efficiency as
established by a Bernstein-von Mises theorem, thereby ensuring robustness to
misspecification. In simulations, our BDML achieves lower RMSE, better
frequentist coverage, and shorter confidence interval width than alternatives
from the literature, both Bayesian and frequentist.

</details>


### [343] [Bivariate Distribution Regression; Theory, Estimation and an Application to Intergenerational Mobility](https://arxiv.org/abs/2508.12716)
*Victor Chernozhukov,Iván Fernández-Val,Jonas Meier,Aico van Vuuren,Francis Vella*

Main category: econ.EM

TL;DR: 本文提出双变量分布回归(BDR)方法，用于估计两个结果变量在给定协变量下的联合分布，特别适用于处理协变量无法完全解释的残差依赖性。


<details>
  <summary>Details</summary>
Motivation: 当两个结果变量之间存在协变量无法完全解释的依赖关系时，需要一种能够建模这种残差依赖性的方法。双变量分布回归能够有效处理这种情况，特别在社会流动性研究等领域有重要应用价值。

Method: 基于Chernozhukov等人(2018)的局部高斯表示理论，实现双变量分布回归。通过分解联合分布差异为组成效应、边际效应和排序效应，并提供相应的推断程序。

Result: 在代际流动性的实证分析中，使用PSID数据建模父母与子女收入的联合分布，通过构建反事实分析分离可观测和不可观测因素的影响，并评估儿子和女儿转移矩阵差异的原因。

Conclusion: 双变量分布回归为分析条件联合分布提供了有效框架，特别适用于存在残差依赖性的场景，在社会科学实证研究中具有重要应用价值。

Abstract: We employ distribution regression (DR) to estimate the joint distribution of
two outcome variables conditional on chosen covariates. While Bivariate
Distribution Regression (BDR) is useful in a variety of settings, it is
particularly valuable when some dependence between the outcomes persists after
accounting for the impact of the covariates. Our analysis relies on a result
from Chernozhukov et al. (2018) which shows that any conditional joint
distribution has a local Gaussian representation. We describe how BDR can be
implemented and present some associated functionals of interest. As modeling
the unexplained dependence is a key feature of BDR, we focus on functionals
related to this dependence. We decompose the difference between the joint
distributions for different groups into composition, marginal and sorting
effects. We provide a similar decomposition for the transition matrices which
describe how location in the distribution in one of the outcomes is associated
with location in the other. Our theoretical contributions are the derivation of
the properties of these estimated functionals and appropriate procedures for
inference. Our empirical illustration focuses on intergenerational mobility.
Using the Panel Survey of Income Dynamics data, we model the joint distribution
of parents' and children's earnings. By comparing the observed distribution
with constructed counterfactuals, we isolate the impact of observable and
unobservable factors on the observed joint distribution. We also evaluate the
forces responsible for the difference between the transition matrices of sons'
and daughters'.

</details>


### [344] [Estimation in linear models with clustered data](https://arxiv.org/abs/2508.12860)
*Anna Mikusheva,Mikkel Sølvsten,Baiyun Jing*

Main category: econ.EM

TL;DR: 提出了一个针对聚类数据、高维控制和复杂排除约束的线性回归模型的内生IV估计器，具有去中心化、计算高效和稳健推断的特点


<details>
  <summary>Details</summary>
Motivation: 处理聚类数据、高维控制和复杂排除约束的线性回归问题，传统方法难以有效处理这类复杂结构

Method: 开发了正确中心化的内部IV估计器，允许聚类内依赖，具有留一法解释，计算上易于处理，并推导了二次型的中心极限定理和稳健方差估计

Result: 估计器能够处理各种排除约束，在弱识别条件下仍保持有效的推断方法，扩展了经典动态面板方法到更一般的聚类设置

Conclusion: 该方法为处理复杂数据结构的线性回归提供了有效的估计和推断框架，并通过肯尼亚农村大规模财政干预的实证应用验证了方法的实用性

Abstract: We study linear regression models with clustered data, high-dimensional
controls, and a complicated structure of exclusion restrictions. We propose a
correctly centered internal IV estimator that accommodates a variety of
exclusion restrictions and permits within-cluster dependence. The estimator has
a simple leave-out interpretation and remains computationally tractable. We
derive a central limit theorem for its quadratic form and propose a robust
variance estimator. We also develop inference methods that remain valid under
weak identification. Our framework extends classical dynamic panel methods to
more general clustered settings. An empirical application of a large-scale
fiscal intervention in rural Kenya with spatial interference illustrates the
approach.

</details>


### [345] [The purpose of an estimator is what it does: Misspecification, estimands, and over-identification](https://arxiv.org/abs/2508.13076)
*Isaiah Andrew,Jiafeng Chen,Otavio Tecchio*

Main category: econ.EM

TL;DR: 论文分析了过度识别模型中的误设定问题，指出误设定会改变估计量的估计目标而非效率，并基于对AER期刊应用的观察提出了透明稳健实证研究的指导原则。


<details>
  <summary>Details</summary>
Motivation: 基于对美国经济评论中广义矩方法应用的观察，发现误设定普遍存在但缺乏正式检验，且研究者广泛使用在正确模型下效率较低的估计量，这促使作者重新审视误设定下的估计问题。

Method: 回顾和综合了模型误设定下的最新估计结果，提供了新的理论结果证明Hansen's J统计量渐近地衡量了在给定标准误下可达到的估计范围。

Result: 发现误设定下不同估计量对应不同的估计目标而非效率差异，建议更广泛地报告J统计量以应对研究者自由度问题。

Conclusion: 在误设定普遍存在的情况下，需要采用更透明和稳健的实证研究方法，特别推荐广泛报告J统计量来约束研究者的自由度。

Abstract: In over-identified models, misspecification -- the norm rather than exception
-- fundamentally changes what estimators estimate. Different estimators imply
different estimands rather than different efficiency for the same target. A
review of recent applications of generalized method of moments in the American
Economic Review suggests widespread acceptance of this fact: There is little
formal specification testing and widespread use of estimators that would be
inefficient were the model correct, including the use of "hand-selected"
moments and weighting matrices. Motivated by these observations, we review and
synthesize recent results on estimation under model misspecification, providing
guidelines for transparent and robust empirical research. We also provide a new
theoretical result, showing that Hansen's J-statistic measures, asymptotically,
the range of estimates achievable at a given standard error. Given the
widespread use of inefficient estimators and the resulting researcher degrees
of freedom, we thus particularly recommend the broader reporting of
J-statistics.

</details>


### [346] [Reasonable uncertainty: Confidence intervals in empirical Bayes discrimination detection](https://arxiv.org/abs/2508.13110)
*Jiaying Gu,Nikolaos Ignatiadis,Azeem M. Shaikh*

Main category: econ.EM

TL;DR: 本文重新审视了经验贝叶斯歧视检测方法，重点关注部分识别和抽样变异带来的不确定性，提出了具有良好性质和解释的反事实比值比估计量。


<details>
  <summary>Details</summary>
Motivation: 先前的研究主要关注部分识别问题，但作者发现一些实证结果对抽样不确定性不够稳健。为了更好地将统计证据与现实世界歧视行为的严重程度联系起来，需要更全面的不确定性量化方法。

Method: 提出了一个反事实比值比估计量，该估计量具有良好的统计性质和直观的解释，能够同时处理部分识别和抽样变异带来的不确定性。

Result: 分析表明，在经验贝叶斯分析中，仔细关注不确定性量化和下游目标非常重要，某些实证发现对抽样不确定性不够稳健。

Conclusion: 经验贝叶斯歧视检测需要同时考虑部分识别和抽样变异的不确定性，提出的反事实比值比估计量为连接统计证据与现实歧视行为提供了更好的方法。

Abstract: We revisit empirical Bayes discrimination detection, focusing on uncertainty
arising from both partial identification and sampling variability. While prior
work has mostly focused on partial identification, we find that some empirical
findings are not robust to sampling uncertainty. To better connect statistical
evidence to the magnitude of real-world discriminatory behavior, we propose a
counterfactual odds-ratio estimand with a attractive properties and
interpretation. Our analysis reveals the importance of careful attention to
uncertainty quantification and downstream goals in empirical Bayes analyses.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [347] [Incorporating an economic approach to production in a health system model](https://arxiv.org/abs/2508.11730)
*Martin Chalkley,Tim Colbourn,Timothy B. Hallett,Tara D. Mangal,Margherita Molaro,Sakshi Mohan,Bingling She,Paul Revill,Wiktoria Tafese*

Main category: econ.GN

TL;DR: Thanzi la Onse (TLO)模型是马拉维首个多疾病卫生系统模型，通过整合经济概念和更复杂的医疗工作者可用性影响分析，为资源约束下的政策评估提供了更灵活的工具。


<details>
  <summary>Details</summary>
Motivation: 随着计算能力的提升，需要开发更详细的卫生系统模型来理解医疗资源约束对人口健康的影响，并分析更丰富的政策情景。

Method: 在多疾病卫生系统模型TLO中整合经济概念，包括医疗工作者不可用性的影响分析，以及不同所有制形式和管理实践的作用研究。

Result: 开发了更灵活的模型工具，能够分析医疗工作者扩张或减少缺勤等政策情景对健康收益的潜在影响。

Conclusion: 这种综合方法不仅增强了模型在资源约束影响分析中的灵活性，还为更丰富的政策情景分析开辟了可能性。

Abstract: As computational capacity increases, it becomes possible to model health
systems in greater detail. Multi-disease health system models (HSMs) represent
a new development, building on individual level epidemiological models of
multiple diseases and capturing how healthcare delivery systems respond to
population health needs. The Thanzi la Onse (TLO) model of Malawi is the first
of its kind in these respects. In this article, we discuss how we have been
bringing economic concepts into the TLO model, and how we are continuing to
develop this line of research. This has involved incorporating more
sophisticated approaches to account for the effects of the unavailability of
healthcare workers, and we are working towards establishing the role of
different forms of ownership of healthcare facilities and different management
practices. Not only does this broad approach make the model more flexible as a
tool for understanding the impact of resource constraints, it opens up the
possibility of analysing considerably richer policy scenarios; for example
establishing an estimate of the health gain that could be achieved through
expanding the workforce or reducing healthcare worker absence.

</details>


### [348] [The European Union Deforestation Regulation: The Impact on Argentina](https://arxiv.org/abs/2508.11796)
*Pablo de la Vega*

Main category: econ.GN

TL;DR: 欧盟森林清除规定(EUDR)将对阿根廷造成有限的经济影响(国内生产总值平均下降0.14%)，但环境效益明显(森林清除面积减少2.45%，温室气体排放减少0.19%)。大豆和牛羊产业受影响最大，但符合规定的产品仍可进入欧盟市场。


<details>
  <summary>Details</summary>
Motivation: 分析欧盟森林清除规定(EUDR)对阿根廷经济的影响，评估该规定在2026年1月生效后对阿根廷出口的影响程度和环境效益。

Method: 使用动态可计算一般均衡模型，模拟EUDR对阿根廷经济的影响。估算规定覆盖的出口价值和不符合规定的产品比例。

Result: EUDR覆盖约60亿美元出口价值，但仅2.84%不符合规定。大豆和牛羊产业链受影响最大。影响主要在微观层面，宏观经济影响有限(GDP平均下降0.14%)，但环境效益明显(森林清除面积减少2.45%，温室气体排放减少0.19%)。

Conclusion: EUDR对阿根廷的宏观经济影响相对有限，但环境保护效果明显。然而，合规性审查成本可能仍会阻碍符合规定的产品进入欧盟市场，因此实际影响可能比模拟结果更大。

Abstract: We analyze the potential economic impacts in Argentina of the European Union
Deforestation Regulation (EUDR), which as of January 2026 will prohibit the
export to the European Union of certain raw materials and related products if
they involve the use of deforested land. We estimate that the EUDR would cover
around 6 billion US dollars in exported value, but only 2.84% is not compliant
with the EUDR, with soy and cattle being the most affected production chains.
We use a dynamic computable general equilibrium model to simulate the impact of
the EUDR on the Argentine economy. If the non-compliant production cannot enter
the EU market because of the EUDR, the results of the simulations suggest that
the potential macroeconomic impacts are limited: GDP would be reduced by an
average of 0.14% with respect to the baseline scenario. However, the potential
environmental impact is greater. Deforested hectares would be reduced by 2.45%
and GHG emissions by 0.19%. Notwithstanding, EUDR due diligence costs may still
prevent compliant production from entering the EU market, so the total impacts
could be higher.

</details>


### [349] [Conformity: Resolving the Trade-Off Between Performance and Synchrony in Multi-Unit Organizations](https://arxiv.org/abs/2508.11807)
*Ravshanbek Khodzhimatov,Stephan Leitner,Friederike Wall*

Main category: econ.GN

TL;DR: 多单元组织中通过适当的沟通网络结构和知识分享规范，可以同时提升组织性能和同步性，解决中央化与分散化的两难问题


<details>
  <summary>Details</summary>
Motivation: 传统观点认为多单元组织在中央化控制和分散化自主权之间存在特征性交换，性能需要分散化而同步性需要中央化，本研究探索如何解决这一两难问题

Method: 建立了一个基亊模型的多单元组织模型，研究单元经理的沟通能力、知识分享和同行行为互动对组织动态的影响

Result: 发现在特定的沟通网络结构下，增加分散化可以同时提高组织性能和同步性，但如果单元间存在相互依赖关系，中央化控制仍然更有利于同步性

Conclusion: 通过促进知识分享规范和设置适当的沟通通道，多单元组织可以使用分散化策略同时实现高性能和高同步性，但需要根据单元间依赖性来选择合适的控制策略

Abstract: Multi-unit organizations are a form of organizations where the geographically
dispersed units provide similar products or services in different markets.
Deciding on an appropriate level of centralization in such organizations
presents a unique challenge. One the one hand the organizations want to
maintain a consistent brand identity in all units through centralized control,
but on the other hand, they want to provide the units with sufficient autonomy
to respond to the challenges they face locally. Traditionally, this challenge
was perceived to require a trade-off between performance and organizational
synchrony, with performance demanding more decentralization and synchrony
requiring more centralized control. However, our research explores how
organizations can potentially resolve this trade-off by promoting norms for
knowledge-sharing and setting up the right communication channels, relying on
the unit managers' intrinsic tendency to conform to the behavior of their
peers. We build an agent-based model of an organization with multiple
interdependent units facing highly similar task environments to investigate how
unit managers' ability to communicate, share knowledge, and conform to peer
practices might influence organizational dynamics. We find that, under specific
communication network structures, increased decentralization can enhance both
performance and organizational synchrony without sacrificing one or the other.
Furthermore, we discover that centralization might still be preferable for
synchrony if the units are interdependent.

</details>


### [350] [Deciphering the global production network from cross-border firm transactions](https://arxiv.org/abs/2508.12315)
*Neave O'Clery,Ben Radcliffe-Brown,Thomas Spencer,Daniel Tarling-Hunter*

Main category: econ.GN

TL;DR: 基于10亿级全球企业交易数据构建供应链网络，发现产品聚为三大类群，欧洲和中国在关键中间产品中占主导地位，网络结构指标能高精度预测国家-产品多样化模式。


<details>
  <summary>Details</summary>
Motivation: 全球供应链研究对政策制定和商业运营至关重要，但一直受限于细粒度数据的缺乏。

Method: 利用20万家全球企业的10亿级跨境交易数据，构建有向网络推断1200多种产品的关键输入，并与LLM查询和NAFTA源头追踪等方法验证网络结构。

Result: 产品聚为纺织品、化学品和食品、机械和金属三大群组，欧洲工业国家和中国在金属、通用零部件、工具等关键中间产品中占主导地位，工业复杂性与供应链网络嵌入度相关。

Conclusion: 通过大规模企业交易数据构建的供应链网络有效揭示了全球产业结构，网络结构指标能够高精度预测国家产业发展模式，为政策制定提供了重要视角。

Abstract: Critical for policy-making and business operations, the study of global
supply chains has been severely hampered by a lack of detailed data. Here we
harness global firm-level transaction data covering 20m global firms, and 1
billion cross-border transactions, to infer key inputs for over 1200 products.
Transforming this data to a directed network, we find that products are
clustered into three large groups including textiles, chemicals and food, and
machinery and metals. European industrial nations and China dominate critical
intermediate products in the network such as metals, common components and
tools, while industrial complexity is correlated with embeddedness in densely
connected supply chains. To validate the network, we find structural
similarities with two alternative product networks, one generated via LLM
queries and the other derived by NAFTA to track product origins. We further
detect linkages between products identified in manually mapped single sector
supply chains, including electric vehicle batteries and semi-conductors.
Finally, metrics derived from network structure capturing both forward and
backward linkages are able to predict country-product diversification patterns
with high accuracy.

</details>


### [351] [Evaluating sugarcane bagasse-based biochar as an economically viable catalyst for agricultural and environmental advancement in Brazil through scenario-based economic modeling](https://arxiv.org/abs/2508.12454)
*Sebastian G. Nosenzo*

Main category: econ.GN

TL;DR: 已经对已有文献进行了审查，但是存在空白。


<details>
  <summary>Details</summary>
Motivation: 全球对可持续农业和废物管理的需求增加，生物炭作为多功能解决方案的潜力。

Method: 采用场景基于经济学建模方法，包含相关经济模型。

Result: 生物炭实施在中大型甘蔗农场具有经济可行性，平均投资回报率18%，约7.5年投资回本。小型农场仅在土壤施用生物炭时才可行。

Conclusion: 土壤施用是最可行的方案，大型农场效果最佳，规模重要。小型和中型农场无土壤施用时不具或疑会可行性。

Abstract: The increasing global demand for sustainable agricultural practices and
effective waste management has highlighted the potential of biochar as a
multifaceted solution. This study evaluates the economic viability of sugarcane
bagasse-based biochar in Brazil, focusing on its potential to enhance
agricultural productivity and contribute to environmental sustainability. While
existing literature predominantly explores the production, crop yield benefits,
and carbon sequestration capabilities of biochar, there is a notable gap in
comprehensive economic modeling and viability analysis for the region. This
paper aims to fill this gap by employing a scenario-based economic modeling
approach, incorporating relevant economic models. Findings include that biochar
implementation can be economically viable for medium and large sugarcane farms
(20000-50000 hectares) given the availability of funding, breaking even in
about 7.5 years with an internal rate of return of 18% on average. For small
farms, biochar can only be viable when applying biochar to the soil, which in
all scenarios is found to be the more profitable practice by a large margin.
Sensitivity analyses found that generally, biochar becomes economically
feasible at biochar carbon credit prices above $120 USD/tCO2e, and at sugarcane
bagasse availability percentages above 60%. While the economic models are
well-grounded in existing literature, the production of biochar at the studied
scales is not yet widespread, especially in Brazil and uncertainties can
result. Reviewing the results, the land application scenario was found to be
the most viable, and large farms saw the best results, highlighting the
importance of scale to biochar operation. Small and medium farms with no land
application were concluded to have no and questionable viability, respectively.

</details>


### [352] [From fields to fuel: analyzing the global economic and emissions potential of agricultural pellets, informed by a case study](https://arxiv.org/abs/2508.12457)
*Sebastian G. Nosenzo,Rafael Kelman*

Main category: econ.GN

TL;DR: 本研究通过全球农业残留物球壳化潜力分析，发现可替代4.5%全球化石燃料能源，年减排163亿美元成1.35亿吨CO2排放，具备竞争力价格和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 农业残留物作为大量未装利用的可再生能源资源，需要评估其在替代化石燃料和减排方面的全球潜力。

Method: 结189个国家的实证分析结合球壳化设施案例研究，使用自主开发的CLASP-P和RECOP模型进行技术和经济性分析。

Result: 技术可用量达14.4亿吨作物残留物，可替代917亿吨煤炼，经济优化情景下年减排163亿美元成1.35亿吨CO2等效排放，且在许多市场中具备价格竞争力。

Conclusion: 农业球壳化是一条可扩展的市场驱动路径，能支持全球脱碳目标并促进农村经济发展，需要针对性投资、技术进步和支持性政策来充分发挥其潜力。

Abstract: Agricultural residues represent a vast, underutilized resource for renewable
energy. This study combines empirical analysis from 179 countries with a case
study of a pelletization facility to evaluate the global potential of
agricultural pelletization for fossil fuel replacement. The findings estimate a
technical availability of 1.44 billion tons of crop residues suitable for
pellet production, translating to a 4.5% potential displacement of global
fossil fuel energy use, equating to 22 million TJ and equivalent to 917 million
tons of coal annually. The economically optimized scenario projects annual
savings of $163 billion and a reduction of 1.35 billion tons of CO2 equivalent
in emissions. Utilizing the custom-developed CLASP-P and RECOP models, the
study further demonstrates that agricultural pellets can achieve competitive
pricing against conventional fossil fuels in many markets. Despite logistical
and policy challenges, agricultural pelletization emerges as a scalable,
market-driven pathway to support global decarbonization goals while fostering
rural economic development. These results reinforce the need for targeted
investment, technological advancement, and supportive policy to unlock the full
potential of agricultural pellets in the renewable energy mix.

</details>


### [353] [Do STEM graduates fare better at times of Crises? Evidence from COVID 19 pandemic in India](https://arxiv.org/abs/2508.12471)
*Jheelum Sarkar*

Main category: econ.GN

TL;DR: STEM学位在COVID-19疫情期间提供就业韧性，STEM毕业生比非STEM毕业生更可能保持就业，但工资增长差异不显著


<details>
  <summary>Details</summary>
Motivation: 研究STEM大学学位是否在COVID-19冲击期间提供劳动力市场韧性，因为疫情和封锁对不同职业的影响不均

Method: 使用2017-2023年全国代表性高频劳动力调查数据，采用双重差分策略比较STEM和非STEM毕业生在疫情期间及之后的就业参与和月收入变化

Result: STEM大学学位持有者在疫情期间及之后比非STEM同行更可能就业；虽然STEM毕业生工资增长似乎更高，但差异统计不显著；结果由STEM毕业生集中的行业类型、地理位置和职业阶段驱动

Conclusion: STEM学位在疫情冲击期间提供了就业韧性保护，主要发现通过多种替代规范和证伪测试保持稳健

Abstract: I study whether and to what extent STEM college degrees offer labor market
resilience during the COVID 19 shock. Both the pandemic and its nationwide
lockdown affected occupations unevenly. While some jobs could adapt by
switching to remote work or surging demand, others could not. Using the
nationally representative high-frequency labor force survey data (2017-2023), I
used a difference-in-difference strategy to compare changes in employment
participation and monthly earnings between STEM and non-STEM graduates during
and after the pandemic. The results suggest that individuals with a STEM
college degree were more likely to be employed compared to their non-STEM
counterparts during and after the pandemic period. Although STEM graduates
appeared to experience higher wage growth compared to their non-STEM peers, the
difference was statistically insignificant. Additional evidence on mechanisms
suggests that the results are driven by the type of industries with higher
share of STEM graduates, their geographical location and their career stages.
The main findings were robust across alternative specifications and
falsification tests.

</details>


### [354] [Do the rich pay their fair share? Enumerating the price of flying (and abolishing) premium air travel](https://arxiv.org/abs/2508.12507)
*Megan Yeo,Sebastian Nosenzo,Daniel S. Palmer,Alexei K. Varah,Lucas Woodley,Ashley Nunes*

Main category: econ.GN

TL;DR: 去除豪华舱位可降低每位乘客排放8.1-21.5%，但每航班排放变化不确定（-0.45%到+1.43%），且会导致航空公司收入下降4.92-23.1%，需提高6-30%票价来补偿，这可能加重工薪阶层经济负担。


<details>
  <summary>Details</summary>
Motivation: 豪华舱位通常占据更多空间和设施，被认为更加耐油和排放集中，当前讨论建议去除豪华舱位来减排，但需要评估这种政策的效果和影响。

Method: 采用实证模型，结合舱位配置数据、不同机型的燃油消耗模型和多月票价数据集进行分析。

Result: 1. 每位乘客排放可降低8.1-21.5%（取决于机型和航程） 2. 每航班排放变化不确定（-0.45%到+1.43%） 3. 收入下降4.92-23.1%，需提高6-30%票价来维持基准收入

Conclusion: 去除豪华舱位在环境效益上并非确定，而且会导致重大的经济影响，特别是可能加重工薪阶层的负担，这也显示了航空业通过跨补贴来保障航空旅行可达性的现实。

Abstract: Premium air travel is often associated with a disproportionately large carbon
emissions footprint. This association reflects the increased space and
amenities typically found in premium cabins that existing discourse suggests
makes their carriage more fuel, and consequently carbon, intensive. One
increasingly popular solution is disincentivizing the use of premium cabins in
favor of all-economy cabins. How effective might such a policy be. To what
extent. And how may the revenue impact affect travelers. We address these
questions by leveraging an empirical model that integrates cabin configuration
data, fuel burn profiles across various aircraft types, and multi-month airfare
datasets. Our findings are threefold. First, we find that favoring entirely
foregoing premium travel classes can reduce per-passenger emissions by between
8.1 and 21.5 percent, the precise figure varying based on the type of aircraft
and aircraft stage length involved. Second, we observe that these emissions
reductions are far less assured on a per-flight and a lifespan basis. Here, an
all-economy configuration can reduce emissions by 0.45 percent or increase
emissions by as much as 1.43 percent. Third, we enumerate pronounced revenue
consequences associated with an all-economy configuration. This configuration
produces aggregate revenue declines of between 4.92 and 23.1 percent,
necessitating airfare increases of between 6 and 30 percent to maintain
baseline revenue. This increase risks imposing a profound and regressive
economic burden on working-class travelers who exhibit markedly higher price
elasticities of demand compared to their wealthier counterparts and highlights
the cross-subsidization airlines leverage to ensure the accessibility of air
travel.

</details>


### [355] [Testing health expenditure rationing under universal healthcare coverage: the case of Italy](https://arxiv.org/abs/2508.13102)
*Leonardo Becchetti,Nazaria Solferino*

Main category: econ.GN

TL;DR: 调查意大利私人医疗支出的收入影响，发现高收入者每年比低收入者多支出约300欧元，显示了医疗访问的结构性不公平


<details>
  <summary>Details</summary>
Motivation: 研究私人医疗支出是否受收入水平影响，而不仅仅是健康需求的反映，以证明医疗访问存在收入相关的不公平现象

Method: 利用意大利健康调查微观数据，在控制客观健康状况、自我评估健康和社会人口因素的基础上，分析收入对私人医疗支出的解释力

Result: 最高收入等级的个体每年比最低收入等级多支出约300欧元，显示收入在控制健康需求后仍然对医疗支出有显著影响

Conclusion: 研究指出了医疗访问存在结构性不公平，政策措施不仅需要关注正式覆盖范围，还应考虑收入在形成医疗使用方面的根本作用

Abstract: We investigate the phenomenon of (private, out-of-pocket) "health expenditure
rationing", or whether out-of-pocket health expenditures are shaped by income
independently of actual health needs. Using microdata from an Italian Health
Interview Survey, we assess the extent to which income explains variation in
private health spending, after controlling for objective health conditions,
self-assessed health, and a comprehensive set of socio-demographic factors. We
find that individuals in the highest income brackets spend approximately 300
euros more annually than those in the lowest. Our findings point to a
structural inequity in access and highlight the need for policy measures that
address not only formal coverage but also the underlying role of income in
shaping healthcare use.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [356] [Closed-Form of Two-Agent New Keynesian Model with Price and Wage Rigidities](https://arxiv.org/abs/2508.12073)
*Kenji Miyazaki*

Main category: econ.TH

TL;DR: 在具有Rotemberg型名义刚性的双代理新凯恩斯模型中，货币传导的放大需要两个条件：异质性导致的IS斜率效应占主导，且价格粘性渠道活跃。


<details>
  <summary>Details</summary>
Motivation: 研究家庭异质性（储蓄者与手头现金家庭）与名义刚性如何相互作用影响货币政策传导效果，澄清在何种条件下货币政策会获得或失去效力。

Method: 构建完全分析性的双代理新凯恩斯模型，包含Rotemberg型名义刚性，严格遵循微观经济基础，避免对相对工资或劳动供给的约束性假设。

Result: 发现货币传导放大需要异质性IS斜率效应主导和价格粘性渠道活跃两个条件；在纯工资粘性下放大效应减弱或消失；推导了修正的总体福利损失函数。

Conclusion: 该分析框架阐明了家庭异质性与名义刚性的相互作用，精确指出了货币政策获得或失去效力的具体条件，为理解货币政策传导机制提供了清晰的理论基础。

Abstract: This paper argues and analytically demonstrates that, in a fully analytical
Two-Agent New Keynesian model with Rotemberg-type nominal rigidities, monetary
transmission is amplified if and only if two conditions hold: first, the
heterogeneity-induced IS-slope effect dominates; second, the price-stickiness
channel is active. We also show when amplification weakens or disappears, most
notably under pure wage stickiness, where the price channel shuts down and the
heterogeneity-driven term vanishes. The framework features household
heterogeneity between savers and hand-to-mouth households and adheres strictly
to microeconomic foundations while avoiding restrictive assumptions on relative
wages or labor supply across types that are common in prior analytical work.
The closed-form solution makes transparent how price stickiness, wage
stickiness, and the share of hand-to-mouth households jointly shape
amplification. We further derive a modified aggregate welfare loss function
that quantifies how heterogeneity, operating through distributional effects
from firm profits, re-weights the relative importance of stabilizing inflation.
Overall, the tractable yet micro-founded analytical framework clarifies the
interaction between household heterogeneity and nominal rigidities and
pinpoints the precise conditions under which monetary policy gains or loses
traction.

</details>


### [357] [Dynamic Non-Bayesian Persuasion](https://arxiv.org/abs/2508.12328)
*Masanori Kobayashi*

Main category: econ.TH

TL;DR: 研究贝叶斯发送者与非贝叶斯接收者的多步说服问题，分析信息逐步揭示对发送者价值的影响


<details>
  <summary>Details</summary>
Motivation: 当接收者偏离贝叶斯更新时，发送者通过分阶段揭示信息可能获益或受损，需要理解这种动态的影响机制

Method: 使用可分割更新规则(Cripps, 2018)和Grether(1980)的α-β规则，分析两步说服方案下的发送者价值变化

Result: 在可分割更新规则下，延迟信息提供不影响发送者事前价值；在α-β规则下，推导出发送者在两步方案中严格更好或更差的条件

Conclusion: 接收者的非贝叶斯更新行为显著影响多步说服策略的效果，需要根据具体更新规则设计最优信息揭示时序

Abstract: We study a multi-step persuasion problem involving a Bayesian sender and a
non-Bayesian receiver. When the receiver deviates from Bayesian updating, the
sender may benefit from -- or be harmed by -- gradually revealing information
over time. We show that under divisible updating rules (Cripps, 2018), delaying
information provision does not affect the sender's ex-ante value. Focusing on
the $\alpha$--$\beta$ rule of Grether (1980), we derive the necessary and
sufficient conditions under which the sender is strictly better or worse off
under a two-step persuasion scheme.

</details>


### [358] [When is it (im)possible to respect all individuals' preferences under uncertainty?](https://arxiv.org/abs/2508.12542)
*Kensei Nakamura*

Main category: econ.TH

TL;DR: 主观期望效用偏好聚合时，帕累托原则会导致不可能性结果，除非个体有共同信念。本文通过分析一类能表示渐进模糊感知的不完全偏好聚合，揭示了这种不可能性的根源。


<details>
  <summary>Details</summary>
Motivation: 研究帕累托原则在主观期望效用偏好聚合中导致不可能性结果的根本原因，特别是当个体具有模糊感知时的聚合问题。

Method: 分析一类能表示渐进模糊感知的不完全偏好的聚合特性，考察规划者如何避免忽视某些个体的偏好。

Result: 结果显示，除非存在所有个体都同意的最可信概率分布，否则规划者无法避免忽视某些个体的偏好。即使个体有相似的模糊感知，只要某些个体的最可信信念与他人略有不同，不可能性就会持续存在。

Conclusion: 主观期望效用偏好聚合中的不可能性源于个体间最可信信念的微小差异，即使模糊感知相似，这种差异也足以导致帕累托原则下的聚合困难。

Abstract: When aggregating Subjective Expected Utility preferences, the Pareto
principle leads to an impossibility result unless the individuals have a common
belief. This paper examines the source of this impossibility in more detail by
considering the aggregation of a general class of incomplete preferences that
can represent gradual ambiguity perceptions. Our result shows that the planner
cannot avoid ignoring some individuals unless there is a probability
distribution that all individuals agree is most plausible. This means that even
if individuals have similar ambiguity perceptions, the impossibility persists
as long as some individual's most plausible belief differs even slightly from
those of others.

</details>


### [359] [Contest success functions with luck](https://arxiv.org/abs/2508.12934)
*Hao Yu*

Main category: econ.TH

TL;DR: 本文为带有运气成分的竞赛成功函数（CSF）提供了公理化框架，扩展了Tullock CSF的经典公理化，并与带有平局的CSF研究相连接。


<details>
  <summary>Details</summary>
Motivation: 现有的竞赛成功函数研究需要更系统的公理化基础，特别是在包含运气因素的情况下，需要建立统一的数学框架来理解和分析不同参数规格的CSF。

Method: 采用公理化方法，提出核心公理——齐次相对外部性，该公理限制了一个参赛者努力对其他参赛者概率分配的相对外部性具有尺度不变性。

Result: 建立了带有运气成分的CSF的完整公理体系，证明了该体系能够扩展Tullock CSF的经典公理化，并与带有平局的CSF研究建立联系。

Conclusion: 提出的齐次相对外部性公理为CSF提供了有力的数学基础，使得在不同参数设定下都能保持理论一致性，为竞赛理论的研究提供了更严谨的分析工具。

Abstract: The contest success function (CSF) is a mapping from contestants' efforts to
the probabilistic allocation. An axiomatization of the CSFs with luck is
provided. It extends the classic axiomatization of Tullock CSF and connects to
works of CSF with draws. The central axiom is homogeneous relative externality,
which restricts the relative externality from one contestant's effort to
others' probabilistic allocation to be scale-invariant. More specifications on
parameters are also discussed.

</details>
