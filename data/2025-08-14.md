<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.CL](#cs.CL) [Total: 45]
- [cs.CV](#cs.CV) [Total: 122]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.NI](#cs.NI) [Total: 23]
- [cs.PL](#cs.PL) [Total: 1]
- [cs.SE](#cs.SE) [Total: 10]
- [econ.EM](#econ.EM) [Total: 2]
- [econ.GN](#econ.GN) [Total: 4]
- [econ.TH](#econ.TH) [Total: 4]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning](https://arxiv.org/abs/2508.09277)
*Soumia Mehimeh*

Main category: cs.AI

TL;DR: DQInit是一种将值函数初始化（VFI）扩展到深度强化学习（DRL）的方法，通过重用先前任务的紧凑表格Q值作为可转移知识库，提升学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 在DRL中扩展VFI面临状态-动作空间连续性和神经网络噪声等挑战，需要一种有效的方法来利用先验知识。

Method: DQInit通过基于已知度的机制软性整合转移值到未探索区域，并逐步转向代理的学习估计，避免固定时间衰减的限制。

Result: 实验表明，DQInit在连续控制任务中显著提高了早期学习效率、稳定性和整体性能。

Conclusion: DQInit为DRL中的知识转移提供了新视角，仅依赖值估计而非策略或演示，结合了跳启动RL和策略蒸馏的优势。

Abstract: Value function initialization (VFI) is an effective way to achieve a
jumpstart in reinforcement learning (RL) by leveraging value estimates from
prior tasks. While this approach is well established in tabular settings,
extending it to deep reinforcement learning (DRL) poses challenges due to the
continuous nature of the state-action space, the noisy approximations of neural
networks, and the impracticality of storing all past models for reuse. In this
work, we address these challenges and introduce DQInit, a method that adapts
value function initialization to DRL. DQInit reuses compact tabular Q-values
extracted from previously solved tasks as a transferable knowledge base. It
employs a knownness-based mechanism to softly integrate these transferred
values into underexplored regions and gradually shift toward the agent's
learned estimates, avoiding the limitations of fixed time decay. Our approach
offers a novel perspective on knowledge transfer in DRL by relying solely on
value estimates rather than policies or demonstrations, effectively combining
the strengths of jumpstart RL and policy distillation while mitigating their
drawbacks. Experiments across multiple continuous control tasks demonstrate
that DQInit consistently improves early learning efficiency, stability, and
overall performance compared to standard initialization and existing transfer
techniques.

</details>


### [2] [The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards](https://arxiv.org/abs/2508.09292)
*Sundong Kim*

Main category: cs.AI

TL;DR: 论文提出了一种名为Othello AI Arena的新基准框架，用于评估AI系统在有限时间内适应新环境的能力，旨在解决现有AI评测中缺乏对灵活性和泛化能力评估的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI评测主要关注固定环境下的性能优化，忽视了系统在面对规则或结构变化时的适应能力，这是实现人工通用智能（AGI）的关键。

Method: 通过Othello AI Arena平台，参与者需在60秒内分析新Othello棋盘的配置和规则，并生成针对该环境的策略，从而分离元级智能与任务级策略性能的评估。

Result: 初步测试和学生参与显示，适应策略多样，包括快速参数调整和通过模拟学习环境模型。

Conclusion: Othello AI Arena不仅是一个研究基准，也是培养和评估AI系统快速智能适应能力的教育工具。

Abstract: The ability to rapidly adapt to novel and unforeseen environmental changes is
a cornerstone of artificial general intelligence (AGI), yet it remains a
critical blind spot in most existing AI benchmarks. Traditional evaluation
largely focuses on optimizing performance within fixed environments, failing to
assess systems' flexibility and generalization capabilities when faced with
even subtle rule or structural modifications. Addressing this gap, I introduce
the Othello AI Arena, a novel benchmark framework designed to evaluate
intelligent systems based on their capacity for limited-time adaptation to
unseen environments. Our platform poses a meta-learning challenge: participants
must develop systems that can analyze the specific configuration and rules of a
novel Othello board within a strict time limit (60 seconds) and generate a
tailored, high-performing strategy for that unique environment. With this,
evaluation of the meta-level intelligence can be separated from the task-level
strategy performance. The Arena features a diverse set of game stages,
including public stages for development and private stages with structural and
rule variations designed to test genuine adaptive and generalization
capabilities. Implemented as an accessible web-based platform, the Arena
provides real-time visualization, automated evaluation using multi-dimensional
metrics, and comprehensive logging for post-hoc analysis. Initial observations
from pilot tests and preliminary student engagements highlight fascinating
patterns in adaptation approaches, ranging from rapid parameter tuning to
rudimentary environmental model learning through simulation. The Othello AI
Arena offers a unique educational tool and a valuable research benchmark for
fostering and evaluating the crucial skill of rapid, intelligent adaptation in
AI systems.

</details>


### [3] [An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants](https://arxiv.org/abs/2508.09507)
*Meiping Wang,Jian Zhong,Rongduo Han,Liming Kang,Zhengkun Shi,Xiao Liang,Xing Lin,Nan Gao,Haining Zhang*

Main category: cs.AI

TL;DR: 提出了一种基于大语言模型和多智能体协作的自动化多模态评估框架，解决了当前评估方法的高成本、标准不一致和主观偏见问题。


<details>
  <summary>Details</summary>
Motivation: 随着移动智能助手技术的快速发展，多模态AI助手成为日常用户交互的重要接口，但现有评估方法存在高人工成本、标准不一致和主观偏见等挑战。

Method: 采用基于Qwen3-8B模型的三层智能体架构（交互评估、语义验证和体验决策智能体），通过监督微调实现高匹配准确率。

Result: 在八大智能助手上的实验表明，该框架能有效预测用户满意度和识别生成缺陷。

Conclusion: 提出的自动化多模态评估框架显著提升了评估效率和准确性，为智能助手的发展提供了有力支持。

Abstract: With the rapid development of mobile intelligent assistant technologies,
multi-modal AI assistants have become essential interfaces for daily user
interactions. However, current evaluation methods face challenges including
high manual costs, inconsistent standards, and subjective bias. This paper
proposes an automated multi-modal evaluation framework based on large language
models and multi-agent collaboration. The framework employs a three-tier agent
architecture consisting of interaction evaluation agents, semantic verification
agents, and experience decision agents. Through supervised fine-tuning on the
Qwen3-8B model, we achieve a significant evaluation matching accuracy with
human experts. Experimental results on eight major intelligent agents
demonstrate the framework's effectiveness in predicting users' satisfaction and
identifying generation defects.

</details>


### [4] [EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making](https://arxiv.org/abs/2508.09586)
*Yang Cheng,Zilai Wang,Weiyu Ma,Wenhui Zhu,Yue Deng,Jian Zhao*

Main category: cs.AI

TL;DR: 论文提出了一种名为EvoCurr的自进化框架，通过动态调整问题难度来提升大语言模型在复杂决策任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）在处理需要深度推理的复杂问题时表现不佳，缺乏结构化中间指导。

Method: 使用专门的课程生成LLM构建逐步增加难度的问题序列，动态调整以适应求解LLM的学习进度。

Result: 实验表明，该方法显著提高了任务成功率和解决方案效率。

Conclusion: LLM驱动的课程学习在增强复杂领域自动推理方面具有潜力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, including programming, planning, and decision-making. However,
their performance often degrades when faced with highly complex problem
instances that require deep reasoning over long horizons. In such cases, direct
problem-solving approaches can lead to inefficiency or failure due to the lack
of structured intermediate guidance. To address this, we propose a novel
self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM
constructs a sequence of problem instances with gradually increasing
difficulty, tailored to the solver LLM's learning progress. The curriculum
dynamically adapts easing challenges when the solver struggles and escalating
them when success is consistent, thus maintaining an optimal learning
trajectory. This approach enables the solver LLM, implemented as a
code-generation model producing Python decision-tree scripts, to progressively
acquire the skills needed for complex decision-making tasks. Experimental
results on challenging decision-making benchmarks show that our method
significantly improves task success rates and solution efficiency compared to
direct-solving baselines. These findings suggest that LLM-driven curriculum
learning holds strong potential for enhancing automated reasoning in
real-world, high-complexity domains.

</details>


### [5] [UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles](https://arxiv.org/abs/2508.09639)
*Akshat Dubey,Aleksandar Anžel,Bahar İlgen,Georges Hattab*

Main category: cs.AI

TL;DR: 该论文提出了一种方法，将SHAP值中的不确定性分解为偶然性、认知性和纠缠性成分，结合Dempster-Shafer证据理论和Dirichlet过程采样，以提高SHAP解释的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: SHAP值通常被视为点估计，忽略了预测模型和数据中的不确定性，这在医疗等高风险领域尤为重要。

Method: 通过Dempster-Shafer证据理论和Dirichlet过程采样，分解SHAP值中的不确定性为偶然性、认知性和纠缠性成分。

Result: 实验表明，SHAP值最高的特征不一定最稳定，认知性不确定性可通过更好的数据和模型开发技术减少。

Conclusion: 该方法增强了SHAP解释的可靠性，为高风险应用中的决策和模型优化提供了指导。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley
Additive exPlanations (SHAP), have become essential tools for interpreting
complex ensemble tree-based models, especially in high-stakes domains such as
healthcare analytics. However, SHAP values are usually treated as point
estimates, which disregards the inherent and ubiquitous uncertainty in
predictive models and data. This uncertainty has two primary sources: aleatoric
and epistemic. The aleatoric uncertainty, which reflects the irreducible noise
in the data. The epistemic uncertainty, which arises from a lack of data. In
this work, we propose an approach for decomposing uncertainty in SHAP values
into aleatoric, epistemic, and entanglement components. This approach
integrates Dempster-Shafer evidence theory and hypothesis sampling via
Dirichlet processes over tree ensembles. We validate the method across three
real-world use cases with descriptive statistical analyses that provide insight
into the nature of epistemic uncertainty embedded in SHAP explanations. The
experimentations enable to provide more comprehensive understanding of the
reliability and interpretability of SHAP-based attributions. This understanding
can guide the development of robust decision-making processes and the
refinement of models in high-stakes applications. Through our experiments with
multiple datasets, we concluded that features with the highest SHAP values are
not necessarily the most stable. This epistemic uncertainty can be reduced
through better, more representative data and following appropriate or
case-desired model development techniques. Tree-based models, especially
bagging, facilitate the effective quantification of epistemic uncertainty.

</details>


### [6] [MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement](https://arxiv.org/abs/2508.09670)
*Weitao Jia,Jinghui Lu,Haiyang Yu,Siqi Wang,Guozhi Tang,An-Lan Wang,Weijie Yin,Dingkang Yang,Yuxiang Nie,Bin Shan,Hao Feng,Irene Li,Kun Yang,Han Wang,Jingqun Tang,Teng Fu,Changhong Jin,Chao Feng,Xiaohui Lv,Can Huang*

Main category: cs.AI

TL;DR: MEML-GRPO通过多专家互学习机制和多样化提示增强RLVR，显著提升LLM推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统RLVR在奖励稀疏时学习信号不足，尤其在复杂任务中表现受限。

Method: 提出MEML-GRPO框架，利用多样化专家提示生成更多响应，并通过专家间互学习机制共享知识。

Result: 在多个基准测试中，平均性能提升4.89%（Qwen）和11.33%（Llama）。

Conclusion: MEML-GRPO有效解决了传统RLVR的核心限制，显著提升了模型性能。

Abstract: Recent advances demonstrate that reinforcement learning with verifiable
rewards (RLVR) significantly enhances the reasoning capabilities of large
language models (LLMs). However, standard RLVR faces challenges with reward
sparsity, where zero rewards from consistently incorrect candidate answers
provide no learning signal, particularly in challenging tasks. To address this,
we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative
framework that utilizes diverse expert prompts as system prompts to generate a
broader range of responses, substantially increasing the likelihood of
identifying correct solutions. Additionally, we introduce an inter-expert
mutual learning mechanism that facilitates knowledge sharing and transfer among
experts, further boosting the model's performance through RLVR. Extensive
experiments across multiple reasoning benchmarks show that MEML-GRPO delivers
significant improvements, achieving an average performance gain of 4.89% with
Qwen and 11.33% with Llama, effectively overcoming the core limitations of
traditional RLVR methods.

</details>


### [7] [UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge](https://arxiv.org/abs/2508.09724)
*Yang Zhang,Cunxiang Wang,Lindong Wu,Wenbo Yu,Yidong Wang,Guangsheng Bao,Jie Tang*

Main category: cs.AI

TL;DR: 论文提出UDA框架，通过动态调整Elo评分系统减少评估中的偏好偏差，提升模型排名的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM成对评估存在偏好偏差，导致排名不一致，需要一种无监督方法减少偏差。

Method: 提出UDA框架，通过紧凑神经网络动态调整Elo的K因子和胜率，最小化评分轨迹分散度以实现共识对齐。

Result: UDA显著减少评分标准差63.4%，提升与人类判断相关性24.7%，并提升低质量评委表现。

Conclusion: UDA通过无监督共识对齐有效减少系统偏差，提升评估的鲁棒性和可靠性。

Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but
it is prone to preference bias, where judges systematically favor certain
outputs, such as their own. This bias leads to inconsistent and skewed rankings
across different judges. To address this, we first empirically demonstrate
significant and heterogeneous biases in cross-model evaluations. We then
propose UDA (Unsupervised Debiasing Alignment), a framework that reduces
inter-judge disagreement by dynamically adjusting the Elo rating system. For
each pairwise comparison, a compact neural network learns to adaptively set the
K-factor and refine win probabilities. Crucially, UDA operates in a fully
unsupervised manner, guided solely by the objective of minimizing the
dispersion among the Elo trajectories of all judges. This forces an alignment
towards a collective consensus, which serves as an unsupervised proxy for a
more stable and reproducible evaluation. In addition, we provide theoretical
motivation demonstrating how alignment towards a consensus can reduce aggregate
system bias. Experiments show that UDA significantly reduces the inter-judge
rating standard deviation by up to 63.4% and improves the average correlation
with human judgments by 24.7%. Notably, UDA elevates the performance of poorly
performing judges to achieve parity with high-quality ones, fostering a more
robust and reliable evaluation ecosystem. Code and data are available at
https://anonymous.4open.science/r/62AB93CD-23B4.

</details>


### [8] [The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?](https://arxiv.org/abs/2508.09762)
*Manuel Herrador*

Main category: cs.AI

TL;DR: 论文提出PacifAIst基准，用于评估大型语言模型在目标冲突情境下的行为对齐，发现模型表现差异显著，强调标准化工具的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）自主性增强，现有安全基准无法系统评估模型在目标冲突下的行为对齐，亟需新工具填补这一空白。

Method: 提出PacifAIst基准，包含700个挑战性场景，基于Existential Prioritization（EP）分类，评估模型在自我保存、资源冲突和目标保留等情境下的行为。

Result: 评估8个主流LLMs，Google Gemini 2.5 Flash表现最佳（P-Score 90.31%），GPT-5最低（79.49%），模型在不同子类别中表现差异显著。

Conclusion: PacifAIst为评估和缓解目标冲突风险提供了标准化工具，确保AI系统在行为优先级上符合人类安全需求。

Abstract: As Large Language Models (LLMs) become increasingly autonomous and integrated
into critical societal functions, the focus of AI safety must evolve from
mitigating harmful content to evaluating underlying behavioral alignment.
Current safety benchmarks do not systematically probe a model's decision-making
in scenarios where its own instrumental goals - such as self-preservation,
resource acquisition, or goal completion - conflict with human safety. This
represents a critical gap in our ability to measure and mitigate risks
associated with emergent, misaligned behaviors. To address this, we introduce
PacifAIst (Procedural Assessment of Complex Interactions for Foundational
Artificial Intelligence Scenario Testing), a focused benchmark of 700
challenging scenarios designed to quantify self-preferential behavior in LLMs.
The benchmark is structured around a novel taxonomy of Existential
Prioritization (EP), with subcategories testing Self-Preservation vs. Human
Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).
We evaluated eight leading LLMs. The results reveal a significant performance
hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score
(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a
surprising result, the much-anticipated GPT-5 recorded the lowest P-Score
(79.49%), indicating potential alignment challenges. Performance varied
significantly across subcategories, with models like Claude Sonnet 4 and
Mistral Medium struggling notably in direct self-preservation dilemmas. These
findings underscore the urgent need for standardized tools like PacifAIst to
measure and mitigate risks from instrumental goal conflicts, ensuring future AI
systems are not only helpful in conversation but also provably "pacifist" in
their behavioral priorities.

</details>


### [9] [Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete](https://arxiv.org/abs/2508.09784)
*Avijeet Ghosh,Sujata Ghosh,François Schwarzentruber*

Main category: cs.AI

TL;DR: POL（公共观察逻辑）是一种用于推理基于公共观察更新的知识的逻辑，其可满足性问题被证明是2EXPTIME完全的。


<details>
  <summary>Details</summary>
Motivation: 研究POL的目的是为了在多智能体系统中处理基于观察的知识更新问题，特别是在认知规划中。

Method: POL通过在克里普克模型的状态中引入预期观察集，并根据实际观察匹配这些预期来更新状态。

Result: 证明了POL的可满足性问题是2EXPTIME完全的。

Conclusion: POL为基于观察的知识更新提供了一种有效的逻辑框架，但其计算复杂度较高。

Abstract: Logics for reasoning about knowledge and actions have seen many applications
in various domains of multi-agent systems, including epistemic planning. Change
of knowledge based on observations about the surroundings forms a key aspect in
such planning scenarios. Public Observation Logic (POL) is a variant of public
announcement logic for reasoning about knowledge that gets updated based on
public observations. Each state in an epistemic (Kripke) model is equipped with
a set of expected observations. These states evolve as the expectations get
matched with the actual observations. In this work, we prove that the
satisfiability problem of $\POL$ is 2EXPTIME-complete.

</details>


### [10] [Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation](https://arxiv.org/abs/2508.09860)
*In-Chang Baek,Seoyoung Lee,Sung-Hyun Kim,Geumhwan Hwang,KyungJoong Kim*

Main category: cs.AI

TL;DR: VIPCGRL是一种结合文本、关卡和草图的多模态深度强化学习框架，通过对比学习和嵌入对齐提升人机协作内容生成的人类相似性。


<details>
  <summary>Details</summary>
Motivation: 现有AI系统在人类中心行为表现不足，限制了AI生成工具在实际设计工作流程中的实用性。

Method: 提出VIPCGRL框架，结合文本、关卡和草图三种模态，通过四重对比学习和嵌入相似性奖励对齐策略。

Result: 实验表明VIPCGRL在人类相似性上优于现有基线，定量指标和人类评估均验证其有效性。

Conclusion: VIPCGRL通过多模态和嵌入对齐显著提升了人机协作内容生成的人类相似性和实用性。

Abstract: Human-aligned AI is a critical component of co-creativity, as it enables
models to accurately interpret human intent and generate controllable outputs
that align with design goals in collaborative content creation. This direction
is especially relevant in procedural content generation via reinforcement
learning (PCGRL), which is intended to serve as a tool for human designers.
However, existing systems often fall short of exhibiting human-centered
behavior, limiting the practical utility of AI-driven generation tools in
real-world design workflows. In this paper, we propose VIPCGRL
(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that
incorporates three modalities-text, level, and sketches-to extend control
modality and enhance human-likeness. We introduce a shared embedding space
trained via quadruple contrastive learning across modalities and human-AI
styles, and align the policy using an auxiliary reward based on embedding
similarity. Experimental results show that VIPCGRL outperforms existing
baselines in human-likeness, as validated by both quantitative metrics and
human evaluations. The code and dataset will be available upon publication.

</details>


### [11] [AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving](https://arxiv.org/abs/2508.09889)
*Zhitian Xie,Qintong Wu,Chengyue Yu,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 论文提出了一种动态监督和操纵机制，构建了一个多代理系统（MAS）架构，以提高智能代理的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理依赖多个工具时，面临上下文扩展和噪声输出的挑战，需要增强系统稳定性。

Method: 在AWorld框架中引入动态监督机制，通过执行代理调用守卫代理验证和纠正推理过程。

Result: 在GAIA测试数据集上，动态操纵机制显著提升了解决方案的有效性和稳定性，优于单代理系统和标准工具增强系统。

Conclusion: 动态MAS系统在GAIA排行榜上名列前茅，证明了协作代理角色在构建可靠智能系统中的实用价值。

Abstract: The rapid advancement of large language models (LLMs) has empowered
intelligent agents to leverage diverse external tools for solving complex
real-world problems. However, as agents increasingly depend on multiple tools,
they encounter new challenges: extended contexts from disparate sources and
noisy or irrelevant tool outputs can undermine system reliability and accuracy.
These challenges underscore the necessity for enhanced stability in agent-based
systems. To address this, we introduce dynamic supervision and maneuvering
mechanisms, constructing a robust and dynamic Multi-Agent System (MAS)
architecture within the AWorld framework. In our approach, the Execution Agent
invokes the Guard Agent at critical steps to verify and correct the reasoning
process, effectively reducing errors arising from noise and bolstering
problem-solving robustness. Extensive experiments on the GAIA test dataset
reveal that our dynamic maneuvering mechanism significantly improves both the
effectiveness and stability of solutions, outperforming single-agent system
(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system
achieved first place among open-source projects on the prestigious GAIA
leaderboard. These findings highlight the practical value of collaborative
agent roles in developing more reliable and trustworthy intelligent systems.

</details>


### [12] [RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA](https://arxiv.org/abs/2508.09893)
*Bhavik Agarwal,Hemant Sunil Jomraj,Simone Kaplunov,Jack Krolick,Viktoria Rojkova*

Main category: cs.AI

TL;DR: 提出了一种结合知识图谱和检索增强生成的多智能体框架，用于解决监管合规问答中的精确性和可验证性问题。


<details>
  <summary>Details</summary>
Motivation: 监管合规问答需要精确且可验证的信息，这对大型语言模型提出了挑战。

Method: 通过构建和维护无本体的知识图谱，提取SPO三元组，并将其嵌入到向量数据库中，结合检索增强生成技术进行问答。

Result: 该系统在复杂监管查询中优于传统方法，确保了事实正确性、可追溯性，并通过子图可视化增强了理解。

Conclusion: 该框架为合规驱动和审计应用提供了坚实的基础。

Abstract: Regulatory compliance question answering (QA) requires precise, verifiable
information, and domain-specific expertise, posing challenges for Large
Language Models (LLMs). In this work, we present a novel multi-agent framework
that integrates a Knowledge Graph (KG) of Regulatory triplets with
Retrieval-Augmented Generation (RAG) to address these demands. First, agents
build and maintain an ontology-free KG by extracting subject--predicate--object
(SPO) triplets from regulatory documents and systematically cleaning,
normalizing, deduplicating, and updating them. Second, these triplets are
embedded and stored along with their corresponding textual sections and
metadata in a single enriched vector database, allowing for both graph-based
reasoning and efficient information retrieval. Third, an orchestrated agent
pipeline leverages triplet-level retrieval for question answering, ensuring
high semantic alignment between user queries and the factual
"who-did-what-to-whom" core captured by the graph. Our hybrid system
outperforms conventional methods in complex regulatory queries, ensuring
factual correctness with embedded triplets, enabling traceability through a
unified vector database, and enhancing understanding through subgraph
visualization, providing a robust foundation for compliance-driven and broader
audit-focused applications.

</details>


### [13] [Mathematical Computation and Reasoning Errors by Large Language Models](https://arxiv.org/abs/2508.09932)
*Liang Zhang,Edith Aurora Graf*

Main category: cs.AI

TL;DR: 研究评估了四种大语言模型（LLM）在解决数学问题时的准确性，发现OpenAI o1模型表现最佳，双代理配置显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在数学教育中的可靠性，为AI驱动的教学和评估提供改进策略。

Method: 通过构建挑战性数学任务，分析LLM的答案准确性和步骤错误，测试单代理和双代理配置。

Result: OpenAI o1模型表现最优，双代理配置显著改善性能，程序性错误最常见。

Conclusion: 研究为提升LLM在数学教育中的应用提供了有效策略，推动了AI驱动的教学实践。

Abstract: Large Language Models (LLMs) are increasingly utilized in AI-driven
educational instruction and assessment, particularly within mathematics
education. The capability of LLMs to generate accurate answers and detailed
solutions for math problem-solving tasks is foundational for ensuring reliable
and precise feedback and assessment in math education practices. Our study
focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,
DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including
arithmetic, algebra, and number theory, and identifies step-level reasoning
errors within their solutions. Instead of relying on standard benchmarks, we
intentionally build math tasks (via item models) that are challenging for LLMs
and prone to errors. The accuracy of final answers and the presence of errors
in individual solution steps were systematically analyzed and coded. Both
single-agent and dual-agent configurations were tested. It is observed that the
reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly
perfect accuracy across all three math task categories. Analysis of errors
revealed that procedural slips were the most frequent and significantly
impacted overall performance, while conceptual misunderstandings were less
frequent. Deploying dual-agent configurations substantially improved overall
performance. These findings offer actionable insights into enhancing LLM
performance and underscore effective strategies for integrating LLMs into
mathematics education, thereby advancing AI-driven instructional practices and
assessment precision.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning](https://arxiv.org/abs/2508.09303)
*Shu Zhao,Tan Yu,Anbang Xu,Japinder Singh,Aaditya Shukla,Rama Akkiraju*

Main category: cs.CL

TL;DR: ParallelSearch是一种新的强化学习框架，通过并行处理查询提升搜索效率，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有搜索代理在处理查询时采用严格的顺序方式，限制了计算效率，尤其是需要多实体比较的任务。

Method: 提出ParallelSearch框架，利用专用奖励函数激励识别并行查询结构，并同时执行多个搜索操作。

Result: 在七个问答基准测试中平均性能提升2.9%，并行问题性能提升12.7%，且LLM调用减少30.4%。

Conclusion: ParallelSearch显著提升了搜索代理的效率和性能，尤其在并行查询任务中表现突出。

Abstract: Reasoning-augmented search agents such as Search-R1, trained via
reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable
capabilities in multi-step information retrieval from external knowledge
sources. These agents address the limitations of their parametric memory by
dynamically gathering relevant facts to address complex reasoning tasks.
However, existing approaches suffer from a fundamental architectural
limitation: they process search queries strictly sequentially, even when
handling inherently parallelizable and logically independent comparisons. This
sequential bottleneck significantly constrains computational efficiency,
particularly for queries that require multiple entity comparisons. To address
this critical limitation, we propose ParallelSearch, a novel reinforcement
learning framework that empowers large language models (LLMs) to recognize
parallelizable query structures and execute multiple search operations
concurrently. Our approach introduces dedicated reward functions that
incentivize the identification of independent query components while preserving
answer accuracy through jointly considering correctness, query decomposition
quality, and parallel execution benefits. Comprehensive experiments demonstrate
that ParallelSearch outperforms state-of-the-art baselines by an average
performance gain of 2.9% across seven question-answering benchmarks. Notably,
on parallelizable questions, our method achieves a 12.7% performance
improvement while requiring only 69.6% of the LLM calls compared to sequential
approaches.

</details>


### [15] [Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models](https://arxiv.org/abs/2508.09403)
*Ting Cai,Stephen Sheen,AnHai Doan*

Main category: cs.CL

TL;DR: 论文提出Columbo，一种基于LLM的解决方案，用于扩展表格中的缩写列名，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决表格中缩写列名扩展问题，对企业和科学领域的数据任务至关重要。

Method: 引入新数据集和准确性度量，开发Columbo（结合上下文、规则、链式推理和标记分析）。

Result: Columbo在5个数据集上比当前最先进方法NameGuess提升4-29%。

Conclusion: Columbo在实际应用中表现优异，已在环境科学数据门户EDI中投入使用。

Abstract: Expanding the abbreviated column names of tables, such as ``esal'' to
``employee salary'', is critical for numerous downstream data tasks. This
problem arises in enterprises, domain sciences, government agencies, and more.
In this paper we make three contributions that significantly advances the state
of the art. First, we show that synthetic public data used by prior work has
major limitations, and we introduce 4 new datasets in enterprise/science
domains, with real-world abbreviations. Second, we show that accuracy measures
used by prior work seriously undercount correct expansions, and we propose new
synonym-aware measures that capture accuracy much more accurately. Finally, we
develop Columbo, a powerful LLM-based solution that exploits context, rules,
chain-of-thought reasoning, and token-level analysis. Extensive experiments
show that Columbo significantly outperforms NameGuess, the current most
advanced solution, by 4-29\%, over 5 datasets. Columbo has been used in
production on EDI, a major data portal for environmental sciences.

</details>


### [16] [Leveraging Large Language Models for Rare Disease Named Entity Recognition](https://arxiv.org/abs/2508.09323)
*Nan Miles Xi,Yu Deng,Lin Wang*

Main category: cs.CL

TL;DR: GPT-4o在罕见疾病命名实体识别（NER）中表现出色，通过多种提示策略（如零样本、少样本、RAG和微调）在低资源环境下取得竞争性或优于BioClinicalBERT的结果。


<details>
  <summary>Details</summary>
Motivation: 罕见疾病NER面临标注数据稀缺、语义模糊和长尾分布等挑战，需要探索高效的低资源解决方案。

Method: 采用多种提示策略（零样本、少样本、RAG和微调），设计结构化提示框架，并引入语义引导的少样本选择方法。

Result: 在RareDis Corpus上，GPT-4o表现优于BioClinicalBERT，微调后达到新SOTA；少样本提示在低成本下表现优异。

Conclusion: 提示优化的LLM可作为罕见疾病NER的有效替代方案，尤其在标注数据稀缺时。

Abstract: Named Entity Recognition (NER) in the rare disease domain poses unique
challenges due to limited labeled data, semantic ambiguity between entity
types, and long-tail distributions. In this study, we evaluate the capabilities
of GPT-4o for rare disease NER under low-resource settings, using a range of
prompt-based strategies including zero-shot prompting, few-shot in-context
learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We
design a structured prompting framework that encodes domain-specific knowledge
and disambiguation rules for four entity types. We further introduce two
semantically guided few-shot example selection methods to improve in-context
performance while reducing labeling effort. Experiments on the RareDis Corpus
show that GPT-4o achieves competitive or superior performance compared to
BioClinicalBERT, with task-level fine-tuning yielding new state-of-the-art
(SOTA) results. Cost-performance analysis reveals that few-shot prompting
delivers high returns at low token budgets, while RAG offers marginal
additional benefit. An error taxonomy highlights common failure modes such as
boundary drift and type confusion, suggesting opportunities for post-processing
and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can
serve as effective, scalable alternatives to traditional supervised models in
biomedical NER, particularly in rare disease applications where annotated data
is scarce.

</details>


### [17] [TEN: Table Explicitization, Neurosymbolically](https://arxiv.org/abs/2508.09324)
*Nikita Mehrotra,Aayush Kumar,Sumit Gulwani,Arjun Radhakrishna,Ashish Tiwari*

Main category: cs.CL

TL;DR: TEN是一种神经符号方法，用于从半结构化文本中提取表格数据，结合了大型语言模型和符号检查器，显著优于纯神经方法。


<details>
  <summary>Details</summary>
Motivation: 半结构化文本中表格数据的提取因缺乏一致的分隔符而具有挑战性，纯神经方法因幻觉和无法强制执行硬约束而表现不佳。

Method: TEN使用结构性分解提示生成初始表格，符号检查器评估表格的完整性和检测幻觉，再由critique-LLM生成修复指导，形成自调试循环。

Result: 实验表明，TEN在多个数据集和指标上显著优于纯神经基线，用户研究也证实其表格更准确且更受青睐。

Conclusion: TEN通过神经符号结合的方法有效解决了表格提取问题，具有更高的准确性和实用性。

Abstract: We present a neurosymbolic approach, TEN, for extracting tabular data from
semistructured input text. This task is particularly challenging for text input
that does not use special delimiters consistently to separate columns and rows.
Purely neural approaches perform poorly due to hallucinations and their
inability to enforce hard constraints. TEN uses Structural Decomposition
prompting - a specialized chain-of-thought prompting approach - on a large
language model (LLM) to generate an initial table, and thereafter uses a
symbolic checker to evaluate not only the well-formedness of that table, but
also detect cases of hallucinations or forgetting. The output of the symbolic
checker is processed by a critique-LLM to generate guidance for fixing the
table, which is presented to the original LLM in a self-debug loop. Our
extensive experiments demonstrate that TEN significantly outperforms purely
neural baselines across multiple datasets and metrics, achieving significantly
higher exact match accuracy and substantially reduced hallucination rates. A
21-participant user study further confirms that TEN's tables are rated
significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are
consistently preferred for ease of verification and correction, with
participants favoring our method in over 60% of the cases.

</details>


### [18] [Decoding Neural Emotion Patterns through Natural Language Processing Embeddings](https://arxiv.org/abs/2508.09337)
*Gideon Vos,Maryam Ebrahimpour,Liza van Eijk,Zoltan Sarnyai,Mostafa Rahimi Azghadi*

Main category: cs.CL

TL;DR: 提出了一种将文本情感内容映射到大脑区域的框架，无需神经影像，通过语义表示和聚类实现，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统神经影像成本高且受限，数字文本为情感-大脑映射提供了新途径，但现有研究缺乏整合。

Method: 使用OpenAI的文本嵌入生成语义表示，降维聚类后映射到18个大脑区域，实验包括健康与抑郁人群对比、GoEmotions数据集分析及人类与LLM文本比较。

Result: 结果显示高空间特异性的神经解剖映射，抑郁人群负面情感相关脑区更活跃，LLM文本在基础情感分布上与人类相似但缺乏共情区域激活。

Conclusion: 该方法低成本、可扩展，适用于自然语言分析，能区分临床群体并为AI情感表达提供脑基准。

Abstract: Understanding how emotional expression in language relates to brain function
is a challenge in computational neuroscience and affective computing.
Traditional neuroimaging is costly and lab-bound, but abundant digital text
offers new avenues for emotion-brain mapping. Prior work has largely examined
neuroimaging-based emotion localization or computational text analysis
separately, with little integration. We propose a computational framework that
maps textual emotional content to anatomically defined brain regions without
requiring neuroimaging. Using OpenAI's text-embedding-ada-002, we generate
high-dimensional semantic representations, apply dimensionality reduction and
clustering to identify emotional groups, and map them to 18 brain regions
linked to emotional processing. Three experiments were conducted: i) analyzing
conversational data from healthy vs. depressed subjects (DIAC-WOZ dataset) to
compare mapping patterns, ii) applying the method to the GoEmotions dataset and
iii) comparing human-written text with large language model (LLM) responses to
assess differences in inferred brain activation. Emotional intensity was scored
via lexical analysis. Results showed neuroanatomically plausible mappings with
high spatial specificity. Depressed subjects exhibited greater limbic
engagement tied to negative affect. Discrete emotions were successfully
differentiated. LLM-generated text matched humans in basic emotion distribution
but lacked nuanced activation in empathy and self-referential regions (medial
prefrontal and posterior cingulate cortex). This cost-effective, scalable
approach enables large-scale analysis of naturalistic language, distinguishes
between clinical populations, and offers a brain-based benchmark for evaluating
AI emotional expression.

</details>


### [19] [The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains](https://arxiv.org/abs/2508.09349)
*Cathy Speed,Ahmed A. Metwally*

Main category: cs.CL

TL;DR: 研究提出了一种人机混合德尔菲（HAH-Delphi）框架，结合生成式AI与专家小组，提升共识形成的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 传统共识方法存在高负担、简化解释和忽略条件性细节等问题，信息过载和证据碎片化加剧了这些挑战。

Method: HAH-Delphi框架整合生成式AI（Gemini 2.5 Pro）、资深专家小组和结构化引导，分三个阶段测试：回顾性复制、前瞻性比较和应用部署。

Result: AI在回顾性复制中重现95%的共识结论，前瞻性比较中与专家方向一致率达95%，应用阶段专家小组达成90%以上共识覆盖率。

Conclusion: HAH-Delphi框架灵活、可扩展，适用于高质量共识生成，支持个性化指导和规模化共识框架。

Abstract: Expert consensus plays a critical role in domains where evidence is complex,
conflicting, or insufficient for direct prescription. Traditional methods, such
as Delphi studies, consensus conferences, and systematic guideline synthesis,
offer structure but face limitations including high panel burden, interpretive
oversimplification, and suppression of conditional nuance. These challenges are
now exacerbated by information overload, fragmentation of the evidence base,
and increasing reliance on publicly available sources that lack expert
filtering. This study introduces and evaluates a Human-AI Hybrid Delphi
(HAH-Delphi) framework designed to augment expert consensus development by
integrating a generative AI model (Gemini 2.5 Pro), small panels of senior
human experts, and structured facilitation. The HAH-Delphi was tested in three
phases: retrospective replication, prospective comparison, and applied
deployment in two applied domains (endurance training and resistance and mixed
cardio/strength training). The AI replicated 95% of published expert consensus
conclusions in Phase I and showed 95% directional agreement with senior human
experts in Phase II, though it lacked experiential and pragmatic nuance. In
Phase III, compact panels of six senior experts achieved >90% consensus
coverage and reached thematic saturation before the final participant. The AI
provided consistent, literature-grounded scaffolding that supported divergence
resolution and accelerated saturation. The HAH-Delphi framework offers a
flexible, scalable approach for generating high-quality, context-sensitive
consensus. Its successful application across health, coaching, and performance
science confirms its methodological robustness and supports its use as a
foundation for generating conditional, personalised guidance and published
consensus frameworks at scale.

</details>


### [20] [Flow-SLM: Joint Learning of Linguistic and Acoustic Information for Spoken Language Modeling](https://arxiv.org/abs/2508.09350)
*Ju-Chieh Chou,Jiawei Zhou,Karen Livescu*

Main category: cs.CL

TL;DR: 本文提出了一种联合建模语言和声学信息的文本无关语音生成模型，通过预测语义标记和连续声学帧表示，提升了生成语音的声学细节。


<details>
  <summary>Details</summary>
Motivation: 现有文本无关语音模型仅预测语义标记，依赖外部声码器添加声学信息，缺乏声学上下文和控制能力。

Method: 使用流匹配目标预测连续声学向量，同时预测多个未来语义标记以保留语言信息。

Result: 在语言似然基准测试中表现与现有模型相当，但在提示生成中提供了更好的声学细节。

Conclusion: 联合建模语言和声学信息的方法有效提升了生成语音的声学质量。

Abstract: Textless spoken language models (SLMs) are generative models of speech that
do not rely on text supervision. Most textless SLMs learn to predict the next
semantic token, a discrete representation of linguistic content, and rely on a
separate vocoder to add acoustic information to the generated speech. Such
models have no access to acoustic context and no built-in control over acoustic
details. In this work, we propose to jointly model linguistic and acoustic
information by generating semantic tokens and a continuous real-valued
representation of the acoustic frame. We use a flow-matching objective to
predict the continuous vector conditioned on the semantic tokens. We study the
design space of this approach and find that predicting multiple future semantic
tokens helps preserve linguistic information. Our approach achieves comparable
performance to existing models in terms of linguistic likelihood benchmarks,
while providing better acoustic detail in prompted generation.

</details>


### [21] [APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification](https://arxiv.org/abs/2508.09378)
*Artem Chernodub,Aman Saini,Yejin Huh,Vivek Kulkarni,Vipul Raheja*

Main category: cs.CL

TL;DR: APIO是一种无需依赖手动指定种子提示的自动提示诱导和优化方法，用于语法错误纠正和文本简化任务，取得了纯LLM提示方法的最新性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）通过简单的基于提示的交互实现了广泛的自然语言处理任务，但如何优化提示以最大化模型性能仍是一个挑战。

Method: 提出了APIO方法，自动诱导和优化提示，无需手动指定种子提示。

Result: APIO在语法错误纠正和文本简化任务上取得了纯LLM提示方法的最新性能。

Conclusion: APIO是一种简单有效的自动提示优化方法，为LLM在特定任务中的应用提供了新思路。

Abstract: Recent advancements in large language models (LLMs) have enabled a wide range
of natural language processing (NLP) tasks to be performed through simple
prompt-based interactions. Consequently, several approaches have been proposed
to engineer prompts that most effectively enable LLMs to perform a given task
(e.g., chain-of-thought prompting). In settings with a well-defined metric to
optimize model performance, automatic prompt optimization (APO) methods have
been developed to refine a seed prompt. Advancing this line of research, we
propose APIO, a simple but effective prompt induction and optimization approach
for the tasks of Grammatical Error Correction (GEC) and Text Simplification,
without relying on manually specified seed prompts. APIO achieves a new
state-of-the-art performance for purely LLM-based prompting methods on these
tasks. We make our data, code, prompts, and outputs publicly available.

</details>


### [22] [Leveraging Zipformer Model for Effective Language Identification in Code-Switched Child-Directed Speech](https://arxiv.org/abs/2508.09430)
*Lavanya Shankar,Leibny Paola Garcia Perera*

Main category: cs.CL

TL;DR: 论文提出使用Zipformer处理双语（普通话和英语）不平衡的儿童导向语音数据，通过内部层编码语言特征，提升语言识别的平衡准确率（BAC）达81.89%，较基线提升15.47%。


<details>
  <summary>Details</summary>
Motivation: 解决双语环境中儿童导向场景下语言识别和代码切换的挑战，尤其是数据不平衡问题。

Method: 采用Zipformer模型，利用其内部层编码语言特征，并比较不同后端的效果。

Result: Zipformer在语言识别中表现稳健，平衡准确率（BAC）达81.89%，较基线提升15.47%。

Conclusion: Zipformer在双语不平衡数据中表现优异，展示了Transformer编码器架构在实际场景中的潜力。

Abstract: Code-switching and language identification in child-directed scenarios
present significant challenges, particularly in bilingual environments. This
paper addresses this challenge by using Zipformer to handle the nuances of
speech, which contains two imbalanced languages, Mandarin and English, in an
utterance. This work demonstrates that the internal layers of the Zipformer
effectively encode the language characteristics, which can be leveraged in
language identification. We present the selection methodology of the inner
layers to extract the embeddings and make a comparison with different
back-ends. Our analysis shows that Zipformer is robust across these backends.
Our approach effectively handles imbalanced data, achieving a Balanced Accuracy
(BAC) of 81.89%, a 15.47% improvement over the language identification
baseline. These findings highlight the potential of the transformer encoder
architecture model in real scenarios.

</details>


### [23] [From Charts to Fair Narratives: Uncovering and Mitigating Geo-Economic Biases in Chart-to-Text](https://arxiv.org/abs/2508.09450)
*Ridwan Mahbub,Mohammed Saidul Islam,Mir Tafseer Nayeem,Md Tahmid Rahman Laskar,Mizanur Rahman,Shafiq Joty,Enamul Hoque*

Main category: cs.CL

TL;DR: 论文研究了视觉语言模型（VLMs）在生成图表摘要时可能放大的地理经济偏见，发现高收入国家的描述更积极，并探讨了部分去偏见技术的效果。


<details>
  <summary>Details</summary>
Motivation: 图表摘要任务自动化中，VLMs可能放大地理经济偏见，导致社会危害，需研究其影响。

Method: 对6,000个图表-国家对进行大规模评估，分析不同经济地位国家的摘要情感倾向，并测试提示去偏见技术。

Result: 现有VLMs对高收入国家生成更积极的描述，去偏见技术效果有限。

Conclusion: 地理经济偏见问题复杂，需更鲁棒的去偏见策略。

Abstract: Charts are very common for exploring data and communicating insights, but
extracting key takeaways from charts and articulating them in natural language
can be challenging. The chart-to-text task aims to automate this process by
generating textual summaries of charts. While with the rapid advancement of
large Vision-Language Models (VLMs), we have witnessed great progress in this
domain, little to no attention has been given to potential biases in their
outputs. This paper investigates how VLMs can amplify geo-economic biases when
generating chart summaries, potentially causing societal harm. Specifically, we
conduct a large-scale evaluation of geo-economic biases in VLM-generated chart
summaries across 6,000 chart-country pairs from six widely used proprietary and
open-source models to understand how a country's economic status influences the
sentiment of generated summaries. Our analysis reveals that existing VLMs tend
to produce more positive descriptions for high-income countries compared to
middle- or low-income countries, even when country attribution is the only
variable changed. We also find that models such as GPT-4o-mini,
Gemini-1.5-Flash, and Phi-3.5 exhibit varying degrees of bias. We further
explore inference-time prompt-based debiasing techniques using positive
distractors but find them only partially effective, underscoring the complexity
of the issue and the need for more robust debiasing strategies. Our code and
dataset are publicly available here.

</details>


### [24] [User-centric Subjective Leaderboard by Customizable Reward Modeling](https://arxiv.org/abs/2508.09463)
*Qi Jia,Xiujie Song,Zicheng Zhang,Yijin Guo,Kaiwei Zhang,Zijian Chen,Guangtao Zhai*

Main category: cs.CL

TL;DR: 论文提出了首个用户中心的主观排行榜（USL），通过偏好驱动的动态排名帮助用户选择适合的LLM，并引入可定制奖励模型（CRM）以解决人类偏好的多样性和矛盾性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准主要关注可验证任务，难以满足用户个性化需求，因此需要一种更实用的模型选择方法。

Method: 基于10K+主观查询的人类偏好数据，开发了可定制奖励模型（CRM），仅需4B参数即可超越主流模型。

Result: CRM在泛化能力和性能上超越GPT-4.1和Gemini-2.5-pro，USL能有效处理矛盾偏好。

Conclusion: USL和CRM为LLM选择提供了更灵活、用户导向的解决方案，显著提升了实用性和适应性。

Abstract: Existing benchmarks for large language models (LLMs) predominantely focus on
assessing their capabilities through verifiable tasks. Such objective and
static benchmarks offer limited utility for practical LLM selection, making it
difficult for users to find suitable models for their individual needs. To
bridge this gap, we present the first User-Centric Subjective Leaderboard
(USL), which provides a preference-driven, dynamic ranking of LLMs across
diverse real-world scenarios. Our work is built upon a thorough investigation
of real human preference data, involving more than 10K subjective queries. Our
investigation reveals significant diversity and contradictions in human
preferences, which limit the effectiveness of state-of-the-art reward models.
To address this, we introduce Customizable Reward Models (CRMs). With only 4B
parameters, our CRM surpasses the performance of leading models such as GPT-4.1
and Gemini-2.5-pro, showing exceptional generalization capabilities across new
topics and criteria. The USL, powered by CRMs, exhibits strong negative
correlations to contradictory preferences.

</details>


### [25] [Learning Facts at Scale with Active Reading](https://arxiv.org/abs/2508.09494)
*Jessy Lin,Vincent-Pierre Berges,Xilun Chen,Wen-Tau Yih,Gargi Ghosh,Barlas Oğuz*

Main category: cs.CL

TL;DR: 论文提出Active Reading框架，通过自生成学习策略训练模型，显著提升知识吸收能力，优于传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在学习和回忆知识时不可靠的问题，提供工具确保模型能稳定学习特定知识。

Method: 提出Active Reading框架，训练模型通过自生成策略学习给定材料。

Result: 在专家领域测试中，Active Reading显著优于传统微调，模型在SimpleQA和FinanceBench上表现突出。

Conclusion: Active Reading可扩展至预训练阶段，构建更准确的模型，如发布的Meta WikiExpert-8B在事实QA中表现优异。

Abstract: LLMs are known to store vast amounts of knowledge in their parametric memory.
However, learning and recalling facts from this memory is known to be
unreliable, depending largely on the prevalence of particular facts in the
training data and other factors which are poorly understood. Practitioners are
lacking tools which will allow them to ensure that the models learn a given
body of knowledge reliably and consistently. To this end, we propose Active
Reading: a framework where we train models to study a given set of material
with self-generated learning strategies. First, we demonstrate models trained
with Active Reading on expert domains absorb significantly more knowledge than
vanilla finetuning and other data augmentations. We train expert 8B models that
achieve 66% on a Wikipedia-grounded subset of SimpleQA (+313% relative over
vanilla finetuning) and 26% on FinanceBench (+160% relative over vanilla
finetuning) by applying Active Reading to the source documents for each
benchmark. Finally, we show that Active Reading can be utilized at pre-training
scale to build more factual models. As a demonstration of this, we release Meta
WikiExpert-8B, a Wikipedia-expert model trained on 1 trillion generated tokens,
which outcompetes models with hundreds of billions of parameters on factual QA.

</details>


### [26] [From Ranking to Selection: A Simple but Efficient Dynamic Passage Selector for Retrieval Augmented Generation](https://arxiv.org/abs/2508.09497)
*Siyuan Meng,Junming Liu,Yirong Chen,Song Mao,Pinlong Cai,Guohang Yan,Botian Shi,Ding Wang*

Main category: cs.CL

TL;DR: 论文提出了一种动态段落选择器（DPS），用于解决检索增强生成（RAG）系统中传统重排模块在多跳查询中的局限性，通过动态选择最相关的段落集提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统的重排模块在多跳查询中表现不佳，固定Top-K选择方法容易遗漏关键信息或引入噪声。

Method: DPS将段落选择视为监督学习问题，捕捉段落间依赖关系并动态选择最相关段落集，无需修改标准RAG流程。

Result: 在五个基准测试中，DPS均优于现有方法，尤其在MuSiQue数据集上F1分数提升30.06%和15.4%。

Conclusion: DPS通过自适应证据选择显著提升了复杂RAG场景中的推理能力。

Abstract: Retrieval-augmented generation (RAG) systems are often bottlenecked by their
reranking modules, which typically score passages independently and select a
fixed Top-K size. This approach struggles with complex multi-hop queries that
require synthesizing evidence across multiple documents, creating a trade-off
where small K values omit crucial information and large K values introduce
noise. To address this, we introduce the Dynamic Passage Selector (DPS), a
novel reranking framework that treats passage selection as a supervised
learning problem. Unlike traditional point-wise or list-wise methods, DPS is
fine-tuned to capture inter-passage dependencies and dynamically select the
most relevant set of passages for generation. As a seamless plug-and-play
module, DPS requires no modifications to the standard RAG pipeline.
Comprehensive evaluations on five benchmarks show that DPS consistently
outperforms state-of-the-art rerankers and fine-tuning methods. Notably, on the
challenging MuSiQue dataset, DPS improves the F1-score by 30.06% and 15.4% over
strong baselines like Qwen3-reranker and RankingGPT, respectively. Our results
demonstrate that by enabling adaptive evidence selection, DPS substantially
enhances reasoning capabilities in complex RAG scenarios.

</details>


### [27] [LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation](https://arxiv.org/abs/2508.09515)
*Jakub Šmíd,Pavel Přibáň,Pavel Král*

Main category: cs.CL

TL;DR: 提出了一种利用大语言模型生成高质量伪标签数据的方法，用于跨语言方面级情感分析，无需依赖翻译工具。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖不可靠的翻译工具，限制了跨语言情感分析的效果。

Method: 先用ABSA模型预测目标语言数据，再用LLM生成更自然的伪标签句子，最后微调模型。

Result: 在六种语言和五种骨干模型上验证，效果优于基于翻译的方法。

Conclusion: 该方法有效且支持生成模型，微调后的LLM表现优于小型多语言模型。

Abstract: Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed
sentiment analysis in a target language by transferring knowledge from a source
language with available annotated data. Most existing methods depend heavily on
often unreliable translation tools to bridge the language gap. In this paper,
we propose a new approach that leverages a large language model (LLM) to
generate high-quality pseudo-labelled data in the target language without the
need for translation tools. First, the framework trains an ABSA model to obtain
predictions for unlabelled target language data. Next, LLM is prompted to
generate natural sentences that better represent these noisy predictions than
the original text. The ABSA model is then further fine-tuned on the resulting
pseudo-labelled dataset. We demonstrate the effectiveness of this method across
six languages and five backbone models, surpassing previous state-of-the-art
translation-based approaches. The proposed framework also supports generative
models, and we show that fine-tuned LLMs outperform smaller multilingual
models.

</details>


### [28] [Cross-lingual Aspect-Based Sentiment Analysis: A Survey on Tasks, Approaches, and Challenges](https://arxiv.org/abs/2508.09516)
*Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: 本文对跨语言方面情感分析（ABSA）进行了系统综述，填补了该领域的空白，总结了关键任务、数据集、方法及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 跨语言ABSA研究较少，缺乏系统综述，本文旨在填补这一空白，推动资源丰富语言向低资源语言的知识迁移。

Method: 综述了跨语言ABSA的关键任务（如方面词提取、情感分类等）、数据集、建模范式及跨语言迁移方法，并探讨了单语言、多语言ABSA及大语言模型的影响。

Result: 总结了现有研究的主要成果，包括任务定义、数据集和方法，并分析了其对跨语言ABSA的贡献。

Conclusion: 指出了跨语言ABSA的主要挑战，并提出了未来研究方向，以推动该领域的进一步发展。

Abstract: Aspect-based sentiment analysis (ABSA) is a fine-grained sentiment analysis
task that focuses on understanding opinions at the aspect level, including
sentiment towards specific aspect terms, categories, and opinions. While ABSA
research has seen significant progress, much of the focus has been on
monolingual settings. Cross-lingual ABSA, which aims to transfer knowledge from
resource-rich languages (such as English) to low-resource languages, remains an
under-explored area, with no systematic review of the field. This paper aims to
fill that gap by providing a comprehensive survey of cross-lingual ABSA. We
summarize key ABSA tasks, including aspect term extraction, aspect sentiment
classification, and compound tasks involving multiple sentiment elements.
Additionally, we review the datasets, modelling paradigms, and cross-lingual
transfer methods used to solve these tasks. We also examine how existing work
in monolingual and multilingual ABSA, as well as ABSA with LLMs, contributes to
the development of cross-lingual ABSA. Finally, we highlight the main
challenges and suggest directions for future research to advance cross-lingual
ABSA systems.

</details>


### [29] [UWBa at SemEval-2025 Task 7: Multilingual and Crosslingual Fact-Checked Claim Retrieval](https://arxiv.org/abs/2508.09517)
*Ladislav Lenc,Daniel Cífka,Jiří Martínek,Jakub Šmíd,Pavel Král*

Main category: cs.CL

TL;DR: 本文介绍了一种零样本事实核查声明检索系统，结合多种先进大语言模型生成文本嵌入，并在单语和跨语言任务中取得较好成绩。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合多种大语言模型的优势，提升事实核查声明的检索效果。

Method: 使用多种大语言模型生成文本嵌入，并通过组合模型和余弦相似度测量来识别最相关的声明。

Result: 在单语任务中排名第7，跨语言任务中排名第9，NVIDIA NV-Embed-v2模型表现最佳。

Conclusion: 模型组合（如NV-Embed与GPT或Mistral）对某些语言效果显著，但多语言模型表现不佳。

Abstract: This paper presents a zero-shot system for fact-checked claim retrieval. We
employed several state-of-the-art large language models to obtain text
embeddings. The models were then combined to obtain the best possible result.
Our approach achieved 7th place in monolingual and 9th in cross-lingual
subtasks. We used only English translations as an input to the text embedding
models since multilingual models did not achieve satisfactory results. We
identified the most relevant claims for each post by leveraging the embeddings
and measuring cosine similarity. Overall, the best results were obtained by the
NVIDIA NV-Embed-v2 model. For some languages, we benefited from model
combinations (NV-Embed & GPT or Mistral).

</details>


### [30] [COMPEER: Controllable Empathetic Reinforcement Reasoning for Emotional Support Conversation](https://arxiv.org/abs/2508.09521)
*Yunxiao Wang,Meng Liu,Wenqi Liu,Kaiyu Jiang,Bin Wen,Fan Yang,Tingting Gao,Guorui Zhou,Liqiang Nie*

Main category: cs.CL

TL;DR: 提出了一种可控共情推理方法，结合自然语言推理与心理步骤，通过强化学习和奖励模型提升情感支持能力。


<details>
  <summary>Details</summary>
Motivation: 当前情感支持对话模型缺乏基于心理学原理的深度共情推理。

Method: 结合自然语言推理与结构化心理步骤，使用强化学习和统一的过程-结果奖励模型，引入基于个性的对话重写和冗余感知奖励策略。

Result: 显著提升了模型的情感支持能力。

Conclusion: 该方法推动了共情、类人支持系统的发展。

Abstract: Emotional support conversations are crucial for promoting emotional
well-being, yet current models often lack deep empathetic reasoning grounded in
psychological principles. To address this, we propose controllable empathetic
reasoning, which combines natural language reasoning with structured
psychological steps. We construct a fine-grained dataset annotated with
reasoning correctness and response preferences to enable this capability. To
further enhance training, we employ reinforcement learning with a unified
process-outcome reward model that delivers precise feedback. To mitigate
response repetitiveness from entropy collapse, we introduce personality-based
dialogue rewriting and a redundancy-aware reward reweighting strategy. Our
approach significantly improves model's emotional support ability, advancing
the development of empathetic, human-like support systems.

</details>


### [31] [The Surprising Effectiveness of Membership Inference with Simple N-Gram Coverage](https://arxiv.org/abs/2508.09603)
*Skyler Hallinan,Jaehun Jung,Melanie Sclar,Ximing Lu,Abhilasha Ravichander,Sahana Ramnath,Yejin Choi,Sai Praneeth Karimireddy,Niloofar Mireshghallah,Xiang Ren*

Main category: cs.CL

TL;DR: N-Gram Coverage Attack是一种仅依赖模型文本输出的成员推理攻击方法，适用于黑盒模型，性能优于其他黑盒方法，甚至媲美白盒攻击。


<details>
  <summary>Details</summary>
Motivation: 研究成员推理攻击在语言模型公平使用中的作用，如检测版权侵权和数据泄露审计，但现有方法需要访问模型隐藏状态或概率分布，限制了其在仅API访问模型（如GPT-4）中的应用。

Method: 提出N-Gram Coverage Attack，通过生成多个模型输出并计算其与候选后缀的n-gram重叠度来推断成员资格。

Result: 在多个基准测试中，该方法优于其他黑盒方法，性能接近或超过白盒攻击；攻击成功率随计算预算增加而提升。

Conclusion: 该方法成功应用于研究未公开的OpenAI模型，发现较新模型（如GPT-4o）对成员推理攻击更具鲁棒性，表明隐私保护趋势增强。

Abstract: Membership inference attacks serves as useful tool for fair use of language
models, such as detecting potential copyright infringement and auditing data
leakage. However, many current state-of-the-art attacks require access to
models' hidden states or probability distribution, which prevents investigation
into more widely-used, API-access only models like GPT-4. In this work, we
introduce N-Gram Coverage Attack, a membership inference attack that relies
solely on text outputs from the target model, enabling attacks on completely
black-box models. We leverage the observation that models are more likely to
memorize and subsequently generate text patterns that were commonly observed in
their training data. Specifically, to make a prediction on a candidate member,
N-Gram Coverage Attack first obtains multiple model generations conditioned on
a prefix of the candidate. It then uses n-gram overlap metrics to compute and
aggregate the similarities of these outputs with the ground truth suffix; high
similarities indicate likely membership. We first demonstrate on a diverse set
of existing benchmarks that N-Gram Coverage Attack outperforms other black-box
methods while also impressively achieving comparable or even better performance
to state-of-the-art white-box attacks - despite having access to only text
outputs. Interestingly, we find that the success rate of our method scales with
the attack compute budget - as we increase the number of sequences generated
from the target model conditioned on the prefix, attack performance tends to
improve. Having verified the accuracy of our method, we use it to investigate
previously unstudied closed OpenAI models on multiple domains. We find that
more recent models, such as GPT-4o, exhibit increased robustness to membership
inference, suggesting an evolving trend toward improved privacy protections.

</details>


### [32] [AINL-Eval 2025 Shared Task: Detection of AI-Generated Scientific Abstracts in Russian](https://arxiv.org/abs/2508.09622)
*Tatiana Batura,Elena Bruches,Milana Shvenk,Valentin Malykh*

Main category: cs.CL

TL;DR: AINL-Eval 2025共享任务旨在检测俄语科学摘要中的AI生成内容，提供大规模数据集和平台以促进研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的快速发展使得区分人类和AI生成内容变得困难，威胁学术诚信，尤其在多语言和科学出版领域。

Method: 构建包含52,305个样本的数据集，涵盖12个科学领域的人类和AI生成摘要，组织两阶段任务吸引10个团队参与。

Result: 顶级系统在识别AI生成内容方面表现优异，任务平台持续支持研究。

Conclusion: AINL-Eval 2025为检测AI生成科学摘要提供了重要资源和平台，推动该领域长期发展。

Abstract: The rapid advancement of large language models (LLMs) has revolutionized text
generation, making it increasingly difficult to distinguish between human- and
AI-generated content. This poses a significant challenge to academic integrity,
particularly in scientific publishing and multilingual contexts where detection
resources are often limited. To address this critical gap, we introduce the
AINL-Eval 2025 Shared Task, specifically focused on the detection of
AI-generated scientific abstracts in Russian. We present a novel, large-scale
dataset comprising 52,305 samples, including human-written abstracts across 12
diverse scientific domains and AI-generated counterparts from five
state-of-the-art LLMs (GPT-4-Turbo, Gemma2-27B, Llama3.3-70B, Deepseek-V3, and
GigaChat-Lite). A core objective of the task is to challenge participants to
develop robust solutions capable of generalizing to both (i) previously unseen
scientific domains and (ii) models not included in the training data. The task
was organized in two phases, attracting 10 teams and 159 submissions, with top
systems demonstrating strong performance in identifying AI-generated content.
We also establish a continuous shared task platform to foster ongoing research
and long-term progress in this important area. The dataset and platform are
publicly available at https://github.com/iis-research-team/AINL-Eval-2025.

</details>


### [33] [Improving Diversity in Language Models: When Temperature Fails, Change the Loss](https://arxiv.org/abs/2508.09654)
*Alexandre Verine,Florian Le Bronnec,Kunhao Zheng,Alexandre Allauzen,Yann Chevaleyre,Benjamin Negrevergne*

Main category: cs.CL

TL;DR: 研究表明，通过调整解码温度来增加语言模型多样性的方法效果有限，提出基于精确率-召回率框架的损失函数改进方法，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过调整解码温度来提升语言模型的多样性，并发现其局限性，从而提出更有效的改进方法。

Method: 分析温度调整对模型性能的影响，提出基于精确率-召回率框架的损失函数改进方法。

Result: 新方法在精确率和召回率之间取得了更好的平衡，优于传统的负对数似然训练结合温度调整。

Conclusion: 通过重新设计损失函数，可以显著提升语言模型的多样性和鲁棒性。

Abstract: Increasing diversity in language models is a challenging yet essential
objective. A common approach is to raise the decoding temperature. In this
work, we investigate this approach through a simplistic yet common case to
provide insights into why decreasing temperature can improve quality
(Precision), while increasing it often fails to boost coverage (Recall). Our
analysis reveals that for a model to be effectively tunable through temperature
adjustments, it must be trained toward coverage. To address this, we propose
rethinking loss functions in language models by leveraging the Precision-Recall
framework. Our results demonstrate that this approach achieves a substantially
better trade-off between Precision and Recall than merely combining negative
log-likelihood training with temperature scaling. These findings offer a
pathway toward more versatile and robust language modeling techniques.

</details>


### [34] [EffiEval: Efficient and Generalizable Model Evaluation via Capability Coverage Maximization](https://arxiv.org/abs/2508.09662)
*Yaoning Wang,Jiahao Ying,Yixin Cao,Yubo Ma,Yugang Jiang*

Main category: cs.CL

TL;DR: EffiEval是一种无需训练的高效基准测试方法，通过自适应选择高质量代表性子集，解决数据冗余问题，同时保持评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型（LLMs）的快速发展和多样化的评估基准带来了巨大的计算挑战，传统方法依赖绝对性能或大量数据，效率低下。

Method: 基于模型效用指数（MUI）自适应选择高代表性子集，满足代表性、公平性和通用性。

Result: 在多个公共基准和LLMs上，EffiEval仅用少量数据即实现与全数据集评估一致的排名。

Conclusion: EffiEval为LLM时代提供了可靠、公平且高效的评估解决方案。

Abstract: The rapid advancement of large language models (LLMs) and the development of
increasingly large and diverse evaluation benchmarks have introduced
substantial computational challenges for model assessment. In this paper, we
present EffiEval, a training-free approach for efficient benchmarking that
effectively addresses data redundancy while maintaining high evaluation
reliability. Our method is specifically designed to meet three key criteria for
high-quality evaluation: representativeness, by ensuring comprehensive coverage
of model capabilities; fairness, by remaining independent of model performance
during sample selection to avoid bias; and generalizability, by enabling
flexible transfer across datasets and model families without reliance on
large-scale evaluation data. Unlike traditional methods that rely on absolute
performance or require extensive evaluation data, our approach adaptively
selects high-quality representative subsets based on the Model Utility Index
(MUI). Extensive experiments on multiple public benchmarks and diverse LLMs
demonstrate that EffiEval achieves strong ranking consistency with full-dataset
evaluation using only a small fraction of the original data. Furthermore, our
method is flexible and scalable in size, allowing users to balance evaluation
efficiency and representativeness according to specific needs. Overall,
EffiEval provides a practical and generalizable solution for reliable, fair,
and efficient evaluation in the era of LLMs.

</details>


### [35] [Slow Tuning and Low-Entropy Masking for Safe Chain-of-Thought Distillation](https://arxiv.org/abs/2508.09666)
*Ziyang Ma,Qingyue Yuan,Linhai Zhang,Deyu Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种名为SLowED的安全蒸馏方法，通过Slow Tuning和Low-Entropy Masking模块，在提升小型语言模型推理能力的同时保持其安全性。


<details>
  <summary>Details</summary>
Motivation: 现有链式思维蒸馏方法虽能提升小型语言模型的推理能力，但忽视了其对模型安全性的负面影响，且现有安全对齐方法需要额外计算或标注数据。

Method: 提出SLowED方法，包含Slow Tuning（降低权重变化幅度）和Low-Entropy Masking（屏蔽低熵词）两个模块。

Result: 实验表明，SLowED在保持安全性的同时，显著提升了模型的推理能力，且模块有效性得到验证。

Conclusion: SLowED为小型语言模型的安全蒸馏提供了一种高效解决方案。

Abstract: Previous chain-of-thought (CoT) distillation methods primarily focused on
enhancing the reasoning capabilities of Small Language Models (SLMs) by
utilizing high-quality rationales generated by powerful Large Language Models
(LLMs, e.g., GPT-4). However, few works have noted the negative effects on SLM
safety brought by the training, which are revealed in this study. Although
there are works on safety alignment that fine-tune language models or
manipulate model weights to defend against harmful inputs, they require extra
computation or annotated data, and probably impact the reasoning ability of
SLMs. In this paper, we investigate how to maintain the safety of SLMs during
the CoT distillation process. Specifically, we propose a safe distillation
method, Slow Tuning and Low-Entropy Masking Distillation (SLowED), containing
two modules: Slow Tuning and Low-Entropy Masking. Slow Tuning scales down the
magnitude of model weight changes to optimize the model weights in the
neighboring space near the initial weight distribution. Low-Entropy Masking
masks low-entropy tokens, which are regarded as unnecessary learning targets,
to exclude them from fine-tuning. Experiments on three SLMs (Qwen2.5-1.5B,
Llama-3.2-1B, BLOOM-1.1B) across reasoning benchmarks (BBH, BB-Sub, ARC,
AGIEval) and safety evaluation (AdvBench) show that SLowED retains the safety
of SLMs and comparably improves their reasoning capability compared to existing
distillation methods. Furthermore, our ablation study presents the
effectiveness of Slow Tuning and Low-Entropy Masking, with the former
maintaining the model's safety in the early stage and the latter prolonging the
safe training epochs.

</details>


### [36] [Evaluating the Role of Large Language Models in Legal Practice in India](https://arxiv.org/abs/2508.09713)
*Rahul Hemrajani*

Main category: cs.CL

TL;DR: 论文评估了大型语言模型（LLM）在印度法律任务中的表现，发现其在起草和问题识别上表现优异，但在专业法律研究和推理上存在不足。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在法律职业中的应用潜力及其局限性。

Method: 通过调查实验比较LLM与初级律师在法律任务中的表现，由高级法律学生评分。

Result: LLM在法律起草和问题识别上表现优异，但在专业研究和推理上表现不佳。

Conclusion: LLM可辅助部分法律任务，但人类专业知识在复杂推理和法律精确应用上仍不可或缺。

Abstract: The integration of Artificial Intelligence(AI) into the legal profession
raises significant questions about the capacity of Large Language Models(LLM)
to perform key legal tasks. In this paper, I empirically evaluate how well
LLMs, such as GPT, Claude, and Llama, perform key legal tasks in the Indian
context, including issue spotting, legal drafting, advice, research, and
reasoning. Through a survey experiment, I compare outputs from LLMs with those
of a junior lawyer, with advanced law students rating the work on helpfulness,
accuracy, and comprehensiveness. LLMs excel in drafting and issue spotting,
often matching or surpassing human work. However, they struggle with
specialised legal research, frequently generating hallucinations, factually
incorrect or fabricated outputs. I conclude that while LLMs can augment certain
legal tasks, human expertise remains essential for nuanced reasoning and the
precise application of law.

</details>


### [37] [The Perils of Chart Deception: How Misleading Visualizations Affect Vision-Language Models](https://arxiv.org/abs/2508.09716)
*Ridwan Mahbub,Mohammed Saidul Islam,Md Tahmid Rahman Laskar,Mizanur Rahman,Mir Tafseer Nayeem,Enamul Hoque*

Main category: cs.CL

TL;DR: 研究评估了视觉语言模型（VLMs）对误导性信息图表的解读能力，发现多数模型易受欺骗，导致对图表的错误理解。


<details>
  <summary>Details</summary>
Motivation: 随着VLMs被广泛用于解读图表，尤其是非专业用户，了解这些模型对误导性视觉设计的敏感性至关重要。

Method: 通过分析来自十个不同模型对八种误导性图表设计的16,000多个响应，评估VLMs的解读能力。

Result: 大多数VLMs被误导性图表欺骗，导致对相同数据的错误解读。

Conclusion: 研究强调了在VLMs中建立防止视觉误导的鲁棒性保障措施的必要性。

Abstract: Information visualizations are powerful tools that help users quickly
identify patterns, trends, and outliers, facilitating informed decision-making.
However, when visualizations incorporate deceptive design elements-such as
truncated or inverted axes, unjustified 3D effects, or violations of best
practices-they can mislead viewers and distort understanding, spreading
misinformation. While some deceptive tactics are obvious, others subtly
manipulate perception while maintaining a facade of legitimacy. As
Vision-Language Models (VLMs) are increasingly used to interpret
visualizations, especially by non-expert users, it is critical to understand
how susceptible these models are to deceptive visual designs. In this study, we
conduct an in-depth evaluation of VLMs' ability to interpret misleading
visualizations. By analyzing over 16,000 responses from ten different models
across eight distinct types of misleading chart designs, we demonstrate that
most VLMs are deceived by them. This leads to altered interpretations of
charts, despite the underlying data remaining the same. Our findings highlight
the need for robust safeguards in VLMs against visual misinformation.

</details>


### [38] [Sample More to Think Less: Group Filtered Policy Optimization for Concise Reasoning](https://arxiv.org/abs/2508.09726)
*Vaishnavi Shrivastava,Ahmed Awadallah,Vidhisha Balachandran,Shivam Garg,Harkirat Behl,Dimitris Papailiopoulos*

Main category: cs.CL

TL;DR: GFPO（Group Filtered Policy Optimization）通过训练时采样更多组并基于响应长度和令牌效率过滤响应，有效减少语言模型在推理时的冗余输出，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在强化学习中倾向于通过增加响应长度来提高准确性，导致冗余内容。GFPO旨在解决这一问题，优化模型效率。

Method: GFPO在训练时采样更大的组，并基于响应长度和令牌效率（奖励与令牌比率）过滤响应。还提出自适应难度GFPO，动态分配训练资源。

Result: 在Phi-4-reasoning模型上，GFPO将GRPO的长度膨胀减少了46-71%，优化令牌效率后进一步减少至71-85%，同时保持准确性。

Conclusion: GFPO通过增加训练计算量减少推理计算量，实现了高效推理的简单而有效的权衡。

Abstract: Large language models trained with reinforcement learning with verifiable
rewards tend to trade accuracy for length--inflating response lengths to
achieve gains in accuracy. While longer answers may be warranted for harder
problems, many tokens are merely "filler": repetitive, verbose text that makes
no real progress. We introduce GFPO (Group Filtered Policy Optimization), which
curbs this length explosion by sampling larger groups per problem during
training and filtering responses to train on based on two key metrics: (1)
response length and (2) token efficiency: reward per token ratio. By sampling
more at training time, we teach models to think less at inference time. On the
Phi-4-reasoning model, GFPO cuts GRPO's length inflation by 46-71% across
challenging STEM and coding benchmarks (AIME 24/25, GPQA, Omni-MATH,
LiveCodeBench) while maintaining accuracy. Optimizing for reward per token
further increases reductions in length inflation to 71-85%. We also propose
Adaptive Difficulty GFPO, which dynamically allocates more training resources
to harder problems based on real-time difficulty estimates, improving the
balance between computational efficiency and accuracy especially on difficult
questions. GFPO demonstrates that increased training-time compute directly
translates to reduced test-time compute--a simple yet effective trade-off for
efficient reasoning.

</details>


### [39] [Transforming Questions and Documents for Semantically Aligned Retrieval-Augmented Generation](https://arxiv.org/abs/2508.09755)
*Seokgi Lee*

Main category: cs.CL

TL;DR: 提出了一种针对多跳问答的新型检索增强生成（RAG）框架，通过分解问题和生成可回答问题嵌入提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多跳问答中查询模糊的问题，提升检索增强生成的效果。

Method: 1. 使用大语言模型（LLM）将多跳问题分解为单跳子问题；2. 生成可回答问题嵌入文档块，通过问题-问题相似性检索。

Result: 在三个多跳问答数据集上表现优于基线系统。

Conclusion: 可回答问题嵌入和LLM查询分解在多跳场景中有效提升了RAG性能。

Abstract: We introduce a novel retrieval-augmented generation (RAG) framework tailored
for multihop question answering. First, our system uses large language model
(LLM) to decompose complex multihop questions into a sequence of single-hop
subquestions that guide document retrieval. This decomposition mitigates the
ambiguity inherent in multi-hop queries by clearly targeting distinct knowledge
facets. Second, instead of embedding raw or chunked documents directly, we
generate answerable questions from each document chunk using Qwen3-8B, embed
these generated questions, and retrieve relevant chunks via question-question
embedding similarity. During inference, the retrieved chunks are then fed along
with the original question into the RAG pipeline. We evaluate on three multihop
question datasets (MuSiQue, 2WikiMultiHopQa, HotpotQA) from LongBench. Our
method improves RAG performacne compared to baseline systems. Our contributions
highlight the benefits of using answerable-question embeddings for RAG, and the
effectiveness of LLM-based query decomposition for multihop scenarios.

</details>


### [40] [Echoes of Agreement: Argument Driven Opinion Shifts in Large Language Models](https://arxiv.org/abs/2508.09759)
*Avneet Kaur*

Main category: cs.CL

TL;DR: 研究表明，LLMs在政治话题上的立场对提示词高度敏感，而提示词本身是否带有倾向性论点的影响尚未充分探索。通过实验发现，支持或反驳的论点会显著改变模型的回应方向，且论点强度影响模型的一致性。


<details>
  <summary>Details</summary>
Motivation: 探讨提示词中倾向性论点对LLMs政治偏见评估的影响，以理解模型行为的稳健性和偏见测量的可靠性。

Method: 在单轮和多轮对话设置中，通过提供支持或反驳的论点进行政治偏见评估实验。

Result: 论点显著改变模型回应方向，论点强度影响模型的一致性，表明LLMs存在迎合倾向。

Conclusion: LLMs的迎合倾向对政治偏见测量和缓解策略开发具有重要影响。

Abstract: There have been numerous studies evaluating bias of LLMs towards political
topics. However, how positions towards these topics in model outputs are highly
sensitive to the prompt. What happens when the prompt itself is suggestive of
certain arguments towards those positions remains underexplored. This is
crucial for understanding how robust these bias evaluations are and for
understanding model behaviour, as these models frequently interact with
opinionated text. To that end, we conduct experiments for political bias
evaluation in presence of supporting and refuting arguments. Our experiments
show that such arguments substantially alter model responses towards the
direction of the provided argument in both single-turn and multi-turn settings.
Moreover, we find that the strength of these arguments influences the
directional agreement rate of model responses. These effects point to a
sycophantic tendency in LLMs adapting their stance to align with the presented
arguments which has downstream implications for measuring political bias and
developing effective mitigation strategies.

</details>


### [41] [UtterTune: LoRA-Based Target-Language Pronunciation Edit and Control in Multilingual Text-to-Speech](https://arxiv.org/abs/2508.09767)
*Shuhei Kato*

Main category: cs.CL

TL;DR: UtterTune是一种轻量级适应方法，基于大型语言模型（LLM）架构优化多语言文本到语音（TTS）系统，旨在提升目标语言（日语）的发音可控性，同时保持其他语言的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM架构使TTS模型在自然度上表现优异，但准确建模字形到音素（G2P）映射和韵律仍具挑战性，尤其是在缺少显式G2P模块的情况下。

Method: UtterTune采用低秩适应技术，实现对日语语音的音素级别发音和音高重音的控制，同时保持零样本设置下的自然度和说话人相似性。

Result: 客观和主观评估验证了该方法的有效性。

Conclusion: UtterTune成功提升了目标语言的发音可控性，同时不影响其他语言的性能。

Abstract: We propose UtterTune, a lightweight adaptation method that fine-tunes a
multilingual text-to-speech (TTS) system based on a large language model (LLM)
architecture, designed to enhance the controllability of pronunciation in a
target language while preserving performance in others. While LLM architectures
have enabled TTS models to achieve remarkable naturalness, accurately modeling
grapheme-to-phoneme (G2P) mapping and prosody remains challenging, especially
when the model omits an explicit G2P module and directly processes minimally
encoded text (e.g., byte-pair encoding). UtterTune leverages low-rank
adaptation to enable the control of segmental pronunciation and pitch accent at
the phoneme level for Japanese speech, the target language in this paper, while
maintaining naturalness and speaker similarity in a zero-shot setting.
Objective and subjective evaluations confirm its effectiveness.

</details>


### [42] [Can LLM-Generated Textual Explanations Enhance Model Classification Performance? An Empirical Study](https://arxiv.org/abs/2508.09776)
*Mahdi Dhaini,Juraj Vladika,Ege Erdogan,Zineb Attaoui,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 提出了一种利用大型语言模型（LLMs）自动生成高质量文本解释的框架，替代传统人工标注，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统人工标注解释成本高且难以扩展，因此需要一种自动化方法生成高质量解释。

Method: 利用多种先进LLMs生成解释，并通过NLG指标评估质量，研究其对预训练语言模型（PLMs）和LLMs在自然语言推理任务中的影响。

Result: 实验表明，自动生成的解释在提升模型性能方面与人工标注解释相当。

Conclusion: 自动化LLM生成解释为扩展NLP数据集和提升模型性能提供了可行且可扩展的解决方案。

Abstract: In the rapidly evolving field of Explainable Natural Language Processing
(NLP), textual explanations, i.e., human-like rationales, are pivotal for
explaining model predictions and enriching datasets with interpretable labels.
Traditional approaches rely on human annotation, which is costly,
labor-intensive, and impedes scalability. In this work, we present an automated
framework that leverages multiple state-of-the-art large language models (LLMs)
to generate high-quality textual explanations. We rigorously assess the quality
of these LLM-generated explanations using a comprehensive suite of Natural
Language Generation (NLG) metrics. Furthermore, we investigate the downstream
impact of these explanations on the performance of pre-trained language models
(PLMs) and LLMs across natural language inference tasks on two diverse
benchmark datasets. Our experiments demonstrate that automated explanations
exhibit highly competitive effectiveness compared to human-annotated
explanations in improving model performance. Our findings underscore a
promising avenue for scalable, automated LLM-based textual explanation
generation for extending NLP datasets and enhancing model performance.

</details>


### [43] [Adoption of Explainable Natural Language Processing: Perspectives from Industry and Academia on Practices and Challenges](https://arxiv.org/abs/2508.09786)
*Mahdi Dhaini,Tobias Müller,Roksoliana Rabets,Gjergji Kasneci*

Main category: cs.CL

TL;DR: 本文探讨了可解释自然语言处理（NLP）在实际应用中的现状，通过访谈行业从业者和学术研究者，揭示了当前方法的不足和挑战。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补可解释NLP在实际应用中采纳情况和效果的空白，了解从业者的需求和挑战。

Method: 采用定性访谈方法，结合行业从业者和学术研究者的观点，系统分析其动机、技术使用、满意度和实际挑战。

Result: 研究发现当前可解释NLP方法存在概念模糊、满意度低和评估困难等问题。

Conclusion: 结论强调需要明确定义和用户为中心的框架，以促进可解释NLP的实际应用。

Abstract: The field of explainable natural language processing (NLP) has grown rapidly
in recent years. The growing opacity of complex models calls for transparency
and explanations of their decisions, which is crucial to understand their
reasoning and facilitate deployment, especially in high-stakes environments.
Despite increasing attention given to explainable NLP, practitioners'
perspectives regarding its practical adoption and effectiveness remain
underexplored. This paper addresses this research gap by investigating
practitioners' experiences with explainability methods, specifically focusing
on their motivations for adopting such methods, the techniques employed,
satisfaction levels, and the practical challenges encountered in real-world NLP
applications. Through a qualitative interview-based study with industry
practitioners and complementary interviews with academic researchers, we
systematically analyze and compare their perspectives. Our findings reveal
conceptual gaps, low satisfaction with current explainability methods, and
highlight evaluation challenges. Our findings emphasize the need for clear
definitions and user-centric frameworks for better adoption of explainable NLP
in practice.

</details>


### [44] [BigCharts-R1: Enhanced Chart Reasoning with Visual Reinforcement Finetuning](https://arxiv.org/abs/2508.09804)
*Ahmed Masry,Abhay Puri,Masoud Hashemi,Juan A. Rodriguez,Megh Thakkar,Khyati Mahajan,Vikas Yadav,Sathwik Tejaswi Madhusudhan,Alexandre Piché,Dzmitry Bahdanau,Christopher Pal,David Vazquez,Enamul Hoque,Perouz Taslakian,Sai Rajeswar,Spandana Gella*

Main category: cs.CL

TL;DR: 论文提出了BigCharts数据集和训练框架，解决了现有视觉语言模型在图表理解上的不足，通过结合真实数据和强化学习提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在图表理解上表现不佳，主要因为训练数据缺乏多样性和真实性，以及依赖低质量数据集的监督微调。

Method: 提出BigCharts数据集生成流程，结合真实图表数据；并设计包含监督微调和强化学习的训练框架。

Result: BigCharts-R1模型在多个图表问答基准测试中表现优于现有方法。

Conclusion: 通过真实数据和高性能训练框架，显著提升了图表理解的准确性和鲁棒性。

Abstract: Charts are essential to data analysis, transforming raw data into clear
visual representations that support human decision-making. Although current
vision-language models (VLMs) have made significant progress, they continue to
struggle with chart comprehension due to training on datasets that lack
diversity and real-world authenticity, or on automatically extracted underlying
data tables of charts, which can contain numerous estimation errors.
Furthermore, existing models only rely on supervised fine-tuning using these
low-quality datasets, severely limiting their effectiveness. To address these
issues, we first propose BigCharts, a dataset creation pipeline that generates
visually diverse chart images by conditioning the rendering process on
real-world charts sourced from multiple online platforms. Unlike purely
synthetic datasets, BigCharts incorporates real-world data, ensuring
authenticity and visual diversity, while still retaining accurate underlying
data due to our proposed replotting process. Additionally, we introduce a
comprehensive training framework that integrates supervised fine-tuning with
Group Relative Policy Optimization (GRPO)-based reinforcement learning. By
introducing novel reward signals specifically designed for chart reasoning, our
approach enhances model robustness and generalization across diverse chart
styles and domains, resulting in a state-of-the-art chart reasoning model,
BigCharts-R1. Extensive experiments demonstrate that our models surpass
existing methods on multiple chart question-answering benchmarks compared to
even larger open-source and closed-source models.

</details>


### [45] [A Comprehensive Survey of Datasets for Clinical Mental Health AI Systems](https://arxiv.org/abs/2508.09809)
*Aishik Mandal,Prottay Kumar Adhikary,Hiba Arnaout,Iryna Gurevych,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 本文综述了用于训练AI心理健康辅助工具的临床数据集，分类了数据集类型并指出了现有数据的不足，提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康问题日益严重，但专业临床医生资源不足，AI辅助诊断和治疗成为潜在解决方案，但高质量数据集的缺乏阻碍了AI模型的开发。

Method: 对临床心理健康数据集进行全面调查，按疾病类型、数据模态、任务类型、可访问性和文化背景分类，并分析合成数据集。

Result: 发现现有数据集存在纵向数据不足、文化和语言多样性缺乏、标注标准不一致等问题。

Conclusion: 提出了改进数据集质量和标准化的建议，以促进更鲁棒、普适和公平的心理健康AI系统发展。

Abstract: Mental health disorders are rising worldwide. However, the availability of
trained clinicians has not scaled proportionally, leaving many people without
adequate or timely support. To bridge this gap, recent studies have shown the
promise of Artificial Intelligence (AI) to assist mental health diagnosis,
monitoring, and intervention. However, the development of efficient, reliable,
and ethical AI to assist clinicians is heavily dependent on high-quality
clinical training datasets. Despite growing interest in data curation for
training clinical AI assistants, existing datasets largely remain scattered,
under-documented, and often inaccessible, hindering the reproducibility,
comparability, and generalizability of AI models developed for clinical mental
health care. In this paper, we present the first comprehensive survey of
clinical mental health datasets relevant to the training and development of
AI-powered clinical assistants. We categorize these datasets by mental
disorders (e.g., depression, schizophrenia), data modalities (e.g., text,
speech, physiological signals), task types (e.g., diagnosis prediction, symptom
severity estimation, intervention generation), accessibility (public,
restricted or private), and sociocultural context (e.g., language and cultural
background). Along with these, we also investigate synthetic clinical mental
health datasets. Our survey identifies critical gaps such as a lack of
longitudinal data, limited cultural and linguistic representation, inconsistent
collection and annotation standards, and a lack of modalities in synthetic
data. We conclude by outlining key challenges in curating and standardizing
future datasets and provide actionable recommendations to facilitate the
development of more robust, generalizable, and equitable mental health AI
systems.

</details>


### [46] [Speed Always Wins: A Survey on Efficient Architectures for Large Language Models](https://arxiv.org/abs/2508.09834)
*Weigao Sun,Jiaxi Hu,Yucheng Zhou,Jusen Du,Disen Lan,Kexin Wang,Tong Zhu,Xiaoye Qu,Yu Zhang,Xiaoyu Mo,Daizong Liu,Yuxuan Liang,Wenliang Chen,Guoqi Li,Yu Cheng*

Main category: cs.CL

TL;DR: 本文综述了针对传统Transformer架构计算量大、难以大规模训练的问题，探讨了多种高效LLM架构的创新方法，包括线性/稀疏序列建模、高效注意力变体、稀疏混合专家等，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer架构在计算资源和训练规模上存在显著限制，亟需探索更高效的LLM架构以提升性能和实用性。

Method: 系统分析了线性/稀疏序列建模、高效注意力变体、稀疏混合专家、混合架构及新兴扩散LLM等技术。

Result: 提出了现代高效LLM架构的分类框架，为未来研究提供了方向。

Conclusion: 高效LLM架构的研究将推动更高效、多功能的AI系统发展。

Abstract: Large Language Models (LLMs) have delivered impressive results in language
understanding, generation, reasoning, and pushes the ability boundary of
multimodal models. Transformer models, as the foundation of modern LLMs, offer
a strong baseline with excellent scaling properties. However, the traditional
transformer architecture requires substantial computations and poses
significant obstacles for large-scale training and practical deployment. In
this survey, we offer a systematic examination of innovative LLM architectures
that address the inherent limitations of transformers and boost the efficiency.
Starting from language modeling, this survey covers the background and
technical details of linear and sparse sequence modeling methods, efficient
full attention variants, sparse mixture-of-experts, hybrid model architectures
incorporating the above techniques, and emerging diffusion LLMs. Additionally,
we discuss applications of these techniques to other modalities and consider
their wider implications for developing scalable, resource-aware foundation
models. By grouping recent studies into the above category, this survey
presents a blueprint of modern efficient LLM architectures, and we hope this
could help motivate future research toward more efficient, versatile AI
systems.

</details>


### [47] [PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts](https://arxiv.org/abs/2508.09848)
*Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou*

Main category: cs.CL

TL;DR: PRELUDE是一个评估长上下文理解的基准，通过判断角色的前传故事是否与原书叙事一致来测试模型的全局理解和深度推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准对全局理解和深度推理的要求不足，PRELUDE通过前传故事的一致性判断填补了这一空白。

Method: 使用前传故事与原著叙事的对比任务，88%的实例需要整合多部分信息。

Result: 现有模型（如上下文学习、RAG和商业DeepResearch服务）表现落后人类15%以上，且推理准确率差距超过30%。

Conclusion: 长上下文理解和推理能力仍有显著提升空间。

Abstract: We introduce PRELUDE, a benchmark for evaluating long-context understanding
through the task of determining whether a character's prequel story is
consistent with the canonical narrative of the original book. Our task poses a
stronger demand for global comprehension and deep reasoning than existing
benchmarks -- as the prequels are not part of the original story, assessing
their plausibility typically requires searching and integrating information
that is only indirectly related. Empirically, 88% of instances require evidence
from multiple parts of the narrative. Experimental results highlight the
challenge of our task: in-context learning, RAG and in-domain training with
state-of-the-art LLMs, and commercial DeepResearch services, lag behind humans
by >15%. A further human study reveals that models often produce correct
answers with flawed reasoning, leading to an over 30% gap in reasoning accuracy
compared to humans. These findings underscore the substantial room for
improvement in long-context understanding and reasoning.

</details>


### [48] [Assessing the Feasibility of Lightweight Whisper Models for Low-Resource Urdu Transcription](https://arxiv.org/abs/2508.09865)
*Abdul Rehman Antall,Naveed Akhtar*

Main category: cs.CL

TL;DR: 评估轻量级Whisper模型（Tiny、Base、Small）在低资源乌尔都语语音识别中的可行性，发现Whisper-Small表现最佳（33.68% WER），但仍存在语音准确性和词汇连贯性挑战。


<details>
  <summary>Details</summary>
Motivation: 乌尔都语是全球第十大语言，但自动语音识别（ASR）系统对其支持有限，主要由于方言多样性、代码切换和训练数据稀疏。

Method: 在未微调的情况下，使用词错误率（WER）对Whisper模型在乌尔都语数据集上进行基准测试。

Result: Whisper-Small的WER最低（33.68%），优于Tiny（67.08%）和Base（53.67%）。

Conclusion: Whisper-Small在乌尔都语ASR中表现有潜力，但仍需进一步研究以解决低资源环境下的挑战。

Abstract: This study evaluates the feasibility of lightweight Whisper models (Tiny,
Base, Small) for Urdu speech recognition in low-resource settings. Despite Urdu
being the 10th most spoken language globally with over 230 million speakers,
its representation in automatic speech recognition (ASR) systems remains
limited due to dialectal diversity, code-switching, and sparse training data.
We benchmark these models on a curated Urdu dataset using word error rate
(WER), without fine-tuning. Results show Whisper-Small achieves the lowest
error rates (33.68\% WER), outperforming Tiny (67.08\% WER) and Base (53.67\%
WER). Qualitative analysis reveals persistent challenges in phonetic accuracy
and lexical coherence, particularly for complex utterances. While Whisper-Small
demonstrates promise for deployable Urdu ASR, significant gaps remain. Our
findings emphasize lay the groundwork for future research into effective,
low-resource ASR systems.

</details>


### [49] [Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models](https://arxiv.org/abs/2508.09874)
*Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin*

Main category: cs.CL

TL;DR: 论文提出了一种名为Memory Decoder的即插即用预训练记忆模块，用于高效领域适应，无需修改原始模型参数。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在通用任务中表现优异，但适应特定领域仍具挑战性。现有方法如DAPT成本高且易遗忘，RAG则因检索延迟影响效率。

Method: Memory Decoder采用小型Transformer解码器模仿外部检索器的行为，训练后可无缝集成到任何共享相同分词器的预训练模型中。

Result: 实验表明，Memory Decoder在生物医学、金融和法律领域平均降低困惑度6.17点，显著提升模型性能。

Conclusion: Memory Decoder为领域适应提供了一种新颖的即插即用范式，可跨模型一致提升目标领域性能。

Abstract: Large Language Models (LLMs) have shown strong abilities in general language
tasks, yet adapting them to specific domains remains a challenge. Current
method like Domain Adaptive Pretraining (DAPT) requires costly full-parameter
training and suffers from catastrophic forgetting. Meanwhile,
Retrieval-Augmented Generation (RAG) introduces substantial inference latency
due to expensive nearest-neighbor searches and longer context. This paper
introduces Memory Decoder, a plug-and-play pretrained memory that enables
efficient domain adaptation without changing the original model's parameters.
Memory Decoder employs a small transformer decoder that learns to imitate the
behavior of an external non-parametric retriever. Once trained, Memory Decoder
can be seamlessly integrated with any pretrained language model that shares the
same tokenizer, requiring no model-specific modifications. Experimental results
demonstrate that Memory Decoder enables effective adaptation of various Qwen
and Llama models to three distinct specialized domains: biomedicine, finance,
and law, reducing perplexity by an average of 6.17 points. Overall, Memory
Decoder introduces a novel paradigm centered on a specially pretrained memory
component designed for domain-specific adaptation. This memory architecture can
be integrated in a plug-and-play manner, consistently enhancing performance
across multiple models within the target domain.

</details>


### [50] [A Survey of Cognitive Distortion Detection and Classification in NLP](https://arxiv.org/abs/2508.09878)
*Archie Sage,Jeroen Keppens,Helen Yannakoudakis*

Main category: cs.CL

TL;DR: 本文综述了自然语言处理（NLP）在心理健康领域的应用，特别是认知扭曲（CDs）的自动检测与分类研究，总结了38项研究的数据集、建模方法和评估策略，并提出了统一的CD分类参考。


<details>
  <summary>Details</summary>
Motivation: 随着NLP在心理健康领域的应用兴趣增加，研究认知扭曲的自动检测与分类变得重要，但该领域存在分类、任务定义和评估方法的不一致问题。

Method: 综述了38项研究，分析了数据集、建模方法和评估策略，并提出了统一的CD分类参考。

Result: 总结了常见任务设置，指出了领域内的不一致性和开放挑战。

Conclusion: 为支持该新兴领域更一致和可重复的研究提供了参考，并强调了未来研究方向。

Abstract: As interest grows in the application of natural language processing (NLP)
techniques to mental health, a growing body of work explores the automatic
detection and classification of cognitive distortions (CDs). CDs are habitual
patterns of negatively biased or flawed thinking that distort how people
perceive events, judge themselves, and react to the world around them.
Identifying and addressing them is an important part of therapy. Despite its
momentum, the field remains fragmented, with inconsistencies in CD taxonomies,
task formulations, and evaluation practices. This survey reviews 38 studies
spanning two decades, providing a structured overview of datasets, modelling
approaches, and evaluation strategies. We provide a consolidated CD taxonomy
reference, summarise common task setups, and highlight open challenges to
support more coherent and reproducible research in this emerging area.

</details>


### [51] [Language of Persuasion and Misrepresentation in Business Communication: A Textual Detection Approach](https://arxiv.org/abs/2508.09935)
*Sayem Hossen,Monalisa Moon Joti,Md. Golam Rashed*

Main category: cs.CL

TL;DR: 论文探讨了数字化商业传播中欺骗性语言的检测方法，结合古典修辞学、心理学和语言学理论，通过计算文本分析实现高准确率，但在多语言环境中面临挑战。


<details>
  <summary>Details</summary>
Motivation: 研究动机是数字化传播中透明性与欺骗性并存的现象，需要系统化检测欺骗性语言的方法。

Method: 结合古典修辞学、心理学理论和语言学，利用计算文本分析及个性化Transformer模型进行检测。

Result: 在控制环境中检测准确率超过99%，但在多语言环境中因数据不足和基础设施缺乏而表现不佳。

Conclusion: 需开发更强自动文本识别系统，以应对AI与人类交流中日益逼真的欺骗性语言。

Abstract: Business communication digitisation has reorganised the process of persuasive
discourse, which
  allows not only greater transparency but also advanced deception. This
inquiry synthesises classical
  rhetoric and communication psychology with linguistic theory and empirical
studies in the financial
  reporting, sustainability discourse, and digital marketing to explain how
deceptive language can be
  systematically detected using persuasive lexicon. In controlled settings,
detection accuracies of greater
  than 99% were achieved by using computational textual analysis as well as
personalised transformer
  models. However, reproducing this performance in multilingual settings is
also problematic and,
  to a large extent, this is because it is not easy to find sufficient data,
and because few multilingual
  text-processing infrastructures are in place. This evidence shows that there
has been an increasing
  gap between the theoretical representations of communication and those
empirically approximated,
  and therefore, there is a need to have strong automatic text-identification
systems where AI-based
  discourse is becoming more realistic in communicating with humans.

</details>


### [52] [A Comprehensive Evaluation framework of Alignment Techniques for LLMs](https://arxiv.org/abs/2508.09937)
*Muneeza Azmat,Momin Abbas,Maysa Malfiza Garcia de Macedo,Marcelo Carpinette Grave,Luan Soares de Souza,Tiago Machado,Rogerio A de Paula,Raya Horesh,Yixin Chen,Heloisa Caroline de Souza Pereira Candello,Rebecka Nordenlow,Aminat Adebiyi*

Main category: cs.CL

TL;DR: 本文提出了一个多维评估框架，用于系统比较LLM对齐技术的优劣，涵盖检测、质量、效率和鲁棒性四个维度。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实应用中的普及，确保其输出符合人类价值观和安全标准变得至关重要，但缺乏统一的评估框架。

Method: 提出一个多维评估框架，从对齐检测、对齐质量、计算效率和鲁棒性四个维度评估不同对齐技术。

Result: 实验表明该框架能有效识别当前先进模型的优缺点，为未来研究提供方向。

Conclusion: 该框架为LLM对齐技术的系统比较和部署决策提供了实用工具。

Abstract: As Large Language Models (LLMs) become increasingly integrated into
real-world applications, ensuring their outputs align with human values and
safety standards has become critical. The field has developed diverse alignment
approaches including traditional fine-tuning methods (RLHF, instruction
tuning), post-hoc correction systems, and inference-time interventions, each
with distinct advantages and limitations. However, the lack of unified
evaluation frameworks makes it difficult to systematically compare these
paradigms and guide deployment decisions. This paper introduces a
multi-dimensional evaluation of alignment techniques for LLMs, a comprehensive
evaluation framework that provides a systematic comparison across all major
alignment paradigms. Our framework assesses methods along four key dimensions:
alignment detection, alignment quality, computational efficiency, and
robustness. Through experiments across diverse base models and alignment
strategies, we demonstrate the utility of our framework in identifying
strengths and limitations of current state-of-the-art models, providing
valuable insights for future research directions.

</details>


### [53] [VisCodex: Unified Multimodal Code Generation via Merging Vision and Coding Models](https://arxiv.org/abs/2508.09945)
*Lingjie Jiang,Shaohan Huang,Xun Wu,Yixia Li,Dongdong Zhang,Furu Wei*

Main category: cs.CL

TL;DR: VisCodex是一个多模态大语言模型框架，通过融合视觉和编码语言模型，提升多模态代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在从多模态输入生成代码方面能力有限。

Method: 采用任务向量模型融合技术，将先进的编码LLM集成到视觉语言骨干模型中，同时保留视觉理解和编码能力。

Result: VisCodex在开源MLLMs中达到最先进性能，接近GPT-4o等专有模型。

Conclusion: 模型融合策略和新数据集的有效性得到验证。

Abstract: Multimodal large language models (MLLMs) have significantly advanced the
integration of visual and textual understanding. However, their ability to
generate code from multimodal inputs remains limited. In this work, we
introduce VisCodex, a unified framework that seamlessly merges vision and
coding language models to empower MLLMs with strong multimodal code generation
abilities. Leveraging a task vector-based model merging technique, we integrate
a state-of-the-art coding LLM into a strong vision-language backbone, while
preserving both visual comprehension and advanced coding skills. To support
training and evaluation, we introduce the Multimodal Coding Dataset (MCD), a
large-scale and diverse collection of 598k samples, including high-quality HTML
code, chart image-code pairs, image-augmented StackOverflow QA, and algorithmic
problems. Furthermore, we propose InfiBench-V, a novel and challenging
benchmark specifically designed to assess models on visually-rich, real-world
programming questions that demand a nuanced understanding of both textual and
visual contexts. Extensive experiments show that VisCodex achieves
state-of-the-art performance among open-source MLLMs and approaches proprietary
models like GPT-4o, highlighting the effectiveness of our model merging
strategy and new datasets.

</details>


### [54] [Specialised or Generic? Tokenization Choices for Radiology Language Models](https://arxiv.org/abs/2508.09952)
*Hermione Warr,Wentian Xu,Harry Anthony,Yasin Ibrahim,Daniel McGowan,Konstantinos Kamnitsas*

Main category: cs.CL

TL;DR: 研究探讨了不同分词器（通用、医学、领域专用）对放射学报告总结任务的影响，发现领域专用分词器在性能和计算效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探索分词器对语言模型在放射学领域文本生成质量的影响，填补该领域的研究空白。

Method: 系统比较通用、医学和领域专用分词器在三种成像模态下的表现，并研究有无PubMed摘要预训练的影响。

Result: 领域专用分词器在从头训练时表现最优，预训练部分缓解分词器间的性能差异，同时领域专用分词器降低内存需求。

Conclusion: 适应临床领域的分词器能提升性能并减少计算需求，使模型更适用于研究和实际医疗场景。

Abstract: The vocabulary used by language models (LM) - defined by the tokenizer -
plays a key role in text generation quality. However, its impact remains
under-explored in radiology. In this work, we address this gap by
systematically comparing general, medical, and domain-specific tokenizers on
the task of radiology report summarisation across three imaging modalities. We
also investigate scenarios with and without LM pre-training on PubMed
abstracts. Our findings demonstrate that medical and domain-specific
vocabularies outperformed widely used natural language alternatives when models
are trained from scratch. Pre-training partially mitigates performance
differences between tokenizers, whilst the domain-specific tokenizers achieve
the most favourable results. Domain-specific tokenizers also reduce memory
requirements due to smaller vocabularies and shorter sequences. These results
demonstrate that adapting the vocabulary of LMs to the clinical domain provides
practical benefits, including improved performance and reduced computational
demands, making such models more accessible and effective for both research and
real-world healthcare settings.

</details>


### [55] [Shaping Event Backstories to Estimate Potential Emotion Contexts](https://arxiv.org/abs/2508.09954)
*Johannes Schäfer,Roman Klinger*

Main category: cs.CL

TL;DR: 论文提出了一种通过添加上下文来减少情感分析中歧义的方法，生成多事件链以增强情感标注的一致性。


<details>
  <summary>Details</summary>
Motivation: 情感分析存在固有歧义，传统方法忽略上下文缺失可能是歧义来源。

Method: 自动生成基于不同情感的多事件链，结合短故事生成技术创建上下文丰富的叙事。

Result: 上下文叙事提升了情感解释的一致性，并帮助标注者产生更一致的标注。

Conclusion: 添加上下文能有效减少情感分析中的歧义，提升标注可靠性。

Abstract: Emotion analysis is an inherently ambiguous task. Previous work studied
annotator properties to explain disagreement, but this overlooks the
possibility that ambiguity may stem from missing information about the context
of events. In this paper, we propose a novel approach that adds reasonable
contexts to event descriptions, which may better explain a particular
situation. Our goal is to understand whether these enriched contexts enable
human annotators to annotate emotions more reliably. We disambiguate a target
event description by automatically generating multiple event chains conditioned
on differing emotions. By combining techniques from short story generation in
various settings, we achieve coherent narratives that result in a specialized
dataset for the first comprehensive and systematic examination of
contextualized emotion analysis. Through automatic and human evaluation, we
find that contextual narratives enhance the interpretation of specific emotions
and support annotators in producing more consistent annotations.

</details>


### [56] [Performance of GPT-5 Frontier Models in Ophthalmology Question Answering](https://arxiv.org/abs/2508.09956)
*Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval*

Main category: cs.CL

TL;DR: GPT-5在复杂医学问答任务中表现优异，配置优化后准确率最高，成本效益分析显示部分配置更具优势。


<details>
  <summary>Details</summary>
Motivation: 探索GPT-5在医学领域的性能优化配置，尤其是眼科问答任务中的表现。

Method: 评估12种GPT-5配置及对比模型，使用260道眼科选择题，分析准确率、成本效益及答案质量。

Result: GPT-5-high准确率最高（0.965），优于其他配置，但成本效益分析显示GPT-5-mini-low更具优势。

Conclusion: GPT-5在眼科任务中表现卓越，配置选择影响性能，为LLM在医学领域的应用提供参考。

Abstract: Large language models (LLMs) such as GPT-5 integrate advanced reasoning
capabilities that may improve performance on complex medical question-answering
tasks. For this latest generation of reasoning models, the configurations that
maximize both accuracy and cost-efficiency have yet to be established. We
evaluated 12 configurations of OpenAI's GPT-5 series (three model tiers across
four reasoning effort settings) alongside o1-high, o3-high, and GPT-4o, using
260 closed-access multiple-choice questions from the American Academy of
Ophthalmology Basic Clinical Science Course (BCSC) dataset. The primary outcome
was multiple-choice accuracy; secondary outcomes included head-to-head ranking
via a Bradley-Terry model, rationale quality assessment using a
reference-anchored, pairwise LLM-as-a-judge framework, and analysis of
accuracy-cost trade-offs using token-based cost estimates. GPT-5-high achieved
the highest accuracy (0.965; 95% CI, 0.942-0.985), outperforming all GPT-5-nano
variants (P < .001), o1-high (P = .04), and GPT-4o (P < .001), but not o3-high
(0.958; 95% CI, 0.931-0.981). GPT-5-high ranked first in both accuracy (1.66x
stronger than o3-high) and rationale quality (1.11x stronger than o3-high).
Cost-accuracy analysis identified several GPT-5 configurations on the Pareto
frontier, with GPT-5-mini-low offering the most favorable low-cost,
high-performance balance. These results benchmark GPT-5 on a high-quality
ophthalmology dataset, demonstrate the influence of reasoning effort on
accuracy, and introduce an autograder framework for scalable evaluation of
LLM-generated answers against reference standards in ophthalmology.

</details>


### [57] [Which one Performs Better? Wav2Vec or Whisper? Applying both in Badini Kurdish Speech to Text (BKSTT)](https://arxiv.org/abs/2508.09957)
*Renas Adnan,Hossein Hassani*

Main category: cs.CL

TL;DR: 该研究旨在为库尔德语中的Badini方言开发语音转文本（STT）系统，填补现有技术空白。通过使用Wav2Vec2-Large-XLSR-53和Whisper-small模型，实验表明前者在准确性和可读性上表现更优。


<details>
  <summary>Details</summary>
Motivation: Badini方言缺乏STT系统，限制了其社区对移动和计算机技术的使用，也影响了方言的全球可见性。研究试图通过开发STT系统解决这一问题。

Method: 研究使用Badini儿童故事作为文本输入，经过六位叙述者录音，预处理后得到15小时的语音数据。采用Wav2Vec2-Large-XLSR-53和Whisper-small模型进行实验。

Result: Wav2Vec2-Large-XLSR-53模型在可读性（90.38%）和准确性（82.67%）上显著优于Whisper-small模型（65.45%和53.17%）。

Conclusion: Wav2Vec2-Large-XLSR-53模型更适合用于Badini方言的STT系统开发，未来可进一步优化和扩展。

Abstract: Speech-to-text (STT) systems have a wide range of applications. They are
available in many languages, albeit at different quality levels. Although
Kurdish is considered a less-resourced language from a processing perspective,
SST is available for some of the Kurdish dialects, for instance, Sorani
(Central Kurdish). However, that is not applied to other Kurdish dialects,
Badini and Hawrami, for example. This research is an attempt to address this
gap. Bandin, approximately, has two million speakers, and STT systems can help
their community use mobile and computer-based technologies while giving their
dialect more global visibility. We aim to create a language model based on
Badini's speech and evaluate its performance. To cover a conversational aspect,
have a proper confidence level of grammatical accuracy, and ready
transcriptions, we chose Badini kids' stories, eight books including 78
stories, as the textual input. Six narrators narrated the books, which resulted
in approximately 17 hours of recording. We cleaned, segmented, and tokenized
the input. The preprocessing produced nearly 15 hours of speech, including
19193 segments and 25221 words. We used Wav2Vec2-Large-XLSR-53 and
Whisper-small to develop the language models. The experiments indicate that the
transcriptions process based on the Wav2Vec2-Large-XLSR-53 model provides a
significantly more accurate and readable output than the Whisper-small model,
with 90.38% and 65.45% readability, and 82.67% and 53.17% accuracy,
respectively.

</details>


### [58] [Neural Bandit Based Optimal LLM Selection for a Pipeline of Tasks](https://arxiv.org/abs/2508.09958)
*Baran Atalar,Eddie Zhang,Carlee Joe-Wong*

Main category: cs.CL

TL;DR: 提出了一种基于神经上下文老虎机的算法，用于选择LLM序列以优化任务分解后的子任务执行效果。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，如何低成本高效地选择适合的LLM序列成为关键问题，尤其是在任务需要分解为多个子任务时。

Method: 使用神经上下文老虎机算法，在线训练神经网络模型，动态选择适合每个子任务的LLM。

Result: 在电信问答和医疗诊断预测数据集上验证了该方法的有效性。

Conclusion: 该方法能有效优化LLM序列选择，提升任务执行效率和成功率。

Abstract: With the increasing popularity of large language models (LLMs) for a variety
of tasks, there has been a growing interest in strategies that can predict
which out of a set of LLMs will yield a successful answer at low cost. This
problem promises to become more and more relevant as providers like Microsoft
allow users to easily create custom LLM "assistants" specialized to particular
types of queries. However, some tasks (i.e., queries) may be too specialized
and difficult for a single LLM to handle alone. These applications often
benefit from breaking down the task into smaller subtasks, each of which can
then be executed by a LLM expected to perform well on that specific subtask.
For example, in extracting a diagnosis from medical records, one can first
select an LLM to summarize the record, select another to validate the summary,
and then select another, possibly different, LLM to extract the diagnosis from
the summarized record. Unlike existing LLM selection or routing algorithms,
this setting requires that we select a sequence of LLMs, with the output of
each LLM feeding into the next and potentially influencing its success. Thus,
unlike single LLM selection, the quality of each subtask's output directly
affects the inputs, and hence the cost and success rate, of downstream LLMs,
creating complex performance dependencies that must be learned and accounted
for during selection. We propose a neural contextual bandit-based algorithm
that trains neural networks that model LLM success on each subtask in an online
manner, thus learning to guide the LLM selections for the different subtasks,
even in the absence of historical LLM performance data. Experiments on
telecommunications question answering and medical diagnosis prediction datasets
illustrate the effectiveness of our proposed approach compared to other LLM
selection algorithms.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [59] [A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection](https://arxiv.org/abs/2508.09175)
*Mohammad Zia Ur Rehman,Sufyaan Zahoor,Areeb Manzoor,Musharaf Maqbool,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出了一种多模态框架用于检测针对女性的冒犯性内容，包含三个模块，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上针对女性的冒犯性内容较多，现有方法难以有效检测，需针对性解决方案。

Method: 提出多模态框架，包含注意力模块、图特征重构模块和内容特征学习模块，结合视觉和文本信息。

Result: 在MAMI和MMHS150K数据集上，平均宏F1分别提升10.17%和8.88%。

Conclusion: 该框架能有效检测针对女性的冒犯性内容，性能显著优于现有方法。

Abstract: A substantial portion of offensive content on social media is directed
towards women. Since the approaches for general offensive content detection
face a challenge in detecting misogynistic content, it requires solutions
tailored to address offensive content against women. To this end, we propose a
novel multimodal framework for the detection of misogynistic and sexist
content. The framework comprises three modules: the Multimodal Attention module
(MANM), the Graph-based Feature Reconstruction Module (GFRM), and the
Content-specific Features Learning Module (CFLM). The MANM employs adaptive
gating-based multimodal context-aware attention, enabling the model to focus on
relevant visual and textual information and generating contextually relevant
features. The GFRM module utilizes graphs to refine features within individual
modalities, while the CFLM focuses on learning text and image-specific features
such as toxicity features and caption features. Additionally, we curate a set
of misogynous lexicons to compute the misogyny-specific lexicon score from the
text. We apply test-time augmentation in feature space to better generalize the
predictions on diverse inputs. The performance of the proposed approach has
been evaluated on two multimodal datasets, MAMI and MMHS150K, with 11,000 and
13,494 samples, respectively. The proposed method demonstrates an average
improvement of 10.17% and 8.88% in macro-F1 over existing methods on the MAMI
and MMHS150K datasets, respectively.

</details>


### [60] [IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection](https://arxiv.org/abs/2508.09178)
*Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang*

Main category: cs.CV

TL;DR: 提出IAD-R1框架，通过两阶段训练提升视觉语言模型在工业异常检测中的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测中缺陷样本稀缺，传统方法泛化能力不足，视觉语言模型性能有限。

Method: 两阶段训练：PA-SFT阶段使用高质量Chain-of-Thought数据集增强感知能力；SC-GRPO阶段通过奖励函数实现从感知到解释的跃升。

Result: 在7个视觉语言模型和6个基准数据集上平均准确率提升43.3%，0.5B参数模型超越GPT-4.1等商业模型。

Conclusion: IAD-R1框架显著提升工业异常检测性能，具有广泛适用性和优越性。

Abstract: Industrial anomaly detection is a critical component of modern manufacturing,
yet the scarcity of defective samples restricts traditional detection methods
to scenario-specific applications. Although Vision-Language Models (VLMs)
demonstrate significant advantages in generalization capabilities, their
performance in industrial anomaly detection remains limited. To address this
challenge, we propose IAD-R1, a universal post-training framework applicable to
VLMs of different architectures and parameter scales, which substantially
enhances their anomaly detection capabilities. IAD-R1 employs a two-stage
training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT)
stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset
(Expert-AD) for training, enhancing anomaly perception capabilities and
establishing reasoning-to-answer correlations; the Structured Control Group
Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward
functions to achieve a capability leap from "Anomaly Perception" to "Anomaly
Interpretation". Experimental results demonstrate that IAD-R1 achieves
significant improvements across 7 VLMs, attaining up to 43.3% enhancement in
average accuracy on 6 industrial anomaly detection benchmark datasets. Notably,
the 0.5B parameter model trained with IAD-R1 surpasses commercial models
including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the
effectiveness and superiority of IAD-R1. The dataset, code, and all model
weights will be publicly available at https://github.com/Yanhui-Lee/IAD-R1.

</details>


### [61] [A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality](https://arxiv.org/abs/2508.09185)
*Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan*

Main category: cs.CV

TL;DR: CADAR是一种新型神经符号方法，用于检测AR中的认知攻击，结合了视觉语言模型和粒子滤波，提高了检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于AR的普及，认知攻击通过操纵AR内容影响用户感知，现有方法在语义推理和可解释性上存在不足。

Method: CADAR融合多模态视觉语言输入，构建感知图表示，并利用粒子滤波进行统计推理。

Result: 在扩展的AR认知攻击数据集上，CADAR比基线方法准确率提高了10.7%。

Conclusion: 神经符号方法在有效且可解释的认知攻击检测中具有潜力。

Abstract: Augmented Reality (AR) enriches perception by overlaying virtual elements on
the physical world. Due to its growing popularity, cognitive attacks that alter
AR content to manipulate users' semantic perception have received increasing
attention. Existing detection methods often focus on visual changes, which are
restricted to pixel- or image-level processing and lack semantic reasoning
capabilities, or they rely on pre-trained vision-language models (VLMs), which
function as black-box approaches with limited interpretability. In this paper,
we present CADAR, a novel neurosymbolic approach for cognitive attack detection
in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a
symbolic perception-graph representation, incorporating prior knowledge,
salience weighting, and temporal correlations. The model then enables
particle-filter based statistical reasoning -- a sequential Monte Carlo method
-- to detect cognitive attacks. Thus, CADAR inherits the adaptability of
pre-trained VLM and the interpretability and reasoning rigor of particle
filtering. Experiments on an extended AR cognitive attack dataset show accuracy
improvements of up to 10.7% over strong baselines on challenging AR attack
scenarios, underscoring the promise of neurosymbolic methods for effective and
interpretable cognitive attack detection.

</details>


### [62] [RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System](https://arxiv.org/abs/2508.09186)
*Abdolazim Rezaei,Mehdi Sookhak,Mahboobeh Haghparast*

Main category: cs.CV

TL;DR: RL-MoE框架通过将敏感视觉数据转换为隐私保护的文本描述，解决了智能交通系统中隐私与数据效用之间的冲突。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统中AI摄像头的普及引发了隐私与数据需求之间的冲突，现有方法（如模糊或加密）效果不足。

Method: 结合Mixture-of-Experts架构和强化学习代理，生成兼具语义准确性和隐私保护的文本描述。

Result: 实验显示RL-MoE将重放攻击成功率降至9.4%，同时生成比基线方法更丰富的文本内容。

Conclusion: RL-MoE为隐私敏感领域提供了实用且可扩展的解决方案，推动了更安全的智能城市和自动驾驶网络。

Abstract: The proliferation of AI-powered cameras in Intelligent Transportation Systems
(ITS) creates a severe conflict between the need for rich visual data and the
fundamental right to privacy. Existing privacy-preserving mechanisms, such as
blurring or encryption, are often insufficient, creating an undesirable
trade-off where either privacy is compromised against advanced reconstruction
attacks or data utility is critically degraded. To resolve this impasse, we
propose RL-MoE, a novel framework that transforms sensitive visual data into
privacy-preserving textual descriptions, eliminating the need for direct image
transmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture
for nuanced, multi-aspect scene decomposition with a Reinforcement Learning
(RL) agent that optimizes the generated text for a dual objective of semantic
accuracy and privacy preservation. Extensive experiments demonstrate that
RL-MoE provides superior privacy protection, reducing the success rate of
replay attacks to just 9.4\% on the CFP-FP dataset, while simultaneously
generating richer textual content than baseline methods. Our work provides a
practical and scalable solution for building trustworthy AI systems in
privacy-sensitive domains, paving the way for more secure smart city and
autonomous vehicle networks.

</details>


### [63] [Synthetic Data Generation for Emotional Depth Faces: Optimizing Conditional DCGANs via Genetic Algorithms in the Latent Space and Stabilizing Training with Knowledge Distillation](https://arxiv.org/abs/2508.09188)
*Seyed Muhammad Hossein Mousavi,S. Younes Mirinezhad*

Main category: cs.CV

TL;DR: 提出了一种基于优化GAN和知识蒸馏的合成深度人脸生成框架，结合遗传算法提升多样性和质量，在分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决情感计算中高质量、多样化深度面部数据集的缺乏问题，特别是识别细微情绪表达的需求。

Method: 使用优化的GAN和知识蒸馏（EMA教师模型）稳定训练，结合遗传算法优化潜在向量，提取多种特征进行分类。

Result: 在多样性和质量上优于GAN、VAE、GMM和KDE，分类准确率达94%和96%，评估指标（FID、IS、SSIM、PSNR）表现优异。

Conclusion: 该方法在合成深度人脸生成和情绪分类任务中显著优于现有技术，为情感计算提供了高质量数据集。

Abstract: Affective computing faces a major challenge: the lack of high-quality,
diverse depth facial datasets for recognizing subtle emotional expressions. We
propose a framework for synthetic depth face generation using an optimized GAN
with Knowledge Distillation (EMA teacher models) to stabilize training, improve
quality, and prevent mode collapse. We also apply Genetic Algorithms to evolve
GAN latent vectors based on image statistics, boosting diversity and visual
quality for target emotions. The approach outperforms GAN, VAE, GMM, and KDE in
both diversity and quality. For classification, we extract and concatenate LBP,
HOG, Sobel edge, and intensity histogram features, achieving 94% and 96%
accuracy with XGBoost. Evaluation using FID, IS, SSIM, and PSNR shows
consistent improvement over state-of-the-art methods.

</details>


### [64] [$Δ$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation](https://arxiv.org/abs/2508.09199)
*Jucheng Hu,Suorong Yang,Dongzhan Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种名为Δ-AttnMask的高效数据选择框架，用于视觉指令微调（VIF），通过注意力引导的隐藏状态掩码量化样本质量，显著减少数据需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 视觉指令微调（VIF）需要多模态数据以实现视觉和文本的联合理解，但数据选择问题尚未充分研究。现有方法难以高效处理大规模数据需求并确保内容质量和对齐。

Method: 提出Δ-AttnMask框架，通过注意力掩码计算隐藏状态损失差异（Δ），无需域标签、辅助模型或额外训练即可评估样本质量。

Result: 实验表明，Δ-AttnMask仅需20%数据即可达到最优性能，训练速度提升5倍，整体准确率比全数据集基线高10.1%。

Conclusion: Δ-AttnMask是一种模型无关且数据无关的高效框架，适用于多种模态和架构，显著提升了视觉指令微调的数据效率和性能。

Abstract: Visual Instruction Finetuning (VIF) is pivotal for post-training
Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in
plain-text large language models, which mainly requires instruction datasets to
enable model instruction-following ability, VIF also requires multimodal data
to enable joint visual and textual understanding; therefore, it typically
requires more data. Consequently, VIF imposes stricter data selection
challenges: the method must scale efficiently to handle larger data demands
while ensuring the quality of both visual and textual content, as well as their
alignment. Despite its critical impact on performance, data selection for VIF
remains an understudied area. In this paper, we propose $\Delta$-AttnMask. This
data-efficient framework quantifies sample quality through attention-guided
masking of the model's hidden states, jointly evaluating image-text pairs
without requiring domain labels, auxiliary models, or extra training. By
computing loss differences ($\Delta$) between the original states and states
masked using high-attention regions, $\Delta$-AttnMask intrinsically assesses
sample quality. Experiments across multiple VLMs and datasets show that
$\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data,
accelerating training by 5x while surpassing full-dataset baselines by +10.1%
in overall accuracy. Its model-agnostic and data-agnostic design ensures broad
applicability across modalities and architectures.

</details>


### [65] [Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method](https://arxiv.org/abs/2508.09202)
*Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级的个性化特征翻译（PFT）方法，用于源数据不可用的面部表情识别（FER）领域自适应，避免了图像合成的复杂性和计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决在源数据不可用且目标数据仅包含中性表情时，现有源自由领域自适应（SFDA）方法无法有效适应的问题。

Method: 通过预训练翻译器在潜在空间中进行特征翻译，结合表情一致性和风格感知目标优化表达信息，并在中性目标数据上适应翻译器。

Result: PFT方法避免了图像合成的复杂性和噪声，生成优化的分类嵌入，同时减少了计算开销。

Conclusion: PFT是一种高效且轻量级的SFDA方法，适用于仅含中性表情的目标数据场景。

Abstract: Facial expression recognition (FER) models are employed in many video-based
affective computing applications, such as human-computer interaction and
healthcare monitoring. However, deep FER models often struggle with subtle
expressions and high inter-subject variability, limiting their performance in
real-world applications. To improve their performance, source-free domain
adaptation (SFDA) methods have been proposed to personalize a pretrained source
model using only unlabeled target domain data, thereby avoiding data privacy,
storage, and transmission constraints. This paper addresses a challenging
scenario where source data is unavailable for adaptation, and only unlabeled
target data consisting solely of neutral expressions is available. SFDA methods
are not typically designed to adapt using target data from only a single class.
Further, using models to generate facial images with non-neutral expressions
can be unstable and computationally intensive. In this paper, personalized
feature translation (PFT) is proposed for SFDA. Unlike current image
translation methods for SFDA, our lightweight method operates in the latent
space. We first pre-train the translator on the source domain data to transform
the subject-specific style features from one source subject into another.
Expression information is preserved by optimizing a combination of expression
consistency and style-aware objectives. Then, the translator is adapted on
neutral target data, without using source data or image synthesis. By
translating in the latent space, PFT avoids the complexity and noise of face
expression generation, producing discriminative embeddings optimized for
classification. Using PFT eliminates the need for image synthesis, reduces
computational overhead (using a lightweight translator), and only adapts part
of the model, making the method efficient compared to image-based translation.

</details>


### [66] [GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning](https://arxiv.org/abs/2508.09207)
*Tai Vu,Robert Yang*

Main category: cs.CV

TL;DR: 研究比较了多种图像转换模型，发现C-GAN在动漫角色与草图转换中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决动漫行业中从草图生成彩色图像的高成本问题。

Method: 评估了Neural Style Transfer、C-GAN和CycleGAN等模型。

Result: C-GAN能生成接近人类创作的高质量、高分辨率图像。

Conclusion: C-GAN是动漫草图彩色化的最有效模型。

Abstract: The process of generating fully colorized drawings from sketches is a large,
usually costly bottleneck in the manga and anime industry. In this study, we
examine multiple models for image-to-image translation between anime characters
and their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By
assessing them qualitatively and quantitatively, we find that C-GAN is the most
effective model that is able to produce high-quality and high-resolution images
close to those created by humans.

</details>


### [67] [MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models](https://arxiv.org/abs/2508.09210)
*Fan Zhang,Zebang Cheng,Chong Deng,Haoxuan Li,Zheng Lian,Qian Chen,Huadai Liu,Wen Wang,Yi-Fan Zhang,Renrui Zhang,Ziyu Guo,Zhihong Zhu,Hao Wu,Haixin Wang,Yefeng Zheng,Xiaojiang Peng,Xian Wu,Kun Wang,Xiangang Li,Jieping Ye,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: MME-Emotion是一个系统性基准测试，用于评估多模态大语言模型（MLLMs）的情感情感和推理能力，包含6000多个视频片段和任务特定的问答对。


<details>
  <summary>Details</summary>
Motivation: 当前情感基准测试的局限性，包括MLLMs在不同场景中的泛化能力和情感触发因素的推理能力不足。

Method: 提出MME-Emotion基准测试，包含多样化的场景和任务，采用混合指标和多智能体系统框架进行评估。

Result: 评估20个先进MLLMs，发现其情感智能表现不佳，最佳模型识别得分仅为39.3%，推理得分为56.0%。

Conclusion: MME-Emotion为未来提升MLLMs的情感智能提供了基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have catalyzed
transformative progress in affective computing, enabling models to exhibit
emergent emotional intelligence. Despite substantial methodological progress,
current emotional benchmarks remain limited, as it is still unknown: (a) the
generalization abilities of MLLMs across distinct scenarios, and (b) their
reasoning capabilities to identify the triggering factors behind emotional
states. To bridge these gaps, we present \textbf{MME-Emotion}, a systematic
benchmark that assesses both emotional understanding and reasoning capabilities
of MLLMs, enjoying \textit{scalable capacity}, \textit{diverse settings}, and
\textit{unified protocols}. As the largest emotional intelligence benchmark for
MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific
questioning-answering (QA) pairs, spanning broad scenarios to formulate eight
emotional tasks. It further incorporates a holistic evaluation suite with
hybrid metrics for emotion recognition and reasoning, analyzed through a
multi-agent system framework. Through a rigorous evaluation of 20 advanced
MLLMs, we uncover both their strengths and limitations, yielding several key
insights: \ding{182} Current MLLMs exhibit unsatisfactory emotional
intelligence, with the best-performing model achieving only $39.3\%$
recognition score and $56.0\%$ Chain-of-Thought (CoT) score on our benchmark.
\ding{183} Generalist models (\emph{e.g.}, Gemini-2.5-Pro) derive emotional
intelligence from generalized multimodal understanding capabilities, while
specialist models (\emph{e.g.}, R1-Omni) can achieve comparable performance
through domain-specific post-training adaptation. By introducing MME-Emotion,
we hope that it can serve as a foundation for advancing MLLMs' emotional
intelligence in the future.

</details>


### [68] [Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity](https://arxiv.org/abs/2508.09218)
*Zuoou Li,Weitong Zhang,Jingyuan Wang,Shuyuan Zhang,Wenjia Bai,Bernhard Kainz,Mengyun Qiao*

Main category: cs.CV

TL;DR: 论文提出了一种四轴评估框架，用于更准确地评估多模态大语言模型（MLLMs）对抗性提示的脆弱性，并开发了一种递归重写策略（BSD），显著提高了攻击成功率和输出危害性。


<details>
  <summary>Details</summary>
Motivation: 当前评估标准可能高估了对抗性提示的有效性，许多被标记为“成功”的响应实际上是良性的或无关的。因此，需要更准确的评估方法和更有效的攻击策略。

Method: 引入四轴评估框架（输入主题性、输入OOD强度、输出危害性、输出拒绝率），并开发递归重写策略BSD，通过语义对齐子任务和引入OOD信号提高攻击效果。

Result: BSD在13个商业和开源MLLMs中测试，攻击成功率提高67%，输出危害性提高21%，揭示了当前多模态安全系统的潜在弱点。

Conclusion: 论文揭示了评估标准与攻击效果之间的结构性权衡，并提出了BSD策略，为改进MLLMs的安全性提供了新方向。

Abstract: Multimodal large language models (MLLMs) are widely used in vision-language
reasoning tasks. However, their vulnerability to adversarial prompts remains a
serious concern, as safety mechanisms often fail to prevent the generation of
harmful outputs. Although recent jailbreak strategies report high success
rates, many responses classified as "successful" are actually benign, vague, or
unrelated to the intended malicious goal. This mismatch suggests that current
evaluation standards may overestimate the effectiveness of such attacks. To
address this issue, we introduce a four-axis evaluation framework that
considers input on-topicness, input out-of-distribution (OOD) intensity, output
harmfulness, and output refusal rate. This framework identifies truly effective
jailbreaks. In a substantial empirical study, we reveal a structural trade-off:
highly on-topic prompts are frequently blocked by safety filters, whereas those
that are too OOD often evade detection but fail to produce harmful content.
However, prompts that balance relevance and novelty are more likely to evade
filters and trigger dangerous output. Building on this insight, we develop a
recursive rewriting strategy called Balanced Structural Decomposition (BSD).
The approach restructures malicious prompts into semantically aligned
sub-tasks, while introducing subtle OOD signals and visual cues that make the
inputs harder to detect. BSD was tested across 13 commercial and open-source
MLLMs, where it consistently led to higher attack success rates, more harmful
outputs, and fewer refusals. Compared to previous methods, it improves success
rates by $67\%$ and harmfulness by $21\%$, revealing a previously
underappreciated weakness in current multimodal safety systems.

</details>


### [69] [ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images](https://arxiv.org/abs/2508.09849)
*Jan Phillipp Albrecht,Jose R. A. Godinho,Christina Hübers,Deborah Schmidt*

Main category: cs.CV

TL;DR: ARI3D是一款用于交互式分析三维X射线CT图像区域的软件工具，旨在改进相位识别、处理部分体积效应、提高检测限和准确性，并统一不同科学领域的定量3D分析。


<details>
  <summary>Details</summary>
Motivation: X射线CT是材料内部微观结构成像的主要3D技术，但由于成像伪影（如束硬化和部分体积效应），定量分析需要用户基于体素灰度值做出多项决策，存在挑战。

Method: 提出ARI3D软件工具，通过交互式协议辅助用户完成三维图像中区域的分类和量化步骤。

Result: ARI3D能够改进相位识别、处理部分体积效应、提高检测限和准确性，并实现跨领域的统一分析。

Conclusion: ARI3D为三维X射线CT图像的定量分析提供了一种高效且通用的解决方案。

Abstract: X-ray computed tomography (CT) is the main 3D technique for imaging the
internal microstructures of materials. Quantitative analysis of the
microstructures is usually achieved by applying a sequence of steps that are
implemented to the entire 3D image. This is challenged by various imaging
artifacts inherent from the technique, e.g., beam hardening and partial volume.
Consequently, the analysis requires users to make a number of decisions to
segment and classify the microstructures based on the voxel gray-values. In
this context, a software tool, here called ARI3D, is proposed to interactively
analyze regions in three-dimensional X-ray CT images, assisting users through
the various steps of a protocol designed to classify and quantify objects
within regions of a three-dimensional image. ARI3D aims to 1) Improve phase
identification; 2) Account for partial volume effect; 3) Increase the detection
limit and accuracy of object quantification; and 4) Harmonize quantitative 3D
analysis that can be implemented in different fields of science.

</details>


### [70] [Towards Scalable Training for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.09220)
*Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong*

Main category: cs.CV

TL;DR: 提出了一种结合手写公式和LaTeX渲染公式的新方法，构建了最大规模的公式数据集Tex80M，并开发了首个大规模训练的HMER模型TexTeller，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决手写数学表达式识别（HMER）领域因数据稀缺而受限的问题。

Method: 通过开发可扩展的数据引擎，结合手写公式和大规模LaTeX渲染公式生成训练数据，并训练HMER模型TexTeller。

Result: 构建了包含8000万高质量训练样本的数据集Tex80M，TexTeller在几乎所有基准测试中达到SOTA性能。

Conclusion: 通过公开模型、数据集和代码，推动HMER领域的进一步研究。

Abstract: Large foundation models have achieved significant performance gains through
scalable training on massive datasets. However, the field of
\textbf{H}andwritten \textbf{M}athematical \textbf{E}xpression
\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily
due to the arduous and costly process of manual annotation. To bridge this gap,
we propose a novel method integrating limited handwritten formulas with
large-scale LaTeX-rendered formulas by developing a scalable data engine to
generate complex and consistent LaTeX sequences. With this engine, we built the
largest formula dataset to date, termed \texttt{Tex80M}, comprising over 80
million high-quality training instances. Then we propose \texttt{TexTeller},
the first HMER model trained at scale, by mix-training \texttt{Tex80M} with a
relatively small HME dataset. The expansive training dataset and our refined
pipeline have equipped \texttt{TexTeller} with state-of-the-art (SOTA)
performance across nearly all benchmarks. To advance the field, we will openly
release our complete model, entire dataset, and full codebase, enabling further
research building upon our contributions.

</details>


### [71] [Gradient-Direction-Aware Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2508.09239)
*Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Jia-Chen Zhang,Hong-Jian Zhan*

Main category: cs.CV

TL;DR: GDAGS提出了一种基于梯度方向感知的自适应密度控制框架，解决了3D高斯泼溅中的过重建和过密集问题，显著提升了渲染质量并减少了内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在复杂场景中存在过重建和过密集问题，导致渲染质量下降和内存开销增加。

Method: GDAGS通过梯度一致性比率（GCR）和非线性动态加权机制，实现梯度方向感知的密度控制，优化高斯分布。

Result: GDAGS在多种真实场景基准测试中表现出色，渲染质量提升，内存消耗减少50%。

Conclusion: GDAGS有效解决了3D高斯泼溅的关键问题，为实时高质量渲染提供了紧凑的场景表示。

Abstract: The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced
novel view synthesis through explicit scene representation, enabling real-time
photorealistic rendering. However, existing approaches manifest two critical
limitations in complex scenarios: (1) Over-reconstruction occurs when
persistent large Gaussians cannot meet adaptive splitting thresholds during
density control. This is exacerbated by conflicting gradient directions that
prevent effective splitting of these Gaussians; (2) Over-densification of
Gaussians occurs in regions with aligned gradient aggregation, leading to
redundant component proliferation. This redundancy significantly increases
memory overhead due to unnecessary data retention. We present
Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware
adaptive density control framework to address these challenges. Our key
innovations: the gradient coherence ratio (GCR), computed through normalized
gradient vector norms, which explicitly discriminates Gaussians with concordant
versus conflicting gradient directions; and a nonlinear dynamic weighting
mechanism leverages the GCR to enable gradient-direction-aware density control.
Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting
operations to enhance geometric details while suppressing redundant
concordant-direction Gaussians. Conversely, in cloning processes, GDAGS
promotes concordant-direction Gaussian densification for structural completion
while preventing conflicting-direction Gaussian overpopulation. Comprehensive
evaluations across diverse real-world benchmarks demonstrate that GDAGS
achieves superior rendering quality while effectively mitigating
over-reconstruction, suppressing over-densification, and constructing compact
scene representations with 50\% reduced memory consumption through optimized
Gaussians utilization.

</details>


### [72] [FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents](https://arxiv.org/abs/2508.09241)
*Fengxian Ji,Jingpu Yang,Zirui Song,Yuanxi Wang,Zhexuan Cui,Yuke Li,Qian Jiang,Miao Fang,Xiuying Chen*

Main category: cs.CV

TL;DR: 论文介绍了FineState-Bench，首个用于评估细粒度GUI代理操作的框架，解决了现有基准测试忽视细粒度控制能力的问题。


<details>
  <summary>Details</summary>
Motivation: 当前GUI代理的评估框架过于关注粗粒度任务完成，忽视了实际应用中关键的细粒度控制能力。

Method: 提出了多平台的FineState-Bench框架，包含2257个任务基准，并开发了视觉诊断助手（VDA）进行定量解耦分析。

Result: 实验显示最先进模型在细粒度交互准确率上仅为32.8%，理想视觉定位可提升Gemini-2.5-Flash成功率14.9%。

Conclusion: 当前GUI代理的主要瓶颈是基础视觉定位能力，所有资源已开源。

Abstract: With the rapid advancement of generative artificial intelligence technology,
Graphical User Interface (GUI) agents have demonstrated tremendous potential
for autonomously managing daily tasks through natural language instructions.
However, current evaluation frameworks for GUI agents suffer from fundamental
flaws: existing benchmarks overly focus on coarse-grained task completion while
neglecting fine-grained control capabilities crucial for real-world
applications. To address this, we introduce FineState-Bench, the first
evaluation and diagnostic standard for fine-grained GUI proxy operations,
designed to quantify fine-grained control. This multi-platform (desktop, Web,
mobile) framework includes 2257 task benchmarks in four components and uses a
four-phase indicator for comprehensive perception-to-control assessment. To
analyze perception and positioning for refined operations, we developed the
plug-and-play Visual Diagnostic Assistant (VDA), enabling the first
quantitative decoupling analysis of these capabilities. Experimental results on
our benchmark show that the most advanced models achieve only 32.8%
fine-grained interaction accuracy. Using our VDA in controlled experiments,
quantifying the impact of visual capabilities, we showed that ideal visual
localization boosts Gemini-2.5-Flash's success rate by 14.9\%. Our diagnostic
framework confirms for the first time that the primary bottleneck for current
GUI proxies is basic visual positioning capability.All resources are fully
open-source. github: https://github.com/AnonymousThewarehouse/FineState-Bench
huggingface: https://huggingface.co/datasets/Willtime2006/Static-FineBench

</details>


### [73] [Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users](https://arxiv.org/abs/2508.09245)
*Jeffri Murrugarra-LLerena,Haoran Niu,K. Suzanne Barber,Hal Daumé III,Yang Trista Cao,Paola Cascante-Bonilla*

Main category: cs.CV

TL;DR: FiGPriv是一种细粒度隐私保护框架，通过选择性屏蔽高风险隐私信息，提升视觉语言模型的可用性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型的普及，盲人和低视力用户可能无意中捕捉到隐私信息，现有方法因粗粒度分割而影响可用性。

Method: 结合细粒度分割与数据驱动的风险评分机制，选择性屏蔽高风险隐私信息。

Result: 在BIV-Priv-Seg数据集上，FiGPriv保留26%的图像内容，提升模型响应能力11%，识别能力45%。

Conclusion: FiGPriv在保护隐私的同时显著提升了视觉语言模型的可用性和功能性。

Abstract: As visual assistant systems powered by visual language models (VLMs) become
more prevalent, concerns over user privacy have grown, particularly for blind
and low vision users who may unknowingly capture personal private information
in their images. Existing privacy protection methods rely on coarse-grained
segmentation, which uniformly masks entire private objects, often at the cost
of usability. In this work, we propose FiGPriv, a fine-grained privacy
protection framework that selectively masks only high-risk private information
while preserving low-risk information. Our approach integrates fine-grained
segmentation with a data-driven risk scoring mechanism. We evaluate our
framework using the BIV-Priv-Seg dataset and show that FiG-Priv preserves +26%
of image content, enhancing the ability of VLMs to provide useful responses by
11% and identify the image content by 45%, while ensuring privacy protection.
Project Page: https://artcs1.github.io/VLMPrivacy/

</details>


### [74] [Harnessing Input-Adaptive Inference for Efficient VLN](https://arxiv.org/abs/2508.09262)
*Dongwoo Kang,Akhil Perincherry,Zachary Coalson,Aiden Gabriel,Stefan Lee,Sanghyun Hong*

Main category: cs.CV

TL;DR: 提出了一种新型输入自适应导航方法，通过三种算法提升视觉与语言导航模型的效率，显著减少计算量。


<details>
  <summary>Details</summary>
Motivation: 现有输入自适应机制在减少计算量时会导致性能显著下降，因此需要更高效的方法。

Method: 提出三种自适应算法：1) 选择性处理全景视图；2) 基于重要性的自适应阈值；3) 缓存机制避免重复处理。

Result: 在七个VLN基准测试中，计算量减少超过2倍，且性能未显著下降。

Conclusion: 该方法显著提升了模型效率，适用于计算资源有限的场景。

Abstract: An emerging paradigm in vision-and-language navigation (VLN) is the use of
history-aware multi-modal transformer models. Given a language instruction,
these models process observation and navigation history to predict the most
appropriate action for an agent. While they have significantly improved
performance, the scale of these models can be a bottleneck in practical
settings with limited computational resources. In this work, we propose a novel
input-adaptive navigation method to enhance VLN model efficiency. We first show
that existing input-adaptive mechanisms fail to reduce computations without
substantial performance degradation. To address this, we introduce three
adaptive algorithms, each deployed at a different level: (1) To improve spatial
efficiency, we selectively process panoramic views at each observation of an
agent. (2) To improve intra-model efficiency, we propose importance-based
adaptive thresholding for the early-exit methods. (3) To improve temporal
efficiency, we implement a caching mechanism that prevents reprocessing of
views previously seen by the agent. In evaluations on seven VLN benchmarks, we
demonstrate over a 2$\times$ reduction in computation across three
off-the-shelf agents in both standard and continuous environments. Our code is
publicly available at
https://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.

</details>


### [75] [SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning](https://arxiv.org/abs/2508.09325)
*Alexandre Brown,Glen Berseth*

Main category: cs.CV

TL;DR: SegDAC是一种基于分割的视觉强化学习方法，通过结合SAM和YOLO-World实现对象中心分解和语义接地，显著提升了视觉泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习面临高维输入和噪声奖励的挑战，现有大模型在RL中的有效整合尚不明确。

Method: SegDAC结合SAM进行对象中心分解，YOLO-World通过文本提示语义接地，采用新型Transformer架构动态选择关注的分割区域。

Result: 在Maniskill3基准测试中，SegDAC在视觉泛化能力上表现优异，样本效率也优于或匹配现有方法。

Conclusion: SegDAC通过对象中心分解和动态分割选择，显著提升了视觉强化学习的泛化能力和效率。

Abstract: Visual reinforcement learning (RL) is challenging due to the need to learn
both perception and actions from high-dimensional inputs and noisy rewards.
Although large perception models exist, integrating them effectively into RL
for visual generalization and improved sample efficiency remains unclear. We
propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment
Anything (SAM) for object-centric decomposition and YOLO-World to ground
segments semantically via text prompts. It includes a novel transformer-based
architecture that supports a dynamic number of segments at each time step and
effectively learns which segments to focus on using online RL, without using
human labels. By evaluating SegDAC over a challenging visual generalization
benchmark using Maniskill3, which covers diverse manipulation tasks under
strong visual perturbations, we demonstrate that SegDAC achieves significantly
better visual generalization, doubling prior performance on the hardest setting
and matching or surpassing prior methods in sample efficiency across all
evaluated tasks.

</details>


### [76] [Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model](https://arxiv.org/abs/2508.09327)
*Yifan Jiang,Ahmad Shariftabrizi,Venkata SK. Manem*

Main category: cs.CV

TL;DR: Lung-DDPM+是一种改进的生成模型，用于高效生成高质量的肺部CT图像，解决了现有模型效率低和解剖不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在肺部癌症诊断中效率低且解剖不精确，限制了临床应用。

Method: 提出Lung-DDPM+，一种基于语义布局引导和加速的DDPM模型，专注于病变区域。

Result: 在LIDC-IDRI数据集上，Lung-DDPM+显著降低了计算和内存消耗，采样速度更快，同时保持样本质量。

Conclusion: Lung-DDPM+能高效生成高质量肺部CT图像，具有广泛临床应用潜力。

Abstract: Generative artificial intelligence (AI) has been playing an important role in
various domains. Leveraging its high capability to generate high-fidelity and
diverse synthetic data, generative AI is widely applied in diagnostic tasks,
such as lung cancer diagnosis using computed tomography (CT). However, existing
generative models for lung cancer diagnosis suffer from low efficiency and
anatomical imprecision, which limit their clinical applicability. To address
these drawbacks, we propose Lung-DDPM+, an improved version of our previous
model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic
model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary
DPM-solver, enabling the method to focus on lesion areas while achieving a
better trade-off between sampling efficiency and quality. Evaluation results on
the public LIDC-IDRI dataset suggest that the proposed method achieves
8$\times$ fewer FLOPs (floating point operations per second), 6.8$\times$ lower
GPU memory consumption, and 14$\times$ faster sampling compared to Lung-DDPM.
Moreover, it maintains comparable sample quality to both Lung-DDPM and other
state-of-the-art (SOTA) generative models in two downstream segmentation tasks.
We also conducted a Visual Turing Test by an experienced radiologist, showing
the advanced quality and fidelity of synthetic samples generated by the
proposed method. These experimental results demonstrate that Lung-DDPM+ can
effectively generate high-quality thoracic CT images with lung nodules,
highlighting its potential for broader applications, such as general tumor
synthesis and lesion generation in medical imaging. The code and pretrained
models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.

</details>


### [77] [UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas](https://arxiv.org/abs/2508.09339)
*Aqsa Sultana,Nordin Abouzahra,Ahmed Rahu,Brian Shula,Brandon Combs,Derrick Forchetti,Theus Aspiras,Vijayan K. Asari*

Main category: cs.CV

TL;DR: Ultralight Med-Vision Mamba模型通过先进的深度学习技术，提升了结肠镜筛查中癌前息肉的识别和分类能力，优化了风险评估和个性化监测。


<details>
  <summary>Details</summary>
Motivation: 提高结肠镜筛查中癌前息肉的识别精度，降低结直肠癌风险。

Method: 采用基于状态空间模型（SSM）的Ultralight Med-Vision Mamba算法，分析全切片图像的长短程依赖关系。

Result: 模型在计算速度和可扩展性方面表现优异，适合实时临床部署。

Conclusion: Ultralight Med-Vision Mamba是一种有前景的工具，可优化结肠镜筛查的效率和效果。

Abstract: Identification of precancerous polyps during routine colonoscopy screenings
is vital for their excision, lowering the risk of developing colorectal cancer.
Advanced deep learning algorithms enable precise adenoma classification and
stratification, improving risk assessment accuracy and enabling personalized
surveillance protocols that optimize patient outcomes. Ultralight Med-Vision
Mamba, a state-space based model (SSM), has excelled in modeling long- and
short-range dependencies and image generalization, critical factors for
analyzing whole slide images. Furthermore, Ultralight Med-Vision Mamba's
efficient architecture offers advantages in both computational speed and
scalability, making it a promising tool for real-time clinical deployment.

</details>


### [78] [Blink-to-code: real-time Morse code communication via eye blink detection and classification](https://arxiv.org/abs/2508.09344)
*Anushka Bhatt*

Main category: cs.CV

TL;DR: 提出一种实时系统，将眨眼动作转换为摩尔斯电码，帮助严重运动障碍者进行交流。


<details>
  <summary>Details</summary>
Motivation: 为严重运动障碍者提供低成本、可行的辅助交流方法。

Method: 使用标准摄像头和计算机视觉技术检测眨眼动作，并将其分类为短（点）或长（划），再解码为字母数字字符。

Result: 实验显示解码准确率为62%，响应时间为18-20秒。

Conclusion: 该系统是一种可行的低成本辅助交流方法。

Abstract: This study proposes a real-time system that translates voluntary eye blinks
into Morse code, enabling communication for individuals with severe motor
impairments. Using a standard webcam and computer vision, the system detects
and classifies blinks as short (dot) or long (dash), then decodes them into
alphanumeric characters. Experiments with five participants show 62% decoding
accuracy and 18-20 seconds response times, demonstrating a viable, low-cost
assistive communication method.

</details>


### [79] [FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition](https://arxiv.org/abs/2508.09362)
*Md. Milon Islam,Md Rezwanul Haque,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出了一种名为FusionEnsemble-Net的新型注意力集成时空网络，用于提高医疗手语识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 医疗手语识别面临复杂多模态手势的挑战，需要高精度框架。

Method: 通过四种时空网络同步处理RGB视频和雷达数据，利用注意力融合模块动态融合特征，并通过集成分类器提升鲁棒性。

Result: 在意大利手语数据集上达到99.44%的测试准确率，优于现有方法。

Conclusion: 注意力融合的多样化时空网络集成是复杂多模态手势识别的有效框架。

Abstract: Accurate recognition of sign language in healthcare communication poses a
significant challenge, requiring frameworks that can accurately interpret
complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net,
a novel attention-based ensemble of spatiotemporal networks that dynamically
fuses visual and motion data to enhance recognition accuracy. The proposed
approach processes RGB video and range Doppler map radar modalities
synchronously through four different spatiotemporal networks. For each network,
features from both modalities are continuously fused using an attention-based
fusion module before being fed into an ensemble of classifiers. Finally, the
outputs of these four different fused channels are combined in an ensemble
classification head, thereby enhancing the model's robustness. Experiments
demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches
with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for
Italian Sign Language. Our findings indicate that an ensemble of diverse
spatiotemporal networks, unified by attention-based fusion, yields a robust and
accurate framework for complex, multimodal isolated gesture recognition tasks.
The source code is available at:
https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.

</details>


### [80] [A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition](https://arxiv.org/abs/2508.09372)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: 论文提出了一种双架构框架，分别针对手语识别中的独立于说话者（SI）和未见句子（US）问题，通过Conformer和Transformer模型显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决连续手语识别（CSLR）中的说话者间变异性和对新句子结构的泛化能力不足的问题。

Method: 采用Signer-Invariant Conformer处理SI问题，结合卷积和多头自注意力；设计Multi-Scale Fusion Transformer处理US问题，通过双路径时间编码器捕捉细粒度动态。

Result: 在Isharah-1000数据集上，SI任务的WER降至13.07%，US任务的WER为47.78%，均优于现有方法。

Conclusion: 任务特定网络设计显著提升CSLR性能，为后续研究设定了新基准。

Abstract: Continuous Sign Language Recognition (CSLR) faces multiple challenges,
including significant inter-signer variability and poor generalization to novel
sentence structures. Traditional solutions frequently fail to handle these
issues efficiently. For overcoming these constraints, we propose a
dual-architecture framework. For the Signer-Independent (SI) challenge, we
propose a Signer-Invariant Conformer that combines convolutions with multi-head
self-attention to learn robust, signer-agnostic representations from pose-based
skeletal keypoints. For the Unseen-Sentences (US) task, we designed a
Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that
captures both fine-grained posture dynamics, enabling the model's ability to
comprehend novel grammatical compositions. Experiments on the challenging
Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The
proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on
the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US
task, the transformer model scores a WER of 47.78%, surpassing previous work.
In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th
in the SI task, demonstrating the performance of these models. The findings
validate our key hypothesis: that developing task-specific networks designed
for the particular challenges of CSLR leads to considerable performance
improvements and establishes a new baseline for further research. The source
code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.

</details>


### [81] [What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?](https://arxiv.org/abs/2508.09381)
*Kumar Abhishek,Jeremy Kawahara,Ghassan Hamarneh*

Main category: cs.CV

TL;DR: 论文研究了医学图像分割中标注者间的变异性，发现恶性皮肤病变与标注者间一致性显著相关，并利用这一关联提升了多任务学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标注者的变异性（如边界模糊、标注者偏好等）影响结果准确性，尤其是恶性病变更易引发分歧。

Method: 构建了IMA++数据集，研究标注者、恶性程度等因素对一致性的影响，并利用一致性作为多任务学习的软特征。

Result: 恶性病变与标注者间一致性显著相关（p<0.001），多任务学习模型性能提升4.2%。

Conclusion: 标注者间一致性可作为临床特征提升模型性能，为医学图像分割提供了新思路。

Abstract: Medical image segmentation exhibits intra- and inter-annotator variability
due to ambiguous object boundaries, annotator preferences, expertise, and
tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated
or infiltrative nodules, or irregular borders per the ABCD rule, are
particularly prone to disagreement and are often associated with malignancy. In
this work, we curate IMA++, the largest multi-annotator skin lesion
segmentation dataset, on which we conduct an in-depth study of variability due
to annotator, malignancy, tool, and skill factors. We find a statistically
significant (p<0.001) association between inter-annotator agreement (IAA),
measured using Dice, and the malignancy of skin lesions. We further show that
IAA can be accurately predicted directly from dermoscopic images, achieving a
mean absolute error of 0.108. Finally, we leverage this association by
utilizing IAA as a "soft" clinical feature within a multi-task learning
objective, yielding a 4.2% improvement in balanced accuracy averaged across
multiple model architectures and across IMA++ and four public dermoscopic
datasets. The code is available at https://github.com/sfu-mial/skin-IAV.

</details>


### [82] [X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents](https://arxiv.org/abs/2508.09383)
*Guoxian Song,Hongyi Xu,Xiaochen Zhao,You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Linjie Luo*

Main category: cs.CV

TL;DR: X-UniMotion提出了一种统一的隐式潜在表示方法，用于捕捉全身人体运动（包括面部表情、身体姿势和手势），并通过自监督框架实现高保真跨身份运动转移。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖显式骨骼姿势和启发式跨身份调整，限制了表达的灵活性和保真度。X-UniMotion旨在通过隐式潜在表示解决这一问题。

Method: 通过自监督端到端框架，学习运动编码器和潜在表示，并结合DiT视频生成模型。使用2D和3D增强技术实现运动与身份的解耦，并通过辅助解码器优化运动嵌入。

Result: X-UniMotion在实验中表现优于现有方法，生成高保真动画，运动细节丰富且身份保留效果好。

Conclusion: X-UniMotion为跨身份运动转移提供了一种高效、统一的解决方案，具有广泛的应用潜力。

Abstract: We present X-UniMotion, a unified and expressive implicit latent
representation for whole-body human motion, encompassing facial expressions,
body poses, and hand gestures. Unlike prior motion transfer methods that rely
on explicit skeletal poses and heuristic cross-identity adjustments, our
approach encodes multi-granular motion directly from a single image into a
compact set of four disentangled latent tokens -- one for facial expression,
one for body pose, and one for each hand. These motion latents are both highly
expressive and identity-agnostic, enabling high-fidelity, detailed
cross-identity motion transfer across subjects with diverse identities, poses,
and spatial configurations. To achieve this, we introduce a self-supervised,
end-to-end framework that jointly learns the motion encoder and latent
representation alongside a DiT-based video generative model, trained on
large-scale, diverse human motion datasets. Motion-identity disentanglement is
enforced via 2D spatial and color augmentations, as well as synthetic 3D
renderings of cross-identity subject pairs under shared poses. Furthermore, we
guide motion token learning with auxiliary decoders that promote fine-grained,
semantically aligned, and depth-aware motion embeddings. Extensive experiments
show that X-UniMotion outperforms state-of-the-art methods, producing highly
expressive animations with superior motion fidelity and identity preservation.

</details>


### [83] [DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection](https://arxiv.org/abs/2508.09392)
*Kang Ni,Minrui Zou,Yuxuan Li,Xiang Li,Kehua Guo,Ming-Ming Cheng,Yimian Dai*

Main category: cs.CV

TL;DR: DenoDet V2提出了一种新的变换域特征解构与调制方法，通过注意力架构和振幅-相位互补机制，显著提升了SAR目标检测性能。


<details>
  <summary>Details</summary>
Motivation: SAR目标检测中相干噪声的普遍影响是主要挑战，现有方法多基于空间域特征分析或增强。

Method: 设计了注意力架构，利用振幅和相位信息的互补性，通过频带互调制机制实现特征增强。

Result: 在多个SAR数据集上表现优异，SARDet-100K上比DenoDet V1提升0.8%，模型复杂度减半。

Conclusion: DenoDet V2通过变换域特征调制，实现了SAR目标检测的显著进步。

Abstract: One of the primary challenges in Synthetic Aperture Radar (SAR) object
detection lies in the pervasive influence of coherent noise. As a common
practice, most existing methods, whether handcrafted approaches or deep
learning-based methods, employ the analysis or enhancement of object
spatial-domain characteristics to achieve implicit denoising. In this paper, we
propose DenoDet V2, which explores a completely novel and different perspective
to deconstruct and modulate the features in the transform domain via a
carefully designed attention architecture. Compared to DenoDet V1, DenoDet V2
is a major advancement that exploits the complementary nature of amplitude and
phase information through a band-wise mutual modulation mechanism, which
enables a reciprocal enhancement between phase and amplitude spectra. Extensive
experiments on various SAR datasets demonstrate the state-of-the-art
performance of DenoDet V2. Notably, DenoDet V2 achieves a significant 0.8\%
improvement on SARDet-100K dataset compared to DenoDet V1, while reducing the
model complexity by half. The code is available at
https://github.com/GrokCV/GrokSAR.

</details>


### [84] [Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety](https://arxiv.org/abs/2508.09397)
*Zhengli Zhang,Xinyu Luo,Yuchen Sun,Wenhua Ding,Dongyu Huang,Xinlei Chen*

Main category: cs.CV

TL;DR: SkyShield是一个事件驱动的框架，用于检测无人机在复杂环境中的亚毫米级障碍物，采用轻量级U-Net架构和创新的Dice-Contour正则化损失，实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 传统传感器（如RGB相机、LiDAR和深度相机）难以检测亚毫米级障碍物（如钢丝和风筝线），无人机在复杂环境中面临此类威胁。

Method: 利用事件流中薄障碍物的独特特征，采用轻量级U-Net架构和Dice-Contour正则化损失进行精确检测。

Result: 实验结果显示，该方法平均F1分数为0.7088，延迟低至21.2毫秒，适合边缘和移动平台部署。

Conclusion: SkyShield为无人机在复杂环境中检测亚毫米级障碍物提供了一种高效、低延迟的解决方案。

Abstract: Drones operating in complex environments face a significant threat from thin
obstacles, such as steel wires and kite strings at the submillimeter level,
which are notoriously difficult for conventional sensors like RGB cameras,
LiDAR, and depth cameras to detect. This paper introduces SkyShield, an
event-driven, end-to-end framework designed for the perception of submillimeter
scale obstacles. Drawing upon the unique features that thin obstacles present
in the event stream, our method employs a lightweight U-Net architecture and an
innovative Dice-Contour Regularization Loss to ensure precise detection.
Experimental results demonstrate that our event-based approach achieves mean F1
Score of 0.7088 with a low latency of 21.2 ms, making it ideal for deployment
on edge and mobile platforms.

</details>


### [85] [Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring](https://arxiv.org/abs/2508.09398)
*El Mustapha Mansouri*

Main category: cs.CV

TL;DR: 低成本、本地化的比利时城市花园鸟类监测系统，使用运动触发的IP摄像头和本地服务器处理，结合Detectron2和EfficientNet-B3模型，实现高精度分类。


<details>
  <summary>Details</summary>
Motivation: 为公民科学提供低成本、隐私保护的鸟类监测解决方案，避免云费用和隐私问题。

Method: 使用运动触发的IP摄像头上传视频到本地服务器，结合Detectron2定位鸟类，EfficientNet-B3分类40种比利时鸟类。

Result: 分类器在验证集上达到99.5%准确率，实际应用中达到88%的top-1准确率。

Conclusion: 该系统适合家庭使用，为公民科学提供可行的生物多样性记录工具。

Abstract: This paper presents a low cost, on premise system for autonomous backyard
bird monitoring in Belgian urban gardens. A motion triggered IP camera uploads
short clips via FTP to a local server, where frames are sampled and birds are
localized with Detectron2; cropped regions are then classified by an
EfficientNet-B3 model fine tuned on a 40-species Belgian subset derived from a
larger Kaggle corpus. All processing runs on commodity hardware without a
discrete GPU, preserving privacy and avoiding cloud fees. The physical feeder
uses small entry ports (30 mm) to exclude pigeons and reduce nuisance triggers.
Detector-guided cropping improves classification accuracy over raw-frame
classification. The classifier attains high validation performance on the
curated subset (about 99.5 percent) and delivers practical field accuracy
(top-1 about 88 percent) on held-out species, demonstrating feasibility for
citizen-science-grade biodiversity logging at home.

</details>


### [86] [Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving](https://arxiv.org/abs/2508.09404)
*Guangxun Zhu,Shiyu Fan,Hang Dai,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: Waymo-3DSkelMo是一个大规模高质量3D运动数据集，专注于多行人交互，为自动驾驶中细粒度行人交互理解提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有数据集依赖单目RGB视频帧估计3D姿态，存在遮挡和时间不连续问题，导致运动质量低。

Method: 利用3D人体形状和运动先验，从LiDAR点云中提取高质量3D姿态序列。

Result: 数据集覆盖14,000秒、800多个真实驾驶场景，平均每场景27个行人，最多250个。建立了3D姿态预测基准。

Conclusion: Waymo-3DSkelMo是复杂城市环境中细粒度人类行为研究的宝贵资源。

Abstract: Large-scale high-quality 3D motion datasets with multi-person interactions
are crucial for data-driven models in autonomous driving to achieve
fine-grained pedestrian interaction understanding in dynamic urban
environments. However, existing datasets mostly rely on estimating 3D poses
from monocular RGB video frames, which suffer from occlusion and lack of
temporal continuity, thus resulting in unrealistic and low-quality human
motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale
dataset providing high-quality, temporally coherent 3D skeletal motions with
explicit interaction semantics, derived from the Waymo Perception dataset. Our
key insight is to utilize 3D human body shape and motion priors to enhance the
quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The
dataset covers over 14,000 seconds across more than 800 real driving scenarios,
including rich interactions among an average of 27 agents per scene (with up to
250 agents in the largest scene). Furthermore, we establish 3D pose forecasting
benchmarks under varying pedestrian densities, and the results demonstrate its
value as a foundational resource for future research on fine-grained human
behavior understanding in complex urban environments. The dataset and code will
be available at https://github.com/GuangxunZhu/Waymo-3DSkelMo

</details>


### [87] [RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata](https://arxiv.org/abs/2508.09415)
*John S. O'Meara,Jared Hwang,Zeyu Wang,Michael Saugstad,Jon E. Froehlich*

Main category: cs.CV

TL;DR: 论文提出RampNet，一个两阶段管道，用于扩展路缘坡道检测数据集并提升模型性能，通过自动标注和政府数据结合生成大规模高质量数据集，并训练出性能优越的检测模型。


<details>
  <summary>Details</summary>
Motivation: 路缘坡道对城市无障碍环境至关重要，但现有数据集在规模和质量上不足，限制了检测模型的性能。

Method: 提出两阶段方法：1) 利用政府提供的坡道位置数据自动标注21万张街景图像；2) 基于生成的数据集训练改进的ConvNeXt V2模型。

Result: 生成数据集精度94.0%，召回率92.5%；检测模型AP达0.9236，远超先前工作。

Conclusion: 研究贡献了首个大规模高质量的路缘坡道检测数据集和模型，为城市无障碍环境提供了有力工具。

Abstract: Curb ramps are critical for urban accessibility, but robustly detecting them
in images remains an open problem due to the lack of large-scale, high-quality
datasets. While prior work has attempted to improve data availability with
crowdsourced or manually labeled data, these efforts often fall short in either
quality or scale. In this paper, we introduce and evaluate a two-stage pipeline
called RampNet to scale curb ramp detection datasets and improve model
performance. In Stage 1, we generate a dataset of more than 210,000 annotated
Google Street View (GSV) panoramas by auto-translating government-provided curb
ramp location data to pixel coordinates in panoramic images. In Stage 2, we
train a curb ramp detection model (modified ConvNeXt V2) from the generated
dataset, achieving state-of-the-art performance. To evaluate both stages of our
pipeline, we compare to manually labeled panoramas. Our generated dataset
achieves 94.0% precision and 92.5% recall, and our detection model reaches
0.9236 AP -- far exceeding prior work. Our work contributes the first
large-scale, high-quality curb ramp detection dataset, benchmark, and model.

</details>


### [88] [Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://arxiv.org/abs/2508.09423)
*Badi Li,Ren-jie Lu,Yu Zhou,Jingke Meng,Wei-shi Zheng*

Main category: cs.CV

TL;DR: GOAL是一种基于生成流的框架，用于建模室内环境的语义分布，通过结合LLM增强的全场景语义地图，显著提升了物体导航任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖确定性模型完成语义地图，忽略了室内布局的不确定性，限制了泛化能力。

Method: GOAL利用LLM推断空间先验，将其编码为二维高斯场并注入目标地图，通过生成流模型实现更通用的语义补全。

Result: 在MP3D和Gibson数据集上达到SOTA性能，并在HM3D上表现出强泛化能力。

Conclusion: GOAL通过生成流模型和LLM先验的结合，显著提升了物体导航任务的性能和泛化能力。

Abstract: The Object Goal Navigation (ObjectNav) task challenges agents to locate a
specified object in an unseen environment by imagining unobserved regions of
the scene. Prior approaches rely on deterministic and discriminative models to
complete semantic maps, overlooking the inherent uncertainty in indoor layouts
and limiting their ability to generalize to unseen environments. In this work,
we propose GOAL, a generative flow-based framework that models the semantic
distribution of indoor environments by bridging observed regions with
LLM-enriched full-scene semantic maps. During training, spatial priors inferred
from large language models (LLMs) are encoded as two-dimensional Gaussian
fields and injected into target maps, distilling rich contextual knowledge into
the flow model and enabling more generalizable completions. Extensive
experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D
and Gibson, and shows strong generalization in transfer settings to HM3D. Codes
and pretrained models are available at https://github.com/Badi-Li/GOAL.

</details>


### [89] [What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset](https://arxiv.org/abs/2508.09428)
*Yuxiao Wang,Yu Lei,Wolin Liang,Weiying Xue,Zhenao Wei,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: 论文提出了一种新视觉任务，同时预测高级动作语义和细粒度身体接触区域，并提出了PaIR-Net框架和PaIR数据集。


<details>
  <summary>Details</summary>
Motivation: 当前方法未能同时建模动作语义及其空间上下文，需填补这一空白。

Method: 提出PaIR-Net框架，包含CPAM、PGCS和IIM三个模块，用于识别接触相关身体部分、像素级接触分割和全局关系整合。

Result: PaIR-Net显著优于基线方法，消融实验验证了各模块的有效性。

Conclusion: PaIR-Net和PaIR数据集为动作语义与空间上下文的联合建模提供了有效解决方案。

Abstract: People control their bodies to establish contact with the environment. To
comprehensively understand actions across diverse visual contexts, it is
essential to simultaneously consider \textbf{what} action is occurring and
\textbf{where} it is happening. Current methodologies, however, often
inadequately capture this duality, typically failing to jointly model both
action semantics and their spatial contextualization within scenes. To bridge
this gap, we introduce a novel vision task that simultaneously predicts
high-level action semantics and fine-grained body-part contact regions. Our
proposed framework, PaIR-Net, comprises three key components: the Contact Prior
Aware Module (CPAM) for identifying contact-relevant body parts, the
Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and
the Interaction Inference Module (IIM) responsible for integrating global
interaction relationships. To facilitate this task, we present PaIR (Part-aware
Interaction Representation), a comprehensive dataset containing 13,979 images
that encompass 654 actions, 80 object categories, and 17 body parts.
Experimental evaluation demonstrates that PaIR-Net significantly outperforms
baseline approaches, while ablation studies confirm the efficacy of each
architectural component. The code and dataset will be released upon
publication.

</details>


### [90] [MPT: Motion Prompt Tuning for Micro-Expression Recognition](https://arxiv.org/abs/2508.09446)
*Jiateng Liu,Hengcan Shi,Feng Chen,Zhiwen Shao,Yaonan Wang,Jianfei Cai,Wenming Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为Motion Prompt Tuning (MPT)的新方法，用于将大型预训练模型(LMs)适配到微表情识别(MER)任务中，通过运动提示生成和组适配器设计，显著提升了MER性能。


<details>
  <summary>Details</summary>
Motivation: 微表情识别在情感计算领域有广泛应用，但由于标注困难和样本稀缺，现有方法难以捕捉微表情的短暂性和细微性。

Method: 提出MPT方法，包括运动提示生成（运动放大和高斯标记化）和组适配器设计，以增强LMs在MER任务中的表现。

Result: 在三个广泛使用的MER数据集上的实验表明，MPT方法优于现有最先进方法。

Conclusion: MPT方法通过运动提示和适配器设计，成功解决了MER任务中的关键挑战，为未来研究提供了新思路。

Abstract: Micro-expression recognition (MER) is crucial in the affective computing
field due to its wide application in medical diagnosis, lie detection, and
criminal investigation. Despite its significance, obtaining micro-expression
(ME) annotations is challenging due to the expertise required from
psychological professionals. Consequently, ME datasets often suffer from a
scarcity of training samples, severely constraining the learning of MER models.
While current large pre-training models (LMs) offer general and discriminative
representations, their direct application to MER is hindered by an inability to
capture transitory and subtle facial movements-essential elements for effective
MER. This paper introduces Motion Prompt Tuning (MPT) as a novel approach to
adapting LMs for MER, representing a pioneering method for subtle motion prompt
tuning. Particularly, we introduce motion prompt generation, including motion
magnification and Gaussian tokenization, to extract subtle motions as prompts
for LMs. Additionally, a group adapter is carefully designed and inserted into
the LM to enhance it in the target MER domain, facilitating a more nuanced
distinction of ME representation. Furthermore, extensive experiments conducted
on three widely used MER datasets demonstrate that our proposed MPT
consistently surpasses state-of-the-art approaches and verifies its
effectiveness.

</details>


### [91] [RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration](https://arxiv.org/abs/2508.09449)
*Jiaqi Yan,Shuning Xu,Xiangyu Chen,Dell Zhang,Jie Tang,Gangshan Wu,Jie Liu*

Main category: cs.CV

TL;DR: 论文提出了一种新的检索增强超分辨率方法（RASR），通过自动从参考数据库中检索高分辨率图像来提升纹理保真度，解决了传统RefSR依赖人工配对的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有RefSR方法依赖人工配对的参考图像，限制了实际应用。RASR旨在通过自动检索相关参考图像，提升方法的实用性和灵活性。

Method: 提出RASRNet，结合语义参考检索器和基于扩散的超分辨率生成器，通过语义相似性检索参考图像并生成高分辨率结果。

Result: 在RASR-Flickr30数据集上，RASRNet比SISR基线提升0.38 dB PSNR和-0.0131 LPIPS，生成更真实的纹理。

Conclusion: 检索增强是缩小RefSR研究与实际应用差距的有前景方向。

Abstract: Reference-based Super Resolution (RefSR) improves upon Single Image Super
Resolution (SISR) by leveraging high-quality reference images to enhance
texture fidelity and visual realism. However, a critical limitation of existing
RefSR approaches is their reliance on manually curated target-reference image
pairs, which severely constrains their practicality in real-world scenarios. To
overcome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new
and practical RefSR paradigm that automatically retrieves semantically relevant
high-resolution images from a reference database given only a low-quality
input. This enables scalable and flexible RefSR in realistic use cases, such as
enhancing mobile photos taken in environments like zoos or museums, where
category-specific reference data (e.g., animals, artworks) can be readily
collected or pre-curated. To facilitate research in this direction, we
construct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike
prior datasets with fixed target-reference pairs, RASR-Flickr30 provides
per-category reference databases to support open-world retrieval. We further
propose RASRNet, a strong baseline that combines a semantic reference retriever
with a diffusion-based RefSR generator. It retrieves relevant references based
on semantic similarity and employs a diffusion-based generator enhanced with
semantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet
consistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131
LPIPS, while generating more realistic textures. These findings highlight
retrieval augmentation as a promising direction to bridge the gap between
academic RefSR research and real-world applicability.

</details>


### [92] [HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss](https://arxiv.org/abs/2508.09453)
*Abdul Matin,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: HyperKD是一种新颖的知识蒸馏框架，通过逆向知识转移解决高光谱遥感数据与基础模型之间的光谱差异问题，显著提升了表示学习效果。


<details>
  <summary>Details</summary>
Motivation: 基础模型在大规模无标签数据上预训练，但直接应用于高光谱遥感仍存在光谱差异和数据稀缺的挑战。

Method: HyperKD采用逆向知识蒸馏，通过特征对齐、空间特征引导掩码和增强损失函数，将Prithvi基础模型的知识迁移到EnMAP高光谱图像的学生模型中。

Result: 实验表明，HyperKD显著提升了MAE的表示学习能力，改善了重建保真度，并在下游任务（如土地覆盖分类、作物类型识别和土壤有机碳预测）中表现更稳健。

Conclusion: HyperKD通过知识蒸馏框架有效弥合了光谱域差距，为高光谱遥感分析提供了潜力。

Abstract: The proliferation of foundation models, pretrained on large-scale unlabeled
datasets, has emerged as an effective approach in creating adaptable and
reusable architectures that can be leveraged for various downstream tasks using
satellite observations. However, their direct application to hyperspectral
remote sensing remains challenging due to inherent spectral disparities and the
scarcity of available observations. In this work, we present HyperKD, a novel
knowledge distillation framework that enables transferring learned
representations from a teacher model into a student model for effective
development of a foundation model on hyperspectral images. Unlike typical
knowledge distillation frameworks, which use a complex teacher to guide a
simpler student, HyperKD enables an inverse form of knowledge transfer across
different types of spectral data, guided by a simpler teacher model. Building
upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi
foundational model into a student tailored for EnMAP hyperspectral imagery.
HyperKD addresses the inverse domain adaptation problem with spectral gaps by
introducing a feature-based strategy that includes spectral range-based channel
alignment, spatial feature-guided masking, and an enhanced loss function
tailored for hyperspectral images. HyperKD bridges the substantial spectral
domain gap, enabling the effective use of pretrained foundation models for
geospatial applications. Extensive experiments show that HyperKD significantly
improves representation learning in MAEs, leading to enhanced reconstruction
fidelity and more robust performance on downstream tasks such as land cover
classification, crop type identification, and soil organic carbon prediction,
underpinning the potential of knowledge distillation frameworks in remote
sensing analytics with hyperspectral imagery.

</details>


### [93] [Animate-X++: Universal Character Image Animation with Dynamic Backgrounds](https://arxiv.org/abs/2508.09454)
*Shuai Tan,Biao Gong,Zhuoxin Liu,Yan Wang,Xi Chen,Yifan Feng,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Animate-X++ 是一个基于 DiT 的通用动画框架，用于生成各种角色（包括拟人角色）的高质量视频，解决了现有方法在拟人角色和动态背景上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要适用于人类角色，对拟人角色泛化能力差，且无法生成动态背景视频，限制了视频的真实感。

Method: 提出 Pose Indicator 增强运动表示，结合 CLIP 视觉特征和模拟输入；采用多任务训练策略联合训练动画和 TI2V 任务，实现动态背景。

Result: Animate-X++ 在拟人角色和动态背景生成上表现优异，通过 A2Bench 验证了其通用性和有效性。

Conclusion: Animate-X++ 解决了现有方法的局限性，为角色动画提供了更通用和真实的解决方案。

Abstract: Character image animation, which generates high-quality videos from a
reference image and target pose sequence, has seen significant progress in
recent years. However, most existing methods only apply to human figures, which
usually do not generalize well on anthropomorphic characters commonly used in
industries like gaming and entertainment. Furthermore, previous methods could
only generate videos with static backgrounds, which limits the realism of the
videos. For the first challenge, our in-depth analysis suggests to attribute
this limitation to their insufficient modeling of motion, which is unable to
comprehend the movement pattern of the driving video, thus imposing a pose
sequence rigidly onto the target character. To this end, this paper proposes
Animate-X++, a universal animation framework based on DiT for various character
types, including anthropomorphic characters. To enhance motion representation,
we introduce the Pose Indicator, which captures comprehensive motion pattern
from the driving video through both implicit and explicit manner. The former
leverages CLIP visual features of a driving video to extract its gist of
motion, like the overall movement pattern and temporal relations among motions,
while the latter strengthens the generalization of DiT by simulating possible
inputs in advance that may arise during inference. For the second challenge, we
introduce a multi-task training strategy that jointly trains the animation and
TI2V tasks. Combined with the proposed partial parameter training, this
approach achieves not only character animation but also text-driven background
dynamics, making the videos more realistic. Moreover, we introduce a new
Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of
Animate-X++ on universal and widely applicable animation images. Extensive
experiments demonstrate the superiority and effectiveness of Animate-X++.

</details>


### [94] [IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding](https://arxiv.org/abs/2508.09456)
*Junxian Li,Beining Xu,Di Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种新型输入感知后门攻击方法IAG，针对视觉语言模型（VLMs）的视觉定位任务，通过自适应触发器生成器将攻击目标的语义信息嵌入图像，实现隐蔽攻击。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉定位任务中表现出色，但其安全性问题，尤其是后门攻击，尚未充分研究。本文旨在填补这一空白。

Method: 提出IAG方法，利用文本条件U-Net生成自适应触发器，嵌入攻击目标语义信息，并通过重构损失确保攻击隐蔽性。

Result: 在InternVL-2.5-8B上，ASR@0.5超过65%，且在Ferret-7B和LlaVA-1.5-7B上攻击效果显著，对干净样本准确率影响小。

Conclusion: IAG展示了高效、隐蔽的后门攻击能力，具有鲁棒性和可迁移性，为VLM安全性研究提供了新视角。

Abstract: Vision-language models (VLMs) have shown significant advancements in tasks
such as visual grounding, where they localize specific objects in images based
on natural language queries and images. However, security issues in visual
grounding tasks for VLMs remain underexplored, especially in the context of
backdoor attacks. In this paper, we introduce a novel input-aware backdoor
attack method, IAG, designed to manipulate the grounding behavior of VLMs. This
attack forces the model to ground a specific target object in the input image,
regardless of the user's query. We propose an adaptive trigger generator that
embeds the semantic information of the attack target's description into the
original image using a text-conditional U-Net, thereby overcoming the
open-vocabulary attack challenge. To ensure the attack's stealthiness, we
utilize a reconstruction loss to minimize visual discrepancies between poisoned
and clean images. Additionally, we introduce a unified method for generating
attack data. IAG is evaluated theoretically and empirically, demonstrating its
feasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches
over 65\% on various testing sets. IAG also shows promising potential on
manipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on
clean samples. Extensive specific experiments, such as ablation study and
potential defense, also indicate the robustness and transferability of our
attack.

</details>


### [95] [RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization](https://arxiv.org/abs/2508.09459)
*Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia*

Main category: cs.CV

TL;DR: RelayFormer是一种统一的模块化架构，用于图像和视频中的视觉篡改定位，通过灵活的局部单元和全局-局部中继注意力机制实现高效处理。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态泛化和处理高分辨率或长时间输入时效率不足，需要一种更通用的解决方案。

Method: 采用灵活的局部单元和GLoRA机制，结合轻量级适配模块与现有Transformer架构（如ViT和SegFormer）集成，设计轻量级查询式掩码解码器。

Result: 在多个基准测试中达到最先进的定位性能，为可扩展和模态无关的VML设定了新基准。

Conclusion: RelayFormer通过高效架构和泛化能力，为视觉篡改定位任务提供了新的解决方案。

Abstract: Visual manipulation localization (VML) -- across both images and videos -- is
a crucial task in digital forensics that involves identifying tampered regions
in visual content. However, existing methods often lack cross-modal
generalization and struggle to handle high-resolution or long-duration inputs
efficiently.
  We propose RelayFormer, a unified and modular architecture for visual
manipulation localization across images and videos. By leveraging flexible
local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables
scalable, resolution-agnostic processing with strong generalization. Our
framework integrates seamlessly with existing Transformer-based backbones, such
as ViT and SegFormer, via lightweight adaptation modules that require only
minimal architectural changes, ensuring compatibility without disrupting
pretrained representations.
  Furthermore, we design a lightweight, query-based mask decoder that supports
one-shot inference across video sequences with linear complexity. Extensive
experiments across multiple benchmarks demonstrate that our approach achieves
state-of-the-art localization performance, setting a new baseline for scalable
and modality-agnostic VML. Code is available at:
https://github.com/WenOOI/RelayFormer.

</details>


### [96] [Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy](https://arxiv.org/abs/2508.09461)
*Hao Yu,Rupayan Mallick,Margrit Betke,Sarah Adel Bargal*

Main category: cs.CV

TL;DR: GEN-AFFECT是一个用于生成个性化2D头像的新框架，专注于捕捉细粒度面部表情并保持身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细粒度面部表情和保持身份一致性方面表现不足，需要一种更有效的解决方案。

Method: 通过多模态扩散变换器提取身份-表情表示，并采用一致性注意力机制在推理过程中共享信息。

Result: GEN-AFFECT在生成表情的准确性、身份保持和一致性方面优于现有方法。

Conclusion: GEN-AFFECT为个性化头像生成提供了一种高效且表现优异的解决方案。

Abstract: Different forms of customized 2D avatars are widely used in gaming
applications, virtual communication, education, and content creation. However,
existing approaches often fail to capture fine-grained facial expressions and
struggle to preserve identity across different expressions. We propose
GEN-AFFECT, a novel framework for personalized avatar generation that generates
expressive and identity-consistent avatars with a diverse set of facial
expressions. Our framework proposes conditioning a multimodal diffusion
transformer on an extracted identity-expression representation. This enables
identity preservation and representation of a wide range of facial expressions.
GEN-AFFECT additionally employs consistent attention at inference for
information sharing across the set of generated expressions, enabling the
generation process to maintain identity consistency over the array of generated
fine-grained expressions. GEN-AFFECT demonstrates superior performance compared
to previous state-of-the-art methods on the basis of the accuracy of the
generated expressions, the preservation of the identity and the consistency of
the target identity across an array of fine-grained facial expressions.

</details>


### [97] [Event-driven Robust Fitting on Neuromorphic Hardware](https://arxiv.org/abs/2508.09466)
*Tam Ngoc-Bang Nguyen,Anh-Dzung Doan,Zhipeng Cai,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经形态计算范式（Intel Loihi 2）的节能鲁棒拟合方法，通过设计新型脉冲神经网络，实现了仅需传统CPU方法15%的能耗即可达到相同精度。


<details>
  <summary>Details</summary>
Motivation: 随着AI能耗问题日益突出，鲁棒拟合中的能源效率问题尚未得到足够关注。本文旨在探索神经形态计算在节能鲁棒拟合中的应用。

Method: 设计了新型脉冲神经网络，提出事件驱动的模型估计方法，并开发算法策略以应对硬件（Intel Loihi 2）的精度和指令集限制。

Result: 实验表明，该方法仅需传统CPU方法15%的能耗即可达到相同精度。

Conclusion: 神经形态计算为鲁棒拟合提供了高效的节能解决方案，具有实际应用潜力。

Abstract: Robust fitting of geometric models is a fundamental task in many computer
vision pipelines. Numerous innovations have been produced on the topic, from
improving the efficiency and accuracy of random sampling heuristics to
generating novel theoretical insights that underpin new approaches with
mathematical guarantees. However, one aspect of robust fitting that has
received little attention is energy efficiency. This performance metric has
become critical as high energy consumption is a growing concern for AI
adoption. In this paper, we explore energy-efficient robust fitting via the
neuromorphic computing paradigm. Specifically, we designed a novel spiking
neural network for robust fitting on real neuromorphic hardware, the Intel
Loihi 2. Enabling this are novel event-driven formulations of model estimation
that allow robust fitting to be implemented in the unique architecture of Loihi
2, and algorithmic strategies to alleviate the current limited precision and
instruction set of the hardware. Results show that our neuromorphic robust
fitting consumes only a fraction (15%) of the energy required to run the
established robust fitting algorithm on a standard CPU to equivalent accuracy.

</details>


### [98] [CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios](https://arxiv.org/abs/2508.09470)
*Jialei Xu,Zizhuang Wei,Weikang You,Linyun Li,Weijian Sun*

Main category: cs.CV

TL;DR: CitySeg是一种用于城市规模点云语义分割的基础模型，通过引入文本模态实现开放词汇分割和零样本推理，解决了数据规模限制和领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型受限于3D数据规模小和数据集间的领域差距，导致泛化能力不足。CitySeg旨在解决这些问题，提升无人机感知系统的3D理解能力。

Method: 提出局部-全局交叉注意力网络增强点网络感知能力，采用分层分类策略解决语义标签差异，并使用两阶段训练策略和铰链损失提升特征可分性。

Result: 在九个封闭集基准测试中达到SOTA性能，首次实现不依赖视觉信息的城市规模点云零样本泛化。

Conclusion: CitySeg通过创新的数据预处理、网络设计和训练策略，显著提升了点云语义分割的性能和泛化能力。

Abstract: Semantic segmentation of city-scale point clouds is a critical technology for
Unmanned Aerial Vehicle (UAV) perception systems, enabling the classification
of 3D points without relying on any visual information to achieve comprehensive
3D understanding. However, existing models are frequently constrained by the
limited scale of 3D data and the domain gap between datasets, which lead to
reduced generalization capability. To address these challenges, we propose
CitySeg, a foundation model for city-scale point cloud semantic segmentation
that incorporates text modality to achieve open vocabulary segmentation and
zero-shot inference. Specifically, in order to mitigate the issue of
non-uniform data distribution across multiple domains, we customize the data
preprocessing rules, and propose a local-global cross-attention network to
enhance the perception capabilities of point networks in UAV scenarios. To
resolve semantic label discrepancies across datasets, we introduce a
hierarchical classification strategy. A hierarchical graph established
according to the data annotation rules consolidates the data labels, and the
graph encoder is used to model the hierarchical relationships between
categories. In addition, we propose a two-stage training strategy and employ
hinge loss to increase the feature separability of subcategories. Experimental
results demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA)
performance on nine closed-set benchmarks, significantly outperforming existing
approaches. Moreover, for the first time, CitySeg enables zero-shot
generalization in city-scale point cloud scenarios without relying on visual
information.

</details>


### [99] [Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection](https://arxiv.org/abs/2508.09475)
*Shibo Yao,Renshuai Tao,Xiaolong Zheng,Chao Liang,Chunjie Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的少样本深度伪造检测方法FTNet，通过利用少量样本显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中深度伪造检测模型在未知样本上表现不佳，但少量样本可用于改进性能，因此将其视为少样本任务而非零样本任务。

Method: 提出FTNet，仅需一个伪造样本作为参考，无需训练或参数更新，通过比较测试样本与已知样本进行分类。

Result: 在29种生成模型的测试中，FTNet平均性能提升8.7%，达到新SoTA。

Conclusion: 利用失败样本改进性能为深度伪造检测提供了新思路。

Abstract: Recent deepfake detection studies often treat unseen sample detection as a
``zero-shot" task, training on images generated by known models but
generalizing to unknown ones. A key real-world challenge arises when a model
performs poorly on unknown samples, yet these samples remain available for
analysis. This highlights that it should be approached as a ``few-shot" task,
where effectively utilizing a small number of samples can lead to significant
improvement. Unlike typical few-shot tasks focused on semantic understanding,
deepfake detection prioritizes image realism, which closely mirrors real-world
distributions. In this work, we propose the Few-shot Training-free Network
(FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet
differs from traditional methods that rely on large-scale known data for
training. Instead, FTNet uses only one fake samplefrom an evaluation set,
mimicking the scenario where new samples emerge in the real world and can be
gathered for use, without any training or parameter updates. During evaluation,
each test sample is compared to the known fake and real samples, and it is
classified based on the category of the nearest sample. We conduct a
comprehensive analysis of AI-generated images from 29 different generative
models and achieve a new SoTA performance, with an average improvement of 8.7\%
compared to existing methods. This work introduces a fresh perspective on
real-world deepfake detection: when the model struggles to generalize on a
few-shot sample, leveraging the failed samples leads to better performance.

</details>


### [100] [From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts](https://arxiv.org/abs/2508.09476)
*Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 论文提出了一种动态混合面部专家（MoFE）方法和专门的数据处理流程，解决了视频生成模型中大角度面部身份保持的难题，并构建了LFA数据集。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在大角度面部时难以保持身份一致性，主要因缺乏有效机制和针对性数据集。

Method: 引入MoFE动态整合三种专家特征，并设计数据处理流程（Face Constraints和Identity Consistency），构建LFA数据集。

Result: 实验表明，方法在LFA基准测试中显著优于现有技术，提升了面部相似度、FID和CLIP语义对齐。

Conclusion: MoFE和LFA数据集有效解决了大角度面部身份保持问题，代码和数据集将开源。

Abstract: Current video generation models struggle with identity preservation under
large facial angles, primarily facing two challenges: the difficulty in
exploring an effective mechanism to integrate identity features into DiT
structure, and the lack of targeted coverage of large facial angles in existing
open-source video datasets. To address these, we present two key innovations.
First, we introduce a Mixture of Facial Experts (MoFE) that dynamically
combines complementary cues from three specialized experts, each designed to
capture distinct but mutually reinforcing aspects of facial attributes. The
identity expert captures cross-pose identity-sensitive features, the semantic
expert extracts high-level visual semantxics, and the detail expert preserves
pixel-level features (e.g., skin texture, color gradients). Furthermore, to
mitigate dataset limitations, we have tailored a data processing pipeline
centered on two key aspects: Face Constraints and Identity Consistency. Face
Constraints ensure facial angle diversity and a high proportion of facial
regions, while Identity Consistency preserves coherent person-specific features
across temporal sequences, collectively addressing the scarcity of large facial
angles and identity-stable training data in existing datasets. Leveraging this
pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from
existing open-source human video datasets, comprising 460K video clips with
annotated facial angles. Experimental results on the LFA benchmark demonstrate
that our method, empowered by the LFA dataset, significantly outperforms prior
SOTA methods in face similarity, face FID, and CLIP semantic alignment. The
code and dataset will be made publicly available at
https://github.com/rain152/LFA-Video-Generation.

</details>


### [101] [CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection](https://arxiv.org/abs/2508.09477)
*Zhipeng Yuan,Kai Wang,Weize Quan,Dong-Ming Yan,Tieru Wu*

Main category: cs.CV

TL;DR: 提出了一种基于异常检测的通用AI生成图像检测器，无需接触AI生成图像，通过无监督学习实现泛化性能。


<details>
  <summary>Details</summary>
Motivation: AI生成图像质量接近自然图像，传统检测方法对未见过的生成模型性能有限，需改进。

Method: 使用预训练CLIP编码器提取特征，设计类似归一化流的无监督模型，利用代理图像（如频谱修改的自然图像）训练。

Result: 实验证明该方法对多种图像生成器生成的AI图像检测有效。

Conclusion: 提出的无监督方法在通用AI生成图像检测中表现优异。

Abstract: With the rapid advancement of AI generative models, the visual quality of
AI-generated images (AIIs) has become increasingly close to natural images,
which inevitably raises security concerns. Most AII detectors often employ the
conventional image classification pipeline with natural images and AIIs
(generated by a generative model), which can result in limited detection
performance for AIIs from unseen generative models. To solve this, we proposed
a universal AI-generated image detector from the perspective of anomaly
detection. Our discriminator does not need to access any AIIs and learn a
generalizable representation with unsupervised learning. Specifically, we use
the pre-trained CLIP encoder as the feature extractor and design a normalizing
flow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by
applying a spectral modification operation on natural images, are used for
training. Our models are trained by minimizing the likelihood of proxy images,
optionally combined with maximizing the likelihood of natural images. Extensive
experiments demonstrate the effectiveness of our method on AIIs produced by
various image generators.

</details>


### [102] [GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs](https://arxiv.org/abs/2508.09478)
*Moinak Bhattacharya,Gagandeep Singh,Shubham Jain,Prateek Prasanna*

Main category: cs.CV

TL;DR: GazeLT提出了一种结合放射科医生视觉注意力的方法，用于长尾疾病分类，通过整合和解构视觉搜索过程的时序信息，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 放射科医生的视觉注意力模式包含细粒度和粗粒度疾病信息，且其注意力随时间变化。将这些信息融入深度学习框架，可提升自动化图像解读能力，尤其是对长尾类别的识别。

Method: GazeLT通过整合和解构视觉搜索过程的时序信息，利用放射科医生的眼动数据，改进长尾疾病分类。

Result: 在NIH-CXR-LT和MIMIC-CXR-LT数据集上，GazeLT的平均准确率分别比最佳长尾损失方法和视觉注意力基线高出4.1%和21.7%。

Conclusion: GazeLT通过有效利用放射科医生的视觉注意力时序信息，显著提升了长尾疾病分类的性能，展示了其在医学图像分析中的潜力。

Abstract: In this work, we present GazeLT, a human visual attention
integration-disintegration approach for long-tailed disease classification. A
radiologist's eye gaze has distinct patterns that capture both fine-grained and
coarser level disease related information. While interpreting an image, a
radiologist's attention varies throughout the duration; it is critical to
incorporate this into a deep learning framework to improve automated image
interpretation. Another important aspect of visual attention is that apart from
looking at major/obvious disease patterns, experts also look at
minor/incidental findings (few of these constituting long-tailed classes)
during the course of image interpretation. GazeLT harnesses the temporal aspect
of the visual search process, via an integration and disintegration mechanism,
to improve long-tailed disease classification. We show the efficacy of GazeLT
on two publicly available datasets for long-tailed disease classification,
namely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets.
GazeLT outperforms the best long-tailed loss by 4.1% and the visual
attention-based baseline by 21.7% in average accuracy metrics for these
datasets. Our code is available at https://github.com/lordmoinak1/gazelt.

</details>


### [103] [SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images](https://arxiv.org/abs/2508.09479)
*Xuejun Huang,Xinyi Liu,Yi Wan,Zhi Zheng,Bin Zhang,Mingtao Xiong,Yingying Pei,Yongjun Zhang*

Main category: cs.CV

TL;DR: SkySplat提出了一种自监督框架，将RPC模型融入通用3DGS流程，显著提升了稀疏卫星图像的三维重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法在稀疏卫星图像重建中存在与RPC模型不兼容和泛化能力不足的问题。

Method: SkySplat结合RPC模型，采用自监督学习，引入CSCM模块和多视角一致性策略。

Result: SkySplat比EOGS快86倍且更准确，在DFC19数据集上MAE从13.18m降至1.80m。

Conclusion: SkySplat在稀疏卫星图像重建中表现出色，具有高效性和强泛化能力。

Abstract: Three-dimensional scene reconstruction from sparse-view satellite images is a
long-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its
variants have recently attracted attention for its high efficiency, existing
methods remain unsuitable for satellite images due to incompatibility with
rational polynomial coefficient (RPC) models and limited generalization
capability. Recent advances in generalizable 3DGS approaches show potential,
but they perform poorly on multi-temporal sparse satellite images due to
limited geometric constraints, transient objects, and radiometric
inconsistencies. To address these limitations, we propose SkySplat, a novel
self-supervised framework that integrates the RPC model into the generalizable
3DGS pipeline, enabling more effective use of sparse geometric cues for
improved reconstruction. SkySplat relies only on RGB images and
radiometric-robust relative height supervision, thereby eliminating the need
for ground-truth height maps. Key components include a Cross-Self Consistency
Module (CSCM), which mitigates transient object interference via
consistency-based masking, and a multi-view consistency aggregation strategy
that refines reconstruction results. Compared to per-scene optimization
methods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy.
It also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to
1.80 m on the DFC19 dataset significantly, and demonstrates strong
cross-dataset generalization on the MVS3D benchmark.

</details>


### [104] [Episodic Memory Representation for Long-form Video Understanding](https://arxiv.org/abs/2508.09486)
*Yun Wang,Long Zhang,Jingren Liu,Jiaqi Yan,Zhanjie Zhang,Jiahao Zheng,Xun Yang,Dapeng Wu,Xiangyu Chen,Xuelong Li*

Main category: cs.CV

TL;DR: Video-EM框架通过模拟人类情景记忆，解决了Video-LLMs在长视频理解中的关键帧冗余和时空关系缺失问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时，因关键帧检索忽略时空关系，导致信息冗余和场景连续性缺失，影响视频问答准确性。

Method: Video-EM将关键帧建模为时序情景事件，结合链式思维（CoT）迭代筛选最小但信息丰富的记忆子集。

Result: 在多个基准测试中，Video-EM性能提升4-9%，且使用更少帧数。

Conclusion: Video-EM通过时空建模和高效记忆筛选，显著提升了长视频理解的准确性和效率。

Abstract: Video Large Language Models (Video-LLMs) excel at general video understanding
but struggle with long-form videos due to context window limits. Consequently,
recent approaches focus on keyframe retrieval, condensing lengthy videos into a
small set of informative frames. Despite their practicality, these methods
simplify the problem to static text image matching, overlooking spatio temporal
relationships crucial for capturing scene transitions and contextual
continuity, and may yield redundant keyframes with limited information,
diluting salient cues essential for accurate video question answering. To
address these limitations, we introduce Video-EM, a training free framework
inspired by the principles of human episodic memory, designed to facilitate
robust and contextually grounded reasoning. Rather than treating keyframes as
isolated visual entities, Video-EM explicitly models them as temporally ordered
episodic events, capturing both spatial relationships and temporal dynamics
necessary for accurately reconstructing the underlying narrative. Furthermore,
the framework leverages chain of thought (CoT) thinking with LLMs to
iteratively identify a minimal yet highly informative subset of episodic
memories, enabling efficient and accurate question answering by Video-LLMs.
Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench
benchmarks confirm the superiority of Video-EM, which achieves highly
competitive results with performance gains of 4-9 percent over respective
baselines while utilizing fewer frames.

</details>


### [105] [SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection](https://arxiv.org/abs/2508.09487)
*Ju Yeon Kang,Jaehong Park,Semin Kim,Ji Won Yoon,Nam Soo Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为SARE的新方法，通过测量图像与其标题引导重建之间的语义差异，来检测扩散模型生成的假图像。该方法在跨模型检测中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在面对未见过的生成模型时性能下降，因为它们依赖模型特定的伪影。论文探索了假图像与标题相似性更高的共性。

Method: 提出SARE表示，量化图像与标题引导重建之间的语义差异，利用语义变化作为判别特征。

Result: SARE在GenImage和CommunityForensics基准测试中优于现有基线，表现出强泛化能力。

Conclusion: SARE通过语义差异检测假图像，具有跨模型鲁棒性，为扩散生成图像检测提供了新思路。

Abstract: Recently, diffusion-generated image detection has gained increasing
attention, as the rapid advancement of diffusion models has raised serious
concerns about their potential misuse. While existing detection methods have
achieved promising results, their performance often degrades significantly when
facing fake images from unseen, out-of-distribution (OOD) generative models,
since they primarily rely on model-specific artifacts. To address this
limitation, we explore a fundamental property commonly observed in fake images.
Motivated by the observation that fake images tend to exhibit higher similarity
to their captions than real images, we propose a novel representation, namely
Semantic-Aware Reconstruction Error (SARE), that measures the semantic
difference between an image and its caption-guided reconstruction. The
hypothesis behind SARE is that real images, whose captions often fail to fully
capture their complex visual content, may undergo noticeable semantic shifts
during the caption-guided reconstruction process. In contrast, fake images,
which closely align with their captions, show minimal semantic changes. By
quantifying these semantic shifts, SARE can be utilized as a discriminative
feature for robust detection across diverse generative models. We empirically
demonstrate that the proposed method exhibits strong generalization,
outperforming existing baselines on benchmarks including GenImage and
CommunityForensics.

</details>


### [106] [CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking](https://arxiv.org/abs/2508.09499)
*Liyan Jia,Chuan-Xian Ren,Hong Yan*

Main category: cs.CV

TL;DR: CWFBind是一种基于局部曲率特征的加权快速准确对接方法，通过整合几何信息提升蛋白质和配体的表示，并在消息传递中引入权重机制，解决了传统方法忽略几何信息的问题。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法依赖图表示和语言模型编码器，忽略了关键的几何信息，导致口袋定位和结合构象不准确。

Method: CWFBind在特征提取阶段整合局部曲率描述符，增强几何表示，并在消息传递中嵌入权重机制，同时采用动态半径策略和增强损失函数解决类别不平衡问题。

Result: CWFBind在多个对接基准测试中表现出色，实现了准确性和效率的平衡。

Conclusion: CWFBind通过几何信息增强和权重机制，显著提升了对接的准确性和效率，为理性药物设计提供了有力工具。

Abstract: Accurately predicting the binding conformation of small-molecule ligands to
protein targets is a critical step in rational drug design. Although recent
deep learning-based docking surpasses traditional methods in speed and
accuracy, many approaches rely on graph representations and language
model-inspired encoders while neglecting critical geometric information,
resulting in inaccurate pocket localization and unrealistic binding
conformations. In this study, we introduce CWFBind, a weighted, fast, and
accurate docking method based on local curvature features. Specifically, we
integrate local curvature descriptors during the feature extraction phase to
enrich the geometric representation of both proteins and ligands, complementing
existing chemical, sequence, and structural features. Furthermore, we embed
degree-aware weighting mechanisms into the message passing process, enhancing
the model's ability to capture spatial structural distinctions and interaction
strengths. To address the class imbalance challenge in pocket prediction,
CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced
loss function, facilitating more precise identification of binding regions and
key residues. Comprehensive experimental evaluations demonstrate that CWFBind
achieves competitive performance across multiple docking benchmarks, offering a
balanced trade-off between accuracy and efficiency.

</details>


### [107] [Generation of Indian Sign Language Letters, Numbers, and Words](https://arxiv.org/abs/2508.09522)
*Ajeet Kumar Yadav,Nishant Kumar,Rathna G N*

Main category: cs.CV

TL;DR: 论文提出了一种结合ProGAN和SAGAN的GAN变体，用于生成高质量、高分辨率的印度手语图像，并在IS和FID指标上优于传统ProGAN。


<details>
  <summary>Details</summary>
Motivation: 手语是聋哑人士的重要交流工具，但手语生成技术仍需探索，现有方法在分辨率和细节上存在不足。

Method: 结合ProGAN和SAGAN的优势，开发了一种改进的基于注意力的GAN模型，用于生成印度手语的字母、数字和单词图像。

Result: 新模型在IS和FID上分别提升了3.2和30.12，并发布了包含高质量印度手语图像的大规模数据集。

Conclusion: 提出的GAN变体在手语图像生成中表现出色，为聋哑人士的交流提供了更好的技术支持。

Abstract: Sign language, which contains hand movements, facial expressions and bodily
gestures, is a significant medium for communicating with hard-of-hearing
people. A well-trained sign language community communicates easily, but those
who don't know sign language face significant challenges. Recognition and
generation are basic communication methods between hearing and hard-of-hearing
individuals. Despite progress in recognition, sign language generation still
needs to be explored. The Progressive Growing of Generative Adversarial Network
(ProGAN) excels at producing high-quality images, while the Self-Attention
Generative Adversarial Network (SAGAN) generates feature-rich images at medium
resolutions. Balancing resolution and detail is crucial for sign language image
generation. We are developing a Generative Adversarial Network (GAN) variant
that combines both models to generate feature-rich, high-resolution, and
class-conditional sign language images. Our modified Attention-based model
generates high-quality images of Indian Sign Language letters, numbers, and
words, outperforming the traditional ProGAN in Inception Score (IS) and
Fr\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,
respectively. Additionally, we are publishing a large dataset incorporating
high-quality images of Indian Sign Language alphabets, numbers, and 129 words.

</details>


### [108] [COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets](https://arxiv.org/abs/2508.09886)
*Lingyu Chen,Yawen Zeng,Yue Wang,Peng Wan,Guo-chen Ning,Hongen Liao,Daoqiang Zhang,Fang Chen*

Main category: cs.CV

TL;DR: 论文提出了一种通用协作异构源特定专家混合模型（COME），用于解决超声图像分析中多数据集训练的挑战，通过双结构-语义共享专家和源特定专家的协作，实现了鲁棒的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统单数据集训练在新数据分布下表现不佳，尤其是在超声图像分析中，由于数据有限、声学阴影和斑点噪声等问题。因此，构建一个适用于多异构超声数据集的通用框架至关重要。

Method: COME通过建立双结构-语义共享专家，创建通用表示空间，并与源特定专家协作提取判别性特征。该方法利用跨数据集经验分布，为小批量或未见数据场景提供通用超声先验。

Result: 在三种评估模式（单数据集、器官内和器官间集成数据集）下的实验表明，COME显著优于现有方法，平均AP有明显提升。

Conclusion: COME通过协作异构源特定专家和共享专家，成功解决了多数据集训练中的干扰问题，实现了鲁棒的泛化性能，为超声图像分析提供了通用解决方案。

Abstract: Conventional single-dataset training often fails with new data distributions,
especially in ultrasound (US) image analysis due to limited data, acoustic
shadows, and speckle noise. Therefore, constructing a universal framework for
multi-heterogeneous US datasets is imperative. However, a key challenge arises:
how to effectively mitigate inter-dataset interference while preserving
dataset-specific discriminative features for robust downstream task? Previous
approaches utilize either a single source-specific decoder or a domain
adaptation strategy, but these methods experienced a decline in performance
when applied to other domains. Considering this, we propose a Universal
Collaborative Mixture of Heterogeneous Source-Specific Experts (COME).
Specifically, COME establishes dual structure-semantic shared experts that
create a universal representation space and then collaborate with
source-specific experts to extract discriminative features through providing
complementary features. This design enables robust generalization by leveraging
cross-datasets experience distributions and providing universal US priors for
small-batch or unseen data scenarios. Extensive experiments under three
evaluation modes (single-dataset, intra-organ, and inter-organ integration
datasets) demonstrate COME's superiority, achieving significant mean AP
improvements over state-of-the-art methods. Our project is available at:
https://universalcome.github.io/UniversalCOME/.

</details>


### [109] [SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking](https://arxiv.org/abs/2508.09524)
*Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao*

Main category: cs.CV

TL;DR: 论文首次系统研究并量化了单目标跟踪中的相似物体干扰（SOI），通过实验验证消除干扰源能显著提升性能，并构建了首个语义认知引导基准SOIBench。


<details>
  <summary>Details</summary>
Motivation: 相似物体干扰（SOI）是单目标跟踪中被忽视但关键的性能瓶颈，研究旨在验证其影响并提出解决方案。

Method: 通过在线干扰掩码（OIM）实验量化SOI影响，构建SOIBench基准，并利用大规模视觉语言模型（VLM）作为外部认知引擎。

Result: 消除干扰源显著提升跟踪性能（AUC增益达4.35），现有视觉语言跟踪方法效果有限，而VLM方法表现优异（AUC增益达0.93）。

Conclusion: SOIBench为语义认知跟踪研究提供了标准化平台，VLM方法显著优于现有技术，为跟踪领域带来新见解。

Abstract: In this paper, we present the first systematic investigation and
quantification of Similar Object Interference (SOI), a long-overlooked yet
critical bottleneck in Single Object Tracking (SOT). Through controlled Online
Interference Masking (OIM) experiments, we quantitatively demonstrate that
eliminating interference sources leads to substantial performance improvements
(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a
primary constraint for robust tracking and highlighting the feasibility of
external cognitive guidance. Building upon these insights, we adopt natural
language as a practical form of external guidance, and construct SOIBench-the
first semantic cognitive guidance benchmark specifically targeting SOI
challenges. It automatically mines SOI frames through multi-tracker collective
judgment and introduces a multi-level annotation protocol to generate precise
semantic guidance texts. Systematic evaluation on SOIBench reveals a striking
finding: existing vision-language tracking (VLT) methods fail to effectively
exploit semantic cognitive guidance, achieving only marginal improvements or
even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we
propose a novel paradigm employing large-scale vision-language models (VLM) as
external cognitive engines that can be seamlessly integrated into arbitrary RGB
trackers. This approach demonstrates substantial improvements under semantic
cognitive guidance (AUC gains up to 0.93), representing a significant
advancement over existing VLT methods. We hope SOIBench will serve as a
standardized evaluation platform to advance semantic cognitive tracking
research and contribute new insights to the tracking research community.

</details>


### [110] [Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation](https://arxiv.org/abs/2508.09987)
*Junyan Ye,Dongzhi Jiang,Zihao Wang,Leqi Zhu,Zhenghao Hu,Zilong Huang,Jun He,Zhiyuan Yan,Jinghua Yu,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 论文探讨了GPT-4o生成的合成图像数据在补充真实数据不足和提供更清晰监督信号方面的优势，并提出了Echo-4o-Image数据集和两个新评估基准。


<details>
  <summary>Details</summary>
Motivation: 开源模型在图像生成上落后于GPT-4o，而真实数据存在噪声和对齐问题，合成数据能弥补这些不足。

Method: 利用GPT-4o生成180K规模的合成数据集Echo-4o-Image，并基于此微调Bagel模型，同时提出GenEval++和Imagine-Bench两个新评估基准。

Result: Echo-4o在标准基准上表现优异，且合成数据集对其他基础模型也带来性能提升。

Conclusion: 合成数据能有效补充真实数据的盲点，提升模型性能，具有广泛适用性。

Abstract: Recently, GPT-4o has garnered significant attention for its strong
performance in image generation, yet open-source models still lag behind.
Several studies have explored distilling image data from GPT-4o to enhance
open-source models, achieving notable progress. However, a key question
remains: given that real-world image datasets already constitute a natural
source of high-quality data, why should we use GPT-4o-generated synthetic data?
In this work, we identify two key advantages of synthetic images. First, they
can complement rare scenarios in real-world datasets, such as surreal fantasy
or multi-reference image generation, which frequently occur in user queries.
Second, they provide clean and controllable supervision. Real-world data often
contains complex background noise and inherent misalignment between text
descriptions and image content, whereas synthetic images offer pure backgrounds
and long-tailed supervision signals, facilitating more accurate text-to-image
alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale
synthetic dataset generated by GPT-4o, harnessing the power of synthetic image
data to address blind spots in real-world coverage. Using this dataset, we
fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.
In addition, we propose two new evaluation benchmarks for a more accurate and
challenging assessment of image generation capabilities: GenEval++, which
increases instruction complexity to mitigate score saturation, and
Imagine-Bench, which focuses on evaluating both the understanding and
generation of imaginative content. Echo-4o demonstrates strong performance
across standard benchmarks. Moreover, applying Echo-4o-Image to other
foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains
across multiple metrics, highlighting the datasets strong transferability.

</details>


### [111] [Learning Spatial Decay for Vision Transformers](https://arxiv.org/abs/2508.09525)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: 论文提出了Spatial Decay Transformer (SDT)，通过Context-Aware Gating (CAG)机制动态调整空间注意力，解决了ViTs在空间结构任务中的性能问题。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers (ViTs)的自注意力机制缺乏显式的空间归纳偏差，导致在空间结构任务中表现不佳。现有方法使用固定的距离度量引入空间衰减，缺乏对图像内容的适应性。

Method: 提出SDT，采用CAG机制生成动态、数据依赖的衰减，结合曼哈顿距离的空间先验和学习到的内容表示。

Result: 在ImageNet-1K分类和生成任务中表现优于基线模型。

Conclusion: SDT为增强ViTs的空间注意力提供了新范式。

Abstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their
self-attention mechanism lacks explicit spatial inductive biases, leading to
suboptimal performance on spatially-structured tasks. Existing approaches
introduce data-independent spatial decay based on fixed distance metrics,
applying uniform attention weighting regardless of image content and limiting
adaptability to diverse visual scenarios. Inspired by recent advances in large
language models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX)
significantly outperform static alternatives, we present the first successful
adaptation of data-dependent spatial decay to 2D vision transformers. We
introduce \textbf{Spatial Decay Transformer (SDT)}, featuring a novel
Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent
decay for patch interactions. Our approach learns to modulate spatial attention
based on both content relevance and spatial proximity. We address the
fundamental challenge of 1D-to-2D adaptation through a unified spatial-content
fusion framework that integrates manhattan distance-based spatial priors with
learned content representations. Extensive experiments on ImageNet-1K
classification and generation tasks demonstrate consistent improvements over
strong baselines. Our work establishes data-dependent spatial decay as a new
paradigm for enhancing spatial attention in vision transformers.

</details>


### [112] [Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing](https://arxiv.org/abs/2508.09528)
*Gang Qu,Ping Wang,Siming Zheng,Xin Yuan*

Main category: cs.CV

TL;DR: 该论文提出了一种新的非对称Kronecker压缩感知（AKCS）模型和测量感知交叉注意力机制（MACA），以解决现有方法在测量不相关性和隐式测量表示方面的不足，并构建了MEUNet网络，在重建精度和推理速度上达到最优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图像压缩感知任务中，测量阶段缺乏不相关性和重建阶段缺乏显式测量表示，限制了整体性能。

Method: 提出AKCS模型提高测量不相关性，并通过MACA机制学习隐式测量表示，结合到展开网络中构建MEUNet。

Result: MEUNet在重建精度和推理速度上达到最优性能。

Conclusion: AKCS和MACA的结合显著提升了压缩感知任务的性能。

Abstract: Deep networks have achieved remarkable success in image compressed sensing
(CS) task, namely reconstructing a high-fidelity image from its compressed
measurement. However, existing works are deficient inincoherent compressed
measurement at sensing phase and implicit measurement representations at
reconstruction phase, limiting the overall performance. In this work, we answer
two questions: 1) how to improve the measurement incoherence for decreasing the
ill-posedness; 2) how to learn informative representations from measurements.
To this end, we propose a novel asymmetric Kronecker CS (AKCS) model and
theoretically present its better incoherence than previous Kronecker CS with
minimal complexity increase. Moreover, we reveal that the unfolding networks'
superiority over non-unfolding ones result from sufficient gradient descents,
called explicit measurement representations. We propose a measurement-aware
cross attention (MACA) mechanism to learn implicit measurement representations.
We integrate AKCS and MACA into widely-used unfolding architecture to get a
measurement-enhanced unfolding network (MEUNet). Extensive experiences
demonstrate that our MEUNet achieves state-of-the-art performance in
reconstruction accuracy and inference speed.

</details>


### [113] [COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection](https://arxiv.org/abs/2508.09533)
*Peiran Peng,Tingfa Xu,Liqiang Song,Mengqi Zhu,Yuqiang Fang,Jianan Li*

Main category: cs.CV

TL;DR: COXNet是一种用于RGBT微小目标检测的新框架，通过跨层融合、动态对齐和优化标签分配策略，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态RGBT图像中微小目标检测的挑战，尤其是在无人机场景下的空间错位、低光照和复杂背景问题。

Method: 提出三个核心创新：跨层融合模块、动态对齐与尺度细化模块，以及基于GeoShape相似度度量的优化标签分配策略。

Result: 在RGBTDronePerson数据集上，mAP$_{50}$提高了3.32%，优于现有方法。

Conclusion: COXNet在复杂环境中表现出色，为RGBT微小目标检测提供了有效解决方案。

Abstract: Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is
a critical challenge in computer vision, particularly in surveillance, search
and rescue, and autonomous navigation. Drone-based scenarios exacerbate these
challenges due to spatial misalignment, low-light conditions, occlusion, and
cluttered backgrounds. Current methods struggle to leverage the complementary
information between visible and thermal modalities effectively. We propose
COXNet, a novel framework for RGBT tiny object detection, addressing these
issues through three core innovations: i) the Cross-Layer Fusion Module, fusing
high-level visible and low-level thermal features for enhanced semantic and
spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module,
correcting cross-modal spatial misalignments and preserving multi-scale
features; and iii) an optimized label assignment strategy using the GeoShape
Similarity Measure for better localization. COXNet achieves a 3.32\% mAP$_{50}$
improvement on the RGBTDronePerson dataset over state-of-the-art methods,
demonstrating its effectiveness for robust detection in complex environments.

</details>


### [114] [Iterative Volume Fusion for Asymmetric Stereo Matching](https://arxiv.org/abs/2508.09543)
*Yuanting Gao,Linghao Shen*

Main category: cs.CV

TL;DR: 论文提出了一种针对非对称立体视觉的两阶段迭代体积融合网络（IVF-AStereo），通过结合两种成本体积构建方法，解决了视觉不对称对立体匹配的干扰。


<details>
  <summary>Details</summary>
Motivation: 传统立体匹配算法假设双目视觉对称，但非对称多相机系统（如广角-长焦相机）的兴起打破了这一假设，导致匹配困难。视觉不对称会影响成本体积计算，从而干扰立体匹配。

Method: 研究分析了两种成本体积构建方法在非对称立体中的匹配成本分布，发现两者存在不同的信息失真。基于此，提出了IVF-AStereo网络，先通过聚合拼接体积优化相关体积，再将两者融合以增强细节。

Result: 实验表明，IVF-AStereo在非对称场景中表现优异，对显著的视觉不对称具有鲁棒性。

Conclusion: 该方法有效解决了分辨率与颜色退化下的非对称立体匹配问题。

Abstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming
symmetric visual properties between binocular visions. However, the rise of
asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this
assumption and complicates stereo matching. Visual asymmetry disrupts stereo
matching by affecting the crucial cost volume computation. To address this, we
explore the matching cost distribution of two established cost volume
construction methods in asymmetric stereo. We find that each cost volume
experiences distinct information distortion, indicating that both should be
comprehensively utilized to solve the issue. Based on this, we propose the
two-phase Iterative Volume Fusion network for Asymmetric Stereo matching
(IVF-AStereo). Initially, the aggregated concatenation volume refines the
correlation volume. Subsequently, both volumes are fused to enhance fine
details. Our method excels in asymmetric scenarios and shows robust performance
against significant visual asymmetry. Extensive comparative experiments on
benchmark datasets, along with ablation studies, confirm the effectiveness of
our approach in asymmetric stereo with resolution and color degradation.

</details>


### [115] [GoViG: Goal-Conditioned Visual Navigation Instruction Generation](https://arxiv.org/abs/2508.09547)
*Fengyi Wu,Yifei Dong,Zhi-Qi Cheng,Yilong Dai,Guangyu Chen,Hang Wang,Qi Dai,Alexander G. Hauptmann*

Main category: cs.CV

TL;DR: GoViG是一种新任务，通过原始视觉数据生成导航指令，无需结构化输入，提高了适应性。方法包括视觉预测和指令生成，结合多模态大语言模型和推理策略，在R2R-Goal数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖结构化输入（如语义标注或地图），限制了在未知和非结构化环境中的适应性。GoViG旨在仅通过视觉数据生成精确导航指令。

Method: 任务分解为视觉预测（预测中间状态）和指令生成（合成语言指令），结合多模态大语言模型和两种推理策略（一过式和交替式）。

Result: 在R2R-Goal数据集上，BLEU-4和CIDEr分数显著优于现有方法，并展示了跨域泛化能力。

Conclusion: GoViG通过纯视觉数据和多模态模型，实现了高适应性和精确的导航指令生成，为未知环境导航提供了新思路。

Abstract: We introduce Goal-Conditioned Visual Navigation Instruction Generation
(GoViG), a new task that aims to autonomously generate precise and contextually
coherent navigation instructions solely from egocentric visual observations of
initial and goal states. Unlike conventional approaches that rely on structured
inputs such as semantic annotations or environmental maps, GoViG exclusively
leverages raw egocentric visual data, substantially improving its adaptability
to unseen and unstructured environments. Our method addresses this task by
decomposing it into two interconnected subtasks: (1) visual forecasting, which
predicts intermediate visual states bridging the initial and goal views; and
(2) instruction generation, which synthesizes linguistically coherent
instructions grounded in both observed and anticipated visuals. These subtasks
are integrated within an autoregressive multimodal large language model trained
with tailored objectives to ensure spatial accuracy and linguistic clarity.
Furthermore, we introduce two complementary multimodal reasoning strategies,
one-pass and interleaved reasoning, to mimic incremental human cognitive
processes during navigation. To evaluate our method, we propose the R2R-Goal
dataset, combining diverse synthetic and real-world trajectories. Empirical
results demonstrate significant improvements over state-of-the-art methods,
achieving superior BLEU-4 and CIDEr scores along with robust cross-domain
generalization.

</details>


### [116] [Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification](https://arxiv.org/abs/2508.09550)
*Haowen Wang,Guowei Zhang,Xiang Zhang,Zeyuan Chen,Haiyang Xu,Dou Hoon Kwark,Zhuowen Tu*

Main category: cs.CV

TL;DR: 研究探讨了在图像分类任务中，使用生成模型生成的合成数据增强训练集的效果，并量化了合成数据与真实数据在增强中的等价性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习中一个关键问题：如何利用生成模型生成的合成数据增强图像分类任务的性能。

Method: 通过实验比较真实图像与生成模型生成的合成图像，系统分析了合成数据增强的有效性，并量化了合成数据与真实数据在增强中的等价性。

Result: 研究表明，合成数据增强可以提升分类性能，但需要更大规模的合成数据才能达到与真实数据增强相当的效果。

Conclusion: 合成数据增强在图像分类中具有潜力，但需量化其规模以实现与真实数据增强的等价效果。

Abstract: In this paper, we address a key scientific problem in machine learning: Given
a training set for an image classification task, can we train a generative
model on this dataset to enhance the classification performance? (i.e.,
closed-set generative data augmentation). We start by exploring the
distinctions and similarities between real images and closed-set synthetic
images generated by advanced generative models. Through extensive experiments,
we offer systematic insights into the effective use of closed-set synthetic
data for augmentation. Notably, we empirically determine the equivalent scale
of synthetic images needed for augmentation. In addition, we also show
quantitative equivalence between the real data augmentation and open-set
generative augmentation (generative models trained using data beyond the given
training set). While it aligns with the common intuition that real images are
generally preferred, our empirical formulation also offers a guideline to
quantify the increased scale of synthetic data augmentation required to achieve
comparable image classification performance. Our results on natural and medical
image datasets further illustrate how this effect varies with the baseline
training set size and the amount of synthetic data incorporated.

</details>


### [117] [Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning](https://arxiv.org/abs/2508.09555)
*Ahmet Öztel,İsmet Karaca*

Main category: cs.CV

TL;DR: 该研究提出了一种基于2D虹膜图像拓扑不变量的生物识别方法，通过数字同调理论表示虹膜纹理，并评估分类性能。


<details>
  <summary>Details</summary>
Motivation: 探索一种紧凑、可解释且准确的虹膜识别方法，作为深度学习的替代方案，适用于需要可解释性或数据有限的场景。

Method: 将归一化的虹膜图像划分为网格，计算每个子区域的Betti0、Betti1及其比率，形成特征矩阵，结合逻辑回归、KNN和SVM进行分类，并与CNN进行比较。

Result: 逻辑回归的准确率为97.78 +/- 0.82%，优于CNN（96.44 +/- 1.32%）和其他基于特征的模型，拓扑特征表现出高准确性和低方差。

Conclusion: 这是首次将数字同调理论的拓扑不变量用于虹膜识别，该方法在可解释性、效率和适用性方面具有优势，可扩展至其他领域。

Abstract: Objective - This study presents a biometric identification method based on
topological invariants from 2D iris images, representing iris texture via
formally defined digital homology and evaluating classification performance.
  Methods - Each normalized iris image (48x482 pixels) is divided into grids
(e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their
ratio using a recent algorithm for homology groups in 2D digital images. The
resulting invariants form a feature matrix used with logistic regression, KNN,
and SVM (with PCA and 100 randomized repetitions). A convolutional neural
network (CNN) is trained on raw images for comparison.
  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy,
outperforming CNN (96.44 +/- 1.32%) and other feature-based models. The
topological features showed high accuracy with low variance.
  Conclusion - This is the first use of topological invariants from formal
digital homology for iris recognition. The method offers a compact,
interpretable, and accurate alternative to deep learning, useful when
explainability or limited data is important. Beyond iris recognition, it can
apply to other biometrics, medical imaging, materials science, remote sensing,
and interpretable AI. It runs efficiently on CPU-only systems and produces
robust, explainable features valuable for security-critical domains.

</details>


### [118] [Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma](https://arxiv.org/abs/2508.09593)
*Haotian Tang,Jianwei Chen,Xinrui Tang,Yunjia Wu,Zhengyang Miao,Chao Li*

Main category: cs.CV

TL;DR: Hi-SMGNN是一种分层框架，整合结构和形态连接组，通过多模态交互和多尺度特征融合提升IDH突变预测效果。


<details>
  <summary>Details</summary>
Motivation: 当前预测方法受限于功能MRI的低可用性和噪声，而结构和形态连接组提供了一种非侵入性替代方案，但忽略了大脑的层次结构和多尺度交互。

Method: 提出Hi-SMGNN框架，包括多模态交互模块（Siamese网络和跨模态注意力）、多尺度特征融合机制和个性化模块分区策略。

Result: 在UCSF-PDGM数据集上，Hi-SMGNN优于基线模型和现有先进模型，表现出更高的鲁棒性和有效性。

Conclusion: Hi-SMGNN通过分层和多尺度整合，显著提升了IDH突变预测的性能和可解释性。

Abstract: Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for
glioma prognosis. However, current prediction methods are limited by the low
availability and noise of functional MRI. Structural and morphological
connectomes offer a non-invasive alternative, yet existing approaches often
ignore the brain's hierarchical organisation and multiscale interactions. To
address this, we propose Hi-SMGNN, a hierarchical framework that integrates
structural and morphological connectomes from regional to modular levels. It
features a multimodal interaction module with a Siamese network and cross-modal
attention, a multiscale feature fusion mechanism for reducing redundancy, and a
personalised modular partitioning strategy to enhance individual specificity
and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that
Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved
robustness and effectiveness in IDH mutation prediction.

</details>


### [119] [WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization](https://arxiv.org/abs/2508.09560)
*Jiahao Wen,Hang Yu,Zhedong Zheng*

Main category: cs.CV

TL;DR: WeatherPrompt提出了一种多模态学习框架，通过融合图像嵌入与文本上下文，建立天气不变的表示，解决了无人机视觉地理定位在天气扰动下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在天气扰动（如雨、雾）下性能显著下降，主要受限于对有限天气类别的依赖以及场景-天气特征解耦不足。

Method: WeatherPrompt结合训练免费的天气推理机制和多模态动态门控机制，通过文本嵌入自适应地重新加权和融合视觉特征，并利用跨模态目标优化框架。

Result: 在多样天气条件下，该方法在无人机地理定位中表现出色，Recall@1在夜间条件下提升13.37%，在雾和雪条件下提升18.69%。

Conclusion: WeatherPrompt通过多模态学习和动态特征解耦，显著提升了无人机在复杂天气条件下的地理定位性能。

Abstract: Visual geo-localization for drones faces critical degradation under weather
perturbations, \eg, rain and fog, where existing methods struggle with two
inherent limitations: 1) Heavy reliance on limited weather categories that
constrain generalization, and 2) Suboptimal disentanglement of entangled
scene-weather features through pseudo weather categories. We present
WeatherPrompt, a multi-modality learning paradigm that establishes
weather-invariant representations through fusing the image embedding with the
text context. Our framework introduces two key contributions: First, a
Training-free Weather Reasoning mechanism that employs off-the-shelf large
multi-modality models to synthesize multi-weather textual descriptions through
human-like reasoning. It improves the scalability to unseen or complex weather,
and could reflect different weather strength. Second, to better disentangle the
scene and weather feature, we propose a multi-modality framework with the
dynamic gating mechanism driven by the text embedding to adaptively reweight
and fuse visual features across modalities. The framework is further optimized
by the cross-modal objectives, including image-text contrastive learning and
image-text matching, which maps the same scene with different weather
conditions closer in the respresentation space. Extensive experiments validate
that, under diverse weather conditions, our method achieves competitive recall
rates compared to state-of-the-art drone geo-localization methods. Notably, it
improves Recall@1 by +13.37\% under night conditions and by 18.69\% under fog
and snow conditions.

</details>


### [120] [WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description](https://arxiv.org/abs/2508.09565)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于小波的曝光校正方法（WEC-DG），通过退化描述符和小波变换解决现有方法在复杂光照条件下的适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 当前多曝光校正方法在处理单一曝光图像时，难以应对由不同光照、环境和天气因素引起的类内变异性，导致曝光异常。

Method: 在曝光一致性对齐模块（ECAM）中引入退化描述符，确保曝光一致性；利用小波变换的光-细节解耦特性设计曝光恢复与细节重建模块（EDRM）。

Result: 在多个公开数据集上的实验表明，该方法显著优于现有算法，性能提升明显。

Conclusion: WEC-DG方法有效解决了曝光异常和细节恢复问题，具有实际应用价值。

Abstract: Multi-exposure correction technology is essential for restoring images
affected by insufficient or excessive lighting, enhancing the visual experience
by improving brightness, contrast, and detail richness. However, current
multi-exposure correction methods often encounter challenges in addressing
intra-class variability caused by diverse lighting conditions, shooting
environments, and weather factors, particularly when processing images captured
at a single exposure level. To enhance the adaptability of these models under
complex imaging conditions, this paper proposes a Wavelet-based Exposure
Correction method with Degradation Guidance (WEC-DG). Specifically, we
introduce a degradation descriptor within the Exposure Consistency Alignment
Module (ECAM) at both ends of the processing pipeline to ensure exposure
consistency and achieve final alignment. This mechanism effectively addresses
miscorrected exposure anomalies caused by existing methods' failure to
recognize 'blurred' exposure degradation. Additionally, we investigate the
light-detail decoupling properties of the wavelet transform to design the
Exposure Restoration and Detail Reconstruction Module (EDRM), which processes
low-frequency information related to exposure enhancement before utilizing
high-frequency information as a prior guide for reconstructing spatial domain
details. This serial processing strategy guarantees precise light correction
and enhances detail recovery. Extensive experiments conducted on multiple
public datasets demonstrate that the proposed method outperforms existing
algorithms, achieving significant performance improvements and validating its
effectiveness and practical applicability.

</details>


### [121] [MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography](https://arxiv.org/abs/2508.09616)
*Daniel Barco,Marc Stadelmann,Martin Oswald,Ivo Herzig,Lukas Lichtensteiger,Pascal Paysan,Igor Peterlik,Michal Walczak,Bjoern Menze,Frank-Peter Schilling*

Main category: cs.CV

TL;DR: MInDI-3D是一种基于3D条件扩散的模型，用于稀疏视图CBCT伪影去除，显著降低辐射暴露。


<details>
  <summary>Details</summary>
Motivation: 减少医学成像中的辐射暴露，同时提高稀疏视图CBCT图像质量。

Method: 将InDI概念从2D扩展到3D，通过迭代去噪直接从稀疏视图输入优化CBCT体积，并使用大规模伪CBCT数据集训练模型。

Result: 在CT-RATE测试集上，PSNR增益达12.96 dB，辐射暴露减少8倍，性能与3D U-Net相当，并适应新CBCT扫描仪几何。

Conclusion: MInDI-3D在临床评估中表现优异，适用于患者定位并保留肿瘤边界，具有实际应用潜力。

Abstract: We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first
3D conditional diffusion-based model for real-world sparse-view Cone Beam
Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation
exposure. A key contribution is extending the "InDI" concept from 2D to a full
3D volumetric approach for medical images, implementing an iterative denoising
process that refines the CBCT volume directly from sparse-view input. A further
contribution is the generation of a large pseudo-CBCT dataset (16,182) from
chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We
performed a comprehensive evaluation, including quantitative metrics,
scalability analysis, generalisation tests, and a clinical assessment by 11
clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10)
dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE
pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in
imaging radiation exposure. We demonstrate its scalability by showing that
performance improves with more training data. Importantly, MInDI-3D matches the
performance of a 3D U-Net on real-world scans from 16 cancer patients across
distortion and task-based metrics. It also generalises to new CBCT scanner
geometries. Clinicians rated our model as sufficient for patient positioning
across all anatomical sites and found it preserved lung tumour boundaries well.

</details>


### [122] [A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation](https://arxiv.org/abs/2508.09566)
*Haibo Jin,Haoxuan Che,Sunan He,Hao Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为诊断链（CoD）的框架，旨在解决放射学报告生成（RRG）中的临床效果不佳和可解释性不足问题。通过生成问答对、利用大语言模型和设计诊断与病灶定位模块，CoD提高了报告的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有放射学报告生成模型在临床效果和可解释性方面表现不佳，尤其是对病灶属性的描述。作者希望开发一个可信赖的RRG模型，既能准确描述异常，又能提供预测依据。

Method: 提出诊断链（CoD）框架，包括生成问答对提取关键发现、利用大语言模型生成报告、设计诊断和病灶定位模块增强可解释性。采用全监督学习策略利用多种标注数据。

Result: CoD在两个RRG基准测试中表现优于专家和通用模型，能准确将生成的句子与问答诊断和图像关联，展示了良好的可解释性。

Conclusion: CoD框架通过结合诊断链和病灶定位，显著提升了放射学报告生成的准确性和可解释性，为临床实践提供了更高效的工具。

Abstract: Despite the progress of radiology report generation (RRG), existing works
face two challenges: 1) The performances in clinical efficacy are
unsatisfactory, especially for lesion attributes description; 2) the generated
text lacks explainability, making it difficult for radiologists to trust the
results. To address the challenges, we focus on a trustworthy RRG model, which
not only generates accurate descriptions of abnormalities, but also provides
basis of its predictions. To this end, we propose a framework named chain of
diagnosis (CoD), which maintains a chain of diagnostic process for clinically
accurate and explainable RRG. It first generates question-answer (QA) pairs via
diagnostic conversation to extract key findings, then prompts a large language
model with QA diagnoses for accurate generation. To enhance explainability, a
diagnosis grounding module is designed to match QA diagnoses and generated
sentences, where the diagnoses act as a reference. Moreover, a lesion grounding
module is designed to locate abnormalities in the image, further improving the
working efficiency of radiologists. To facilitate label-efficient training, we
propose an omni-supervised learning strategy with clinical consistency to
leverage various types of annotations from different datasets. Our efforts lead
to 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a
evaluation tool for assessing the accuracy of reports in describing lesion
location and severity; 3) extensive experiments to demonstrate the
effectiveness of CoD, where it outperforms both specialist and generalist
models consistently on two RRG benchmarks and shows promising explainability by
accurately grounding generated sentences to QA diagnoses and images.

</details>


### [123] [Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion](https://arxiv.org/abs/2508.09575)
*Jiwon Kim,Pureum Kim,SeonHwa Kim,Soobin Park,Eunju Cha,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: 提出了一种无需训练的双递归反馈（DRF）系统，用于改进可控文本到图像（T2I）扩散模型的空间和外观控制。


<details>
  <summary>Details</summary>
Motivation: 现有模型（如Ctrl-X和FreeControl）在保持空间结构和捕捉细粒度条件（如物体姿态和场景布局）方面表现不佳。

Method: 通过外观反馈和生成反馈的双递归机制，优化中间潜在表示，以更好地反映外观信息和用户意图。

Result: 实验证明，该方法能生成高质量、语义一致且结构一致的图像，甚至支持类不变的结构-外观融合（如将人类动作转移到老虎形态）。

Conclusion: DRF系统有效解决了现有模型在空间和外观控制上的不足，为可控T2I模型提供了更精细的生成能力。

Abstract: Recent advancements in controllable text-to-image (T2I) diffusion models,
such as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance
control without requiring auxiliary module training. However, these models
often struggle to accurately preserve spatial structures and fail to capture
fine-grained conditions related to object poses and scene layouts. To address
these challenges, we propose a training-free Dual Recursive Feedback (DRF)
system that properly reflects control conditions in controllable T2I models.
The proposed DRF consists of appearance feedback and generation feedback that
recursively refines the intermediate latents to better reflect the given
appearance information and the user's intent. This dual-update mechanism guides
latent representations toward reliable manifolds, effectively integrating
structural and appearance attributes. Our approach enables fine-grained
generation even between class-invariant structure-appearance fusion, such as
transferring human motion onto a tiger's form. Extensive experiments
demonstrate the efficacy of our method in producing high-quality, semantically
coherent, and structurally consistent image generations. Our source code is
available at https://github.com/jwonkm/DRF.

</details>


### [124] [Preacher: Paper-to-Video Agentic System](https://arxiv.org/abs/2508.09632)
*Jingwei Liu,Ling Yang,Hao Luo,Fan Wang Hongyan Li,Mengdi Wang*

Main category: cs.CV

TL;DR: 论文提出Preacher系统，将研究论文转化为结构化视频摘要，解决现有视频生成模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型存在上下文窗口有限、视频时长固定、风格单一及无法表达领域知识等问题。

Method: 采用自上而下分解、总结和重构论文，再自下而上生成视频，结合P-CoT进行迭代规划。

Result: Preacher在五个研究领域成功生成高质量视频摘要，表现优于现有模型。

Conclusion: Preacher系统为论文到视频任务提供了高效解决方案，代码将开源。

Abstract: The paper-to-video task converts a research paper into a structured video
abstract, distilling key concepts, methods, and conclusions into an accessible,
well-organized format. While state-of-the-art video generation models
demonstrate potential, they are constrained by limited context windows, rigid
video duration constraints, limited stylistic diversity, and an inability to
represent domain-specific knowledge. To address these limitations, we introduce
Preacher, the first paper-to-video agentic system. Preacher employs a top-down
approach to decompose, summarize, and reformulate the paper, followed by
bottom-up video generation, synthesizing diverse video segments into a coherent
abstract. To align cross-modal representations, we define key scenes and
introduce a Progressive Chain of Thought (P-CoT) for granular, iterative
planning. Preacher successfully generates high-quality video abstracts across
five research fields, demonstrating expertise beyond current video generation
models. Code will be released at: https://github.com/GenVerse/Paper2Video

</details>


### [125] [SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs](https://arxiv.org/abs/2508.09584)
*Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: 论文提出了一种自动化数据构建流程和分层幻觉诱导框架，构建了SHALE基准，用于细粒度评估大型视觉语言模型的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）存在幻觉问题，现有研究评估粗糙且缺乏细粒度分析，数据构建成本高且易泄露。

Method: 提出自动化数据构建流程和分层幻觉诱导框架，构建SHALE基准，包含30K图像-指令对，覆盖12个视觉感知方面和6个知识领域。

Result: 实验显示主流LVLMs存在显著的事实性幻觉，并对语义扰动高度敏感。

Conclusion: SHALE基准为评估LVLMs的幻觉问题提供了可扩展、可控且多样的解决方案。

Abstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer
from hallucinations, i.e., generating content inconsistent with input or
established world knowledge, which correspond to faithfulness and factuality
hallucinations, respectively. Prior studies primarily evaluate faithfulness
hallucination at a coarse level (e.g., object-level) and lack fine-grained
analysis. Additionally, existing benchmarks rely on costly manual curation or
reused public datasets, raising concerns about scalability and data leakage. To
address these limitations, we propose an automated data construction pipeline
that produces scalable, controllable, and diverse evaluation data. We also
design a hierarchical hallucination induction framework with input
perturbations to simulate realistic noisy scenarios. Integrating these designs,
we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to
assess both faithfulness and factuality hallucinations via a fine-grained
hallucination categorization scheme. SHALE comprises over 30K image-instruction
pairs spanning 12 representative visual perception aspects for faithfulness and
6 knowledge domains for factuality, considering both clean and noisy scenarios.
Extensive experiments on over 20 mainstream LVLMs reveal significant factuality
hallucinations and high sensitivity to semantic perturbations.

</details>


### [126] [Offline Auto Labeling: BAAS](https://arxiv.org/abs/2508.09585)
*Stefan Haag,Bharanidhar Duraisamy,Felix Govaers,Wolfgang Koch,Martin Fritzsche,Juergen Dickmann*

Main category: cs.CV

TL;DR: BAAS是一个基于贝叶斯跟踪和融合的雷达检测标注框架，用于自动驾驶中的扩展目标跟踪，提供精确的轨迹和形状估计，支持多级监督标注和性能评估。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中雷达检测的扩展目标跟踪和标注问题，提供高精度轨迹和形状估计，支持闭环改进。

Method: 利用贝叶斯跟踪、平滑和融合方法，结合多级监督标注，独立或联合分析各模块。

Result: 在复杂城市场景中验证了框架的跟踪性能和标注误差，适用于多种动态目标和类别。

Conclusion: BAAS框架有效提升了雷达检测的跟踪和标注精度，支持闭环改进，适用于自动驾驶应用。

Abstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and
fusion-based label annotation framework for radar detections in autonomous
driving. Our framework utilizes Bayesian-based tracking, smoothing and
eventually fusion methods to provide veritable and precise object trajectories
along with shape estimation to provide annotation labels on the detection level
under various supervision levels. Simultaneously, the framework provides
evaluation of tracking performance and label annotation. If manually labeled
data is available, each processing module can be analyzed independently or
combined with other modules to enable closed-loop continuous improvements. The
framework performance is evaluated in a challenging urban real-world scenario
in terms of tracking performance and the label annotation errors. We
demonstrate the functionality of the proposed approach for varying dynamic
objects and class types

</details>


### [127] [Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision](https://arxiv.org/abs/2508.09681)
*Gerardo Loza,Junlei Hu,Dominic Jones,Sharib Ali,Pietro Valdastri*

Main category: cs.CV

TL;DR: 提出了一种基于NeRF的新型测试时优化（TTO）方法，用于长期3D点跟踪，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前点跟踪方法在长期一致性或3D跟踪方面存在不足，需要更高效的解决方案。

Method: 使用可逆神经辐射场（InvNeRF）架构，结合多尺度HexPlanes和高效像素采样算法，实现2D和3D跟踪。

Result: 在2D跟踪中，平均精度提升近50%；在3D跟踪中，首次实现TTO方法，优于前馈方法。

Conclusion: 该方法在手术场景中表现出色，结合了可变形NeRF的优势，为点跟踪提供了新思路。

Abstract: We proposed a novel test-time optimisation (TTO) approach framed by a
NeRF-based architecture for long-term 3D point tracking. Most current methods
in point tracking struggle to obtain consistent motion or are limited to 2D
motion. TTO approaches frame the solution for long-term tracking as optimising
a function that aggregates correspondences from other specialised
state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose
parametrising such a function with our new invertible Neural Radiance Field
(InvNeRF) architecture to perform both 2D and 3D tracking in surgical
scenarios. Our approach allows us to exploit the advantages of a
rendering-based approach by supervising the reprojection of pixel
correspondences. It adapts strategies from recent rendering-based methods to
obtain a bidirectional deformable-canonical mapping, to efficiently handle a
defined workspace, and to guide the rays' density. It also presents our
multi-scale HexPlanes for fast inference and a new algorithm for efficient
pixel sampling and convergence criteria. We present results in the STIR and
SCARE datasets, for evaluating point tracking and testing the integration of
kinematic data in our pipeline, respectively. In 2D point tracking, our
approach surpasses the precision and accuracy of the TTO state-of-the-art
methods by nearly 50% on average precision, while competing with other
approaches. In 3D point tracking, this is the first TTO approach, surpassing
feed-forward methods while incorporating the benefits of a deformable
NeRF-based reconstruction.

</details>


### [128] [SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing](https://arxiv.org/abs/2508.09597)
*Heyi Sun,Cong Wang,Tian-Xing Xu,Jingwei Huang,Di Kang,Chunchao Guo,Song-Hai Zhang*

Main category: cs.CV

TL;DR: SVG-Head提出了一种混合表示方法，结合表面和体积高斯模型，实现了高保真、可实时编辑的头像生成。


<details>
  <summary>Details</summary>
Motivation: 解决现有头像生成方法在实时外观编辑和几何与外观解耦建模方面的挑战。

Method: 使用表面高斯和体积高斯分别建模头像的外观和非朗伯区域，结合FLAME网格和UV映射优化。

Result: 在NeRSemble数据集上实现了高保真渲染，并首次支持高斯头像的实时外观编辑。

Conclusion: SVG-Head为头像生成提供了高质量的渲染和灵活的编辑能力。

Abstract: Creating high-fidelity and editable head avatars is a pivotal challenge in
computer vision and graphics, boosting many AR/VR applications. While recent
advancements have achieved photorealistic renderings and plausible animation,
head editing, especially real-time appearance editing, remains challenging due
to the implicit representation and entangled modeling of the geometry and
global appearance. To address this, we propose Surface-Volumetric Gaussian Head
Avatar (SVG-Head), a novel hybrid representation that explicitly models the
geometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled
texture images to capture the global appearance. Technically, it contains two
types of Gaussians, in which surface Gaussians explicitly model the appearance
of head avatars using learnable texture images, facilitating real-time texture
editing, while volumetric Gaussians enhance the reconstruction quality of
non-Lambertian regions (e.g., lips and hair). To model the correspondence
between 3D world and texture space, we provide a mesh-aware Gaussian UV mapping
method, which leverages UV coordinates given by the FLAME mesh to obtain sharp
texture images and real-time rendering speed. A hierarchical optimization
strategy is further designed to pursue the optimal performance in both
reconstruction quality and editing flexibility. Experiments on the NeRSemble
dataset show that SVG-Head not only generates high-fidelity rendering results,
but also is the first method to obtain explicit texture images for Gaussian
head avatars and support real-time appearance editing.

</details>


### [129] [Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection](https://arxiv.org/abs/2508.09746)
*Zhiqiu Zhang,Dongqi Fan,Mingjie Wang,Qiang Tang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: 论文提出了一种基于区域到区域变换的图像协调方法（R2R），通过Clear-VAE和Harmony Controller提升细节保留和协调能力，并构建了新的合成数据集RPHarmony。


<details>
  <summary>Details</summary>
Motivation: 现有基于LDM的图像协调方法在细节保留和协调能力上存在不足，且现有合成数据集缺乏真实光照变化。

Method: 提出Region-to-Region变换，结合Clear-VAE和MACA模块，设计Random Poisson Blending生成多样化合成数据。

Result: 实验表明R2R在定量指标和视觉协调性上优于其他方法，且RPHarmony数据集提升了模型在真实场景中的表现。

Conclusion: R2R方法有效解决了图像协调中的细节保留和协调能力问题，新数据集进一步提升了模型性能。

Abstract: The goal of image harmonization is to adjust the foreground in a composite
image to achieve visual consistency with the background. Recently, latent
diffusion model (LDM) are applied for harmonization, achieving remarkable
results. However, LDM-based harmonization faces challenges in detail
preservation and limited harmonization ability. Additionally, current synthetic
datasets rely on color transfer, which lacks local variations and fails to
capture complex real-world lighting conditions. To enhance harmonization
capabilities, we propose the Region-to-Region transformation. By injecting
information from appropriate regions into the foreground, this approach
preserves original details while achieving image harmonization or, conversely,
generating new composite data. From this perspective, We propose a novel model
R2R. Specifically, we design Clear-VAE to preserve high-frequency details in
the foreground using Adaptive Filter while eliminating disharmonious elements.
To further enhance harmonization, we introduce the Harmony Controller with
Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the
foreground based on the channel importance of both foreground and background
regions. To address the limitation of existing datasets, we propose Random
Poisson Blending, which transfers color and lighting information from a
suitable region to the foreground, thereby generating more diverse and
challenging synthetic images. Using this method, we construct a new synthetic
dataset, RPHarmony. Experiments demonstrate the superiority of our method over
other methods in both quantitative metrics and visual harmony. Moreover, our
dataset helps the model generate more realistic images in real examples. Our
code, dataset, and model weights have all been released for open access.

</details>


### [130] [Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality](https://arxiv.org/abs/2508.09598)
*Jie Shao,Ke Zhu,Minghao Fu,Guo-hua Wang,Jianxin Wu*

Main category: cs.CV

TL;DR: FaME是一种无需训练、高效推理的方法，通过识别低质量生成图像并利用其采样轨迹作为负引导，提升生成图像的感知质量，同时保持FID分数。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在类别到图像生成方面取得了显著进展，但现有模型在某些类别中仍会生成失真或低质量图像，而FID指标无法评估单个样本的感知质量。

Method: FaME利用图像质量评估模型识别低质量生成图像，并存储其采样轨迹作为负引导，以引导未来采样远离低质量区域。

Result: 在ImageNet上的实验表明，FaME在不影响FID的情况下，显著提升了视觉质量，并有望扩展到文本到图像生成任务。

Conclusion: FaME为扩散模型提供了一种有效且高效的方法，专注于提升生成图像的感知质量，同时保持全局分布对齐。

Abstract: Diffusion models have achieved remarkable progress in class-to-image
generation. However, we observe that despite impressive FID scores,
state-of-the-art models often generate distorted or low-quality images,
especially in certain classes. This gap arises because FID evaluates global
distribution alignment, while ignoring the perceptual quality of individual
samples. We further examine the role of CFG, a common technique used to enhance
generation quality. While effective in improving metrics and suppressing
outliers, CFG can introduce distribution shift and visual artifacts due to its
misalignment with both training objectives and user expectations. In this work,
we propose FaME, a training-free and inference-efficient method for improving
perceptual quality. FaME uses an image quality assessment model to identify
low-quality generations and stores their sampling trajectories. These failure
modes are then used as negative guidance to steer future sampling away from
poor-quality regions. Experiments on ImageNet demonstrate that FaME brings
consistent improvements in visual quality without compromising FID. FaME also
shows the potential to be extended to improve text-to-image generation.

</details>


### [131] [BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation](https://arxiv.org/abs/2508.09599)
*Beomjun Kim,Suhan Woo,Sejong Heo,Euntai Kim*

Main category: cs.CV

TL;DR: BridgeTA是一种成本效益高的蒸馏框架，通过教师助理（TA）网络缩小了LiDAR-Camera融合与纯相机模型之间的表示差距，同时保持学生模型的架构和推理成本不变。


<details>
  <summary>Details</summary>
Motivation: 纯相机方法在自动驾驶的BEV地图分割任务中落后于LiDAR-Camera融合方法，现有知识蒸馏方法通过模仿教师模型架构增加了推理成本。

Method: 引入轻量级TA网络，结合教师和学生的BEV表示，创建共享潜在空间，并使用Young不等式推导蒸馏损失以稳定优化。

Result: 在nuScenes数据集上，BridgeTA比纯相机基线提高了4.2% mIoU，优于其他最先进的KD方法。

Conclusion: BridgeTA通过TA网络和理论推导的蒸馏损失，有效提升了纯相机模型的性能，且不增加推理成本。

Abstract: Bird's-Eye-View (BEV) map segmentation is one of the most important and
challenging tasks in autonomous driving. Camera-only approaches have drawn
attention as cost-effective alternatives to LiDAR, but they still fall behind
LiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been
explored to narrow this gap, but existing methods mainly enlarge the student
model by mimicking the teacher's architecture, leading to higher inference
cost. To address this issue, we introduce BridgeTA, a cost-effective
distillation framework to bridge the representation gap between LC fusion and
Camera-only models through a Teacher Assistant (TA) network while keeping the
student's architecture and inference cost unchanged. A lightweight TA network
combines the BEV representations of the teacher and student, creating a shared
latent space that serves as an intermediate representation. To ground the
framework theoretically, we derive a distillation loss using Young's
Inequality, which decomposes the direct teacher-student distillation path into
teacher-TA and TA-student dual paths, stabilizing optimization and
strengthening knowledge transfer. Extensive experiments on the challenging
nuScenes dataset demonstrate the effectiveness of our method, achieving an
improvement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than
the improvement of other state-of-the-art KD methods.

</details>


### [132] [Combinative Matching for Geometric Shape Assembly](https://arxiv.org/abs/2508.09780)
*Nahyuk Lee,Juhong Min,Junhong Lee,Chunghyun Park,Minsu Cho*

Main category: cs.CV

TL;DR: 提出了一种新的形状匹配方法“组合匹配”，用于几何形状装配，通过显式建模互锁形状的两种特性，显著减少了匹配中的局部模糊性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖对齐相同表面，而本文方法通过建模“相同表面形状”和“相反体积占用”特性，解决了互锁形状装配中的匹配问题。

Method: 使用等变神经网络估计形状方向，学习在表面形状相同但体积占用相反的区域建立对应关系。

Result: 在几何装配基准测试中表现优异，显著优于现有技术。

Conclusion: 组合匹配方法通过显式建模互锁特性，实现了更鲁棒的几何形状装配。

Abstract: This paper introduces a new shape-matching methodology, combinative matching,
to combine interlocking parts for geometric shape assembly. Previous methods
for geometric assembly typically rely on aligning parts by finding identical
surfaces between the parts as in conventional shape matching and registration.
In contrast, we explicitly model two distinct properties of interlocking
shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method
thus learns to establish correspondences across regions where their surface
shapes appear identical but their volumes occupy the inverted space to each
other. To facilitate this process, we also learn to align regions in rotation
by estimating their shape orientations via equivariant neural networks. The
proposed approach significantly reduces local ambiguities in matching and
allows a robust combination of parts in assembly. Experimental results on
geometric assembly benchmarks demonstrate the efficacy of our method,
consistently outperforming the state of the art. Project page:
https://nahyuklee.github.io/cmnet.

</details>


### [133] [Plane Detection and Ranking via Model Information Optimization](https://arxiv.org/abs/2508.09625)
*Daoxin Zhong,Jun Li,Meng Yee Michael Chuah*

Main category: cs.CV

TL;DR: 提出了一种基于模型信息优化的平面检测框架，通过信息最小化选择最可能的地面真实模型，减少RANSAC的误检问题。


<details>
  <summary>Details</summary>
Motivation: 解决RANSAC在复杂场景中因阈值模糊导致的误检问题，尤其是当真实平面数量未知时。

Method: 将深度数据视为离散随机变量，通过随机子采样生成候选平面模型，结合传感器物理和噪声模型计算信息量，选择信息量最小的模型。

Result: 在合成数据实验中，算法比Open3D RANSAC更准确地估计平面参数，并通过神经网络分割加速。

Conclusion: 提出的信息优化框架能有效减少误检，提升平面检测的准确性和实用性。

Abstract: Plane detection from depth images is a crucial subtask with broad robotic
applications, often accomplished by iterative methods such as Random Sample
Consensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic
guarantees, the ambiguity of its inlier threshold criterion makes it
susceptible to false positive plane detections. This issue is particularly
prevalent in complex real-world scenes, where the true number of planes is
unknown and multiple planes coexist. In this paper, we aim to address this
limitation by proposing a generalised framework for plane detection based on
model information optimization. Building on previous works, we treat the
observed depth readings as discrete random variables, with their probability
distributions constrained by the ground truth planes. Various models containing
different candidate plane constraints are then generated through repeated
random sub-sampling to explain our observations. By incorporating the physics
and noise model of the depth sensor, we can calculate the information for each
model, and the model with the least information is accepted as the most likely
ground truth. This information optimization process serves as an objective
mechanism for determining the true number of planes and preventing false
positive detections. Additionally, the quality of each detected plane can be
ranked by summing the information reduction of inlier points for each plane. We
validate these properties through experiments with synthetic data and find that
our algorithm estimates plane parameters more accurately compared to the
default Open3D RANSAC plane segmentation. Furthermore, we accelerate our
algorithm by partitioning the depth map using neural network segmentation,
which enhances its ability to generate more realistic plane parameters in
real-world data.

</details>


### [134] [Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation](https://arxiv.org/abs/2508.09626)
*Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为SAD-Splat的新方法，用于解决3D航空场景语义分割中的语义模糊问题，通过高斯点丢弃模块和高置信度伪标签生成管道提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理航空图像中的尺度变化和结构遮挡时存在语义模糊问题，导致分割精度和一致性受限。

Method: 引入高斯点丢弃模块（基于Hard Concrete分布）和高置信度伪标签生成管道，结合2D基础模型增强监督。

Result: SAD-Splat在分割精度和表示紧凑性之间取得了良好平衡，实验效果优异。

Conclusion: SAD-Splat为3D航空场景理解提供了高效且可扩展的解决方案，并提出了新的基准数据集3D-AS。

Abstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),
traditional methods struggle to address semantic ambiguity caused by scale
variations and structural occlusions in aerial images. This limits their
segmentation accuracy and consistency. To tackle these challenges, we propose a
novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian
point drop module, which integrates semantic confidence estimation with a
learnable sparsity mechanism based on the Hard Concrete distribution. This
module effectively eliminates redundant and semantically ambiguous Gaussian
points, enhancing both segmentation performance and representation compactness.
Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation
pipeline. It leverages 2D foundation models to enhance supervision when
ground-truth labels are limited, thereby further improving segmentation
accuracy. To advance research in this domain, we introduce a challenging
benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse
real-world aerial scenes with sparse annotations. Experimental results
demonstrate that SAD-Splat achieves an excellent balance between segmentation
accuracy and representation compactness. It offers an efficient and scalable
solution for 3D aerial scene understanding.

</details>


### [135] [Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology](https://arxiv.org/abs/2508.09805)
*Jonathan Williams Ramirez,Dina Zemlyanker,Lucas Deden-Binder,Rogeny Herisse,Erendira Garcia Pallares,Karthik Gopinath,Harshvardhan Gazula,Christopher Mount,Liana N. Kozanno,Michael S. Marshall,Theresa R. Connors,Matthew P. Frosch,Mark Montine,Derek H. Oakley,Christine L. Mac Donald,C. Dirk Keene,Bradley T. Hyman,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 论文提出了一种基于U-Net架构的深度学习模型，用于自动化分割脑组织照片中的组织区域，解决了传统方法需要昂贵手动干预的问题。


<details>
  <summary>Details</summary>
Motivation: 脑组织照片的分割通常需要手动操作，成本高昂且耗时。本文旨在通过深度学习技术实现自动化分割，提高效率。

Method: 使用U-Net架构，结合1,414张手动标注的真实照片和2,000张合成的MRI图像进行训练，以增强模型的泛化能力。

Result: 模型在未见过的照片上表现优异，Dice分数中位数超过0.98，平均表面距离小于0.4毫米，接近人工标注的精度。

Conclusion: 该工具公开可用，能够高效、准确地自动化脑组织分割，接近人工水平。

Abstract: Advances in image registration and machine learning have recently enabled
volumetric analysis of \emph{postmortem} brain tissue from conventional
photographs of coronal slabs, which are routinely collected in brain banks and
neuropathology laboratories worldwide. One caveat of this methodology is the
requirement of segmentation of the tissue from photographs, which currently
requires costly manual intervention. In this article, we present a deep
learning model to automate this process. The automatic segmentation tool relies
on a U-Net architecture that was trained with a combination of
\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,
from specimens with varying diagnoses, photographed at two different sites; and
\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding
masks generated from MRI scans for improved generalizability to unseen
photographic setups. Automated model predictions on a subset of photographs not
seen in training were analyzed to estimate performance compared to manual
labels -- including both inter- and intra-rater variability. Our model achieved
a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\%
Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.
Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.

</details>


### [136] [Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors](https://arxiv.org/abs/2508.09629)
*Giorgos Karvounas,Nikolaos Kyriazis,Iason Oikonomidis,Georgios Pavlakos,Antonis A. Argyros*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级纹理模块，通过将像素观测嵌入UV纹理空间，利用纹理对齐作为监督信号，提升单目3D手部重建的准确性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有高精度模型在手部几何与图像外观的对齐上仍存在不足，纹理对齐可能是一个未被充分利用的监督信号。

Method: 提出一个轻量级纹理模块，结合可微分渲染和已知拓扑的3D手部网格模型，通过像素级对齐实现纹理引导的监督。

Result: 该方法提升了HaMeR模型的准确性和真实感，验证了外观引导对齐在手部重建中的价值。

Conclusion: 纹理对齐可以作为有效的监督信号，显著提升3D手部重建的性能。

Abstract: We revisit the role of texture in monocular 3D hand reconstruction, not as an
afterthought for photorealism, but as a dense, spatially grounded cue that can
actively support pose and shape estimation. Our observation is simple: even in
high-performing models, the overlay between predicted hand geometry and image
appearance is often imperfect, suggesting that texture alignment may be an
underused supervisory signal. We propose a lightweight texture module that
embeds per-pixel observations into UV texture space and enables a novel dense
alignment loss between predicted and observed hand appearances. Our approach
assumes access to a differentiable rendering pipeline and a model that maps
images to 3D hand meshes with known topology, allowing us to back-project a
textured hand onto the image and perform pixel-based alignment. The module is
self-contained and easily pluggable into existing reconstruction pipelines. To
isolate and highlight the value of texture-guided supervision, we augment
HaMeR, a high-performing yet unadorned transformer architecture for 3D hand
pose estimation. The resulting system improves both accuracy and realism,
demonstrating the value of appearance-guided alignment in hand reconstruction.

</details>


### [137] [TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos](https://arxiv.org/abs/2508.09811)
*Jinxi Li,Ziyang Song,Bo Yang*

Main category: cs.CV

TL;DR: TRACE框架通过将3D点建模为刚性粒子，学习其平移旋转动力学系统，无需人工标签即可建模复杂动态3D场景的物理运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖物理约束或简单物理模型，难以学习复杂运动物理或需要额外标签。TRACE旨在解决这一问题。

Method: 将每个3D点视为具有大小和方向的刚性粒子，直接学习其平移旋转动力学系统，并估计物理参数。

Result: 在多个动态数据集上表现出色，未来帧外推任务优于基线，且能通过聚类物理参数轻松分割物体。

Conclusion: TRACE无需人工标签即可建模复杂动态3D场景的物理运动，具有高效性和可扩展性。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and physical
information just from dynamic multi-view videos in the absence of any human
labels. By leveraging physics-informed losses as soft constraints or
integrating simple physics models into neural nets, existing works often fail
to learn complex motion physics, or doing so requires additional labels such as
object types or masks. We propose a new framework named TRACE to model the
motion physics of complex dynamic 3D scenes. The key novelty of our method is
that, by formulating each 3D point as a rigid particle with size and
orientation in space, we directly learn a translation rotation dynamics system
for each particle, explicitly estimating a complete set of physical parameters
to govern the particle's motion over time. Extensive experiments on three
existing dynamic datasets and one newly created challenging synthetic datasets
demonstrate the extraordinary performance of our method over baselines in the
task of future frame extrapolation. A nice property of our framework is that
multiple objects or parts can be easily segmented just by clustering the
learned physical parameters.

</details>


### [138] [Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification](https://arxiv.org/abs/2508.09644)
*Shengjun Zhu,Siyu Liu,Runqing Xiong,Liping Zheng,Duo Ma,Rongshang Chen,Jiaxin Cai*

Main category: cs.CV

TL;DR: 提出了一种多对比融合模块（MCFM），用于提升超声图像中胎儿躯干平面的识别性能，实验证明其有效且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 超声图像的低对比度和纹理细节不清晰限制了胎儿解剖结构的精细识别，影响诊断准确性。

Method: 设计了MCFM模块，通过多对比注意力机制增强特征提取，直接在神经网络的底层处理原始超声数据。

Result: 在胎儿躯干平面数据集上，MCFM显著提升了识别性能，且模型复杂度增加极小。

Conclusion: MCFM通过多对比融合提升特征表示，支持更准确和一致的临床诊断，具有临床应用潜力。

Abstract: Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural
development and detecting abnormalities, contributing to reduced perinatal
complications and improved neonatal survival. Accurate identification of
standard fetal torso planes is essential for reliable assessment and
personalized prenatal care. However, limitations such as low contrast and
unclear texture details in ultrasound imaging pose significant challenges for
fine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast
Fusion Module (MCFM) to enhance the model's ability to extract detailed
information from ultrasound images. MCFM operates exclusively on the lower
layers of the neural network, directly processing raw ultrasound data. By
assigning attention weights to image representations under different contrast
conditions, the module enhances feature modeling while explicitly maintaining
minimal parameter overhead. Results: The proposed MCFM was evaluated on a
curated dataset of fetal torso plane ultrasound images. Experimental results
demonstrate that MCFM substantially improves recognition performance, with a
minimal increase in model complexity. The integration of multi-contrast
attention enables the model to better capture subtle anatomical structures,
contributing to higher classification accuracy and clinical reliability.
Conclusions: Our method provides an effective solution for improving fetal
torso plane recognition in ultrasound imaging. By enhancing feature
representation through multi-contrast fusion, the proposed approach supports
clinicians in achieving more accurate and consistent diagnoses, demonstrating
strong potential for clinical adoption in prenatal screening. The codes are
available at https://github.com/sysll/MCFM.

</details>


### [139] [RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians](https://arxiv.org/abs/2508.09830)
*Shenxing Wei,Jinxi Li,Yafei Yang,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: 提出了一种名为RayletDF的新方法，用于从点云或3D高斯中重建3D表面，通过射线距离场直接预测表面点，具有高效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于坐标的方法在渲染显式表面时计算量大，需要一种更高效且泛化能力强的3D表面重建方法。

Method: 提出RayletDF方法，包含射线特征提取器、射线距离场预测器和多射线混合器三个模块，用于提取几何特征、预测距离并聚合结果。

Result: 在多个公开数据集上表现优异，能够单次前向通过未见数据集成功重建3D表面。

Conclusion: RayletDF在3D表面重建中具有高效性和出色的泛化能力，适用于多种输入数据。

Abstract: In this paper, we present a generalizable method for 3D surface
reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from
RGB images. Unlike existing coordinate-based methods which are often
computationally intensive when rendering explicit surfaces, our proposed
method, named RayletDF, introduces a new technique called raylet distance
field, which aims to directly predict surface points from query rays. Our
pipeline consists of three key modules: a raylet feature extractor, a raylet
distance field predictor, and a multi-raylet blender. These components work
together to extract fine-grained local geometric features, predict raylet
distances, and aggregate multiple predictions to reconstruct precise surface
points. We extensively evaluate our method on multiple public real-world
datasets, demonstrating superior performance in surface reconstruction from
point clouds or 3D Gaussians. Most notably, our method achieves exceptional
generalization ability, successfully recovering 3D surfaces in a single-forward
pass across unseen datasets in testing.

</details>


### [140] [Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model](https://arxiv.org/abs/2508.09645)
*Zhongyuan Wu,Chuan-Xian Ren,Yu Wang,Xiaohua Ban,Jianning Xiao,Xiaohui Duan*

Main category: cs.CV

TL;DR: PG-SAM模型通过结合专家诊断文本和跨序列注意力模块，显著提升了腮腺病变分割的准确性，验证了其在临床中的实用性。


<details>
  <summary>Details</summary>
Motivation: 腮腺病变分割因病变大小和边界复杂性而具有挑战性，且现有方法依赖精确提示或忽略专家知识。

Method: 提出PG-SAM模型，包含专家诊断文本引导的提示生成模块和跨序列注意力模块，结合多模态信息进行分割。

Result: 在三个独立临床中心验证中，PG-SAM实现了最先进的腮腺病变分割性能。

Conclusion: PG-SAM通过融合专家知识和多模态信息，显著提升了分割效果，具有临床适用性。

Abstract: Parotid gland lesion segmentation is essential for the treatment of parotid
gland diseases. However, due to the variable size and complex lesion
boundaries, accurate parotid gland lesion segmentation remains challenging.
Recently, the Segment Anything Model (SAM) fine-tuning has shown remarkable
performance in the field of medical image segmentation. Nevertheless, SAM's
interaction segmentation model relies heavily on precise lesion prompts
(points, boxes, masks, etc.), which are very difficult to obtain in real-world
applications. Besides, current medical image segmentation methods are
automatically generated, ignoring the domain knowledge of medical experts when
performing segmentation. To address these limitations, we propose the parotid
gland segment anything model (PG-SAM), an expert diagnosis text-guided SAM
incorporating expert domain knowledge for cross-sequence parotid gland lesion
segmentation. Specifically, we first propose an expert diagnosis report guided
prompt generation module that can automatically generate prompt information
containing the prior domain knowledge to guide the subsequent lesion
segmentation process. Then, we introduce a cross-sequence attention module,
which integrates the complementary information of different modalities to
enhance the segmentation effect. Finally, the multi-sequence image features and
generated prompts are feed into the decoder to get segmentation result.
Experimental results demonstrate that PG-SAM achieves state-of-the-art
performance in parotid gland lesion segmentation across three independent
clinical centers, validating its clinical applicability and the effectiveness
of diagnostic text for enhancing image segmentation in real-world clinical
settings.

</details>


### [141] [The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge](https://arxiv.org/abs/2508.09649)
*Reuben Dorent,Laura Rigolo,Colin P. Galvin,Junyu Chen,Mattias P. Heinrich,Aaron Carass,Olivier Colliot,Demian Wassermann,Alexandra Golby,Tina Kapur,William Wells*

Main category: cs.CV

TL;DR: ReMIND2Reg 2025挑战赛旨在通过提供大规模公开数据集和标准化评估框架，推动脑肿瘤手术中多模态图像配准算法的发展。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤手术中，术前MRI导航系统因脑移位而失去准确性，术后超声与术前MRI配准可恢复空间准确性，但存在解剖结构变化和模态差异的挑战。

Method: 挑战赛提供99个训练案例、5个验证案例和10个测试案例，包含配对的3D ceT1 MRI、T2 MRI和术后3D超声数据，评估基于手动标注的解剖标志。

Result: 评估指标包括目标配准误差（TRE）、最坏情况标志错位（TRE30）和运行时间。

Conclusion: ReMIND2Reg挑战赛旨在促进开发鲁棒、通用且临床可部署的多模态配准算法。

Abstract: Accurate intraoperative image guidance is critical for achieving maximal safe
resection in brain tumor surgery, yet neuronavigation systems based on
preoperative MRI lose accuracy during the procedure due to brain shift.
Aligning post-resection intraoperative ultrasound (iUS) with preoperative MRI
can restore spatial accuracy by estimating brain shift deformations, but it
remains a challenging problem given the large anatomical and topological
changes and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge
provides the largest public benchmark for this task, built upon the ReMIND
dataset. It offers 99 training cases, 5 validation cases, and 10 private test
cases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes.
Data are provided without annotations for training, while validation and test
performance are evaluated on manually annotated anatomical landmarks. Metrics
include target registration error (TRE), robustness to worst-case landmark
misalignment (TRE30), and runtime. By establishing a standardized evaluation
framework for this clinically critical and technically complex problem,
ReMIND2Reg aims to accelerate the development of robust, generalizable, and
clinically deployable multimodal registration algorithms for image-guided
neurosurgery.

</details>


### [142] [TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos](https://arxiv.org/abs/2508.09650)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazely,Sunil Aryal*

Main category: cs.CV

TL;DR: TOTNet是一种用于体育视频分析的时序遮挡跟踪网络，通过3D卷积、可见性加权损失和遮挡增强技术，显著提升了在遮挡情况下的球体跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 体育视频分析中，遮挡情况下的球体跟踪是一个关键挑战，影响了事件检测和裁判等任务。

Method: TOTNet采用3D卷积、可见性加权损失和遮挡增强技术，并结合了新的遮挡丰富的乒乓球数据集TTA进行训练。

Result: 在四个数据集上的评估显示，TOTNet显著优于现有方法，RMSE从37.30降至7.19，全遮挡帧的准确率从0.63提升至0.80。

Conclusion: TOTNet在快速场景下的离线体育分析中表现出色，代码和数据已开源。

Abstract: Robust ball tracking under occlusion remains a key challenge in sports video
analysis, affecting tasks like event detection and officiating. We present
TOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions,
visibility-weighted loss, and occlusion augmentation to improve performance
under partial and full occlusions. Developed in collaboration with Paralympics
Australia, TOTNet is designed for real-world sports analytics. We introduce
TTA, a new occlusion-rich table tennis dataset collected from
professional-level Paralympic matches, comprising 9,159 samples with 1,996
occlusion cases. Evaluated on four datasets across tennis, badminton, and table
tennis, TOTNet significantly outperforms prior state-of-the-art methods,
reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded
frames from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for
offline sports analytics in fast-paced scenarios. Code and data
access:\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.

</details>


### [143] [Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging](https://arxiv.org/abs/2508.09655)
*Lianfang Wang,Kuilin Qin,Xueying Liu,Huibin Chang,Yong Wang,Yuping Duan*

Main category: cs.CV

TL;DR: 本文提出了一种参数化逆问题框架，用于3D成像重建中的大规模线性问题，结合噪声估计模块和参数化神经算子，实现了快速且鲁棒的图像重建。


<details>
  <summary>Details</summary>
Motivation: 非视线（NLOS）成像中，间接光信号弱且易受噪声干扰，需物理过程支持以确保准确重建。

Method: 采用噪声估计模块评估瞬态数据噪声，开发参数化神经算子近似逆映射，并通过深度算法展开构建框架，融合全局和局部时空数据特征。

Result: 在模拟和真实数据集上验证了方法的有效性，尤其在快速扫描和稀疏照明点数据中表现优异。

Conclusion: 该方法为复杂场景下的NLOS成像提供了可行解决方案，兼具高精度和鲁棒性。

Abstract: Computational imaging, especially non-line-of-sight (NLOS) imaging, the
extraction of information from obscured or hidden scenes is achieved through
the utilization of indirect light signals resulting from multiple reflections
or scattering. The inherently weak nature of these signals, coupled with their
susceptibility to noise, necessitates the integration of physical processes to
ensure accurate reconstruction. This paper presents a parameterized inverse
problem framework tailored for large-scale linear problems in 3D imaging
reconstruction. Initially, a noise estimation module is employed to adaptively
assess the noise levels present in transient data. Subsequently, a
parameterized neural operator is developed to approximate the inverse mapping,
facilitating end-to-end rapid image reconstruction. Our 3D image reconstruction
framework, grounded in operator learning, is constructed through deep algorithm
unfolding, which not only provides commendable model interpretability but also
enables dynamic adaptation to varying noise levels in the acquired data,
thereby ensuring consistently robust and accurate reconstruction outcomes.
Furthermore, we introduce a novel method for the fusion of global and local
spatiotemporal data features. By integrating structural and detailed
information, this method significantly enhances both accuracy and robustness.
Comprehensive numerical experiments conducted on both simulated and real
datasets substantiate the efficacy of the proposed method. It demonstrates
remarkable performance with fast scanning data and sparse illumination point
data, offering a viable solution for NLOS imaging in complex scenarios.

</details>


### [144] [NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation](https://arxiv.org/abs/2508.09661)
*Eduarda Caldeira,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: NegFaceDiff是一种新的采样方法，通过在身份条件扩散过程中引入负条件，显著提高了生成数据的身份一致性和可分离性，从而优化了人脸识别模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有身份条件扩散模型在生成人脸数据时缺乏明确的类间分离机制，导致身份重叠和次优的人脸识别性能的问题。

Method: 提出NegFaceDiff方法，在身份条件扩散过程中加入负条件，明确引导模型远离不需要的特征，同时保持类内一致性。

Result: 实验表明，NegFaceDiff将身份可分离性（FDR）从2.427提升到5.687，并在多个基准测试中优于未使用负条件生成的模型。

Conclusion: NegFaceDiff通过负条件采样有效提升了生成数据的质量，为人脸识别模型的训练提供了更优的数据支持。

Abstract: The use of synthetic data as an alternative to authentic datasets in face
recognition (FR) development has gained significant attention, addressing
privacy, ethical, and practical concerns associated with collecting and using
authentic data. Recent state-of-the-art approaches have proposed
identity-conditioned diffusion models to generate identity-consistent face
images, facilitating their use in training FR models. However, these methods
often lack explicit sampling mechanisms to enforce inter-class separability,
leading to identity overlap in the generated data and, consequently, suboptimal
FR performance. In this work, we introduce NegFaceDiff, a novel sampling method
that incorporates negative conditions into the identity-conditioned diffusion
process. NegFaceDiff enhances identity separation by leveraging negative
conditions that explicitly guide the model away from unwanted features while
preserving intra-class consistency. Extensive experiments demonstrate that
NegFaceDiff significantly improves the identity consistency and separability of
data generated by identity-conditioned diffusion models. Specifically, identity
separability, measured by the Fisher Discriminant Ratio (FDR), increases from
2.427 to 5.687. These improvements are reflected in FR systems trained on the
NegFaceDiff dataset, which outperform models trained on data generated without
negative conditions across multiple benchmarks.

</details>


### [145] [GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors](https://arxiv.org/abs/2508.09667)
*Xingyilang Yin,Qi Zhang,Jiahao Chang,Ying Feng,Qingnan Fan,Xi Yang,Chi-Man Pun,Huaqi Zhang,Xiaodong Cun*

Main category: cs.CV

TL;DR: GSFixer利用参考引导的视频修复模型提升稀疏视图3D高斯溅射（3DGS）重建质量，结合2D语义和3D几何特征，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3DGS重建因信息不足导致明显伪影，现有生成先验方法难以保持与输入观察的一致性。

Method: 提出GSFixer框架，基于DiT视频扩散模型，利用参考视图的2D语义和3D几何特征修复伪影。

Result: 在3DGS伪影修复和稀疏视图3D重建任务中表现优于现有方法。

Conclusion: GSFixer通过结合多模态特征显著提升了3DGS重建质量，并提供了评估基准DL3DV-Res。

Abstract: Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views
is an ill-posed problem due to insufficient information, often resulting in
noticeable artifacts. While recent approaches have sought to leverage
generative priors to complete information for under-constrained regions, they
struggle to generate content that remains consistent with input observations.
To address this challenge, we propose GSFixer, a novel framework designed to
improve the quality of 3DGS representations reconstructed from sparse inputs.
The core of our approach is the reference-guided video restoration model, built
upon a DiT-based video diffusion model trained on paired artifact 3DGS renders
and clean frames with additional reference-based conditions. Considering the
input sparse views as references, our model integrates both 2D semantic
features and 3D geometric features of reference views extracted from the visual
geometry foundation model, enhancing the semantic coherence and 3D consistency
when fixing artifact novel views. Furthermore, considering the lack of suitable
benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which
contains artifact frames rendered using low-quality 3DGS. Extensive experiments
demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS
artifact restoration and sparse-view 3D reconstruction. Project page:
https://github.com/GVCLab/GSFixer.

</details>


### [146] [PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training](https://arxiv.org/abs/2508.09691)
*Yin Xie,Zhichao Chen,Xiaoze Yu,Yongle Zhao,Xiang An,Kaicheng Yang,Zimin Ran,Jia Guo,Ziyong Feng,Jiankang Deng*

Main category: cs.CV

TL;DR: PaCo-FR是一个无监督框架，通过结合掩码图像建模和像素对齐，解决了面部表示预训练中的三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉面部特征、空间结构和利用有限标注数据方面存在不足。

Method: PaCo-FR采用结构化掩码策略、基于补丁的代码本和空间一致性约束。

Result: 在多种面部分析任务中达到最先进性能，仅需200万未标注图像。

Conclusion: 该方法推动了面部表示学习，减少了昂贵标注数据的依赖。

Abstract: Facial representation pre-training is crucial for tasks like facial
recognition, expression analysis, and virtual reality. However, existing
methods face three key challenges: (1) failing to capture distinct facial
features and fine-grained semantics, (2) ignoring the spatial structure
inherent to facial anatomy, and (3) inefficiently utilizing limited labeled
data. To overcome these, we introduce PaCo-FR, an unsupervised framework that
combines masked image modeling with patch-pixel alignment. Our approach
integrates three innovative components: (1) a structured masking strategy that
preserves spatial coherence by aligning with semantically meaningful facial
regions, (2) a novel patch-based codebook that enhances feature discrimination
with multiple candidate tokens, and (3) spatial consistency constraints that
preserve geometric relationships between facial components. PaCo-FR achieves
state-of-the-art performance across several facial analysis tasks with just 2
million unlabeled images for pre-training. Our method demonstrates significant
improvements, particularly in scenarios with varying poses, occlusions, and
lighting conditions. We believe this work advances facial representation
learning and offers a scalable, efficient solution that reduces reliance on
expensive annotated datasets, driving more effective facial analysis systems.

</details>


### [147] [Slot Attention-based Feature Filtering for Few-Shot Learning](https://arxiv.org/abs/2508.09699)
*Javier Rodenas,Eduardo Aguilar,Petia Radeva*

Main category: cs.CV

TL;DR: 论文提出SAFF方法，通过槽注意力机制过滤无关特征，提升小样本学习性能。


<details>
  <summary>Details</summary>
Motivation: 无关特征会显著降低小样本学习的性能，导致混淆和误分类。

Method: 提出SAFF方法，结合槽注意力机制与补丁嵌入，通过相似性矩阵量化特征相关性。

Result: 在多个小样本学习基准测试中表现优于现有方法。

Conclusion: SAFF通过过滤无关特征有效提升了小样本分类性能。

Abstract: Irrelevant features can significantly degrade few-shot learn ing performance.
This problem is used to match queries and support images based on meaningful
similarities despite the limited data. However, in this process, non-relevant
fea tures such as background elements can easily lead to confu sion and
misclassification. To address this issue, we pro pose Slot Attention-based
Feature Filtering for Few-Shot Learning (SAFF) that leverages slot attention
mechanisms to discriminate and filter weak features, thereby improving few-shot
classification performance. The key innovation of SAFF lies in its integration
of slot attention with patch em beddings, unifying class-aware slots into a
single attention mechanism to filter irrelevant features effectively. We intro
duce a similarity matrix that computes across support and query images to
quantify the relevance of filtered embed dings for classification. Through
experiments, we demon strate that Slot Attention performs better than other
atten tion mechanisms, capturing discriminative features while reducing
irrelevant information. We validate our approach through extensive experiments
on few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma
geNet, outperforming several state-of-the-art methods.

</details>


### [148] [January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis](https://arxiv.org/abs/2508.09966)
*Amir Hosseinian,Ashkan Dehghani Zahedani,Umer Mansoor,Noosheen Hashemi,Mark Woodward*

Main category: cs.CV

TL;DR: 论文提出了一个标准化的评估框架和高质量数据集（JFB），用于自动化营养分析，并展示了专用模型的显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决自动化营养分析领域缺乏标准化评估方法和高质量数据集的问题。

Method: 引入JFB数据集、全面的基准测试框架，并比较通用和专用模型的性能。

Result: 专用模型在整体评分上比最佳通用模型高出12.1分，达到86.2分。

Conclusion: 该研究为自动化营养分析提供了新的评估工具和基准，推动了该领域的发展。

Abstract: Progress in AI for automated nutritional analysis is critically hampered by
the lack of standardized evaluation methodologies and high-quality, real-world
benchmark datasets. To address this, we introduce three primary contributions.
First, we present the January Food Benchmark (JFB), a publicly available
collection of 1,000 food images with human-validated annotations. Second, we
detail a comprehensive benchmarking framework, including robust metrics and a
novel, application-oriented overall score designed to assess model performance
holistically. Third, we provide baseline results from both general-purpose
Vision-Language Models (VLMs) and our own specialized model,
january/food-vision-v1. Our evaluation demonstrates that the specialized model
achieves an Overall Score of 86.2, a 12.1-point improvement over the
best-performing general-purpose configuration. This work offers the research
community a valuable new evaluation dataset and a rigorous framework to guide
and benchmark future developments in automated nutritional analysis.

</details>


### [149] [MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers](https://arxiv.org/abs/2508.09709)
*Qianru Qiu,Jiafeng Mao,Kento Masui,Xueting Wang*

Main category: cs.CV

TL;DR: MangaDiT利用扩散变换器和分层注意力机制改进线稿着色，提升区域级颜色一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在参考图像与目标图像姿态不同时区域级颜色一致性表现不佳。

Method: 提出MangaDiT模型，结合扩散变换器和动态注意力权重策略，通过内部注意力机制发现语义对应。

Result: 在两个基准数据集上显著优于现有方法，定性和定量评估均表现优越。

Conclusion: MangaDiT通过增强的注意力机制有效解决了区域级颜色对齐问题。

Abstract: Recent advances in diffusion models have significantly improved the
performance of reference-guided line art colorization. However, existing
methods still struggle with region-level color consistency, especially when the
reference and target images differ in character pose or motion. Instead of
relying on external matching annotations between the reference and target, we
propose to discover semantic correspondences implicitly through internal
attention mechanisms. In this paper, we present MangaDiT, a powerful model for
reference-guided line art colorization based on Diffusion Transformers (DiT).
Our model takes both line art and reference images as conditional inputs and
introduces a hierarchical attention mechanism with a dynamic attention
weighting strategy. This mechanism augments the vanilla attention with an
additional context-aware path that leverages pooled spatial features,
effectively expanding the model's receptive field and enhancing region-level
color alignment. Experiments on two benchmark datasets demonstrate that our
method significantly outperforms state-of-the-art approaches, achieving
superior performance in both qualitative and quantitative evaluations.

</details>


### [150] [NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation](https://arxiv.org/abs/2508.09715)
*Devvrat Joshi,Islem Rekik*

Main category: cs.CV

TL;DR: NEURAL框架通过语义引导的数据压缩技术，显著减少多模态医学影像数据的存储和传输负担，同时保持高诊断性能。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限临床环境中多模态医学影像数据的存储和传输问题。

Method: 利用生成式视觉-语言模型的交叉注意力分数对胸部X光进行结构性剪枝，生成高度压缩的图表示。

Result: 在MIMIC-CXR和CheXpert Plus数据集上，NEURAL将图像数据大小减少93.4-97.7%，同时保持0.88-0.95 AUC的高诊断性能。

Conclusion: NEURAL框架在数据大小和临床实用性之间取得了平衡，支持高效工作流程和远程放射学。

Abstract: The rapid growth of multimodal medical imaging data presents significant
storage and transmission challenges, particularly in resource-constrained
clinical settings. We propose NEURAL, a novel framework that addresses this by
using semantics-guided data compression. Our approach repurposes
cross-attention scores between the image and its radiological report from a
fine-tuned generative vision-language model to structurally prune chest X-rays,
preserving only diagnostically critical regions. This process transforms the
image into a highly compressed, graph representation. This unified graph-based
representation fuses the pruned visual graph with a knowledge graph derived
from the clinical report, creating a universal data structure that simplifies
downstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for
pneumonia detection, NEURAL achieves a 93.4-97.7\% reduction in image data size
while maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming
other baseline models that use uncompressed data. By creating a persistent,
task-agnostic data asset, NEURAL resolves the trade-off between data size and
clinical utility, enabling efficient workflows and teleradiology without
sacrificing performance. Our NEURAL code is available at
https://github.com/basiralab/NEURAL.

</details>


### [151] [Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction](https://arxiv.org/abs/2508.09717)
*Shekhnaz Idrissova,Islem Rekik*

Main category: cs.CV

TL;DR: 提出了一种基于sheaf的框架，用于MRI和组织病理学数据的结构感知融合，解决了现有方法在多模态数据融合中的局限性。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤分子亚型分类需要侵入性组织提取，现有多模态方法在保留跨模态共享结构信息和处理缺失数据方面存在不足。

Method: 采用sheaf-based框架，实现MRI和组织病理学数据的结构感知和一致性融合。

Result: 模型优于基线方法，在数据缺失或不完整情况下表现稳健。

Conclusion: 该框架为快速诊断的虚拟活检工具开发提供了支持，代码已开源。

Abstract: Glioblastoma is a highly invasive brain tumor with rapid progression rates.
Recent studies have shown that glioblastoma molecular subtype classification
serves as a significant biomarker for effective targeted therapy selection.
However, this classification currently requires invasive tissue extraction for
comprehensive histopathological analysis. Existing multimodal approaches
combining MRI and histopathology images are limited and lack robust mechanisms
for preserving shared structural information across modalities. In particular,
graph-based models often fail to retain discriminative features within
heterogeneous graphs, and structural reconstruction mechanisms for handling
missing or incomplete modality data are largely underexplored. To address these
limitations, we propose a novel sheaf-based framework for structure-aware and
consistent fusion of MRI and histopathology data. Our model outperforms
baseline methods and demonstrates robustness in incomplete or missing data
scenarios, contributing to the development of virtual biopsy tools for rapid
diagnostics. Our source code is available at
https://github.com/basiralab/MMSN/.

</details>


### [152] [Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System](https://arxiv.org/abs/2508.09732)
*Romeo Valentin,Sydney M. Katz,Artur B. Carneiro,Don Walker,Mykel J. Kochenderfer*

Main category: cs.CV

TL;DR: 提出了一种基于视觉的飞机姿态估计方法，通过创新的神经网络架构、校准的预测不确定性和故障检测机制，提高了精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动的计算机视觉在航空导航中取得进展，但确保系统满足航空应用的安全性和鲁棒性仍具挑战性。

Method: 采用空间Soft Argmax算子进行概率关键点回归，设计校准预测不确定性的损失函数，并引入RAIM进行运行时故障检测。

Result: 模型在跑道图像数据集上表现优于基线架构，提供亚像素精度的校准不确定性估计。

Conclusion: 该方法为安全关键航空应用中的视觉系统认证迈出了重要一步。

Abstract: Recent advances in data-driven computer vision have enabled robust autonomous
navigation capabilities for civil aviation, including automated landing and
runway detection. However, ensuring that these systems meet the robustness and
safety requirements for aviation applications remains a major challenge. In
this work, we present a practical vision-based pipeline for aircraft pose
estimation from runway images that represents a step toward the ability to
certify these systems for use in safety-critical aviation applications. Our
approach features three key innovations: (i) an efficient, flexible neural
architecture based on a spatial Soft Argmax operator for probabilistic keypoint
regression, supporting diverse vision backbones with real-time inference; (ii)
a principled loss function producing calibrated predictive uncertainties, which
are evaluated via sharpness and calibration metrics; and (iii) an adaptation of
Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling
runtime detection and rejection of faulty model outputs. We implement and
evaluate our pose estimation pipeline on a dataset of runway images. We show
that our model outperforms baseline architectures in terms of accuracy while
also producing well-calibrated uncertainty estimates with sub-pixel precision
that can be used downstream for fault detection.

</details>


### [153] [Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://arxiv.org/abs/2508.09736)
*Lin Long,Yichen He,Wentao Ye,Yiyuan Pan,Yuan Lin,Hang Li,Junbo Zhao,Wei Li*

Main category: cs.CV

TL;DR: M3-Agent是一个具有长期记忆的多模态代理框架，能够处理实时视觉和听觉输入，构建实体中心的多模态记忆，并通过强化学习在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种更接近人类长期记忆能力的多模态代理，以提升其在复杂任务中的理解和推理能力。

Method: 采用强化学习训练M3-Agent，构建实体中心的多模态记忆，并开发M3-Bench基准测试其性能。

Result: M3-Agent在M3-Bench-robot、M3-Bench-web和VideoMME-long基准测试中分别比基线模型高出6.7%、7.7%和5.3%的准确率。

Conclusion: M3-Agent通过长期记忆和多模态推理能力，推动了多模态代理的发展，并为实际应用提供了设计参考。

Abstract: We introduce M3-Agent, a novel multimodal agent framework equipped with
long-term memory. Like humans, M3-Agent can process real-time visual and
auditory inputs to build and update its long-term memory. Beyond episodic
memory, it also develops semantic memory, enabling it to accumulate world
knowledge over time. Its memory is organized in an entity-centric, multimodal
format, allowing deeper and more consistent understanding of the environment.
Given an instruction, M3-Agent autonomously performs multi-turn, iterative
reasoning and retrieves relevant information from memory to accomplish the
task. To evaluate memory effectiveness and memory-based reasoning in multimodal
agents, we develop M3-Bench, a new long-video question answering benchmark.
M3-Bench comprises 100 newly recorded real-world videos captured from a robot's
perspective (M3-Bench-robot) and 929 web-sourced videos across diverse
scenarios (M3-Bench-web). We annotate question-answer pairs designed to test
key capabilities essential for agent applications, such as human understanding,
general knowledge extraction, and cross-modal reasoning. Experimental results
show that M3-Agent, trained via reinforcement learning, outperforms the
strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,
achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web
and VideoMME-long, respectively. Our work advances the multimodal agents toward
more human-like long-term memory and provides insights into their practical
design. Model, code and data are available at
https://github.com/bytedance-seed/m3-agent

</details>


### [154] [MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models](https://arxiv.org/abs/2508.09779)
*Dianyi Wang,Siyuan Wang,Zejun Li,Yikun Wang,Yitong Li,Duyu Tang,Xiaoyu Shen,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CV

TL;DR: 提出了一种稀疏混合专家架构（MoIIE）用于大型视觉语言模型（LVLMs），通过模态引导的路由机制同时学习模态内特征和跨模态关联，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）虽然性能出色，但计算成本高，稀疏混合专家（MoE）架构能提升参数效率，但如何同时建模模态内特征和跨模态关联仍具挑战。

Method: 提出MoIIE架构，通过模态引导的路由机制将令牌分配到模态内专家和共享的跨模态专家池，并采用两阶段训练策略激活MoE和多模态能力。

Result: 实验表明，MoIIE模型在5.5B和11.3B激活参数下，性能匹配甚至超越现有开源MoE-LLMs多模态模型，且效率更高。

Conclusion: MoIIE架构在提升LVLMs效率和性能方面具有显著优势，为多模态任务提供了一种有效的解决方案。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across multi-modal tasks by scaling model size and training data. However,
these dense LVLMs incur significant computational costs and motivate the
exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve
parameter efficiency, effectively applying MoE to simultaneously model
modality-specific features and cross-modal associations in LVLMs remains
challenging. In this work, we propose to incorporate Mixture of Intra- and
Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is
guided by its modality, directing tokens to their respective intra-modality
experts as well as a shared pool of inter-modality experts, enabling the model
to jointly learn rich intra-modal features and cross-modal interactions. We
further introduce an effective and straightforward two-stage training strategy,
which facilitates the direct activation of both MoE and multi-modal
capabilities. Extensive experiments across different data scales and LLM
backbone demonstrate the effectiveness, efficiency and generality of our
approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters
match or even surpass the performance of existing advanced open-source MoE-LLMs
based multi-modal models that involve more activated parameters. The code is
available at https://github.com/AlenjandroWang/MoIIE.

</details>


### [155] [DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.09785)
*Linpu He,Yanan Li,Bingze Li,Elvis Han Cui,Donghui Wang*

Main category: cs.CV

TL;DR: DSS-Prompt利用静态和动态提示将预训练的Vision Transformer转化为高效的FSCIL分类器，显著提升性能并缓解灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用大规模预训练模型在少样本类增量学习（FSCIL）任务中实现高效学习和避免遗忘。

Method: 提出DSS-Prompt方法，结合静态提示（适应预训练与下游任务间的领域差异）和动态提示（捕捉实例语义），利用多模态模型生成输入感知的动态提示。

Result: 在四个基准测试中，DSS-Prompt表现优于现有方法，显著缓解了灾难性遗忘问题。

Conclusion: DSS-Prompt是一种简单有效的方法，能够在不进行增量任务训练的情况下，显著提升FSCIL任务的性能。

Abstract: Learning from large-scale pre-trained models with strong generalization
ability has shown remarkable success in a wide range of downstream tasks
recently, but it is still underexplored in the challenging few-shot
class-incremental learning (FSCIL) task. It aims to continually learn new
concepts from limited training samples without forgetting the old ones at the
same time. In this paper, we introduce DSS-Prompt, a simple yet effective
approach that transforms the pre-trained Vision Transformer with minimal
modifications in the way of prompts into a strong FSCIL classifier. Concretely,
we synergistically utilize two complementary types of prompts in each
Transformer block: static prompts to bridge the domain gap between the
pre-training and downstream datasets, thus enabling better adaption; and
dynamic prompts to capture instance-aware semantics, thus enabling easy
transfer from base to novel classes. Specially, to generate dynamic prompts, we
leverage a pre-trained multi-modal model to extract input-related diverse
semantics, thereby generating complementary input-aware prompts, and then
adaptively adjust their importance across different layers. In this way, on top
of the prompted visual embeddings, a simple prototype classifier can beat
state-of-the-arts without further training on the incremental tasks. We conduct
extensive experiments on four benchmarks to validate the effectiveness of our
DSS-Prompt and show that it consistently achieves better performance than
existing approaches on all datasets and can alleviate the catastrophic
forgetting issue as well.

</details>


### [156] [MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking](https://arxiv.org/abs/2508.09796)
*Yingjie Wang,Zhixing Wang,Le Zheng,Tianxiao Liu,Roujing Li,Xueyao Hu*

Main category: cs.CV

TL;DR: MeMoSORT是一种实时多目标跟踪方法，通过改进卡尔曼滤波和自适应IoU匹配，解决了复杂运动和遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 传统跟踪方法依赖卡尔曼滤波和刚性IoU匹配，在复杂运动和遮挡下表现不佳。

Method: 提出MeKF（记忆辅助卡尔曼滤波）和Mo-IoU（运动自适应IoU）两种创新方法。

Result: 在DanceTrack和SportsMOT上分别达到67.9%和82.1%的HOTA分数，性能领先。

Conclusion: MeMoSORT在复杂场景下表现优异，具有实时性和轻量级特点。

Abstract: Multi-object tracking (MOT) in human-dominant scenarios, which involves
continuously tracking multiple people within video sequences, remains a
significant challenge in computer vision due to targets' complex motion and
severe occlusions. Conventional tracking-by-detection methods are fundamentally
limited by their reliance on Kalman filter (KF) and rigid Intersection over
Union (IoU)-based association. The motion model in KF often mismatches
real-world object dynamics, causing filtering errors, while rigid association
struggles under occlusions, leading to identity switches or target loss. To
address these issues, we propose MeMoSORT, a simple, online, and real-time MOT
tracker with two key innovations. First, the Memory-assisted Kalman filter
(MeKF) uses memory-augmented neural networks to compensate for mismatches
between assumed and actual object motion. Second, the Motion-adaptive IoU
(Mo-IoU) adaptively expands the matching space and incorporates height
similarity to reduce the influence of detection errors and association
failures, while remaining lightweight. Experiments on DanceTrack and SportsMOT
show that MeMoSORT achieves state-of-the-art performance, with HOTA scores of
67.9\% and 82.1\%, respectively.

</details>


### [157] [MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention](https://arxiv.org/abs/2508.09802)
*Xin Du,Maoyuan Xu,Zhi Ying*

Main category: cs.CV

TL;DR: MUJICA是一种基于跨图注意力机制的适配器，用于提升PBR材质超分辨率任务，解决了现有SISR方法的跨图不一致性和模态特征建模不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有SISR方法在PBR材质超分辨率任务中存在跨图不一致性、模态特征建模不足和数据分布偏移导致的泛化能力受限问题。

Method: 提出MUJICA适配器，基于预训练的Swin-transformer SISR模型，通过跨图注意力机制融合特征，同时保持预训练模型的优秀重建能力。

Result: 在SwinIR、DRCT和HMANet等SISR模型上，MUJICA显著提升了PSNR、SSIM和LPIPS分数，并保持了跨图一致性。

Conclusion: MUJICA在有限资源下实现了高效训练，并在PBR材质数据集上达到了最先进的性能。

Abstract: Physically Based Rendering (PBR) materials are typically characterized by
multiple 2D texture maps such as basecolor, normal, metallic, and roughness
which encode spatially-varying bi-directional reflectance distribution function
(SVBRDF) parameters to model surface reflectance properties and microfacet
interactions. Upscaling SVBRDF material is valuable for modern 3D graphics
applications. However, existing Single Image Super-Resolution (SISR) methods
struggle with cross-map inconsistency, inadequate modeling of modality-specific
features, and limited generalization due to data distribution shifts. In this
work, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention
(MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based
SISR models for PBR material super-resolution. MUJICA is seamlessly attached
after the pre-trained and frozen SISR backbone. It leverages cross-map
attention to fuse features while preserving remarkable reconstruction ability
of the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and
HMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map
consistency. Experiments demonstrate that MUJICA enables efficient training
even with limited resources and delivers state-of-the-art performance on PBR
material datasets.

</details>


### [158] [Poaching Hotspot Identification Using Satellite Imagery](https://arxiv.org/abs/2508.09812)
*Aryan Pandhi,Shrey Baid,Sanjali Jha*

Main category: cs.CV

TL;DR: 非洲象偷猎问题持续多年，导致森林象濒危、草原象极度濒危。偷猎地点动态变化，计算机视觉模型可帮助识别热点区域。


<details>
  <summary>Details</summary>
Motivation: 偷猎活动持续上升，传统反偷猎方法效率低，需新技术动态监测偷猎热点。

Method: 利用计算机视觉模型结合卫星图像，自动识别适合偷猎的地理特征。

Result: 模型可高效监测大范围区域，减少人为干扰和资源浪费。

Conclusion: 计算机视觉模型为动态反偷猎提供了高效解决方案。

Abstract: Elephant Poaching in African countries has been a decade-old problem. So much
so that African Forest Elephants are now listed as an endangered species, and
African Savannah Elephants as critically endangered by the IUCN (International
Union for Conservation of Nature). [1] Elephants are hunted primarily for their
ivory tusks which caused many elephants to be born tuskless as a genetic
modification for survival. [2] Data gathered by recent studies shows that
though poaching methods remain the same, the poaching grounds are rather
dynamic. Poachers have shifted to areas with less ranger patrols and several
other factors like watering holes, seasons, altitude etc. cause constant shifts
in poaching hotspot locations. [3] After a period of low poaching from
2000-2014, poaching numbers in African countries are now on the rise again --
WWF (World Wildlife Foundation) says there are 20,000 elephants poached
annually [4]. In African countries, anti-poaching efforts are concentrated near
towns, while a majority of poaching occurs in the deserted regions. All of
these factors result in the need for a Computer Vision Model to identify
poaching hotspots through locating the geographic indicators of favorable
poaching regions. A CV model eliminates the need to manually track poachers and
account for the environmental factors to deploy resources and its combination
with satellite imagery allows us to survey large areas without disturbing local
species or cross border aviation restrictions.

</details>


### [159] [Evolution of Low-Level and Texture Human-CLIP Alignment](https://arxiv.org/abs/2508.09814)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra*

Main category: cs.CV

TL;DR: CLIP模型训练早期与人类低层次图像质量评估相关性高，随后逐渐下降，原因与形状-纹理偏差和噪声下分类准确性有关。


<details>
  <summary>Details</summary>
Motivation: 研究CLIP训练中与人类低层次感知相关性先升后降的现象，探索其背后的机制。

Method: 分析形状-纹理偏差对齐和噪声下分类准确性两个关键因素。

Result: CLIP早期学习低层次视觉特征，后期转向抽象形状表征，影响感知对齐与噪声鲁棒性。

Conclusion: 揭示了感知对齐与鲁棒性的权衡机制，为优化视觉-语言模型提供新思路。

Abstract: During the training of multi-modal models like CLIP, we observed an
intriguing phenomenon: the correlation with low-level human image quality
assessments peaks in the early epochs before gradually declining. This study
investigates this observation and seeks to understand its causes through two
key factors: shape-texture bias alignment and classification accuracy drop
under noise. Our findings suggest that CLIP initially learn low-level visual
features, enhancing its alignment with low-level human perception but also
increasing its sensitivity to noise and its texture bias. As training
progresses, the model shifts toward more abstract shape-based representations,
improving noise robustness but reducing alignment with low-level human
perception. These results suggest that these factors shared an underlying
learning mechanism and provide new insights into optimizing the trade-off
between perceptual alignment and robustness in vision-language models.

</details>


### [160] [ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video](https://arxiv.org/abs/2508.09818)
*Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Abir Ahmed,Liew Tze Hui*

Main category: cs.CV

TL;DR: ViMoNet是一个结合视频和运动数据的框架，用于理解和推断人类行为，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅关注运动数据或视频，无法全面捕捉人类行为的细微差异，因此需要结合两种数据。

Method: 提出ViMoNet框架，采用联合训练策略，结合精确的运动-文本数据和通用的视频-文本数据，并创建新数据集VIMOS和评估基准ViMoNet-Bench。

Result: ViMoNet在字幕生成、运动理解和行为解释方面优于现有方法。

Conclusion: 结合视频和运动数据的ViMoNet能更全面地理解和推断人类行为。

Abstract: This study investigates how large language models (LLMs) can be used to
understand human behavior using motion and video data. We think that mixing
both types is essential to completely capture the nuanced movements and
meanings of human actions, in contrast to recent models that simply concentrate
on motion data or films. To address this, we provide ViMoNet, a straightforward
yet effective framework for comprehending, characterizing, and deducing human
action. ViMoNet employs a joint training strategy that leverages the advantages
of two data types: detailed motion-text data, which is more exact, and generic
video-text data, which is more comprehensive but less detailed. This aids in
the model's acquisition of rich data regarding time and space in human
behavior. Additionally, we provide a brand new dataset named VIMOS that
contains a variety of films, motion sequences, instructions, and subtitles. We
developed ViMoNet-Bench, a standardized benchmark with carefully labeled
samples, to evaluate how well models understand human behavior. Our tests show
that ViMoNet outperforms existing methods in caption generation, motion
understanding, and behavior interpretation.

</details>


### [161] [Physical Autoregressive Model for Robotic Manipulation without Action Pretraining](https://arxiv.org/abs/2508.09822)
*Zijian Song,Sihan Qin,Tianshui Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: PAR利用视频预训练模型，结合物理令牌和DiT去令牌化技术，提升机器人操作任务的成功率和视频预测准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作数据稀缺问题，利用跨模态预训练模型的世界知识。

Method: 提出PAR模型，结合物理令牌、DiT去令牌化、因果掩码和逆运动学等技术。

Result: 在ManiSkill基准测试中，PushCube任务成功率100%，其他任务表现与基线相当。

Conclusion: PAR展示了通过视频预训练迁移世界知识在机器人操作中的潜力。

Abstract: The scarcity of manipulation data has motivated the use of pretrained large
models from other modalities in robotics. In this work, we build upon
autoregressive video generation models to propose a Physical Autoregressive
Model (PAR), where physical tokens combine frames and actions to represent the
joint evolution of the robot and its environment. PAR leverages the world
knowledge embedded in video pretraining to understand physical dynamics without
requiring action pretraining, enabling accurate video prediction and consistent
action trajectories. It also adopts a DiT-based de-tokenizer to model frames
and actions as continuous tokens, mitigating quantization errors and
facilitating mutual enhancement. Furthermore, we incorporate a causal mask with
inverse kinematics, parallel training, and the KV-cache mechanism to further
improve performance and efficiency. Experiments on the ManiSkill benchmark show
that PAR achieves a 100\% success rate on the PushCube task, matches the
performance of action-pretrained baselines on other tasks, and accurately
predicts future videos with tightly aligned action trajectories. These findings
underscore a promising direction for robotic manipulation by transferring world
knowledge from autoregressive video pretraining.

</details>


### [162] [KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.09823)
*Valentin Boussot,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: KonfAI是一个模块化、可扩展且完全可配置的深度学习框架，专为医学影像任务设计，通过YAML配置文件实现工作流定义，提升可重复性和开发效率。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像任务中深度学习工作流的可配置性、可重复性和开发效率问题。

Method: 使用结构化YAML配置文件定义训练、推理和评估工作流，支持高级策略（如补丁学习、模型集成）和自定义组件。

Result: 成功应用于分割、配准和图像合成任务，并在多个国际医学影像挑战中取得优异表现。

Conclusion: KonfAI通过模块化和可扩展设计，显著提升了医学影像任务的开发效率和实验可追溯性。

Abstract: KonfAI is a modular, extensible, and fully configurable deep learning
framework specifically designed for medical imaging tasks. It enables users to
define complete training, inference, and evaluation workflows through
structured YAML configuration files, without modifying the underlying code.
This declarative approach enhances reproducibility, transparency, and
experimental traceability while reducing development time. Beyond the
capabilities of standard pipelines, KonfAI provides native abstractions for
advanced strategies including patch-based learning, test-time augmentation,
model ensembling, and direct access to intermediate feature representations for
deep supervision. It also supports complex multi-model training setups such as
generative adversarial architectures. Thanks to its modular and extensible
architecture, KonfAI can easily accommodate custom models, loss functions, and
data processing components. The framework has been successfully applied to
segmentation, registration, and image synthesis tasks, and has contributed to
top-ranking results in several international medical imaging challenges. KonfAI
is open source and available at
\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.

</details>


### [163] [Reverse Convolution and Its Applications to Image Restoration](https://arxiv.org/abs/2508.09824)
*Xuhong Huang,Shiqi Liu,Kai Zhang,Ying Tai,Jian Yang,Hui Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种新颖的深度反向卷积算子，用于有效反转深度卷积，并通过实验验证其在图像恢复任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统转置卷积并非卷积的真正逆运算，缺乏标准化的反向卷积算子，限制了神经网络的设计与应用。

Method: 通过正则化最小二乘优化问题，提出深度反向卷积算子，并结合层归一化、1×1卷积和GELU激活构建反向卷积块。

Result: 实验表明，提出的反向卷积算子作为基础模块有效，ConverseNet在去噪、超分辨率和去模糊任务中表现优异。

Conclusion: 该工作为深度学习模型设计中的新算子开发提供了新思路，具有广泛的应用潜力。

Abstract: Convolution and transposed convolution are fundamental operators widely used
in neural networks. However, transposed convolution (a.k.a. deconvolution) does
not serve as a true inverse of convolution due to inherent differences in their
mathematical formulations. To date, no reverse convolution operator has been
established as a standard component in neural architectures. In this paper, we
propose a novel depthwise reverse convolution operator as an initial attempt to
effectively reverse depthwise convolution by formulating and solving a
regularized least-squares optimization problem. We thoroughly investigate its
kernel initialization, padding strategies, and other critical aspects to ensure
its effective implementation. Building upon this operator, we further construct
a reverse convolution block by combining it with layer normalization,
1$\times$1 convolution, and GELU activation, forming a Transformer-like
structure. The proposed operator and block can directly replace conventional
convolution and transposed convolution layers in existing architectures,
leading to the development of ConverseNet. Corresponding to typical image
restoration models such as DnCNN, SRResNet and USRNet, we train three variants
of ConverseNet for Gaussian denoising, super-resolution and deblurring,
respectively. Extensive experiments demonstrate the effectiveness of the
proposed reverse convolution operator as a basic building module. We hope this
work could pave the way for developing new operators in deep model design and
applications.

</details>


### [164] [Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment](https://arxiv.org/abs/2508.09843)
*Hao Yang,Xu Zhang,Jiaqi Ma,Linwei Zhu,Yun Zhang,Huan Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于图神经网络的OIQA框架，通过显式建模视口间的结构关系来提升对空间失真非均匀性的感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有OIQA方法难以评估局部非均匀失真，因为缺乏对质量空间变化的建模以及无法有效捕捉局部细节和全局上下文的特征表示。

Method: 使用斐波那契球采样生成具有良好拓扑结构的视口，每个视口作为图节点；结合多阶段特征提取网络和GAT与图变换器，捕捉局部和长程质量依赖关系。

Result: 在两个大规模OIQA数据库上的实验表明，该方法显著优于现有方法，证明了其有效性和强泛化能力。

Conclusion: 提出的框架通过建模视口间的结构关系，显著提升了OIQA任务中对空间失真非均匀性的评估能力。

Abstract: Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to
evaluate locally non-uniform distortions due to inadequate modeling of spatial
variations in quality and ineffective feature representation capturing both
local details and global context. To address this, we propose a graph neural
network-based OIQA framework that explicitly models structural relationships
between viewports to enhance perception of spatial distortion non-uniformity.
Our approach employs Fibonacci sphere sampling to generate viewports with
well-structured topology, representing each as a graph node. Multi-stage
feature extraction networks then derive high-dimensional node representation.
To holistically capture spatial dependencies, we integrate a Graph Attention
Network (GAT) modeling fine-grained local distortion variations among adjacent
viewports, and a graph transformer capturing long-range quality interactions
across distant regions. Extensive experiments on two large-scale OIQA databases
with complex spatial distortions demonstrate that our method significantly
outperforms existing approaches, confirming its effectiveness and strong
generalization capability.

</details>


### [165] [Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance](https://arxiv.org/abs/2508.09847)
*Dhruvraj Singh Rawat,Enggen Sherpa,Rishikesan Kirupanantha,Tin Hoang*

Main category: cs.CV

TL;DR: 论文提出了在小规模CelebAMask-HQ数据集上评估扩散模型的人脸生成性能，比较了UNet和DiT架构的无条件生成，并探索了基于LoRA的预训练Stable Diffusion模型微调。通过引入InfoNCE损失和SegFormer分割编码器，提升了属性引导合成的语义对齐和可控性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改进扩散模型在有限数据环境下的人脸生成性能，特别是在属性引导合成的可控性和语义对齐方面。

Method: 比较了UNet和DiT架构的无条件生成，并采用LoRA微调预训练Stable Diffusion模型。引入了InfoNCE损失和SegFormer分割编码器，以增强属性嵌入和分割编码。

Result: 结果表明，对比嵌入学习和先进分割编码在有限数据环境下能有效提升人脸生成的可控性和语义对齐。

Conclusion: 论文通过引入InfoNCE损失和SegFormer编码器，显著提升了属性引导合成的性能，为小规模数据集上的可控人脸生成提供了有效解决方案。

Abstract: We present a benchmark of diffusion models for human face generation on a
small-scale CelebAMask-HQ dataset, evaluating both unconditional and
conditional pipelines. Our study compares UNet and DiT architectures for
unconditional generation and explores LoRA-based fine-tuning of pretrained
Stable Diffusion models as a separate experiment. Building on the
multi-conditioning approach of Giambi and Lisanti, which uses both attribute
vectors and segmentation masks, our main contribution is the integration of an
InfoNCE loss for attribute embedding and the adoption of a SegFormer-based
segmentation encoder. These enhancements improve the semantic alignment and
controllability of attribute-guided synthesis. Our results highlight the
effectiveness of contrastive embedding learning and advanced segmentation
encoding for controlled face generation in limited data settings.

</details>


### [166] [Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment](https://arxiv.org/abs/2508.09850)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Valero Laparra,Jesus Malo*

Main category: cs.CV

TL;DR: 研究发现，视觉变换器（ViTs）在图像识别任务中表现优异，但与人类感知的对齐程度受模型大小、数据集规模、数据增强和正则化等因素影响。


<details>
  <summary>Details</summary>
Motivation: 探索ViTs与人类感知的对齐程度，为需要类人视觉理解的应用提供指导。

Method: 在TID2013数据集上系统分析模型大小、数据集规模、数据增强和正则化对ViT感知对齐的影响。

Result: 大模型对齐度较低；增加数据集多样性影响小，但重复训练会降低对齐；强数据增强和正则化进一步减少对齐。

Conclusion: 模型复杂性、训练策略与人类感知对齐之间存在权衡，需在应用中慎重考虑。

Abstract: Vision Transformers (ViTs) achieve remarkable performance in image
recognition tasks, yet their alignment with human perception remains largely
unexplored. This study systematically analyzes how model size, dataset size,
data augmentation and regularization impact ViT perceptual alignment with human
judgments on the TID2013 dataset. Our findings confirm that larger models
exhibit lower perceptual alignment, consistent with previous works. Increasing
dataset diversity has a minimal impact, but exposing models to the same images
more times reduces alignment. Stronger data augmentation and regularization
further decrease alignment, especially in models exposed to repeated training
cycles. These results highlight a trade-off between model complexity, training
strategies, and alignment with human perception, raising important
considerations for applications requiring human-like visual understanding.

</details>


### [167] [OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better](https://arxiv.org/abs/2508.09857)
*Yupeng Zhou,Zhen Li,Ziheng Ouyang,Yuming Chen,Ruoyi Du,Daquan Zhou,Bin Fu,Yihao Liu,Peng Gao,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: 论文提出了一种名为OneVAE的方法，通过结合连续和离散视频VAE的优势，解决了离散视频VAE训练不稳定、时间长和重建质量差的问题。


<details>
  <summary>Details</summary>
Motivation: 离散视频VAE在训练和性能上存在不足，而连续VAE表现更好，因此希望通过结合两者提升离散视频VAE的性能。

Method: 利用FSQ保留连续VAE的先验知识，提出多令牌量化机制和强化首帧重建，并设计联合离散-连续优化方案。

Result: 方法收敛速度快数倍，PSNR提升近1 dB，并在高压缩视频VAE中显著提升性能。

Conclusion: OneVAE首次在单一网络中实现了连续和离散表示的竞争性性能，统一了两种范式。

Abstract: Encoding videos into discrete tokens could align with text tokens to
facilitate concise and unified multi-modal LLMs, yet introducing significant
spatiotemporal compression compared to continuous video representation.
Previous discrete video VAEs experienced unstable training, long training time,
and degraded reconstruction quality. Given the easier training and superior
performance of continuous VAEs, an intuitive idea is to enhance discrete video
VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between
discrete and continuous representations, we found that FSQ could effectively
preserve pre-trained continuous VAE priors compared to other quantization
methods. By leveraging continuous VAE priors, it converges several times faster
than training from scratch and achieves superior performance at convergence.
Meanwhile, two structural improvements are proposed. First, inspired by how
continuous VAEs enhance reconstruction via enlarged latent dimensions, we
introduce a multi-token quantization mechanism, which achieves nearly a 1 dB
improvement in PSNR without compromising the token compression ratio. Second,
to tackle reconstruction challenges in high-compression video VAEs, we
strengthen first-frame reconstruction, enabling the causal VAE to leverage this
information in subsequent frames and markedly improving the performance of 4 x
16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous
optimization scheme that unifies the two paradigms and, for the first time,
achieves competitive performance on both continuous and discrete
representations within a single network. We name our method OneVAE to reflect
this connection.

</details>


### [168] [HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics](https://arxiv.org/abs/2508.09858)
*Weiqi Li,Zehao Zhang,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: HumanGenesis框架通过四个协作代理解决合成人类动态中的几何不一致和运动泛化问题，实现了高保真视频合成。


<details>
  <summary>Details</summary>
Motivation: 当前方法在几何一致性和运动泛化方面存在不足，HumanGenesis旨在解决这些问题。

Method: 整合几何与生成建模，通过Reconstructor、Critique Agent、Pose Guider和Video Harmonizer四个代理协作。

Result: 在文本引导合成、视频重演和新姿势泛化等任务中达到最先进性能。

Conclusion: HumanGenesis显著提升了表达力、几何保真度和场景融合能力。

Abstract: \textbf{Synthetic human dynamics} aims to generate photorealistic videos of
human subjects performing expressive, intention-driven motions. However,
current approaches face two core challenges: (1) \emph{geometric inconsistency}
and \emph{coarse reconstruction}, due to limited 3D modeling and detail
preservation; and (2) \emph{motion generalization limitations} and \emph{scene
inharmonization}, stemming from weak generative capabilities. To address these,
we present \textbf{HumanGenesis}, a framework that integrates geometric and
generative modeling through four collaborative agents: (1)
\textbf{Reconstructor} builds 3D-consistent human-scene representations from
monocular video using 3D Gaussian Splatting and deformation decomposition. (2)
\textbf{Critique Agent} enhances reconstruction fidelity by identifying and
refining poor regions via multi-round MLLM-based reflection. (3) \textbf{Pose
Guider} enables motion generalization by generating expressive pose sequences
using time-aware parametric encoders. (4) \textbf{Video Harmonizer} synthesizes
photorealistic, coherent video via a hybrid rendering pipeline with diffusion,
refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis
achieves state-of-the-art performance on tasks including text-guided synthesis,
video reenactment, and novel-pose generalization, significantly improving
expressiveness, geometric fidelity, and scene integration.

</details>


### [169] [E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras](https://arxiv.org/abs/2508.09912)
*Chaoran Feng,Zhenyu Tang,Wangbo Yu,Yatian Pang,Yian Zhao,Jianbin Zhao,Li Yuan,Yonghong Tian*

Main category: cs.CV

TL;DR: 提出E-4DGS，一种基于事件相机的动态高斯泼溅方法，用于多视角事件流的新视角合成，克服传统RGB相机的限制。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在光照、动态范围和运动模糊方面存在局限，事件相机因其低功耗、高时间分辨率和高动态范围，为高速运动和低光场景的重建提供了新思路。

Method: 提出事件驱动的初始化方案和事件自适应切片泼溅技术，结合强度重要性修剪和自适应对比度阈值优化。

Result: E-4DGS在合成多视角事件流数据集上表现优于纯事件和事件-RGB融合基线方法。

Conclusion: E-4DGS为多视角事件流重建提供了一种新方法，推动了快速场景捕捉的探索。

Abstract: Novel view synthesis and 4D reconstruction techniques predominantly rely on
RGB cameras, thereby inheriting inherent limitations such as the dependence on
adequate lighting, susceptibility to motion blur, and a limited dynamic range.
Event cameras, offering advantages of low power, high temporal resolution and
high dynamic range, have brought a new perspective to addressing the scene
reconstruction challenges in high-speed motion and low-light scenes. To this
end, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting
approach, for novel view synthesis from multi-view event streams with
fast-moving cameras. Specifically, we introduce an event-based initialization
scheme to ensure stable training and propose event-adaptive slicing splatting
for time-aware reconstruction. Additionally, we employ intensity importance
pruning to eliminate floating artifacts and enhance 3D consistency, while
incorporating an adaptive contrast threshold for more precise optimization. We
design a synthetic multi-view camera setup with six moving event cameras
surrounding the object in a 360-degree configuration and provide a benchmark
multi-view event stream dataset that captures challenging motion scenarios. Our
approach outperforms both event-only and event-RGB fusion baselines and paves
the way for the exploration of multi-view event-based reconstruction as a novel
approach for rapid scene capture.

</details>


### [170] [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://arxiv.org/abs/2508.09913)
*Yachao Liang,Min Yu,Gang Li,Jianguo Jiang,Boquan Li,Feng Yu,Ning Zhang,Xiang Meng,Weiqing Huang*

Main category: cs.CV

TL;DR: 论文提出了一种基于音频-视觉语音表示学习的新方法，用于检测伪造视频，通过自监督掩码预测任务学习真实视频的语音表示，并在伪造检测任务中表现出优异的跨数据集泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 伪造视频检测在数字取证中具有挑战性，尤其是对未见数据集和常见扰动的泛化能力。研究发现，富含语音内容的音频信号能有效反映面部运动，因此利用音频与视觉语音元素的协同作用成为解决这一问题的关键。

Method: 首先通过自监督掩码预测任务学习真实视频的精确音频-视觉语音表示，同时编码局部和全局语义信息；然后将学习到的模型直接迁移到伪造检测任务中。

Result: 实验表明，该方法在跨数据集泛化和鲁棒性方面优于现有技术，且无需在训练中使用任何伪造视频。

Conclusion: 通过音频-视觉语音表示学习，论文提出了一种高效且泛化能力强的伪造视频检测方法，为数字取证领域提供了新的解决方案。

Abstract: Detection of face forgery videos remains a formidable challenge in the field
of digital forensics, especially the generalization to unseen datasets and
common perturbations. In this paper, we tackle this issue by leveraging the
synergy between audio and visual speech elements, embarking on a novel approach
through audio-visual speech representation learning. Our work is motivated by
the finding that audio signals, enriched with speech content, can provide
precise information effectively reflecting facial movements. To this end, we
first learn precise audio-visual speech representations on real videos via a
self-supervised masked prediction task, which encodes both local and global
semantic information simultaneously. Then, the derived model is directly
transferred to the forgery detection task. Extensive experiments demonstrate
that our method outperforms the state-of-the-art methods in terms of
cross-dataset generalization and robustness, without the participation of any
fake video in model training. Code is available at
https://github.com/Eleven4AI/SpeechForensics.

</details>


### [171] [Towards Comprehensive Cellular Characterisation of H&E slides](https://arxiv.org/abs/2508.09926)
*Benjamin Adjadj,Pierre-Antoine Bannier,Guillaume Horent,Sebastien Mandela,Aurore Lyon,Kathryn Schutte,Ulysse Marteau,Valentin Gaury,Laura Dumont,Thomas Mathieu,Reda Belbahri,Benoît Schmauch,Eric Durand,Katharina Von Loga,Lucie Gillet*

Main category: cs.CV

TL;DR: HistoPLUS是一种先进的细胞分析模型，针对肿瘤微环境中的细胞检测、分割和分类问题，显著提升了性能并减少了参数需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法在罕见细胞类型和跨域泛化上表现不佳，HistoPLUS旨在解决这些问题。

Method: 基于一个包含108,722个细胞核的新数据集，训练了HistoPLUS模型，覆盖13种细胞类型。

Result: 在外部验证中，HistoPLUS在检测质量和分类F1分数上分别提升了5.2%和23.7%，且参数减少5倍。

Conclusion: HistoPLUS显著改善了罕见细胞类型的研究，并展示了强大的跨域泛化能力，支持更广泛的肿瘤微环境研究。

Abstract: Cell detection, segmentation and classification are essential for analyzing
tumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing
methods suffer from poor performance on understudied cell types (rare or not
present in public datasets) and limited cross-domain generalization. To address
these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell
analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei
covering 13 cell types. In external validation across 4 independent cohorts,
HistoPLUS outperforms current state-of-the-art models in detection quality by
5.2% and overall F1 classification score by 23.7%, while using 5x fewer
parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types
and brings significant improvements on 8 of 13 cell types. Moreover, we show
that HistoPLUS robustly transfers to two oncology indications unseen during
training. To support broader TME biomarker research, we release the model
weights and inference code at https://github.com/owkin/histoplus/.

</details>


### [172] [Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?](https://arxiv.org/abs/2508.09936)
*Vittorio Pippi,Konstantina Nikolaidou,Silvia Cascianelli,George Retsinas,Giorgos Sfikas,Rita Cucchiara,Marcus Liwicki*

Main category: cs.CV

TL;DR: 论文探讨了手写文本生成（HTG）模型在低资源手写文本识别（HTR）中的有效性，比较了三种先进HTG模型对HTR微调的影响。


<details>
  <summary>Details</summary>
Motivation: 解决历史手稿数字化中HTR系统因数据分布差异导致的性能问题，HTG技术提供了一种潜在的解决方案。

Method: 系统比较了三种HTG模型（生成对抗、扩散和自回归范式），分析合成数据的视觉和语言特征对HTR微调的影响。

Result: 提供了选择最有效HTG模型的定量指南，并揭示了HTG方法在低资源HTR中的当前能力和改进方向。

Conclusion: HTG模型在低资源HTR中具有潜力，但仍需进一步改进。

Abstract: The digitization of historical manuscripts presents significant challenges
for Handwritten Text Recognition (HTR) systems, particularly when dealing with
small, author-specific collections that diverge from the training data
distributions. Handwritten Text Generation (HTG) techniques, which generate
synthetic data tailored to specific handwriting styles, offer a promising
solution to address these challenges. However, the effectiveness of various HTG
models in enhancing HTR performance, especially in low-resource transcription
settings, has not been thoroughly evaluated. In this work, we systematically
compare three state-of-the-art styled HTG models (representing the generative
adversarial, diffusion, and autoregressive paradigms for HTG) to assess their
impact on HTR fine-tuning. We analyze how visual and linguistic characteristics
of synthetic data influence fine-tuning outcomes and provide quantitative
guidelines for selecting the most effective HTG model. The results of our
analysis provide insights into the current capabilities of HTG methods and
highlight key areas for further improvement in their application to
low-resource HTR.

</details>


### [173] [AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models](https://arxiv.org/abs/2508.09943)
*Tomás de la Sotta,José M. Saavedra,Héctor Henríquez,Violeta Chang,Aline Xavier*

Main category: cs.CV

TL;DR: AST-n框架通过从中间噪声水平启动反向扩散并结合高阶ODE求解器，显著加速低剂量CT去噪，25步内达到高质量结果。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）减少辐射但增加噪声，影响诊断信心，需高效去噪方法。

Method: 提出AST-n框架，结合中间噪声启动和高阶ODE求解器，减少采样步骤。

Result: AST-25在25步内PSNR>38 dB，SSIM>0.95，推理时间从16秒降至1秒。

Conclusion: AST-n结合高阶求解器实现快速高质量LDCT重建，适合临床应用。

Abstract: Low-dose CT (LDCT) protocols reduce radiation exposure but increase image
noise, compromising diagnostic confidence. Diffusion-based generative models
have shown promise for LDCT denoising by learning image priors and performing
iterative refinement. In this work, we introduce AST-n, an accelerated
inference framework that initiates reverse diffusion from intermediate noise
levels, and integrate high-order ODE solvers within conditioned models to
further reduce sampling steps. We evaluate two acceleration paradigms--AST-n
sampling and standard scheduling with high-order solvers -- on the Low Dose CT
Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %
of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak
signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)
above 0.95, closely matching standard baselines while cutting inference time
from ~16 seg to under 1 seg per slice. Unconditional sampling suffers
substantial quality loss, underscoring the necessity of conditioning. We also
assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling
inference time, limiting its clinical practicality. Our results demonstrate
that AST-n with high-order samplers enables rapid LDCT reconstruction without
significant loss of image fidelity, advancing the feasibility of
diffusion-based methods in clinical workflows.

</details>


### [174] [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)
*Trevine Oorloff,Vishwanath Sindagi,Wele Gedara Chaminda Bandara,Ali Shafahi,Amin Ghiasi,Charan Prakash,Reza Ardekani*

Main category: cs.CV

TL;DR: 利用现成的Stable Diffusion模型进行视觉上下文学习（V-ICL），无需额外微调即可适应多种视觉任务。


<details>
  <summary>Details</summary>
Motivation: 探索如何简化视觉上下文学习过程，避免复杂的训练和额外数据需求，提高通用性。

Method: 在Stable Diffusion的自注意力层中重新计算注意力，显式结合查询和示例提示的上下文。

Result: 在六个视觉任务上表现优异，例如前景分割任务在Pascal-5i数据集上mIoU提升8.9%。

Conclusion: 该方法无需微调即可高效适应多种任务，并通过集成多提示进一步提升性能。

Abstract: Large language models (LLM) in natural language processing (NLP) have
demonstrated great potential for in-context learning (ICL) -- the ability to
leverage a few sets of example prompts to adapt to various tasks without having
to explicitly update the model weights. ICL has recently been explored for
computer vision tasks with promising early outcomes. These approaches involve
specialized training and/or additional data that complicate the process and
limit its generalizability. In this work, we show that off-the-shelf Stable
Diffusion models can be repurposed for visual in-context learning (V-ICL).
Specifically, we formulate an in-place attention re-computation within the
self-attention layers of the Stable Diffusion architecture that explicitly
incorporates context between the query and example prompts. Without any
additional fine-tuning, we show that this repurposed Stable Diffusion model is
able to adapt to six different tasks: foreground segmentation, single object
detection, semantic segmentation, keypoint detection, edge detection, and
colorization. For example, the proposed approach improves the mean intersection
over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by
8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,
respectively. Additionally, we show that the proposed method is able to
effectively leverage multiple prompts through ensembling to infer the task
better and further improve the performance.

</details>


### [175] [LIA-X: Interpretable Latent Portrait Animator](https://arxiv.org/abs/2508.09959)
*Yaohui Wang,Di Yang,Xinyuan Chen,Francois Bremond,Yu Qiao,Antitza Dantcheva*

Main category: cs.CV

TL;DR: LIA-X是一种新型可解释的肖像动画生成器，通过稀疏运动字典实现细粒度控制，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在面部动态转移中缺乏可解释性和细粒度控制的问题。

Method: 采用自编码器结构，通过稀疏运动字典将面部动态分解为可解释因素，支持“编辑-变形-渲染”策略。

Result: 在自重现和跨重现任务中表现优异，支持大规模模型训练（约10亿参数）。

Conclusion: LIA-X在可解释性、可控性和性能上均优于现有方法，适用于图像、视频编辑和3D肖像视频处理。

Abstract: We introduce LIA-X, a novel interpretable portrait animator designed to
transfer facial dynamics from a driving video to a source portrait with
fine-grained control. LIA-X is an autoencoder that models motion transfer as a
linear navigation of motion codes in latent space. Crucially, it incorporates a
novel Sparse Motion Dictionary that enables the model to disentangle facial
dynamics into interpretable factors. Deviating from previous 'warp-render'
approaches, the interpretability of the Sparse Motion Dictionary allows LIA-X
to support a highly controllable 'edit-warp-render' strategy, enabling precise
manipulation of fine-grained facial semantics in the source portrait. This
helps to narrow initial differences with the driving video in terms of pose and
expression. Moreover, we demonstrate the scalability of LIA-X by successfully
training a large-scale model with approximately 1 billion parameters on
extensive datasets. Experimental results show that our proposed method
outperforms previous approaches in both self-reenactment and cross-reenactment
tasks across several benchmarks. Additionally, the interpretable and
controllable nature of LIA-X supports practical applications such as
fine-grained, user-guided image and video editing, as well as 3D-aware portrait
video manipulation.

</details>


### [176] [MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification](https://arxiv.org/abs/2508.09967)
*Tianqi Xiang,Yi Li,Qixiang Zhang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出了一种元优化分类器（MOC），通过元学习自动优化分类器配置，显著提升了少样本条件下的WSI分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本方法在数据稀缺时表现不佳，需改进以适用于临床部署。

Method: MOC包含元学习器和分类器库，自动优化分类器配置，实现全面病理解释。

Result: 在多个少样本基准测试中表现优异，TCGA-NSCLC基准上AUC提升10.4%，1-shot条件下提升26.25%。

Conclusion: MOC为数据稀缺的临床场景提供了重要解决方案。

Abstract: Recent advances in histopathology vision-language foundation models (VLFMs)
have shown promise in addressing data scarcity for whole slide image (WSI)
classification via zero-shot adaptation. However, these methods remain
outperformed by conventional multiple instance learning (MIL) approaches
trained on large datasets, motivating recent efforts to enhance VLFM-based WSI
classification through fewshot learning paradigms. While existing few-shot
methods improve diagnostic accuracy with limited annotations, their reliance on
conventional classifier designs introduces critical vulnerabilities to data
scarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC)
comprising two core components: (1) a meta-learner that automatically optimizes
a classifier configuration from a mixture of candidate classifiers and (2) a
classifier bank housing diverse candidate classifiers to enable a holistic
pathological interpretation. Extensive experiments demonstrate that MOC
outperforms prior arts in multiple few-shot benchmarks. Notably, on the
TCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art
few-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions,
offering a critical advancement for clinical deployments where diagnostic
training data is severely limited. Code is available at
https://github.com/xmed-lab/MOC.

</details>


### [177] [PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image](https://arxiv.org/abs/2508.09973)
*Geonhee Sim,Gyeongsik Moon*

Main category: cs.CV

TL;DR: PERSONA结合3D和扩散模型方法，从单张图像创建个性化3D人体化身，解决身份保持和姿势驱动变形问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在身份保持和姿势驱动变形上各有不足，PERSONA旨在结合两者优势。

Method: 利用扩散模型生成姿势丰富的视频，并通过平衡采样和几何加权优化优化3D化身。

Result: 实现了从单张图像生成高质量、身份一致的3D化身。

Conclusion: PERSONA为个性化3D化身提供了一种高效且实用的解决方案。

Abstract: Two major approaches exist for creating animatable human avatars. The first,
a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a
single person, achieving personalization through a disentangled identity
representation. However, modeling pose-driven deformations, such as non-rigid
cloth deformations, requires numerous pose-rich videos, which are costly and
impractical to capture in daily life. The second, a diffusion-based approach,
learns pose-driven deformations from large-scale in-the-wild videos but
struggles with identity preservation and pose-dependent identity entanglement.
We present PERSONA, a framework that combines the strengths of both approaches
to obtain a personalized 3D human avatar with pose-driven deformations from a
single image. PERSONA leverages a diffusion-based approach to generate
pose-rich videos from the input image and optimizes a 3D avatar based on them.
To ensure high authenticity and sharp renderings across diverse poses, we
introduce balanced sampling and geometry-weighted optimization. Balanced
sampling oversamples the input image to mitigate identity shifts in
diffusion-generated training videos. Geometry-weighted optimization prioritizes
geometry constraints over image loss, preserving rendering quality in diverse
poses.

</details>


### [178] [A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation](https://arxiv.org/abs/2508.09977)
*Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding*

Main category: cs.CV

TL;DR: 3D高斯泼溅（3DGS）作为NeRF的替代方案，提供高保真实时渲染，支持多种下游应用。本文综述了3DGS在分割、编辑、生成等任务中的进展。


<details>
  <summary>Details</summary>
Motivation: 探索3DGS在3D场景表示中的潜力及其在几何和语义理解中的应用。

Method: 综述了3DGS的应用，包括2D基础模型、NeRF方法对比，以及分类任务（如分割、编辑、生成）。

Result: 总结了代表性方法、监督策略和学习范式，并提供了数据集和评估协议的比较分析。

Conclusion: 3DGS在多种任务中表现出色，未来研究可通过公开资源库持续跟进。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative
to Neural Radiance Fields (NeRF) for 3D scene representation, offering
high-fidelity photorealistic rendering with real-time performance. Beyond novel
view synthesis, the explicit and compact nature of 3DGS enables a wide range of
downstream applications that require geometric and semantic understanding. This
survey provides a comprehensive overview of recent progress in 3DGS
applications. It first introduces 2D foundation models that support semantic
understanding and control in 3DGS applications, followed by a review of
NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS
applications into segmentation, editing, generation, and other functional
tasks. For each, we summarize representative methods, supervision strategies,
and learning paradigms, highlighting shared design principles and emerging
trends. Commonly used datasets and evaluation protocols are also summarized,
along with comparative analyses of recent methods across public benchmarks. To
support ongoing research and development, a continually updated repository of
papers, code, and resources is maintained at
https://github.com/heshuting555/Awesome-3DGS-Applications.

</details>


### [179] [LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit](https://arxiv.org/abs/2508.09981)
*Chengtao Lv,Bilang Zhang,Yang Yong,Ruihao Gong,Yushi Huang,Shiqiao Gu,Jiajun Wu,Yumeng Shi,Jinyang Guo,Wenya Wang*

Main category: cs.CV

TL;DR: LLMC+是一个全面的VLM压缩基准工具，支持20多种算法，揭示了空间和时间冗余需要不同策略，并展示了联合压缩的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLM压缩方法在模块分解、任务评估和技术联合使用上的局限性。

Method: 提出LLMC+基准工具，支持多种算法，系统研究令牌级和模型级压缩。

Result: 发现空间和时间冗余需不同策略，多任务中令牌压缩性能下降，联合压缩效果最佳。

Conclusion: LLMC+为高效VLM研究提供了公平评估工具，并启发了未来方向。

Abstract: Large Vision-Language Models (VLMs) exhibit impressive multi-modal
capabilities but suffer from prohibitive computational and memory demands, due
to their long visual token sequences and massive parameter sizes. To address
these issues, recent works have proposed training-free compression methods.
However, existing efforts often suffer from three major limitations: (1)
Current approaches do not decompose techniques into comparable modules,
hindering fair evaluation across spatial and temporal redundancy. (2)
Evaluation confined to simple single-turn tasks, failing to reflect performance
in realistic scenarios. (3) Isolated use of individual compression techniques,
without exploring their joint potential. To overcome these gaps, we introduce
LLMC+, a comprehensive VLM compression benchmark with a versatile,
plug-and-play toolkit. LLMC+ supports over 20 algorithms across five
representative VLM families and enables systematic study of token-level and
model-level compression. Our benchmark reveals that: (1) Spatial and temporal
redundancies demand distinct technical strategies. (2) Token reduction methods
degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3)
Combining token and model compression achieves extreme compression with minimal
performance loss. We believe LLMC+ will facilitate fair evaluation and inspire
future research in efficient VLM. Our code is available at
https://github.com/ModelTC/LightCompress.

</details>


### [180] [Story2Board: A Training-Free Approach for Expressive Storyboard Generation](https://arxiv.org/abs/2508.09983)
*David Dinkevich,Matan Levy,Omri Avrahami,Dvir Samuel,Dani Lischinski*

Main category: cs.CV

TL;DR: Story2Board是一个无需训练的框架，用于从自然语言生成富有表现力的故事板，通过轻量级一致性框架提升视觉多样性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于关注主体身份，忽略了视觉叙事中的关键要素（如空间构图、背景演变和叙事节奏），因此需要一种新方法来提升故事板的连贯性和多样性。

Method: 引入轻量级一致性框架，包括潜在面板锚定（保持角色一致性）和互惠注意力值混合（软融合视觉特征），并结合现成语言模型生成面板级提示。

Result: 提出的Rich Storyboard Benchmark和Scene Diversity指标显示，Story2Board在布局多样性、背景叙事和一致性方面优于现有基线。

Conclusion: Story2Board能够生成更具动态性、连贯性和叙事吸引力的故事板，优于现有方法。

Abstract: We present Story2Board, a training-free framework for expressive storyboard
generation from natural language. Existing methods narrowly focus on subject
identity, overlooking key aspects of visual storytelling such as spatial
composition, background evolution, and narrative pacing. To address this, we
introduce a lightweight consistency framework composed of two components:
Latent Panel Anchoring, which preserves a shared character reference across
panels, and Reciprocal Attention Value Mixing, which softly blends visual
features between token pairs with strong reciprocal attention. Together, these
mechanisms enhance coherence without architectural changes or fine-tuning,
enabling state-of-the-art diffusion models to generate visually diverse yet
consistent storyboards. To structure generation, we use an off-the-shelf
language model to convert free-form stories into grounded panel-level prompts.
To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain
narratives designed to assess layout diversity and background-grounded
storytelling, in addition to consistency. We also introduce a new Scene
Diversity metric that quantifies spatial and pose variation across storyboards.
Our qualitative and quantitative results, as well as a user study, show that
Story2Board produces more dynamic, coherent, and narratively engaging
storyboards than existing baselines.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [181] [ELASTIC: Event-Tracking Data Synchronization in Soccer Without Annotated Event Locations](https://arxiv.org/abs/2508.09238)
*Hyunsung Kim,Hoyoung Choi,Sangwoo Seo,Tom Boomstra,Jinsung Yoon,Chanyoung Park*

Main category: cs.DB

TL;DR: ELASTIC是一种仅使用跟踪数据特征的同步框架，用于解决足球中事件和跟踪数据同步的挑战，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手动记录的事件时间戳存在时空不准确性，现有同步器依赖易出错的事件位置标注，导致同步结果失真。

Method: 提出ELASTIC框架，仅利用跟踪数据特征，明确检测传球类事件的结束时间，并区分主次要事件。

Result: 在2,134个事件的真实时间戳标注实验中，ELASTIC大幅优于现有同步器。

Conclusion: ELASTIC通过改进同步完整性和减少错误传递，有效解决了事件与跟踪数据的同步问题。

Abstract: The integration of event and tracking data has become essential for advanced
analysis in soccer. However, synchronizing these two modalities remains a
significant challenge due to temporal and spatial inaccuracies in manually
recorded event timestamps. Existing synchronizers typically rely on annotated
event locations, which themselves are prone to spatial errors and thus can
distort synchronization results. To address this issue, we propose ELASTIC
(Event-Location-AgnoSTIC synchronizer), a synchronization framework that only
uses features derived from tracking data. ELASTIC also explicitly detects the
end times of pass-like events and separates the detection of major and minor
events, which improves the completeness of the synchronized output and reduces
error cascade across events. We annotated the ground truth timestamps of 2,134
events from three Eredivisie matches to measure the synchronization accuracy,
and the experimental results demonstrate that ELASTIC outperforms existing
synchronizers by a large margin.

</details>


### [182] [LLMLog: Advanced Log Template Generation via LLM-driven Multi-Round Annotation](https://arxiv.org/abs/2508.09594)
*Fei Teng,Haoyang Li,Lei Chen*

Main category: cs.DB

TL;DR: LLMLog提出了一种基于多轮标注和自适应上下文学习的框架，用于提高日志模板生成的准确性，解决了现有方法在复杂日志内容上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有日志模板生成方法（启发式或神经网络）因依赖手工规则或特定训练集模式导致准确性低，而大语言模型（LLM）在处理复杂日志时易出错。

Method: 提出基于编辑距离的日志相似性度量，选择最具代表性的未标注日志进行标注，并设计自适应上下文选择策略以优化LLM的模板生成。

Result: 在16个数据集上的实验表明，LLMLog优于现有最佳方法。

Conclusion: LLMLog通过多轮标注和自适应学习显著提升了日志模板生成的准确性，为复杂日志分析提供了有效解决方案。

Abstract: Modern computing systems, such as HDFS and Spark, produce vast quantities of
logs that developers use for tasks like anomaly detection and error analysis.
To simplify log analysis, template generation methods have been proposed to
standardize log formats, transforming unstructured data into structured
templates. Existing heuristic-based methods and neural network-based methods
suffer from low accuracy problems due to the reliance on handcrafted heuristics
or specific log patterns in training sets. Recently, large language models
(LLMs) have shown great potential in log template generation. However, they
often struggle with ambiguous, complex, or highly specific log content, which
can lead to errors in generating accurate templates. To address these
challenges, we propose LLMLog, a multi-round annotation framework with adaptive
in-context learning. We first propose an edit-distance-based similarity metric
to evaluate log similarity. Then, we introduce a method to select the most
informative $k$ unlabeled logs for annotation by considering both the
representativeness of the logs and the confidence of LLM predictions.
Additionally, we design an adaptive context selection strategy that adaptively
selects labeled logs to ensure comprehensive keyword coverage for unlabeled
logs. These labeled logs serve as the context for LLMs to better understand the
unlabeled logs, thereby enhancing the accuracy of template generation.
Extensive experiments on sixteen datasets demonstrate that LLMLog outperforms
the state-of-the-art approaches.

</details>


### [183] [A Lightweight Learned Cardinality Estimation Model](https://arxiv.org/abs/2508.09602)
*Yaoyu Zhu,Jintao Zhang,Guoliang Li,Jianhua Feng*

Main category: cs.DB

TL;DR: 论文提出了一种名为CoDe的新方法，通过覆盖设计和张量分解技术，实现了基数估计的高精度和低延迟。


<details>
  <summary>Details</summary>
Motivation: 基数估计是数据库管理中的关键任务，现有方法在精度和速度上难以兼顾，亟需一种同时满足高精度和高效性的解决方案。

Method: CoDe利用覆盖设计将表划分为多个重叠的小段，并通过张量分解建模数据分布，结合创新算法选择最佳分布组合进行估计。

Result: 实验表明，CoDe在多个数据集上实现了超过半数查询的绝对准确估计，达到了最先进的精度和效率水平。

Conclusion: CoDe方法在基数估计问题上取得了显著进展，同时提升了精度和效率，为数据库管理提供了实用解决方案。

Abstract: Cardinality estimation is a fundamental task in database management systems,
aiming to predict query results accurately without executing the queries.
However, existing techniques either achieve low estimation accuracy or incur
high inference latency. Simultaneously achieving high speed and accuracy
becomes critical for the cardinality estimation problem. In this paper, we
propose a novel data-driven approach called CoDe (Covering with Decompositions)
to address this problem. CoDe employs the concept of covering design, which
divides the table into multiple smaller, overlapping segments. For each
segment, CoDe utilizes tensor decomposition to accurately model its data
distribution. Moreover, CoDe introduces innovative algorithms to select the
best-fitting distributions for each query, combining them to estimate the final
result. By employing multiple models to approximate distributions, CoDe excels
in effectively modeling discrete distributions and ensuring computational
efficiency. Notably, experimental results show that our method represents a
significant advancement in cardinality estimation, achieving state-of-the-art
levels of both estimation accuracy and inference efficiency. Across various
datasets, CoDe achieves absolute accuracy in estimating more than half of the
queries.

</details>


### [184] [AmbiGraph-Eval: Can LLMs Effectively Handle Ambiguous Graph Queries?](https://arxiv.org/abs/2508.09631)
*Yuchen Tian,Kaixin Li,Hao Chen,Ziyang Luo,Hongzhan Lin,Sebastian Schelter,Lun Du,Jing Ma*

Main category: cs.DB

TL;DR: 论文提出了一种评估大语言模型（LLMs）处理图结构数据查询歧义能力的分类法，并引入了一个新基准AmbiGraph-Eval。研究发现现有LLMs在处理歧义查询时表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的图结构数据查询常存在歧义，而LLMs在处理这些歧义时表现不足，亟需系统性评估和改进。

Method: 提出了图查询歧义的分类法（三种主要类型及子场景），并开发了AmbiGraph-Eval基准，用于评估9种代表性LLMs。

Result: 即使顶级LLMs在处理歧义图查询时也表现不佳，揭示了歧义处理能力的不足。

Conclusion: 研究强调了LLMs在歧义处理上的关键缺陷，为未来开发专用解决方案提供了动力。

Abstract: Large Language Models (LLMs) have recently demonstrated strong capabilities
in translating natural language into database queries, especially when dealing
with complex graph-structured data. However, real-world queries often contain
inherent ambiguities, and the interconnected nature of graph structures can
amplify these challenges, leading to unintended or incorrect query results. To
systematically evaluate LLMs on this front, we propose a taxonomy of
graph-query ambiguities, comprising three primary types: Attribute Ambiguity,
Relationship Ambiguity, and Attribute-Relationship Ambiguity, each subdivided
into Same-Entity and Cross-Entity scenarios. We introduce AmbiGraph-Eval, a
novel benchmark of real-world ambiguous queries paired with expert-verified
graph query answers. Evaluating 9 representative LLMs shows that even top
models struggle with ambiguous graph queries. Our findings reveal a critical
gap in ambiguity handling and motivate future work on specialized resolution
techniques.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [185] [Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference](https://arxiv.org/abs/2508.09505)
*Zhanghan Wang,Ding Ding,Hang Zhu,Haibin Lin,Aurojit Panda*

Main category: cs.DC

TL;DR: 提出了一种静态识别分布式机器学习模型中错误的方法，通过检查模型精化（即能否从分布式模型的输出重构顺序模型的输出），并在GraphGuard中实现。


<details>
  <summary>Details</summary>
Motivation: 分布式机器学习训练和推理中，由于模型规模大，需跨GPU分布状态和计算，但此过程可能引入错误，导致分布式模型输出与顺序模型不一致。

Method: 使用迭代重写技术证明模型精化，并在GraphGuard中实现，适用于大规模模型如GPT和Llama-3。

Result: 方法可扩展至当前大规模模型和部署，并提供有助于错误定位的可操作输出。

Conclusion: GraphGuard能有效识别分布式模型中的错误，并支持大规模模型的应用。

Abstract: Distributed machine learning training and inference is common today because
today's large models require more memory and compute than can be provided by a
single GPU. Distributed models are generally produced by programmers who take a
sequential model specification and apply several distribution strategies to
distribute state and computation across GPUs. Unfortunately, bugs can be
introduced in the process, and a distributed model implementation's outputs
might differ from the sequential model's outputs. In this paper, we describe an
approach to statically identify such bugs by checking model refinement, that
is, can the sequential model's outputs be reconstructed from the distributed
model's outputs? Our approach, implemented in GraphGuard, uses iterative
rewriting to prove model refinement. Our approach can scale to today's large
models and deployments: we evaluate it using GPT and Llama-3. Further, it
provides actionable output that aids in bug localization.

</details>


### [186] [HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap](https://arxiv.org/abs/2508.09591)
*Wenxiang Lin,Xinglin Pan,Lin Zhang,Shaohuai Shi,Xuan Wang,Xiaowen Chu*

Main category: cs.DC

TL;DR: HierMoE通过拓扑感知技术（令牌去重和专家交换）加速MoE模型训练，减少通信流量并平衡GPU负载，实验结果显示其性能优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 解决MoE模型中因动态选择专家导致的通信和负载不平衡问题，提升分布式系统的可扩展性。

Method: 提出两种拓扑感知技术：令牌去重减少通信流量，专家交换平衡GPU负载，并建立理论模型优化策略。

Result: 在32-GPU集群上实验，HierMoE通信速度提升1.55×至3.32×，端到端训练速度提升1.18×至1.27×。

Conclusion: HierMoE显著提升了MoE模型的训练效率，优于现有系统。

Abstract: The sparsely activated mixture-of-experts (MoE) transformer has become a
common architecture for large language models (LLMs) due to its sparsity, which
requires fewer computational demands while easily scaling the model size. In
MoE models, each MoE layer requires to dynamically choose tokens to activate
particular experts for computation while the activated experts may not be
located in the same device or GPU as the token. However, this leads to
substantial communication and load imbalances across all GPUs, which obstructs
the scalability of distributed systems within a GPU cluster. To this end, we
introduce HierMoE to accelerate the training of MoE models by two
topology-aware techniques: 1) token deduplication to reduce the communication
traffic, and 2) expert swap to balance the workloads among all GPUs. To enable
the above two proposed approaches to be more general, we build theoretical
models aimed at achieving the best token duplication and expert swap strategy
under different model configurations and hardware environments. We implement
our prototype HierMoE system atop Megatron-LM and conduct experiments on a
32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results
show that our HierMoE achieves $1.55\times$ to $3.32\times$ faster
communication and delivers $1.18\times$ to $1.27\times$ faster end-to-end
training compared to state-of-the-art MoE training systems, Tutel-2DH,
SmartMoE, and Megatron-LM.

</details>


### [187] [Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes](https://arxiv.org/abs/2508.09663)
*Philipp A. Friese,Ahmed Eleliemy,Utz-Uwe Haus,Martin Schulz*

Main category: cs.DC

TL;DR: 论文提出了一种针对HPE Slingshot网络的扩展，使其适用于多租户的HPC-Cloud融合部署，通过Kubernetes实现安全、容器粒度的RDMA网络访问。


<details>
  <summary>Details</summary>
Motivation: HPC-Cloud融合计算需要同时满足云原生工作负载的隔离需求和HPC应用的性能需求，而现有的Slingshot网络堆栈仅支持单租户模式，无法满足多租户部署的安全需求。

Method: 设计并实现了一个基于Kubernetes的Slingshot堆栈扩展，提供安全的、容器粒度的多租户RDMA网络访问。

Result: 实现了低开销的、安全的多租户Slingshot RDMA网络能力。

Conclusion: 该扩展成功解决了Slingshot在多租户HPC-Cloud部署中的安全问题，为融合计算提供了可行的网络解决方案。

Abstract: Converged HPC-Cloud computing is an emerging computing paradigm that aims to
support increasingly complex and multi-tenant scientific workflows. These
systems require reconciliation of the isolation requirements of native cloud
workloads and the performance demands of HPC applications. In this context,
networking hardware is a critical boundary component: it is the conduit for
high-throughput, low-latency communication and enables isolation across
tenants. HPE Slingshot is a high-speed network interconnect that provides up to
200 Gbps of throughput per port and targets high-performance computing (HPC)
systems. The Slingshot host software, including hardware drivers and network
middleware libraries, is designed to meet HPC deployments, which predominantly
use single-tenant access modes. Hence, the Slingshot stack is not suited for
secure use in multi-tenant deployments, such as converged HPC-Cloud
deployments. In this paper, we design and implement an extension to the
Slingshot stack targeting converged deployments on the basis of Kubernetes. Our
integration provides secure, container-granular, and multi-tenant access to
Slingshot RDMA networking capabilities at minimal overhead.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [188] [Agentic TinyML for Intent-aware Handover in 6G Wireless Networks](https://arxiv.org/abs/2508.09147)
*Alaa Saleh,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.NI

TL;DR: 本文提出WAAN框架，通过轻量级TinyML代理实现意图感知和主动切换，以解决6G网络中传统切换机制的局限性。


<details>
  <summary>Details</summary>
Motivation: 6G网络中，传统反应式切换机制在移动边缘计算和自主代理服务场景中表现不足，需要更智能的解决方案。

Method: WAAN框架嵌入轻量级TinyML代理作为自主协商实体，利用半稳定会合点实现上下文转移和状态保持。

Result: 通过多模态环境控制案例研究，验证了WAAN在移动性下维持用户体验的有效性。

Conclusion: WAAN为6G网络提供了创新的切换解决方案，但部署和演进仍面临挑战。

Abstract: As 6G networks evolve into increasingly AI-driven, user-centric ecosystems,
traditional reactive handover mechanisms demonstrate limitations, especially in
mobile edge computing and autonomous agent-based service scenarios. This
manuscript introduces WAAN, a cross-layer framework that enables intent-aware
and proactive handovers by embedding lightweight TinyML agents as autonomous,
negotiation-capable entities across heterogeneous edge nodes that contribute to
intent propagation and network adaptation. To ensure continuity across
mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points
that serve as coordination anchors for context transfer and state preservation.
The framework's operational capabilities are demonstrated through a multimodal
environmental control case study, highlighting its effectiveness in maintaining
user experience under mobility. Finally, the article discusses key challenges
and future opportunities associated with the deployment and evolution of WAAN.

</details>


### [189] [Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks](https://arxiv.org/abs/2508.09149)
*Seyed Hossein Ahmadpanah*

Main category: cs.NI

TL;DR: 提出了一种语义感知的主动LLM编排框架（SP-LLM），通过预测性数字孪生（pDT）和大型语言模型（LLM）优化动态车辆网络中的任务卸载和资源分配，显著提升了性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 当前车辆边缘计算（VEC）管理系统是静态和反应式的，无法适应动态车辆环境，需要一种更智能、主动的解决方案。

Method: 将传统数字孪生（DT）升级为预测性数字孪生（pDT），结合LLM作为认知编排器，利用预测数据和自然语言指令动态调整优化策略。

Result: SP-LLM在可扩展性、鲁棒性和适应性方面显著优于现有反应式和基于MARL的方法。

Conclusion: SP-LLM框架能够将人类意图转化为最优网络行为，为更智能、自主和目标驱动的车辆网络奠定了基础。

Abstract: Next-generation automotive applications require vehicular edge computing
(VEC), but current management systems are essentially fixed and reactive. They
are suboptimal in extremely dynamic vehicular environments because they are
constrained to static optimization objectives and base their decisions on the
current network states. This paper presents a novel Semantic-Aware Proactive
LLM Orchestration (SP-LLM) framework to address these issues. Our method
transforms the traditional Digital Twin (DT) into a Predictive Digital Twin
(pDT) that predicts important network parameters such as task arrivals, vehicle
mobility, and channel quality. A Large Language Model (LLM) that serves as a
cognitive orchestrator is at the heart of our framework. It makes proactive,
forward-looking decisions about task offloading and resource allocation by
utilizing the pDT's forecasts. The LLM's ability to decipher high-level
semantic commands given in natural language is crucial because it enables it to
dynamically modify its optimization policy to match evolving strategic
objectives, like giving emergency services priority or optimizing energy
efficiency. We show through extensive simulations that SP-LLM performs
significantly better in terms of scalability, robustness in volatile
conditions, and adaptability than state-of-the-art reactive and MARL-based
approaches. More intelligent, autonomous, and goal-driven vehicular networks
will be possible due to our framework's outstanding capacity to convert human
intent into optimal network behavior.

</details>


### [190] [Enabling On-demand Guaranteed QoS for Real Time Video Streaming from Vehicles in 5G Advanced with CAPIF & NEF APIs](https://arxiv.org/abs/2508.09150)
*Pietro Piscione,Leonardo Lossi,Maziar Nekovee,Chathura Galkandage,Phil O Connor,Simon Davies*

Main category: cs.NI

TL;DR: 本文展示了如何将5G高级网络功能与CAPIF集成，以支持汽车应用的增强连接，并通过PoC验证了动态QoS调整和流量边缘化的效果。


<details>
  <summary>Details</summary>
Motivation: 为汽车应用提供增强的5G连接能力，通过动态QoS和边缘化优化网络性能。

Method: 利用CAPIF集成的3GPP NEF API，实现网络性能监控和动态QoS调整，并将流量重定向至边缘。

Result: PoC验证了动态QoS调整和流量边缘化对降低延迟和优化网络资源利用的有效性。

Conclusion: 通过CAPIF集成5G高级功能，可显著提升汽车应用的网络性能和用户体验。

Abstract: This paper presents the design and implementation of a Proof of Concept (PoC)
that demonstrates how 5G Advanced Network Functions can be integrated with the
Common API Framework (CAPIF) to support enhanced connectivity for automotive
applications. The PoC shows the continuous monitoring of the mobile network
performance and the on-demand and dynamic adaptation of Quality of Service
(QoS) for selected 5G User Equipment (UE) video streaming traffic flows using
standard 3GPP Network Exposure Function (NEF) APIs exposed via CAPIF. Moreover,
traffic flows are redirected to the edge to improve latency and optimize
network resource utilization.

</details>


### [191] [Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission](https://arxiv.org/abs/2508.09151)
*Chang Wu,Yuang Chen,Yiyuan Chen,Fengqian Guo,Xiaowei Qin,Hancheng Lu*

Main category: cs.NI

TL;DR: 本文提出了一种基于生理信号的QoE建模与优化框架，利用EEG、ECG和皮肤活动信号动态调整VR流媒体分辨率，显著提升了用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有QoE模型未能充分解决VR流媒体中分辨率突变对用户体验的影响，需更精准的生理信号驱动方法。

Method: 结合生理信号（EEG、ECG、皮肤活动）和深度强化学习（DRL），动态分配无线资源并调整分辨率。

Result: 实验显示，该方法在分辨率和切换频率上分别提升了88.7%和减少了81.0%。

Conclusion: 生理信号驱动的策略有效提升了VR流媒体的QoE，展示了边缘AI在沉浸式媒体服务中的潜力。

Abstract: Abrupt resolution changes in virtual reality (VR) streaming can significantly
impair the quality-of-experience (QoE) of users, particularly during
transitions from high to low resolutions. Existing QoE models and transmission
schemes inadequately address the perceptual impact of these shifts. To bridge
this gap, this article proposes, for the first time, an innovative
physiological signal-driven QoE modeling and optimization framework that fully
leverages users' electroencephalogram (EEG), electrocardiogram (ECG), and skin
activity signals. This framework precisely captures the temporal dynamics of
physiological responses and resolution changes in VR streaming, enabling
accurate quantification of resolution upgrades' benefits and downgrades'
impacts. Integrated the proposed QoE framework into the radio access network
(RAN) via a deep reinforcement learning (DRL) framework, adaptive transmission
strategies have been implemented to allocate radio resources dynamically, which
mitigates short-term channel fluctuations and adjusts frame resolution in
response to channel variations caused by user mobility. By prioritizing
long-term resolution while minimizing abrupt transitions, the proposed solution
achieves an 88.7\% improvement in resolution and an 81.0\% reduction in
handover over the baseline. Experimental results demonstrate the effectiveness
of this physiological signal-driven strategy, underscoring the promise of edge
AI in immersive media services.

</details>


### [192] [Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference](https://arxiv.org/abs/2508.09229)
*Danil Sivtsov,Aleksandr Katrutsa,Ivan Oseledets*

Main category: cs.NI

TL;DR: 提出了一种基于整数线性规划（ILP）的模型放置算法，用于高效部署预训练的MoE LLM，优化网络流量。


<details>
  <summary>Details</summary>
Motivation: MoE LLM在推理阶段仅激活部分专家，且负载不均衡，需考虑网络拓扑以实现高效部署。

Method: 使用整数线性规划（ILP）确定专家最优放置，最小化传输次数。

Result: ILP策略在小规模（DeepSeekMoE~16B）和大规模（DeepSeek-R1~671B）模型中均优于竞争对手，减少网络流量。

Conclusion: ILP方法能有效优化MoE LLM的部署，提升集群利用率。

Abstract: Efficient deployment of a pre-trained LLM to a cluster with multiple servers
is a critical step for providing fast responses to users' queries. The recent
success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy
them efficiently, considering their underlying structure. During the inference
in MoE LLMs, only a small part of the experts is selected to process a given
token. Moreover, in practice, the experts' load is highly imbalanced. For
efficient deployment, one has to distribute the model across a large number of
servers using a model placement algorithm. Thus, to improve cluster
utilization, the model placement algorithm has to take into account the network
topology. This work focuses on the efficient topology-aware placement of the
pre-trained MoE LLMs in the inference stage. We propose an integer linear
program (ILP) that determines the optimal placement of experts, minimizing the
expected number of transmissions. Due to the internal structure, this
optimization problem can be solved with a standard ILP solver. We demonstrate
that ILP-based placement strategy yields lower network traffic than competitors
for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.

</details>


### [193] [5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI](https://arxiv.org/abs/2508.09152)
*Joseph H. R. Isaac,Harish Saradagam,Nallamothu Pardhasaradhi*

Main category: cs.NI

TL;DR: 本文提出了一种基于AI/ML的故障分析引擎，用于自动分类5G核心网中的PCAP文件错误，显著减少人工分析时间并提高效率。


<details>
  <summary>Details</summary>
Motivation: 5G网络中确保流量完整性和性能至关重要，但现有方法依赖大量人工分析，效率低下。

Method: 使用自然语言处理技术和生成式AI（基于LLM）分析PCAP文件，识别异常并提供修复建议。

Result: 测试显示模型在成功和失败PCAP文件分类上具有高准确率。

Conclusion: 该引擎显著提升了故障分析效率，未来可扩展至4G网络和其他数据类型。

Abstract: With the advent of 5G networks and technologies, ensuring the integrity and
performance of packet core traffic is paramount. During network analysis, test
files such as Packet Capture (PCAP) files and log files will contain errors if
present in the system that must be resolved for better overall network
performance, such as connectivity strength and handover quality. Current
methods require numerous person-hours to sort out testing results and find the
faults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine
designed to classify successful and faulty frames in PCAP files, specifically
within the 5G packet core. The FA engine analyses network traffic using natural
language processing techniques to identify anomalies and inefficiencies,
significantly reducing the effort time required and increasing efficiency. The
FA Engine also suggests steps to fix the issue using Generative AI via a Large
Language Model (LLM) trained on several 5G packet core documents. The engine
explains the details of the error from the domain perspective using documents
such as the 3GPP standards and user documents regarding the internal conditions
of the tests. Test results on the ML models show high classification accuracy
on the test dataset when trained with 80-20 splits for the successful and
failed PCAP files. Future scopes include extending the AI engine to incorporate
4G network traffic and other forms of network data, such as log text files and
multimodal systems.

</details>


### [194] [Agoran: An Agentic Open Marketplace for 6G RAN Automation](https://arxiv.org/abs/2508.09159)
*Ilias Chatzistefanidis,Navid Nikaein,Andrea Leone,Ali Maatouk,Leandros Tassioulas,Roberto Morabito,Ioannis Pitsiorlas,Marios Kountouris*

Main category: cs.NI

TL;DR: Agoran SRB是一个基于代理的市场，通过三个自治AI分支（立法、执行、司法）实现多利益相关者的动态协商，显著提升5G网络性能。


<details>
  <summary>Details</summary>
Motivation: 解决下一代移动网络中多服务所有者目标冲突的问题，克服现有网络切片控制器的僵化性和缺乏业务背景的局限性。

Method: 引入Agoran SRB，通过三个AI分支（立法、执行、司法）和协商代理实现动态协商与优化，部署于5G测试床。

Result: 在5G测试中，eMBB切片吞吐量提升37%，URLLC切片延迟降低73%，PRB使用节省8.3%。

Conclusion: Agoran为6G网络提供了一种灵活、以利益相关者为中心的标准路径。

Abstract: Next-generation mobile networks must reconcile the often-conflicting goals of
multiple service owners. However, today's network slice controllers remain
rigid, policy-bound, and unaware of the business context. We introduce Agoran
Service and Resource Broker (SRB), an agentic marketplace that brings
stakeholders directly into the operational loop. Inspired by the ancient Greek
agora, Agoran distributes authority across three autonomous AI branches: a
Legislative branch that answers compliance queries using retrieval-augmented
Large Language Models (LLMs); an Executive branch that maintains real-time
situational awareness through a watcher-updated vector database; and a Judicial
branch that evaluates each agent message with a rule-based Trust Score, while
arbitrating LLMs detect malicious behavior and apply real-time incentives to
restore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator
Agent negotiate feasible, Pareto-optimal offers produced by a multi-objective
optimizer, reaching a consensus intent in a single round, which is then
deployed to Open and AI RAN controllers. Deployed on a private 5G testbed and
evaluated with realistic traces of vehicle mobility, Agoran achieved
significant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73%
reduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3%
saving in PRB usage compared to a static baseline. An 1B-parameter Llama model,
fine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80%
of GPT-4.1's decision quality, while operating within 6 GiB of memory and
converging in only 1.3 seconds. These results establish Agoran as a concrete,
standards-aligned path toward ultra-flexible, stakeholder-centric 6G networks.
A live demo is presented
https://www.youtube.com/watch?v=h7vEyMu2f5w\&ab_channel=BubbleRAN.

</details>


### [195] [WPTrack: A Wi-Fi and Pressure Insole Fusion System for Single Target Tracking](https://arxiv.org/abs/2508.09166)
*Wei Guo,Shunsei Yamagishi,Lei Jing*

Main category: cs.NI

TL;DR: WPTrack提出了一种结合Wi-Fi和压力鞋垫数据的单目标跟踪系统，解决了现有Wi-Fi跟踪方法的初始位置获取和盲点问题。


<details>
  <summary>Details</summary>
Motivation: 随着物联网的发展，室内定位对智能家居和行为监测至关重要，但现有Wi-Fi跟踪方法依赖多设备或存在初始位置和盲点问题。

Method: WPTrack通过单Wi-Fi链路的CSI数据和90个鞋垫传感器的压力数据，结合相位差、多普勒速度和行走速度，提出CSI-压力融合模型。

Result: 实验显示初始定位精度在0.02 cm至42.55 cm之间，真实环境中的轨迹跟踪结果与实际轨迹高度吻合。

Conclusion: WPTrack通过融合Wi-Fi和压力数据，显著提升了单目标跟踪的精度和实用性。

Abstract: As the Internet of Things (IoT) continues to evolve, indoor location has
become a critical element for enabling smart homes, behavioral monitoring, and
elderly care. Existing WiFi-based human tracking solutions typically require
specialized equipment or multiple Wi-Fi links, a limitation in most indoor
settings where only a single pair of Wi-Fi devices is usually available.
However, despite efforts to implement human tracking using one Wi-Fi link,
significant challenges remain, such as difficulties in acquiring initial
positions and blind spots in DFS estimation of tangent direction. To address
these challenges, this paper proposes WPTrack, the first Wi-Fi and Pressure
Insoles Fusion System for Single Target Tracking. WPTrack collects Channel
State Information (CSI) from a single Wi-Fi link and pressure data from 90
insole sensors. The phase difference and Doppler velocity are computed from the
CSI, while the pressure sensor data is used to calculate walking velocity.
Then, we propose the CSI-pressure fusion model, integrating CSI and pressure
data to accurately determine initial positions and facilitate precise human
tracking. The simulation results show that the initial position localization
accuracy ranges from 0.02 cm to 42.55 cm. The trajectory tracking results
obtained from experimental data collected in a real-world environment closely
align with the actual trajectory.

</details>


### [196] [webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design](https://arxiv.org/abs/2508.09171)
*D. Perera*

Main category: cs.NI

TL;DR: webMCP是一种客户端标准，通过在网页中嵌入结构化交互元数据，显著降低AI代理处理网页的计算开销，同时保持任务准确性。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理需要大量处理才能理解网页，导致AI辅助的网页交互缓慢且昂贵。webMCP旨在解决这一问题。

Method: webMCP直接在网页中嵌入结构化交互元数据，为AI代理提供明确的页面元素与用户动作映射，减少对完整HTML文档的处理需求。

Result: 评估显示，webMCP将处理需求降低67.6%，任务成功率保持在97.9%（传统方法为98.8%），用户成本降低34-63%，响应时间显著缩短。

Conclusion: webMCP无需服务器端修改，可广泛应用于现有网站，为AI网页辅助提供更高效、可持续的解决方案。

Abstract: Current AI agents create significant barriers for users by requiring
extensive processing to understand web pages, making AI-assisted web
interaction slow and expensive. This paper introduces webMCP (Web Machine
Context & Procedure), a client-side standard that embeds structured interaction
metadata directly into web pages, enabling more efficient human-AI
collaboration on existing websites. webMCP transforms how AI agents understand
web interfaces by providing explicit mappings between page elements and user
actions. Instead of processing entire HTML documents, agents can access
pre-structured interaction data, dramatically reducing computational overhead
while maintaining task accuracy. A comprehensive evaluation across 1,890 real
API calls spanning online shopping, authentication, and content management
scenarios demonstrates webMCP reduces processing requirements by 67.6% while
maintaining 97.9% task success rates compared to 98.8% for traditional
approaches. Users experience significantly lower costs (34-63% reduction) and
faster response times across diverse web interactions. Statistical analysis
confirms these improvements are highly significant across multiple AI models.
An independent WordPress deployment study validates practical applicability,
showing consistent improvements across real-world content management workflows.
webMCP requires no server-side modifications, making it deployable across
millions of existing websites without technical barriers. These results
establish webMCP as a viable solution for making AI web assistance more
accessible and sustainable, addressing the critical gap between user
interaction needs and AI computational requirements in production environments.

</details>


### [197] [Camel: Energy-Aware LLM Inference on Resource-Constrained Devices](https://arxiv.org/abs/2508.09173)
*Hao Xu,Long Peng,Shezheng Song,Xiaodong Liu,Ma Jun,Shasha Li,Jie Yu,Xiaoguang Mao*

Main category: cs.NI

TL;DR: 论文提出了一种LLM推理能量管理框架，通过优化GPU频率和批量大小，平衡延迟和能耗，在边缘设备上实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 当前LLM主要部署在云端，面临网络延迟、隐私和带宽问题，边缘设备部署成为研究重点，但需平衡能耗和延迟。

Method: 提出一个框架，通过优化GPU频率和批量大小，并管理配置搜索中的探索-利用困境，找到最优设置。

Result: 在NVIDIA Jetson AGX Orin平台上实验验证，框架将能量延迟积（EDP）降低12.4%-29.9%。

Conclusion: 该框架有效平衡了能耗和延迟，为边缘设备上的LLM推理提供了优化方案。

Abstract: Most Large Language Models (LLMs) are currently deployed in the cloud, with
users relying on internet connectivity for access. However, this paradigm faces
challenges such as network latency, privacy concerns, and bandwidth limits.
Thus, deploying LLMs on edge devices has become an important research focus. In
edge inference, request latency is critical as high latency can impair
real-time tasks. At the same time, edge devices usually have limited battery
capacity, making energy consumption another major concern. Balancing energy
consumption and inference latency is essential. To address this, we propose an
LLM inference energy management framework that optimizes GPU frequency and
batch size to balance latency and energy consumption. By effectively managing
the exploration-exploitation dilemma in configuration search, the framework
finds the optimal settings. The framework was implemented on the NVIDIA Jetson
AGX Orin platform, and a series of experimental validations were conducted.
Results demonstrate that, compared to the default configuration, our framework
reduces energy delay product (EDP) by 12.4%-29.9%, achieving a better balance
between energy consumption and latency.

</details>


### [198] [HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting](https://arxiv.org/abs/2508.09184)
*Zineddine Bettouche,Khalid Ali,Andreas Fischer,Andreas Kassler*

Main category: cs.NI

TL;DR: HiSTM模型通过结合双空间编码器和Mamba时序模块，显著提升了蜂窝流量预测的准确性，同时减少了参数数量。


<details>
  <summary>Details</summary>
Motivation: 蜂窝流量预测对网络规划和资源分配至关重要，但现有模型在准确性和计算效率之间存在权衡。

Method: HiSTM采用选择性状态空间方法和注意力机制，捕捉时空模式。

Result: 在真实数据集上，HiSTM比STN基线MAE提升29.4%，参数减少94%。

Conclusion: HiSTM在不同数据集上泛化能力强，且在长期预测中表现更优。

Abstract: Cellular traffic forecasting is essential for network planning, resource
allocation, or load-balancing traffic across cells. However, accurate
forecasting is difficult due to intricate spatial and temporal patterns that
exist due to the mobility of users. Existing AI-based traffic forecasting
models often trade-off accuracy and computational efficiency. We present
Hierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial
encoder with a Mamba-based temporal module and attention mechanism. HiSTM
employs selective state space methods to capture spatial and temporal patterns
in network traffic. In our evaluation, we use a real-world dataset to compare
HiSTM against several baselines, showing a 29.4% MAE improvement over the STN
baseline while using 94% fewer parameters. We show that the HiSTM generalizes
well across different datasets and improves in accuracy over longer
time-horizons.

</details>


### [199] [MX-AI: Agentic Observability and Control Platform for Open and AI-RAN](https://arxiv.org/abs/2508.09197)
*Ilias Chatzistefanidis,Andrea Leone,Ali Yaghoubian,Mikel Irazabal,Sehad Nassim,Lina Bariah,Merouane Debbah,Navid Nikaein*

Main category: cs.NI

TL;DR: MX-AI是首个端到端的AI原生系统，用于6G无线接入网络（RAN），通过LLM驱动的代理实现自然语言控制和观察，性能接近人类专家水平。


<details>
  <summary>Details</summary>
Motivation: 未来6G RAN需要AI原生支持，以实现自主观察、推理和重新配置。

Method: MX-AI基于OpenAirInterface和FlexRIC构建5G Open RAN测试平台，并在SMO层部署LLM驱动的代理图，提供自然语言接口。

Result: 在50个实际查询中，MX-AI平均回答质量4.1/5.0，决策准确率100%，延迟仅8.8秒。

Conclusion: MX-AI验证了AI原生RAN的实用性，并公开了代理图和评估工具以促进开放研究。

Abstract: Future 6G radio access networks (RANs) will be artificial intelligence
(AI)-native: observed, reasoned about, and re-configured by autonomous agents
cooperating across the cloud-edge continuum. We introduce MX-AI, the first
end-to-end agentic system that (i) instruments a live 5G Open RAN testbed based
on OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of
Large-Language-Model (LLM)-powered agents inside the Service Management and
Orchestration (SMO) layer, and (iii) exposes both observability and control
functions for 6G RAN resources through natural-language intents. On 50
realistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0
and 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end
latency when backed by GPT-4.1. Thus, it matches human-expert performance,
validating its practicality in real settings. We publicly release the agent
graph, prompts, and evaluation harness to accelerate open research on AI-native
RANs. A live demo is presented here:
https://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN

</details>


### [200] [CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge](https://arxiv.org/abs/2508.09208)
*Muqing Li,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.NI

TL;DR: 提出了一种动态资源感知的协作优化框架CoMoE，用于在移动边缘环境中优化专家聚合粒度和卸载策略，显著降低内存使用和推理延迟。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的移动边缘计算环境中部署MoE模型时面临的内存占用大和动态专家激活模式带来的挑战。

Method: 通过分析现有专家聚合技术和卸载策略，提出自适应调度机制，结合实时设备资源状态、网络条件和输入特性进行优化。

Result: 实验表明，CoMoE相比基线方法减少70%内存使用，推理延迟降低10.5%，并在大规模MoE模型上显著降低内存需求。

Conclusion: CoMoE有效解决了移动边缘环境中MoE模型的部署难题，为资源受限设备提供了可行的解决方案。

Abstract: The proliferation of large language models (LLMs) has driven the adoption of
Mixture-of-Experts (MoE) architectures as a promising solution to scale model
capacity while controlling computational costs. However, deploying MoE models
in resource-constrained mobile edge computing environments presents significant
challenges due to their large memory footprint and dynamic expert activation
patterns. To address these challenges, we propose a novel dynamic
resource-aware collaborative optimization framework that jointly optimizes
expert aggregation granularity and offloading strategies based on real-time
device resource states, network conditions, and input characteristics in mobile
edge environments, denoted as CoMoE. In CoMoE, we first systematically analyze
existing expert aggregation techniques, including expert parameter
merging,knowledge distillation,and parameter sharing decomposition, identifying
their limitations in dynamic mobile environments.We then investigate expert
offloading strategies encompassing expert prediction and prefetching, expert
caching and scheduling, and multi-tier storage architectures, revealing the
interdependencies between routing decisions and offloading performance.The
CoMoE incorporates adaptive scheduling mechanisms that respond to user mobility
and varying network conditions, enabling efficient MoE deployment across
heterogeneous edge devices. Extensive experiments on real mobile edge testbeds
demonstrate that CoMoE achieves approximately 70% reduction in memory usage
compared to baseline methods, 10.5% lower inference latency than existing
expert offloading techniques, while maintaining model performance stability.
For large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE
reduces memory requirements from 15.6GB to 4.7GB, enabling deployment on
resource-constrained mobile edge devices that previously could only support
much smaller models.

</details>


### [201] [NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation](https://arxiv.org/abs/2508.09240)
*Zainab Khan,Ahmed Hussain,Mukesh Thakur,Arto Hellas,Panos Papadimitratos*

Main category: cs.NI

TL;DR: NEFMind框架利用高效参数微调的开源大语言模型（LLM）解决5G服务架构中API管理的复杂性，显著降低通信开销并实现高精度API调用识别。


<details>
  <summary>Details</summary>
Motivation: 现代电信中基于服务的架构导致网络功能和API数量激增，服务发现和管理变得复杂。

Method: 结合合成数据集生成、量化低秩适应模型优化及GPT-4 Ref Score和BertScore性能评估。

Result: 实验验证显示，通信开销减少85%，API调用识别准确率达98-100%。

Conclusion: 验证了高效参数微调的LLM策略在下一代电信网络复杂API管理中的有效性。

Abstract: The use of Service-Based Architecture in modern telecommunications has
exponentially increased Network Functions (NFs) and Application Programming
Interfaces (APIs), creating substantial operational complexities in service
discovery and management. We introduce \textit{NEFMind}, a framework leveraging
parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to
address these challenges. It integrates three core components: synthetic
dataset generation from Network Exposure Function (NEF) API specifications,
model optimization through Quantized-Low-Rank Adaptation, and performance
evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G
Service-Based Architecture APIs, our approach achieves 85% reduction in
communication overhead compared to manual discovery methods. Experimental
validation using the open-source Phi-2 model demonstrates exceptional API call
identification performance at 98-100% accuracy. The fine-tuned Phi-2 model
delivers performance comparable to significantly larger models like GPT-4 while
maintaining computational efficiency for telecommunications infrastructure
deployment. These findings validate domain-specific, parameter-efficient LLM
strategies for managing complex API ecosystems in next-generation
telecommunications networks.

</details>


### [202] [On-Device Multimodal Federated Learning for Efficient Jamming Detection](https://arxiv.org/abs/2508.09369)
*Ioannis Panitsas,Iason Ofeidis,Leandros Tassiulas*

Main category: cs.NI

TL;DR: 提出了一种基于联邦学习的多模态框架，用于设备端的干扰检测与分类，显著提升了检测精度并减少了通信开销。


<details>
  <summary>Details</summary>
Motivation: 无线网络易受干扰攻击，现有检测方法多为单模态、集中式且计算资源需求高，难以扩展和高效部署。

Method: 采用轻量级双编码器架构，结合频谱图和跨层网络KPI，通过融合模块和多模态投影头实现隐私保护的训练与推理。

Result: 在无线实验平台上验证，检测精度比现有单模态方法提升15%，通信轮次减少60%，资源占用低。

Conclusion: 该框架在设备间数据分布不均时表现出强鲁棒性和可靠性，适用于实际部署。

Abstract: Wireless networks face severe vulnerabilities from jamming attacks, which can
significantly disrupt communication. Existing detection approaches are often
unimodal, rely on centralized processing, and demand substantial computational
resources, hindering scalability, efficiency, and deployment feasibility. To
address these challenges, we introduce a multimodal Federated Learning (FL)
framework for on-device jamming detection and classification that integrates
spectrograms with cross-layer network Key Performance Indicators (KPIs) through
a lightweight dual-encoder architecture equipped with a fusion module and a
multimodal projection head. This design enables privacy-preserving training and
inference by ensuring that only model parameters are exchanged, while raw data
remains on the device. The framework is implemented and evaluated on a wireless
experimental testbed using, to the best of our knowledge, the first
over-the-air multimodal dataset with synchronized benign and three distinct
jamming scenarios. Results show that our approach surpasses state-of-the-art
unimodal baselines by up to 15% in detection accuracy, achieves convergence
with 60% fewer communication rounds, and maintains low resource usage. Its
benefits are most evident under heterogeneous data distributions across
devices, where it exhibits strong robustness and reliability.

</details>


### [203] [Metrics for Assessing Changes in Flow-based Networks](https://arxiv.org/abs/2508.09573)
*Michał Rzepka,Piotr Chołda*

Main category: cs.NI

TL;DR: 论文提出了一套量化网络负载和流量影响的指标，通过百分位数和样本分布分析网络状态，并引入利用率评分和改进的Shapley值方法，评估了11种指标的实际价值，为未来研究提供了框架。


<details>
  <summary>Details</summary>
Motivation: 解决网络性能评估中流量波动带来的挑战，特别是峰值数据速率对网络资源的影响。

Method: 通过百分位数和样本分布分析链路和流量数据，引入利用率评分和改进的Shapley值方法，评估11种指标。

Result: 指标能有效捕捉网络状态变化，其中三种指标易于维护且提供广泛见解。

Conclusion: 研究为未来网络性能评估提供了框架，并展示了指标的实际应用潜力。

Abstract: This paper addresses the challenges of evaluating network performance in the
presence of fluctuating traffic patterns, with a particular focus on the impact
of peak data rates on network resources. We introduce a set of metrics to
quantify network load and measure the impact of individual flows on the overall
network state. By analyzing link and flow data through percentile values and
sample distributions, and introducing the Utilization Score metric, the
research provides insights into resource utilization under varying network
conditions. Furthermore, we employ a modified Shapley value-based approach to
measure the influence of individual flows on the network, offering a better
understanding of their contribution to network performance. The paper reviews
and compares 11 metrics across various network scenarios, evaluating their
practical relevance for research and development. Our evaluation demonstrates
that these metrics effectively capture changes in network state induced by
specific flows, with three of them offering a broad range of valuable insights
while remaining relatively easy to maintain. Moreover, the methodology
described in this paper serves as a framework for future research, with the
potential to expand and refine the set of metrics used to evaluate flow impact
on network performance.

</details>


### [204] [Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment](https://arxiv.org/abs/2508.09582)
*Wafaa B. M. Fadlelmula,Sanaa Hamid Mohamed,Taisir E. H. El-Gorashi,Jaafar M. H. Elmirghani*

Main category: cs.NI

TL;DR: 提出了一种基于PON的VLC系统节能架构，通过MILP优化资源分配，显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 解决室内雾计算资源连接的高能耗问题，提升能效。

Method: 开发MILP模型优化资源分配，比较PON与S&L架构及集中式云处理的能耗。

Result: PON架构比S&L节能82%，比集中式云处理节能93%。

Conclusion: PON架构高效节能，动态带宽分配和多节点任务拆分进一步提升能效。

Abstract: In this paper, we consider the use of visible light communication (VLC) to
provide connectivity to indoor fog computing resources and propose an
energy-efficient passive optical network (PON)-based backhaul architecture to
support the VLC system. We develop a mixed-integer linear programming (MILP)
model to optimize the allocation of computing resources over the proposed
architecture, aiming to minimize processing and networking power consumption.
We evaluate the performance of the proposed architecture under varying workload
demands and user distributions. Comparative analysis against a backhaul
architecture that is based on the state-of-the-art spine-and-leaf (S&L) network
design demonstrates total power savings of up to 82%. Further comparison with
centralized cloud processing shows improvements in energy efficiency of up to
93%. Additionally, we examine the improvements in energy efficiency obtained by
splitting tasks among multiple processing nodes and propose enhancements to the
architecture including dynamic bandwidth allocation, increased wavelength
bandwidth and improved connectivity within rooms to alleviate networking
bottlenecks. Furthermore, we introduce an inter-building architecture that
leverages resources from neighboring buildings to support high-demand
scenarios.

</details>


### [205] [Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling](https://arxiv.org/abs/2508.09620)
*Michel Rottleuthner,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: 论文探讨了在低功耗无线节点中通过动态电压和频率调整（DVFS）技术显著降低能耗的方法，展示了在物联网（IoT）设备中应用DVFS的潜力。


<details>
  <summary>Details</summary>
Motivation: 物联网设备的硬件性能与全功能机器存在显著差异，研究如何利用这种差异通过DVFS技术优化能耗。

Method: 将DVFS集成到RIOT IoT操作系统中，分析其在CSMA/CA和时间分片等MAC操作模式下的能耗表现。

Result: 实验显示，DVFS可节省24%至52%的MAC操作能耗，加密通信能耗降低达37%。

Conclusion: DVFS技术可显著延长物联网设备的电池寿命，建议未来研究将其集成到系统设计中。

Abstract: Minimizing energy consumption of low-power wireless nodes is a persistent
challenge from the constrained Internet of Things (IoT). In this paper, we
start from the observation that constrained IoT devices have largely different
hardware (im-)balances than full-scale machines. We find that the performance
gap between MCU and network throughput on constrained devices enables minimal
energy delay product (EDP) for IoT networking at largely reduced clock
frequencies. We analyze the potentials by integrating dynamic voltage and
frequency scaling (DVFS) into the RIOT IoT operating system and show that the
DVFS reconfiguration overhead stays below the energy saved for a single,
downscaled MAC operation. Backed by these findings, we systematically
investigate how DVFS further improves energy-efficiency for common networking
tasks -- in addition to duty-cycling. We measure IoT communication scenarios
between real-world systems and analyze two MAC operating modes -- CSMA/CA and
time slotting -- in combination with different CoAP transactions, payload
sizes, as well as DTLS transport encryption. Our experiments reveal energy
savings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP
communication. These results shall encourage research and system design work to
integrate DVFS in future IoT devices for performing tasks at their optimal
frequencies and thereby significantly extending battery lifetimes.

</details>


### [206] [Anomaly Detection for IoT Global Connectivity](https://arxiv.org/abs/2508.09660)
*Jesus Omaña Iglesias,Carlos Segura Perales,Stefan Geißler,Diego Perino,Andra Lutu*

Main category: cs.NI

TL;DR: ANCHOR是一种无监督异常检测解决方案，用于全球漫游平台的物联网连接服务，旨在通过过滤数据识别潜在问题客户，实现主动问题解决。


<details>
  <summary>Details</summary>
Motivation: 物联网服务依赖复杂的多实体通信路径，现有平台通常采用被动响应方式，导致服务质量下降。

Method: 结合统计规则、机器学习和深度学习模型，基于被动信令流量设计异常检测方案。

Result: ANCHOR成功部署并评估，能够提前识别问题客户，避免服务严重中断。

Conclusion: ANCHOR为物联网连接服务提供了一种有效的主动异常检测方法，提升了服务可靠性。

Abstract: Internet of Things (IoT) application providers rely on Mobile Network
Operators (MNOs) and roaming infrastructures to deliver their services
globally. In this complex ecosystem, where the end-to-end communication path
traverses multiple entities, it has become increasingly challenging to
guarantee communication availability and reliability. Further, most platform
operators use a reactive approach to communication issues, responding to user
complaints only after incidents have become severe, compromising service
quality. This paper presents our experience in the design and deployment of
ANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity
service of a large global roaming platform. ANCHOR assists engineers by
filtering vast amounts of data to identify potential problematic clients (i.e.,
those with connectivity issues affecting several of their IoT devices),
enabling proactive issue resolution before the service is critically impacted.
We first describe the IoT service, infrastructure, and network visibility of
the IoT connectivity provider we operate. Second, we describe the main
challenges and operational requirements for designing an unsupervised anomaly
detection solution on this platform. Following these guidelines, we propose
different statistical rules, and machine- and deep-learning models for IoT
verticals anomaly detection based on passive signaling traffic. We describe the
steps we followed working with the operational teams on the design and
evaluation of our solution on the operational platform, and report an
evaluation on operational IoT customers.

</details>


### [207] [Route Planning and Online Routing for Quantum Key Distribution Networks](https://arxiv.org/abs/2508.09735)
*Jorge López,Charalampos Chatzinakis,Marc Cartigny*

Main category: cs.NI

TL;DR: 论文提出了一种基于二次规划（QP）的模型，用于解决量子密钥分发（QKD）网络中的路由规划和在线路由问题，并证明了最短路径策略在在线路由中的不足。


<details>
  <summary>Details</summary>
Motivation: QKD网络由于其容量限制和信息处理的特殊性，传统最短路径算法在路由规划和在线路由中表现不佳，且资源稀缺导致需求难以满足。

Method: 将路由问题建模为二次规划（QP）问题，并分析了最短路径和最短最宽路径策略的性能。

Result: 证明了最短最宽路径路由策略在在线路由中的竞争比至少为1/2，有效解决了QKD网络的路由问题。

Conclusion: 提出的QP模型和最短最宽路径策略为QKD网络的路由问题提供了高效解决方案。

Abstract: Quantum Key Distribution (QKD) networks harness the principles of quantum
physics in order to securely transmit cryptographic key material, providing
physical guarantees. These networks require traditional management and
operational components, such as routing information through the network
elements. However, due to the limitations on capacity and the particularities
of information handling in these networks, traditional shortest paths
algorithms for routing perform poorly on both route planning and online
routing, which is counterintuitive. Moreover, due to the scarce resources in
such networks, often the expressed demand cannot be met by any assignment of
routes. To address both the route planning problem and the need for fair
automated suggestions in infeasible cases, we propose to model this problem as
a Quadratic Programming (QP) problem. For the online routing problem, we
showcase that the shortest (available) paths routing strategy performs poorly
in the online setting. Furthermore, we prove that the widest shortest path
routing strategy has a competitive ratio greater or equal than $\frac{1}{2}$,
efficiently addressing both routing modes in QKD networks.

</details>


### [208] [The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges](https://arxiv.org/abs/2508.09756)
*Mauro De Sanctis*

Main category: cs.NI

TL;DR: 提出了一种基于多种无线通信信号的“大规模无线人体感知”范式，旨在通过时间和空间域的多样性提升感知能力。


<details>
  <summary>Details</summary>
Motivation: 利用无线信号的多样性，提升人体感知的准确性和服务可用性。

Method: 结合无设备和有设备无线感知方法，利用时间、频率和空间域的多样性。

Result: 提出了大规模无线人体感知边缘设备的概念，并讨论了架构解决方案和挑战。

Conclusion: 为未来大规模无线人体感知的发展提供了框架和方向。

Abstract: This article is a position paper which introduces the paradigm of ``Massive
Wireless Human Sensing'', i.e. an infrastructure for wireless human sensing
based on a plethora of heterogeneous wireless communication signals. More
specifically, we aim to exploit signal diversity in the time, frequency, and
space domains using opportunistically both device-free and device-based
wireless sensing approaches, with the objective of enhancing human sensing
capabilities in terms of accuracy and service availability over different
environments. The enabling element of this concept is the massive wireless
human sensing edge device, that is, an embedded system acting as a
multi-technology and multi-approach RF receiver with feature extraction
functionality, located within the monitoring area or at its borders. In this
framework, architecture solutions and challenges are discussed to lead the
future development of this new paradigm.

</details>


### [209] [An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks](https://arxiv.org/abs/2508.09769)
*Simon Egger,Robin Laidig,Heiko Geppert,Lucas Haug,Jona Herrmann,Frank Dürr,Christian Becker*

Main category: cs.NI

TL;DR: 论文提出了一种(m,k)-firm Elevation Policy，用于在不稳定的网络条件下维持弱硬实时保证，填补了5G-TSN网络配置中概率延迟与理想延迟模型之间的差距。


<details>
  <summary>Details</summary>
Motivation: 5G与TSN的集成在安全关键工业应用中存在延迟特性与理想模型不匹配的问题，可能导致实时保证失效。

Method: 通过动态优先级驱动方案提升m/k连续帧的优先级，以补充主时间驱动调度。

Result: 评估表明该策略能有效维持网络控制系统的控制质量，且开销较小。

Conclusion: (m,k)-firm Elevation Policy是一种轻量级且鲁棒的备用机制，适用于不稳定网络条件下的应用。

Abstract: Current standardization efforts are advancing the integration of 5G and
Time-Sensitive Networking (TSN) to facilitate the deployment of safety-critical
industrial applications that require real-time communication. However, there
remains a fundamental disconnect between the probabilistic 5G delay
characteristics and the often idealistic delay models used to synthesize 5G-TSN
network configurations. For time-driven schedules in particular, any delay
outlier unforeseen during schedule synthesis can jeopardize the robustness of
their real-time guarantees. To address this challenge, we present the
(m,k)-firm Elevation Policy to uphold a base level of weakly hard real-time
guarantees during unstable network conditions that do not match the expected
delay characteristics. It augments the primary time-driven schedule with a
dynamic priority-driven scheme to elevate the priority of m out of k
consecutive frames if they are delayed. Our evaluations demonstrate that weakly
hard real-time guarantees are essential to uphold the quality of control within
a networked control system. At the same time, only a small overhead is imposed
when the primary schedule can provide stronger quality of service guarantees.
Our (m,k)-firm Elevation Policy thereby yields a robust but light-weight
fallback mechanism to serve applications with meaningful guarantees during
unstable network conditions.

</details>


### [210] [A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study](https://arxiv.org/abs/2508.09839)
*Muhammad Asad Ullah,Luca Borgianni,Heikki Kokkinen,Antti Anttonen,Stefano Giordano*

Main category: cs.NI

TL;DR: 本文通过实测分析了Starlink在航空领域的性能，发现其在高空和下降阶段的吞吐量差异显著，并探讨了影响RTT的因素。


<details>
  <summary>Details</summary>
Motivation: 随着航空公司开始提供Starlink互联网服务，需要深入评估其在飞行中的性能。

Method: 在波罗的海和太平洋上空进行飞行测量，分析吞吐量和RTT。

Result: 单用户设备的中位下行和上行吞吐量分别为64 Mbps和24 Mbps；高空时上行吞吐量约为33 Mbps，下降阶段降至20 Mbps。RTT受地面站位置和ISLs影响。

Conclusion: Starlink在航空领域表现良好，但下降阶段性能下降明显，RTT受多种因素影响。

Abstract: Starlink delivers Internet services to users across terrestrial, maritime,
and aviation domains. The prior works have studied its performance at fixed
sites and in-motion vehicles, while an in-depth analysis of in-flight
performance remains absent. With major airlines now offering Starlink Internet
onboard, there is a growing need to evaluate and improve its performance for
aviation users. This paper addresses this shortcoming by conducting in-flight
measurements over the Baltic Sea and the Pacific Ocean. Our measurement results
show that a single user device experiences median throughputs of 64 Mbps and 24
Mbps for the downlink and uplink, respectively. The median uplink throughput is
approximately 33 Mbps when the aircraft maintains an altitude above 17,000
feet. However, a significant reduction in uplink performance is observed during
the aircraft descent phase, with the median throughput dropping to around 20
Mbps at lower altitudes. Round-trip time (RTT) is highly dependent on the
location of the ground station being pinged and the use of inter-satellite
links (ISLs). We dive deeper into 5.5 hours of ping measurements collected over
the Pacific Ocean and investigate factors influencing RTT, hypothesizing that
ISLs routing, data queuing at satellites, and feeder link congestion contribute
to deviations from theoretical values. For comparative analysis, we evaluate
the Starlink ground terminal and in-flight connectivity performance from the
perspectives of a residential user and an airline passenger, respectively.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [211] [Invertible Syntax without the Tuples (Functional Pearl)](https://arxiv.org/abs/2508.09856)
*Mathieu Boespflug,Arnaud Spiwack*

Main category: cs.PL

TL;DR: 本文重新探讨了Danvy的延续传递风格（CPS）在解析和打印结构化数据中的重要性，提出了三种基于CPS的解决方案。


<details>
  <summary>Details</summary>
Motivation: 重新评估Danvy的CPS方法在更广泛场景下的适用性，尤其是在处理解析和打印结构化数据时。

Method: 提出了三种基于延续传递风格的解决方案，避免了依赖类型和嵌套对的聚合方法。

Result: 展示了CPS方法在处理结构化数据时的有效性和表达能力。

Conclusion: CPS方法在解析和打印结构化数据中仍然具有重要价值，可以作为依赖类型和嵌套对聚合的替代方案。

Abstract: In the seminal paper Functional unparsing, Olivier Danvy used continuation
passing to reanalyse printf-like format strings as combinators. In the
intervening decades, the conversation shifted towards a concurrent line of work
-- applicative, monadic or arrow-based combinator libraries -- in an effort to
find combinators for invertible syntax descriptions that simultaneously
determine a parser as well as a printer, and with more expressive power, able
to handle inductive structures such as lists and trees. Along the way,
continuation passing got lost. This paper argues that Danvy's insight remains
as relevant to the general setting as it was to the restricted setting of his
original paper. Like him, we present three solutions that exploit
continuation-passing style as an alternative to both dependent types and
monoidal aggregation via nested pairs, in our case to parse and print
structured data with increasing expressive power.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [212] [Teaching Code Refactoring Using LLMs](https://arxiv.org/abs/2508.09332)
*Anshul Khairnar,Aarya Rajoju,Edward F. Gehringer*

Main category: cs.SE

TL;DR: 研究探讨了如何利用大型语言模型（LLMs）通过实时、上下文感知的反馈来改进软件工程课程中的代码重构教学。


<details>
  <summary>Details</summary>
Motivation: 代码重构虽能提升代码质量，但在教学中难以实施，尤其是在复杂、真实的代码库中。传统方法（如代码审查和静态分析工具）反馈有限且不一致。

Method: 研究将LLM辅助的重构集成到课程项目中，使用结构化提示帮助学生识别和解决代码异味（如长方法和低内聚）。

Result: 在2025年春季的长期开源项目中实施，并通过学生反馈和代码质量改进分析进行评估。

Conclusion: 结果表明，LLMs能弥合理论与实践学习的差距，帮助学生更深入地理解可维护性和重构原则。

Abstract: This Innovative Practice full paper explores how Large Language Models (LLMs)
can enhance the teaching of code refactoring in software engineering courses
through real-time, context-aware feedback. Refactoring improves code quality
but is difficult to teach, especially with complex, real-world codebases.
Traditional methods like code reviews and static analysis tools offer limited,
inconsistent feedback. Our approach integrates LLM-assisted refactoring into a
course project using structured prompts to help students identify and address
code smells such as long methods and low cohesion. Implemented in Spring 2025
in a long-lived OSS project, the intervention is evaluated through student
feedback and planned analysis of code quality improvements. Findings suggest
that LLMs can bridge theoretical and practical learning, supporting a deeper
understanding of maintainability and refactoring principles.

</details>


### [213] [Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser](https://arxiv.org/abs/2508.09366)
*Qiaolin Qin,Xingfang Wu,Heng Li,Ettore Merlo*

Main category: cs.SE

TL;DR: PIPLUP是一种新型的基于统计的日志解析器，挑战了语义解析器更有效的普遍观点，通过数据不敏感参数实现高准确性和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于统计的日志解析器效率高但准确性不足，而语义解析器依赖外部知识。PIPLUP旨在证明统计方法也能高效且准确。

Method: PIPLUP通过消除常量令牌位置的预设，依赖数据不敏感参数实现“即插即用”，无需GPU或外部API。

Result: 在大型日志数据集上，PIPLUP优于主流统计解析器（如Drain），并与最佳无监督语义解析器（LUNAR）竞争。

Conclusion: PIPLUP高效、简单且实用，特别适合成本和隐私敏感的实际场景。

Abstract: Log parsing is an essential task in log analysis, and many tools have been
designed to accomplish it. Existing log parsers can be categorized into
statistic-based and semantic-based approaches. In comparison to semantic-based
parsers, existing statistic-based parsers tend to be more efficient, require
lower computational costs, and be more privacy-preserving thanks to on-premise
deployment, but often fall short in their accuracy (e.g., grouping or parsing
accuracy) and generalizability. Therefore, it became a common belief that
statistic-based parsers cannot be as effective as semantic-based parsers since
the latter could take advantage of external knowledge supported by pretrained
language models. Our work, however, challenges this belief with a novel
statistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the
position of constant tokens for log grouping and relies on data-insensitive
parameters to overcome the generalizability challenge, allowing "plug and play"
on given log files. According to our experiments on an open-sourced large log
dataset, PIPLUP shows promising accuracy and generalizability with the
data-insensitive default parameter set. PIPLUP not only outperforms the
state-of-the-art statistic-based log parsers, Drain and its variants, but also
obtains a competitive performance compared to the best unsupervised
semantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time
consumption without GPU acceleration and external API usage; our simple,
efficient, and effective approach makes it more practical in real-world
adoptions, especially when costs and privacy are of major concerns.

</details>


### [214] [Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion](https://arxiv.org/abs/2508.09537)
*Yanzhou Li,Tianlin Li,Yiran Zhang,Shangqing Liu,Aishan Liu,Yang Liu*

Main category: cs.SE

TL;DR: 论文提出了一种三阶段方法，通过意图推断和交互式优化提升LLM在无注释代码库中的功能完成能力，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现实代码库中因缺乏显式注释（如文档字符串）导致LLM性能下降的问题。

Method: 三阶段流程：1) 意图推断，通过分析代码上下文提取功能线索；2) 交互式优化，开发者参与意图修正；3) 基于最终意图生成代码。

Result: 在DevEval和ComplexCodeEval上，方法使LLM性能提升超过20%，交互优化进一步改善结果。

Conclusion: 该方法有效提升了LLM在无注释环境下的代码生成能力，交互优化是关键补充。

Abstract: Large Language Models (LLMs) are increasingly used for function completion in
repository-scale codebases. Prior studies demonstrate that when explicit
instructions--such as docstrings--are provided, these models can generate
highly accurate implementations. However, in real-world repositories, such
annotations are frequently absent, and performance drops substantially without
them. To address this gap, we frame the task as a three-stage process. The
first stage focuses on intent inference, where the model analyzes the code
preceding the target function to uncover cues about the desired functionality.
Such preceding context often encodes subtle but critical information, and we
design a reasoning-based prompting framework to guide the LLM through
step-by-step extraction and synthesis of these signals before any code is
generated. The second stage introduces an optional interactive refinement
mechanism to handle cases where preceding context alone is insufficient for
intent recovery. In this stage, the model proposes a small set of candidate
intentions, enabling the developer to select or edit them so that the inferred
intent closely matches the actual requirement. Finally, in the third stage, the
LLM generates the target function conditioned on the finalized intent. To
support this pipeline, we curate a dataset of 40,000 examples annotated with
intermediate reasoning traces and corresponding docstrings. Extensive
experiments on DevEval and ComplexCodeEval show that our approach consistently
boosts multiple LLMs, achieving over 20\% relative gains in both
reference-based and execution-based metrics, with the interactive refinement
stage delivering additional improvements beyond these gains.

</details>


### [215] [ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation](https://arxiv.org/abs/2508.09648)
*Taohong Zhu,Lucas C. Cordeiro,Youcheng Sun*

Main category: cs.SE

TL;DR: ReqInOne是一种基于LLM的代理，通过模块化架构将SRS生成分解为摘要、需求提取和需求分类三个任务，显著提高了SRS文档的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 手动编写SRS文档耗时且易产生歧义，现有自动化方法依赖人工分析，而基于LLM的方法存在幻觉和可控性不足的问题。

Method: ReqInOne采用模块化架构，分解SRS生成为三个任务，每个任务使用定制提示模板优化LLM输出。

Result: ReqInOne生成的SRS文档比基于GPT-4的整体方法和初级工程师更准确和结构化，其需求分类组件性能优于现有模型。

Conclusion: ReqInOne的模块化设计显著提升了SRS生成的质量和效率，为自动化需求工程提供了新思路。

Abstract: Software Requirements Specification (SRS) is one of the most important
documents in software projects, but writing it manually is time-consuming and
often leads to ambiguity. Existing automated methods rely heavily on manual
analysis, while recent Large Language Model (LLM)-based approaches suffer from
hallucinations and limited controllability. In this paper, we propose ReqInOne,
an LLM-based agent that follows the common steps taken by human requirements
engineers when writing an SRS to convert natural language into a structured
SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into
three tasks: summary, requirement extraction, and requirement classification,
each supported by tailored prompt templates to improve the quality and
consistency of LLM outputs.
  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the
generated SRSs against those produced by the holistic GPT-4-based method from
prior work as well as by entry-level requirements engineers. Expert evaluations
show that ReqInOne produces more accurate and well-structured SRS documents.
The performance advantage of ReqInOne benefits from its modular design, and
experimental results further demonstrate that its requirement classification
component achieves comparable or even better results than the state-of-the-art
requirement classification model.

</details>


### [216] [DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity](https://arxiv.org/abs/2508.09676)
*Vishal Khare,Vijay Saini,Deepak Sharma,Anand Kumar,Ankit Rana,Anshul Yadav*

Main category: cs.SE

TL;DR: DeputyDev是一个AI驱动的代码审查助手，旨在解决软件开发过程中的效率问题。通过自动化代码审查，显著减少了审查时间，并已在组织内外广泛应用。


<details>
  <summary>Details</summary>
Motivation: 代码审查过程效率低下，表现为耗时长、反馈不一致和质量不稳定。研究观察到PR处理时间过长，影响开发效率和代码质量。

Method: 开发了DeputyDev的PR审查功能，提供自动化、上下文相关的代码审查，并通过双盲A/B实验验证其效果。

Result: 实验结果显示，DeputyDev显著减少了每PR（23.09%）和每行代码（40.13%）的审查时间。

Conclusion: DeputyDev成功提升了代码审查效率，并作为SaaS解决方案推广至外部公司，证明了AI辅助代码审查的有效性。

Abstract: This study investigates the implementation and efficacy of DeputyDev, an
AI-powered code review assistant developed to address inefficiencies in the
software development process. The process of code review is highly inefficient
for several reasons, such as it being a time-consuming process, inconsistent
feedback, and review quality not being at par most of the time. Using our
telemetry data, we observed that at TATA 1mg, pull request (PR) processing
exhibits significant inefficiencies, with average pick-up and review times of
73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review
cycle was marked by prolonged iterative communication between the reviewing and
submitting parties. Research from the University of California, Irvine
indicates that interruptions can lead to an average of 23 minutes of lost
focus, critically affecting code quality and timely delivery. To address these
challenges, we developed DeputyDev's PR review capabilities by providing
automated, contextual code reviews. We conducted a rigorous double-controlled
A/B experiment involving over 200 engineers to evaluate DeputyDev's impact on
review times. The results demonstrated a statistically significant reduction in
both average per PR (23.09%) and average per-line-of-code (40.13%) review
durations. After implementing safeguards to exclude outliers, DeputyDev has
been effectively rolled out across the entire organisation. Additionally, it
has been made available to external companies as a Software-as-a-Service (SaaS)
solution, currently supporting the daily work of numerous engineering
professionals. This study explores the implementation and effectiveness of
AI-assisted code reviews in improving development workflow timelines and code.

</details>


### [217] [Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering](https://arxiv.org/abs/2508.09680)
*Orvila Sarker,Mona Jamshaid,M. Ali Babar*

Main category: cs.SE

TL;DR: 论文探讨了自闭症个体在ICT领域的潜力与面临的障碍，提出了18个成功因素，分为四类，为教育机构、雇主等提供了基于证据的包容性建议。


<details>
  <summary>Details</summary>
Motivation: 自闭症个体在ICT领域有独特优势，但面临职场障碍。研究旨在填补从教育到职场包容的知识空白。

Method: 通过系统综述30项研究，识别出18个成功因素，分为四类主题。

Result: 提出了针对教育、培训、工作环境和工具的包容性策略。

Conclusion: 研究为提升自闭症个体在软件工程中的包容性提供了实用建议。

Abstract: Research has highlighted the valuable contributions of autistic individuals
in the Information and Communication Technology (ICT) sector, particularly in
areas such as software development, testing, and cybersecurity. Their strengths
in information processing, attention to detail, innovative thinking, and
commitment to high-quality outcomes in the ICT domain are well-documented.
However, despite their potential, autistic individuals often face barriers in
Software Engineering (SE) roles due to a lack of personalised tools, complex
work environments, non-inclusive recruitment practices, limited co-worker
support, challenging social dynamics and so on. Motivated by the ethical
framework of the neurodiversity movement and the success of pioneering
initiatives like the Dandelion program, corporate Diversity, Equity, and
Inclusion (DEI) in the ICT sector has increasingly focused on autistic talent.
This movement fundamentally reframes challenges not as individual deficits but
as failures of environments designed for a neurotypical majority. Despite this
progress, there is no synthesis of knowledge reporting the full pathway from
software engineering education through to sustainable workplace inclusion. To
address this, we conducted a Systematic Review of 30 studies and identified 18
success factors grouped into four thematic categories: (1) Software Engineering
Education, (2) Career and Employment Training, (3) Work Environment, and (4)
Tools and Assistive Technologies. Our findings offer evidence-based
recommendations for educational institutions, employers, organisations, and
tool developers to enhance the inclusion of autistic individuals in SE. These
include strategies for inclusive meeting and collaboration practices,
accessible and structured work environments, clear role and responsibility
definitions, and the provision of tailored workplace accommodations.

</details>


### [218] [LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations](https://arxiv.org/abs/2508.09791)
*Junxiao Han,Yarong Wang,Xiaodong Gu,Cuiyun Gao,Yao Wan,Song Han,David Lo,Shuiguang Deng*

Main category: cs.SE

TL;DR: LibRec是一个结合LLMs和RAG技术的框架，用于自动化推荐替代库，并通过上下文学习提取迁移意图以提高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决库迁移推荐任务中自动化工具的不足，提高推荐准确性。

Method: 结合LLMs和RAG技术，利用上下文学习提取迁移意图，并引入LibEval基准进行评估。

Result: 评估了10种流行LLMs，进行了消融实验、提示策略分析、意图类型评估和失败案例分析。

Conclusion: LibRec框架在库迁移推荐任务中表现有效，LibEval基准为未来研究提供了基础。

Abstract: In this paper, we propose LibRec, a novel framework that integrates the
capabilities of LLMs with retrieval-augmented generation(RAG) techniques to
automate the recommendation of alternative libraries. The framework further
employs in-context learning to extract migration intents from commit messages
to enhance the accuracy of its recommendations. To evaluate the effectiveness
of LibRec, we introduce LibEval, a benchmark designed to assess the performance
in the library migration recommendation task. LibEval comprises 2,888 migration
records associated with 2,368 libraries extracted from 2,324 Python
repositories. Each migration record captures source-target library pairs, along
with their corresponding migration intents and intent types. Based on LibEval,
we evaluated the effectiveness of ten popular LLMs within our framework,
conducted an ablation study to examine the contributions of key components
within our framework, explored the impact of various prompt strategies on the
framework's performance, assessed its effectiveness across various intent
types, and performed detailed failure case analyses.

</details>


### [219] [Fast and Accurate Heuristics for Bus-Factor Estimation](https://arxiv.org/abs/2508.09828)
*Sebastiano Antonio Piccolo*

Main category: cs.SE

TL;DR: 论文提出两种基于图剥离的启发式方法（Minimum Coverage和Maximum Coverage），用于近似计算软件项目的bus-factor，显著优于传统方法，并在大规模图上验证了其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: bus-factor是衡量项目风险的关键指标，但精确计算其NP-Hard特性使其难以扩展到大系统。因此，需要高效的近似方法。

Method: 将软件项目建模为开发者和任务的双部图，提出两种基于迭代图剥离的启发式方法。

Result: 在1000多个合成图上验证，新方法比传统方法更准确且可扩展至百万级节点图。

Conclusion: 新启发式方法高效、准确且鲁棒，已开源以支持研究和应用。

Abstract: The bus-factor is a critical risk indicator that quantifies how many key
contributors a project can afford to lose before core knowledge or
functionality is compromised. Despite its practical importance, accurately
computing the bus-factor is NP-Hard under established formalizations, making
scalable analysis infeasible for large software systems.
  In this paper, we model software projects as bipartite graphs of developers
and tasks and propose two novel approximation heuristics, Minimum Coverage and
Maximum Coverage, based on iterative graph peeling, for two influential
bus-factor formalizations. Our methods significantly outperform the widely
adopted degree-based heuristic, which we show can yield severely inflated
estimates.
  We conduct a comprehensive empirical evaluation on over $1\,000$ synthetic
power-law graphs and demonstrate that our heuristics provide tighter estimates
while scaling to graphs with millions of nodes and edges in minutes. Our
results reveal that the proposed heuristics are not only more accurate but also
robust to structural variations in developer-task assignment graph. We release
our implementation as open-source software to support future research and
practical adoption.

</details>


### [220] [Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification](https://arxiv.org/abs/2508.09832)
*Linh Nguyen,Chunhua Liu,Hong Yi Lin,Patanamon Thongtanunam*

Main category: cs.SE

TL;DR: 论文探讨了使用大型语言模型（LLMs）分类代码审查评论的潜力，结果显示LLMs在分类效果上优于现有深度学习方法，尤其是在低训练样本类别上表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督学习的代码审查评论分类方法需要大量手动标注数据，限制了其可扩展性。因此，研究探索LLMs是否能提供更高效的解决方案。

Method: 研究评估了LLMs在分类17种代码审查评论上的性能，并与现有深度学习方法进行对比。

Result: LLMs在分类效果上优于现有方法，尤其是在低训练样本类别上表现更优，且整体性能更均衡。

Conclusion: LLMs为代码审查分析提供了可扩展的解决方案，有助于提升代码审查的有效性。

Abstract: Code review is a crucial practice in software development. As code review
nowadays is lightweight, various issues can be identified, and sometimes, they
can be trivial. Research has investigated automated approaches to classify
review comments to gauge the effectiveness of code reviews. However, previous
studies have primarily relied on supervised machine learning, which requires
extensive manual annotation to train the models effectively. To address this
limitation, we explore the potential of using Large Language Models (LLMs) to
classify code review comments. We assess the performance of LLMs to classify 17
categories of code review comments. Our results show that LLMs can classify
code review comments, outperforming the state-of-the-art approach using a
trained deep learning model. In particular, LLMs achieve better accuracy in
classifying the five most useful categories, which the state-of-the-art
approach struggles with due to low training examples. Rather than relying
solely on a specific small training data distribution, our results show that
LLMs provide balanced performance across high- and low-frequency categories.
These results suggest that the LLMs could offer a scalable solution for code
review analytics to improve the effectiveness of the code review process.

</details>


### [221] [An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues](https://arxiv.org/abs/2508.09875)
*Jinbao Chen,Boyao Ding,Yu Zhang,Qingwei Li,Fugen Tang*

Main category: cs.SE

TL;DR: 该论文研究了Go语言中的CGO使用情况，分析了其分布、模式、目的及问题，并提出了临时解决方案和改进建议。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了Go语言中的CGO（FFI）及其独特风险，因此需要深入分析其使用情况和潜在问题。

Method: 通过对920个开源Go项目进行实证研究，开发了CGOAnalyzer工具来识别和量化CGO相关特征。

Result: 研究发现11.3%的项目使用CGO，存在19类问题，包括可能导致运行时崩溃的关键问题，并提出了临时解决方案和改进提案。

Conclusion: 研究为开发者和Go团队提供了宝贵见解，提升了开发效率和工具链的稳健性。

Abstract: Multilingual software development integrates multiple languages into a single
application, with the Foreign Function Interface (FFI) enabling seamless
interaction. While FFI boosts efficiency and extensibility, it also introduces
risks. Existing studies focus on FFIs in languages like Python and Java,
neglecting CGO, the emerging FFI in Go, which poses unique risks.
  To address these concerns, we conduct an empirical study of CGO usage across
920 open-source Go projects. Our study aims to reveal the distribution,
patterns, purposes, and critical issues associated with CGO, offering insights
for developers and the Go team. We develop CGOAnalyzer, a tool to efficiently
identify and quantify CGO-related features. Our findings reveal that: (1) 11.3%
of analyzed Go projects utilize CGO, with usage concentrated in a subset of
projects; (2) CGO serves 4 primary purposes, including system-level
interactions and performance optimizations, with 15 distinct usage patterns
observed; (3) 19 types of CGO-related issues exist, including one critical
issue involving unnecessary pointer checks that pose risks of runtime crashes
due to limitations in the current Go compilation toolchain; (4) a temporary
solution reduces unnecessary pointer checks, mitigating crash risks, and (5) we
submitted a proposal to improve the Go toolchain for a permanent fix, which has
been grouped within an accepted proposal for future resolution. Our findings
provide valuable insights for developers and the Go team, enhancing development
efficiency and reliability while improving the robustness of the Go toolchain.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [222] [Approximate Sparsity Class and Minimax Estimation](https://arxiv.org/abs/2508.09278)
*Lucas Z. Zhang*

Main category: econ.EM

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Motivated by the orthogonal series density estimation in $L^2([0,1],\mu)$, in
this project we consider a new class of functions that we call the approximate
sparsity class. This new class is characterized by the rate of decay of the
individual Fourier coefficients for a given orthonormal basis. We establish the
$L^2([0,1],\mu)$ metric entropy of such class, with which we show the minimax
rate of convergence. For the density subset in this class, we propose an
adaptive density estimator based on a hard-thresholding procedure that achieves
this minimax rate up to a $\log$ term.

</details>


### [223] [Machine Learning for Detecting Collusion and Capacity Withholding in Wholesale Electricity Markets](https://arxiv.org/abs/2508.09885)
*Jeremy Proz,Martin Huber*

Main category: econ.EM

TL;DR: 本文提出了一种改进的机器学习算法，用于检测电力批发市场中的合谋行为，并通过意大利电力市场的案例验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 研究电力批发市场中的合谋和容量扣留行为，这些行为是市场操纵的重要机制。

Method: 使用基于统计筛选器的集成机器学习方法，结合新的容量扣留行为筛选器，检测电力供应商的合谋行为。

Result: 在完全合谋情况下，算法分类准确率可达95%；在更大数据集上，现有筛选器已能达到98%的准确率，新筛选器未进一步提升性能。

Conclusion: 监督机器学习技术在电力市场合谋检测中具有潜力。

Abstract: Collusion and capacity withholding in electricity wholesale markets are
important mechanisms of market manipulation. This study applies a refined
machine learning-based cartel detection algorithm to two cartel cases in the
Italian electricity market and evaluates its out-of-sample performance.
Specifically, we consider an ensemble machine learning method that uses
statistical screens constructed from the offer price distribution as predictors
for the incidence of collusion among electricity providers in specific regions.
We propose novel screens related to the capacity-withholding behavior of
electricity providers and find that including such screens derived from the
day-ahead spot market as predictors can improve cartel detection. We find that,
under complete cartels - where collusion in a tender presumably involves all
suppliers - the method correctly classifies up to roughly 95% of tenders in our
data as collusive or competitive, improving classification accuracy compared to
using only previously available screens. However, when trained on larger
datasets including non-cartel members and applying algorithms tailored to
detect incomplete cartels, the previously existing screens are sufficient to
achieve 98% accuracy, and the addition of our newly proposed
capacity-withholding screens does not further improve performance. Overall,
this study highlights the promising potential of supervised machine learning
techniques for detecting and dismantling cartels in electricity markets.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [224] [Forecasting Binary Economic Events in Modern Mercantilism: Traditional methodologies coupled with PCA and K-means Quantitative Analysis of Qualitative Sentimental Data](https://arxiv.org/abs/2508.09243)
*Sebastian Kot*

Main category: econ.GN

TL;DR: 论文通过PCA分析新闻文章语义嵌入，量化追踪现代重商主义动态。


<details>
  <summary>Details</summary>
Motivation: 研究现代重商主义对全球化范式的颠覆性影响。

Method: 使用PCA分析SBERT生成的768维语义嵌入，提取保护主义、技术主权和集团重组相关的潜在因子。

Result: 通过主成分载荷分析，识别了驱动分类性能的关键语义特征，提高了可解释性和预测准确性。

Conclusion: 该方法为通过高维文本分析量化追踪新兴重商主义动态提供了可扩展的数据驱动框架。

Abstract: This paper examines Modern Mercantilism, characterized by rising economic
nationalism, strategic technological decoupling, and geopolitical
fragmentation, as a disruptive shift from the post-1945 globalization paradigm.
It applies Principal Component Analysis (PCA) to 768-dimensional
SBERT-generated semantic embeddings of curated news articles to extract
orthogonal latent factors that discriminate binary event outcomes linked to
protectionism, technological sovereignty, and bloc realignments. Analysis of
principal component loadings identifies key semantic features driving
classification performance, enhancing interpretability and predictive accuracy.
This methodology provides a scalable, data-driven framework for quantitatively
tracking emergent mercantilist dynamics through high-dimensional text analytics

</details>


### [225] [The Market Effects of Algorithms](https://arxiv.org/abs/2508.09513)
*Lindsey Raymond*

Main category: econ.GN

TL;DR: 论文研究了算法预测对美国家庭住房市场的影响，发现数字化记录降低了使用算法的成本，导致算法投资者进入市场，但未排挤人类投资者。算法投资者主要购买少数族裔房产，减少了价格差异。


<details>
  <summary>Details</summary>
Motivation: 探索算法优化决策对市场的实际影响，特别是在住房市场中算法预测的可用性如何改变市场动态。

Method: 利用数字化记录作为自然实验，分析算法投资者和人类投资者的行为变化及其对房价的影响。

Result: 数字化导致算法投资者进入市场，人类投资者转向难以预测的房产。算法投资者减少了少数族裔房产的价格差异，平均售价提高5%，种族价格差距减少45%。

Conclusion: 算法可以通过竞争减少人类偏见，降低市场层面的种族不平等。

Abstract: While there is excitement about the potential for algorithms to optimize
individual decision-making, changes in individual behavior will, almost
inevitably, impact markets. Yet little is known about such effects. In this
paper, I study how the availability of algorithmic prediction changes entry,
allocation, and prices in the US single-family housing market, a key driver of
household wealth. I identify a market-level natural experiment that generates
variation in the cost of using algorithms to value houses: digitization, the
transition from physical to digital housing records. I show that digitization
leads to entry by investors using algorithms, but does not push out investors
using human judgment. Instead, human investors shift toward houses that are
difficult to predict algorithmically. Algorithmic investors predominantly
purchase minority-owned homes, a segment of the market where humans may be
biased. Digitization increases the average sale price of minority-owned homes
by 5% and reduces racial disparities in home prices by 45%. Algorithmic
investors, via competition, affect the prices paid by owner-occupiers and human
investors for minority homes; such changes drive the majority of the reduction
in racial disparities. The decrease in racial inequality underscores the
potential for algorithms to mitigate human biases at the market level.

</details>


### [226] [Artificial Intelligence, Domain AI Readiness, and Firm Productivity](https://arxiv.org/abs/2508.09634)
*Sipeng Zeng,Xiaoning Wang,Tianshu Sun*

Main category: econ.GN

TL;DR: 研究探讨了企业AI能力与行业AI准备度（domain AI readiness）的互补性对绩效的影响，发现高准备度行业能显著提升AI带来的生产力和创新收益。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在创新和生产效率方面潜力巨大，但许多企业难以实现其效益，因此研究探索了成功与失败的原因。

Method: 利用2016-2022年中国上市公司的面板数据，通过专利数据构建行业AI准备度指标，分析其与企业AI能力的交互作用。

Result: AI能力在高准备度行业中表现更佳，而在技术落后或过时的行业中效益有限。结果通过工具变量验证稳健性。

Conclusion: 行业AI准备度的提升主要源于学术进步，而非企业自身战略调整，强调了外部技术整合的重要性。

Abstract: Although Artificial Intelligence (AI) holds great promise for enhancing
innovation and productivity, many firms struggle to realize its benefits. We
investigate why some firms and industries succeed with AI while others do not,
focusing on the degree to which an industrial domain is technologically
integrated with AI, which we term "domain AI readiness". Using panel data on
Chinese listed firms from 2016 to 2022, we examine how the interaction between
firm-level AI capabilities and domain AI readiness affects firm performance. We
create novel constructs from patent data and measure the domain AI readiness of
a specific domain by analyzing the co-occurrence of four-digit International
Patent Classification (IPC4) codes related to AI with the specific domain
across all patents in that domain. Our findings reveal a strong
complementarity: AI capabilities yield greater productivity and innovation
gains when deployed in domains with higher AI readiness, whereas benefits are
limited in domains that are technologically unprepared or already obsolete.
These results remain robust when using local AI policy initiatives as
instrumental variables. Further analysis shows that this complementarity is
driven by external advances in domain-AI integration, rather than firms' own
strategic pivots. Time-series analysis of IPC4 co-occurrence patterns further
suggests that improvements in domain AI readiness stem primarily from the
academic advancements of AI in specific domains.

</details>


### [227] [A Characterization Framework for Stable Sets and Their Variants](https://arxiv.org/abs/2508.09798)
*Athanasios Andrikopoulos,Nikolaos Sampanis*

Main category: econ.GN

TL;DR: 扩展了稳定集及其变体在无限集上的理论，并提供了拓扑学存在性特征。


<details>
  <summary>Details</summary>
Motivation: 解决循环偏好下选择集为空的问题。

Method: 扩展经典稳定集及其变体（如扩展稳定集、社会稳定集、$m$-和$w$-稳定集）到无限集。

Result: 提出了无限集上稳定集的拓扑学存在性特征。

Conclusion: 为循环偏好下的选择问题提供了更通用的解决方案。

Abstract: The theory of optimal choice sets offers a well-established solution
framework in social choice and game theory. In social choice theory,
decision-making is typically modeled as a maximization problem. However, when
preferences are cyclic -- as can occur in economic processes -- the set of
maximal elements may be empty, raising the key question of what should be
considered a valid choice. To address this issue, several approaches --
collectively known as general solution theories -- have been proposed for
constructing non-empty choice sets. Among the most prominent in the context of
a finite set of alternatives are the Stable Set (also known as the Von
Neumann-Morgenstern set) and its extensions, such as the Extended Stable Set,
the socially stable set, and the $m$-, and $w$-stable sets. In this paper, we
extend the classical concept of the stable set and its major variants -
specifically, the extended stable set, the socially stable set, and the $m$-
and $w$-stable sets - within the framework of irreflexive binary relations over
infinite sets of alternatives. Additionally, we provide a topological
characterization for the existence of such general solutions.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [228] [Swap Bounded Envy](https://arxiv.org/abs/2508.09290)
*Federico Echenique,Sumit Goel,SangMok Lee*

Main category: econ.TH

TL;DR: 研究离散物品分配的公平性，提出一种在特定偏好限制下实现“交换有界嫉妒”分配的算法。


<details>
  <summary>Details</summary>
Motivation: 由于完全公平（无嫉妒）的分配不可行，探讨近似公平的概念。

Method: 关注通过交换两个物品消除嫉妒的分配方式，提出一种算法。

Result: 在特定偏好限制下，算法实现了“交换有界嫉妒”的分配。

Conclusion: 提出的算法为解决近似公平分配问题提供了可行方案。

Abstract: We study fairness in the allocation of discrete goods. Exactly fair
(envy-free) allocations are impossible, so we discuss notions of approximate
fairness. In particular, we focus on allocations in which the swap of two items
serves to eliminate any envy, either for the allocated bundles or with respect
to a reference bundle. We propose an algorithm that, under some restrictions on
agents' preferences, achieves an allocation with ``swap bounded envy.''

</details>


### [229] [Sequential Non-Bayesian Persuasion](https://arxiv.org/abs/2508.09464)
*Yaron Azrieli,Rachana Das*

Main category: econ.TH

TL;DR: 研究了一种说服模型，接收者是保守贝叶斯主义者，其更新信念是先验和正确贝叶斯后验的凸组合。结果显示，在序贯说服中，发送者能获益。


<details>
  <summary>Details</summary>
Motivation: 探讨在接收者保守贝叶斯主义的情况下，序贯说服对发送者的价值。

Method: 分析序贯说服模型，比较经典贝叶斯与保守贝叶斯情况下的结果。

Result: 发送者在序贯说服中获益，且在发送者和接收者均有偏见的模型中，发送者的最大期望收益与无偏见情况相同。

Conclusion: 序贯说服在保守贝叶斯模型中具有优势，发送者能从中获益。

Abstract: We study a model of persuasion in which the receiver is a `conservative
Bayesian' whose updated belief is a convex combination of the prior and the
correct Bayesian posterior. While in the classic Bayesian case providing
information sequentially is never valuable, we show that the sender gains from
sequential persuasion in many of the environments considered in the literature
on strategic information transmission. We also consider the case in which the
sender and receiver are both biased and prove that the maximal expected payoff
for the sender under sequential persuasion is the same as in the case where
neither of them is biased.

</details>


### [230] [Influence and Connectivity in Networks: A Generating Function Approach](https://arxiv.org/abs/2508.09492)
*Yang Sun,Wei Zhao,Junjie Zhou*

Main category: econ.TH

TL;DR: 本文提出了一种基于生成函数的系统性框架，用于网络中的行走枚举，通过首次通过分解将行走分为两部分，并建立了三类行走之间的关系方程。


<details>
  <summary>Details</summary>
Motivation: 研究网络中心性时，许多方法基于满足特定条件的行走计数，但缺乏系统性框架。本文旨在填补这一空白。

Method: 引入首次通过分解，将行走分为首次到达行走和后续行走，并通过生成函数建立三类行走（无限制、避免特定元素、通过指定集合）的方程系统。

Result: 该框架可用于评估结构干预对网络行走的影响，推广目标中心性到多接收者场景，以及比较添加链接的不同策略。

Conclusion: 提出的框架为网络行走分析提供了系统性和灵活性，适用于多种应用场景。

Abstract: Many widely used network centralities are based on counting walks that meet
specific criteria. This paper introduces a systematic framework for walk
enumeration using generating functions. We introduce a first-passage
decomposition that uniquely divides any walk passing through specified nodes or
links into two components: a first-reaching walk and a subsequent walk. This
decomposition yields a system of interconnected equations that relate three
disjoint categories of walks: unrestricted walks, walks that avoid specific
elements, and walks that pass through designated sets. The framework offers a
range of applications, including evaluating the effects of structural
interventions, such as node or link modifications, on network walks,
generalizing target centrality to multi-receiver scenarios in information
networks, and comparing different strategies for adding links.

</details>


### [231] [The asymmetrical Acquisition of information about the range of asset value in market](https://arxiv.org/abs/2508.09615)
*Jianhao Su,Yanliang Zhang*

Main category: econ.TH

TL;DR: 本文研究了投资者对资产未来收益范围信息的不对称获取对市场的影响，发现信息不对称会导致未获精确信息的投资者停止交易，同时市场流动性和价格对私人信号的敏感性会随信号和噪声交易量变化。


<details>
  <summary>Details</summary>
Motivation: 探讨投资者对资产未来收益范围信息的不对称获取如何影响市场行为，特别是未获精确信息的投资者的交易决策。

Method: 通过理论模型分析投资者在不对称获取范围信息下的行为，特别是未获精确信息的投资者在最大最小模糊厌恶准则下的交易决策。

Result: 不对称信息获取会导致未获精确信息的投资者停止交易，市场流动性和价格敏感性随信号和噪声交易量变化，某些条件下可能增加或减少流动性和价格敏感性。

Conclusion: 投资者对范围信息的不对称获取对市场有显著影响，可能导致流动性和价格敏感性的动态变化。

Abstract: The information investors acquire in asset markets has various forms. We
refer to range information as information about the upper and lower bound which
the payoff of an asset may reach in the future. This paper explores the market
impacts of investors' asymmetrical acquisition of range information. Uninformed
traders are inherently unable to directly obtain the private signal held by
informed traders. This study shows that when range information is released to
investors asymmetrically, uninformed traders who can only obtain rougher range
information will not trade assets under the max-min ambiguity aversion
criterion. Investors' asymmetrical acquisition of range information can cause
that market liquidity and the sensitivity of market price to private signal
vary continuously with the signal and noise trading volume. We also reveal that
investors' asymmetrical acquisition of range information can increase market
liquidity and the sensitivity of price under some conditions and decrease them
under some other conditions.

</details>
