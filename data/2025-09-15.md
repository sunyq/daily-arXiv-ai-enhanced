<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 22]
- [cs.CL](#cs.CL) [Total: 52]
- [cs.CV](#cs.CV) [Total: 64]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.SE](#cs.SE) [Total: 11]
- [econ.GN](#econ.GN) [Total: 6]
- [econ.TH](#econ.TH) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Human-AI Collaboration Increases Efficiency in Regulatory Writing](https://arxiv.org/abs/2509.09738)
*Umut Eser,Yael Gozin,L. Jay Stallons,Ari Caroline,Martin Preusse,Brandon Rice,Scott Wright,Andrew Robertson*

Main category: cs.AI

TL;DR: AutoIND大语言模型平台可将IND申请的非临床书面总结起草时间减少约97%，从约100小时缩短至3-4小时，质量评分达70-78%，无关键监管错误，但仍需专家完善以提高提交质量。


<details>
  <summary>Details</summary>
Motivation: 新药临床试验申请(IND)准备过程耗时且依赖专业知识，拖慢早期临床开发进程，需要寻找提高效率的方法。

Method: 使用AutoIND LLM平台生成IND非临床书面总结(eCTD模块2.6.2、2.6.4、2.6.6)，记录起草时间并与人工起草时间对比，由盲评监管写作评估员从7个预定义类别评估质量。

Result: 起草时间减少97%(从约100小时降至3.7小时和2.6小时)，质量评分分别为69.6%和77.9%，无关键监管错误，但在重点突出、简洁性和清晰度方面存在不足。

Conclusion: AutoIND能显著加速IND起草，但专家监管写作者仍需完善输出以达到提交质量要求，发现的系统性缺陷为针对性模型改进提供了路线图。

Abstract: Background: Investigational New Drug (IND) application preparation is
time-intensive and expertise-dependent, slowing early clinical development.
Objective: To evaluate whether a large language model (LLM) platform (AutoIND)
can reduce first-draft composition time while maintaining document quality in
regulatory submissions. Methods: Drafting times for IND nonclinical written
summaries (eCTD modules 2.6.2, 2.6.4, 2.6.6) generated by AutoIND were directly
recorded. For comparison, manual drafting times for IND summaries previously
cleared by the U.S. FDA were estimated from the experience of regulatory
writers ($\geq$6 years) and used as industry-standard benchmarks. Quality was
assessed by a blinded regulatory writing assessor using seven pre-specified
categories: correctness, completeness, conciseness, consistency, clarity,
redundancy, and emphasis. Each sub-criterion was scored 0-3 and normalized to a
percentage. A critical regulatory error was defined as any misrepresentation or
omission likely to alter regulatory interpretation (e.g., incorrect NOAEL,
omission of mandatory GLP dose-formulation analysis). Results: AutoIND reduced
initial drafting time by $\sim$97% (from $\sim$100 h to 3.7 h for 18,870
pages/61 reports in IND-1; and to 2.6 h for 11,425 pages/58 reports in IND-2).
Quality scores were 69.6\% and 77.9\% for IND-1 and IND-2. No critical
regulatory errors were detected, but deficiencies in emphasis, conciseness, and
clarity were noted. Conclusions: AutoIND can dramatically accelerate IND
drafting, but expert regulatory writers remain essential to mature outputs to
submission-ready quality. Systematic deficiencies identified provide a roadmap
for targeted model improvements.

</details>


### [2] [Executable Ontologies: Synthesizing Event Semantics with Dataflow Architecture](https://arxiv.org/abs/2509.09775)
*Aleksandr Boldachev*

Main category: cs.AI

TL;DR: boldsea是一个基于语义事件的可执行本体架构，用于建模复杂动态系统，通过整合事件语义和数据流架构来解决传统BPM系统和面向对象语义技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统业务过程管理(BPM)系统和面向对象语义技术在动态系统建模中的局限性，提供能够实时修改事件模型并统一数据和业务逻辑的语义框架。

Method: 提出BSL(boldsea语义语言)及其BNF语法，设计boldsea-engine架构，直接解释语义模型作为可执行算法而无需编译。

Result: 实现了运行时修改事件模型的能力，确保时间透明度，并在统一的语义框架内无缝融合数据和业务逻辑。

Conclusion: boldsea架构通过可执行本体和语义事件方法，为复杂动态系统的建模提供了有效的解决方案，克服了传统方法的限制。

Abstract: This paper presents boldsea, Boldachev's semantic-event approach -- an
architecture for modeling complex dynamic systems using executable ontologies
-- semantic models that act as dynamic structures, directly controlling process
execution. We demonstrate that integrating event semantics with a dataflow
architecture addresses the limitations of traditional Business Process
Management (BPM) systems and object-oriented semantic technologies. The paper
presents the formal BSL (boldsea Semantic Language), including its BNF grammar,
and outlines the boldsea-engine's architecture, which directly interprets
semantic models as executable algorithms without compilation. It enables the
modification of event models at runtime, ensures temporal transparency, and
seamlessly merges data and business logic within a unified semantic framework.

</details>


### [3] [How well can LLMs provide planning feedback in grounded environments?](https://arxiv.org/abs/2509.09790)
*Yuxuan Li,Victor Zhong*

Main category: cs.AI

TL;DR: 基础模型能够提供多样化的高质量规划反馈，模型越大、进行推理能力越强，但复杂动力学和连续空间会降低反馈质量


<details>
  <summary>Details</summary>
Motivation: 减少规划任务中的奖励函数设计和注释示范的需求，利用预训练基础模型提供背景知识来支持规划

Method: 评估LLM和VLM在符号、语言和连续控制环境中提供反馈的能力，包括二进制反馈、偏好反馈、动作建议、目标建议等，并考察不同推理方法的影响

Result: 基础模型能够在多个领域提供高质量反馈，较大、具有推理能力的模型更准确、偏差更小，从加强的推理方法中获益更多

Conclusion: 预训练基础模型是规划任务中有效的反馈来源，但环境复杂性会影响反馈质量，需要根据环境特性选择适当的模型和推理方法

Abstract: Learning to plan in grounded environments typically requires carefully
designed reward functions or high-quality annotated demonstrations. Recent
works show that pretrained foundation models, such as large language models
(LLMs) and vision language models (VLMs), capture background knowledge helpful
for planning, which reduces the amount of reward design and demonstrations
needed for policy learning. We evaluate how well LLMs and VLMs provide feedback
across symbolic, language, and continuous control environments. We consider
prominent types of feedback for planning including binary feedback, preference
feedback, action advising, goal advising, and delta action feedback. We also
consider inference methods that impact feedback performance, including
in-context learning, chain-of-thought, and access to environment dynamics. We
find that foundation models can provide diverse high-quality feedback across
domains. Moreover, larger and reasoning models consistently provide more
accurate feedback, exhibit less bias, and benefit more from enhanced inference
methods. Finally, feedback quality degrades for environments with complex
dynamics or continuous state spaces and action spaces.

</details>


### [4] [A Modular and Multimodal Generative AI Framework for Urban Building Energy Data: Generating Synthetic Homes](https://arxiv.org/abs/2509.09794)
*Jackson Eshbaugh,Chetan Tiwari,Jorge Silveyra*

Main category: cs.AI

TL;DR: 提出一种模块化多模态框架，利用生成式AI从公开住宅信息和图片生成能源建模所需的数据，解决数据获取难、费用高和隐私问题


<details>
  <summary>Details</summary>
Motivation: 能源建模需要大量数据，但部分数据获取困难、费用高或存在隐私风险，影响研究的可访问性和可复现性

Method: 开发模块化多模态框架，使用生成式人工智能从公开住宅信息和图片生成标签化数据，并提供相应的流水线实现

Result: 实验表明该框架避免了生成模型的常见问题，能够生成实际的标签数据

Conclusion: 通过减少对成本高或受限数据源的依赖，为更可访问和可复现的研究打开了途径

Abstract: Computational models have emerged as powerful tools for energy modeling
research, touting scalability and quantitative results. However, these models
require a plethora of data, some of which is inaccessible, expensive, or raises
privacy concerns. We introduce a modular multimodal framework to produce this
data from publicly accessible residential information and images using
generative artificial intelligence (AI). Additionally, we provide a pipeline
demonstrating this framework, and we evaluate its generative AI components. Our
experiments show that our framework's use of AI avoids common issues with
generative models. Our framework produces realistic, labeled data. By reducing
dependence on costly or restricted data sources, we pave a path towards more
accessible and reproducible research.

</details>


### [5] [The (R)evolution of Scientific Workflows in the Agentic AI Era: Towards Autonomous Science](https://arxiv.org/abs/2509.09915)
*Woong Shin,Renan Souza,Daniel Rosendo,Frédéric Suter,Feiyi Wang,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.AI

TL;DR: 这篇论文提出了一个概念框架，通过从静态到智能、单体到群体的两维进化路径，将当前的工作流管理系统发展为完全自主的分布式科学实验室，以实现100倍的科学发现加速。


<details>
  <summary>Details</summary>
Motivation: 现代科学发现需要协调分布式设施和异构资源，使研究人员变成手动工作流协调员而非科学家。AI动力组件提供了加速科学发现的新机遇，但需要明确如何在真实世界中实现和集成。

Method: 提出一个概念框架，让工作流沿两个维度进化：智能程度（从静态到智能）和组成方式（从单体到群体），并提出了对应的建筑蓝图。

Result: 记载了从当前工作流管理系统到完全自主分布式科学实验室的进化路径，为社区提供了下一步发展的指导框架。

Conclusion: 该框架有力于利用AI动力组件的机遇，实现自主科学的转型性发展，有望带来100倍的科学发现加速和革命性的工作流变革。

Abstract: Modern scientific discovery increasingly requires coordinating distributed
facilities and heterogeneous resources, forcing researchers to act as manual
workflow coordinators rather than scientists. Advances in AI leading to AI
agents show exciting new opportunities that can accelerate scientific discovery
by providing intelligence as a component in the ecosystem. However, it is
unclear how this new capability would materialize and integrate in the real
world. To address this, we propose a conceptual framework where workflows
evolve along two dimensions which are intelligence (from static to intelligent)
and composition (from single to swarm) to chart an evolutionary path from
current workflow management systems to fully autonomous, distributed scientific
laboratories. With these trajectories in mind, we present an architectural
blueprint that can help the community take the next steps towards harnessing
the opportunities in autonomous science with the potential for 100x discovery
acceleration and transformational scientific workflows.

</details>


### [6] [Towards a Common Framework for Autoformalization](https://arxiv.org/abs/2509.09810)
*Agnieszka Mensfelt,David Tena Cucala,Santiago Franco,Angeliki Koutsoukou-Argyraki,Vince Trencsenyi,Kostas Stathis*

Main category: cs.AI

TL;DR: 这篇论文对自动形式化（autoformalization）领域进行了统一回顾和框架构建，将数学形式化和普通语言到形式表示的转换统一在一个概念下，以促进不同领域间的知识交流和技术进步。


<details>
  <summary>Details</summary>
Motivation: 随着深度学习和大语言模型的发展，自动形式化技术在数学和普通语言到形式表示转换方面都取得了进步，但这些领域的研究发展相对独立，缺乏统一的方法论、测试标准和理论框架，限制了技术的进一步发展。

Method: 论文通过综述明显或隐含的自动形式化实例，对该领域进行系统性回顾和分析，并提出了一个统一的概念框架，以促进不同研究领域之间的知识交流和技术融合。

Result: 论文完成了对自动形式化领域的统一回顾和分类，构建了一个能够涵盖数学形式化和普通语言形式化的概念框架，为不同领域的研究者提供了共同的理论基础和方法论指导。

Conclusion: 通过建立统一的自动形式化框架，可以推动不同研究领域之间的知识交流和技术融合，加速下一代人工智能系统的发展，对于推进自动化理论证明、知识表示和智能推理等方面都具有重要意义。

Abstract: Autoformalization has emerged as a term referring to the automation of
formalization - specifically, the formalization of mathematics using
interactive theorem provers (proof assistants). Its rapid development has been
driven by progress in deep learning, especially large language models (LLMs).
More recently, the term has expanded beyond mathematics to describe the broader
task of translating informal input into formal logical representations. At the
same time, a growing body of research explores using LLMs to translate informal
language into formal representations for reasoning, planning, and knowledge
representation - often without explicitly referring to this process as
autoformalization. As a result, despite addressing similar tasks, the largely
independent development of these research areas has limited opportunities for
shared methodologies, benchmarks, and theoretical frameworks that could
accelerate progress. The goal of this paper is to review - explicit or implicit
- instances of what can be considered autoformalization and to propose a
unified framework, encouraging cross-pollination between different fields to
advance the development of next generation AI systems.

</details>


### [7] [Towards an AI-based knowledge assistant for goat farmers based on Retrieval-Augmented Generation](https://arxiv.org/abs/2509.09848)
*Nana Han,Dong Liu,Tomas Norton*

Main category: cs.AI

TL;DR: 本研究开发了一个基于RAG的智能知识助手系统，用于山羊养殖健康管理，通过表格文本化和决策树文本化两种结构化知识处理方法，提高了LLM对异构数据的理解能力，在验证集和测试集上分别达到87.90%和84.22%的平均准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在畜牧业应用受限，主要受限于知识源的可用性、多样性和复杂性，特别是在山羊养殖健康管理领域缺乏专门的知识支持系统。

Method: 采用检索增强生成(RAG)技术，提出表格文本化和决策树文本化两种结构化知识处理方法，建立覆盖疾病防治、营养管理、饲养管理等五个关键领域的山羊养殖知识库，并集成在线搜索模块实现实时信息检索。

Result: 异构知识融合方法取得最佳效果，验证集平均准确率87.90%，测试集84.22%。在文本、表格、决策树三类问答任务中准确率均超过85%，证明了模块化设计中结构化知识融合的有效性。

Conclusion: 该系统展现了在实际山羊养殖应用中的鲁棒性和可靠性，错误分析显示遗漏是主要错误类型，为进一步提高检索覆盖率和上下文整合提供了改进方向。

Abstract: Large language models (LLMs) are increasingly being recognised as valuable
knowledge communication tools in many industries. However, their application in
livestock farming remains limited, being constrained by several factors not
least the availability, diversity and complexity of knowledge sources. This
study introduces an intelligent knowledge assistant system designed to support
health management in farmed goats. Leveraging the Retrieval-Augmented
Generation (RAG), two structured knowledge processing methods, table
textualization and decision-tree textualization, were proposed to enhance large
language models' (LLMs) understanding of heterogeneous data formats. Based on
these methods, a domain-specific goat farming knowledge base was established to
improve LLM's capacity for cross-scenario generalization. The knowledge base
spans five key domains: Disease Prevention and Treatment, Nutrition Management,
Rearing Management, Goat Milk Management, and Basic Farming Knowledge.
Additionally, an online search module is integrated to enable real-time
retrieval of up-to-date information. To evaluate system performance, six
ablation experiments were conducted to examine the contribution of each
component. The results demonstrated that heterogeneous knowledge fusion method
achieved the best results, with mean accuracies of 87.90% on the validation set
and 84.22% on the test set. Across the text-based, table-based, decision-tree
based Q&A tasks, accuracy consistently exceeded 85%, validating the
effectiveness of structured knowledge fusion within a modular design. Error
analysis identified omission as the predominant error category, highlighting
opportunities to further improve retrieval coverage and context integration. In
conclusion, the results highlight the robustness and reliability of the
proposed system for practical applications in goat farming.

</details>


### [8] [LLMs as Agentic Cooperative Players in Multiplayer UNO](https://arxiv.org/abs/2509.09867)
*Yago Romano Matinez,Jesse Roberts*

Main category: cs.AI

TL;DR: LLM在UNO游戏中作为助手参与，测试其是否能有效帮助其他玩家获胜，而非自己获胜。研究发现虽然LLM能超越随机基线，但很少能显著帮助其他玩家。


<details>
  <summary>Details</summary>
Motivation: 测试LLM作为主动参与者是否能真正帮助人类完成目标，特别是在协作性任务中。

Method: 构建工具让decoder-only LLM在RLCard游戏环境中作为智能体参与UNO游戏，接收完整游戏状态信息，使用两种不同的提示策略，评估从1B到70B参数的不同规模模型。

Result: 所有模型在玩UNO时都能成功超越随机基线，但很少有模型能够显著帮助其他玩家获胜。

Conclusion: LLM在协作性任务中的帮助能力有限，模型规模对性能有影响但不足以实现有效的玩家协助。

Abstract: LLMs promise to assist humans -- not just by answering questions, but by
offering useful guidance across a wide range of tasks. But how far does that
assistance go? Can a large language model based agent actually help someone
accomplish their goal as an active participant? We test this question by
engaging an LLM in UNO, a turn-based card game, asking it not to win but
instead help another player to do so. We built a tool that allows decoder-only
LLMs to participate as agents within the RLCard game environment. These models
receive full game-state information and respond using simple text prompts under
two distinct prompting strategies. We evaluate models ranging from small (1B
parameters) to large (70B parameters) and explore how model scale impacts
performance. We find that while all models were able to successfully outperform
a random baseline when playing UNO, few were able to significantly aid another
player.

</details>


### [9] [A Markovian Framing of WaveFunctionCollapse for Procedurally Generating Aesthetically Complex Environments](https://arxiv.org/abs/2509.09919)
*Franklin Yiu,Mohan Lu,Nina Li,Kevin Joseph,Tianxu Zhang,Julian Togelius,Timothy Merino,Sam Earle*

Main category: cs.AI

TL;DR: 将WaveFunctionCollapse重构为马尔可夫决策过程，分离局部约束满足和全局目标优化，相比传统联合优化方法在复杂任务中表现更优


<details>
  <summary>Details</summary>
Motivation: 解决程序化内容生成中需要同时满足设计者指定目标和瓦片集隐含邻接约束的挑战

Method: 将WaveFunctionCollapse重新表述为马尔可夫决策过程(MDP)，利用WFC的传播机制强制执行约束满足，让外部优化算法专注于目标最大化

Result: 在多个不同难度的领域中，联合优化方法随着任务复杂性增加而表现不佳，始终不如在WFC-MDP上进行优化的方法

Conclusion: 将局部约束满足与全局目标优化解耦具有明显优势，WFC-MDP方法在复杂内容生成任务中表现更优

Abstract: Procedural content generation often requires satisfying both
designer-specified objectives and adjacency constraints implicitly imposed by
the underlying tile set. To address the challenges of jointly optimizing both
constraints and objectives, we reformulate WaveFunctionCollapse (WFC) as a
Markov Decision Process (MDP), enabling external optimization algorithms to
focus exclusively on objective maximization while leveraging WFC's propagation
mechanism to enforce constraint satisfaction. We empirically compare optimizing
this MDP to traditional evolutionary approaches that jointly optimize global
metrics and local tile placement. Across multiple domains with various
difficulties, we find that joint optimization not only struggles as task
complexity increases, but consistently underperforms relative to optimization
over the WFC-MDP, underscoring the advantages of decoupling local constraint
satisfaction from global objective optimization.

</details>


### [10] [Evaluation of Black-Box XAI Approaches for Predictors of Values of Boolean Formulae](https://arxiv.org/abs/2509.09982)
*Stav Armoni-Friedmann,Hana Chockler,David A. Kelly*

Main category: cs.AI

TL;DR: 本文提出基于实际因果关系的变量重要性度量方法，并开发了新的XAI工具B-ReX，在布尔函数预测任务中优于现有黑盒XAI工具


<details>
  <summary>Details</summary>
Motivation: 由于解释的主观性，评估可解释AI(XAI)方法具有挑战性。本文专注于表格数据和布尔函数预测这一特定用例，旨在提供更精确的评估方法

Method: 提出基于实际因果关系的正式变量重要性度量方法，并开发了新的XAI工具B-ReX（基于现有ReX工具的改进）

Result: 在大规模基准测试中，B-ReX表现出色，在随机10值布尔公式上实现了0.072±0.012的Jensen-Shannon散度，优于其他黑盒XAI工具

Conclusion: 基于实际因果关系的度量方法为XAI评估提供了更精确的标准，B-ReX工具在布尔函数预测任务中具有优越性能，为表格数据的XAI研究提供了新的方向

Abstract: Evaluating explainable AI (XAI) approaches is a challenging task in general,
due to the subjectivity of explanations. In this paper, we focus on tabular
data and the specific use case of AI models predicting the values of Boolean
functions. We extend the previous work in this domain by proposing a formal and
precise measure of importance of variables based on actual causality, and we
evaluate state-of-the-art XAI tools against this measure. We also present a
novel XAI tool B-ReX, based on the existing tool ReX, and demonstrate that it
is superior to other black-box XAI tools on a large-scale benchmark.
Specifically, B-ReX achieves a Jensen-Shannon divergence of 0.072 $\pm$ 0.012
on random 10-valued Boolean formulae

</details>


### [11] [GAMA: A General Anonymizing Multi-Agent System for Privacy Preservation Enhanced by Domain Rules and Disproof Method](https://arxiv.org/abs/2509.10018)
*Hailong Yang,Renhuo Zhao,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: GAMA是一个保护隐私的多智能体系统，通过将工作空间划分为私有和公共区域，使用匿名化机制保护敏感数据，同时通过知识增强和逻辑增强模块减少语义损失。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在多智能体系统中的广泛应用，当任务涉及隐私数据时，需要在不牺牲性能的前提下保护数据隐私，但现有系统缺乏有效的隐私保护机制。

Method: 提出GAMA系统，划分私有和公共空间，在私有空间处理敏感数据，公共空间只使用匿名化数据。采用DRKE（基于领域规则的知识增强）和DLE（基于反证的逻辑增强）来减少匿名化带来的语义损失。

Result: 在两个公开问答数据集（Trivia Creative Writing和Logic Grid Puzzle）上表现优于最先进模型。在专门设计的隐私保护数据集（Knowledge Privacy Preservation和Logic Privacy Preservation）上也显示出卓越的隐私保护效果。

Conclusion: GAMA系统在保持任务处理性能的同时，有效实现了隐私保护，为大语言模型在多智能体系统中的隐私安全应用提供了可行解决方案。

Abstract: With the rapid advancement of Large Language Model (LLM), LLM-based agents
exhibit exceptional abilities in understanding and generating natural language,
facilitating human-like collaboration and information transmission in LLM-based
Multi-Agent System (MAS). High-performance LLMs are often hosted on remote
servers in public spaces. When tasks involve privacy data, MAS cannot securely
utilize these LLMs without implementing privacy-preserving mechanisms. To
address this challenge, we propose a General Anonymizing Multi-Agent system
(GAMA), which divides the agents' workspace into private and public spaces and
protects privacy through the anonymizing mechanism. In the private space,
agents handle sensitive data, while in the public space, only anonymized data
is utilized. GAMA incorporates two key modules to mitigate semantic loss caused
by anonymization: Domain-Rule-based Knowledge Enhancement (DRKE) and
Disproof-based Logic Enhancement (DLE). We evaluate GAMA on two public
question-answering datasets: Trivia Creative Writing and Logic Grid Puzzle. The
results demonstrate that GAMA has superior performance compared to the
state-of-the-art models. To further assess its privacy-preserving capabilities,
we designed two new datasets: Knowledge Privacy Preservation and Logic Privacy
Preservation. The final results highlight GAMA's exceptional effectiveness in
both task processing and privacy preservation.

</details>


### [12] [XAgents: A Unified Framework for Multi-Agent Cooperation via IF-THEN Rules and Multipolar Task Processing Graph](https://arxiv.org/abs/2509.10054)
*Hailong Yang,Mingxian Gu,Jianqi Wang,Guanjin Wang,Zhaohong Deng*

Main category: cs.AI

TL;DR: XAgents是一个基于多极任务处理图和IF-THEN规则的多智能体协作框架，旨在解决复杂任务规划中的不确定性挑战，在知识型和逻辑型问答任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型提升了多智能体系统的能力，但在处理高度复杂和不确定的任务时，仍然存在任务规划效果不佳、产生误导性输出等问题，需要新的解决方案。

Method: 提出XAgents框架，使用多极任务处理图实现动态任务规划和处理任务不确定性，结合领域特定的IF-THEN规则约束智能体行为，并通过全局规则增强智能体间协作。

Result: 在三个不同数据集上的评估表明，XAgents在知识型和逻辑型问答任务中 consistently 超越最先进的单智能体和多智能体方法。

Conclusion: XAgents通过创新的多极任务处理图和规则集成机制，有效解决了复杂任务规划中的不确定性挑战，为多智能体系统提供了更可靠的任务执行能力。

Abstract: The rapid advancement of Large Language Models (LLMs) has significantly
enhanced the capabilities of Multi-Agent Systems (MAS) in supporting humans
with complex, real-world tasks. However, MAS still face challenges in effective
task planning when handling highly complex tasks with uncertainty, often
resulting in misleading or incorrect outputs that hinder task execution. To
address this, we propose XAgents, a unified multi-agent cooperative framework
built on a multipolar task processing graph and IF-THEN rules. XAgents uses the
multipolar task processing graph to enable dynamic task planning and handle
task uncertainty. During subtask processing, it integrates domain-specific
IF-THEN rules to constrain agent behaviors, while global rules enhance
inter-agent collaboration. We evaluate the performance of XAgents across three
distinct datasets, demonstrating that it consistently surpasses
state-of-the-art single-agent and multi-agent approaches in both
knowledge-typed and logic-typed question-answering tasks. The codes for XAgents
are available at: https://github.com/AGI-FHBC/XAgents.

</details>


### [13] [AI Harmonics: a human-centric and harms severity-adaptive AI risk assessment framework](https://arxiv.org/abs/2509.10104)
*Sofia Vei,Paolo Giudici,Pavlos Sermpezis,Athena Vakali,Adelaide Emma Bernardelli*

Main category: cs.AI

TL;DR: 提出了AI Harmonics框架，使用基于事件数据的AI危害评估指标(AIH)，通过序数严重性数据捕捉相对影响，无需精确数值估计，能够有效识别和优先处理AI危害。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估模型主要关注内部合规性，忽视了不同利益相关者视角和现实世界后果，无法有效应对AI带来的前所未有的社会危害和风险。

Method: 提出了AI Harmonics框架，包括新颖的AI危害评估指标(AIH)，利用序数严重性数据来捕捉相对影响，结合稳健的通用方法和数据驱动、利益相关者感知的框架。

Result: 在标注事件数据上的实验证实，政治和物理危害表现出最高的集中度，需要紧急缓解：政治危害侵蚀公众信任，物理危害构成严重甚至危及生命的风险。

Conclusion: AI Harmonics能够一致地识别不均匀的危害分布，使政策制定者和组织能够有效地针对其缓解工作，强调了该方法在现实世界中的相关性。

Abstract: The absolute dominance of Artificial Intelligence (AI) introduces
unprecedented societal harms and risks. Existing AI risk assessment models
focus on internal compliance, often neglecting diverse stakeholder perspectives
and real-world consequences. We propose a paradigm shift to a human-centric,
harm-severity adaptive approach grounded in empirical incident data. We present
AI Harmonics, which includes a novel AI harm assessment metric (AIH) that
leverages ordinal severity data to capture relative impact without requiring
precise numerical estimates. AI Harmonics combines a robust, generalized
methodology with a data-driven, stakeholder-aware framework for exploring and
prioritizing AI harms. Experiments on annotated incident data confirm that
political and physical harms exhibit the highest concentration and thus warrant
urgent mitigation: political harms erode public trust, while physical harms
pose serious, even life-threatening risks, underscoring the real-world
relevance of our approach. Finally, we demonstrate that AI Harmonics
consistently identifies uneven harm distributions, enabling policymakers and
organizations to target their mitigation efforts effectively.

</details>


### [14] [Virtual Agent Economies](https://arxiv.org/abs/2509.10147)
*Nenad Tomasev,Matija Franklin,Joel Z. Leibo,Julian Jacobs,William A. Cunningham,Iason Gabriel,Simon Osindero*

Main category: cs.AI

TL;DR: 本文提出"沙箱经济"框架用于分析自主AI代理经济体系，讨论了其机遇与挑战，并提出主动设计可调控市场的解决方案。


<details>
  <summary>Details</summary>
Motivation: 自主AI代理的快速采用形成了新的经济层，代理在超出人类监管范围的规模和速度上进行交易和协调，需要框架来分析和应对这种新兴系统。

Method: 提出"沙箱经济"框架，从起源（自发出现vs意图性）和与人类经济的分离程度（可穿透vs不可穿透）两个维度进行分析，考虑竞价机制、AI"任务经济"设计和社会技术基础设施。

Result: 分析显示当前趋势指向一个自发出现的广泛且高度可穿透的AI代理经济，带来无前未有的协调机遇，但也带来系统性经济风险和加剧的不平等挑战。

Conclusion: 建议主动设计可调控的代理市场，通过竞价机制、任务经济和基础设施确保信任、安全和责任制，以便这次技术变革能够与人类长期集体繁荣相对齐。

Abstract: The rapid adoption of autonomous AI agents is giving rise to a new economic
layer where agents transact and coordinate at scales and speeds beyond direct
human oversight. We propose the "sandbox economy" as a framework for analyzing
this emergent system, characterizing it along two key dimensions: its origins
(emergent vs. intentional) and its degree of separateness from the established
human economy (permeable vs. impermeable). Our current trajectory points toward
a spontaneous emergence of a vast and highly permeable AI agent economy,
presenting us with opportunities for an unprecedented degree of coordination as
well as significant challenges, including systemic economic risk and
exacerbated inequality. Here we discuss a number of possible design choices
that may lead to safely steerable AI agent markets. In particular, we consider
auction mechanisms for fair resource allocation and preference resolution, the
design of AI "mission economies" to coordinate around achieving collective
goals, and socio-technical infrastructure needed to ensure trust, safety, and
accountability. By doing this, we argue for the proactive design of steerable
agent markets to ensure the coming technological shift aligns with humanity's
long-term collective flourishing.

</details>


### [15] [Online Robust Planning under Model Uncertainty: A Sample-Based Approach](https://arxiv.org/abs/2509.10162)
*Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman*

Main category: cs.AI

TL;DR: 提出了Robust Sparse Sampling (RSS)算法，这是第一个具有有限样本理论性能保证的在线鲁棒MDP规划算法，能够在模型不确定性环境下实现可处理的鲁棒策略计算。


<details>
  <summary>Details</summary>
Motivation: 在线规划方法在实际应用中，生成模型往往从有限数据中学习，存在近似误差，可能导致性能下降或不安全行为。现有鲁棒MDP方法计算量大，不适合实时应用。

Method: 基于Sample Average Approximation (SAA)的高效性和理论特性，通过计算鲁棒价值函数而非名义价值函数，开发了Robust Sparse Sampling算法。

Result: RSS适用于无限或连续状态空间，其样本和计算复杂度与状态空间大小无关。理论性能保证显示，在动态不确定环境中优于标准稀疏采样方法。

Conclusion: RSS是第一个具有理论保证的在线鲁棒MDP规划算法，为模型不确定性环境下的实时决策提供了有效解决方案。

Abstract: Online planning in Markov Decision Processes (MDPs) enables agents to make
sequential decisions by simulating future trajectories from the current state,
making it well-suited for large-scale or dynamic environments. Sample-based
methods such as Sparse Sampling and Monte Carlo Tree Search (MCTS) are widely
adopted for their ability to approximate optimal actions using a generative
model. However, in practical settings, the generative model is often learned
from limited data, introducing approximation errors that can degrade
performance or lead to unsafe behaviors. To address these challenges, Robust
MDPs (RMDPs) offer a principled framework for planning under model uncertainty,
yet existing approaches are typically computationally intensive and not suited
for real-time use. In this work, we introduce Robust Sparse Sampling (RSS), the
first online planning algorithm for RMDPs with finite-sample theoretical
performance guarantees. Unlike Sparse Sampling, which estimates the nominal
value function, RSS computes a robust value function by leveraging the
efficiency and theoretical properties of Sample Average Approximation (SAA),
enabling tractable robust policy computation in online settings. RSS is
applicable to infinite or continuous state spaces, and its sample and
computational complexities are independent of the state space size. We provide
theoretical performance guarantees and empirically show that RSS outperforms
standard Sparse Sampling in environments with uncertain dynamics.

</details>


### [16] [Towards Fully Automated Molecular Simulations: Multi-Agent Framework for Simulation Setup and Force Field Extraction](https://arxiv.org/abs/2509.10210)
*Marko Petković,Vlado Menkovski,Sofía Calero*

Main category: cs.AI

TL;DR: 提出基于LLM的多智能体框架，用于自动化多孔材料表征，包括理解任务、规划模拟、组装力场、执行模拟和解释结果，初步评估显示高正确性和可重现性。


<details>
  <summary>Details</summary>
Motivation: 自动化多孔材料表征能加速材料发现，但目前受限于模拟设置和力场选择的复杂性，需要开发更智能的自动化解决方案。

Method: 采用基于大语言模型的多智能体框架，能够自主理解表征任务、规划适当模拟、组装相关力场、执行模拟并解释结果以指导后续步骤。

Result: 初步评估表明该方法具有高正确性和可重现性，验证了框架的有效性和可靠性。

Conclusion: 该方法为实现完全自主、可扩展的材料表征提供了有前景的途径，展示了多智能体系统在材料科学自动化中的潜力。

Abstract: Automated characterization of porous materials has the potential to
accelerate materials discovery, but it remains limited by the complexity of
simulation setup and force field selection. We propose a multi-agent framework
in which LLM-based agents can autonomously understand a characterization task,
plan appropriate simulations, assemble relevant force fields, execute them and
interpret their results to guide subsequent steps. As a first step toward this
vision, we present a multi-agent system for literature-informed force field
extraction and automated RASPA simulation setup. Initial evaluations
demonstrate high correctness and reproducibility, highlighting this approach's
potential to enable fully autonomous, scalable materials characterization.

</details>


### [17] [Compartmentalised Agentic Reasoning for Clinical NLI](https://arxiv.org/abs/2509.10222)
*Maël Jullien,Lei Xu,Marco Valentino,André Freitas*

Main category: cs.AI

TL;DR: CARENLI是一个用于临床自然语言推理的模块化代理推理框架，通过将知识访问与原则推理分离，显著提高了推理准确性和可审计性。


<details>
  <summary>Details</summary>
Motivation: 传统假设认为扩大数据和参数规模会提高内部表示的结构化和泛化能力，但本文质疑这一假设在临床NLI任务中的有效性，特别是在推理过程不明确时LLMs倾向于使用启发式方法。

Method: 提出CARENLI框架，将临床NLI分解为四个推理家族（因果归因、组合基础、认知验证、风险状态抽象），使用特定家族求解器，并通过规划器、验证器和精炼器强制执行可审计程序。

Result: 在四个LLMs上，CARENLI将保真度提高了最多42个百分点，在因果归因达到98.0%，在风险状态抽象达到81.2%。验证器能够近乎完美地标记违规，精炼器纠正了大量认知错误。

Conclusion: LLMs通常保留相关事实但在推理不明确时默认使用启发式方法，CARENLI通过显式分离知识访问和推理过程，为更安全、可审计的推理提供了框架，路由和家族分类是主要瓶颈。

Abstract: A common assumption holds that scaling data and parameters yields
increasingly structured, generalisable internal representations. We interrogate
this assumption in clinical natural language inference (NLI) by adopting a
benchmark decomposed into four reasoning families, Causal Attribution,
Compositional Grounding, Epistemic Verification, and Risk State Abstraction,
and introducing CARENLI, a Compartmentalised Agentic Reasoning for Clinical NLI
that separates knowledge access from principled inference. CARENLI routes each
premise, statement pair to a family specific solver and enforces auditable
procedures via a planner, verifier, and refiner.
  Across four LLMs, CARENLI improves fidelity by up to 42 points, reaching
98.0% in Causal Attribution and 81.2% in Risk State Abstraction. Verifiers flag
violations with near-ceiling reliability, while refiners correct a substantial
share of epistemic errors. Remaining failures cluster in routing, identifying
family classification as the main bottleneck. These results show that LLMs
often retain relevant facts but default to heuristics when inference is
underspecified, a dissociation CARENLI makes explicit while offering a
framework for safer, auditable reasoning.

</details>


### [18] [Investigating Language Model Capabilities to Represent and Process Formal Knowledge: A Preliminary Study to Assist Ontology Engineering](https://arxiv.org/abs/2509.10249)
*Hanna Abi Akl*

Main category: cs.AI

TL;DR: 小型语言模型在逻辑推理任务中使用简洁的形式语言替代自然语言，仍能保持良好性能，为本体工程领域提供新方向


<details>
  <summary>Details</summary>
Motivation: 语言模型在推理能力方面的局限性影响了本体工程等任务的表现，需要研究如何通过形式方法提升小型语言模型的推理能力

Method: 设计一系列预实验，测试不同语法表达逻辑问题对小型语言模型在推理任务上性能的影响

Result: 发现可以用更简洁的逻辑语言替代自然语言，同时保持强劲的推理任务性能

Conclusion: 这些结果为精炼小型语言模型在本体工程中的作用提供了基础，展示了形式方法在提升语言模型推理能力方面的潜力

Abstract: Recent advances in Language Models (LMs) have failed to mask their
shortcomings particularly in the domain of reasoning. This limitation impacts
several tasks, most notably those involving ontology engineering. As part of a
PhD research, we investigate the consequences of incorporating formal methods
on the performance of Small Language Models (SLMs) on reasoning tasks.
Specifically, we aim to orient our work toward using SLMs to bootstrap ontology
construction and set up a series of preliminary experiments to determine the
impact of expressing logical problems with different grammars on the
performance of SLMs on a predefined reasoning task. Our findings show that it
is possible to substitute Natural Language (NL) with a more compact logical
language while maintaining a strong performance on reasoning tasks and hope to
use these results to further refine the role of SLMs in ontology engineering.

</details>


### [19] [The Morality of Probability: How Implicit Moral Biases in LLMs May Shape the Future of Human-AI Symbiosis](https://arxiv.org/abs/2509.10297)
*Eoin O'Doherty,Nicole Weinrauch,Andrew Talone,Uri Klempner,Xiaoyuan Yi,Xing Xie,Yi Zeng*

Main category: cs.AI

TL;DR: 本文通过量化实验研究大型语言模型在道德困境中的价值偏好，发现所有模型都一致偏好关怀和美德价值观，而惩罚自由主义选择。推理模型对情境更敏感，非推理模型判断更一致但不透明。


<details>
  <summary>Details</summary>
Motivation: 随着AI快速发展，需要解决机器决策与人类道德价值观对齐的紧迫问题，探索AI系统如何优先考虑道德结果以及人类-AI共生的前景。

Method: 对6个大型语言模型进行量化实验，在代表5种道德框架的18个困境中对结果进行排名和评分。

Result: 发现所有模型都存在显著一致的价值偏见：关怀和美德价值观被评为最道德，自由主义选择被一致惩罚。推理模型对情境更敏感并提供更丰富的解释，非推理模型产生更一致但不透明的判断。

Conclusion: 研究强调了可解释性和文化意识作为关键设计原则的重要性，以指导AI走向透明、对齐和共生的未来。

Abstract: Artificial intelligence (AI) is advancing at a pace that raises urgent
questions about how to align machine decision-making with human moral values.
This working paper investigates how leading AI systems prioritize moral
outcomes and what this reveals about the prospects for human-AI symbiosis. We
address two central questions: (1) What moral values do state-of-the-art large
language models (LLMs) implicitly favour when confronted with dilemmas? (2) How
do differences in model architecture, cultural origin, and explainability
affect these moral preferences? To explore these questions, we conduct a
quantitative experiment with six LLMs, ranking and scoring outcomes across 18
dilemmas representing five moral frameworks. Our findings uncover strikingly
consistent value biases. Across all models, Care and Virtue values outcomes
were rated most moral, while libertarian choices were consistently penalized.
Reasoning-enabled models exhibited greater sensitivity to context and provided
richer explanations, whereas non-reasoning models produced more uniform but
opaque judgments. This research makes three contributions: (i) Empirically, it
delivers a large-scale comparison of moral reasoning across culturally distinct
LLMs; (ii) Theoretically, it links probabilistic model behaviour with
underlying value encodings; (iii) Practically, it highlights the need for
explainability and cultural awareness as critical design principles to guide AI
toward a transparent, aligned, and symbiotic future.

</details>


### [20] [State Algebra for Propositional Logic](https://arxiv.org/abs/2509.10326)
*Dmitry Lesnik,Tobias Schäfer*

Main category: cs.AI

TL;DR: State Algebra是一个使用代数方法表示和操作命题逻辑的新框架，包含集合、坐标和行分解三种层次化表示，在保持语义清晰的同时提供计算灵活性。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一表示命题逻辑并支持高效代数计算的框架，为搜索算法和知识编译提供基础工具，并扩展到概率逻辑和加权模型计数领域。

Method: 构建三层表示层次（Set、Coordinate、Row Decomposition），通过代数引擎进行计算，采用固定变量顺序获得规范形式，在规范性和灵活性之间取得平衡。

Result: 框架虽然默认状态向量约简不是规范的，但通过固定变量顺序可以获得唯一规范形式，这种灵活性使得某些问题类能够获得更紧凑的表示。

Conclusion: State Algebra为命题逻辑提供了强大的代数表示和操作框架，具有良好的扩展性，能够支持多种算法并自然扩展到概率逻辑领域。

Abstract: This paper presents State Algebra, a novel framework designed to represent
and manipulate propositional logic using algebraic methods. The framework is
structured as a hierarchy of three representations: Set, Coordinate, and Row
Decomposition. These representations anchor the system in well-known semantics
while facilitating the computation using a powerful algebraic engine. A key
aspect of State Algebra is its flexibility in representation. We show that
although the default reduction of a state vector is not canonical, a unique
canonical form can be obtained by applying a fixed variable order during the
reduction process. This highlights a trade-off: by foregoing guaranteed
canonicity, the framework gains increased flexibility, potentially leading to
more compact representations of certain classes of problems. We explore how
this framework provides tools to articulate both search-based and knowledge
compilation algorithms and discuss its natural extension to probabilistic logic
and Weighted Model Counting.

</details>


### [21] [Abduct, Act, Predict: Scaffolding Causal Inference for Automated Failure Attribution in Multi-Agent Systems](https://arxiv.org/abs/2509.10401)
*Alva West,Yixuan Weng,Minjun Zhu,Zhen Lin,Yue Zhang*

Main category: cs.AI

TL;DR: A2P Scaffolding框架通过结构化因果推理方法，将多智能体系统中的故障归因从模式识别任务转变为因果推理任务，显著提高了步骤级准确率


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统故障归因方法存在步骤级准确率低（低于17%）的问题，主要原因是缺乏鲁棒的反事实推理能力，无法确定纠正单个动作是否能真正避免任务失败

Method: 提出Abduct-Act-Predict (A2P) Scaffolding框架，通过三步推理过程：1)溯因推理推断行动背后的隐藏原因；2)定义最小纠正干预；3)模拟后续轨迹验证干预是否解决故障

Result: 在Algorithm-Generated数据集上达到47.46%的步骤级准确率（比基线16.67%提高2.85倍），在Hand-Crafted数据集上达到29.31%准确率（比基线12.07%提高2.43倍）

Conclusion: 通过因果推理视角重构问题，A2P Scaffolding为自动化故障归因提供了鲁棒、可验证且显著更准确的解决方案

Abstract: Failure attribution in multi-agent systems -- pinpointing the exact step
where a decisive error occurs -- is a critical yet unsolved challenge. Current
methods treat this as a pattern recognition task over long conversation logs,
leading to critically low step-level accuracy (below 17\%), which renders them
impractical for debugging complex systems. Their core weakness is a fundamental
inability to perform robust counterfactual reasoning: to determine if
correcting a single action would have actually averted the task failure. To
bridge this counterfactual inference gap, we introduce Abduct-Act-Predict (A2P)
Scaffolding, a novel agent framework that transforms failure attribution from
pattern recognition into a structured causal inference task. A2P explicitly
guides a large language model through a formal three-step reasoning process
within a single inference pass: (1) Abduction, to infer the hidden root causes
behind an agent's actions; (2) Action, to define a minimal corrective
intervention; and (3) Prediction, to simulate the subsequent trajectory and
verify if the intervention resolves the failure. This structured approach
leverages the holistic context of the entire conversation while imposing a
rigorous causal logic on the model's analysis. Our extensive experiments on the
Who\&When benchmark demonstrate its efficacy. On the Algorithm-Generated
dataset, A2P achieves 47.46\% step-level accuracy, a 2.85$\times$ improvement
over the 16.67\% of the baseline. On the more complex Hand-Crafted dataset, it
achieves 29.31\% step accuracy, a 2.43$\times$ improvement over the baseline's
12.07\%. By reframing the problem through a causal lens, A2P Scaffolding
provides a robust, verifiable, and significantly more accurate solution for
automated failure attribution.

</details>


### [22] [Mutual Information Tracks Policy Coherence in Reinforcement Learning](https://arxiv.org/abs/2509.10423)
*Cameron Reid,Wael Hafez,Amirhossein Nazeri*

Main category: cs.AI

TL;DR: 该论文提出了一个信息理论框架，通过分析状态-动作互信息模式来诊断RL代理在部署时的异常故障，能够区分传感器故障和制动器故障。


<details>
  <summary>Details</summary>
Motivation: RL代理在真实世界部署中面临传感器故障、制动器磨损和环境变化等问题，但缺乏内在机制来检测和诊断这些故障。

Method: 使用信息理论框架分析状态-动作互信息模式，通过控制扰动实验验证故障诊断能力。

Result: 成功学习表现出特征性信息签名：状态-动作互信息从0.84增长到2.83比特（238%增长）；信息指标能够区分系统故障类型：状态噪声导致所有信息通道崩溃，而动作噪声选择性破坏动作-结果可预测性。

Conclusion: 信息模式既是学习的签名，也是系统健康的诊断工具，为能够基于信息理论原则进行自主故障检测和政策调整的自适应RL系统奠定了基础。

Abstract: Reinforcement Learning (RL) agents deployed in real-world environments face
degradation from sensor faults, actuator wear, and environmental shifts, yet
lack intrinsic mechanisms to detect and diagnose these failures. We present an
information-theoretic framework that reveals both the fundamental dynamics of
RL and provides practical methods for diagnosing deployment-time anomalies.
Through analysis of state-action mutual information patterns in a robotic
control task, we first demonstrate that successful learning exhibits
characteristic information signatures: mutual information between states and
actions steadily increases from 0.84 to 2.83 bits (238% growth) despite growing
state entropy, indicating that agents develop increasingly selective attention
to task-relevant patterns. Intriguingly, states, actions and next states joint
mutual information, MI(S,A;S'), follows an inverted U-curve, peaking during
early learning before declining as the agent specializes suggesting a
transition from broad exploration to efficient exploitation. More immediately
actionable, we show that information metrics can differentially diagnose system
failures: observation-space, i.e., states noise (sensor faults) produces broad
collapses across all information channels with pronounced drops in state-action
coupling, while action-space noise (actuator faults) selectively disrupts
action-outcome predictability while preserving state-action relationships. This
differential diagnostic capability demonstrated through controlled perturbation
experiments enables precise fault localization without architectural
modifications or performance degradation. By establishing information patterns
as both signatures of learning and diagnostic for system health, we provide the
foundation for adaptive RL systems capable of autonomous fault detection and
policy adjustment based on information-theoretic principles.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [23] [Structured Information Matters: Explainable ICD Coding with Patient-Level Knowledge Graphs](https://arxiv.org/abs/2509.09699)
*Mingyang Li,Viktor Schlegel,Tingting Mu,Warren Del-Pinto,Goran Nenadic*

Main category: cs.CL

TL;DR: 本文提出使用知识图谱结构化表示临床文档，用于自动化ICD编码任务，在保持90%信息的同时减少23%文本量，将知识图谱集成到PLM-ICD架构中，在基准测试中Macro-F1得分提升达3.20%，同时提高了训练效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 临床文档到标准化临床词汇的映射是重要但耗时的任务，现有方法主要关注输出代码表示的外部知识利用，而对输入文档表示的外部资源利用不足。

Method: 计算输入文档的结构化表示，利用文档级知识图谱提供患者状况的全面结构化视图，将知识图谱集成到最先进的ICD编码架构PLM-ICD中。

Result: 知识图谱用23%的原始文本有效表示患者中心文档，保留90%信息。在ICD-9编码任务中，Macro-F1得分提升达3.20%，训练效率提高，可解释性增强。

Conclusion: 知识图谱结构化表示能有效提升自动化临床编码性能，通过不同类型的实体和关系提供更好的可解释性，证明了在输入文档表示中使用外部知识资源的重要性。

Abstract: Mapping clinical documents to standardised clinical vocabularies is an
important task, as it provides structured data for information retrieval and
analysis, which is essential to clinical research, hospital administration and
improving patient care. However, manual coding is both difficult and
time-consuming, making it impractical at scale. Automated coding can
potentially alleviate this burden, improving the availability and accuracy of
structured clinical data. The task is difficult to automate, as it requires
mapping to high-dimensional and long-tailed target spaces, such as the
International Classification of Diseases (ICD). While external knowledge
sources have been readily utilised to enhance output code representation, the
use of external resources for representing the input documents has been
underexplored. In this work, we compute a structured representation of the
input documents, making use of document-level knowledge graphs (KGs) that
provide a comprehensive structured view of a patient's condition. The resulting
knowledge graph efficiently represents the patient-centred input documents with
23\% of the original text while retaining 90\% of the information. We assess
the effectiveness of this graph for automated ICD-9 coding by integrating it
into the state-of-the-art ICD coding architecture PLM-ICD. Our experiments
yield improved Macro-F1 scores by up to 3.20\% on popular benchmarks, while
improving training efficiency. We attribute this improvement to different types
of entities and relationships in the KG, and demonstrate the improved
explainability potential of the approach over the text-only baseline.

</details>


### [24] [Cross-Layer Attention Probing for Fine-Grained Hallucination Detection](https://arxiv.org/abs/2509.09700)
*Malavika Suresh,Rahaf Aljundi,Ikechukwu Nkisi-Orji,Nirmalie Wiratunga*

Main category: cs.CL

TL;DR: 提出CLAP方法，通过跨层注意力探测技术检测LLM幻觉，在多个模型和任务上优于基线方法，支持细粒度检测和检测后缓解策略


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型广泛应用，其生成不准确文本（幻觉）的可靠性问题日益突出，需要有效的检测方法

Method: Cross-Layer Attention Probing (CLAP) - 一种新颖的激活探测技术，将整个残差流中的LLM激活作为联合序列处理

Result: 在5个LLM和3个任务上的实验表明，CLAP在幻觉检测方面优于基线方法，支持贪婪解码和高温度采样响应，且具有分布外可靠性

Conclusion: CLAP能够实现细粒度幻觉检测，并提出检测后缓解策略，相比直接缓解方法能更好地减少幻觉并提高LLM可靠性

Abstract: With the large-scale adoption of Large Language Models (LLMs) in various
applications, there is a growing reliability concern due to their tendency to
generate inaccurate text, i.e. hallucinations. In this work, we propose
Cross-Layer Attention Probing (CLAP), a novel activation probing technique for
hallucination detection, which processes the LLM activations across the entire
residual stream as a joint sequence. Our empirical evaluations using five LLMs
and three tasks show that CLAP improves hallucination detection compared to
baselines on both greedy decoded responses as well as responses sampled at
higher temperatures, thus enabling fine-grained detection, i.e. the ability to
disambiguate hallucinations and non-hallucinations among different sampled
responses to a given prompt. This allows us to propose a detect-then-mitigate
strategy using CLAP to reduce hallucinations and improve LLM reliability
compared to direct mitigation approaches. Finally, we show that CLAP maintains
high reliability even when applied out-of-distribution.

</details>


### [25] [Optimal Multi-Task Learning at Regularization Horizon for Speech Translation Task](https://arxiv.org/abs/2509.09701)
*JungHo Jung,Junhyun Lee*

Main category: cs.CL

TL;DR: 通过一致性正则化（不同模态）、R-drop（相同模态）和机器翻译损失系数的三重正则化来解决语音到文本翻译中语料稀缺问题，提出了正则化地平线概念并在MuST-C数据集上达到接近SOTA的性能。


<details>
  <summary>Details</summary>
Motivation: 结合机器翻译任务的双语语料进行多任务学习，以充分利用相对丰富的文本语料来解决语音到文本翻译中语料稀缺的问题。

Method: 从正则化角度重新形式化多任务学习，探索模态内和模态间的序列正则化方法，包括一致性正则化（不同模态）、R-drop（相同模态）和机器翻译损失系数的调节。提出了高维空间中的正则化地平线概念。

Result: 在MuST-C数据集上通过调整超参数在正则化地平线范围内实现了接近最新水平的性能表现。

Conclusion: 通过系统性地结合三种正则化来源，可以有效提升多任务学习在语音到文本翻译任务中的效果，正则化地平线概念为超参数调整提供了理论指导。

Abstract: End-to-end speech-to-text translation typically suffers from the scarcity of
paired speech-text data. One way to overcome this shortcoming is to utilize the
bitext data from the Machine Translation (MT) task and perform Multi-Task
Learning (MTL). In this paper, we formulate MTL from a regularization
perspective and explore how sequences can be regularized within and across
modalities. By thoroughly investigating the effect of consistency
regularization (different modality) and R-drop (same modality), we show how
they respectively contribute to the total regularization. We also demonstrate
that the coefficient of MT loss serves as another source of regularization in
the MTL setting. With these three sources of regularization, we introduce the
optimal regularization contour in the high-dimensional space, called the
regularization horizon. Experiments show that tuning the hyperparameters within
the regularization horizon achieves near state-of-the-art performance on the
MuST-C dataset.

</details>


### [26] [Creativity Benchmark: A benchmark for marketing creativity for LLM models](https://arxiv.org/abs/2509.09702)
*Ninad Bhat,Kieran Browne,Pip Bingemann*

Main category: cs.CL

TL;DR: Creativity Benchmark是一个评估LLM在营销创意领域的框架，通过人类创意专家对11,012对比较的偏好分析显示，各模型表现相近，没有明显优势，自动化评估与人类评价相关性弱。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在创意任务上的评估缺乏专业标准，需要建立基于人类专家偏好的评估框架来衡量LLM在营销创意领域的真实表现。

Method: 覆盖100个品牌（12个类别）和三种提示类型（洞察、想法、疯狂想法），通过678名创意从业者进行11,012次匿名配对比较，使用Bradley-Terry模型分析，并计算余弦距离来评估模型多样性。

Result: 模型表现紧密聚集，没有模型在品牌或提示类型上占据主导地位（Δθ≈0.45，胜率61%），LLM作为评判者与人类排名相关性弱且不一致，传统创造力测试仅部分适用于品牌约束任务。

Conclusion: 需要专家人类评估和多样性感知的工作流程，自动化评判无法替代人类评价。

Abstract: We introduce Creativity Benchmark, an evaluation framework for large language
models (LLMs) in marketing creativity. The benchmark covers 100 brands (12
categories) and three prompt types (Insights, Ideas, Wild Ideas). Human
pairwise preferences from 678 practising creatives over 11,012 anonymised
comparisons, analysed with Bradley-Terry models, show tightly clustered
performance with no model dominating across brands or prompt types: the
top-bottom spread is $\Delta\theta \approx 0.45$, which implies a head-to-head
win probability of $0.61$; the highest-rated model beats the lowest only about
$61\%$ of the time. We also analyse model diversity using cosine distances to
capture intra- and inter-model variation and sensitivity to prompt reframing.
Comparing three LLM-as-judge setups with human rankings reveals weak,
inconsistent correlations and judge-specific biases, underscoring that
automated judges cannot substitute for human evaluation. Conventional
creativity tests also transfer only partially to brand-constrained tasks.
Overall, the results highlight the need for expert human evaluation and
diversity-aware workflows.

</details>


### [27] [CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor](https://arxiv.org/abs/2509.09703)
*Zhenhua Xu,Xixiang Zhao,Xubin Yue,Shengwei Tian,Changting Lin,Meng Han*

Main category: cs.CL

TL;DR: CTCC是一个新颖的基于规则的语言模型指纹框架，通过多轮对话的上下文相关性编码来实现所有权验证，解决了现有方法在隐蔽性、鲁棒性和通用性方面的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型广泛部署引发了知识产权保护担忧，现有指纹方法存在可检测性、易受攻击和通用性不足等问题，需要一种更可靠的模型所有权验证方案。

Method: 提出CTCC框架，采用规则驱动的方法编码多轮对话中的上下文相关性（如反事实关系），而非依赖词级或单轮触发，支持黑盒访问下的指纹验证。

Result: 在多LLM架构上的广泛实验表明，CTCC相比先前工作 consistently 实现了更强的隐蔽性和鲁棒性，有效减少误报和指纹泄露风险。

Conclusion: CTCC为实际LLM部署场景提供了可靠且实用的所有权验证解决方案，支持在部分触发暴露情况下基于共享语义规则的持续构建。

Abstract: The widespread deployment of large language models (LLMs) has intensified
concerns around intellectual property (IP) protection, as model theft and
unauthorized redistribution become increasingly feasible. To address this,
model fingerprinting aims to embed verifiable ownership traces into LLMs.
However, existing methods face inherent trade-offs between stealthness,
robustness, and generalizability, being either detectable via distributional
shifts, vulnerable to adversarial modifications, or easily invalidated once the
fingerprint is revealed. In this work, we introduce CTCC, a novel rule-driven
fingerprinting framework that encodes contextual correlations across multiple
dialogue turns, such as counterfactual, rather than relying on token-level or
single-turn triggers. CTCC enables fingerprint verification under black-box
access while mitigating false positives and fingerprint leakage, supporting
continuous construction under a shared semantic rule even if partial triggers
are exposed. Extensive experiments across multiple LLM architectures
demonstrate that CTCC consistently achieves stronger stealth and robustness
than prior work. Our findings position CTCC as a reliable and practical
solution for ownership verification in real-world LLM deployment scenarios. Our
code and data are publicly available at <https://github.com/Xuzhenhua55/CTCC>.

</details>


### [28] [Temporal Preferences in Language Models for Long-Horizon Assistance](https://arxiv.org/abs/2509.09704)
*Ali Mazyaki,Mohammad Naghizadeh,Samaneh Ranjkhah Zonouzaghi,Hossein Setareh*

Main category: cs.CL

TL;DR: 语言模型在时间偏好选择中存在未来导向性，且可通过提示词系统性操控，理性模型更容易选择延迟满足


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在间隔选择中的时间偏好特征，以及这些偏好是否可以系统性地被操纵

Method: 采用适配的人类实验协议，在时间交易任务中评估多个LM，并与人类决策者进行对比，引入操控性时间导向(MTO)指标

Result: 理性模型(如DeepSeek-Reasoner和grok-3-mini)在未来导向提示下更容易选择延迟满足，但在身份和地理个性化方面仅部分个性化，正确理解时间导向的模型会内化为AI决策者的未来导向

Conclusion: 需要设计能够与异质性、长期目标对齐的AI助手，并推进个性化上下文检验和社会意识部署的研究议程

Abstract: We study whether language models (LMs) exhibit future- versus
present-oriented preferences in intertemporal choice and whether those
preferences can be systematically manipulated. Using adapted human experimental
protocols, we evaluate multiple LMs on time-tradeoff tasks and benchmark them
against a sample of human decision makers. We introduce an operational metric,
the Manipulability of Time Orientation (MTO), defined as the change in an LM's
revealed time preference between future- and present-oriented prompts. In our
tests, reasoning-focused models (e.g., DeepSeek-Reasoner and grok-3-mini)
choose later options under future-oriented prompts but only partially
personalize decisions across identities or geographies. Moreover, models that
correctly reason about time orientation internalize a future orientation for
themselves as AI decision makers. We discuss design implications for AI
assistants that should align with heterogeneous, long-horizon goals and outline
a research agenda on personalized contextual calibration and socially aware
deployment.

</details>


### [29] [The Non-Determinism of Small LLMs: Evidence of Low Answer Consistency in Repetition Trials of Standard Multiple-Choice Benchmarks](https://arxiv.org/abs/2509.09705)
*Claudio Pinhanez,Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Yago Primerano*

Main category: cs.CL

TL;DR: 本研究探讨了小型LLM（2B-8B参数）在重复回答同一问题时的答案一致性，分析了不同温度设置、模型大小、微调状态等因素对一致性和准确性的影响。


<details>
  <summary>Details</summary>
Motivation: 评估小型LLM在多次回答相同问题时的答案一致性，了解不同参数设置对一致性的影响，并研究一致性与准确性之间的权衡关系。

Method: 使用开源LLM对MMLU-Redux和MedQA基准测试中的问题进行10次重复回答，分析不同推理温度、模型大小（2B-8B vs 50B-80B）、微调状态等参数的影响，并开发新的分析和可视化工具。

Result: 小型模型在低推理温度下，能够一致回答的问题比例通常在50%-80%之间；一致答案的准确性与整体准确性存在合理相关性；中型模型显示出更高的一致性水平。

Conclusion: 小型LLM在答案一致性方面存在显著差异，低温度设置可提高一致性，中型模型在一致性方面表现更优，一致性与准确性之间存在正相关关系。

Abstract: This work explores the consistency of small LLMs (2B-8B parameters) in
answering multiple times the same question. We present a study on known,
open-source LLMs responding to 10 repetitions of questions from the
multiple-choice benchmarks MMLU-Redux and MedQA, considering different
inference temperatures, small vs. medium models (50B-80B), finetuned vs. base
models, and other parameters. We also look into the effects of requiring
multi-trial answer consistency on accuracy and the trade-offs involved in
deciding which model best provides both of them. To support those studies, we
propose some new analytical and graphical tools. Results show that the number
of questions which can be answered consistently vary considerably among models
but are typically in the 50%-80% range for small models at low inference
temperatures. Also, accuracy among consistent answers seems to reasonably
correlate with overall accuracy. Results for medium-sized models seem to
indicate much higher levels of answer consistency.

</details>


### [30] [Beyond I'm Sorry, I Can't: Dissecting Large Language Model Refusal](https://arxiv.org/abs/2509.09708)
*Nirmalendu Prakash,Yeo Wei Jie,Amir Abdullah,Ranjan Satapathy,Erik Cambria,Roy Ka Wei Lee*

Main category: cs.CL

TL;DR: 本文通过稀疏自编码器分析LLM拒绝有害提示的内部机制，发现关键特征集并实现越狱，揭示了安全行为的冗余性和可干预性


<details>
  <summary>Details</summary>
Motivation: 理解指令调优大语言模型中拒绝有害提示的安全行为内部机制，目前对此行为的内部原因了解不足

Method: 使用稀疏自编码器分析残差流激活，通过三阶段搜索流程：拒绝方向识别、贪婪过滤和交互发现，寻找能翻转模型从拒绝到顺从的关键特征集

Result: 成功识别出导致越狱的关键特征集，发现存在冗余特征，这些特征在前序特征被抑制时才会激活

Conclusion: 研究展示了通过操作可解释潜在空间进行细粒度审计和针对性干预安全行为的潜力

Abstract: Refusal on harmful prompts is a key safety behaviour in instruction-tuned
large language models (LLMs), yet the internal causes of this behaviour remain
poorly understood. We study two public instruction-tuned models, Gemma-2-2B-IT
and LLaMA-3.1-8B-IT, using sparse autoencoders (SAEs) trained on
residual-stream activations. Given a harmful prompt, we search the SAE latent
space for feature sets whose ablation flips the model from refusal to
compliance, demonstrating causal influence and creating a jailbreak. Our search
proceeds in three stages: (1) Refusal Direction: find a refusal-mediating
direction and collect SAE features near that direction; (2) Greedy Filtering:
prune to a minimal set; and (3) Interaction Discovery: fit a factorization
machine (FM) that captures nonlinear interactions among the remaining active
features and the minimal set. This pipeline yields a broad set of
jailbreak-critical features, offering insight into the mechanistic basis of
refusal. Moreover, we find evidence of redundant features that remain dormant
unless earlier features are suppressed. Our findings highlight the potential
for fine-grained auditing and targeted intervention in safety behaviours by
manipulating the interpretable latent space.

</details>


### [31] [Assisting Research Proposal Writing with Large Language Models: Evaluation and Refinement](https://arxiv.org/abs/2509.09709)
*Jing Ren,Weiqi Wang*

Main category: cs.CL

TL;DR: 这篇论文提出了两个关键评估指标（内容质量和参考文献有效性）和一种迭代提示方法，用于定量评估和提升大语言模型在学术写作中的表现，解决了以往主观人工评判的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在学术写作中常出现错误或虚构参考文献等依赖性问题，而当前的内容质量评估主要依靠主观人工判断，苦糙、缺乏客观性且影响一致性和可靠性。

Method: 提出两个关键评估指标：内容质量和参考文献有效性，并基于这两个指标的得分设计了一种迭代提示方法。

Result: 实验结果显示，提出的评估指标为评估ChatGPT的写作表现提供了客观的定量框架，迭代提示方法显著提升了内容质量，同时减少了参考文献的不准确和虚构问题。

Conclusion: 该研究为学术写作领域提供了客观的定量评估方法，有效解决了大语言模型在学术上下文中的关键依赖性挑战。

Abstract: Large language models (LLMs) like ChatGPT are increasingly used in academic
writing, yet issues such as incorrect or fabricated references raise ethical
concerns. Moreover, current content quality evaluations often rely on
subjective human judgment, which is labor-intensive and lacks objectivity,
potentially compromising the consistency and reliability. In this study, to
provide a quantitative evaluation and enhance research proposal writing
capabilities of LLMs, we propose two key evaluation metrics--content quality
and reference validity--and an iterative prompting method based on the scores
derived from these two metrics. Our extensive experiments show that the
proposed metrics provide an objective, quantitative framework for assessing
ChatGPT's writing performance. Additionally, iterative prompting significantly
enhances content quality while reducing reference inaccuracies and
fabrications, addressing critical ethical challenges in academic contexts.

</details>


### [32] [Generating Individual Travel Diaries Using Large Language Models Informed by Census and Land-Use Data](https://arxiv.org/abs/2509.09710)
*Sepehr Golrokh Amin,Devin Rhoads,Fatemeh Fakhrmoosavi,Nicholas E. Lownes,John N. Ivan*

Main category: cs.CL

TL;DR: 本研究提出了一种基于大语言模型（LLM）的个体出行日记生成方案，通过开源数据生成虚拟人物并合成出行记录，在零样本条件下达到与传统方法相当的生成效果。


<details>
  <summary>Details</summary>
Motivation: 传统基于专有家庭出行调查的方法数据获取成本高，需要开发一种能够利用开源数据生成高质量个体出行日记的新方法。

Method: 使用美国社区调查（ACS）和智能位置数据库（SLD）数据随机生成虚拟人物，通过直接提示LLM合成出行日记，并采用包含四个指标（出行次数、时间间隔、出行目的、交通方式）的复合真实性评分体系进行验证。

Result: LLM生成的日记在整体真实性评分（0.485 vs 0.455）和统计代表性（0.612 vs 0.435）方面优于传统方法，在出行目的确定方面表现优异，且具有更好的一致性。

Conclusion: LLM方法在零样本条件下可行，为未来合成出行日记评估系统建立了可量化的真实性度量标准，展示了在交通建模中的应用潜力。

Abstract: This study introduces a Large Language Model (LLM) scheme for generating
individual travel diaries in agent-based transportation models. While
traditional approaches rely on large quantities of proprietary household travel
surveys, the method presented in this study generates personas stochastically
from open-source American Community Survey (ACS) and Smart Location Database
(SLD) data, then synthesizes diaries through direct prompting. This study
features a novel one-to-cohort realism score: a composite of four metrics (Trip
Count Score, Interval Score, Purpose Score, and Mode Score) validated against
the Connecticut Statewide Transportation Study (CSTS) diaries, matched across
demographic variables. The validation utilizes Jensen-Shannon Divergence to
measure distributional similarities between generated and real diaries. When
compared to diaries generated with classical methods (Negative Binomial for
trip generation; Multinomial Logit for mode/purpose) calibrated on the
validation set, LLM-generated diaries achieve comparable overall realism (LLM
mean: 0.485 vs. 0.455). The LLM excels in determining trip purpose and
demonstrates greater consistency (narrower realism score distribution), while
classical models lead in numerical estimates of trip count and activity
duration. Aggregate validation confirms the LLM's statistical
representativeness (LLM mean: 0.612 vs. 0.435), demonstrating LLM's zero-shot
viability and establishing a quantifiable metric of diary realism for future
synthetic diary evaluation systems.

</details>


### [33] [Psychiatry-Bench: A Multi-Task Benchmark for LLMs in Psychiatry](https://arxiv.org/abs/2509.09711)
*Aya E. Fouda,Abdelrahamn A. Hassan,Radwa J. Hanafy,Mohammed E. Fouda*

Main category: cs.CL

TL;DR: PsychiatryBench是一个基于权威精神病学教科书构建的基准测试，包含11个问答任务和5300多个专家标注项目，用于评估LLMs在精神病学应用中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有评估资源主要依赖小型临床访谈语料库、社交媒体帖子或合成对话，临床有效性有限，无法捕捉精神病学推理的复杂性。

Method: 基于权威专家验证的精神病学教科书和案例手册构建基准测试，包含诊断推理、治疗计划等11个任务类型，使用传统指标和LLM-as-judge相似性评分框架评估多种前沿LLM。

Result: 结果显示出在临床一致性和安全性方面存在显著差距，特别是在多轮随访和管理任务中。

Conclusion: 需要专门的模型调优和更强大的评估范式，PsychiatryBench为高风险心理健康应用中的LLM性能基准测试和改进提供了模块化、可扩展的平台。

Abstract: Large language models (LLMs) hold great promise in enhancing psychiatric
practice, from improving diagnostic accuracy to streamlining clinical
documentation and therapeutic support. However, existing evaluation resources
heavily rely on small clinical interview corpora, social media posts, or
synthetic dialogues, which limits their clinical validity and fails to capture
the full complexity of psychiatric reasoning. In this work, we introduce
PsychiatryBench, a rigorously curated benchmark grounded exclusively in
authoritative, expert-validated psychiatric textbooks and casebooks.
PsychiatryBench comprises eleven distinct question-answering tasks ranging from
diagnostic reasoning and treatment planning to longitudinal follow-up,
management planning, clinical approach, sequential case analysis, and
multiple-choice/extended matching formats totaling over 5,300 expert-annotated
items. We evaluate a diverse set of frontier LLMs (including Google Gemini,
DeepSeek, LLaMA 3, and QWQ-32) alongside leading open-source medical models
(e.g., OpenBiloLLM, MedGemma) using both conventional metrics and an
"LLM-as-judge" similarity scoring framework. Our results reveal substantial
gaps in clinical consistency and safety, particularly in multi-turn follow-up
and management tasks, underscoring the need for specialized model tuning and
more robust evaluation paradigms. PsychiatryBench offers a modular, extensible
platform for benchmarking and improving LLM performance in high-stakes mental
health applications.

</details>


### [34] [The Thinking Therapist: Training Large Language Models to Deliver Acceptance and Commitment Therapy using Supervised Fine-Tuning and Odds Ratio Policy Optimization](https://arxiv.org/abs/2509.09712)
*Talha Tahir*

Main category: cs.CL

TL;DR: 这研究识别了ORPO训练方法在小型语言模型中实现接纳与承诺疗法（ACT）的优劢性，而显式推理的作用取决于基础训练方法。


<details>
  <summary>Details</summary>
Motivation: 探索后训练方法和显式推理对小型语言模型执行ACT疗法能力的影响，以提升AI辅助心理治疗的效果。

Method: 使用50组合成ACT话语训练Llama-3.2-3b-Instruct模型，比较SFT和ORPO两种训练方法，每种方法分别包含和不包含链式推理步骤。通过模拟治疗会话评估模型在ACT忠实度和治疗师共情上的表现。

Result: ORPO训练模型在ACT忠实度和治疗共情方面显著优于SFT和基准Instruct模型。链式推理对SFT模型有显著改善作用（ACT-FM得分提高2.68分），但对ORPO模型无显著影响。

Conclusion: 偏好对齐改进策略（ORPO）能够有效培养小型语言模型的ACT能力，而显式推理的作用依赖于基础训练方法。

Abstract: Acceptance and Commitment Therapy (ACT) is a third-wave cognitive behavioral
therapy with emerging evidence of efficacy in several psychiatric conditions.
This study investigates the impact of post-training methodology and explicit
reasoning on the ability of a small open-weight large language model (LLM) to
deliver ACT. Using 50 sets of synthetic ACT transcripts generated by
Mistral-Large, we trained Llama-3.2-3b-Instruct with two distinct approaches,
supervised fine-tuning (SFT) and odds ratio policy optimization (ORPO), each
with and without an explicit chain-of-thought (COT) reasoning step. Performance
was evaluated by comparing these four post-trained variants against the base
Instruct model. These models were benchmarked in simulated therapy sessions,
with performance quantitatively assessed on the ACT Fidelity Measure (ACT-FM)
and the Therapist Empathy Scale (TES) by an LLM judge that had been fine-tuned
on human evaluations. Our findings demonstrate that the ORPO-trained models
significantly outperformed both their SFT and Instruct counterparts on ACT
fidelity ($\chi^2(5) = 185.15, p < .001$) and therapeutic empathy ($\chi^2(5) =
140.37, p < .001$). The effect of COT was conditional as it provided a
significant benefit to SFT models, improving ACT-FM scores by an average of
2.68 points ($p < .001$), while offering no discernible advantage to the
superior ORPO or instruct-tuned variants. We posit that the superiority of ORPO
stems from its ability to learn the therapeutic `process' over imitating
`content,' a key aspect of ACT, while COT acts as a necessary scaffold for
models trained only via imitation. This study establishes that
preference-aligned policy optimization can effectively instill ACT competencies
in small LLMs, and that the utility of explicit reasoning is highly dependent
on the underlying training paradigm.

</details>


### [35] [HANRAG: Heuristic Accurate Noise-resistant Retrieval-Augmented Generation for Multi-hop Question Answering](https://arxiv.org/abs/2509.09713)
*Duolin Sun,Dan Yang,Yue Shen,Yihan Jiao,Zhehao Tan,Jie Feng,Lianzhen Zhong,Jian Wang,Peng Wei,Jinjie Gu*

Main category: cs.CL

TL;DR: HANRAG是一个基于启发式的新型框架，通过查询路由、子查询分解和噪声过滤，有效解决多跳查询中的迭代检索效率低和噪声积累问题，在单跳和多跳问答任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理多跳查询时面临挑战：过度依赖迭代检索浪费步骤，原始复杂查询检索可能无法捕获相关子查询内容，导致噪声积累问题。

Method: 提出HANRAG框架，使用强大的揭示器进行查询路由、将复杂查询分解为子查询，并从检索文档中过滤噪声，增强系统适应性和抗噪能力。

Result: 在多个基准测试中与行业领先方法比较，结果显示该框架在单跳和多跳问答任务中都获得了优越性能。

Conclusion: HANRAG框架通过创新的启发式方法有效解决了多跳查询处理中的关键问题，显著提升了RAG系统的性能和鲁棒性。

Abstract: The Retrieval-Augmented Generation (RAG) approach enhances question-answering
systems and dialogue generation tasks by integrating information retrieval (IR)
technologies with large language models (LLMs). This strategy, which retrieves
information from external knowledge bases to bolster the response capabilities
of generative models, has achieved certain successes. However, current RAG
methods still face numerous challenges when dealing with multi-hop queries. For
instance, some approaches overly rely on iterative retrieval, wasting too many
retrieval steps on compound queries. Additionally, using the original complex
query for retrieval may fail to capture content relevant to specific
sub-queries, resulting in noisy retrieved content. If the noise is not managed,
it can lead to the problem of noise accumulation. To address these issues, we
introduce HANRAG, a novel heuristic-based framework designed to efficiently
tackle problems of varying complexity. Driven by a powerful revelator, HANRAG
routes queries, decomposes them into sub-queries, and filters noise from
retrieved documents. This enhances the system's adaptability and noise
resistance, making it highly capable of handling diverse queries. We compare
the proposed framework against other leading industry methods across various
benchmarks. The results demonstrate that our framework obtains superior
performance in both single-hop and multi-hop question-answering tasks.

</details>


### [36] [How Small Transformation Expose the Weakness of Semantic Similarity Measures](https://arxiv.org/abs/2509.09714)
*Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Aziz Bonkoungou,Micheline Bénédicte Moumoula,Jordan Samhi,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande*

Main category: cs.CL

TL;DR: 这项研究系统性测试18种语义相似性测量方法，发现常用指标存在显著缺陷，嵌入方法对语义相反内容出现高分误判，而LLM方法在区分语义差异方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 评估不同语义相似性测量方法的效果，确定大语言模型是否真正理解语义关系还是仅仅识别表面模式，以支持代码搜索、API推荐等软件工程应用。

Method: 创建系统化测试框架，对文本和代码进行受控变更，测试包括词汇基、嵌入技术、LLM基础和结构感知算法在内的18种方法的表现。

Result: 嵌入方法对语义相反内容的误判率达99.9%，某些变换器方法将相反含义评为比同义词更相似。从欧几里得距离切换为余弦相似性后性能提升24-66%。LLM方法在区分真正语义差异时表现更好（低相似性分数0.00-0.29）。

Conclusion: 当前常用的语义相似性测量方法存在显著缺陷，嵌入方法的距离计算方式影响性能，LLM方法在语义区分方面表现更优。这为软件工程应用中的语义相似性评估提供了重要参考。

Abstract: This research examines how well different methods measure semantic
similarity, which is important for various software engineering applications
such as code search, API recommendations, automated code reviews, and
refactoring tools. While large language models are increasingly used for these
similarity assessments, questions remain about whether they truly understand
semantic relationships or merely recognize surface patterns.
  The study tested 18 different similarity measurement approaches, including
word-based methods, embedding techniques, LLM-based systems, and
structure-aware algorithms. The researchers created a systematic testing
framework that applies controlled changes to text and code to evaluate how well
each method handles different types of semantic relationships.
  The results revealed significant issues with commonly used metrics. Some
embedding-based methods incorrectly identified semantic opposites as similar up
to 99.9 percent of the time, while certain transformer-based approaches
occasionally rated opposite meanings as more similar than synonymous ones. The
study found that embedding methods' poor performance often stemmed from how
they calculate distances; switching from Euclidean distance to cosine
similarity improved results by 24 to 66 percent. LLM-based approaches performed
better at distinguishing semantic differences, producing low similarity scores
(0.00 to 0.29) for genuinely different meanings, compared to embedding methods
that incorrectly assigned high scores (0.82 to 0.99) to dissimilar content.

</details>


### [37] [Investigating Symbolic Triggers of Hallucination in Gemma Models Across HaluEval and TruthfulQA](https://arxiv.org/abs/2509.09715)
*Naveen Lamba,Sanju Tiwari,Manas Gaur*

Main category: cs.CL

TL;DR: 该研究识别并表征了导致大语言模型产生幻觉的关键符号属性，发现即使模型规模增大，符号元素（如修饰词和命名实体）仍然是模型处理中的根本弱点。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM的幻觉问题已被广泛研究，但导致模型内在易产生幻觉的属性尚未被识别和研究。本研究旨在识别和表征这些关键属性，以定位模型内部机制的漏洞。

Method: 使用HaluEval和TruthfulQA两个数据集，将现有的问答格式转换为多种其他格式，以确定符号属性是导致幻觉的原因。

Result: Gemma-2-2B模型在任务和数据集上的平均幻觉率为79.0%，随着模型规模增大，Gemma-2-9B降至73.6%，Gemma-2-27B降至63.9%。修饰词（84.76%-94.98%）和命名实体（83.87%-93.96%）在所有Gemma模型和数据集上都表现出高幻觉率。

Conclusion: 符号元素持续混淆模型，表明这些LLM在处理此类输入时存在根本性弱点，且这种弱点不受模型规模的影响。

Abstract: Hallucination in Large Language Models (LLMs) is a well studied problem.
However, the properties that make LLM intrinsically vulnerable to
hallucinations have not been identified and studied. This research identifies
and characterizes the key properties, allowing us to pinpoint vulnerabilities
within the model's internal mechanisms. To solidify on these properties, we
utilized two established datasets, HaluEval and TruthfulQA and convert their
existing format of question answering into various other formats to narrow down
these properties as the reason for the hallucinations. Our findings reveal that
hallucination percentages across symbolic properties are notably high for
Gemma-2-2B, averaging 79.0% across tasks and datasets. With increased model
scale, hallucination drops to 73.6% for Gemma-2-9B and 63.9% for Gemma-2-27B,
reflecting a 15 percentage point reduction overall. Although the hallucination
rate decreases as the model size increases, a substantial amount of
hallucination caused by symbolic properties still persists. This is especially
evident for modifiers (ranging from 84.76% to 94.98%) and named entities
(ranging from 83.87% to 93.96%) across all Gemma models and both datasets.
These findings indicate that symbolic elements continue to confuse the models,
pointing to a fundamental weakness in how these LLMs process such
inputs--regardless of their scale.

</details>


### [38] [ALIGNS: Unlocking nomological networks in psychological measurement through a large language model](https://arxiv.org/abs/2509.09723)
*Kai R. Larsen,Sen Yan,Roland Müller,Lan Sang,Mikko Rönkkö,Ravi Starzl,Donald Edmondson*

Main category: cs.CL

TL;DR: ALIGNS是一个基于大语言模型的系统，用于生成包含55万+指标的综合nomological网络，解决心理测量中验证网络构建的难题。


<details>
  <summary>Details</summary>
Motivation: 心理测量对多学科至关重要，但构建nomological网络（概念与测量关系的理论图谱）在Cronbach和Meehl提出70年后仍是挑战，这导致临床试验可能无法检测治疗效果，公共政策可能针对错误结果。

Method: 开发基于大语言模型的ALIGNS系统，使用经过验证的问卷测量进行训练，提供三个综合nomological网络，涵盖心理学、医学、社会政策等领域。

Result: 1) NIH PROMIS焦虑和抑郁工具收敛为单一情绪困扰维度；2) 儿童气质测量识别出当前框架未捕捉的四个潜在维度，并质疑一个现有维度；3) 心理测量学专家评估显示系统具有重要性、可访问性和适用性。

Conclusion: ALIGNS是首个应用大语言模型解决测量验证基础问题的系统，可免费使用，通过大规模nomological分析补充传统验证方法。

Abstract: Psychological measurement is critical to many disciplines. Despite advances
in measurement, building nomological networks, theoretical maps of how concepts
and measures relate to establish validity, remains a challenge 70 years after
Cronbach and Meehl proposed them as fundamental to validation. This limitation
has practical consequences: clinical trials may fail to detect treatment
effects, and public policy may target the wrong outcomes. We introduce Analysis
of Latent Indicators to Generate Nomological Structures (ALIGNS), a large
language model-based system trained with validated questionnaire measures.
ALIGNS provides three comprehensive nomological networks containing over
550,000 indicators across psychology, medicine, social policy, and other
fields. This represents the first application of large language models to solve
a foundational problem in measurement validation. We report classification
accuracy tests used to develop the model, as well as three evaluations. In the
first evaluation, the widely used NIH PROMIS anxiety and depression instruments
are shown to converge into a single dimension of emotional distress. The second
evaluation examines child temperament measures and identifies four potential
dimensions not captured by current frameworks, and questions one existing
dimension. The third evaluation, an applicability check, engages expert
psychometricians who assess the system's importance, accessibility, and
suitability. ALIGNS is freely available at nomologicalnetwork.org,
complementing traditional validation methods with large-scale nomological
analysis.

</details>


### [39] [DiTTO-LLM: Framework for Discovering Topic-based Technology Opportunities via Large Language Model](https://arxiv.org/abs/2509.09724)
*Wonyoung Kim,Sujeong Seo,Juhyun Lee*

Main category: cs.CL

TL;DR: 基于专利数据集的时间关系分析框架，利用大语言模型提取技术主题和关系，进而识别新兴技术机会


<details>
  <summary>Details</summary>
Motivation: 技术机会是推动技术进步、产业发展和创新的关键信息，需要一种有效的方法来识别新兴技术趋势

Method: 从专利数据集提取文本，映射文本主题发现技术间关系，通过跟踪主题随时间变化来识别技术机会，利用大语言模型提取主题和聊天模型提示支持机会发现

Result: 使用美国专利庁提供的人工智能专利数据集进行评估，实验结果显示人工智能技术正向日常可访性形式发展

Conclusion: 该框架可以有效识别未来技术机会，为技术预测和创新发展提供有价值的见解

Abstract: Technology opportunities are critical information that serve as a foundation
for advancements in technology, industry, and innovation. This paper proposes a
framework based on the temporal relationships between technologies to identify
emerging technology opportunities. The proposed framework begins by extracting
text from a patent dataset, followed by mapping text-based topics to discover
inter-technology relationships. Technology opportunities are then identified by
tracking changes in these topics over time. To enhance efficiency, the
framework leverages a large language model to extract topics and employs a
prompt for a chat-based language model to support the discovery of technology
opportunities. The framework was evaluated using an artificial intelligence
patent dataset provided by the United States Patent and Trademark Office. The
experimental results suggest that artificial intelligence technology is
evolving into forms that facilitate everyday accessibility. This approach
demonstrates the potential of the proposed framework to identify future
technology opportunities.

</details>


### [40] [BIBERT-Pipe on Biomedical Nested Named Entity Linking at BioASQ 2025](https://arxiv.org/abs/2509.09725)
*Chunyu Li,Xindi Zheng,Siqi Liu*

Main category: cs.CL

TL;DR: 提出了一个轻量级的两阶段生物医学实体链接系统BIBERT-Pipe，用于处理多语言嵌套命名实体链接任务，在BioNNE 2025评测中排名第三


<details>
  <summary>Details</summary>
Motivation: 现有的生物医学实体链接基准主要针对英语单语和平坦提及，缺乏对多语言和嵌套提及的现实场景研究

Method: 采用两阶段检索-排序管道：检索阶段使用原始预训练模型，排序阶段进行领域特定微调；使用可学习的[Ms]/[Me]标签包装提及；通过三种数据源自动扩展训练语料

Result: 在BioNNE 2025多语言赛道排名第三，证明了这些最小但原则性修改的有效性和竞争力

Conclusion: 该方法通过保持原始EL模型不变，仅修改三个任务对齐组件，成功解决了多语言生物医学嵌套实体链接问题，代码已开源

Abstract: Entity linking (EL) for biomedical text is typically benchmarked on
English-only corpora with flat mentions, leaving the more realistic scenario of
nested and multilingual mentions largely unexplored. We present our system for
the BioNNE 2025 Multilingual Biomedical Nested Named Entity Linking shared task
(English & Russian), closing this gap with a lightweight pipeline that keeps
the original EL model intact and modifies only three task-aligned components:
Two-stage retrieval-ranking. We leverage the same base encoder model in both
stages: the retrieval stage uses the original pre-trained model, while the
ranking stage applies domain-specific fine-tuning. Boundary cues. In the
ranking stage, we wrap each mention with learnable [Ms] / [Me] tags, providing
the encoder with an explicit, language-agnostic span before robustness to
overlap and nesting. Dataset augmentation. We also automatically expand the
ranking training corpus with three complementary data sources, enhancing
coverage without extra manual annotation. On the BioNNE 2025 leaderboard, our
two stage system, bilingual bert (BIBERT-Pipe), ranks third in the multilingual
track, demonstrating the effectiveness and competitiveness of these minimal yet
principled modifications. Code are publicly available at
https://github.com/Kaggle-Competitions-Code/BioNNE-L.

</details>


### [41] [Natural Language Translation of Formal Proofs through Informalization of Proof Steps and Recursive Summarization along Proof Structure](https://arxiv.org/abs/2509.09726)
*Seiji Hattori,Takuya Matsuzaki,Makoto Fujiwara*

Main category: cs.CL

TL;DR: 利用LLM的非形式化能力将机器可验证的形式证明翻译为自然语言证明，并在教科书证明数据和Lean证明库上验证了方法的有效性


<details>
  <summary>Details</summary>
Motivation: 为了解决形式证明难以被人类理解的问题，利用大型语言模型的能力将机器可验证的形式证明转换为更易读的自然语言证明

Method: 提出基于LLM的自然语言翻译方法，利用LLM的非形式化（形式语言证明步骤的言语化）和摘要能力，将形式证明转换为自然语言证明

Result: 在本科教科书的形式证明数据上评估，生成的证明质量与原始自然语言证明相当；在Lean证明助手的现有形式证明库上应用，能够输出高可读性和准确性的自然语言证明

Conclusion: 该方法能够有效将形式证明转换为高质量的自然语言证明，提高了形式证明的可读性和可理解性

Abstract: This paper proposes a natural language translation method for
machine-verifiable formal proofs that leverages the informalization
(verbalization of formal language proof steps) and summarization capabilities
of LLMs. For evaluation, it was applied to formal proof data created in
accordance with natural language proofs taken from an undergraduate-level
textbook, and the quality of the generated natural language proofs was analyzed
in comparison with the original natural language proofs. Furthermore, we will
demonstrate that this method can output highly readable and accurate natural
language proofs by applying it to existing formal proof library of the Lean
proof assistant.

</details>


### [42] [A Role-Aware Multi-Agent Framework for Financial Education Question Answering with LLMs](https://arxiv.org/abs/2509.09727)
*Andy Zhu,Yingjun Du*

Main category: cs.CL

TL;DR: 一种多段代理框架，通过角色基于提示和批判性精细化，在金融教育问答中提高了回答准确性，比零射思维链基准提升8.3%，且成本效益更高。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在金融问答领域存在不足，无法满足金融领域对多步数量推理、专业术语和实际场景理解的高要求。

Method: 设计了一个包含Base Generator、Evidence Retriever和Expert Reviewer代理的多段代理框架，通过单次迭代生成精细答案。使用RAG技术从6本金融教科书中获取上下文证据，并采用领域专家审查的提示策略。

Result: 在Study.com的3,532道金融教育问题上评测，批判基于精细化方法比零射思维链基准提高了6.6-8.3%的准确性，Gemini-2.0-Flash表现最佳。GPT-4o-mini能达到与金融局部调优模型FinGPT相当的性能。

Conclusion: 该多段代理框架提供了一种成本效益高的方法来提升金融问答性能，为进一步研究多段金融LLM系统提供了见解。

Abstract: Question answering (QA) plays a central role in financial education, yet
existing large language model (LLM) approaches often fail to capture the
nuanced and specialized reasoning required for financial problem-solving. The
financial domain demands multistep quantitative reasoning, familiarity with
domain-specific terminology, and comprehension of real-world scenarios. We
present a multi-agent framework that leverages role-based prompting to enhance
performance on domain-specific QA. Our framework comprises a Base Generator, an
Evidence Retriever, and an Expert Reviewer agent that work in a single-pass
iteration to produce a refined answer. We evaluated our framework on a set of
3,532 expert-designed finance education questions from Study.com, an online
learning platform. We leverage retrieval-augmented generation (RAG) for
contextual evidence from 6 finance textbooks and prompting strategies for a
domain-expert reviewer. Our experiments indicate that critique-based refinement
improves answer accuracy by 6.6-8.3% over zero-shot Chain-of-Thought baselines,
with the highest performance from Gemini-2.0-Flash. Furthermore, our method
enables GPT-4o-mini to achieve performance comparable to the finance-tuned
FinGPT-mt_Llama3-8B_LoRA. Our results show a cost-effective approach to
enhancing financial QA and offer insights for further research in multi-agent
financial LLM systems.

</details>


### [43] [A meta-analysis on the performance of machine-learning based language models for sentiment analysis](https://arxiv.org/abs/2509.09728)
*Elena Rohde,Jonas Klingwort,Christian Borgs*

Main category: cs.CL

TL;DR: 对Twitter数据情感分析中机器学习性能的综合评估，平均准确率为80%，提出需标准化报告和考虑类别不平衡问题


<details>
  <summary>Details</summary>
Motivation: 评估Twitter数据情感分析中机器学习的综合性能，分析研究特征对模型性能的影响，以及识别当前研究实践中的问题

Method: 使用PRISMA指南搜索学术数据库，选择195个试验数据（来自20项研究），采用双重反正弦变换和三层随机效应模型进行分析

Result: AIC优化模型的平均综合准确率为0.80 [0.76, 0.84]，发现整体准确率存在误导性（受类别不平衡和情感类别数量影响），且标准化报告实践缺乏

Conclusion: 需要对性能指标进行标准化处理，并建立包括混淆矩阵在内的标准化报告框架，以便在不同研究间进行可靠的模型比较

Abstract: This paper presents a meta-analysis evaluating ML performance in sentiment
analysis for Twitter data. The study aims to estimate the average performance,
assess heterogeneity between and within studies, and analyze how study
characteristics influence model performance. Using PRISMA guidelines, we
searched academic databases and selected 195 trials from 20 studies with 12
study features. Overall accuracy, the most reported performance metric, was
analyzed using double arcsine transformation and a three-level random effects
model. The average overall accuracy of the AIC-optimized model was 0.80 [0.76,
0.84]. This paper provides two key insights: 1) Overall accuracy is widely used
but often misleading due to its sensitivity to class imbalance and the number
of sentiment classes, highlighting the need for normalization. 2) Standardized
reporting of model performance, including reporting confusion matrices for
independent test sets, is essential for reliable comparisons of ML classifiers
across studies, which seems far from common practice.

</details>


### [44] [MultimodalHugs: Enabling Sign Language Processing in Hugging Face](https://arxiv.org/abs/2509.09729)
*Gerard Sant,Zifan Jiang,Carlos Escolano,Amit Moryossef,Mathias Müller,Rico Sennrich,Sarah Ebling*

Main category: cs.CL

TL;DR: MultimodalHugs是一个基于Hugging Face构建的多模态框架，专门为解决手语处理研究中的可复现性和公平比较问题而设计，支持更丰富的数据模态和任务。


<details>
  <summary>Details</summary>
Motivation: 手语处理研究面临代码复杂、可复现性低和比较不公平的问题，现有工具如Hugging Face对手语实验的支持不够灵活。

Method: 在Hugging Face基础上构建MultimodalHugs框架，增加抽象层以支持多样化的数据模态（如姿态估计数据和像素数据）和任务。

Result: 框架能够无缝集成手语实验，支持多种模态数据，并通过定量实验验证了其适用性。

Conclusion: MultimodalHugs不仅解决了手语处理研究的技术障碍，还具有更广泛的多模态应用潜力。

Abstract: In recent years, sign language processing (SLP) has gained importance in the
general field of Natural Language Processing. However, compared to research on
spoken languages, SLP research is hindered by complex ad-hoc code,
inadvertently leading to low reproducibility and unfair comparisons. Existing
tools that are built for fast and reproducible experimentation, such as Hugging
Face, are not flexible enough to seamlessly integrate sign language
experiments. This view is confirmed by a survey we conducted among SLP
researchers.
  To address these challenges, we introduce MultimodalHugs, a framework built
on top of Hugging Face that enables more diverse data modalities and tasks,
while inheriting the well-known advantages of the Hugging Face ecosystem. Even
though sign languages are our primary focus, MultimodalHugs adds a layer of
abstraction that makes it more widely applicable to other use cases that do not
fit one of the standard templates of Hugging Face. We provide quantitative
experiments to illustrate how MultimodalHugs can accommodate diverse modalities
such as pose estimation data for sign languages, or pixel data for text
characters.

</details>


### [45] [Benchmarking Vision-Language Models on Chinese Ancient Documents: From OCR to Knowledge Reasoning](https://arxiv.org/abs/2509.09731)
*Haiyang Yu,Yuchuan Wu,Fan Shi,Lei Liao,Jinghui Lu,Xiaodong Ge,Han Wang,Minghan Zhuo,Xuecheng Wu,Xiang Fei,Hao Feng,Guozhi Tang,An-Lan Wang,Hanshen Zhu,Yangfan He,Quanhuan Liang,Liyuan Meng,Chao Feng,Can Huang,Jingqun Tang,Bin Li*

Main category: cs.CL

TL;DR: AncientDoc是首个中文古籍文档基准测试，包含5个任务，涵盖14种文档类型、100多本书籍和约3000页内容，用于评估视觉语言模型在古籍处理中的能力。


<details>
  <summary>Details</summary>
Motivation: 中文古籍作为中华历史文化的重要载体，在数字化和理解方面面临挑战。传统方法仅扫描图像，而现有视觉语言模型难以处理古籍的视觉和语言复杂性。现有文档基准主要针对英文印刷文本或简体中文，缺乏对中文古籍的评估标准。

Method: 构建AncientDoc基准测试，包含5个任务：页面级OCR、白话翻译、推理问答、知识问答和语言变体问答。涵盖14种文档类型、100多本书籍和约3000页内容。使用多种指标评估主流视觉语言模型，并辅以人类对齐的大语言模型进行评分。

Result: 创建了首个专门针对中文古籍的综合性基准测试AncientDoc，为评估视觉语言模型在古籍处理方面的能力提供了标准化测试平台。

Conclusion: AncientDoc填补了中文古籍文档评估的空白，为促进古籍数字化和理解提供了重要的基准工具，有助于推动视觉语言模型在古籍处理领域的发展。

Abstract: Chinese ancient documents, invaluable carriers of millennia of Chinese
history and culture, hold rich knowledge across diverse fields but face
challenges in digitization and understanding, i.e., traditional methods only
scan images, while current Vision-Language Models (VLMs) struggle with their
visual and linguistic complexity. Existing document benchmarks focus on English
printed texts or simplified Chinese, leaving a gap for evaluating VLMs on
ancient Chinese documents. To address this, we present AncientDoc, the first
benchmark for Chinese ancient documents, designed to assess VLMs from OCR to
knowledge reasoning. AncientDoc includes five tasks (page-level OCR, vernacular
translation, reasoning-based QA, knowledge-based QA, linguistic variant QA) and
covers 14 document types, over 100 books, and about 3,000 pages. Based on
AncientDoc, we evaluate mainstream VLMs using multiple metrics, supplemented by
a human-aligned large language model for scoring.

</details>


### [46] [MCP-AgentBench: Evaluating Real-World Language Agent Performance with MCP-Mediated Tools](https://arxiv.org/abs/2509.09734)
*Zikang Guo,Benfeng Xu,Chiwei Zhu,Wentao Hong,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: MCP-AgentBench是一个专门为评估语言代理在MCP协议下的工具交互能力而设计的综合基准测试，包含33个服务器、188个工具和600个查询任务。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试无法准确评估MCP协议下AI代理的真实性能，导致对其操作价值的误解和能力差异的无法可靠区分。

Method: 建立了包含33个操作服务器和188个不同工具的MCP测试床，开发了600个系统设计的查询任务，分布在6个不同复杂度的交互类别中，并引入了MCP-Eval这种以结果为导向的新评估方法。

Result: 通过对领先语言代理的广泛实证评估，提供了基础性见解，展示了不同代理在MCP环境下的性能表现。

Conclusion: MCP-AgentBench为研究社区提供了一个标准化和可靠的框架，用于构建、验证和推进能够充分利用MCP变革性优势的AI代理，加速实现真正有能力且可互操作的AI系统。

Abstract: The Model Context Protocol (MCP) is rapidly emerging as a pivotal open
standard, designed to enhance agent-tool integration and interoperability, and
is positioned to unlock a new era of powerful, interconnected, and genuinely
utilitarian agentic AI. However, despite MCP's growing adoption, existing
benchmarks often fail to capture real-world agent performance within this new
paradigm, leading to a distorted perception of their true operational value and
an inability to reliably differentiate proficiencies. To bridge this critical
evaluation gap, we introduce MCP-AgentBench -- a comprehensive benchmark
specifically engineered to rigorously assess language agent capabilities in
MCP-mediated tool interactions. Core contributions of MCP-AgentBench include:
the establishment of a robust MCP testbed comprising 33 operational servers
with 188 distinct tools; the development of a benchmark featuring 600
systematically designed queries distributed across 6 distinct categories of
varying interaction complexity; and the introduction of MCP-Eval, a novel
outcome-oriented evaluation methodology prioritizing real-world task success.
Through extensive empirical evaluation of leading language agents, we provide
foundational insights. MCP-AgentBench aims to equip the research community with
a standardized and reliable framework to build, validate, and advance agents
capable of fully leveraging MCP's transformative benefits, thereby accelerating
progress toward truly capable and interoperable AI systems.

</details>


### [47] [Discrimination by LLMs: Cross-lingual Bias Assessment and Mitigation in Decision-Making and Summarisation](https://arxiv.org/abs/2509.09735)
*Willem Huijzer,Jieying Chen*

Main category: cs.CL

TL;DR: 这项研究调查了大语言模型在决策和摘要任务中的偏见问题，发现GPT-3.5和GPT-4o在决策中存在显著偏见，偏向女性、年轻者和非洲美国胎股东背景。摘要任务偏见较少，而提示指令策略能部分减少偏见。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的广泛集成，对社会不平等和信息偏见的担忧日益增加，需要研究LLMs在不同任务中的偏见问题和有效的减少策略。

Method: 使用根据Tamkin等人(2023)数据集翻译的荷兰语版本，创建了151,200个决策任务提示和176,400个摘要任务提示。在GPT-3.5和GPT-4o上测试了不同人口统计变量、指令类型、显著性水平和语言。

Result: 两个模型在决策任务中都显示显著偏见，偏向女性、年轻者和非洲美国胎股东背景。摘要任务偏见较少，GPT-3.5在英语中显示出年龄相关差异。跨语言分析显示英语和荷兰语偏见模式大体相似，但在具体人口统计类别中存在显著差异。提示指令策略能部分减少偏见，最有效的指令平均减少27%的偏见差距。GPT-4o在英语中显示更少的偏见。

Conclusion: 研究强调了谨慎采用LLMs的重要性和根据具体上下文进行偏见测试的必要性，并强调了继续开发有效减少策略以确保AI负责任部署的需要。

Abstract: The rapid integration of Large Language Models (LLMs) into various domains
raises concerns about societal inequalities and information bias. This study
examines biases in LLMs related to background, gender, and age, with a focus on
their impact on decision-making and summarization tasks. Additionally, the
research examines the cross-lingual propagation of these biases and evaluates
the effectiveness of prompt-instructed mitigation strategies. Using an adapted
version of the dataset by Tamkin et al. (2023) translated into Dutch, we
created 151,200 unique prompts for the decision task and 176,400 for the
summarisation task. Various demographic variables, instructions, salience
levels, and languages were tested on GPT-3.5 and GPT-4o. Our analysis revealed
that both models were significantly biased during decision-making, favouring
female gender, younger ages, and certain backgrounds such as the
African-American background. In contrast, the summarisation task showed minimal
evidence of bias, though significant age-related differences emerged for
GPT-3.5 in English. Cross-lingual analysis showed that bias patterns were
broadly similar between English and Dutch, though notable differences were
observed across specific demographic categories. The newly proposed mitigation
instructions, while unable to eliminate biases completely, demonstrated
potential in reducing them. The most effective instruction achieved a 27\% mean
reduction in the gap between the most and least favorable demographics.
Notably, contrary to GPT-3.5, GPT-4o displayed reduced biases for all prompts
in English, indicating the specific potential for prompt-based mitigation
within newer models. This research underscores the importance of cautious
adoption of LLMs and context-specific bias testing, highlighting the need for
continued development of effective mitigation strategies to ensure responsible
deployment of AI.

</details>


### [48] [HEFT: A Coarse-to-Fine Hierarchy for Enhancing the Efficiency and Accuracy of Language Model Reasoning](https://arxiv.org/abs/2509.09801)
*Brennen Hill*

Main category: cs.CL

TL;DR: HEFT是一种分层高效微调策略，结合LoRA和ReFT两种PEFT方法，在BoolQ基准测试中仅用3个epoch就达到85.17%准确率，超越单独使用LoRA或ReFT的20个epoch训练结果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专门推理任务上的适配受计算资源限制，现有参数高效微调方法多样但各自独立，研究假设协同组合不同范式可以解锁更好的性能和效率。

Method: 提出HEFT分层适配策略：先在权重空间使用LoRA进行广泛基础适配，然后在表示空间使用ReFT进行精确外科式精炼，形成从粗到细的层次化微调。

Result: 在Llama-2-7B模型和BoolQ推理数据集上，HEFT仅用3个epoch就达到85.17%准确率，优于LoRA-only（85.05%）和ReFT-only（83.36%）的20个epoch结果，显示出显著的协同效应。

Conclusion: PEFT方法的精心组合是强大的算法创新，为提升语言模型推理能力提供了更高效有效的路径，以更少计算预算获得更好结果，为大规模模型适配复杂认知任务提供了原则性方法。

Abstract: The adaptation of large language models (LLMs) to specialized reasoning tasks
is fundamentally constrained by computational resources. Parameter-Efficient
Fine-Tuning (PEFT) methods have emerged as a powerful solution, yet the
landscape of these techniques is diverse, with distinct methods operating in
either the model's weight space or its representation space. This paper
investigates the hypothesis that a synergistic combination of these paradigms
can unlock superior performance and efficiency. We introduce HEFT (Hierarchical
Efficient Fine-Tuning), a novel hierarchical adaptation strategy that composes
two distinct PEFT methods in a coarse-to-fine manner: first, a broad,
foundational adaptation in the weight space using Low-Rank Adaptation (LoRA),
followed by a precise, surgical refinement of internal activations using
Representation Fine-Tuning (ReFT). We evaluate this approach by fine-tuning a
Llama-2-7B model on the BoolQ benchmark, a challenging dataset for inferential
reasoning. Our results reveal a profound synergistic effect. A model fine-tuned
for only three epochs with our HEFT strategy achieves an accuracy of 85.17\%,
exceeding the performance of models trained for 20 epochs with either LoRA-only
(85.05\%) or ReFT-only (83.36\%) methodologies. This work demonstrates that the
thoughtful composition of PEFT methods is a potent algorithmic innovation,
offering a more efficient and effective path toward advancing the reasoning
capabilities of language models. By achieving superior results with a fraction
of the computational budget, our findings present a principled approach to
overcoming the obstacles inherent in adapting large-scale models for complex
cognitive tasks.

</details>


### [49] [Pragmatic Frames Evoked by Gestures: A FrameNet Brasil Approach to Multimodality in Turn Organization](https://arxiv.org/abs/2509.09804)
*Helen de Andrade Abreu,Tiago Timponi Torrent,Ely Edison da Silva Matos*

Main category: cs.CL

TL;DR: 本文提出了一个多模态对话轮流组织模型框架，通过分析语言与互动手势的关联来建模语用框架的概念化和唤起机制。


<details>
  <summary>Details</summary>
Motivation: 虽然对话轮流组织已经在多个领域得到研究，但特别是交流者使用的手势策略尚未在可用于机器学习的数据集中编码。需要填补这一空白。

Method: 开发了一种注释方法，将Frame2多模态数据集中的语义框注释丰富为包含对话轮流组织的语用框模型。该数据集包含已经对视频和文本中语义框进行注释的10集巴西电视剧。

Result: 结果确认了面对面对话中交流者使用手势作为传递、接受和保持对话轮流的工具，并发现了之前未被文档记录的某些手势变体。

Conclusion: 这些手势的使用来源于语用框架的概念化，涵盖心理空间、融合和概念隐喻。语用框注释有助于更深入理解人类认知和语言。

Abstract: This paper proposes a framework for modeling multimodal conversational turn
organization via the proposition of correlations between language and
interactive gestures, based on analysis as to how pragmatic frames are
conceptualized and evoked by communicators. As a means to provide evidence for
the analysis, we developed an annotation methodology to enrich a multimodal
dataset (annotated for semantic frames) with pragmatic frames modeling
conversational turn organization. Although conversational turn organization has
been studied by researchers from diverse fields, the specific strategies,
especially gestures used by communicators, had not yet been encoded in a
dataset that can be used for machine learning. To fill this gap, we enriched
the Frame2 dataset with annotations of gestures used for turn organization. The
Frame2 dataset features 10 episodes from the Brazilian TV series Pedro Pelo
Mundo annotated for semantic frames evoked in both video and text. This dataset
allowed us to closely observe how communicators use interactive gestures
outside a laboratory, in settings, to our knowledge, not previously recorded in
related literature. Our results have confirmed that communicators involved in
face-to-face conversation make use of gestures as a tool for passing, taking
and keeping conversational turns, and also revealed variations of some gestures
that had not been documented before. We propose that the use of these gestures
arises from the conceptualization of pragmatic frames, involving mental spaces,
blending and conceptual metaphors. In addition, our data demonstrate that the
annotation of pragmatic frames contributes to a deeper understanding of human
cognition and language.

</details>


### [50] [Topic-Guided Reinforcement Learning with LLMs for Enhancing Multi-Document Summarization](https://arxiv.org/abs/2509.09852)
*Chuyuan Li,Austin Xu,Shafiq Joty,Giuseppe Carenini*

Main category: cs.CL

TL;DR: 提出基于主题引导的强化学习方法，通过主题奖励机制在GRPO框架中提升多文档摘要的内容选择质量


<details>
  <summary>Details</summary>
Motivation: 解决多文档摘要中信息整合的挑战，虽然大语言模型在单文档摘要表现优异，但在多文档摘要仍有改进空间

Method: 使用主题标签明确提示模型，在GRPO框架中引入新颖的主题奖励来衡量生成摘要与源文档的主题对齐度

Result: 在Multi-News和Multi-XScience数据集上实验表明，该方法持续优于强基线模型

Conclusion: 利用主题线索在多文档摘要中具有显著效果，主题引导的强化学习方法能有效提升摘要质量

Abstract: A key challenge in Multi-Document Summarization (MDS) is effectively
integrating information from multiple sources while maintaining coherence and
topical relevance. While Large Language Models have shown impressive results in
single-document summarization, their performance on MDS still leaves room for
improvement. In this paper, we propose a topic-guided reinforcement learning
approach to improve content selection in MDS. We first show that explicitly
prompting models with topic labels enhances the informativeness of the
generated summaries. Building on this insight, we propose a novel topic reward
within the Group Relative Policy Optimization (GRPO) framework to measure topic
alignment between the generated summary and source documents. Experimental
results on the Multi-News and Multi-XScience datasets demonstrate that our
method consistently outperforms strong baselines, highlighting the
effectiveness of leveraging topical cues in MDS.

</details>


### [51] [Emulating Public Opinion: A Proof-of-Concept of AI-Generated Synthetic Survey Responses for the Chilean Case](https://arxiv.org/abs/2509.09871)
*Bastián González-Bustamante,Nando Verelst,Carla Cisternas*

Main category: cs.CL

TL;DR: 大语言模型生成的合成调查回答在智利公众意见调查中表现出艹异的性能，在信任问题上达到优秀水平，但在全面抓取公众意见细差方面仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成合成调查回答的可靠性，测试其能否减少测量和代表性错误，同时检测是否会复制训练数据中的社会定型和偏见。

Method: 使用128个提示-模型-问题三元组，生成189,696个合成计划，并在128个问题-子样本对中进行元分析，测试关键社会人口学维度上的偏见。评估模型包括OpenAI GPT系列、o系列推理模型以及Llama和Qwen。

Result: 1. 合成回答在信任问题上表现优异（F1分数和准确率>0.90）
2. GPT-4o、GPT-4o-mini和Llama 4 Maverick表现相似
3. 45-59岁反应者的合成-人类对齐度最高

Conclusion: LLM基于合成样本能大致近似概率样本的回答，但存在显著的项目级异质性。要抓取公众意见的完整细差仍需求谨慎的检验和分布测试以确保算法保真度和减少错误。

Abstract: Large Language Models (LLMs) offer promising avenues for methodological and
applied innovations in survey research by using synthetic respondents to
emulate human answers and behaviour, potentially mitigating measurement and
representation errors. However, the extent to which LLMs recover aggregate item
distributions remains uncertain and downstream applications risk reproducing
social stereotypes and biases inherited from training data. We evaluate the
reliability of LLM-generated synthetic survey responses against ground-truth
human responses from a Chilean public opinion probabilistic survey.
Specifically, we benchmark 128 prompt-model-question triplets, generating
189,696 synthetic profiles, and pool performance metrics (i.e., accuracy,
precision, recall, and F1-score) in a meta-analysis across 128
question-subsample pairs to test for biases along key sociodemographic
dimensions. The evaluation spans OpenAI's GPT family and o-series reasoning
models, as well as Llama and Qwen checkpoints. Three results stand out. First,
synthetic responses achieve excellent performance on trust items (F1-score and
accuracy > 0.90). Second, GPT-4o, GPT-4o-mini and Llama 4 Maverick perform
comparably on this task. Third, synthetic-human alignment is highest among
respondents aged 45-59. Overall, LLM-based synthetic samples approximate
responses from a probabilistic sample, though with substantial item-level
heterogeneity. Capturing the full nuance of public opinion remains challenging
and requires careful calibration and additional distributional tests to ensure
algorithmic fidelity and reduce errors.

</details>


### [52] [Large Language Models Meet Legal Artificial Intelligence: A Survey](https://arxiv.org/abs/2509.09969)
*Zhitian Hou,Zihan Ye,Nanli Zeng,Tianyong Hao,Kun Zeng*

Main category: cs.CL

TL;DR: 这篇论文系统性评估了大语言模型在法律人工智能领域的应用，包括16个法律LLM系列、47个框架、15个测试集和29个数据集，并分析了挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 促进大语言模型在法律领域的研究和应用发展，提高法律任务的效率和准确性。

Method: 通过系统性评估法律LLM模型和框架，收集和分析多个测试集和数据集来评估不同的法律能力。

Result: 提供了丰富的资源汇总，包括16个法律LLM系列、47个框架、15个测试集和29个数据集，为该领域提供了系统性的引导。

Conclusion: 论文为初学者提供了系统的入门介绍，并展望了法律LLM领域的挑战和未来研究方向，期待能够推动该领域的进一步发展。

Abstract: Large Language Models (LLMs) have significantly advanced the development of
Legal Artificial Intelligence (Legal AI) in recent years, enhancing the
efficiency and accuracy of legal tasks. To advance research and applications of
LLM-based approaches in legal domain, this paper provides a comprehensive
review of 16 legal LLMs series and 47 LLM-based frameworks for legal tasks, and
also gather 15 benchmarks and 29 datasets to evaluate different legal
capabilities. Additionally, we analyse the challenges and discuss future
directions for LLM-based approaches in the legal domain. We hope this paper
provides a systematic introduction for beginners and encourages future research
in this field. Resources are available at
https://github.com/ZhitianHou/LLMs4LegalAI.

</details>


### [53] [CMHG: A Dataset and Benchmark for Headline Generation of Minority Languages in China](https://arxiv.org/abs/2509.09990)
*Guixian Xu,Zeli Su,Ziyin Zhang,Jianing Liu,XU Han,Ting Zhang,Yushuang Dong*

Main category: cs.CL

TL;DR: 中国少数民族语言标题生成数据集CMHG的提出，包含藏语10万条、维吾尔语和蒙古语各5000条数据，解决少数民族语言语料库缺乏问题


<details>
  <summary>Details</summary>
Motivation: 中国少数民族语言（如藏语、维吾尔语、蒙古语）因其独特的写作系统与国际标准不一致，导致相关语料库严重缺乏，特别是在监督学习任务如标题生成方面

Method: 提出中国少数民族标题生成（CMHG）数据集，包含藏语10万条、维吾尔语和蒙古语各5000条数据，并由本土语者注释构建了高质量测试集

Result: 构建了专门用于少数民族语言标题生成任务的大规模数据集，为该领域提供了量化评估标准

Conclusion: CMHG数据集将成为中国少数民族语言标题生成研究的重要资源，有助于推动相关基准测试的发展

Abstract: Minority languages in China, such as Tibetan, Uyghur, and Traditional
Mongolian, face significant challenges due to their unique writing systems,
which differ from international standards. This discrepancy has led to a severe
lack of relevant corpora, particularly for supervised tasks like headline
generation. To address this gap, we introduce a novel dataset, Chinese Minority
Headline Generation (CMHG), which includes 100,000 entries for Tibetan, and
50,000 entries each for Uyghur and Mongolian, specifically curated for headline
generation tasks. Additionally, we propose a high-quality test set annotated by
native speakers, designed to serve as a benchmark for future research in this
domain. We hope this dataset will become a valuable resource for advancing
headline generation in Chinese minority languages and contribute to the
development of related benchmarks.

</details>


### [54] [Unsupervised Hallucination Detection by Inspecting Reasoning Processes](https://arxiv.org/abs/2509.10004)
*Ponhvoan Srey,Xiaobao Wu,Anh Tuan Luu*

Main category: cs.CL

TL;DR: IRIS是一个无监督幻觉检测框架，利用LLM内部表征来检测生成内容的事实正确性，无需人工标注，计算成本低且适用于实时检测


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法依赖与事实正确性无关的代理信号，导致检测偏向表面特征，限制了跨数据集和场景的泛化能力

Method: 通过提示LLM仔细验证给定陈述的真实性，获取其上下文嵌入作为训练特征，并将每个响应的不确定性作为真实性的软伪标签

Result: 实验结果表明IRIS consistently outperforms existing unsupervised methods

Conclusion: IRIS是一个完全无监督、计算成本低的方法，即使在少量训练数据下也能良好工作，适用于实时幻觉检测

Abstract: Unsupervised hallucination detection aims to identify hallucinated content
generated by large language models (LLMs) without relying on labeled data.
While unsupervised methods have gained popularity by eliminating
labor-intensive human annotations, they frequently rely on proxy signals
unrelated to factual correctness. This misalignment biases detection probes
toward superficial or non-truth-related aspects, limiting generalizability
across datasets and scenarios. To overcome these limitations, we propose IRIS,
an unsupervised hallucination detection framework, leveraging internal
representations intrinsic to factual correctness. IRIS prompts the LLM to
carefully verify the truthfulness of a given statement, and obtain its
contextualized embedding as informative features for training. Meanwhile, the
uncertainty of each response is considered a soft pseudolabel for truthfulness.
Experimental results demonstrate that IRIS consistently outperforms existing
unsupervised methods. Our approach is fully unsupervised, computationally low
cost, and works well even with few training data, making it suitable for
real-time detection.

</details>


### [55] [Multi-Intent Recognition in Dialogue Understanding: A Comparison Between Smaller Open-Source LLMs](https://arxiv.org/abs/2509.10010)
*Adnan Ahmad,Philine Kowol,Stefan Hillmann,Sebastian Möller*

Main category: cs.CL

TL;DR: 本文对开源大语言模型在多标签意图分类任务上的性能进行了全面分析，比较了LLama2-7B、Mistral-7B和Yi-6B在MultiWOZ 2.1数据集上的few-shot表现，并与BERT监督学习基线进行对比。


<details>
  <summary>Details</summary>
Motivation: 研究开源大语言模型在消费级硬件上处理复杂多意图对话分类任务的有效性，为任务导向聊天机器人的自然语言理解提供实用框架。

Method: 使用MultiWOZ 2.1数据集，在few-shot设置下（提示中包含20个示例）测试三个开源LLM，并与BERT监督分类器进行性能对比，评估指标包括准确率、精确率、召回率、F1分数等。

Result: Mistral-7B在14个意图类别中的11个上F分数表现最佳，加权平均F1为0.50，具有较低的Hamming Loss和较高的Jaccard相似度。但BERT监督分类器的性能仍优于最佳few-shot生成式LLM。

Conclusion: 开源LLM在多标签意图分类中展现潜力，Mistral-7B在few-shot设置中表现最佳，但监督学习方法仍具有性能优势，为复杂多意图对话检测提供了实用框架。

Abstract: In this paper, we provide an extensive analysis of multi-label intent
classification using Large Language Models (LLMs) that are open-source,
publicly available, and can be run in consumer hardware. We use the MultiWOZ
2.1 dataset, a benchmark in the dialogue system domain, to investigate the
efficacy of three popular open-source pre-trained LLMs, namely LLama2-7B-hf,
Mistral-7B-v0.1, and Yi-6B. We perform the classification task in a few-shot
setup, giving 20 examples in the prompt with some instructions. Our approach
focuses on the differences in performance of these models across several
performance metrics by methodically assessing these models on multi-label
intent classification tasks. Additionally, we compare the performance of the
instruction-based fine-tuning approach with supervised learning using the
smaller transformer model BertForSequenceClassification as a baseline. To
evaluate the performance of the models, we use evaluation metrics like
accuracy, precision, and recall as well as micro, macro, and weighted F1 score.
We also report the inference time, VRAM requirements, etc. The Mistral-7B-v0.1
outperforms two other generative models on 11 intent classes out of 14 in terms
of F-Score, with a weighted average of 0.50. It also has relatively lower
Humming Loss and higher Jaccard Similarity, making it the winning model in the
few-shot setting. We find BERT based supervised classifier having superior
performance compared to the best performing few-shot generative LLM. The study
provides a framework for small open-source LLMs in detecting complex
multi-intent dialogues, enhancing the Natural Language Understanding aspect of
task-oriented chatbots.

</details>


### [56] [Linguistic trajectories of bipolar disorder on social media](https://arxiv.org/abs/2509.10035)
*Laurin Plank,Armin Zlomuzica*

Main category: cs.CL

TL;DR: 通过分析社交媒体语言，研究发现双相情感障碍诊断前后的语言变化轨迹，包括情绪涉及、养感同症、季节性情绪变化等特征


<details>
  <summary>Details</summary>
Motivation: 语言是情感障碍的重要标记物，但临床评估规模有限，需要利用社交媒体进行大规模监测

Method: 开发方法确定用户诊断时间，分析发现双相障碍前3年到诊断后21年的语言轨迹，与单相郁郁和健康对照组进行对比

Result: 发现BD诊断伴随渐激性语言改变，反映情绪干扰、精神养感、物质滥用等。诊断后两十年内呈现周期性情绪语言变化，有明显的12个月周期性，可能与季节性情绪发作相关

Conclusion: 研究证明了语言在BD急性期和慢性期的改变，验证了利用社交媒体进行可扩展心理健康监测的方法

Abstract: Language provides valuable markers of affective disorders such as bipolar
disorder (BD), yet clinical assessments remain limited in scale. In response,
analyses of social media (SM) language have gained prominence due to their high
temporal resolution and longitudinal scope. Here, we introduce a method to
determine the timing of users' diagnoses and apply it to study language
trajectories from 3 years before to 21 years after BD diagnosis - contrasted
with uses reporting unipolar depression (UD) and non-affected users (HC). We
show that BD diagnosis is accompanied by pervasive linguistic alterations
reflecting mood disturbance, psychiatric comorbidity, substance abuse,
hospitalization, medical comorbidities, unusual thought content, and
disorganized thought. We further observe recurring mood-related language
changes across two decades after the diagnosis, with a pronounced 12-month
periodicity suggestive of seasonal mood episodes. Finally, trend-level evidence
suggests an increased periodicity in users estimated to be female. In sum, our
findings provide evidence for language alterations in the acute and chronic
phase of BD. This validates and extends recent efforts leveraging SM for
scalable monitoring of mental health.

</details>


### [57] [!MSA at BAREC Shared Task 2025: Ensembling Arabic Transformers for Readability Assessment](https://arxiv.org/abs/2509.10040)
*Mohamed Basem,Mohamed Younes,Seif Ahmed,Abdelrahman Moustafa*

Main category: cs.CL

TL;DR: MSA团队在BAREC 2025阿拉伯语细粒度可读性评估任务中获胜，使用四个Transformer模型的置信度加权集成方法，通过数据增强和后处理技术，在句子和文档级别分别达到87.5%和87.4%的QWK分数。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语可读性评估中的类别不平衡和数据稀缺问题，提升细粒度评估性能。

Method: 使用AraBERTv2、AraELECTRA、MARBERT和CAMeLBERT四个Transformer模型集成，采用不同损失函数微调，结合加权训练、数据预处理、SAMER语料库重标注和Gemini 2.5 Flash生成的合成数据增强，以及针对预测分布偏差的后处理。

Result: 在六个赛道中获得第一名，后处理带来6.3%的QWK提升，句子级别QWK达到87.5%，文档级别达到87.4%。

Conclusion: 模型和损失函数的多样性、置信度信息融合以及智能数据增强对阿拉伯语可读性预测具有强大效果。

Abstract: We present MSAs winning system for the BAREC 2025 Shared Task on fine-grained
Arabic readability assessment, achieving first place in six of six tracks. Our
approach is a confidence-weighted ensemble of four complementary transformer
models (AraBERTv2, AraELECTRA, MARBERT, and CAMeLBERT) each fine-tuned with
distinct loss functions to capture diverse readability signals. To tackle
severe class imbalance and data scarcity, we applied weighted training,
advanced preprocessing, SAMER corpus relabeling with our strongest model, and
synthetic data generation via Gemini 2.5 Flash, adding about 10,000 rare-level
samples. A targeted post-processing step corrected prediction distribution
skew, delivering a 6.3 percent Quadratic Weighted Kappa (QWK) gain. Our system
reached 87.5 percent QWK at the sentence level and 87.4 percent at the document
level, demonstrating the power of model and loss diversity, confidence-informed
fusion, and intelligent augmentation for robust Arabic readability prediction.

</details>


### [58] [Established Psychometric vs. Ecologically Valid Questionnaires: Rethinking Psychological Assessments in Large Language Models](https://arxiv.org/abs/2509.10078)
*Dongmin Choi,Woojung Song,Jongwook Han,Eun-Ju Lee,Yohan Jo*

Main category: cs.CL

TL;DR: 研究对比了传统心理测量问卷和生态有效问卷在LLM人格测量上的差异，发现传统方法存在多项限制，建议避免使用


<details>
  <summary>Details</summary>
Motivation: 现有研究将人类心理测量问卷直接应用于LLMs，但缺乏生态有效性，需要明确两类问卷的差异及其意义

Method: 进行综合性对比分析，比较传统心理测量问卷和生态有效问卷在LLM人格测量上的表现差异

Result: 发现传统问卷：(1)与生态有效方法结果差异较大，偏离用户查询语境中的心理特征；(2)项目数量不足导致测量不稳定；(3)会产生LLM拥有稳定构建的误导印象；(4)对人设提示的LLM产生夸张的人格描述

Conclusion: 建议谨慎使用传统心理测量问卷来测量LLMs的人格特征，需要考虑生态有效性问题

Abstract: Researchers have applied established psychometric questionnaires (e.g., BFI,
PVQ) to measure the personality traits and values reflected in the responses of
Large Language Models (LLMs). However, concerns have been raised about applying
these human-designed questionnaires to LLMs. One such concern is their lack of
ecological validity--the extent to which survey questions adequately reflect
and resemble real-world contexts in which LLMs generate texts in response to
user queries. However, it remains unclear how established questionnaires and
ecologically valid questionnaires differ in their outcomes, and what insights
these differences may provide. In this paper, we conduct a comprehensive
comparative analysis of the two types of questionnaires. Our analysis reveals
that established questionnaires (1) yield substantially different profiles of
LLMs from ecologically valid ones, deviating from the psychological
characteristics expressed in the context of user queries, (2) suffer from
insufficient items for stable measurement, (3) create misleading impressions
that LLMs possess stable constructs, and (4) yield exaggerated profiles for
persona-prompted LLMs. Overall, our work cautions against the use of
established psychological questionnaires for LLMs. Our code will be released
upon publication.

</details>


### [59] [Querying Climate Knowledge: Semantic Retrieval for Scientific Discovery](https://arxiv.org/abs/2509.10087)
*Mustapha Adamu,Qi Zhang,Huitong Pan,Longin Jan Latecki,Eduard C. Dragut*

Main category: cs.CL

TL;DR: 构建了一个面向气候科学领域的知识图谱，支持语义查询和LLM集成，帮助研究人员发现模型、数据集和区域之间的精确联系


<details>
  <summary>Details</summary>
Motivation: 气候科学文献的复杂性和数量不断增加，使得研究人员难以跨模型、数据集、区域和变量找到相关信息

Method: 从气候出版物和更广泛的科学文本构建领域特定知识图谱，支持结构化语义查询和Cypher查询，并与大型语言模型在RAG系统中集成

Result: 知识图谱能够回答具体问题，如哪些模型在特定区域经过验证，哪些数据集常用于特定遥相关模式

Conclusion: 这项工作超越了知识图谱构建本身，展示了其对气候研究人员、模型开发者等依赖准确情境科学信息人员的实际价值

Abstract: The growing complexity and volume of climate science literature make it
increasingly difficult for researchers to find relevant information across
models, datasets, regions, and variables. This paper introduces a
domain-specific Knowledge Graph (KG) built from climate publications and
broader scientific texts, aimed at improving how climate knowledge is accessed
and used. Unlike keyword based search, our KG supports structured, semantic
queries that help researchers discover precise connections such as which models
have been validated in specific regions or which datasets are commonly used
with certain teleconnection patterns. We demonstrate how the KG answers such
questions using Cypher queries, and outline its integration with large language
models in RAG systems to improve transparency and reliability in
climate-related question answering. This work moves beyond KG construction to
show its real world value for climate researchers, model developers, and others
who rely on accurate, contextual scientific information.

</details>


### [60] [Arabic Large Language Models for Medical Text Generation](https://arxiv.org/abs/2509.10095)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Ammar Mohammed*

Main category: cs.CL

TL;DR: 该研究通过微调大型语言模型（如Mistral-7B、LLaMA-2-7B和GPT-2）来生成阿拉伯语医疗文本，旨在解决医院管理系统中的实时医疗建议需求，特别是在处理非正规输入和 underrepresented 语言方面。微调后的Mistral-7B模型在评估中表现最佳，平均BERT Score在精确率、召回率和F1分数上分别达到68.5%、69.08%和68.5%。


<details>
  <summary>Details</summary>
Motivation: 现有医院管理系统往往无法提供准确、实时的医疗建议，尤其是在处理非正规输入和 underrepresented 语言（如阿拉伯语）时存在局限。全球医疗系统面临 overcrowding、资源有限和紧急医疗可用性差等挑战，需要更高效的解决方案。

Method: 研究收集了来自社交媒体平台的独特数据集，包含患者与医生之间的真实医疗对话。数据集经过清理和预处理以处理多种阿拉伯语方言。然后对Mistral-7B-Instruct-v0.2、LLaMA-2-7B和GPT-2 Medium等先进生成模型进行微调，优化系统生成可靠医疗文本的能力。

Result: 评估结果显示，微调后的Mistral-7B模型表现最佳，平均BERT Score在精确率、召回率和F1分数上分别达到68.5%、69.08%和68.5%。比较基准测试和定性评估验证了系统能够对非正式输入产生连贯且相关的医疗回复。

Conclusion: 该研究展示了生成式人工智能在医院管理系统中的潜力，为全球医疗挑战（特别是在语言和文化多样性环境中）提供了可扩展和适应性强的解决方案。微调LLMs的方法能够有效处理阿拉伯语医疗文本生成，改善医疗服务的可及性和质量。

Abstract: Efficient hospital management systems (HMS) are critical worldwide to address
challenges such as overcrowding, limited resources, and poor availability of
urgent health care. Existing methods often lack the ability to provide
accurate, real-time medical advice, particularly for irregular inputs and
underrepresented languages. To overcome these limitations, this study proposes
an approach that fine-tunes large language models (LLMs) for Arabic medical
text generation. The system is designed to assist patients by providing
accurate medical advice, diagnoses, drug recommendations, and treatment plans
based on user input. The research methodology required the collection of a
unique dataset from social media platforms, capturing real-world medical
conversations between patients and doctors. The dataset, which includes patient
complaints together with medical advice, was properly cleaned and preprocessed
to account for multiple Arabic dialects. Fine-tuning state-of-the-art
generative models, such as Mistral-7B-Instruct-v0.2, LLaMA-2-7B, and GPT-2
Medium, optimized the system's ability to generate reliable medical text.
Results from evaluations indicate that the fine-tuned Mistral-7B model
outperformed the other models, achieving average BERT (Bidirectional Encoder
Representations from Transformers) Score values in precision, recall, and
F1-scores of 68.5\%, 69.08\%, and 68.5\%, respectively. Comparative
benchmarking and qualitative assessments validate the system's ability to
produce coherent and relevant medical replies to informal input. This study
highlights the potential of generative artificial intelligence (AI) in
advancing HMS, offering a scalable and adaptable solution for global healthcare
challenges, especially in linguistically and culturally diverse environments.

</details>


### [61] [Scaling Arabic Medical Chatbots Using Synthetic Data: Enhancing Generative AI with Synthetic Patient Records](https://arxiv.org/abs/2509.10108)
*Abdulrahman Allam,Seif Ahmed,Ali Hamdi,Khaled Shaban*

Main category: cs.CL

TL;DR: 通过ChatGPT-4o和Gemini生成合成数据扩充阿拉伯语医疗数据集，将训练数据从2万扩充到10万条，提升了医疗聊天机器人的性能和准确性


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语医疗数据集稀缺，导致医疗聊天机器发展受限，需要找到可扩展的数据增强方案

Method: 使用ChatGPT-4o和Gemini 2.5 Pro生成80,000条合成数据，经过语义筛选和手动验证，对Mistral-7B等五个大语言模型进行微调

Result: ChatGPT-4o生成的数据在所有模型中都导致更高的F1分数和更少的幻觉现象

Conclusion: 合成数据增强是低资源医疗NLP领域的可行解决方案，为更包容、可扩展和准确的阿拉伯语健康聊天机器开辟了道路

Abstract: The development of medical chatbots in Arabic is significantly constrained by
the scarcity of large-scale, high-quality annotated datasets. While prior
efforts compiled a dataset of 20,000 Arabic patient-doctor interactions from
social media to fine-tune large language models (LLMs), model scalability and
generalization remained limited. In this study, we propose a scalable synthetic
data augmentation strategy to expand the training corpus to 100,000 records.
Using advanced generative AI systems ChatGPT-4o and Gemini 2.5 Pro we generated
80,000 contextually relevant and medically coherent synthetic question-answer
pairs grounded in the structure of the original dataset. These synthetic
samples were semantically filtered, manually validated, and integrated into the
training pipeline. We fine-tuned five LLMs, including Mistral-7B and AraGPT2,
and evaluated their performance using BERTScore metrics and expert-driven
qualitative assessments. To further analyze the effectiveness of synthetic
sources, we conducted an ablation study comparing ChatGPT-4o and
Gemini-generated data independently. The results showed that ChatGPT-4o data
consistently led to higher F1-scores and fewer hallucinations across all
models. Overall, our findings demonstrate the viability of synthetic
augmentation as a practical solution for enhancing domain-specific language
models in-low resource medical NLP, paving the way for more inclusive,
scalable, and accurate Arabic healthcare chatbot systems.

</details>


### [62] [Prominence-aware automatic speech recognition for conversational speech](https://arxiv.org/abs/2509.10116)
*Julian Linke,Barbara Schuppler*

Main category: cs.CL

TL;DR: 该论文研究了结合重音检测和语音识别的显著性感知自动语音识别系统，针对奥地利德语对话开发了基于wav2vec2的重音检测器，并训练了同时转录单词和重音水平的ASR系统。


<details>
  <summary>Details</summary>
Motivation: 研究如何将韵律重音信息整合到自动语音识别中，以提升对奥地利德语对话的理解能力，为语言学和韵律感知对话系统提供潜在应用。

Method: 1) 微调wav2vec2模型开发词级重音检测器；2) 使用检测器自动标注大型语料库中的韵律重音；3) 基于标注训练同时转录单词和重音水平的显著性感知ASR系统。

Result: 整合重音信息后ASR性能与基线系统相当，在识别正确的语句中重音检测准确率达到85.53%。基于transformer的模型能有效编码韵律信息。

Conclusion: 证明了transformer模型能有效编码韵律信息，为韵律增强的ASR系统提供了新贡献，在语言学研究和韵律感知对话系统中具有应用潜力。

Abstract: This paper investigates prominence-aware automatic speech recognition (ASR)
by combining prominence detection and speech recognition for conversational
Austrian German. First, prominence detectors were developed by fine-tuning
wav2vec2 models to classify word-level prominence. The detector was then used
to automatically annotate prosodic prominence in a large corpus. Based on those
annotations, we trained novel prominence-aware ASR systems that simultaneously
transcribe words and their prominence levels. The integration of prominence
information did not change performance compared to our baseline ASR system,
while reaching a prominence detection accuracy of 85.53% for utterances where
the recognized word sequence was correct. This paper shows that
transformer-based models can effectively encode prosodic information and
represents a novel contribution to prosody-enhanced ASR, with potential
applications for linguistic research and prosody-informed dialogue systems.

</details>


### [63] [Population-Aligned Persona Generation for LLM-based Social Simulation](https://arxiv.org/abs/2509.10127)
*Zhengyu Hu,Zheyuan Xiao,Max Xiong,Yuxuan Lei,Tianfu Wang,Jianxun Lian,Kaize Ding,Ziang Xiao,Nicholas Jing Yuan,Xing Xie*

Main category: cs.CL

TL;DR: 本文提出了一种系统化框架，通过利用大语言模型从社交媒体数据生成身份角色，经过质量评估和重要性采样，实现与实际人群心理特征分布对齐的人物集合，最终通过任务特定模块适配到具体模拟场景。


<details>
  <summary>Details</summary>
Motivation: 目前大语言模型基于社会模拟研究主要关注机器人框架和模拟环境设计，忽视了人物生成的复杂性和偏差问题。本文旨在解决如何构建能真实代表实际人群多样性和分布的人物集合的挑战。

Method: 1. 利用LLM从长期社交媒体数据生成故事化人物
2. 通过严格的质量评估筛选掉低保真度的人物档案
3. 采用重要性采样技术实现全局层面与参考心理测量分布（如大五人格特质）的对齐
4. 通过任务特定模块将全局对齐的人物集适配到目标子人群

Result: 广泛实验表明，该方法显著减少了人群层面的偏差，能够为广泛的研究和政策应用提供准确、灵活的社会模拟能力。

Conclusion: 本文提出的系统化框架能够生成高质量、与人群分布对齐的人物集合，有效解决了现有LLM基于社会模拟中人物生成的偏差问题，为计算社会科学领域提供了更准确、灵活的模拟能力。

Abstract: Recent advances in large language models (LLMs) have enabled human-like
social simulations at unprecedented scale and fidelity, offering new
opportunities for computational social science. A key challenge, however, is
the construction of persona sets that authentically represent the diversity and
distribution of real-world populations. Most existing LLM-based social
simulation studies focus primarily on designing agentic frameworks and
simulation environments, often overlooking the complexities of persona
generation and the potential biases introduced by unrepresentative persona
sets. In this paper, we propose a systematic framework for synthesizing
high-quality, population-aligned persona sets for LLM-driven social simulation.
Our approach begins by leveraging LLMs to generate narrative personas from
long-term social media data, followed by rigorous quality assessment to filter
out low-fidelity profiles. We then apply importance sampling to achieve global
alignment with reference psychometric distributions, such as the Big Five
personality traits. To address the needs of specific simulation contexts, we
further introduce a task-specific module that adapts the globally aligned
persona set to targeted subpopulations. Extensive experiments demonstrate that
our method significantly reduces population-level bias and enables accurate,
flexible social simulation for a wide range of research and policy
applications.

</details>


### [64] [Towards Reliable and Interpretable Document Question Answering via VLMs](https://arxiv.org/abs/2509.10129)
*Alessio Chen,Simone Giovannini,Andrea Gemelli,Fabio Coppini,Simone Marinai*

Main category: cs.CL

TL;DR: DocExplainerV0是一个即插即用的边界框预测模块，将答案生成与空间定位解耦，解决了现有视觉语言模型在文档中精确定位答案的挑战。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型在文档理解方面表现出色，但准确地在文档中定位答案仍然是一个主要挑战，这限制了模型的可解释性和实际应用。

Method: 引入DocExplainerV0模块，该模块与现有VLM解耦，专门负责边界框预测和空间定位，适用于包括专有系统在内的各种模型。

Result: 系统评估显示文本准确性和空间定位之间存在显著差距，正确答案往往缺乏可靠的空间定位。该框架为未来研究建立了基准。

Conclusion: DocExplainerV0为解决文档信息提取中的空间定位问题提供了有效方案，为开发更可解释和鲁棒的文档理解模型奠定了基础。

Abstract: Vision-Language Models (VLMs) have shown strong capabilities in document
understanding, particularly in identifying and extracting textual information
from complex documents. Despite this, accurately localizing answers within
documents remains a major challenge, limiting both interpretability and
real-world applicability. To address this, we introduce
\textit{DocExplainerV0}, a plug-and-play bounding-box prediction module that
decouples answer generation from spatial localization. This design makes it
applicable to existing VLMs, including proprietary systems where fine-tuning is
not feasible. Through systematic evaluation, we provide quantitative insights
into the gap between textual accuracy and spatial grounding, showing that
correct answers often lack reliable localization. Our standardized framework
highlights these shortcomings and establishes a benchmark for future research
toward more interpretable and robust document information extraction VLMs.

</details>


### [65] [Benchmark of stylistic variation in LLM-generated texts](https://arxiv.org/abs/2509.10179)
*Jiří Milička,Anna Marklová,Václav Cvrček*

Main category: cs.CL

TL;DR: 研究使用Biber多维分析法比较人类与LLM生成文本的语基变异，在英语和捷克语中识别了AI与人类文本的系统性差异，并建立了可解释性测量基准。


<details>
  <summary>Details</summary>
Motivation: 调查大语言模型与人类在文本语基特征上的系统性差异，特别是在非英语语言中的表现，以弥补相关研究的空白。

Method: 采用Biber多维分析法，使用AI-Brown和AI-Koditex语料库分别分析英语和捷克语文本，测试16个前沿LLM模型在不同设置和提示下的表现，重点比较基础模型与指令微调模型。

Result: 识别了LLM与人类文本在多维度上的显著差异，建立了可用于模型比较和排名的解释性基准测量指标。

Conclusion: 研究提供了一种系统性方法来量化和评估LLM生成文本与人类文本的语基差异，为AI文本生成质量评估提供了新的视角和工具。

Abstract: This study investigates the register variation in texts written by humans and
comparable texts produced by large language models (LLMs). Biber's
multidimensional analysis (MDA) is applied to a sample of human-written texts
and AI-created texts generated to be their counterparts to find the dimensions
of variation in which LLMs differ most significantly and most systematically
from humans. As textual material, a new LLM-generated corpus AI-Brown is used,
which is comparable to BE-21 (a Brown family corpus representing contemporary
British English). Since all languages except English are underrepresented in
the training data of frontier LLMs, similar analysis is replicated on Czech
using AI-Koditex corpus and Czech multidimensional model. Examined were 16
frontier models in various settings and prompts, with emphasis placed on the
difference between base models and instruction-tuned models. Based on this, a
benchmark is created through which models can be compared with each other and
ranked in interpretable dimensions.

</details>


### [66] [Incongruent Positivity: When Miscalibrated Positivity Undermines Online Supportive Conversations](https://arxiv.org/abs/2509.10184)
*Leen Almajed,Abeer ALdayel*

Main category: cs.CL

TL;DR: 论文研究情感支持对话中不恰当的积极回应问题，分析了人类和LLM生成回复中的不协调积极性现象，特别是在高风险情境下LLM更容易产生不现实的积极回应。


<details>
  <summary>Details</summary>
Motivation: 研究情感支持对话中良好意图的积极回应有时会产生反效果，导致回应显得轻视、最小化或不切实际的乐观，这种现象在人类和LLM生成回复中都存在。

Method: 收集Reddit真实用户-助手对话，按情感强度分类为轻度(关系紧张和一般建议)和重度(悲伤和焦虑对话)，使用LLM生成额外回复，微调LLM并开发弱监督多标签分类器集成。

Result: LLM在高风险情境下更容易通过轻视和最小化语气表现出不现实的积极性，开发的分类器在检测不协调积极性类型方面表现改善。

Conclusion: 需要超越生成通用积极回应，研究协调的支持措施来平衡积极情感与情感认同，为构建情境感知和保持信任的在线对话系统铺平道路。

Abstract: In emotionally supportive conversations, well-intended positivity can
sometimes misfire, leading to responses that feel dismissive, minimizing, or
unrealistically optimistic. We examine this phenomenon of incongruent
positivity as miscalibrated expressions of positive support in both human and
LLM generated responses. To this end, we collected real user-assistant
dialogues from Reddit across a range of emotional intensities and generated
additional responses using large language models for the same context. We
categorize these conversations by intensity into two levels: Mild, which covers
relationship tension and general advice, and Severe, which covers grief and
anxiety conversations. This level of categorization enables a comparative
analysis of how supportive responses vary across lower and higher stakes
contexts. Our analysis reveals that LLMs are more prone to unrealistic
positivity through dismissive and minimizing tone, particularly in high-stakes
contexts. To further study the underlying dimensions of this phenomenon, we
finetune LLMs on datasets with strong and weak emotional reactions. Moreover,
we developed a weakly supervised multilabel classifier ensemble (DeBERTa and
MentalBERT) that shows improved detection of incongruent positivity types
across two sorts of concerns (Mild and Severe). Our findings shed light on the
need to move beyond merely generating generic positive responses and instead
study the congruent support measures to balance positive affect with emotional
acknowledgment. This approach offers insights into aligning large language
models with affective expectations in the online supportive dialogue, paving
the way toward context-aware and trust preserving online conversation systems.

</details>


### [67] [Beyond Token Limits: Assessing Language Model Performance on Long Text Classification](https://arxiv.org/abs/2509.10199)
*Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille*

Main category: cs.CL

TL;DR: 本文比较了多种语言模型在处理长文本分类任务时的表现，发现专门为长文本设计的Longformer模型并无明显优势，开源模型表现优于GPT变体，类别间的支持度和内容重叠是影响长文本分类性能的关键因素。


<details>
  <summary>Details</summary>
Motivation: 解决BERT等主流语言模型在处理长文本（如数百页的法律草案）时的输入长度限制问题，这些模型通常只能处理512个token，无法满足长文本分类任务的需求。

Method: 在5种语言上实验比较了XLM-RoBERTa、Longformer、GPT-3.5和GPT-4模型，使用比较议程项目的21个政策主题标签进行多类分类任务。

Result: 专门为长文本预训练的Longformer模型没有表现出明显优势；开源模型的表现优于GPT变体；类别间的支持度和内容重叠对长文本分类性能有重要影响。

Conclusion: 对于长文本分类任务，专门的长文本模型不一定具有优势，开源模型可能表现更好，且分类性能受到类别间相似性的显著影响。

Abstract: The most widely used large language models in the social sciences (such as
BERT, and its derivatives, e.g. RoBERTa) have a limitation on the input text
length that they can process to produce predictions. This is a particularly
pressing issue for some classification tasks, where the aim is to handle long
input texts. One such area deals with laws and draft laws (bills), which can
have a length of multiple hundred pages and, therefore, are not particularly
amenable for processing with models that can only handle e.g. 512 tokens. In
this paper, we show results from experiments covering 5 languages with
XLM-RoBERTa, Longformer, GPT-3.5, GPT-4 models for the multiclass
classification task of the Comparative Agendas Project, which has a codebook of
21 policy topic labels from education to health care. Results show no
particular advantage for the Longformer model, pre-trained specifically for the
purposes of handling long inputs. The comparison between the GPT variants and
the best-performing open model yielded an edge for the latter. An analysis of
class-level factors points to the importance of support and substance overlaps
between specific categories when it comes to performance on long text inputs.

</details>


### [68] [SI-FACT: Mitigating Knowledge Conflict via Self-Improving Faithfulness-Aware Contrastive Tuning](https://arxiv.org/abs/2509.10208)
*Shengqiang Fu*

Main category: cs.CL

TL;DR: 基于对比学习的自我改进框架SI FACT，通过自动生成对比训练数据，提升LLM在知识冲突任务中的上下文忠实性，减少对参数化知识的依赖


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在知识密集任务中更偏向依赖内部参数化知识而非提供的上下文，导致不忠实响应的问题

Method: 提出SI FACT框架：使用自指导机制自动生成高质量对比学习数据（anchor、正样本、负样本），通过对比学习让模型在表征空间中拉近忠实响应并推开不忠实响应

Result: 在ECARE KRE和COSE KRE评测集上，基于Llama3 8B Instruct的SI FACT模型将上下文回归率提升6.2%，显著减少了对内部记忆的依赖

Conclusion: SI FACT框架在提升LLM上下文忠实性方面具有强有力效果和高数据效率，为构建更主动可靠的语言模型提供了实用途径

Abstract: Large Language Models often generate unfaithful responses in knowledge
intensive tasks due to knowledge conflict,that is,a preference for relying on
internal parametric knowledge rather than the provided context.To address this
issue,we propose a novel self improving framework,Self Improving Faithfulness
Aware Contrastive Tuning.The framework uses a self instruct mechanism that
allows the base LLM to automatically generate high quality,structured
contrastive learning data,including anchor samples,semantically equivalent
positive samples,and negative samples simulating unfaithful scenarios.This
approach significantly reduces the cost of manual
annotation.Subsequently,contrastive learning is applied to train the
model,enabling it to pull faithful responses closer and push unfaithful
responses farther apart in the representation space.Experiments on knowledge
conflict evaluation benchmarks ECARE KRE and COSE KRE show that the SI FACT
model based on Llama3 8B Instruct improves the Contextual Recall Rate by 6.2%
over the best baseline method,while significantly reducing dependence on
internal memory.The results indicate that SI FACT provides strong effectiveness
and high data efficiency in enhancing the contextual faithfulness of
LLMs,offering a practical pathway toward building more proactive and
trustworthy language models.

</details>


### [69] [Dropping Experts, Recombining Neurons: Retraining-Free Pruning for Sparse Mixture-of-Experts LLMs](https://arxiv.org/abs/2509.10377)
*Yixiao Zhou,Ziyu Zhao,Dongzhou Cheng,zhiliang wu,Jie Gui,Yi Yang,Fei Wu,Yu Cheng,Hehe Fan*

Main category: cs.CL

TL;DR: DERN是一个无需重新训练的任务无关框架，通过专家剪枝和神经元重组来减少稀疏混合专家模型的内存使用，在50%专家稀疏度下性能提升超过5%


<details>
  <summary>Details</summary>
Motivation: 稀疏混合专家模型虽然计算效率高，但仍需加载所有专家参数，导致内存使用高和部署困难。现有方法主要关注专家级操作，忽视了神经元级结构

Method: DERN采用三步框架：1)基于路由器统计剪枝冗余专家；2)将专家分解为神经元级片段并分配到最兼容的保留专家；3)在保留专家内合并片段构建紧凑表示

Result: 在Mixtral、Qwen和DeepSeek模型上的实验显示，在50%专家稀疏度下，常识推理和MMLU基准性能提升超过5%，同时大幅减少专家数量和内存使用

Conclusion: DERN有效解决了专家间神经元级语义冲突问题，无需额外训练即可显著提升模型性能并降低部署难度

Abstract: Sparse Mixture-of-Experts (SMoE) architectures are widely used in large
language models (LLMs) due to their computational efficiency. However, though
only a few experts are activated for each token, SMoE still requires loading
all expert parameters, leading to high memory usage and challenges in
deployment. Previous work has tried to reduce the overhead by pruning and
merging experts, but primarily focused on expert-level operations, leaving
neuron-level structure underexplored. We propose DERN (Dropping Experts,
Recombining Neurons), a task-agnostic and retraining-free framework for expert
pruning and reconstruction. We observe that experts are often misaligned and
contain semantic conflicts at the neuron level, which poses challenges for
direct merging. To solve this, DERN works in three steps: it first prunes
redundant experts using router statistics; then it decomposes them into
neuron-level expert segments, assigning each segment to its most compatible
retained expert; and finally, it merges segments within each retained expert to
build a compact representation. Experiments on Mixtral, Qwen, and DeepSeek SMoE
models show that DERN improves performance by more than 5% on commonsense
reasoning and MMLU benchmarks under 50% expert sparsity, without extra
training. It also greatly reduces the number of experts and memory usage,
making SMoE LLMs easier to deploy in practice.

</details>


### [70] [Is In-Context Learning Learning?](https://arxiv.org/abs/2509.10414)
*Adrian de Wynter*

Main category: cs.CL

TL;DR: 本文通过大规模分析证明，虽然上下文学习(ICL)确实构成学习机制，但其学习能力有限，特别是在泛化到未见任务方面表现不足，且对提示格式和分布变化敏感。


<details>
  <summary>Details</summary>
Motivation: 当前对自回归模型上下文学习能力的理解存在争议，需要实证研究来明确ICL是否真正构成学习机制，以及其在各种条件下的表现和局限性。

Method: 进行大规模ICL分析，通过消融实验排除记忆效应、预训练影响、分布偏移等因素，研究不同提示风格和措辞对ICL效果的影响。

Result: ICL是一种有效的学习范式，但学习能力有限；当示例数量足够多时，准确率对示例分布、模型、提示风格和语言特征不敏感；ICL从提示中的规律性推断模式，导致分布敏感性，特别是在思维链等提示风格中。

Conclusion: 自回归模型的临时编码机制不够鲁棒，表明其通用泛化能力有限，ICL虽然构成学习但不是稳健的学习机制。

Abstract: In-context learning (ICL) allows some autoregressive models to solve tasks
via next-token prediction and without needing further training. This has led to
claims about these model's ability to solve (learn) unseen tasks with only a
few shots (exemplars) in the prompt. However, deduction does not always imply
learning, as ICL does not explicitly encode a given observation. Instead, the
models rely on their prior knowledge and the exemplars given, if any. We argue
that, mathematically, ICL does constitute learning, but its full
characterisation requires empirical work. We then carry out a large-scale
analysis of ICL ablating out or accounting for memorisation, pretraining,
distributional shifts, and prompting style and phrasing. We find that ICL is an
effective learning paradigm, but limited in its ability to learn and generalise
to unseen tasks. We note that, in the limit where exemplars become more
numerous, accuracy is insensitive to exemplar distribution, model, prompt
style, and the input's linguistic features. Instead, it deduces patterns from
regularities in the prompt, which leads to distributional sensitivity,
especially in prompting styles such as chain-of-thought. Given the varied
accuracies on formally similar tasks, we conclude that autoregression's ad-hoc
encoding is not a robust mechanism, and suggests limited all-purpose
generalisability.

</details>


### [71] [Long Context Automated Essay Scoring with Language Models](https://arxiv.org/abs/2509.10417)
*Christopher Ormerod,Gitit Kehat*

Main category: cs.CL

TL;DR: 这篇论文研究了如何解决Transformer模型在自动论文评分中的长文本处理问题，通过比较多种支持长上下文的模型在ASAP 2.0数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 高分论文组织结构需要长上下文来评估，但传统Transformer模型有长度限制，截断处理会影响评分效果的有效性。

Method: 使用XLNet、Longformer、ModernBERT、Mamba和Llama等支持长上下文的模型进行微调，在Kaggle ASAP 2.0论文评分数据集上进行评估。

Result: 研究对比了这些模型在长文本论文评分任务上的表现，以确定哪种模型架构更适合这一应用场景。

Conclusion: 使用支持长上下文的模型可以有效解决论文评分中的长文本问题，提高评分系统对组织结构要素的评估能力。

Abstract: Transformer-based language models are architecturally constrained to process
text of a fixed maximum length. Essays written by higher-grade students
frequently exceed the maximum allowed length for many popular open-source
models. A common approach to addressing this issue when using these models for
Automated Essay Scoring is to truncate the input text. This raises serious
validity concerns as it undermines the model's ability to fully capture and
evaluate organizational elements of the scoring rubric, which requires long
contexts to assess. In this study, we evaluate several models that incorporate
architectural modifications of the standard transformer architecture to
overcome these length limitations using the Kaggle ASAP 2.0 dataset. The models
considered in this study include fine-tuned versions of XLNet, Longformer,
ModernBERT, Mamba, and Llama models.

</details>


### [72] [RefactorCoderQA: Benchmarking LLMs for Multi-Domain Coding Question Solutions in Cloud and Edge Deployment](https://arxiv.org/abs/2509.10436)
*Shadikur Rahman,Aroosa Hameed,Gautam Srivastava,Syed Muhammad Danish*

Main category: cs.CL

TL;DR: 这篇论文提出了一种云边协同的多段代理提示框架，通过GuideLLM、SolverLLM和JudgeLLM三个专门组件来优化大语言模型的推理和解题能力，并在RefactorCoderQA标准数据集上达到了独创的性能水平。


<details>
  <summary>Details</summary>
Motivation: 解决现有标准化测试集的局限性，以及大语言模型在多领域编码任务中的表现优化需求。

Method: 设计云边协同架构，包含边缘部署的GuideLLM提供方法论指导，云端SolverLLM生成代码解决方案，以反JudgeLLM评估解决方案质量。构建RefactorCoderQA标准数据集进行评估。

Result: 细调的RefactorCoder-MoE模型在标准化测试中达到76.84%的总体准确率，显著超过现有开源和商业基线模型。人工评估也验证了解决方案的可解释性、准确性和实用性。

Conclusion: 该云边协同多段代理框架有效提升了LLM的推理能力，为实际应用提供了高质量的解决方案，同时考虑了系统级性能指标。

Abstract: To optimize the reasoning and problem-solving capabilities of Large Language
Models (LLMs), we propose a novel cloud-edge collaborative architecture that
enables a structured, multi-agent prompting framework. This framework comprises
three specialized components: GuideLLM, a lightweight model deployed at the
edge to provide methodological guidance; SolverLLM, a more powerful model
hosted in the cloud responsible for generating code solutions; and JudgeLLM, an
automated evaluator for assessing solution correctness and quality. To evaluate
and demonstrate the effectiveness of this architecture in realistic settings,
we introduce RefactorCoderQA, a comprehensive benchmark designed to evaluate
and enhance the performance of Large Language Models (LLMs) across multi-domain
coding tasks. Motivated by the limitations of existing benchmarks,
RefactorCoderQA systematically covers various technical domains, including
Software Engineering, Data Science, Machine Learning, and Natural Language
Processing, using authentic coding challenges from Stack Overflow. Extensive
experiments reveal that our fine-tuned model, RefactorCoder-MoE, achieves
state-of-the-art performance, significantly outperforming leading open-source
and commercial baselines with an overall accuracy of 76.84%. Human evaluations
further validate the interpretability, accuracy, and practical relevance of the
generated solutions. In addition, we evaluate system-level metrics, such as
throughput and latency, to gain deeper insights into the performance
characteristics and trade-offs of the proposed architecture.

</details>


### [73] [DeepDive: Advancing Deep Search Agents with Knowledge Graphs and Multi-Turn RL](https://arxiv.org/abs/2509.10446)
*Rui Lu,Zhenyu Hou,Zihan Wang,Hanchen Zhang,Xiao Liu,Yujiang Li,Shi Feng,Jie Tang,Yuxiao Dong*

Main category: cs.CL

TL;DR: DeepDive通过自动合成复杂问题和多轮强化学习训练，显著提升了开源大语言模型在深度搜索任务中的表现，在BrowseComp基准上达到了新的开源竞争性结果。


<details>
  <summary>Details</summary>
Motivation: 当前开源大语言模型在深度搜索任务中表现不佳，主要受限于长程推理能力和缺乏足够难度的监督数据。

Method: 1) 从开放知识图谱自动合成复杂难找的问题；2) 应用端到端多轮强化学习来增强LLM的长程深度搜索推理能力。

Result: DeepDive-32B在BrowseComp基准上超越了WebSailor、DeepSeek-R1-Browse和Search-o1等模型，多轮RL训练显著提升了深度搜索能力，并支持测试时的工具调用扩展和并行采样。

Conclusion: DeepDive通过自动数据合成和多轮强化学习的结合，有效解决了开源LLM在深度搜索任务中的性能瓶颈，为构建更强大的深度搜索智能体提供了可行方案。

Abstract: Augmenting large language models (LLMs) with browsing tools substantially
improves their potential as deep search agents to solve complex, real-world
tasks. Yet, open LLMs still perform poorly in such settings due to limited
long-horizon reasoning capacity with browsing tools and the lack of
sufficiently difficult supervised data. To address these challenges, we present
DeepDive to advance deep search agents. First, we propose a strategy to
automatically synthesize complex, difficult, and hard-to-find questions from
open knowledge graphs. Second, we apply end-to-end multi-turn reinforcement
learning (RL) to enhance LLMs' long-horizon reasoning with deep search.
Experiments show that DeepDive-32B achieves a new open-source competitive
result on BrowseComp, outperforming WebSailor, DeepSeek-R1-Browse, and
Search-o1. We demonstrate that multi-turn RL training improves deep search
ability and significantly contributes to the performance improvements across
multiple benchmarks. We observe that DeepDive enables test-time scaling of tool
calls and parallel sampling. All datasets, models, and code are publicly
available at https://github.com/THUDM/DeepDive.

</details>


### [74] [WhisTLE: Deeply Supervised, Text-Only Domain Adaptation for Pretrained Speech Recognition Transformers](https://arxiv.org/abs/2509.10452)
*Akshat Pandey,Karun Kumar,Raphael Tang*

Main category: cs.CL

TL;DR: WhisTLE是一种仅使用文本数据进行语音识别模型领域适应的深度监督方法，通过变分自编码器建模编码器输出并微调解码器，无需额外推理成本即可显著降低词错误率。


<details>
  <summary>Details</summary>
Motivation: 预训练语音识别模型如Whisper在未见词汇和方言上表现不佳，但实际场景中收集语音数据困难，需要仅使用文本数据进行领域适应。

Method: 提出WhisTLE方法：训练VAE从文本建模编码器输出，使用学习的文本到潜在编码器微调解码器，可选结合TTS适应。推理时恢复原始编码器，无额外运行时成本。

Result: 在4个域外数据集和4个ASR模型上，WhisTLE+TTS相比仅TTS适应相对降低WER 12.3%，在32个场景中的27个优于所有非WhisTLE基线。

Conclusion: WhisTLE是一种有效的文本only适应方法，能显著提升预训练ASR模型在未见领域的性能，且不增加推理成本。

Abstract: Pretrained automatic speech recognition (ASR) models such as Whisper perform
well but still need domain adaptation to handle unseen vocabulary and parlance.
In many real-world settings, collecting speech data is impractical,
necessitating text-only adaptation. We propose WhisTLE, a deeply supervised,
text-only adaptation method for pretrained encoder-decoder ASR models. WhisTLE
trains a variational autoencoder (VAE) to model encoder outputs from text and
fine-tunes the decoder using the learned text-to-latent encoder, optionally
combined with text-to-speech (TTS) adaptation. At inference, the original
encoder is restored, incurring no extra runtime cost. Across four out-of-domain
datasets and four ASR models, WhisTLE with TTS reduces word error rate (WER) by
12.3% relative to TTS-only adaptation and outperforms all non-WhisTLE baselines
in 27 of 32 scenarios.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [75] [Australian Supermarket Object Set (ASOS): A Benchmark Dataset of Physical Objects and 3D Models for Robotics and Computer Vision](https://arxiv.org/abs/2509.09720)
*Akansel Cosgun,Lachlan Chumbley,Benjamin J. Meyer*

Main category: cs.CV

TL;DR: ASOS是一个包含50种澳大利亚超市常见商品的3D纹理网格数据集，专为机器人和计算机视觉基准测试设计，强调真实性和可获取性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多使用合成模型或难以获取的专业物品，缺乏真实世界应用的实用性和可访问性。ASOS旨在提供成本低廉、易于获取的真实商品数据集。

Method: 采用运动恢复结构技术，通过高分辨率成像生成水密3D网格，涵盖10个不同类别的商品，具有多样化的形状、尺寸和重量。

Result: 创建了一个包含50种超市商品的综合3D数据集，所有物品均可从澳大利亚主要超市连锁店轻松获取，为基准测试提供了高质量的真实数据。

Conclusion: ASOS数据集以其可访问性、真实世界适用性和成本效益，为物体检测、姿态估计和机器人应用提供了有价值的基准测试资源。

Abstract: This paper introduces the Australian Supermarket Object Set (ASOS), a
comprehensive dataset comprising 50 readily available supermarket items with
high-quality 3D textured meshes designed for benchmarking in robotics and
computer vision applications. Unlike existing datasets that rely on synthetic
models or specialized objects with limited accessibility, ASOS provides a
cost-effective collection of common household items that can be sourced from a
major Australian supermarket chain. The dataset spans 10 distinct categories
with diverse shapes, sizes, and weights. 3D meshes are acquired by a
structure-from-motion techniques with high-resolution imaging to generate
watertight meshes. The dataset's emphasis on accessibility and real-world
applicability makes it valuable for benchmarking object detection, pose
estimation, and robotics applications.

</details>


### [76] [A Multimodal RAG Framework for Housing Damage Assessment: Collaborative Optimization of Image Encoding and Policy Vector Retrieval](https://arxiv.org/abs/2509.09721)
*Jiayi Miao,Dingxin Lu,Zhuqi Wang*

Main category: cs.CV

TL;DR: 提出多模态检索增强生成框架(MM-RAG)，用于灾后房屋损坏评估，通过双分支编码器和跨模态交互模块实现图像和文本的语义对齐，在检索准确率和损坏严重程度分类指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 自然灾害后准确评估房屋损坏对于保险理赔和资源规划至关重要，需要结合图像和文本信息进行综合分析。

Method: 采用双分支多模态编码器结构：图像分支使用ResNet和Transformer提取建筑损坏特征，文本分支使用BERT检索器处理文本向量化；集成跨模态交互模块通过多头注意力实现语义对齐；引入模态注意力门控机制动态控制生成过程中的视觉证据和文本先验信息作用。

Result: 在检索准确率和损坏严重程度分类指标上表现优异，Top-1检索准确率提升了9.6%。

Conclusion: 该多模态检索增强生成框架能够有效结合视觉和文本信息，为灾后房屋损坏评估提供准确的分析工具，在保险理赔和资源规划中具有重要应用价值。

Abstract: After natural disasters, accurate evaluations of damage to housing are
important for insurance claims response and planning of resources. In this
work, we introduce a novel multimodal retrieval-augmented generation (MM-RAG)
framework. On top of classical RAG architecture, we further the framework to
devise a two-branch multimodal encoder structure that the image branch employs
a visual encoder composed of ResNet and Transformer to extract the
characteristic of building damage after disaster, and the text branch harnesses
a BERT retriever for the text vectorization of posts as well as insurance
policies and for the construction of a retrievable restoration index. To impose
cross-modal semantic alignment, the model integrates a cross-modal interaction
module to bridge the semantic representation between image and text via
multi-head attention. Meanwhile, in the generation module, the introduced modal
attention gating mechanism dynamically controls the role of visual evidence and
text prior information during generation. The entire framework takes end-to-end
training, and combines the comparison loss, the retrieval loss and the
generation loss to form multi-task optimization objectives, and achieves image
understanding and policy matching in collaborative learning. The results
demonstrate superior performance in retrieval accuracy and classification index
on damage severity, where the Top-1 retrieval accuracy has been improved by
9.6%.

</details>


### [77] [Improving MLLM Historical Record Extraction with Test-Time Image](https://arxiv.org/abs/2509.09722)
*Taylor Archibald,Tony Martinez*

Main category: cs.CV

TL;DR: 通过多重增帽图像转换和美元纳-沃恩斯算法融合输出，提高噪声历史文档文本提取的稳定性和准确性


<details>
  <summary>Details</summary>
Motivation: 解决噪声历史文档中基于LLM的文本提取不稳定的问题

Method: 使用Gemini 2.0 Flash对多个增帽图像变体进行转写，然后通过自定义Needleman Wunsch对齐器融合输出得到共识转写和信心度分数

Result: 在622份庞法尼亚死亡记录数据集上，该方法相比单次基准提高了4%的转写准确性，填充和模糊增帽效果最好，网格扭曲变形最适合区分高低信心度案例

Conclusion: 该方法简单、可扩展且立即可部署到其他文档集和转写模型

Abstract: We present a novel ensemble framework that stabilizes LLM based text
extraction from noisy historical documents. We transcribe multiple augmented
variants of each image with Gemini 2.0 Flash and fuse these outputs with a
custom Needleman Wunsch style aligner that yields both a consensus
transcription and a confidence score. We present a new dataset of 622
Pennsylvania death records, and demonstrate our method improves transcription
accuracy by 4 percentage points relative to a single shot baseline. We find
that padding and blurring are the most useful for improving accuracy, while
grid warp perturbations are best for separating high and low confidence cases.
The approach is simple, scalable, and immediately deployable to other document
collections and transcription models.

</details>


### [78] [MITS: A Large-Scale Multimodal Benchmark Dataset for Intelligent Traffic Surveillance](https://arxiv.org/abs/2509.09730)
*Kaikai Zhao,Zhaoxiang Liu,Peng Wang,Xin Wang,Zhicheng Ma,Yajun Xu,Wenjing Zhang,Yibing Nan,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: 这篇论文提出了首个专门用于智能交通监控领域的大规模多模态数据集MITS，包含17万张图片和500万语音问答对，通过细调LMM模型在ITS任务上实现了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 目前通用大多模态模型在智能交通监控领域表现有限，主要因为缺乏专门的多模态数据集。

Method: 收集170,400张真实交通监控图片，进行全面标注，通过系统化数据生成流水线生成高质量图片描述和500万指令跟随问答对，覆盖5个关键ITS任务。

Result: 细调后的LMM模型在ITS应用中表现显著提升：LLaVA-1.5从0.494提升到0.905(+83.2%)，LLaVA-1.6从0.678到0.921(+35.8%)，Qwen2-VL从0.584到0.926(+58.6%)，Qwen2.5-VL从0.732到0.930(+27.0%)。

Conclusion: MITS数据集有效解决了ITS领域缺乏专业数据的问题，显著提升了LMM模型在交通监控任务上的性能，为ITS和LMM研究提供了高价值资源。

Abstract: General-domain large multimodal models (LMMs) have achieved significant
advances in various image-text tasks. However, their performance in the
Intelligent Traffic Surveillance (ITS) domain remains limited due to the
absence of dedicated multimodal datasets. To address this gap, we introduce
MITS (Multimodal Intelligent Traffic Surveillance), the first large-scale
multimodal benchmark dataset specifically designed for ITS. MITS includes
170,400 independently collected real-world ITS images sourced from traffic
surveillance cameras, annotated with eight main categories and 24 subcategories
of ITS-specific objects and events under diverse environmental conditions.
Additionally, through a systematic data generation pipeline, we generate
high-quality image captions and 5 million instruction-following visual
question-answer pairs, addressing five critical ITS tasks: object and event
recognition, object counting, object localization, background analysis, and
event reasoning. To demonstrate MITS's effectiveness, we fine-tune mainstream
LMMs on this dataset, enabling the development of ITS-specific applications.
Experimental results show that MITS significantly improves LMM performance in
ITS applications, increasing LLaVA-1.5's performance from 0.494 to 0.905
(+83.2%), LLaVA-1.6's from 0.678 to 0.921 (+35.8%), Qwen2-VL's from 0.584 to
0.926 (+58.6%), and Qwen2.5-VL's from 0.732 to 0.930 (+27.0%). We release the
dataset, code, and models as open-source, providing high-value resources to
advance both ITS and LMM research.

</details>


### [79] [Decomposing Visual Classification: Assessing Tree-Based Reasoning in VLMs](https://arxiv.org/abs/2509.09732)
*Sary Elmansoury,Islam Mesabah,Gerrit Großmann,Peter Neigel,Raj Bhalwankar,Daniel Kondermann,Sebastian J. Vollmer*

Main category: cs.CV

TL;DR: 该研究探索了视觉语言模型在细粒度分类任务中的表现，尝试用决策树结构提升性能，但结果显示结构化推理方法在视觉分类中并不如标准零样本提示。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在细粒度任务和大规模层次标签空间下的表现，探索结构化树基推理是否能提升模型性能和可解释性。

Method: 提出了一个框架，将分类任务分解为可解释的决策树结构，并在GTSRB和CIFAR-10数据集上进行评估，同时尝试用LLM生成的类别和图片描述优化提示。

Result: 模型在理解树知识方面达到98.2%的准确率，但树基推理方法在分类任务中一赴不如标准零样本提示。图片描述的加入能同时提升两种方法的性能。

Conclusion: 结构化推理在规视分类中存在限制，研究结果为设计更可解释的视觉语言模型系统提供了见解。

Abstract: Vision language models (VLMs) excel at zero-shot visual classification, but
their performance on fine-grained tasks and large hierarchical label spaces is
understudied. This paper investigates whether structured, tree-based reasoning
can enhance VLM performance. We introduce a framework that decomposes
classification into interpretable decisions using decision trees and evaluates
it on fine-grained (GTSRB) and coarse-grained (CIFAR-10) datasets. Although the
model achieves 98.2% accuracy in understanding the tree knowledge, tree-based
reasoning consistently underperforms standard zero-shot prompting. We also
explore enhancing the tree prompts with LLM-generated classes and image
descriptions to improve alignment. The added description enhances the
performance of the tree-based and zero-shot methods. Our findings highlight
limitations of structured reasoning in visual classification and offer insights
for designing more interpretable VLM systems.

</details>


### [80] [World Modeling with Probabilistic Structure Integration](https://arxiv.org/abs/2509.09737)
*Klemen Kotar,Wanhee Lee,Rahul Venkatesh,Honglin Chen,Daniel Bear,Jared Watrous,Simon Kim,Khai Loong Aw,Lilian Naing Chen,Stefan Stojanov,Kevin Feigelis,Imran Thobani,Alex Durango,Khaled Jedoui,Atlas Kazemian,Dan Yamins*

Main category: cs.CV

TL;DR: PSI是一个从数据中学习可控、可提示世界模型的系统，通过概率预测、结构提取和集成三个步骤的循环来增强模型能力


<details>
  <summary>Details</summary>
Motivation: 构建能够从视频数据中学习丰富可控性和灵活提示性的世界模型，以支持多种视频理解和预测任务

Method: 三步循环：1) 概率预测构建概率图模型；2) 结构提取通过因果推断提取低维结构；3) 集成将结构转换为新token类型并混合回训练

Result: 在1.4万亿视频token上训练，实现了最先进的光流、自监督深度和对象分割，支持完整的预测改进循环

Conclusion: PSI系统通过循环增强机制成功构建了强大的世界模型，既改善了数据建模能力，又创造了新的控制接口

Abstract: We present Probabilistic Structure Integration (PSI), a system for learning
richly controllable and flexibly promptable world models from data. PSI
consists of a three-step cycle. The first step, Probabilistic prediction,
involves building a probabilistic graphical model Psi of the data, in the form
of a random-access autoregressive sequence model. Psi supports a complete set
of learned conditional distributions describing the dependence of any variables
in the data on any other set of variables. In step 2, Structure extraction, we
show how to extract underlying low-dimensional properties in the data,
corresponding to a diverse set of meaningful "intermediate structures", in a
zero-shot fashion via causal inference on Psi. Step 3, Integration, completes
the cycle by converting these structures into new token types that are then
continually mixed back into the training diet as conditioning signals and
prediction targets. Each such cycle augments the capabilities of Psi, both
allowing it to model the underlying data better, and creating new control
handles -- akin to an LLM-like universal prompting language. We train an
instance of Psi on 1.4 trillion tokens of internet video data; we use it to
perform a variety of useful video prediction and understanding inferences; we
extract state-of-the-art optical flow, self-supervised depth and object
segmentation; and we use these structures to support a full cycle of predictive
improvements.

</details>


### [81] [Images in Motion?: A First Look into Video Leakage in Collaborative Deep Learning](https://arxiv.org/abs/2509.09742)
*Md Fazle Rasul,Alanood Alqobaisi,Bruhadeshwar Bezawada,Indrakshi Ray*

Main category: cs.CV

TL;DR: 这篇论文首次分析了联邦学习中视频数据通过梯度逆向攻击泄漏的风险，发现使用特征提取器能提高防御能力，但泄漏仍可能发生。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的核心是保护数据隐私，但梯度逆向攻击可能逆向推断敏感数据。当前研究主要集中在图像、文本和表格数据，对视频数据的影响仍未涉及。

Method: 评估了两种常见的视频分类方法：使用预训练特征提取器和处理原始视频帧的方法。还使用图像超分辨率技术来提升通过梯度逆向攻击提取的帧质量。在攻击者拥有零、一个或多个参考帧的情况下进行验证。

Result: 使用特征提取器能提高对梯度逆向攻击的防御能力，但如果分类器复杂度不够，数据泄漏仍然可能发生。图像超分辨率技术能够重建更高质量的视频。

Conclusion: 视频数据在联邦学习中的泄漏是一个真实威胁，需要进一步研究其发生条件和防御措施。

Abstract: Federated learning (FL) allows multiple entities to train a shared model
collaboratively. Its core, privacy-preserving principle is that participants
only exchange model updates, such as gradients, and never their raw, sensitive
data. This approach is fundamental for applications in domains where privacy
and confidentiality are important. However, the security of this very mechanism
is threatened by gradient inversion attacks, which can reverse-engineer private
training data directly from the shared gradients, defeating the purpose of FL.
While the impact of these attacks is known for image, text, and tabular data,
their effect on video data remains an unexamined area of research. This paper
presents the first analysis of video data leakage in FL using gradient
inversion attacks. We evaluate two common video classification approaches: one
employing pre-trained feature extractors and another that processes raw video
frames with simple transformations. Our initial results indicate that the use
of feature extractors offers greater resilience against gradient inversion
attacks. We also demonstrate that image super-resolution techniques can enhance
the frames extracted through gradient inversion attacks, enabling attackers to
reconstruct higher-quality videos. Our experiments validate this across
scenarios where the attacker has access to zero, one, or more reference frames
from the target environment. We find that although feature extractors make
attacks more challenging, leakage is still possible if the classifier lacks
sufficient complexity. We, therefore, conclude that video data leakage in FL is
a viable threat, and the conditions under which it occurs warrant further
investigation.

</details>


### [82] [A Co-Training Semi-Supervised Framework Using Faster R-CNN and YOLO Networks for Object Detection in Densely Packed Retail Images](https://arxiv.org/abs/2509.09750)
*Hossein Yazdanjouei,Arash Mansouri,Mohammad Shokouhifar*

Main category: cs.CV

TL;DR: 一种用于集密零售环境物体检测的半监督协同训练框架，结合Faster R-CNN和YOLO优势，通过伪标签交换和集成分类提高检测准确度，减少对手动标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 集密零售环境中标签数据有限、遮挡和重叠物体多，传统检测方法面临挑战，需要降低标注成本并适应频繁的商品和布局变化。

Method: 使用Faster R-CNN(ResNet背景)进行精确定位和YOLO(Darknet背景)获取全局上下文，通过互相伪标签交换提升性能。采用XGBoost、Random Forest和SVM的集成分类器增强分类稳健性，并使用元神经算法优化超参数。

Result: 在SKU-110k数据集上表现突出，显示出强大的性能和可扩展性，适用于实际零售应用场景如自动监控、库存跟踪和结账系统。

Conclusion: 该框架通过半监督协同训练有效解决了集密零售环境的物体检测挑战，减少对手动标注的依赖，具有实际应用价值。

Abstract: This study proposes a semi-supervised co-training framework for object
detection in densely packed retail environments, where limited labeled data and
complex conditions pose major challenges. The framework combines Faster R-CNN
(utilizing a ResNet backbone) for precise localization with YOLO (employing a
Darknet backbone) for global context, enabling mutual pseudo-label exchange
that improves accuracy in scenes with occlusion and overlapping objects. To
strengthen classification, it employs an ensemble of XGBoost, Random Forest,
and SVM, utilizing diverse feature representations for higher robustness.
Hyperparameters are optimized using a metaheuristic-driven algorithm, enhancing
precision and efficiency across models. By minimizing reliance on manual
labeling, the approach reduces annotation costs and adapts effectively to
frequent product and layout changes common in retail. Experiments on the
SKU-110k dataset demonstrate strong performance, highlighting the scalability
and practicality of the proposed framework for real-world retail applications
such as automated inventory tracking, product monitoring, and checkout systems.

</details>


### [83] [Purge-Gate: Backpropagation-Free Test-Time Adaptation for Point Clouds Classification via Token Purging](https://arxiv.org/abs/2509.09785)
*Moslem Yazdanpanah,Ali Bahri,Mehrdad Noori,Sahar Dastani,Gustavo Adolfo Vargas Hakim,David Osowiechi,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出Token Purging(PG)方法，一种无需反向传播的测试时适应方法，通过移除受域偏移影响严重的token来提升3D点云分类性能


<details>
  <summary>Details</summary>
Motivation: 解决3D点云分类中因分布偏移导致的性能下降问题，现有测试时适应方法需要迭代更新，效率较低

Method: 提出两种变体：PG-SP利用源域统计信息，PG-SF是完全源无关版本，依赖CLS-token驱动适应。在注意力层前移除受影响token

Result: 在ModelNet40-C、ShapeNet-C和ScanObjectNN-C数据集上，PG-SP比最先进的无反向传播方法平均准确率高10.3%，PG-SF在源无关适应中创下新基准。速度提升12.4倍，内存效率提升5.5倍

Conclusion: Token Purging是一种高效、内存友好的测试时适应方法，适用于实际部署，无需反向传播即可实现鲁棒适应

Abstract: Test-time adaptation (TTA) is crucial for mitigating performance degradation
caused by distribution shifts in 3D point cloud classification. In this work,
we introduce Token Purging (PG), a novel backpropagation-free approach that
removes tokens highly affected by domain shifts before they reach attention
layers. Unlike existing TTA methods, PG operates at the token level, ensuring
robust adaptation without iterative updates. We propose two variants: PG-SP,
which leverages source statistics, and PG-SF, a fully source-free version
relying on CLS-token-driven adaptation. Extensive evaluations on ModelNet40-C,
ShapeNet-C, and ScanObjectNN-C demonstrate that PG-SP achieves an average of
+10.3\% higher accuracy than state-of-the-art backpropagation-free methods,
while PG-SF sets new benchmarks for source-free adaptation. Moreover, PG is
12.4 times faster and 5.5 times more memory efficient than our baseline, making
it suitable for real-world deployment. Code is available at
\hyperlink{https://github.com/MosyMosy/Purge-Gate}{https://github.com/MosyMosy/Purge-Gate}

</details>


### [84] [Fine-Grained Cross-View Localization via Local Feature Matching and Monocular Depth Priors](https://arxiv.org/abs/2509.09792)
*Zimin Xia,Chenghao Xu,Alexandre Alahi*

Main category: cs.CV

TL;DR: 一种高精度可解释的细粒度跨视角定位方法，通过直接匹配地面和帆美图像特征点来估计相机位姿，避免传统BEV转换的信息损失问题


<details>
  <summary>Details</summary>
Motivation: 传统方法将地面图像转换为鸟视图并与帆美图对齐的方法存在视角扩射和高度信息压缩导致的信息损失问题，影响定位精度

Method: 直接在地面和帆美图像之间建立特征对应关系，仅将匹配的关键点提升到BEV空间，使用单目深度预测作为前提。支持计量深度和相对深度，采用制约感矩阵对齐估计相机位姿

Result: 在只有弱监督的情况下学习到了准确的局部特征对应关系，在跨区域治理和未知方向等具有挑战性的条件下实现了优异的定位性能

Conclusion: 该方法不仅精度高，而且兼容各种相对深度模型而无需重新调整，具有强大的实际部署潜力

Abstract: We propose an accurate and highly interpretable fine-grained cross-view
localization method that estimates the 3 Degrees of Freedom pose of a
ground-level image by matching its local features with a reference aerial
image. Previous methods typically transform the ground image into a bird's-eye
view (BEV) representation and then align it with the aerial image for
localization. However, this transformation often leads to information loss due
to perspective distortion or compression of height information, thereby
degrading alignment quality with the aerial view. In contrast, our method
directly establishes correspondences between ground and aerial images and lifts
only the matched keypoints to BEV space using monocular depth prior. Notably,
modern depth predictors can provide reliable metric depth when the test samples
are similar to the training data. When the depth distribution differs, they
still produce consistent relative depth, i.e., depth accurate up to an unknown
scale. Our method supports both metric and relative depth. It employs a
scale-aware Procrustes alignment to estimate the camera pose from the
correspondences and optionally recover the scale when using relative depth.
Experimental results demonstrate that, with only weak supervision on camera
pose, our method learns accurate local feature correspondences and achieves
superior localization performance under challenging conditions, such as
cross-area generalization and unknown orientation. Moreover, our method is
compatible with various relative depth models without requiring per-model
finetuning. This flexibility, combined with strong localization performance,
makes it well-suited for real-world deployment.

</details>


### [85] [Early Detection of Visual Impairments at Home Using a Smartphone Red-Eye Reflex Test](https://arxiv.org/abs/2509.09808)
*Judith Massmann,Alexander Lichtenstein,Francisco M. López*

Main category: cs.CV

TL;DR: 通过智能手机应用KidsVisionCheck使用深度学习分析红眼反射图像，实现儿童视力筛查，准确率达90%


<details>
  <summary>Details</summary>
Motivation: 利用智能手机和AI技术重现Bruckner测试，使儿童视力筛查更加可达和可访问

Method: 使用深度神经网络训练在眼科医生标注的儿童孔径图像数据集上

Result: 在未见测试数据上达到90%的准确率，无需专业设备

Conclusion: 这项工作是向全球可访问儿科视力筛查和早期干预视力异常的第一步

Abstract: Numerous visual impairments can be detected in red-eye reflex images from
young children. The so-called Bruckner test is traditionally performed by
ophthalmologists in clinical settings. Thanks to the recent technological
advances in smartphones and artificial intelligence, it is now possible to
recreate the Bruckner test using a mobile device. In this paper, we present a
first study conducted during the development of KidsVisionCheck, a free
application that can perform vision screening with a mobile device using
red-eye reflex images. The underlying model relies on deep neural networks
trained on children's pupil images collected and labeled by an ophthalmologist.
With an accuracy of 90% on unseen test data, our model provides highly reliable
performance without the necessity of specialist equipment. Furthermore, we can
identify the optimal conditions for data collection, which can in turn be used
to provide immediate feedback to the users. In summary, this work marks a first
step toward accessible pediatric vision screenings and early intervention for
vision abnormalities worldwide.

</details>


### [86] [DGFusion: Depth-Guided Sensor Fusion for Robust Semantic Perception](https://arxiv.org/abs/2509.09828)
*Tim Broedermannn,Christos Sakaridis,Luigi Piccinelli,Wim Abbeloos,Luc Van Gool*

Main category: cs.CV

TL;DR: 提出DGFusion方法，通过深度引导的多模态融合技术，在自动驾驶语义感知中实现动态传感器融合，提升在挑战性条件下的性能表现


<details>
  <summary>Details</summary>
Motivation: 现有传感器融合方法在空间上统一处理传感器数据，在挑战性条件下性能受限。需要利用深度信息来动态适应不同传感器在不同空间位置的可信度

Method: 提出深度引导的多模态融合网络DGFusion，将多模态分割作为多任务问题处理，使用激光雷达测量作为输入和深度学习真值，通过局部深度令牌和全局条件令牌动态调整传感器融合

Result: 在MUSES和DELIVER数据集上实现了最先进的泛光和语义分割性能

Conclusion: 深度引导的传感器融合方法能够有效提升自动驾驶语义感知在挑战性条件下的鲁棒性，深度信息对于动态调整传感器融合策略至关重要

Abstract: Robust semantic perception for autonomous vehicles relies on effectively
combining multiple sensors with complementary strengths and weaknesses.
State-of-the-art sensor fusion approaches to semantic perception often treat
sensor data uniformly across the spatial extent of the input, which hinders
performance when faced with challenging conditions. By contrast, we propose a
novel depth-guided multimodal fusion method that upgrades condition-aware
fusion by integrating depth information. Our network, DGFusion, poses
multimodal segmentation as a multi-task problem, utilizing the lidar
measurements, which are typically available in outdoor sensor suites, both as
one of the model's inputs and as ground truth for learning depth. Our
corresponding auxiliary depth head helps to learn depth-aware features, which
are encoded into spatially varying local depth tokens that condition our
attentive cross-modal fusion. Together with a global condition token, these
local depth tokens dynamically adapt sensor fusion to the spatially varying
reliability of each sensor across the scene, which largely depends on depth. In
addition, we propose a robust loss for our depth, which is essential for
learning from lidar inputs that are typically sparse and noisy in adverse
conditions. Our method achieves state-of-the-art panoptic and semantic
segmentation performance on the challenging MUSES and DELIVER datasets. Code
and models will be available at https://github.com/timbroed/DGFusion

</details>


### [87] [Patch-based Automatic Rosacea Detection Using the ResNet Deep Learning Framework](https://arxiv.org/abs/2509.09841)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 基于ResNet-18的补丁式自动酒渣鼻检测策略，通过提取面部不同区域的局部图像块，在保持准确性的同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 酒渣鼻是一种慢性炎症性皮肤病，需要精确早期检测以提高治疗效果。传统全图像方法存在隐私泄露风险，且可能无法充分关注临床相关区域。

Method: 使用ResNet-18深度学习框架，从面部图像中提取不同尺寸、形状和位置的各种图像补丁，评估局部视觉信息对模型性能的影响。

Result: 实验结果表明，基于补丁的策略在准确性和敏感性方面达到或优于全图像方法，能够引导模型关注临床相关区域，增强鲁棒性和可解释性。

Conclusion: 提出的补丁式策略为改进自动化皮肤病诊断提供了实用见解，在保持检测性能的同时有效保护患者隐私。

Abstract: Rosacea, which is a chronic inflammatory skin condition that manifests with
facial redness, papules, and visible blood vessels, often requirs precise and
early detection for significantly improving treatment effectiveness. This paper
presents new patch-based automatic rosacea detection strategies using the
ResNet-18 deep learning framework. The contributions of the proposed strategies
come from the following aspects. First, various image pateches are extracted
from the facial images of people in different sizes, shapes, and locations.
Second, a number of investigation studies are carried out to evaluate how the
localized visual information influences the deep learing model performance.
Third, thorough experiments are implemented to reveal that several patch-based
automatic rosacea detection strategies achieve competitive or superior accuracy
and sensitivity than the full-image based methods. And finally, the proposed
patch-based strategies, which use only localized patches, inherently preserve
patient privacy by excluding any identifiable facial features from the data.
The experimental results indicate that the proposed patch-based strategies
guide the deep learning model to focus on clinically relevant regions, enhance
robustness and interpretability, and protect patient privacy. As a result, the
proposed strategies offer practical insights for improving automated
dermatological diagnostics.

</details>


### [88] [Privacy-Preserving Automated Rosacea Detection Based on Medically Inspired Region of Interest Selection](https://arxiv.org/abs/2509.09844)
*Chengyu Yang,Rishik Reddy Yesgari,Chengjun Liu*

Main category: cs.CV

TL;DR: 一种基于合成数据和临床前知的隐私保护自动蜗痕症检测方法，通过红色区域提取和ResNet-18模型实现了更高的准确性和回归率


<details>
  <summary>Details</summary>
Motivation: 解决蜗痕症自动检测中因疾病症状散布、标注数据稀缺和面部图像隐私问题导致的挑战

Method: 首先构建固定的红色区域掩码，选择面部图像中红色通道值持续较高的区域，然后使用ResNet-18深度学习模型在掩码后的合成图像上进行训练

Result: 在真实数据测试中较全面基线方法在准确性、回归率和F1分数方面获得显著提升

Conclusion: 合成数据与临床前知能够联合实现准确且符合道德规范的皮肤科AI系统，尤其适用于隐私敏感的远程医疗和大规模筛查应用

Abstract: Rosacea is a common but underdiagnosed inflammatory skin condition that
primarily affects the central face and presents with subtle redness, pustules,
and visible blood vessels. Automated detection remains challenging due to the
diffuse nature of symptoms, the scarcity of labeled datasets, and privacy
concerns associated with using identifiable facial images. A novel
privacy-preserving automated rosacea detection method inspired by clinical
priors and trained entirely on synthetic data is presented in this paper.
Specifically, the proposed method, which leverages the observation that rosacea
manifests predominantly through central facial erythema, first constructs a
fixed redness-informed mask by selecting regions with consistently high red
channel intensity across facial images. The mask thus is able to focus on
diagnostically relevant areas such as the cheeks, nose, and forehead and
exclude identity-revealing features. Second, the ResNet-18 deep learning
method, which is trained on the masked synthetic images, achieves superior
performance over the full-face baselines with notable gains in terms of
accuracy, recall and F1 score when evaluated using the real-world test data.
The experimental results demonstrate that the synthetic data and clinical
priors can jointly enable accurate and ethical dermatological AI systems,
especially for privacy sensitive applications in telemedicine and large-scale
screening.

</details>


### [89] [Investigating the Impact of Various Loss Functions and Learnable Wiener Filter for Laparoscopic Image Desmoking](https://arxiv.org/abs/2509.09849)
*Chengyu Yang,Chengjun Liu*

Main category: cs.CV

TL;DR: 本文对ULW框架进行消融研究，评估U-Net架构、复合损失函数和可学习维纳滤波器在腹腔镜图像去烟效果中的必要性和贡献


<details>
  <summary>Details</summary>
Motivation: 需要严格评估ULW框架中各个组件的有效性和必要性，以确定每个部分对腹腔镜图像去烟整体性能的具体贡献

Method: 采用系统性消融研究方法：1)移除可学习维纳滤波器模块；2)选择性使用复合损失函数中的单个损失项（MSE、SSIM损失、感知损失）；在公开的配对腹腔镜图像数据集上进行基准测试

Result: 使用定量指标（SSIM、PSNR、MSE、CIEDE-2000）和定性视觉比较对所有变体进行评估

Conclusion: 通过消融研究明确了ULW框架中各个组件的相对重要性，为腹腔镜图像去烟方法的优化提供了实证依据

Abstract: To rigorously assess the effectiveness and necessity of individual components
within the recently proposed ULW framework for laparoscopic image desmoking,
this paper presents a comprehensive ablation study. The ULW approach combines a
U-Net based backbone with a compound loss function that comprises mean squared
error (MSE), structural similarity index (SSIM) loss, and perceptual loss. The
framework also incorporates a differentiable, learnable Wiener filter module.
In this study, each component is systematically ablated to evaluate its
specific contribution to the overall performance of the whole framework. The
analysis includes: (1) removal of the learnable Wiener filter, (2) selective
use of individual loss terms from the composite loss function. All variants are
benchmarked on a publicly available paired laparoscopic images dataset using
quantitative metrics (SSIM, PSNR, MSE and CIEDE-2000) alongside qualitative
visual comparisons.

</details>


### [90] [WAVE-DETR Multi-Modal Visible and Acoustic Real-Life Drone Detector](https://arxiv.org/abs/2509.09859)
*Razvan Stefanescu,Ethan Oh,Ruben Vazquez,Chris Mesterharm,Constantin Serban,Ritu Chadha*

Main category: cs.CV

TL;DR: WAVE-DETR是一种结合可见光RGB和声学信号的多模态无人机检测器，通过融合视觉和声学特征，在Deformable DETR和Wav2Vec2架构基础上实现，在挑战性环境条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决在复杂环境条件下无人机检测的鲁棒性问题，利用多模态信息（视觉+声学）来提升检测性能，特别是在小尺寸无人机检测方面。

Method: 基于Deformable DETR和Wav2Vec2架构，开发了四种融合配置：门控机制、线性层、MLP和交叉注意力。将Wav2Vec2声学嵌入与Deformable DETR的多分辨率特征映射融合。

Result: 最佳的门控融合方法在ARDrone数据集上将Deformable DETR的mAP提升了11.1%-15.3%（小无人机），中型和大型无人机也有3.27%-5.84%的提升。

Conclusion: 声学信息能够显著提升无人机检测性能，特别是在小尺寸无人机检测方面，多模态融合是提升现实场景中无人机检测鲁棒性的有效方法。

Abstract: We introduce a multi-modal WAVE-DETR drone detector combining visible RGB and
acoustic signals for robust real-life UAV object detection. Our approach fuses
visual and acoustic features in a unified object detector model relying on the
Deformable DETR and Wav2Vec2 architectures, achieving strong performance under
challenging environmental conditions. Our work leverage the existing
Drone-vs-Bird dataset and the newly generated ARDrone dataset containing more
than 7,500 synchronized images and audio segments. We show how the acoustic
information is used to improve the performance of the Deformable DETR object
detector on the real ARDrone dataset. We developed, trained and tested four
different fusion configurations based on a gated mechanism, linear layer, MLP
and cross attention. The Wav2Vec2 acoustic embeddings are fused with the multi
resolution feature mappings of the Deformable DETR and enhance the object
detection performance over all drones dimensions. The best performer is the
gated fusion approach, which improves the mAP of the Deformable DETR object
detector on our in-distribution and out-of-distribution ARDrone datasets by
11.1% to 15.3% for small drones across all IoU thresholds between 0.5 and 0.9.
The mAP scores for medium and large drones are also enhanced, with overall
gains across all drone sizes ranging from 3.27% to 5.84%.

</details>


### [91] [Surrogate Supervision for Robust and Generalizable Deformable Image Registration](https://arxiv.org/abs/2509.09869)
*Yihao Liu,Junyu Chen,Lianrui Zuo,Shuwen Wei,Brian D. Boyd,Carmen Andreescu,Olusola Ajilore,Warren D. Taylor,Aaron Carass,Bennett A. Landman*

Main category: cs.CV

TL;DR: 提出了一种称为代理监督的新训练范式，通过将估计的空间变换应用于代理图像，将输入域与监督域解耦，从而提高深度学习配准网络对输入图像变化的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习配准方法虽然精度高，但对输入图像特性变化（如伪影、视场不匹配、模态差异）敏感，需要开发能提高配准网络鲁棒性和泛化性的通用训练方法。

Method: 引入代理监督框架，将输入域与监督域解耦，通过将估计的空间变换应用于代理图像来确保在相似性定义良好的域中进行监督计算，支持在异构输入上进行训练。

Result: 在三个代表性应用中（抗伪影脑MR配准、掩模无关肺CT配准、多模态MR配准）均表现出对输入变化的强韧性，包括不均匀场、不一致视场和模态差异，同时在良好整理数据上保持高性能。

Conclusion: 代理监督为训练鲁棒且可泛化的深度学习配准模型提供了原则性框架，不增加复杂性，为医学图像配准在多样化生物医学成像场景中的更广泛应用提供了实用途径。

Abstract: Objective: Deep learning-based deformable image registration has achieved
strong accuracy, but remains sensitive to variations in input image
characteristics such as artifacts, field-of-view mismatch, or modality
difference. We aim to develop a general training paradigm that improves the
robustness and generalizability of registration networks. Methods: We introduce
surrogate supervision, which decouples the input domain from the supervision
domain by applying estimated spatial transformations to surrogate images. This
allows training on heterogeneous inputs while ensuring supervision is computed
in domains where similarity is well defined. We evaluate the framework through
three representative applications: artifact-robust brain MR registration,
mask-agnostic lung CT registration, and multi-modal MR registration. Results:
Across tasks, surrogate supervision demonstrated strong resilience to input
variations including inhomogeneity field, inconsistent field-of-view, and
modality differences, while maintaining high performance on well-curated data.
Conclusions: Surrogate supervision provides a principled framework for training
robust and generalizable deep learning-based registration models without
increasing complexity. Significance: Surrogate supervision offers a practical
pathway to more robust and generalizable medical image registration, enabling
broader applicability in diverse biomedical imaging scenarios.

</details>


### [92] [An Autoencoder and Vision Transformer-based Interpretability Analysis of the Differences in Automated Staging of Second and Third Molars](https://arxiv.org/abs/2509.09911)
*Barkin Buyukcakir,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: 提出结合卷积自编码器和Vision Transformer的框架，提升牙齿年龄估计的准确性和可解释性，解决了第三磨牙分类性能差的数据中心问题


<details>
  <summary>Details</summary>
Motivation: 深度学习在法医牙科年龄估计等高风险应用中存在'黑盒'问题，需要同时提升模型性能和透明度

Method: 使用卷积自编码器(AE)与Vision Transformer(ViT)结合的框架，通过AE的潜在空间度量和图像重建提供多维度诊断洞察

Result: 分类准确率显著提升：牙齿37从0.712提高到0.815，牙齿38从0.462提高到0.543，并发现性能差距主要源于牙齿38数据集的高类内形态变异性

Conclusion: 单一可解释性方法(如注意力图)不足，该框架通过提升准确性并提供模型不确定性证据，为法医年龄估计专家决策提供更可靠工具

Abstract: The practical adoption of deep learning in high-stakes forensic applications,
such as dental age estimation, is often limited by the 'black box' nature of
the models. This study introduces a framework designed to enhance both
performance and transparency in this context. We use a notable performance
disparity in the automated staging of mandibular second (tooth 37) and third
(tooth 38) molars as a case study. The proposed framework, which combines a
convolutional autoencoder (AE) with a Vision Transformer (ViT), improves
classification accuracy for both teeth over a baseline ViT, increasing from
0.712 to 0.815 for tooth 37 and from 0.462 to 0.543 for tooth 38. Beyond
improving performance, the framework provides multi-faceted diagnostic
insights. Analysis of the AE's latent space metrics and image reconstructions
indicates that the remaining performance gap is data-centric, suggesting high
intra-class morphological variability in the tooth 38 dataset is a primary
limiting factor. This work highlights the insufficiency of relying on a single
mode of interpretability, such as attention maps, which can appear anatomically
plausible yet fail to identify underlying data issues. By offering a
methodology that both enhances accuracy and provides evidence for why a model
may be uncertain, this framework serves as a more robust tool to support expert
decision-making in forensic age estimation.

</details>


### [93] [SCoDA: Self-supervised Continual Domain Adaptation](https://arxiv.org/abs/2509.09935)
*Chirayu Agrawal,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 提出SCoDA方法，通过自监督预训练和几何流形对齐解决无源域自适应问题，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有SFDA方法依赖全监督预训练和余弦相似度对齐，丢弃了源模型潜在流形的关键几何信息

Method: 使用自监督预训练初始化教师模型，结合实例级特征匹配和空间相似性损失进行几何流形对齐，通过EMA更新教师参数防止灾难性遗忘

Result: 在基准数据集上的大量实验表明，SCoDA显著优于最先进的SFDA方法

Conclusion: SCoDA通过自监督预训练和几何流形对齐有效解决了SFDA问题，为无源域自适应提供了新思路

Abstract: Source-Free Domain Adaptation (SFDA) addresses the challenge of adapting a
model to a target domain without access to the data of the source domain.
Prevailing methods typically start with a source model pre-trained with full
supervision and distill the knowledge by aligning instance-level features.
However, these approaches, relying on cosine similarity over L2-normalized
feature vectors, inadvertently discard crucial geometric information about the
latent manifold of the source model. We introduce Self-supervised Continual
Domain Adaptation (SCoDA) to address these limitations. We make two key
departures from standard practice: first, we avoid the reliance on supervised
pre-training by initializing the proposed framework with a teacher model
pre-trained entirely via self-supervision (SSL). Second, we adapt the principle
of geometric manifold alignment to the SFDA setting. The student is trained
with a composite objective combining instance-level feature matching with a
Space Similarity Loss. To combat catastrophic forgetting, the teacher's
parameters are updated via an Exponential Moving Average (EMA) of the student's
parameters. Extensive experiments on benchmark datasets demonstrate that SCoDA
significantly outperforms state-of-the-art SFDA methods.

</details>


### [94] [Segment Anything for Cell Tracking](https://arxiv.org/abs/2509.09943)
*Zhu Chen,Mert Edgü,Er Jin,Johannes Stegmaier*

Main category: cs.CV

TL;DR: 基于SAM2的无监督细胞踪踪法，免需训练数据集且具有良好的跨数据集通用性


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法需要昂贵手动标注数据的问题，以及因微镜数据多样性导致的法通用性偏差

Method: 集成Segment Anything 2 (SAM2)基础模型到踪踪流程中，构建完全无监督的零样本学习框架

Result: 在2D和大规模3D时间延迟微镜视频中达到竞争性的准确性，无需数据集特定适配

Conclusion: 该方法为细胞踪踪领域提供了一种免需训练、具有良好通用性的解决方案

Abstract: Tracking cells and detecting mitotic events in time-lapse microscopy image
sequences is a crucial task in biomedical research. However, it remains highly
challenging due to dividing objects, low signal-tonoise ratios, indistinct
boundaries, dense clusters, and the visually similar appearance of individual
cells. Existing deep learning-based methods rely on manually labeled datasets
for training, which is both costly and time-consuming. Moreover, their
generalizability to unseen datasets remains limited due to the vast diversity
of microscopy data. To overcome these limitations, we propose a zero-shot cell
tracking framework by integrating Segment Anything 2 (SAM2), a large foundation
model designed for general image and video segmentation, into the tracking
pipeline. As a fully-unsupervised approach, our method does not depend on or
inherit biases from any specific training dataset, allowing it to generalize
across diverse microscopy datasets without finetuning. Our approach achieves
competitive accuracy in both 2D and large-scale 3D time-lapse microscopy videos
while eliminating the need for dataset-specific adaptation.

</details>


### [95] [Online 3D Multi-Camera Perception through Robust 2D Tracking and Depth-based Late Aggregation](https://arxiv.org/abs/2509.09946)
*Vu-Minh Le,Thao-Anh Tran,Duc Huy Do,Xuan Canh Do,Huong Ninh,Hai Tran*

Main category: cs.CV

TL;DR: 通过深度信息将任何2D多目标多摄像头跟踪系统扩展到3D空间，使用聚簇和yaw精细化恢复3D盒，并提出基于本地ID一致性的改进数据关联机制


<details>
  <summary>Details</summary>
Motivation: 现有MTMC系统在3D空间进行跟踪需要从头建立所有2D跟踪组件，这对现有系统可能不可行，需要一种能够利用现有2D跟踪系统扩展到3D的方法

Method: 利用深度信息在点云空间重建目标，通过聚簇和yaw精细化恢复3D盒，并使用基于本地ID一致性的改进垂数据关联机制赋予全局ID

Result: 在2025 AI City Challenge的3D MTMC数据集上评估，获得排行榜第3名

Conclusion: 该方法能够有效将现有2D多摄像头跟踪系统扩展到3D空间，为大规模监控提供了一种可行的解决方案

Abstract: Multi-Target Multi-Camera Tracking (MTMC) is an essential computer vision
task for automating large-scale surveillance. With camera calibration and depth
information, the targets in the scene can be projected into 3D space, offering
unparalleled levels of automatic perception of a 3D environment. However,
tracking in the 3D space requires replacing all 2D tracking components from the
ground up, which may be infeasible for existing MTMC systems. In this paper, we
present an approach for extending any online 2D multi-camera tracking system
into 3D space by utilizing depth information to reconstruct a target in
point-cloud space, and recovering its 3D box through clustering and yaw
refinement following tracking. We also introduced an enhanced online data
association mechanism that leverages the target's local ID consistency to
assign global IDs across frames. The proposed framework is evaluated on the
2025 AI City Challenge's 3D MTMC dataset, achieving 3rd place on the
leaderboard.

</details>


### [96] [Zero-Shot Referring Expression Comprehension via Visual-Language True/False Verification](https://arxiv.org/abs/2509.09958)
*Jeffrey Liu,Rongbin Hu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Referring Expression Comprehension (REC) is usually addressed with
task-trained grounding models. We show that a zero-shot workflow, without any
REC-specific training, can achieve competitive or superior performance. Our
approach reformulates REC as box-wise visual-language verification: given
proposals from a COCO-clean generic detector (YOLO-World), a general-purpose
VLM independently answers True/False queries for each region. This simple
procedure reduces cross-box interference, supports abstention and multiple
matches, and requires no fine-tuning. On RefCOCO, RefCOCO+, and RefCOCOg, our
method not only surpasses a zero-shot GroundingDINO baseline but also exceeds
reported results for GroundingDINO trained on REC and GroundingDINO+CRG.
Controlled studies with identical proposals confirm that verification
significantly outperforms selection-based prompting, and results hold with open
VLMs. Overall, we show that workflow design, rather than task-specific
pretraining, drives strong zero-shot REC performance.

</details>


### [97] [Augment to Segment: Tackling Pixel-Level Imbalance in Wheat Disease and Pest Segmentation](https://arxiv.org/abs/2509.09961)
*Tianqi Wei,Xin Yu,Zhi Chen,Scott Chapman,Zi Huang*

Main category: cs.CV

TL;DR: 通过随机投影拷贴扩增技术（RPCP）解决小麦叶部病虫害分割中的极端像素不平衡问题，显著提升稀缺类别的分割性能


<details>
  <summary>Details</summary>
Motivation: 小麦叶部病虫害分割存在极端像素不平衡问题，虫害区域占比极小，导致模型过拟合常见类别而忽略稀缺类别，影响整体性能

Method: 提出RPCP扩增技术：从标注训练图片中提取稀缺虫害补丁，应用随机几何变换模拟变化，将转换后补丁粘贴到适宜区域且避免重叠，并通过随机投影滤波精炼局部特征确保与新背景自然融合

Result: 方法显著提升了虫害类别的分割性能，同时保持或轻微提升其他类别的准确性

Conclusion: 目标化扩增技术能有效缓解极端像素不平衡问题，为农业分割问题提供了简单有效的解决方案

Abstract: Accurate segmentation of foliar diseases and insect damage in wheat is
crucial for effective crop management and disease control. However, the insect
damage typically occupies only a tiny fraction of annotated pixels. This
extreme pixel-level imbalance poses a significant challenge to the segmentation
performance, which can result in overfitting to common classes and insufficient
learning of rare classes, thereby impairing overall performance. In this paper,
we propose a Random Projected Copy-and-Paste (RPCP) augmentation technique to
address the pixel imbalance problem. Specifically, we extract rare
insect-damage patches from annotated training images and apply random geometric
transformations to simulate variations. The transformed patches are then pasted
in appropriate regions while avoiding overlaps with lesions or existing damaged
regions. In addition, we apply a random projection filter to the pasted
regions, refining local features and ensuring a natural blend with the new
background. Experiments show that our method substantially improves
segmentation performance on the insect damage class, while maintaining or even
slightly enhancing accuracy on other categories. Our results highlight the
effectiveness of targeted augmentation in mitigating extreme pixel imbalance,
offering a straightforward yet effective solution for agricultural segmentation
problems.

</details>


### [98] [An HMM-based framework for identity-aware long-term multi-object tracking from sparse and uncertain identification: use case on long-term tracking in livestock](https://arxiv.org/abs/2509.09962)
*Anne Marthe Sophie Ngo Bibinbe,Chiron Bang,Patrick Gagnon,Jamie Ahloy-Dallaire,Eric R. Paquet*

Main category: cs.CV

TL;DR: 基于隐马尔可夫模型的新框架，通过结合不确定身份信息来改善长期多目标跟踪性能，在猪只跟踪数据集和MOT标准数据集上都取得了显著提升


<details>
  <summary>Details</summary>
Motivation: 现有多目标跟踪方法在长时间跟踪中存在身份切换问题，但在如畜牧等实际应用中可以获得偶然的身份识别信息，需要利用这些信息来改善长期跟踪性能

Method: 提出一种新的隐马尔可夫模型框架，能够结合不确定的身份信息和跟踪结果，通过模型化身份识别的不确定性来提高跟踪准确性

Result: 在10分钟的猪只跟踪数据集上，该方法在ByteTrack基础上显著提高了F1分数，并在MOT17和MOT20标准数据集上验证了性能提升，而且性能随着身份信息提供频率的增加而提高

Conclusion: 该方法通过利用偶然获得的身份信息，有效解决了长期多目标跟踪中的身份切换问题，为实际应用提供了可靠的解决方案

Abstract: The need for long-term multi-object tracking (MOT) is growing due to the
demand for analyzing individual behaviors in videos that span several minutes.
Unfortunately, due to identity switches between objects, the tracking
performance of existing MOT approaches decreases over time, making them
difficult to apply for long-term tracking. However, in many real-world
applications, such as in the livestock sector, it is possible to obtain
sporadic identifications for some of the animals from sources like feeders. To
address the challenges of long-term MOT, we propose a new framework that
combines both uncertain identities and tracking using a Hidden Markov Model
(HMM) formulation. In addition to providing real-world identities to animals,
our HMM framework improves the F1 score of ByteTrack, a leading MOT approach
even with re-identification, on a 10 minute pig tracking dataset with 21
identifications at the pen's feeding station. We also show that our approach is
robust to the uncertainty of identifications, with performance increasing as
identities are provided more frequently. The improved performance of our HMM
framework was also validated on the MOT17 and MOT20 benchmark datasets using
both ByteTrack and FairMOT. The code for this new HMM framework and the new
10-minute pig tracking video dataset are available at:
https://github.com/ngobibibnbe/uncertain-identity-aware-tracking

</details>


### [99] [Event Camera Guided Visual Media Restoration & 3D Reconstruction: A Survey](https://arxiv.org/abs/2509.09971)
*Aupendu Kar,Vishnu Raj,Guan-Ming Su*

Main category: cs.CV

TL;DR: 这篇调研论文系统性评估了事件相机与传统框基抓取融合在视频恢复和3D重建任务中的进展，包括时空增强、深度学习方法和数据集资源。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为一种生物受听器，具有低延迟、低功耗和超高抓取速率的优势，但需要与传统框基抓取融合来充分发挥其潜力。

Method: 系统性评估主要深度学习在图像/视频增强和恢复方面的贡献，从时间增强（如帧内插和运动去模糊）和空间增强（包括超分辨率、低光和HDR增强、以及伪影减少）两个维度进行分析。

Result: 调研显示，事件流与传统框基抓取的融合在各种视觉任务中带来显著改善，特别是在具有挑战性条件下的视觉质量提升。还编译了开放数据集资源以支持可复现研究。

Conclusion: 通过整合最新进展和见解，这份调研旨在激励进一步研究利用事件相机系统，特别是与深度学习相结合，以实现高级视觉媒体恢复和增强。

Abstract: Event camera sensors are bio-inspired sensors which asynchronously capture
per-pixel brightness changes and output a stream of events encoding the
polarity, location and time of these changes. These systems are witnessing
rapid advancements as an emerging field, driven by their low latency, reduced
power consumption, and ultra-high capture rates. This survey explores the
evolution of fusing event-stream captured with traditional frame-based capture,
highlighting how this synergy significantly benefits various video restoration
and 3D reconstruction tasks. The paper systematically reviews major deep
learning contributions to image/video enhancement and restoration, focusing on
two dimensions: temporal enhancement (such as frame interpolation and motion
deblurring) and spatial enhancement (including super-resolution, low-light and
HDR enhancement, and artifact reduction). This paper also explores how the 3D
reconstruction domain evolves with the advancement of event driven fusion.
Diverse topics are covered, with in-depth discussions on recent works for
improving visual quality under challenging conditions. Additionally, the survey
compiles a comprehensive list of openly available datasets, enabling
reproducible research and benchmarking. By consolidating recent progress and
insights, this survey aims to inspire further research into leveraging event
camera systems, especially in combination with deep learning, for advanced
visual media restoration and enhancement.

</details>


### [100] [ISTASTrack: Bridging ANN and SNN via ISTA Adapter for RGB-Event Tracking](https://arxiv.org/abs/2509.09977)
*Siying Liu,Zikai Wang,Hanle Zheng,Yifan Hu,Xilin Wang,Qingkai Yang,Jibin Wu,Hao Guo,Lei Deng*

Main category: cs.CV

TL;DR: ISTASTrack是首个基于Transformer的ANN-SNN混合跟踪器，通过ISTA适配器实现RGB和事件数据的有效融合，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有ANN网络难以充分利用事件流的稀疏和异步特性，而混合ANN-SNN架构在特征融合方面仍面临挑战，需要更好的跨范式特征交互方法。

Method: 采用双分支架构：视觉Transformer处理RGB输入，脉冲Transformer处理事件流。设计基于稀疏表示理论的ISTA适配器进行双向特征交互，并加入时序下采样注意力模块对齐特征。

Result: 在FE240hz、VisEvent、COESOT和FELT等RGB-Event跟踪基准测试中实现了最先进的性能，同时保持高能效。

Conclusion: ISTASTrack证明了混合ANN-SNN设计在视觉跟踪中的有效性和实用性，为跨模态跨范式特征融合提供了新思路。

Abstract: RGB-Event tracking has become a promising trend in visual object tracking to
leverage the complementary strengths of both RGB images and dynamic spike
events for improved performance. However, existing artificial neural networks
(ANNs) struggle to fully exploit the sparse and asynchronous nature of event
streams. Recent efforts toward hybrid architectures combining ANNs and spiking
neural networks (SNNs) have emerged as a promising solution in RGB-Event
perception, yet effectively fusing features across heterogeneous paradigms
remains a challenge. In this work, we propose ISTASTrack, the first
transformer-based \textbf{A}NN-\textbf{S}NN hybrid \textbf{Track}er equipped
with \textbf{ISTA} adapters for RGB-Event tracking. The two-branch model
employs a vision transformer to extract spatial context from RGB inputs and a
spiking transformer to capture spatio-temporal dynamics from event streams. To
bridge the modality and paradigm gap between ANN and SNN features, we
systematically design a model-based ISTA adapter for bidirectional feature
interaction between the two branches, derived from sparse representation theory
by unfolding the iterative shrinkage thresholding algorithm. Additionally, we
incorporate a temporal downsampling attention module within the adapter to
align multi-step SNN features with single-step ANN features in the latent
space, improving temporal fusion. Experimental results on RGB-Event tracking
benchmarks, such as FE240hz, VisEvent, COESOT, and FELT, have demonstrated that
ISTASTrack achieves state-of-the-art performance while maintaining high energy
efficiency, highlighting the effectiveness and practicality of hybrid ANN-SNN
designs for robust visual tracking. The code is publicly available at
https://github.com/lsying009/ISTASTrack.git.

</details>


### [101] [FLARE-SSM: Deep State Space Models with Influence-Balanced Loss for 72-Hour Solar Flare Prediction](https://arxiv.org/abs/2509.09988)
*Yusuke Takagi,Shunya Nagashima,Komei Sugiura*

Main category: cs.CV

TL;DR: 提出基于多深度状态空间模型和FLARE损失函数的太阳耀斑预测方法，解决了类别不平衡问题，在11年太阳活动周期数据上表现优于基线方法


<details>
  <summary>Details</summary>
Motivation: 当前太阳耀斑预测性能不足，现有方法难以有效处理耀斑类别间的严重不平衡问题，需要更准确的预测来减轻对关键基础设施的影响

Method: 使用多深度状态空间模型构建太阳耀斑预测模型，引入频率和局部边界感知可靠性损失（FLARE损失）来改善类别不平衡下的预测性能和可靠性

Result: 在覆盖完整11年太阳活动周期的多波长太阳图像数据集上，该方法在Gandin-Murphy-Gerrity分数和真实技能统计量两个标准指标上都优于基线方法

Conclusion: 所提出的多深度状态空间模型结合FLARE损失函数能有效提升太阳耀斑预测的准确性和可靠性，特别是在处理类别不平衡问题方面表现优异

Abstract: Accurate and reliable solar flare predictions are essential to mitigate
potential impacts on critical infrastructure. However, the current performance
of solar flare forecasting is insufficient. In this study, we address the task
of predicting the class of the largest solar flare expected to occur within the
next 72 hours. Existing methods often fail to adequately address the severe
class imbalance across flare classes. To address this issue, we propose a solar
flare prediction model based on multiple deep state space models. In addition,
we introduce the frequency & local-boundary-aware reliability loss (FLARE loss)
to improve predictive performance and reliability under class imbalance.
Experiments were conducted on a multi-wavelength solar image dataset covering a
full 11-year solar activity cycle. As a result, our method outperformed
baseline approaches in terms of both the Gandin-Murphy-Gerrity score and the
true skill statistic, which are standard metrics in terms of the performance
and reliability.

</details>


### [102] [TUNI: Real-time RGB-T Semantic Segmentation with Unified Multi-Modal Feature Extraction and Cross-Modal Feature Fusion](https://arxiv.org/abs/2509.10005)
*Xiaodong Guo,Tong Liu,Yike Li,Zi'ang Lin,Zhihong Deng*

Main category: cs.CV

TL;DR: TUNI是一个RGB-热成像语义分割模型，通过统一的编码器同时进行多模态特征提取和跨模态融合，实现了更紧凑的架构和实时推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-T语义分割模型中热特征提取有限、跨模态融合效果不佳以及编码器冗余导致的实时效率问题。

Method: 提出统一的RGB-T编码器，通过大规模RGB和伪热数据预训练，同时进行特征提取和融合；采用精简的热分支架构；引入RGB-T局部模块，使用自适应余弦相似度选择性地强调跨模态的显著一致和差异局部特征。

Result: 在FMB、PST900和CART数据集上达到与最先进模型竞争的性能，参数量和计算成本更低；在Jetson Orin NX上实现27 FPS的推理速度。

Conclusion: TUNI通过统一的编码器设计和局部特征融合增强，在保持高性能的同时显著提升了模型的效率和实时部署能力。

Abstract: RGB-thermal (RGB-T) semantic segmentation improves the environmental
perception of autonomous platforms in challenging conditions. Prevailing models
employ encoders pre-trained on RGB images to extract features from both RGB and
infrared inputs, and design additional modules to achieve cross-modal feature
fusion. This results in limited thermal feature extraction and suboptimal
cross-modal fusion, while the redundant encoders further compromises the
model's real-time efficiency. To address the above issues, we propose TUNI,
with an RGB-T encoder consisting of multiple stacked blocks that simultaneously
perform multi-modal feature extraction and cross-modal fusion. By leveraging
large-scale pre-training with RGB and pseudo-thermal data, the RGB-T encoder
learns to integrate feature extraction and fusion in a unified manner. By
slimming down the thermal branch, the encoder achieves a more compact
architecture. Moreover, we introduce an RGB-T local module to strengthen the
encoder's capacity for cross-modal local feature fusion. The RGB-T local module
employs adaptive cosine similarity to selectively emphasize salient consistent
and distinct local features across RGB-T modalities. Experimental results show
that TUNI achieves competitive performance with state-of-the-art models on FMB,
PST900 and CART, with fewer parameters and lower computational cost. Meanwhile,
it achieves an inference speed of 27 FPS on a Jetson Orin NX, demonstrating its
real-time capability in deployment. Codes are available at
https://github.com/xiaodonguo/TUNI.

</details>


### [103] [Few-Part-Shot Font Generation](https://arxiv.org/abs/2509.10006)
*Masaki Akiba,Shumpei Takezaki,Daichi Haraguchi,Seiichi Uchida*

Main category: cs.CV

TL;DR: 提出了一种基于部分设计元素的少部件字体生成模型，只需输入部分形状而非完整字符即可生成整个字体


<details>
  <summary>Details</summary>
Motivation: 传统少样本字体生成需要完整字符形状，效率较低。本文旨在通过部分设计元素提高字体创建效率，并探索部分设计细节对整体字符结构的影响

Method: 设计了一个新颖的少部件字体生成模型，以部分形状作为输入来生成整个字体

Result: 该方法不仅提高了字体创建效率，还揭示了部分设计细节如何影响单个字符的整体结构

Conclusion: 该模型为字体设计提供了更高效的解决方案，同时深化了对字体设计元素与整体结构关系的理解

Abstract: This paper proposes a novel model of few-part-shot font generation, which
designs an entire font based on a set of partial design elements, i.e., partial
shapes. Unlike conventional few-shot font generation, which requires entire
character shapes for a couple of character classes, our approach only needs
partial shapes as input. The proposed model not only improves the efficiency of
font creation but also provides insights into how partial design details
influence the entire structure of the individual characters.

</details>


### [104] [Efficient and Accurate Downfacing Visual Inertial Odometry](https://arxiv.org/abs/2509.10021)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: 这篇论文提出了一种专门为微纳无人机优化的高效准确视觉悬浮量算法，采用颇尾特征检测和跟踪技术，在低功耗RISC-V芯片上实现了计算复杂度和跟踪准确性的优化。


<details>
  <summary>Details</summary>
Motivation: 解决高精度VIO算法在计算能力有限的微纳无人机上运行的挑战，接合高性能算法与低功耗硬件平台之间的差距。

Method: 采用SuperPoint、PX4FLOW、ORB等颇尾特征检测和跟踪方法，通过量化和优化适配RISC-V低功耗SoC，使用刚体运动模型减少估计错误。

Result: 在GAP9低功耗SoC上，优化后的管道比基准管道平均RMSE降低了3.65倍（ORB跟踪器），PX4FLOW在运动速度低于24像素/帧时以更低运行时间达到与ORB相似的跟踪准确性。

Conclusion: 该算法成功在低功耗硬件平台上实现了高准确的实时VIO，为微纳无人机提供了一种计算效率和性能均衡的解决方案。

Abstract: Visual Inertial Odometry (VIO) is a widely used computer vision method that
determines an agent's movement through a camera and an IMU sensor. This paper
presents an efficient and accurate VIO pipeline optimized for applications on
micro- and nano-UAVs. The proposed design incorporates state-of-the-art feature
detection and tracking methods (SuperPoint, PX4FLOW, ORB), all optimized and
quantized for emerging RISC-V-based ultra-low-power parallel systems on chips
(SoCs). Furthermore, by employing a rigid body motion model, the pipeline
reduces estimation errors and achieves improved accuracy in planar motion
scenarios. The pipeline's suitability for real-time VIO is assessed on an
ultra-low-power SoC in terms of compute requirements and tracking accuracy
after quantization. The pipeline, including the three feature tracking methods,
was implemented on the SoC for real-world validation. This design bridges the
gap between high-accuracy VIO pipelines that are traditionally run on
computationally powerful systems and lightweight implementations suitable for
microcontrollers. The optimized pipeline on the GAP9 low-power SoC demonstrates
an average reduction in RMSE of up to a factor of 3.65x over the baseline
pipeline when using the ORB feature tracker. The analysis of the computational
complexity of the feature trackers further shows that PX4FLOW achieves on-par
tracking accuracy with ORB at a lower runtime for movement speeds below 24
pixels/frame.

</details>


### [105] [Hierarchical MLANet: Multi-level Attention for 3D Face Reconstruction From Single Images](https://arxiv.org/abs/2509.10024)
*Danling Cao*

Main category: cs.CV

TL;DR: 提出基于卷积神经网络的层次化多级注意力网络(MLANet)，从单张野外图像重建3D人脸模型，预测几何、纹理、姿态和光照参数


<details>
  <summary>Details</summary>
Motivation: 从2D野外图像恢复3D人脸模型在计算机视觉中应用广泛，但缺乏真实标注数据和复杂环境仍是主要挑战

Method: 使用预训练层次化主干网络，引入多级注意力机制进行2D特征提取，采用半监督训练策略结合3DMM参数和可微分渲染器实现端到端训练

Result: 在AFLW2000-3D和MICC Florence基准数据集上进行了对比和消融实验，定量和定性评估均显示方法有效

Conclusion: 提出的MLANet方法能够有效从单张野外图像重建3D人脸模型，解决了缺乏标注数据和复杂环境的挑战

Abstract: Recovering 3D face models from 2D in-the-wild images has gained considerable
attention in the computer vision community due to its wide range of potential
applications. However, the lack of ground-truth labeled datasets and the
complexity of real-world environments remain significant challenges. In this
chapter, we propose a convolutional neural network-based approach, the
Hierarchical Multi-Level Attention Network (MLANet), for reconstructing 3D face
models from single in-the-wild images. Our model predicts detailed facial
geometry, texture, pose, and illumination parameters from a single image.
Specifically, we employ a pre-trained hierarchical backbone network and
introduce multi-level attention mechanisms at different stages of 2D face image
feature extraction. A semi-supervised training strategy is employed,
incorporating 3D Morphable Model (3DMM) parameters from publicly available
datasets along with a differentiable renderer, enabling an end-to-end training
process. Extensive experiments, including both comparative and ablation
studies, were conducted on two benchmark datasets, AFLW2000-3D and MICC
Florence, focusing on 3D face reconstruction and 3D face alignment tasks. The
effectiveness of the proposed method was evaluated both quantitatively and
qualitatively.

</details>


### [106] [LaV-CoT: Language-Aware Visual CoT with Multi-Aspect Reward Optimization for Real-World Multilingual VQA](https://arxiv.org/abs/2509.10026)
*Jing Huang,Zhiya Tan,Shutao Gong,Fanwei Zeng,Jianshu Li*

Main category: cs.CV

TL;DR: LaV-CoT是一个语言感知的视觉思维链框架，通过多阶段推理流程和多方面奖励优化，显著提升多语言视觉问答性能，在多个基准测试中超越开源和专有模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖文本思维链，对多语言多模态推理支持有限，限制了在实际应用中的部署。需要开发能够同时处理多语言和视觉信息的推理框架。

Method: 提出多阶段推理流程（文本摘要+边界框、语言识别、空间对象级描述、逐步逻辑推理），采用自动化数据标注方法，结合监督微调和语言感知组相对策略优化的两阶段训练范式。

Result: 在MMMB、Multilingual MMBench和MTVQA等数据集上，比同规模开源基线提升约9.5%准确率，甚至超过2倍规模模型约2.6%，优于GPT-4o-0513和Gemini-2.5-flash等专有模型。

Conclusion: LaV-CoT框架通过语言感知的视觉思维链和多方面奖励优化，有效提升了多语言视觉问答的性能和泛化能力，具有工业部署的实际价值。

Abstract: As large vision language models (VLMs) advance, their capabilities in
multilingual visual question answering (mVQA) have significantly improved.
Chain-of-thought (CoT) reasoning has been proven to enhance interpretability
and complex reasoning. However, most existing approaches rely primarily on
textual CoT and provide limited support for multilingual multimodal reasoning,
constraining their deployment in real-world applications. To address this gap,
we introduce \textbf{LaV-CoT}, the first Language-aware Visual CoT framework
with Multi-Aspect Reward Optimization. LaV-CoT incorporates an interpretable
multi-stage reasoning pipeline consisting of Text Summary with Bounding Box
(BBox), Language Identification, Spatial Object-level Captioning, and
Step-by-step Logical Reasoning. Following this reasoning pipeline, we design an
automated data curation method that generates multilingual CoT annotations
through iterative generation, correction, and refinement, enabling scalable and
high-quality training data. To improve reasoning and generalization, LaV-CoT
adopts a two-stage training paradigm combining Supervised Fine-Tuning (SFT)
with Language-aware Group Relative Policy Optimization (GRPO), guided by
verifiable multi-aspect rewards including language consistency, structural
accuracy, and semantic alignment. Extensive evaluations on public datasets
including MMMB, Multilingual MMBench, and MTVQA show that LaV-CoT achieves up
to \(\sim\)9.5\% accuracy improvements over open-source baselines of similar
size and even surpasses models with 2$\times$ larger scales by \(\sim\)2.6\%.
Moreover, LaV-CoT outperforms advanced proprietary models such as GPT-4o-0513
and Gemini-2.5-flash. We further conducted an online A/B test to validate our
method on real-world data, highlighting its effectiveness for industrial
deployment. Our code is available at this link:
\href{https://github.com/HJNVR/LaV-CoT}

</details>


### [107] [Color Me Correctly: Bridging Perceptual Color Spaces and Text Embeddings for Improved Diffusion Generation](https://arxiv.org/abs/2509.10058)
*Sung-Lin Tsai,Bo-Lun Huang,Yu Ting Shen,Cheng Yu Yeo,Chiang Tseng,Bo-Kai Ruan,Wen-Sheng Lien,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出无需训练的框架，利用大语言模型解析模糊颜色词汇，在文本嵌入空间指导颜色混合，提高文本到图像生成的颜色准确性


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在处理复杂颜色词汇时存在颜色对齐问题，无法准确理解如Tiffany蓝、柠檬绿等复合颜色术语，导致生成图像与人类意图不符

Method: 使用大语言模型解析文本提示中的模糊颜色术语，基于CIELAB颜色空间的空间关系精炼文本嵌入，直接在嵌入空间指导颜色混合操作

Result: 实验结果表明该方法在不影响图像质量的情况下显著提高了颜色对齐准确性，弥合了文本语义与视觉生成之间的差距

Conclusion: 该训练免费框架通过语言模型的颜色消歧和嵌入空间优化，有效解决了文本到图像生成中的颜色准确性问题，无需额外训练或参考图像

Abstract: Accurate color alignment in text-to-image (T2I) generation is critical for
applications such as fashion, product visualization, and interior design, yet
current diffusion models struggle with nuanced and compound color terms (e.g.,
Tiffany blue, lime green, hot pink), often producing images that are misaligned
with human intent. Existing approaches rely on cross-attention manipulation,
reference images, or fine-tuning but fail to systematically resolve ambiguous
color descriptions. To precisely render colors under prompt ambiguity, we
propose a training-free framework that enhances color fidelity by leveraging a
large language model (LLM) to disambiguate color-related prompts and guiding
color blending operations directly in the text embedding space. Our method
first employs a large language model (LLM) to resolve ambiguous color terms in
the text prompt, and then refines the text embeddings based on the spatial
relationships of the resulting color terms in the CIELAB color space. Unlike
prior methods, our approach improves color accuracy without requiring
additional training or external reference images. Experimental results
demonstrate that our framework improves color alignment without compromising
image quality, bridging the gap between text semantics and visual generation.

</details>


### [108] [Multimodal Mathematical Reasoning Embedded in Aerial Vehicle Imagery: Benchmarking, Analysis, and Exploration](https://arxiv.org/abs/2509.10059)
*Yue Zhou,Litong Feng,Mengcheng Lan,Xue Yang,Qingyun Li,Yiping Ke,Xue Jiang,Wayne Zhang*

Main category: cs.CV

TL;DR: AVI-Math是首个专门评估无人机遥感图像中多模态数学推理能力的基准数据集，包含3,773个高质量车辆相关问题，涵盖6个数学学科和20个主题。测试发现当前主流视觉语言模型在数学推理任务上表现不佳，但思维链提示和微调技术显示出改进潜力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在无人机遥感领域的数学推理能力（如精确距离计算、轨迹估计和空间分析）尚未得到充分测试，需要专门的基准来评估和改进模型在这方面的表现。

Method: 构建AVI-Math基准数据集，包含从不同高度和角度采集的无人机图像，涵盖几何、逻辑和代数等数学领域。对14个主流视觉语言模型进行全面评估，并探索思维链提示和微调技术的应用效果。

Result: 尽管这些模型在以往的多模态基准测试中表现成功，但在AVI-Math的推理任务中表现不佳，显示出当前视觉语言模型在数学推理能力方面存在显著局限性。

Conclusion: 研究不仅揭示了视觉语言模型在数学推理方面的局限性，还为推进无人机应用中可信赖视觉语言模型的发展提供了有价值的见解，思维链提示和微调技术为解决这些推理挑战提供了有希望的途径。

Abstract: Mathematical reasoning is critical for tasks such as precise distance and
area computations, trajectory estimations, and spatial analysis in unmanned
aerial vehicle (UAV) based remote sensing, yet current vision-language models
(VLMs) have not been adequately tested in this domain. To address this gap, we
introduce AVI-Math, the first benchmark to rigorously evaluate multimodal
mathematical reasoning in aerial vehicle imagery, moving beyond simple counting
tasks to include domain-specific knowledge in areas such as geometry, logic,
and algebra. The dataset comprises 3,773 high-quality vehicle-related questions
captured from UAV views, covering 6 mathematical subjects and 20 topics. The
data, collected at varying altitudes and from multiple UAV angles, reflects
real-world UAV scenarios, ensuring the diversity and complexity of the
constructed mathematical problems. In this paper, we benchmark 14 prominent
VLMs through a comprehensive evaluation and demonstrate that, despite their
success on previous multimodal benchmarks, these models struggle with the
reasoning tasks in AVI-Math. Our detailed analysis highlights significant
limitations in the mathematical reasoning capabilities of current VLMs and
suggests avenues for future research. Furthermore, we explore the use of
Chain-of-Thought prompting and fine-tuning techniques, which show promise in
addressing the reasoning challenges in AVI-Math. Our findings not only expose
the limitations of VLMs in mathematical reasoning but also offer valuable
insights for advancing UAV-based trustworthy VLMs in real-world applications.
The code, and datasets will be released at
https://github.com/VisionXLab/avi-math

</details>


### [109] [BEVTraj: Map-Free End-to-End Trajectory Prediction in Bird's-Eye View with Deformable Attention and Sparse Goal Proposals](https://arxiv.org/abs/2509.10080)
*Minsang Kong,Myeongjun Kim,Sang Gu Kang,Sang Hun Lee*

Main category: cs.CV

TL;DR: BEVTraj是一个新颖的轨迹预测框架，直接在鸟瞰图空间利用实时传感器数据进行轨迹预测，无需依赖预建高清地图，通过可变形注意力和稀疏目标候选提议模块实现端到端预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预建高清地图或实时地图构建模块，但预建地图局限于特定区域且无法适应瞬时变化，而地图构建模块可能遗漏关键场景细节或引入错误，影响预测性能。

Method: 提出BEVTraj框架，直接在BEV空间操作，使用可变形注意力从密集BEV特征中高效提取相关上下文，并引入稀疏目标候选提议(SGCP)模块实现完全端到端预测，无需后处理步骤。

Result: 大量实验表明，BEVTraj在性能上与最先进的基于高清地图的模型相当，同时通过消除对预建地图的依赖提供了更大的灵活性。

Conclusion: BEVTraj成功克服了现有地图依赖方法的局限性，在保持高性能的同时提供了更好的适应性和灵活性，为自动驾驶轨迹预测提供了新的解决方案。

Abstract: In autonomous driving, trajectory prediction is essential for ensuring safe
and efficient navigation. To improve prediction accuracy, recent approaches
often rely on pre-built high-definition (HD) maps or real-time local map
construction modules to incorporate static environmental information. However,
pre-built HD maps are limited to specific regions and cannot adapt to transient
changes. In addition, local map construction modules, which recognize only
predefined elements, may fail to capture critical scene details or introduce
errors that degrade prediction performance. To overcome these limitations, we
propose Bird's-Eye View Trajectory Prediction (BEVTraj), a novel trajectory
prediction framework that operates directly in the bird's-eye view (BEV) space
utilizing real-time sensor data without relying on any pre-built maps. The
BEVTraj leverages deformable attention to efficiently extract relevant context
from dense BEV features. Furthermore, we introduce a Sparse Goal Candidate
Proposal (SGCP) module, which enables full end-to-end prediction without
requiring any post-processing steps. Extensive experiments demonstrate that the
BEVTraj achieves performance comparable to state-of-the-art HD map-based models
while offering greater flexibility by eliminating the dependency on pre-built
maps. The source code is available at https://github.com/Kongminsang/bevtraj.

</details>


### [110] [Leveraging Multi-View Weak Supervision for Occlusion-Aware Multi-Human Parsing](https://arxiv.org/abs/2509.10093)
*Laura Bragagnolo,Matteo Terreran,Leonardo Barcellona,Stefano Ghidoni*

Main category: cs.CV

TL;DR: 通过利用多视角信息来改善多人语义分割模型在遮挡场景下的表现，提出了包含弱监督和多视角一致性损失的训练框架，并且为此开发了半自动注释策略来生成多视角RGB+D数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的多人语义分割方法在处理重叠人体时表现差强，而不同视角可能揭示被遮挡的部分，因此需要利用多视角信息来提升模型在遮挡情况下的性能。

Method: 提出了一种新的训练框架，包含基于人体实例的弱监督方法和多视角一致性损失。为了解决数据集缺乏问题，还开发了半自动注释策略，从多视角RGB+D数据和3D人体骨架生成人体实例分割面具。

Result: 实验结果显示，该方法在遮挡场景下能够相比基线模型获得4.20%的相对攻测提升，显著改善了多人语义分割的性能。

Conclusion: 通过利用多视角信息和提出的训练框架，成功地提升了多人语义分割模型在遮挡情况下的表现，为处理人体重叠问题提供了有效的解决方案。

Abstract: Multi-human parsing is the task of segmenting human body parts while
associating each part to the person it belongs to, combining instance-level and
part-level information for fine-grained human understanding. In this work, we
demonstrate that, while state-of-the-art approaches achieved notable results on
public datasets, they struggle considerably in segmenting people with
overlapping bodies. From the intuition that overlapping people may appear
separated from a different point of view, we propose a novel training framework
exploiting multi-view information to improve multi-human parsing models under
occlusions. Our method integrates such knowledge during the training process,
introducing a novel approach based on weak supervision on human instances and a
multi-view consistency loss. Given the lack of suitable datasets in the
literature, we propose a semi-automatic annotation strategy to generate human
instance segmentation masks from multi-view RGB+D data and 3D human skeletons.
The experiments demonstrate that the approach can achieve up to a 4.20\%
relative improvement on human parsing over the baseline model in occlusion
scenarios.

</details>


### [111] [VARCO-VISION-2.0 Technical Report](https://arxiv.org/abs/2509.10105)
*Young-rok Cha,Jeongho Ju,SunYoung Park,Jong-Hyeon Lee,Younghyun Yu,Youngjune Kim*

Main category: cs.CV

TL;DR: VARCO-VISION-2.0是一个开源的韩英双语视觉语言模型，相比前代模型能力提升，支持多图像理解、布局感知OCR，在14B和1.7B两个规模版本上都表现出色。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够同时处理韩语和英语的双语视觉语言模型，支持复杂多图像输入和空间定位功能，推动双语VLM的实际应用发展。

Method: 采用四阶段课程训练和内存高效技术，通过偏好优化提高安全性，同时保持核心语言能力并增强多模态对齐。

Result: 在广泛基准测试中展现出强大的空间定位能力，14B模型在OpenCompass VLM排行榜上位列同规模模型第8名，两个版本模型都取得了有竞争力的结果。

Conclusion: VARCO-VISION-2.0模型推动了双语视觉语言模型的发展，提供了从完整规模到轻量级的解决方案，具有实际应用价值。

Abstract: We introduce VARCO-VISION-2.0, an open-weight bilingual vision-language model
(VLM) for Korean and English with improved capabilities compared to the
previous model VARCO-VISION-14B. The model supports multi-image understanding
for complex inputs such as documents, charts, and tables, and delivers
layoutaware OCR by predicting both textual content and its spatial location.
Trained with a four-stage curriculum with memory-efficient techniques, the
model achieves enhanced multimodal alignment, while preserving core language
abilities and improving safety via preference optimization. Extensive benchmark
evaluations demonstrate strong spatial grounding and competitive results for
both languages, with the 14B model achieving 8th place on the OpenCompass VLM
leaderboard among models of comparable scale. Alongside the 14B-scale model, we
release a 1.7B version optimized for on-device deployment. We believe these
models advance the development of bilingual VLMs and their practical
applications. Two variants of VARCO-VISION-2.0 are available at Hugging Face: a
full-scale 14B model and a lightweight 1.7B model.

</details>


### [112] [A Lightweight Ensemble-Based Face Image Quality Assessment Method with Correlation-Aware Loss](https://arxiv.org/abs/2509.10114)
*MohammadAli Hamidi,Hadi Amirpour,Luigi Atzori,Christian Timmerer*

Main category: cs.CV

TL;DR: 轻量级面部图像质量评估方法，结合MobileNetV3-Small和ShuffleNetV2集成学习，通过MSECorrLoss捐失函数提升与人类觉知的一致性，在保持高准确度的同时具有低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有面部图像质量评估方法或者无法抓取面部特定的降级特征，或者计算复杂度过高限制实际应用。需要一种既准确又高效的解决方案。

Method: 集成两个细粒度卷积神经网络(MobileNetV3-Small和ShuffleNetV2)，通过简单平均进行预测级融合。使用MSECorrLoss捐失函数，结合均方误差和Pearson相关性正则化来优化模型。

Result: 在VQualA测试集上达到SRCC 0.9829和PLCC 0.9894的高相关性系数，同时满足效率约束要求。

Conclusion: 该方法在准确性和计算效率之间取得良好平衡，适合实际部署应用。

Abstract: Face image quality assessment (FIQA) plays a critical role in face
recognition and verification systems, especially in uncontrolled, real-world
environments. Although several methods have been proposed, general-purpose
no-reference image quality assessment techniques often fail to capture
face-specific degradations. Meanwhile, state-of-the-art FIQA models tend to be
computationally intensive, limiting their practical applicability. We propose a
lightweight and efficient method for FIQA, designed for the perceptual
evaluation of face images in the wild. Our approach integrates an ensemble of
two compact convolutional neural networks, MobileNetV3-Small and ShuffleNetV2,
with prediction-level fusion via simple averaging. To enhance alignment with
human perceptual judgments, we employ a correlation-aware loss (MSECorrLoss),
combining mean squared error (MSE) with a Pearson correlation regularizer. Our
method achieves a strong balance between accuracy and computational cost,
making it suitable for real-world deployment. Experiments on the VQualA FIQA
benchmark demonstrate that our model achieves a Spearman rank correlation
coefficient (SRCC) of 0.9829 and a Pearson linear correlation coefficient
(PLCC) of 0.9894, remaining within competition efficiency constraints.

</details>


### [113] [Realism Control One-step Diffusion for Real-World Image Super-Resolution](https://arxiv.org/abs/2509.10122)
*Zongliang Wu,Siming Zheng,Peng-Tao Jiang,Xin Yuan*

Main category: cs.CV

TL;DR: 基于预训练模型的实际图像超分辨率方法RCOD，通过潜在域分组策略和视觉提示注入，实现了效率与质量的平衡，支持推理阶段的灵活现实性控制。


<details>
  <summary>Details</summary>
Motivation: 解决一步滑散方法在实际图像超分辨率任务中对保真度和现实性的平衡问题，因为单时间步训练缺乏多步方法通过调整采样步数来控制这些相互冲突目标的灵活性。

Method: 提出RCOD框架，包括：1、潜在域分组策略在噪声预测阶段实现明确的保真度-现实性交换控制；2、降级感知采样策略对齐简化正则化与分组策略；3、用降级感知视觉令牌替代传统文本提示的视觉提示注入模块。

Result: 实验结果显示RCOD在数量指标和视觉质量上都超过了最先进的一步滑散方法，同时保持计算效率，并在推理阶段具有灵活的现实性控制能力。

Conclusion: RCOD框架有效解决了一步滑散方法在实际图像超分辨率中的保真度与现实性平衡问题，通过创新的控制机制实现了效率与质量的优化结合。

Abstract: Pre-trained diffusion models have shown great potential in real-world image
super-resolution (Real-ISR) tasks by enabling high-resolution reconstructions.
While one-step diffusion (OSD) methods significantly improve efficiency
compared to traditional multi-step approaches, they still have limitations in
balancing fidelity and realism across diverse scenarios. Since the OSDs for SR
are usually trained or distilled by a single timestep, they lack flexible
control mechanisms to adaptively prioritize these competing objectives, which
are inherently manageable in multi-step methods through adjusting sampling
steps. To address this challenge, we propose a Realism Controlled One-step
Diffusion (RCOD) framework for Real-ISR. RCOD provides a latent domain grouping
strategy that enables explicit control over fidelity-realism trade-offs during
the noise prediction phase with minimal training paradigm modifications and
original training data. A degradation-aware sampling strategy is also
introduced to align distillation regularization with the grouping strategy and
enhance the controlling of trade-offs. Moreover, a visual prompt injection
module is used to replace conventional text prompts with degradation-aware
visual tokens, enhancing both restoration accuracy and semantic consistency.
Our method achieves superior fidelity and perceptual quality while maintaining
computational efficiency. Extensive experiments demonstrate that RCOD
outperforms state-of-the-art OSD methods in both quantitative metrics and
visual qualities, with flexible realism control capabilities in the inference
stage. The code will be released.

</details>


### [114] [Grad-CL: Source Free Domain Adaptation with Gradient Guided Feature Disalignment](https://arxiv.org/abs/2509.10134)
*Rini Smita Thakur,Rajeev Ranjan Dwivedi,Vinod K Kurmi*

Main category: cs.CV

TL;DR: Grad-CL是一个无需源数据的域适应框架，通过梯度引导的伪标签优化和对比学习策略，在眼底图像分割任务中实现跨域性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决眼底图像分割模型在不同成像协议或条件下性能显著下降的问题，特别是在无法访问原始源数据的情况下实现域适应。

Method: 采用两阶段方法：第一阶段通过梯度机制提取类别特征并进行不确定性量化，优化噪声伪标签；第二阶段使用余弦相似度对比损失增强视杯和视盘特征的类间可分性。

Result: 在多个跨域眼底成像数据集上的实验表明，Grad-CL在分割精度和边界描绘方面优于现有的无监督和无需源数据的域适应方法。

Conclusion: Grad-CL框架有效解决了眼底图像分割的域适应问题，无需源数据即可实现鲁棒的跨域性能，为眼科疾病早期诊断提供了可靠工具。

Abstract: Accurate segmentation of the optic disc and cup is critical for the early
diagnosis and management of ocular diseases such as glaucoma. However,
segmentation models trained on one dataset often suffer significant performance
degradation when applied to target data acquired under different imaging
protocols or conditions. To address this challenge, we propose
\textbf{Grad-CL}, a novel source-free domain adaptation framework that
leverages a pre-trained source model and unlabeled target data to robustly
adapt segmentation performance without requiring access to the original source
data. Grad-CL combines a gradient-guided pseudolabel refinement module with a
cosine similarity-based contrastive learning strategy. In the first stage,
salient class-specific features are extracted via a gradient-based mechanism,
enabling more accurate uncertainty quantification and robust prototype
estimation for refining noisy pseudolabels. In the second stage, a contrastive
loss based on cosine similarity is employed to explicitly enforce inter-class
separability between the gradient-informed features of the optic cup and disc.
Extensive experiments on challenging cross-domain fundus imaging datasets
demonstrate that Grad-CL outperforms state-of-the-art unsupervised and
source-free domain adaptation methods, achieving superior segmentation accuracy
and improved boundary delineation. Project and code are available at
https://visdomlab.github.io/GCL/.

</details>


### [115] [Scalable Training for Vector-Quantized Networks with 100% Codebook Utilization](https://arxiv.org/abs/2509.10140)
*Yifan Chang,Jie Qin,Limeng Qiao,Xiaofeng Wang,Zheng Zhu,Lin Ma,Xingang Wang*

Main category: cs.CV

TL;DR: VQBridge方法通过压缩-处理-恢复流水线解决了VQ训练中的不稳定问题，实现100%码本使用率，提升了重建性能和图像生成质量


<details>
  <summary>Details</summary>
Motivation: 解决向量量化(VQ)在训练过程中遇到的直通估计偏差、一步后更新和码本梯度稀疏等问题，这些问题导致了次优的重建性能和低码本使用率

Method: 提出VQBridge方法，基于map函数方法构建了一个稳健、可扩展的投影器，通过压缩-处理-恢复流水线优化码向量，结合学习逆逆减策略

Result: 实现了100%码本使用率，在262k大码本下仍保持高效率，达到了state-of-the-art的重建性能，并且在LlamaGen中显著提升了图像生成性能，超越了VAR和DiT模型

Conclusion: VQBridge方法有效解决了VQ训练的核心问题，高质量的离散化器对自回归图像生成至关重要，该方法具有良好的可扩展性和通用性

Abstract: Vector quantization (VQ) is a key component in discrete tokenizers for image
generation, but its training is often unstable due to straight-through
estimation bias, one-step-behind updates, and sparse codebook gradients, which
lead to suboptimal reconstruction performance and low codebook usage. In this
work, we analyze these fundamental challenges and provide a simple yet
effective solution. To maintain high codebook usage in VQ networks (VQN) during
learning annealing and codebook size expansion, we propose VQBridge, a robust,
scalable, and efficient projector based on the map function method. VQBridge
optimizes code vectors through a compress-process-recover pipeline, enabling
stable and effective codebook training. By combining VQBridge with learning
annealing, our VQN achieves full (100%) codebook usage across diverse codebook
configurations, which we refer to as FVQ (FullVQ). Through extensive
experiments, we demonstrate that FVQ is effective, scalable, and generalizable:
it attains 100% codebook usage even with a 262k-codebook, achieves
state-of-the-art reconstruction performance, consistently improves with larger
codebooks, higher vector channels, or longer training, and remains effective
across different VQ variants. Moreover, when integrated with LlamaGen, FVQ
significantly enhances image generation performance, surpassing visual
autoregressive models (VAR) by 0.5 and diffusion models (DiT) by 0.2 rFID,
highlighting the importance of high-quality tokenizers for strong
autoregressive image generation.

</details>


### [116] [LayerLock: Non-collapsing Representation Learning with Progressive Freezing](https://arxiv.org/abs/2509.10156)
*Goker Erdogan,Nikhil Parthasarathy,Catalin Ionescu,Drew Hudson,Alexander Lerchner,Andrew Zisserman,Mehdi Sajjadi,Joao Carreira*

Main category: cs.CV

TL;DR: LayerLock是一种通过逐层冻结实现从像素预测到潜在预测渐进过渡的自监督视觉表示学习方法，可加速训练并避免表示崩溃


<details>
  <summary>Details</summary>
Motivation: 观察到ViT层在视频掩码自编码训练中按深度顺序收敛（浅层先收敛，深层后收敛），希望利用这一现象来加速训练并改进潜在预测方法

Method: 通过明确的进度表在训练过程中逐步冻结模型层，实现从像素预测到潜在预测的渐进过渡

Result: 在高达40亿参数的大型模型上应用LayerLock，在4DS感知套件上的结果超越了非潜在掩码预测方法

Conclusion: LayerLock是一种简单有效的自监督学习方法，通过渐进层冻结策略成功解决了表示崩溃问题并提升了大规模模型的性能

Abstract: We introduce LayerLock, a simple yet effective approach for self-supervised
visual representation learning, that gradually transitions from pixel to latent
prediction through progressive layer freezing. First, we make the observation
that during training of video masked-autoencoding (MAE) models, ViT layers
converge in the order of their depth: shallower layers converge early, deeper
layers converge late. We then show that this observation can be exploited to
accelerate standard MAE by progressively freezing the model according to an
explicit schedule, throughout training. Furthermore, this same schedule can be
used in a simple and scalable approach to latent prediction that does not
suffer from "representation collapse". We apply our proposed approach,
LayerLock, to large models of up to 4B parameters with results surpassing those
of non-latent masked prediction on the 4DS perception suite.

</details>


### [117] [On the Geometric Accuracy of Implicit and Primitive-based Representations Derived from View Rendering Constraints](https://arxiv.org/abs/2509.10241)
*Elias De Smijter,Renaud Detry,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: 本文系统比较了隐式和显式新视角合成方法在空间3D物体重建中的表现，发现外观嵌入虽能提升光度保真度但无法显著改善几何精度，凸面体溅射比高斯溅射能产生更紧凑且无杂乱的表示。


<details>
  <summary>Details</summary>
Motivation: 空间机器人应用需要高精度的几何重建，但现有方法在外观嵌入对几何精度的影响方面缺乏系统研究，需要明确外观嵌入在几何中心任务中的局限性。

Method: 使用SPEED+数据集，比较K-Planes、高斯溅射和凸面体溅射三种方法，分析外观嵌入对primitive数量和几何精度的影响。

Result: 外观嵌入主要减少显式方法所需的primitive数量而非提升几何保真度；凸面体溅射相比高斯溅射能产生更紧凑且无杂乱的表示，更适合安全关键应用。

Conclusion: 外观嵌入在几何中心任务中作用有限，空间场景中需要在重建质量和表示效率之间进行权衡，凸面体溅射在交互和碰撞避免等安全关键应用中具有优势。

Abstract: We present the first systematic comparison of implicit and explicit Novel
View Synthesis methods for space-based 3D object reconstruction, evaluating the
role of appearance embeddings. While embeddings improve photometric fidelity by
modeling lighting variation, we show they do not translate into meaningful
gains in geometric accuracy - a critical requirement for space robotics
applications. Using the SPEED+ dataset, we compare K-Planes, Gaussian
Splatting, and Convex Splatting, and demonstrate that embeddings primarily
reduce the number of primitives needed for explicit methods rather than
enhancing geometric fidelity. Moreover, convex splatting achieves more compact
and clutter-free representations than Gaussian splatting, offering advantages
for safety-critical applications such as interaction and collision avoidance.
Our findings clarify the limits of appearance embeddings for geometry-centric
tasks and highlight trade-offs between reconstruction quality and
representation efficiency in space scenarios.

</details>


### [118] [GAMMA: Generalizable Alignment via Multi-task and Manipulation-Augmented Training for AI-Generated Image Detection](https://arxiv.org/abs/2509.10250)
*Haozhen Yan,Yan Hong,Suning Lang,Jiahui Zhan,Yikun Ji,Yujie Gao,Jun Lan,Huijia Zhu,Weiqiang Wang,Jianfu Zhang*

Main category: cs.CV

TL;DR: GAMMA是一个新的AI生成图像检测框架，通过减少域偏差和增强语义对齐来提升对未见生成模型的泛化能力，在GenImage基准上准确率提升5.8%


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器过度依赖生成特定的伪影（如风格先验和压缩模式），导致对未见生成模型的泛化能力有限

Method: 提出GAMMA训练框架，引入多样化操作策略（基于修复的操作和语义保持扰动），采用多任务监督（双分割头和分类头），并引入反向交叉注意力机制

Result: 在GenImage基准上达到最先进的泛化性能，准确率提升5.8%，对新发布的GPT-4o等生成模型保持强鲁棒性

Conclusion: GAMMA通过减少域偏差和增强语义对齐，显著提升了AI生成图像检测的泛化能力和鲁棒性

Abstract: With generative models becoming increasingly sophisticated and diverse,
detecting AI-generated images has become increasingly challenging. While
existing AI-genereted Image detectors achieve promising performance on
in-distribution generated images, their generalization to unseen generative
models remains limited. This limitation is largely attributed to their reliance
on generation-specific artifacts, such as stylistic priors and compression
patterns. To address these limitations, we propose GAMMA, a novel training
framework designed to reduce domain bias and enhance semantic alignment. GAMMA
introduces diverse manipulation strategies, such as inpainting-based
manipulation and semantics-preserving perturbations, to ensure consistency
between manipulated and authentic content. We employ multi-task supervision
with dual segmentation heads and a classification head, enabling pixel-level
source attribution across diverse generative domains. In addition, a reverse
cross-attention mechanism is introduced to allow the segmentation heads to
guide and correct biased representations in the classification branch. Our
method achieves state-of-the-art generalization performance on the GenImage
benchmark, imporving accuracy by 5.8%, but also maintains strong robustness on
newly released generative model such as GPT-4o.

</details>


### [119] [Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI](https://arxiv.org/abs/2509.10257)
*Ema Masterl,Tina Vipotnik Vesnaver,Žiga Špiclin*

Main category: cs.CV

TL;DR: 这篇论文比较了三种元胎脑部MRI超分辨率重建方法（NiftyMIC、SVRTK、NeSVoR）在140例健康和病理案例中的表现，发现NeSVoR具有最高的重建成功率，虽然体积测量存在差异，但诊断性能受SRR方法影响小。


<details>
  <summary>Details</summary>
Motivation: 元胎脑部MRI采集存在分辨率低、运动伪影和缺乏3D解剖结构的问题。虽然有多种超分辨率重建方法，但它们在病理案例中的比较性能能以及对下游份析任务的影响仍未得到充分研究。

Method: 将三种独立的SRR方法（NiftyMIC、SVRTK、NeSVoR）应用于140例元胎脑部MRI扫描（包括健康对照组和脑室扩大病理案例），使用BoUNTi算法进行分割获取9个主要脑部结构的体积，并评估视觉质量、重建成功率、体积测量一致性和诊断分类性能。

Result: NeSVoR在健康和病理组中均展现最高且最一致的重建成功率（>90%）。虽然不同SRR方法之间在体积估计上存在显著差异，但脑室扩大的分类诊断性能并未受到SRR方法选择的影响。

Conclusion: NeSVoR方法具有明显的稳健性优势，而诊断性能在SRR导致的体积变异情况下仍保持良好。这为元胎脑部MRI超分辨率重建方法的选择提供了重要参考。

Abstract: Fetal brain MRI relies on rapid multi-view 2D slice acquisitions to reduce
motion artifacts caused by fetal movement. However, these stacks are typically
low resolution, may suffer from motion corruption, and do not adequately
capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to
address these limitations by combining slice-to-volume registration and
super-resolution techniques to generate high-resolution (HR) 3D volumes. While
several SRR methods have been proposed, their comparative performance -
particularly in pathological cases - and their influence on downstream
volumetric analysis and diagnostic tasks remain underexplored. In this study,
we applied three state-of-the-art SRR method - NiftyMIC, SVRTK, and NeSVoR - to
140 fetal brain MRI scans, including both healthy controls (HC) and
pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was
segmented using the BoUNTi algorithm to extract volumes of nine principal brain
structures. We evaluated visual quality, SRR success rates, volumetric
measurement agreement, and diagnostic classification performance. NeSVoR
demonstrated the highest and most consistent reconstruction success rate (>90%)
across both HC and PC groups. Although significant differences in volumetric
estimates were observed between SRR methods, classification performance for VM
was not affected by the choice of SRR method. These findings highlight NeSVoR's
robustness and the resilience of diagnostic performance despite SRR-induced
volumetric variability.

</details>


### [120] [Mask Consistency Regularization in Object Removal](https://arxiv.org/abs/2509.10259)
*Hua Yuan,Jin Yuan,Yicheng Jiang,Yao Zhang,Xin Geng,Yong Rui*

Main category: cs.CV

TL;DR: 通过提出面具一致性正则化(MCR)训练策略，解决图像修补中的面具幻觉和面具形状偏辛问题，提升物体移除效果


<details>
  <summary>Details</summary>
Motivation: 当前涵散模型在物体移除任务中存在两个关键问题：面具幻觉(在遮罩区域生成无关内容)和面具形状偏辛(按照遮罩形状生成物体而非周围内容)

Method: 提出面具一致性正则化(MCR)训练策略，通过扩张和重新形状两种面具批动方式，强制批动分支与原始面具输出之间的一致性

Result: 实验表明MCR显著减少了幻觉现象和面具形状偏辛，提升了物体移除的性能

Conclusion: MCR能够生成更稳健和上下文一致的图像修补结果，有效解决了当前涵散模型在物体移除任务中的关键挑战

Abstract: Object removal, a challenging task within image inpainting, involves
seamlessly filling the removed region with content that matches the surrounding
context. Despite advancements in diffusion models, current methods still face
two critical challenges. The first is mask hallucination, where the model
generates irrelevant or spurious content inside the masked region, and the
second is mask-shape bias, where the model fills the masked area with an object
that mimics the mask's shape rather than surrounding content. To address these
issues, we propose Mask Consistency Regularization (MCR), a novel training
strategy designed specifically for object removal tasks. During training, our
approach introduces two mask perturbations: dilation and reshape, enforcing
consistency between the outputs of these perturbed branches and the original
mask. The dilated masks help align the model's output with the surrounding
content, while reshaped masks encourage the model to break the mask-shape bias.
This combination of strategies enables MCR to produce more robust and
contextually coherent inpainting results. Our experiments demonstrate that MCR
significantly reduces hallucinations and mask-shape bias, leading to improved
performance in object removal.

</details>


### [121] [MagicMirror: A Large-Scale Dataset and Benchmark for Fine-Grained Artifacts Assessment in Text-to-Image Generation](https://arxiv.org/abs/2509.10260)
*Jia Wang,Jie Hu,Xiaoqi Ma,Hanghang Ma,Yanbing Zeng,Xiaoming Wei*

Main category: cs.CV

TL;DR: 这篇论文提出了MagicMirror框架，包含第一个大规模人工标注的生成图片故障数据集、一个视觉-语言模型评估器和一个自动化测试基准，用于系统评估文本到图像生成模型的图像故障问题。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成模型虽然取得了显著进步，但仍普遍存在生理结构等物理故障，影响感知质量和应用。当前缺乏系统化的细粒度评估框架来应对这些多样化的故障问题。

Method: 1）建立了生成图片故障的详细分类系统
2）手工标注了340K大规模数据集MagicData340K
3）训练了视视-语言模型MagicAssessor进行详细评估
4）设计了新的数据采样策略和多级奖励系统来应对类不平衡问题
5）构建了自动化测试基准MagicBench

Result: 评测结果显示，即使是GPT-image-1等顶级模型也一直受到严重故障问题的困扰，说明故障减少是未来T2I发展的关键前沿。

Conclusion: 该研究为T2I生成模型提供了一个系统化的故障评估框架，帮助识别和解决图像生成中的物理缺陷问题，推动图像生成质量的提升。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress in
instruction following and aesthetics. However, a persistent challenge is the
prevalence of physical artifacts, such as anatomical and structural flaws,
which severely degrade perceptual quality and limit application. Given the
diversity and complexity of these artifacts, a systematic and fine-grained
evaluation framework is required, which is lacking in current benchmarks. To
fill this gap, we introduce MagicMirror, a comprehensive framework for
artifacts assessment. We first establish a detailed taxonomy of generated image
artifacts. Guided by this taxonomy, we manually annotate MagicData340K, the
first human-annotated large-scale dataset of 340K generated images with
fine-grained artifact labels. Building on this dataset, we train MagicAssessor,
a Vision-Language Model (VLM) that provides detailed assessments and
corresponding labels. To overcome challenges like class imbalance and reward
hacking, we design a novel data sampling strategy and a multi-level reward
system for Group Relative Policy Optimization (GRPO). Finally, we leverage
MagicAssessor to construct MagicBench, an automated benchmark for evaluating
the image artifacts of current T2I models. Our evaluation with MagicBench
reveals that despite their widespread adoption, even top-tier models like
GPT-image-1 are consistently plagued by significant artifacts, highlighting
artifact reduction as a critical frontier for future T2I development. Project
page: https://wj-inf.github.io/MagicMirror-page/.

</details>


### [122] [SignClip: Leveraging Mouthing Cues for Sign Language Translation by Multimodal Contrastive Fusion](https://arxiv.org/abs/2509.10266)
*Wenfang Wu,Tingting Yuan,Yupeng Li,Daling Wang,Xiaoming Fu*

Main category: cs.CV

TL;DR: SignClip是一个手语翻译新框架，通过融合手势和唇部运动特征，并采用分层对比学习来提升翻译准确性。


<details>
  <summary>Details</summary>
Motivation: 现有手语翻译方法主要关注手势信号，忽视了唇部运动等非手动线索，而这些线索对于区分视觉相似的手势至关重要。

Method: 提出SignClip框架，融合空间手势和唇部运动特征，引入分层对比学习框架，实现手语-唇部和视觉-文本模态的多层次语义对齐。

Result: 在PHOENIX14T和How2Sign基准测试中表现优异，在PHOENIX14T无注释设置下，BLEU-4从24.32提升至24.71，ROUGE从46.57提升至48.38。

Conclusion: 融合手动和非手动线索（特别是唇部运动）能显著提升手语翻译性能，分层对比学习确保了跨模态语义一致性。

Abstract: Sign language translation (SLT) aims to translate natural language from sign
language videos, serving as a vital bridge for inclusive communication. While
recent advances leverage powerful visual backbones and large language models,
most approaches mainly focus on manual signals (hand gestures) and tend to
overlook non-manual cues like mouthing. In fact, mouthing conveys essential
linguistic information in sign languages and plays a crucial role in
disambiguating visually similar signs. In this paper, we propose SignClip, a
novel framework to improve the accuracy of sign language translation. It fuses
manual and non-manual cues, specifically spatial gesture and lip movement
features. Besides, SignClip introduces a hierarchical contrastive learning
framework with multi-level alignment objectives, ensuring semantic consistency
across sign-lip and visual-text modalities. Extensive experiments on two
benchmark datasets, PHOENIX14T and How2Sign, demonstrate the superiority of our
approach. For example, on PHOENIX14T, in the Gloss-free setting, SignClip
surpasses the previous state-of-the-art model SpaMo, improving BLEU-4 from
24.32 to 24.71, and ROUGE from 46.57 to 48.38.

</details>


### [123] [Detecting Text Manipulation in Images using Vision Language Models](https://arxiv.org/abs/2509.10278)
*Vidit Vidit,Pavel Korshunov,Amir Mohammadi,Christophe Ecabert,Ketan Kotwal,Sébastien Marcel*

Main category: cs.CV

TL;DR: 大型视觉语言模型在文本编辑检测中的性能分析，开源模型逐渐接近闭源模型但仍有差距，专门模型存在普通化问题


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在图像编辑检测，文本编辑检测颇为缺失，需要补充这一知识空白

Method: 对比分析闭源和开源视觉语言模型在不同文本编辑数据集上的表现，包括野外场景文本和假悬身份证类别

Result: 开源模型性能逐渐接近闭源模型如GPT-4o，但仍有差距；专门的图像编辑检测模型在文本检测中普通化能力不佳

Conclusion: 文本编辑检测是视觉语言模型的重要应用场景，需要进一步研究提升模型的普通化能力和实际应用性

Abstract: Recent works have shown the effectiveness of Large Vision Language Models
(VLMs or LVLMs) in image manipulation detection. However, text manipulation
detection is largely missing in these studies. We bridge this knowledge gap by
analyzing closed- and open-source VLMs on different text manipulation datasets.
Our results suggest that open-source models are getting closer, but still
behind closed-source ones like GPT- 4o. Additionally, we benchmark image
manipulation detection-specific VLMs for text manipulation detection and show
that they suffer from the generalization problem. We benchmark VLMs for
manipulations done on in-the-wild scene texts and on fantasy ID cards, where
the latter mimic a challenging real-world misuse.

</details>


### [124] [MCL-AD: Multimodal Collaboration Learning for Zero-Shot 3D Anomaly Detection](https://arxiv.org/abs/2509.10282)
*Gang Li,Tianjiao Chen,Mingle Zhou,Min Li,Delong Han,Jin Wan*

Main category: cs.CV

TL;DR: MCL-AD是一个新颖的多模态协作学习框架，通过整合点云、RGB图像和文本语义，在无需标注数据的情况下实现卓越的零样本3D异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本3D异常检测方法主要专注于点云数据，忽视了RGB图像和文本先验等互补模态提供的丰富语义线索，限制了检测性能。

Method: 提出多模态提示学习机制(MPLM)增强模态内表示能力和模态间协作学习，包括对象无关的解耦文本提示和多模态对比损失；设计协作调制机制(CMM)联合调制RGB图像引导和点云引导分支，充分利用互补表示。

Result: 大量实验证明MCL-AD框架在零样本3D异常检测中达到了最先进的性能。

Conclusion: 通过多模态协作学习整合点云、图像和文本信息，能够显著提升零样本3D异常检测的效果，为解决数据稀缺场景下的缺陷检测问题提供了有效解决方案。

Abstract: Zero-shot 3D (ZS-3D) anomaly detection aims to identify defects in 3D objects
without relying on labeled training data, making it especially valuable in
scenarios constrained by data scarcity, privacy, or high annotation cost.
However, most existing methods focus exclusively on point clouds, neglecting
the rich semantic cues available from complementary modalities such as RGB
images and texts priors. This paper introduces MCL-AD, a novel framework that
leverages multimodal collaboration learning across point clouds, RGB images,
and texts semantics to achieve superior zero-shot 3D anomaly detection.
Specifically, we propose a Multimodal Prompt Learning Mechanism (MPLM) that
enhances the intra-modal representation capability and inter-modal
collaborative learning by introducing an object-agnostic decoupled text prompt
and a multimodal contrastive loss. In addition, a collaborative modulation
mechanism (CMM) is proposed to fully leverage the complementary representations
of point clouds and RGB images by jointly modulating the RGB image-guided and
point cloud-guided branches. Extensive experiments demonstrate that the
proposed MCL-AD framework achieves state-of-the-art performance in ZS-3D
anomaly detection.

</details>


### [125] [Adversarial robustness through Lipschitz-Guided Stochastic Depth in Neural Networks](https://arxiv.org/abs/2509.10298)
*Laith Nayal,Mahmoud Mousatat,Bader Rasheed*

Main category: cs.CV

TL;DR: 提出基于Lipschitz约束的随机深度方法，通过深度相关的DropPath概率控制网络有效Lipschitz常数，在保持精度的同时提升对抗鲁棒性并降低计算量


<details>
  <summary>Details</summary>
Motivation: 深度神经网络和Vision Transformers在计算机视觉中表现优异但对抗扰动脆弱，现有防御方法计算成本高或缺乏形式化保证

Method: Lipschitz引导的随机深度(DropPath)方法，Drop概率随深度增加以控制网络有效Lipschitz常数，对深层进行正则化

Result: 在CIFAR-10和ViT-Tiny上实验表明，自定义深度相关调度保持接近基线精度，提升FGSM、PGD-20和AutoAttack下的鲁棒性，显著降低FLOPs

Conclusion: 深度相关的DropPath调度能有效平衡模型精度、鲁棒性和计算效率，为对抗防御提供新思路

Abstract: Deep neural networks and Vision Transformers achieve state-of-the-art
performance in computer vision but are highly vulnerable to adversarial
perturbations. Standard defenses often incur high computational cost or lack
formal guarantees. We propose a Lipschitz-guided stochastic depth (DropPath)
method, where drop probabilities increase with depth to control the effective
Lipschitz constant of the network. This approach regularizes deeper layers,
improving robustness while preserving clean accuracy and reducing computation.
Experiments on CIFAR-10 with ViT-Tiny show that our custom depth-dependent
schedule maintains near-baseline clean accuracy, enhances robustness under
FGSM, PGD-20, and AutoAttack, and significantly reduces FLOPs compared to
baseline and linear DropPath schedules.

</details>


### [126] [A Stochastic Birth-and-Death Approach for Street Furniture Geolocation in Urban Environments](https://arxiv.org/abs/2509.10310)
*Evan Murphy,Marco Viola,Vladimir A. Krylov*

Main category: cs.CV

TL;DR: 提出基于能量图的概率框架，用于复杂城市环境中街道家具的精确定位，通过随机生死优化算法整合地理空间信息，提高定位精度


<details>
  <summary>Details</summary>
Motivation: 解决城市环境中街道家具的精确定位问题，这对于公共基础设施的有效监控和维护至关重要

Method: 使用基于能量图的概率框架编码对象位置的空间可能性，引入随机生死优化算法推断最可能的资产配置，整合GIS图层、道路地图等外部地理空间信息

Result: 通过在都柏林市中心街灯基础设施数据集上的真实模拟评估，证明了该方法在可扩展和准确的城市资产映射方面的潜力

Conclusion: 该方法为城市资产管理提供了有效的解决方案，算法实现将在GitHub上开源

Abstract: In this paper we address the problem of precise geolocation of street
furniture in complex urban environments, which is a critical task for effective
monitoring and maintenance of public infrastructure by local authorities and
private stakeholders. To this end, we propose a probabilistic framework based
on energy maps that encode the spatial likelihood of object locations.
Representing the energy in a map-based geopositioned format allows the
optimisation process to seamlessly integrate external geospatial information,
such as GIS layers, road maps, or placement constraints, which improves
contextual awareness and localisation accuracy. A stochastic birth-and-death
optimisation algorithm is introduced to infer the most probable configuration
of assets. We evaluate our approach using a realistic simulation informed by a
geolocated dataset of street lighting infrastructure in Dublin city centre,
demonstrating its potential for scalable and accurate urban asset mapping. The
implementation of the algorithm will be made available in the GitHub repository
https://github.com/EMurphy0108/SBD_Street_Furniture.

</details>


### [127] [Compute Only 16 Tokens in One Timestep: Accelerating Diffusion Transformers with Cluster-Driven Feature Caching](https://arxiv.org/abs/2509.10312)
*Zhixin Zheng,Xinyu Wang,Chang Zou,Shaobo Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: ClusCa通过空间聚类减少扩散变换器中的token数量，实现4.96倍加速且保持图像质量


<details>
  <summary>Details</summary>
Motivation: 扩散变换器计算成本高，现有特征缓存方法只利用时间维度相似性，忽略了空间维度相似性

Method: 对每个时间步的token进行空间聚类，每个聚类只计算一个token并将其信息传播给其他token，减少90%以上token数量

Result: 在DiT、FLUX和HunyuanVideo上验证有效，FLUX实现4.96倍加速，ImageReward达到99.49%（比原模型提升0.51%）

Conclusion: ClusCa是现有特征缓存方法的正交补充，无需训练即可直接应用于任何扩散变换器，显著加速推理过程

Abstract: Diffusion transformers have gained significant attention in recent years for
their ability to generate high-quality images and videos, yet still suffer from
a huge computational cost due to their iterative denoising process. Recently,
feature caching has been introduced to accelerate diffusion transformers by
caching the feature computation in previous timesteps and reusing it in the
following timesteps, which leverage the temporal similarity of diffusion models
while ignoring the similarity in the spatial dimension. In this paper, we
introduce Cluster-Driven Feature Caching (ClusCa) as an orthogonal and
complementary perspective for previous feature caching. Specifically, ClusCa
performs spatial clustering on tokens in each timestep, computes only one token
in each cluster and propagates their information to all the other tokens, which
is able to reduce the number of tokens by over 90%. Extensive experiments on
DiT, FLUX and HunyuanVideo demonstrate its effectiveness in both text-to-image
and text-to-video generation. Besides, it can be directly applied to any
diffusion transformer without requirements for training. For instance, ClusCa
achieves 4.96x acceleration on FLUX with an ImageReward of 99.49%, surpassing
the original model by 0.51%. The code is available at
https://github.com/Shenyi-Z/Cache4Diffusion.

</details>


### [128] [I-Segmenter: Integer-Only Vision Transformer for Efficient Semantic Segmentation](https://arxiv.org/abs/2509.10334)
*Jordan Sassoon,Michal Szczepanski,Martyna Poreba*

Main category: cs.CV

TL;DR: I-Segmenter是首个完全整数化的ViT分割框架，通过系统替换浮点运算为整数运算，在保持合理精度损失的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在语义分割中表现优异，但由于高内存占用和计算成本，在资源受限设备上部署受限。量化是提高效率的有效策略，但ViT分割模型在低精度下表现脆弱。

Method: 基于Segmenter架构，系统替换浮点操作为整数操作；提出λ-ShiftGELU激活函数处理长尾分布；移除L2归一化层；用最近邻上采样替换双线性插值。

Result: 在FP32基线5.1%的精度损失范围内，模型大小减少3.8倍，推理速度提升1.2倍；单次PTQ校准也能获得有竞争力的精度。

Conclusion: I-Segmenter为ViT分割模型在资源受限设备上的实际部署提供了实用解决方案，实现了完全整数化执行。

Abstract: Vision Transformers (ViTs) have recently achieved strong results in semantic
segmentation, yet their deployment on resource-constrained devices remains
limited due to their high memory footprint and computational cost. Quantization
offers an effective strategy to improve efficiency, but ViT-based segmentation
models are notoriously fragile under low precision, as quantization errors
accumulate across deep encoder-decoder pipelines. We introduce I-Segmenter, the
first fully integer-only ViT segmentation framework. Building on the Segmenter
architecture, I-Segmenter systematically replaces floating-point operations
with integer-only counterparts. To further stabilize both training and
inference, we propose $\lambda$-ShiftGELU, a novel activation function that
mitigates the limitations of uniform quantization in handling long-tailed
activation distributions. In addition, we remove the L2 normalization layer and
replace bilinear interpolation in the decoder with nearest neighbor upsampling,
ensuring integer-only execution throughout the computational graph. Extensive
experiments show that I-Segmenter achieves accuracy within a reasonable margin
of its FP32 baseline (5.1 % on average), while reducing model size by up to
3.8x and enabling up to 1.2x faster inference with optimized runtimes. Notably,
even in one-shot PTQ with a single calibration image, I-Segmenter delivers
competitive accuracy, underscoring its practicality for real-world deployment.

</details>


### [129] [GARD: Gamma-based Anatomical Restoration and Denoising for Retinal OCT](https://arxiv.org/abs/2509.10341)
*Botond Fazekas,Thomas Pinetz,Guilherme Aresta,Taha Emre,Hrvoje Bogunovic*

Main category: cs.CV

TL;DR: GARD是一种基于伽马扩散模型的新型OCT图像去噪方法，通过噪声降低保真项和加速推理框架，在保持解剖结构的同时有效去除散斑噪声


<details>
  <summary>Details</summary>
Motivation: OCT图像存在固有散斑噪声，传统方法难以平衡噪声去除与解剖结构保留，需要更准确的噪声统计模型和更好的去噪效果

Method: 采用去噪扩散伽马模型替代传统高斯假设，引入噪声降低保真项指导去噪过程，并适配DDIM框架加速推理

Result: 在配对噪声-低噪声OCT B扫描数据集上，GARD在PSNR、SSIM和MSE指标上显著优于传统方法和先进深度学习模型，定性结果显示边缘更清晰、解剖细节保留更好

Conclusion: GARD通过伽马扩散模型和噪声降低保真项，成功实现了OCT图像的高质量去噪，在定量和定性评估中均表现出色

Abstract: Optical Coherence Tomography (OCT) is a vital imaging modality for diagnosing
and monitoring retinal diseases. However, OCT images are inherently degraded by
speckle noise, which obscures fine details and hinders accurate interpretation.
While numerous denoising methods exist, many struggle to balance noise
reduction with the preservation of crucial anatomical structures. This paper
introduces GARD (Gamma-based Anatomical Restoration and Denoising), a novel
deep learning approach for OCT image despeckling that leverages the strengths
of diffusion probabilistic models. Unlike conventional diffusion models that
assume Gaussian noise, GARD employs a Denoising Diffusion Gamma Model to more
accurately reflect the statistical properties of speckle. Furthermore, we
introduce a Noise-Reduced Fidelity Term that utilizes a pre-processed,
less-noisy image to guide the denoising process. This crucial addition prevents
the reintroduction of high-frequency noise. We accelerate the inference process
by adapting the Denoising Diffusion Implicit Model framework to our Gamma-based
model. Experiments on a dataset with paired noisy and less-noisy OCT B-scans
demonstrate that GARD significantly outperforms traditional denoising methods
and state-of-the-art deep learning models in terms of PSNR, SSIM, and MSE.
Qualitative results confirm that GARD produces sharper edges and better
preserves fine anatomical details.

</details>


### [130] [GLAM: Geometry-Guided Local Alignment for Multi-View VLP in Mammography](https://arxiv.org/abs/2509.10344)
*Yuexi Du,Lihui Chen,Nicha C. Dvornek*

Main category: cs.CV

TL;DR: GLAM模型通过几何引导的多视角对齐方法，在乳腺X线摄影视觉语言模型预训练中实现全局和局部对齐，显著提升多数据集性能


<details>
  <summary>Details</summary>
Motivation: 现有乳腺X线摄影VLM从自然图像适配而来，忽略了多视角关系等医学影像特有特征，无法像放射科医生那样同时分析双侧视图，导致几何上下文丢失和预测效果不佳

Method: 利用乳腺X线摄影多视角成像过程的先验知识，通过联合全局和局部、视觉-视觉、视觉-语言的对比学习，学习局部跨视角对齐和细粒度局部特征

Result: 在最大的公开乳腺X线摄影数据集EMBED上预训练后，该模型在不同设置下的多个数据集中均优于基线方法

Conclusion: GLAM模型通过几何引导的多视角对齐策略有效解决了乳腺X线摄影VLM预训练中的领域特异性问题，为医学影像分析提供了新的解决方案

Abstract: Mammography screening is an essential tool for early detection of breast
cancer. The speed and accuracy of mammography interpretation have the potential
to be improved with deep learning methods. However, the development of a
foundation visual language model (VLM) is hindered by limited data and domain
differences between natural and medical images. Existing mammography VLMs,
adapted from natural images, often ignore domain-specific characteristics, such
as multi-view relationships in mammography. Unlike radiologists who analyze
both views together to process ipsilateral correspondence, current methods
treat them as independent images or do not properly model the multi-view
correspondence learning, losing critical geometric context and resulting in
suboptimal prediction. We propose GLAM: Global and Local Alignment for
Multi-view mammography for VLM pretraining using geometry guidance. By
leveraging the prior knowledge about the multi-view imaging process of
mammograms, our model learns local cross-view alignments and fine-grained local
features through joint global and local, visual-visual, and visual-language
contrastive learning. Pretrained on EMBED [14], one of the largest open
mammography datasets, our model outperforms baselines across multiple datasets
under different settings.

</details>


### [131] [Towards Understanding Visual Grounding in Visual Language Models](https://arxiv.org/abs/2509.10345)
*Georgios Pantazopoulos,Eda B. Özyiğit*

Main category: cs.CV

TL;DR: 这是一份关于视觉基础模型的综述性论文，讨论了视视基准定位的概念、核心组件、应用场景、评估指标以及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 评估现代通用视觉语言模型的视视基准定位能力，并为该领域提供系统性的研究综述和分析。

Method: 通过综述性方法，识别和分析代表性的基准定位相关研究工作，分析现代基准模型的核心组件、应用场景、评估指标等。

Result: 形成了对视视基准定位领域的系统性评估，包括关键技术、应用场景、评测方法以及与多模态链式思绪和推理的关系分析。

Conclusion: 视视基准定位是通用视觉语言模型的核心能力，虽然面临着许多挑战，但具有广阔的应用前景和研究价值，需要进一步深入研究。

Abstract: Visual grounding refers to the ability of a model to identify a region within
some visual input that matches a textual description. Consequently, a model
equipped with visual grounding capabilities can target a wide range of
applications in various domains, including referring expression comprehension,
answering questions pertinent to fine-grained details in images or videos,
caption visual context by explicitly referring to entities, as well as low and
high-level control in simulated and real environments. In this survey paper, we
review representative works across the key areas of research on modern
general-purpose vision language models (VLMs). We first outline the importance
of grounding in VLMs, then delineate the core components of the contemporary
paradigm for developing grounded models, and examine their practical
applications, including benchmarks and evaluation metrics for grounded
multimodal generation. We also discuss the multifaceted interrelations among
visual grounding, multimodal chain-of-thought, and reasoning in VLMs. Finally,
we analyse the challenges inherent to visual grounding and suggest promising
directions for future research.

</details>


### [132] [Immunizing Images from Text to Image Editing via Adversarial Cross-Attention](https://arxiv.org/abs/2509.10359)
*Matteo Trippodo,Federico Becattini,Lorenzo Seidenari*

Main category: cs.CV

TL;DR: 提出Attention Attack攻击方法，通过使用源图像的自动生成描述作为编辑提示的代理，破坏文本提示与图像视觉表示之间的交叉注意力，从而干扰基于文本的图像编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的图像编辑方法容易受到对抗攻击，需要一种能够破坏视觉组件而不需要了解编辑方法或编辑提示的攻击手段。

Method: 使用源图像的自动生成描述作为编辑提示的代理，通过破坏文本提示与图像视觉表示之间的交叉注意力来实现攻击，无需了解具体的编辑方法或编辑提示。

Result: 在TEDBench++基准测试中，该攻击显著降低了编辑性能，同时保持不可察觉性。提出了Caption Similarity和语义IoU两种新的评估策略来量化攻击效果。

Conclusion: Attention Attack是一种有效的对抗攻击方法，能够成功干扰基于文本的图像编辑系统，同时提出了更可靠的评估指标来衡量免疫化成功。

Abstract: Recent advances in text-based image editing have enabled fine-grained
manipulation of visual content guided by natural language. However, such
methods are susceptible to adversarial attacks. In this work, we propose a
novel attack that targets the visual component of editing methods. We introduce
Attention Attack, which disrupts the cross-attention between a textual prompt
and the visual representation of the image by using an automatically generated
caption of the source image as a proxy for the edit prompt. This breaks the
alignment between the contents of the image and their textual description,
without requiring knowledge of the editing method or the editing prompt.
Reflecting on the reliability of existing metrics for immunization success, we
propose two novel evaluation strategies: Caption Similarity, which quantifies
semantic consistency between original and adversarial edits, and semantic
Intersection over Union (IoU), which measures spatial layout disruption via
segmentation masks. Experiments conducted on the TEDBench++ benchmark
demonstrate that our attack significantly degrades editing performance while
remaining imperceptible.

</details>


### [133] [Efficient Learned Image Compression Through Knowledge Distillation](https://arxiv.org/abs/2509.10366)
*Fabien Allemand,Attilio Fiandrotti,Sumanta Chaudhuri,Alaa Eddine Mazouz*

Main category: cs.CV

TL;DR: 该论文提出使用知识蒸馏技术来降低神经网络图像压缩方法的计算资源需求，使小模型能够通过向大模型学习获得更好的压缩性能


<details>
  <summary>Details</summary>
Motivation: 现有的神经网络图像压缩方法虽然性能优于传统编解码器，但计算资源需求过高，无法在资源受限平台上实时使用，限制了其实际部署

Method: 采用知识蒸馏训练范式，让小规模神经网络通过学习大规模复杂模型的输出来提升性能，研究了不同架构大小、不同图像质量/比特率权衡下的效果

Result: 研究表明知识蒸馏能有效应用于图像压缩任务，可以节省处理和能源资源，小模型通过蒸馏训练可以获得比独立训练更好的性能

Conclusion: 知识蒸馏为降低神经网络图像压缩的计算需求提供了有效途径，未来可探索不同教师模型、替代损失函数以及扩展到基于transformer的模型

Abstract: Learned image compression sits at the intersection of machine learning and
image processing. With advances in deep learning, neural network-based
compression methods have emerged. In this process, an encoder maps the image to
a low-dimensional latent space, which is then quantized, entropy-coded into a
binary bitstream, and transmitted to the receiver. At the receiver end, the
bitstream is entropy-decoded, and a decoder reconstructs an approximation of
the original image. Recent research suggests that these models consistently
outperform conventional codecs. However, they require significant processing
power, making them unsuitable for real-time use on resource-constrained
platforms, which hinders their deployment in mainstream applications. This
study aims to reduce the resource requirements of neural networks used for
image compression by leveraging knowledge distillation, a training paradigm
where smaller neural networks, partially trained on the outputs of larger, more
complex models, can achieve better performance than when trained independently.
Our work demonstrates that knowledge distillation can be effectively applied to
image compression tasks: i) across various architecture sizes, ii) to achieve
different image quality/bit rate tradeoffs, and iii) to save processing and
energy resources. This approach introduces new settings and hyperparameters,
and future research could explore the impact of different teacher models, as
well as alternative loss functions. Knowledge distillation could also be
extended to transformer-based models. The code is publicly available at:
https://github.com/FABallemand/PRIM .

</details>


### [134] [Ordinality of Visible-Thermal Image Intensities for Intrinsic Image Decomposition](https://arxiv.org/abs/2509.10388)
*Zeqing Leo Yuan,Mani Ramanagopal,Aswin C. Sankaranarayanan,Srinivasa G. Narasimhan*

Main category: cs.CV

TL;DR: 一种无需训练的新方法，利用可见光和热成像对来实现图像内在光照和反射率分解，通过热量吸收原理获得密集的自监督信息


<details>
  <summary>Details</summary>
Motivation: 图像内在光照和反射率分解长期面临真实场景缺乏地表真实数据的挑战，现有方法依赖合成数据或稀疏标注

Method: 利用可见光和热成像对，通过光线未被反射部分被热成像以热量形式检测的原理，建立可见光和热成像强度与光照反射率之间的顺序关系，作为密集自监督信息优化神经网络

Result: 在自然光和人造光照条件下，对已知反射率和光照进行了定量评估，并在多样化外景场景中进行了定性实验，结果显示性能超过最新的学习基于模型

Conclusion: 该方法为获取真实场景的顺序监督信息提供了一条可扩展的途径，这在之前通过手动标注是不可行的

Abstract: Decomposing an image into its intrinsic photometric factors--shading and
reflectance--is a long-standing challenge due to the lack of extensive
ground-truth data for real-world scenes. Recent methods rely on synthetic data
or sparse annotations for limited indoor and even fewer outdoor scenes. We
introduce a novel training-free approach for intrinsic image decomposition
using only a pair of visible and thermal images. We leverage the principle that
light not reflected from an opaque surface is absorbed and detected as heat by
a thermal camera. This allows us to relate the ordinalities between visible and
thermal image intensities to the ordinalities of shading and reflectance, which
can densely self-supervise an optimizing neural network to recover shading and
reflectance. We perform quantitative evaluations with known reflectance and
shading under natural and artificial lighting, and qualitative experiments
across diverse outdoor scenes. The results demonstrate superior performance
over recent learning-based models and point toward a scalable path to curating
real-world ordinal supervision, previously infeasible via manual labeling.

</details>


### [135] [Compressed Video Quality Enhancement: Classifying and Benchmarking over Standards](https://arxiv.org/abs/2509.10407)
*Xiem HoangVan,Dang BuiDinh,Sang NguyenQuang,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 这篇论文为压缩视频质量增强领域提供了系统的分类和评测框架，解决了现有调查报告在分类系统性、比较分析和基准测试方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的压缩视频质量增强调查报告存在系统分类不足、比较分析不充分和基准测试实践不成熟等问题，需要一个更全面的综述来支持该领域的研究和应用。

Method: 论文提出了三个主要方法：1）新的分类法，按架构范式、编码标准和压缩域特征利用进行分类；2）统一的基准测试框架，集成现代压缩协议和标准测试序列；3）系统分析重建性能与计算复杂性之间的关键拉换关系。

Result: 论文建立了一个全面的压缩视频质量增强分析框架，提供了系统的分类体系、公平的多标准评估方法，以及对现有方法性能复杂度拉换关系的深入分析。

Conclusion: 这份综述为CVQE领域的研究和部署建立了一个坚实的基础，提供了一致的评估标准和信息化的模型选择指南，并指明了未来研究的有前景方向。

Abstract: Compressed video quality enhancement (CVQE) is crucial for improving user
experience with lossy video codecs like H.264/AVC, H.265/HEVC, and H.266/VVC.
While deep learning based CVQE has driven significant progress, existing
surveys still suffer from limitations: lack of systematic classification
linking methods to specific standards and artifacts, insufficient comparative
analysis of architectural paradigms across coding types, and underdeveloped
benchmarking practices. To address these gaps, this paper presents three key
contributions. First, it introduces a novel taxonomy classifying CVQE methods
across architectural paradigms, coding standards, and compressed-domain feature
utilization. Second, it proposes a unified benchmarking framework integrating
modern compression protocols and standard test sequences for fair
multi-criteria evaluation. Third, it provides a systematic analysis of the
critical trade-offs between reconstruction performance and computational
complexity observed in state-of-the-art methods and highlighting promising
directions for future research. This comprehensive review aims to establish a
foundation for consistent assessment and informed model selection in CVQE
research and deployment.

</details>


### [136] [Multimodal SAM-adapter for Semantic Segmentation](https://arxiv.org/abs/2509.10408)
*Iacopo Curti,Pierluigi Zama Ramirez,Alioscia Petrelli,Luigi Di Stefano*

Main category: cs.CV

TL;DR: 通过插入融合多模态特征的适配器网络，扩展SAM模型的多模态语义分割能力，在各种挑战性场景下实现了独刻性能能。


<details>
  <summary>Details</summary>
Motivation: 当前语义分割方法在光照不良、遮挡和恼劣天气等挑战性条件下容易失效，需要多模态数据提供补充信息来提升稳健性。

Method: 设计了一种适配器网络，将融合后的多模态特征注入SAM的RGB特征中，保持RGB特征的强大沿用性同时选择性结合辅助模态。

Result: 在DeLiVER、FMB和MUSES三个挑战性测试集上达到了独刻性能能，在RGB-easy和RGB-hard子集上都显示出优势。

Conclusion: MM SAM-adapter框架通过平衡有效地利用多模态信息，显著提升了模型在各种条件下的稳健性和性能，证明了多模态适配在强化场景理解中的有效性。

Abstract: Semantic segmentation, a key task in computer vision with broad applications
in autonomous driving, medical imaging, and robotics, has advanced
substantially with deep learning. Nevertheless, current approaches remain
vulnerable to challenging conditions such as poor lighting, occlusions, and
adverse weather. To address these limitations, multimodal methods that
integrate auxiliary sensor data (e.g., LiDAR, infrared) have recently emerged,
providing complementary information that enhances robustness. In this work, we
present MM SAM-adapter, a novel framework that extends the capabilities of the
Segment Anything Model (SAM) for multimodal semantic segmentation. The proposed
method employs an adapter network that injects fused multimodal features into
SAM's rich RGB features. This design enables the model to retain the strong
generalization ability of RGB features while selectively incorporating
auxiliary modalities only when they contribute additional cues. As a result, MM
SAM-adapter achieves a balanced and efficient use of multimodal information. We
evaluate our approach on three challenging benchmarks, DeLiVER, FMB, and MUSES,
where MM SAM-adapter delivers state-of-the-art performance. To further analyze
modality contributions, we partition DeLiVER and FMB into RGB-easy and RGB-hard
subsets. Results consistently demonstrate that our framework outperforms
competing methods in both favorable and adverse conditions, highlighting the
effectiveness of multimodal adaptation for robust scene understanding. The code
is available at the following link:
https://github.com/iacopo97/Multimodal-SAM-Adapter.

</details>


### [137] [InfGen: A Resolution-Agnostic Paradigm for Scalable Image Synthesis](https://arxiv.org/abs/2509.10441)
*Tao Han,Wanghan Xu,Junchao Gong,Xiaoyu Yue,Song Guo,Luping Zhou,Lei Bai*

Main category: cs.CV

TL;DR: InfGen是一种基于潜在扩散模型的第二代图像生成方法，用一步生成器替代VAE解码器，实现从固定大小潜在表示生成任意分辨率图像，显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散模型在生成高分辨率图像时计算需求呈二次增长的问题，4K图像生成延迟超过100秒，需要更高效的任意分辨率图像生成方案。

Method: 将扩散模型生成的固定潜在表示作为内容表示，提出使用一步生成器解码任意分辨率图像，用新生成器替代VAE解码器，无需重新训练扩散模型。

Result: InfGen能够将4K图像生成时间缩短至10秒以下，同时支持任意高分辨率图像生成，可应用于使用相同潜在空间的任何模型。

Conclusion: InfGen成功将多种模型带入任意高分辨率时代，显著简化了生成过程并降低了计算复杂度，为跨设备一致视觉体验提供了高效解决方案。

Abstract: Arbitrary resolution image generation provides a consistent visual experience
across devices, having extensive applications for producers and consumers.
Current diffusion models increase computational demand quadratically with
resolution, causing 4K image generation delays over 100 seconds. To solve this,
we explore the second generation upon the latent diffusion models, where the
fixed latent generated by diffusion models is regarded as the content
representation and we propose to decode arbitrary resolution images with a
compact generated latent using a one-step generator. Thus, we present the
\textbf{InfGen}, replacing the VAE decoder with the new generator, for
generating images at any resolution from a fixed-size latent without retraining
the diffusion models, which simplifies the process, reducing computational
complexity and can be applied to any model using the same latent space.
Experiments show InfGen is capable of improving many models into the arbitrary
high-resolution era while cutting 4K image generation time to under 10 seconds.

</details>


### [138] [SSL-AD: Spatiotemporal Self-Supervised Learning for Generalizability and Adaptability Across Alzheimer's Prediction Tasks and Datasets](https://arxiv.org/abs/2509.10453)
*Emily Kaczmarek,Justin Szeto,Brennan Nichyporuk,Tal Arbel*

Main category: cs.CV

TL;DR: 本研究将三种先进的时序自监督学习方法应用于3D脑部MRI分析，通过处理可变长度输入和学习鲁棒空间特征，在阿尔茨海默病预测任务中超越了监督学习方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病预测的深度学习模型面临标注数据缺乏、跨数据集泛化能力差以及对不同扫描次数和时间间隔的输入不灵活等限制。

Method: 采用时序自监督学习（SSL）方法，包括时序顺序预测和对比学习，处理可变长度输入并学习鲁棒空间特征，在四个公开数据集（3,161名患者）上进行预训练。

Result: SSL模型在七个下游任务中的六个任务上表现优于监督学习，展示了跨任务和不同输入图像数量及时间间隔的适应性和泛化能力。

Conclusion: 时序自监督学习方法在阿尔茨海默病预测中表现出色，具有强大的临床应用潜力，代码和模型已公开。

Abstract: Alzheimer's disease is a progressive, neurodegenerative disorder that causes
memory loss and cognitive decline. While there has been extensive research in
applying deep learning models to Alzheimer's prediction tasks, these models
remain limited by lack of available labeled data, poor generalization across
datasets, and inflexibility to varying numbers of input scans and time
intervals between scans. In this study, we adapt three state-of-the-art
temporal self-supervised learning (SSL) approaches for 3D brain MRI analysis,
and add novel extensions designed to handle variable-length inputs and learn
robust spatial features. We aggregate four publicly available datasets
comprising 3,161 patients for pre-training, and show the performance of our
model across multiple Alzheimer's prediction tasks including diagnosis
classification, conversion detection, and future conversion prediction.
Importantly, our SSL model implemented with temporal order prediction and
contrastive learning outperforms supervised learning on six out of seven
downstream tasks. It demonstrates adaptability and generalizability across
tasks and number of input images with varying time intervals, highlighting its
capacity for robust performance across clinical applications. We release our
code and model publicly at https://github.com/emilykaczmarek/SSL-AD.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [139] [Space-Time Tradeoffs for Spatial Conjunctive Queries](https://arxiv.org/abs/2509.10050)
*Aryan Esmailpour,Xiao Hu,Stavros Sintos*

Main category: cs.DB

TL;DR: 这篇论文研究如何为联结查询结果构建高效空间索引，以支持空间查询如范围空查、范围计数和最近邻居查询，并在时间和空间效率方面达到最优平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么查询时间过长，要么空间占用过大，无法在实践中高效应用。需要一种时间和空间都高效的索引结构来支持空间联结查询。

Method: 首先设立了时间-空间交换的下界理论，然后构建了最优的索引结构来处理k-星查询和k-路径查询的范围空查和范围计数问题，并扩展到层次查询和通过超树分解处理任意联结查询。

Result: 设计出了时间和空间效率都最优的索引结构，能够高效处理空间联结查询，并且可以提升现有关系算法的运行效率。

Conclusion: 该研究为空间联结查询提供了理论基础和实用索引方案，在保持高效查询性能的同时减少空间占用，对于数据分析和关系算法的优化具有重要意义。

Abstract: Given a conjunctive query and a database instance, we aim to develop an index
that can efficiently answer spatial queries on the results of a conjunctive
query. We are interested in some commonly used spatial queries, such as range
emptiness, range count, and nearest neighbor queries. These queries have
essential applications in data analytics, such as filtering relational data
based on attribute ranges and temporal graph analysis for counting graph
structures like stars, paths, and cliques. Furthermore, this line of research
can accelerate relational algorithms that incorporate spatial queries in their
workflow, such as relational clustering. Known approaches either have to spend
$\tilde{O}(N)$ query time or use space as large as the number of query results,
which are inefficient or unrealistic to employ in practice. Hence, we aim to
construct an index that answers spatial conjunctive queries in both time- and
space-efficient ways.
  In this paper, we establish lower bounds on the tradeoff between answering
time and space usage. For $k$-star (resp. $k$-path) queries, we show that any
index for range emptiness, range counting or nearest neighbor queries with $T$
answering time requires $\Omega\left(N+\frac{N^k}{T^k}\right)$ (resp.
$\Omega\left(N+\frac{N^2}{T^{2/(k-1)}}\right)$) space. Then, we construct
optimal indexes for answering range emptiness and range counting problems over
$k$-star and $k$-path queries. Extending this result, we build an index for
hierarchical queries. By resorting to the generalized hypertree decomposition,
we can extend our index to arbitrary conjunctive queries for supporting spatial
conjunctive queries. Finally, we show how our new indexes can be used to
improve the running time of known algorithms in the relational setting.

</details>


### [140] [Semi-interval Comparison Constraints in Query Containment and Their Impact on Certain Answer Computation](https://arxiv.org/abs/2509.10138)
*Foto N. Afrati,Matthew Damigos*

Main category: cs.DB

TL;DR: 本文研究了包含算术比较的合取查询（CQAC）的包含性测试问题，发现对于某些半区间算术比较的查询类，该问题可在NP内解决，但某些简单情况下仍保持Π₂^p完全性。同时证明了在CQAC视图下，最大包含重写能精确计算所有确定答案，并在某些情况下可在多项式时间内完成。


<details>
  <summary>Details</summary>
Motivation: 研究CQAC查询的包含性测试问题的计算复杂性，探索在特定类型的算术比较条件下能否降低问题的计算复杂度，并为查询重写和确定答案计算提供理论支持。

Method: 通过理论分析和复杂性证明，考察不同类别的CQAC查询（特别是包含半区间算术比较的查询）的包含性测试问题，分析其计算复杂性类别。

Result: 发现对于包含半区间算术比较的CQAC查询，包含性测试问题可在NP内解决；但在某些简单情况下问题仍保持Π₂^p完全性。同时证明了最大包含重写能精确计算所有确定答案，且在某些情况下可在多项式时间内完成。

Conclusion: CQAC查询的包含性测试问题具有复杂的计算特性，但在特定约束条件下可达到更低的计算复杂度，这为高效查询处理和重写提供了理论依据。

Abstract: We consider conjunctive queries with arithmetic comparisons (CQAC) and
investigate the computational complexity of the problem: Given two CQAC
queries, $Q$ and $Q'$, is $Q'$ contained in $Q$? We know that, for CQAC
queries, the problem of testing containment is $\Pi_2 ^p$ -complete. However,
there are broad classes of queries with semi-interval arithmetic comparisons in
the containing query that render the problem solvable in NP. In all cases
examined the contained query is allowed to be any CQAC. Interestingly, we also
prove that there are simple cases where the problem remains $\Pi_2 ^p$
-complete.
  We also investigate the complexity of computing certain answers in the
framework of answering CQAC queries with semi-interval comparisons using any
CQAC views. We prove that maximally contained rewritings in the language of
union of CQACs always compute exactly all certain answers. We find cases where
we can compute certain answers in polynomial time using maximally contained
rewritings.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [141] [Setchain Algorithms for Blockchain Scalability](https://arxiv.org/abs/2509.09795)
*Arivarasan Karmegam,Gabina Luz Bianchi,Margarita Capretto,Martín Ceresa,Antonio Fernández Anta,César Sánchez*

Main category: cs.DC

TL;DR: Setchain通过放宽交易严格全序要求提升区块链可扩展性，提出三种基于底层区块链的算法，实现比底层区块链高数量级的吞吐量和低于4秒的最终性延迟


<details>
  <summary>Details</summary>
Motivation: 解决区块链可扩展性问题，通过放松交易严格全序要求来提高吞吐量

Method: 提出三种Setchain算法：Vanilla（基础实现）、Compresschain（批量压缩）、Hashchain（哈希批量），在CometBFT平台上实现，使用epoch-proof机制确保安全性

Result: 在4、7、10个服务器的集群测试中，Setchain算法达到比底层区块链高数量级的吞吐量，最终性延迟低于4秒

Conclusion: Setchain算法有效提升了区块链的可扩展性，通过放松排序要求实现了高性能，同时保持安全性

Abstract: Setchain has been proposed to increase blockchain scalability by relaxing the
strict total order requirement among transactions. Setchain organizes elements
into a sequence of sets, referred to as epochs, so that elements within each
epoch are unordered. In this paper, we propose and evaluate three distinct
Setchain algorithms, that leverage an underlying block-based ledger. Vanilla is
a basic implementation that serves as a reference point. Compresschain
aggregates elements into batches, and compresses these batches before appending
them as epochs in the ledger. Hashchain converts batches into fixed-length
hashes which are appended as epochs in the ledger. This requires Hashchain to
use a distributed service to obtain the batch contents from its hash. To allow
light clients to safely interact with only one server, the proposed algorithms
maintain, as part of the Setchain, proofs for the epochs. An epoch-proof is the
hash of the epoch, cryptographically signed by a server. A client can verify
the correctness of an epoch with $f+1$ epoch-proofs (where $f$ is the maximum
number of Byzantine servers assumed). All three Setchain algorithms are
implemented on top of the CometBFT blockchain application platform. We
conducted performance evaluations across various configurations, using clusters
of four, seven, and ten servers. Our results show that the Setchain algorithms
reach orders of magnitude higher throughput than the underlying blockchain, and
achieve finality with latency below 4 seconds.

</details>


### [142] [Ordered Consensus with Equal Opportunity](https://arxiv.org/abs/2509.09868)
*Yunhao Zhang,Haobin Ni,Soumya Basu,Shir Cohen,Maofan Yin,Lorenzo Alvisi,Robbert van Renesse,Qi Chen,Lidong Zhou*

Main category: cs.DC

TL;DR: 这篇论文提出了Bercow协议，通过秘密随机神谕和平等机会概念来减少SMR基础区块链中的排序操纵攻击。


<details>
  <summary>Details</summary>
Motivation: 解决状态机复制(SMR)基础区块链中的排序不公平问题，这些问题即使没有宝典节点也会发生，比如网络速度或距离基础设施近的客户获得不公幹优势。

Method: 扩展排序共识以包含平等机会要求，利用随机性控制偏见，并提出秘密随机神谕(SRO)系统组件来容错地生成随机数。提出了基于信任硬件和阈值可验证随机函数的两种SRO设计，并在Bercow协议中实现。

Result: 开发了Bercow协议，能够在可配置的因子范围内近似实现平等机会，有效减缓SMR基础区块链中的知名排序攻击。

Conclusion: 通过引入平等机会概念和随机性机制，这项研究为SMR基础区块链提供了更公平的排序解决方案，能够应对实际中的排序操纵问题。

Abstract: The specification of state machine replication (SMR) has no requirement on
the final total order of commands. In blockchains based on SMR, however, order
matters, since different orders could provide their clients with different
financial rewards. Ordered consensus augments the specification of SMR to
include specific guarantees on such order, with a focus on limiting the
influence of Byzantine nodes. Real-world ordering manipulations, however, can
and do happen even without Byzantine replicas, typically because of factors,
such as faster networks or closer proximity to the blockchain infrastructure,
that give some clients an unfair advantage. To address this challenge, this
paper proceeds to extend ordered consensus by requiring it to also support
equal opportunity, a concrete notion of fairness, widely adopted in social
sciences. Informally, equal opportunity requires that two candidates who,
according to a set of criteria deemed to be relevant, are equally qualified for
a position (in our case, a specific slot in the SMR total order), should have
an equal chance of landing it. We show how randomness can be leveraged to keep
bias in check, and, to this end, introduce the secret random oracle (SRO), a
system component that generates randomness in a fault-tolerant manner. We
describe two SRO designs based, respectively, on trusted hardware and threshold
verifiable random functions, and instantiate them in Bercow, a new ordered
consensus protocol that, by approximating equal opportunity up to within a
configurable factor, can effectively mitigate well-known ordering attacks in
SMR-based blockchains.

</details>


### [143] [Characterizing the Efficiency of Distributed Training: A Power, Performance, and Thermal Perspective](https://arxiv.org/abs/2509.10371)
*Seokjin Go,Joongun Park,Spandan More,Hanjiang Wu,Irene Wang,Aaron Jezghani,Tushar Krishna,Divya Mahajan*

Main category: cs.DC

TL;DR: 大语言模型训练在多GPU系统中的性能形成由硬件、系统拓扑和模型执行的复杂交互作用决定，精心调优的缩放系统在通信绑定情况下可能更优。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的快速扩展，训练负载超过了单节点能力范围，需要深入理解这些模型在大规模多GPU系统中的行为特性。

Method: 通过在NVIDIA H100/H200和AMD MI250 GPU平台上对多种实际工作负载进行综合性能分析，研究了密集和稀疏模型在各种并行策略（张量、水线、数据、专家）下的表现，评估激活重计算和计算-通信重叠等优化技术的效果。

Result: 研究发现性能并不仅仅受硬件规模影响，精心调优的缩放系统在通信绑定情况下可能更优，而某些并行组合会导致带宽利用率不足，过大的微批量会导致峰值功耗和熱阆刻问题。

Conclusion: 训练性能由硬件、系统拓扑和模型执行之间的复杂交互作用决定，为提高未来LLM系统的可扩展性和可靠性提供了设计建议。

Abstract: The rapid scaling of Large Language Models (LLMs) has pushed training
workloads far beyond the limits of single-node analysis, demanding a deeper
understanding of how these models behave across large-scale, multi-GPU systems.
In this paper, we present a comprehensive characterization of LLM training
across diverse real-world workloads and hardware platforms, including NVIDIA
H100/H200 and AMD MI250 GPUs. We analyze dense and sparse models under various
parallelism strategies -- tensor, pipeline, data, and expert -- and evaluate
their effects on hardware utilization, power consumption, and thermal behavior.
We further evaluate the effectiveness of optimizations such as activation
recomputation and compute-communication overlap. Our findings show that
performance is not determined solely by scaling hardware capacity. Scale-up
systems with fewer, higher-memory GPUs can outperform scale-out systems in
communication-bound regimes, but only under carefully tuned configurations; in
other cases, scale-out deployments achieve superior throughput. We also show
that certain parallelism combinations, such as tensor with pipeline, lead to
bandwidth underutilization due to inefficient data chunking, while increasing
microbatch sizes beyond a certain point induces bursty execution and peak power
excursions that worsen thermal throttling. These insights reveal how training
performance is shaped by complex interactions between hardware, system
topology, and model execution. We conclude by offering recommendations for
system and hardware design to improve the scalability and reliability of future
LLM systems and workloads. The source code of this project is available at
https://github.com/sitar-lab/CharLLM-PPT.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [144] [DBOS Network Sensing: A Web Services Approach to Collaborative Awareness](https://arxiv.org/abs/2509.09898)
*Sophia Lockton,Jeremy Kepner,Michael Stonebraker,Hayden Jananthan,LaToya Anderson,William Arcand,David Bestor,William Bergeron,Alex Bonn,Daniel Burrill,Chansup Byun,Timothy Davis,Vijay Gadepally,Michael Houle,Matthew Hubbell,Michael Jones,Piotr Luszczek,Peter Michaleas,Lauren Milechin,Chasen Milner,Guillermo Morales,Julie Mullen,Michel Pelletier,Alex Poliakov,Andrew Prout,Albert Reuther,Antonio Rosa,Charles Yee,Alex Pentland*

Main category: cs.NI

TL;DR: DBOS是一个将网络服务、操作系统功能和数据库特性集成的新型能力系统，通过GraphBLAS超稀疏流量矩阵实现网络感知，显著降低Web部署工作量并提高弹性。


<details>
  <summary>Details</summary>
Motivation: 传统Web部署工作量大且弹性不足，需要一种集成方案来减少部署复杂度，同时通过协作网络感知增强系统整体的弹性和安全性。

Method: 采用两种方法实现网络感知：(1) Python-GraphBLAS方法 (2) OneSparse PostgreSQL方法。系统使用pPython并行化，在MIT SuperCloud的64个计算节点上进行基准测试。

Result: 单个DBOS实例可维持>10^5的Web请求率，远超需求最大值。Python-GraphBLAS和OneSparse PostgreSQL分别在线性扩展到64和32个节点，网络感知功能仅带来可忽略的计算资源增加。

Conclusion: DBOS成功实现了协作网络感知能力，证明可以在不显著增加计算资源开销的情况下，为Web服务提供增强的弹性和安全性。

Abstract: DBOS (DataBase Operating System) is a novel capability that integrates web
services, operating system functions, and database features to significantly
reduce web-deployment effort while increasing resilience. Integration of high
performance network sensing enables DBOS web services to collaboratively create
a shared awareness of their network environments to enhance their collective
resilience and security. Network sensing is added to DBOS using GraphBLAS
hypersparse traffic matrices via two approaches: (1) Python-GraphBLAS and (2)
OneSparse PostgreSQL. These capabilities are demonstrated using the workflow
and analytics from the IEEE/MIT/Amazon Anonymized Network Sensing Graph
Challenge. The system was parallelized using pPython and benchmarked using 64
compute nodes on the MIT SuperCloud. The web request rate sustained by a single
DBOS instance was ${>}10^5$, well above the required maximum, indicating that
network sensing can be added to DBOS with negligible overhead. For
collaborative awareness, many DBOS instances were connected to a single DBOS
aggregator. The Python-GraphBLAS and OneSparse PostgreSQL implementations
scaled linearly up to 64 and 32 nodes respectively. These results suggest that
DBOS collaborative network awareness can be achieved with a negligible increase
in computing resources.

</details>


### [145] [Taming Volatility: Stable and Private QUIC Classification with Federated Learning](https://arxiv.org/abs/2509.09997)
*Richard Jozsa,Karel Hynek,Adrian Pekar*

Main category: cs.NI

TL;DR: 本文提出客户端数据缓冲机制来解决联邦学习中网络流量时间波动性问题，在QUIC分类任务中实现了95.2%的F1分数，仅比非私有集中式模型低2.3个百分点。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在隐私保护的网络流量分析中很有前景，但实际部署受到非IID数据的挑战。现有工作主要关注统计异质性，而时间流量波动性对模型稳定性的影响尚未充分研究。这种波动会导致客户端数据可用性不一致，破坏整个训练过程的稳定性。

Method: 提出并评估客户端数据缓冲机制作为实用解决方案，将本地训练与实时流量波动解耦，确保稳定一致的本地训练。使用真实世界的CESNET-QUIC22数据集，划分为14个自治客户端进行验证。

Result: 该方法实现了稳健收敛，稳定联邦系统达到95.2%的F1分数，仅比非私有集中式模型低2.3个百分点。

Conclusion: 这项工作为构建操作稳定的网络管理联邦学习系统提供了蓝图，证明通过有针对性的架构选择可以克服动态网络环境的挑战。

Abstract: Federated Learning (FL) is a promising approach for privacy-preserving
network traffic analysis, but its practical deployment is challenged by the
non-IID nature of real-world data. While prior work has addressed statistical
heterogeneity, the impact of temporal traffic volatility-the natural daily ebb
and flow of network activity-on model stability remains largely unexplored.
This volatility can lead to inconsistent data availability at clients,
destabilizing the entire training process. In this paper, we systematically
address the problem of temporal volatility in federated QUIC classification. We
first demonstrate the instability of standard FL in this dynamic setting. We
then propose and evaluate a client-side data buffer as a practical mechanism to
ensure stable and consistent local training, decoupling it from real-time
traffic fluctuations. Using the real-world CESNET-QUIC22 dataset partitioned
into 14 autonomous clients, we then demonstrate that this approach enables
robust convergence. Our results show that a stable federated system achieves a
95.2% F1 score, a mere 2.3 percentage points below a non-private centralized
model. This work establishes a blueprint for building operationally stable FL
systems for network management, proving that the challenges of dynamic network
environments can be overcome with targeted architectural choices.

</details>


### [146] [Service Function Chaining Architecture for Multi-hop Split Inference and Learning](https://arxiv.org/abs/2509.10001)
*Takanori Hara,Masahiro Sasabe*

Main category: cs.NI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Service Function Chaining (SFC) is a networking technique that ensures
traffic traverses a predefined sequence of service functions, realizing
arbitrary network services through dynamic and efficient communication paths.
Inspired by this concept, we propose an SFC-based architecture for Multi-hop
Split Inference (MSI), where split sub-models are interpreted as service
functions and their composition forms a service chain representing the global
model. By leveraging SFC, the proposed architecture dynamically establishes
communication paths for split sub-models, ensuring efficient and adaptive
execution. Furthermore, we extend this architecture to Multi-hop Split Learning
(MSL) by applying SFC to the bidirectional communication required for training
tasks. To realize the proposed architecture, we design Neural Service Functions
(NSFs) to execute split sub-models as transparent TCP proxies and integrate
them with Segment Routing over IPv6 (SRv6) and the extended Berkeley Packet
Filter (eBPF)-based SFC proxy. This integration ensures efficient ML processing
over dynamic routing while maintaining compatibility with existing
applications. Evaluation results demonstrate that (1) the proposed architecture
is feasible for both MSI and MSL; (2) it is particularly suitable for real-time
inference in MSI scenarios with small mini-batch sizes; (3) it supports dynamic
path reconfiguration, enabling adaptive responses to changing network
conditions while minimizing the impact of control mechanisms on inference and
learning processes.

</details>


### [147] [Maximising Energy Efficiency in Large-Scale Open RAN: Hybrid xApps and Digital Twin Integration](https://arxiv.org/abs/2509.10097)
*Ahmed Al-Tahmeesschi,Yi Chu,Gurdeep Singh,Charles Turyagyenda,Dritan Kaleshi,David Grace,Hamed Ahmadi*

Main category: cs.NI

TL;DR: 提出了一种基于启发式方法和无监督机器学习的混合xApp，结合数字孪生技术动态管理RU睡眠模式，在Open RAN场景中实现约13%的节能效果且不影响服务质量


<details>
  <summary>Details</summary>
Motivation: 5G及后续网络对高速、超可靠、低延迟通信的需求导致RAN功耗显著增加，带来运营和可持续性挑战，需要在不影响QoS的前提下提高能效

Method: 采用启发式方法和无监督机器学习的混合xApp，通过TeraVM AI RAN场景生成器集成数字孪生技术，动态管理开放无线电单元(RU)的睡眠模式

Result: 在真实大规模仿真Open RAN场景中，混合xApp实现了约13%的节能效果，证明了其在实际部署中的实用性和潜力

Conclusion: 该方法有效解决了O-RAN架构中功耗管理的复杂性，在保持用户服务质量的同时显著降低了能耗，具有重要的实际应用价值

Abstract: The growing demand for high-speed, ultra-reliable, and low-latency
communications in 5G and beyond networks has significantly driven up power
consumption, particularly within the Radio Access Network (RAN). This surge in
energy demand poses critical operational and sustainability challenges for
mobile network operators, necessitating innovative solutions that enhance
energy efficiency without compromising Quality of Service (QoS). Open Radio
Access Network (O-RAN), spearheaded by the O-RAN Alliance, offers
disaggregated, programmable, and intelligent architectures, promoting
flexibility, interoperability, and cost-effectiveness. However, this
disaggregated approach adds complexity, particularly in managing power
consumption across diverse network components such as Open Radio Units (RUs).
In this paper, we propose a hybrid xApp leveraging heuristic methods and
unsupervised machine learning, integrated with digital twin technology through
the TeraVM AI RAN Scenario Generator (AI-RSG). This approach dynamically
manages RU sleep modes to effectively reduce energy consumption. Our
experimental evaluation in a realistic, large-scale emulated Open RAN scenario
demonstrates that the hybrid xApp achieves approximately 13% energy savings,
highlighting its practicality and significant potential for real-world
deployments without compromising user QoS.

</details>


### [148] [Secure and Scalable Rerouting in LEO Satellite Networks](https://arxiv.org/abs/2509.10173)
*Lyubomir Yanev,Pietro Ronchetti,Joshua Smailes,Martin Strohmeier*

Main category: cs.NI

TL;DR: 这篇论文通过扩展DSNS模拟器，系统比较了低轨道卫星网络中三种不同故障知识范围的重路由策略，发现基于网段的重路由方案能在局部响应性和全局协调之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 低轨道卫星网络中频繁且不可预测的链路和节点故障（包括网络安全攻击）使弹性路由成为关键挑战，而现有重路由策略在动态故障条件下的相对交易巡貌未得到充分探索。

Method: 扩展Deep Space Network Simulator (DSNS)，系统比较三种重路由范式：局部邻居基础、网段基础和全局知识基础的重路由，以及一种不知道故障的源路由方案。测量了传输比率、延迟、重路由开销和循环发生率。

Result: 研究结果显示，基于网段的重路由方案能够在局部响应性和全局协调之间实现有利的平衡，在提供弹性优势的同时将开销保持在最低水平。

Conclusion: 基于网段的重路由策略为未来故障容锐性卫星网络设计提供了有价值的见解，它能够在最小化开销的前提下实现良好的弹性性能。

Abstract: Resilient routing in large-scale Low Earth Orbit (LEO) satellite networks
remains a key challenge due to frequent and unpredictable link and node
failures, potentially in response to cybersecurity breaches. While prior work
has explored rerouting strategies with various levels of network awareness,
their relative tradeoffs under dynamic failure conditions remain underexplored.
In this work, we extend the Deep Space Network Simulator (DSNS) to
systematically compare three rerouting paradigms, each differing in the scope
of failure knowledge available to each node. We compare local neighbor-based,
segment-based and global-knowledge-based rerouting as well as a naive source
routing solution that is unaware of failures. Our main goal is to evaluate how
the breadth of failure awareness impacts routing performance and resilience
under failures, both random and targeted. We measure delivery ratio, latency,
rerouting overhead, and loop occurrence. Our findings show the potential of
segment-based rerouting to achieve a favorable tradeoff between local
responsiveness and global coordination, offering resilience benefits with
minimal overhead--insights that can inform future fault-tolerant satellite
network design.

</details>


### [149] [Friend or Foe? Identifying Anomalous Peers in Moneros P2P Network](https://arxiv.org/abs/2509.10214)
*Yannik Kopyciok,Stefan Schmid,Friedhelm Victor*

Main category: cs.NI

TL;DR: 首次系统性研究Monero P2P网络中的异常节点行为，发现约14.74%节点存在非标准行为，揭示了Monero隐私保证和网络去中心化的重大缺陷


<details>
  <summary>Details</summary>
Motivation: Monero作为领先的隐私加密货币，其P2P网络中存在假执诚实节点的非标准节点，可能用于监控网络和闯视其他节点，但对异常节点行为的检测与分析理解有限

Method: 从全球5个不同观测点收集超过240小时的网络流量数据，建立了一个形式框架来分析定义和分类P2P加密货币网络中的异常模式，并实现了离线分析检测方法

Result: 发现约14.74%（13.19%）的可达节点呈现出非标准行为，这些节点显示出特定的行为模式，可能指向多重并发攻击，揭示了Monero隐私保证和网络去中心化的重大缺陷

Conclusion: 研究为实时监控系统奠定了基础，并释放了检测管道以支持可复现性和帮助网络运营商基于新收集的网络流量识别和阻塞可疑节点

Abstract: Monero, the leading privacy-focused cryptocurrency, relies on a peer-to-peer
(P2P) network to propagate transactions and blocks. Growing evidence suggests
that non-standard nodes exist in the network, posing as honest nodes but are
perhaps intended for monitoring the network and spying on other nodes. However,
our understanding of the detection and analysis of anomalous peer behavior
remains limited. This paper presents a first comprehensive study of anomalous
behavior in Monero's P2P network. To this end, we collected and analyzed over
240 hours of network traffic captured from five distinct vantage points
worldwide. We further present a formal framework which allows us to
analytically define and classify anomalous patterns in P2P cryptocurrency
networks. Our detection methodology, implemented as an offline analysis,
provides a foundation for real-time monitoring systems. Our analysis reveals
the presence of non-standard peers in the network where approximately 14.74%
(13.19%) of (reachable) peers in the network exhibit non-standard behavior.
These peers exhibit distinct behavioral patterns that might suggest multiple
concurrent attacks, pointing to substantial shortcomings in Monero's privacy
guarantees and network decentralization. To support reproducibility and enable
network operators to protect themselves, we release our examination pipeline to
identify and block suspicious peers based on newly captured network traffic.

</details>


### [150] [RFSeek and Ye Shall Find](https://arxiv.org/abs/2509.10216)
*Noga H. Rotman,Tiago Ferreira,Hila Peleg,Mark Silberstein,Alexandra Silva*

Main category: cs.NI

TL;DR: RFSeek是一个基于LLM的交互工具，能够从RFC文档中自动提取协议逻辑的可视化摘要，生成可追溯来源的交互式图表，帮助更好地理解网络协议规范。


<details>
  <summary>Details</summary>
Motivation: RFC文档冗长且基于文本的格式阻碍了对协议操作的精确理解，需要更直观的可视化工具来提升协议理解效率。

Method: 利用大型语言模型(LLMs)自动生成可追溯来源的可探索图表，提取RFC文本中的状态机和逻辑关系，支持用户定制化可视化。

Result: RFSeek不仅能够重建RFC中的现有图表，还能发现文本中描述但图表中缺失的重要逻辑节点和边，为复杂协议(如QUIC)生成新的可视化图表。

Conclusion: 结合LLM与形式化、用户定制化可视化的摘要可视化方法，为增强协议理解和支持稳健实现提供了有前景的方向。

Abstract: Requests for Comments (RFCs) are extensive specification documents for
network protocols, but their prose-based format and their considerable length
often impede precise operational understanding. We present RFSeek, an
interactive tool that automatically extracts visual summaries of protocol logic
from RFCs. RFSeek leverages large language models (LLMs) to generate
provenance-linked, explorable diagrams, surfacing both official state machines
and additional logic found only in the RFC text. Compared to existing RFC
visualizations, RFSeek's visual summaries are more transparent and easier to
audit against their textual source. We showcase the tool's potential through a
series of use cases, including guided knowledge extraction and semantic
diffing, applied to protocols such as TCP, QUIC, PPTP, and DCCP.
  In practice, RFSeek not only reconstructs the RFC diagrams included in some
specifications, but, more interestingly, also uncovers important logic such as
nodes or edges described in the text but missing from those diagrams. RFSeek
further derives new visualization diagrams for complex RFCs, with QUIC as a
representative case. Our approach, which we term \emph{Summary Visualization},
highlights a promising direction: combining LLMs with formal, user-customized
visualizations to enhance protocol comprehension and support robust
implementations.

</details>


### [151] [Trusted Repeater Placement in QKD-enabled Optical Networks](https://arxiv.org/abs/2509.10338)
*Arup Kumar Marik,Basabdatta Palit,Sadananda Behera*

Main category: cs.NI

TL;DR: 量子密钥分配网络中的可靠性感知中继节点布置框架，通过信任评分和中心性分析提升安全连接性


<details>
  <summary>Details</summary>
Motivation: 现有量子中继网络假设所有中继节点都可信，忽视了软件漏洞和内部威胁带来的风险

Method: 给每个节点赋予信任评分，并通过加权链路集成到Dijkstra算法中，使用中间度中心性和特征向量中心性的综合评分对节点进行排名

Result: 在参考拓扑结构上，使用同样数量（8个）的TRN时，比传统度数中心性覆盖了10.77%更多的最短路径

Conclusion: 该方法适用于TRN选择，能够最大化安全连接性，实现可扩展的可靠TRN部署

Abstract: Quantum Key Distribution (QKD) provides information-theoretic security, but
is limited by distance in optical networks, thereby requiring repeater nodes to
extend coverage. Existing works usually assume all repeater nodes and
associated Key Management Servers (KMSs) to be Trusted Repeater Nodes (TRNs),
while ignoring risks from software exploits and insider threats. In this paper,
we propose a reliability-aware TRN placement framework for metro optical
networks, which assigns each node a trust score and integrates it into the
Dijkstra algorithm via weighted links. We then rank the nodes using a composite
score, which is a weighted combination of betweenness centrality and
eigenvector centrality to enable a secure and scalable TRN deployment.
Simulation results on a reference topology show that our method covers 10.77%
more shortest paths compared to traditional metrics like degree centrality,
using the same number (around eight) of TRNs, making it suitable for TRN
selection to maximize secure connectivity.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [152] [Stencil-Lifting: Hierarchical Recursive Lifting System for Extracting Summary of Stencil Kernel in Legacy Codes](https://arxiv.org/abs/2509.10236)
*Mingyi Li,Junmin Xiao,Siyan Chen,Hui Ma,Xi Chen,Peihua Bao,Liang Yuan,Guangming Tan*

Main category: cs.SE

TL;DR: Stencil-Lifting是一个自动将低级语言编写的模板核转换为等效DSL实现的系统，通过层次递归提升理论和算法实现高效可扩展的模板核抽象，相比现有系统获得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有验证提升系统在处理模板核时存在效率瓶颈，需要开发更高效的方法来自动转换遗留代码中的低级模板核实现到现代DSL范式。

Method: 提出层次递归提升理论，使用不变子图表示嵌套循环结构的模板核，通过基于谓词的摘要编码计算语义；开发层次递归提升算法，通过收敛递归过程保证终止性。

Result: 在两个不同测试套件的多样化模板基准测试和四个实际应用上评估，相比最先进的STNG和Dexter系统分别实现31.62倍和5.8倍的加速，同时保持完全语义等价。

Conclusion: Stencil-Lifting显著提高了低级模板核到DSL实现的转换效率，有效弥合了传统优化技术与现代DSL范式之间的差距。

Abstract: We introduce Stencil-Lifting, a novel system for automatically converting
stencil kernels written in low-level languages in legacy code into semantically
equivalent Domain-Specific Language (DSL) implementations. Targeting the
efficiency bottlenecks of existing verified lifting systems, Stencil-Lifting
achieves scalable stencil kernel abstraction through two key innovations.
First, we propose a hierarchical recursive lifting theory that represents
stencil kernels, structured as nested loops, using invariant subgraphs, which
are customized data dependency graphs that capture loop-carried computation and
structural invariants. Each vertex in the invariant subgraph is associated with
a predicate-based summary, encoding its computational semantics. By enforcing
self-consistency across these summaries, Stencil-Lifting ensures the derivation
of correct loop invariants and postconditions for nested loops, eliminating the
need for external verification. Second, we develop a hierarchical recursive
lifting algorithm that guarantees termination through a convergent recursive
process, avoiding the inefficiencies of search-based synthesis. The algorithm
efficiently derives the valid summaries of stencil kernels, and its
completeness is formally proven. We evaluate Stencil-Lifting on diverse stencil
benchmarks from two different suites and on four real-world applications.
Experimental results demonstrate that Stencil-Lifting achieves 31.62$\times$
and 5.8$\times$ speedups compared to the state-of-the-art verified lifting
systems STNG and Dexter, respectively, while maintaining full semantic
equivalence. Our work significantly enhances the translation efficiency of
low-level stencil kernels to DSL implementations, effectively bridging the gap
between legacy optimization techniques and modern DSL-based paradigms.

</details>


### [153] [SWE-Effi: Re-Evaluating Software AI Agent System Effectiveness Under Resource Constraints](https://arxiv.org/abs/2509.09853)
*Zhiyu Fan,Kirill Vasilevski,Dayi Lin,Boyuan Chen,Yihao Chen,Zhiqing Zhong,Jie M. Zhang,Pinjia He,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: SWE-Effi是一个新的评估框架，通过综合考虑准确性和资源消耗（token和时间）来重新评估AI系统在软件工程任务中的整体有效性，发现了资源效率的关键影响因素和系统性挑战。


<details>
  <summary>Details</summary>
Motivation: 现有AI软件工程排行榜（如SWE-bench）只关注解决方案准确性，忽视了资源受限环境下的效率问题。任何AI系统不仅要正确，还必须具有成本效益。

Method: 引入SWE-Effi多维度指标，在SWE-bench基准的子集上重新评估流行的AI问题解决系统，定义有效性为结果准确性与资源消耗之间的平衡。

Result: 发现AI系统的有效性不仅取决于框架本身，还取决于与基础模型的整合程度；识别出"token雪球效应"和"昂贵失败"等系统性挑战；观察到token预算和时间预算有效性之间的明显权衡。

Conclusion: 资源效率是AI系统实际部署的关键因素，需要综合考虑准确性和资源消耗来评估AI系统的整体有效性，这对项目预算管理和可扩展强化学习至关重要。

Abstract: The advancement of large language models (LLMs) and code agents has
demonstrated significant potential to assist software engineering (SWE) tasks,
such as autonomous issue resolution and feature addition. Existing AI for
software engineering leaderboards (e.g., SWE-bench) focus solely on solution
accuracy, ignoring the crucial factor of effectiveness in a
resource-constrained world. This is a universal problem that also exists beyond
software engineering tasks: any AI system should be more than correct - it must
also be cost-effective. To address this gap, we introduce SWE-Effi, a set of
new metrics to re-evaluate AI systems in terms of holistic effectiveness
scores. We define effectiveness as the balance between the accuracy of outcome
(e.g., issue resolve rate) and the resources consumed (e.g., token and time).
In this paper, we specifically focus on the software engineering scenario by
re-ranking popular AI systems for issue resolution on a subset of the SWE-bench
benchmark using our new multi-dimensional metrics. We found that AI system's
effectiveness depends not just on the scaffold itself, but on how well it
integrates with the base model, which is key to achieving strong performance in
a resource-efficient manner. We also identified systematic challenges such as
the "token snowball" effect and, more significantly, a pattern of "expensive
failures". In these cases, agents consume excessive resources while stuck on
unsolvable tasks - an issue that not only limits practical deployment but also
drives up the cost of failed rollouts during RL training. Lastly, we observed a
clear trade-off between effectiveness under the token budget and effectiveness
under the time budget, which plays a crucial role in managing project budgets
and enabling scalable reinforcement learning, where fast responses are
essential.

</details>


### [154] [From Hugging Face to GitHub: Tracing License Drift in the Open-Source AI Ecosystem](https://arxiv.org/abs/2509.09873)
*James Jewitt,Hao Li,Bram Adams,Gopi Krishnan Rajbahadur,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 首次对Hugging Face数据集、模型及应用进行全面许可证审计，发现35.5%模型到应用转换存在许可证冲突，并开发了自动检测工具


<details>
  <summary>Details</summary>
Motivation: 开源AI生态中隐藏的许可证冲突带来严重法律风险，但缺乏数据驱动的实证研究来了解其频率、来源和影响范围

Method: 对Hugging Face上364千个数据集、1.6百万个模型以及14万个GitHub项目进行许可证审计，开发了支持近200个SPDX和模型特定条款的扩展规则引擎

Result: 发现35.5%的模型到应用转换通过重新授权消除了限制性许可证条款，开发的工具能解决86.4%软件应用中的许可号冲突

Conclusion: 许可证遵循是开源AI领域的关键治理挑战，研究提供了支持自动化规模遵循的数据和工具

Abstract: Hidden license conflicts in the open-source AI ecosystem pose serious legal
and ethical risks, exposing organizations to potential litigation and users to
undisclosed risk. However, the field lacks a data-driven understanding of how
frequently these conflicts occur, where they originate, and which communities
are most affected. We present the first end-to-end audit of licenses for
datasets and models on Hugging Face, as well as their downstream integration
into open-source software applications, covering 364 thousand datasets, 1.6
million models, and 140 thousand GitHub projects. Our empirical analysis
reveals systemic non-compliance in which 35.5% of model-to-application
transitions eliminate restrictive license clauses by relicensing under
permissive terms. In addition, we prototype an extensible rule engine that
encodes almost 200 SPDX and model-specific clauses for detecting license
conflicts, which can solve 86.4% of license conflicts in software applications.
To support future research, we release our dataset and the prototype engine.
Our study highlights license compliance as a critical governance challenge in
open-source AI and provides both the data and tools necessary to enable
automated, AI-aware compliance at scale.

</details>


### [155] [SLD-Spec: Enhancement LLM-assisted Specification Generation for Complex Loop Functions via Program Slicing and Logical Deletion](https://arxiv.org/abs/2509.09917)
*Zehan Chen,Long Zhang,Zhiwei Zhang,JingJing Zhang,Ruoyu Zhou,Yulong Shen,JianFeng Ma,Lin Yang*

Main category: cs.SE

TL;DR: SLD-Spec是一种针对复杂循环程序的LLM辅助规范生成方法，通过程序切片和逻辑删除两个新阶段，显著提高了生成规范的正确性、相关性和完整性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的方法在处理包含复杂循环结构的程序时往往产生不相关的规范，且验证工具的严格证明义务和设计约束会导致不完整和模糊的规范。

Method: 提出SLD-Spec方法，包含两个新阶段：(1)切片阶段-将函数分解为包含独立循环结构的代码片段；(2)逻辑删除阶段-应用基于LLM的推理过滤错误候选规范。

Result: 在简单数据集上比最先进的AutoSpec多验证5个程序，运行时间减少23.73%。在复杂循环数据集上，95.1%的断言和90.91%的程序通过验证。

Conclusion: 逻辑删除对提高规范正确性和相关性至关重要，程序切片对规范完整性贡献显著，SLD-Spec能有效处理复杂循环程序的规范生成问题。

Abstract: Automatically generating formal specifications from program code can greatly
enhance the efficiency of program verification and enable end-to-end automation
from requirements to reliable software. However, existing LLM-based approaches
often struggle with programs that include complex loop structures, leading to
irrelevant specifications. Moreover, the rigorous proof obligations and design
constraints imposed by verification tools can further result in incomplete and
ambiguous specifications. To address these challenges, we propose SLD-Spec, an
LLM-assisted specification generation method tailored for programs with complex
loop constructs. SLD-Spec introduces two novel phases into the traditional
specification generation framework: (1) A slicing phase, which decomposes each
function into code fragments containing independent loop structures, thereby
reducing the complexity of specification generation; and (2) A logical deletion
phase, which applies LLM-based reasoning to filter out incorrect candidate
specifications--especially those not easily identified by verification
tool--while retaining valid ones. Experimental results show that on the simple
dataset, SLD-Spec successfully verifies five more programs than the
state-of-the-art AutoSpec and reduces runtime by 23.73%. To address the
limitations of existing research, we manually construct a dataset comprising
four categories of complex loop programs. On this dataset, SLD-Spec
significantly improves the correctness, relevance, and completeness of
generated specifications compared to baseline methods, enabling 95.1% of
assertions and 90.91% of programs to pass verification. Ablation studies
further reveal that logical deletion is critical for enhancing specification
correctness and relevance, while program slicing contributes significantly to
specification completeness. Our code and data are publicly available.

</details>


### [156] [WALL: A Web Application for Automated Quality Assurance using Large Language Models](https://arxiv.org/abs/2509.09918)
*Seyed Moein Abtahi,Akramul Azim*

Main category: cs.SE

TL;DR: WALL是一个集成SonarQube和大型语言模型的Web应用，通过三个模块自动化代码问题检测、修复和评估，实验证明能显著减少人工工作量并降低成本。


<details>
  <summary>Details</summary>
Motivation: 随着软件项目复杂度增加，代码问题数量和种类大幅增长，需要高效的自动化工具来检测、修复和评估代码问题。

Method: 开发WALL Web应用，集成SonarQube和GPT-3.5 Turbo/GPT-4o等LLM，包含问题提取工具、代码问题修订器和代码比较工具三个模块。

Result: 在563个文件、7599个问题上进行实验，证明WALL能有效减少人工工作量，同时保持高质量的代码修订。混合使用成本效益型和先进LLM可显著降低成本并提高修订率。

Conclusion: WALL展示了自动化代码质量管理的有效性，未来工作将集成开源LLM并消除人工干预，实现完全自动化的代码质量管理。

Abstract: As software projects become increasingly complex, the volume and variety of
issues in code files have grown substantially. Addressing this challenge
requires efficient issue detection, resolution, and evaluation tools. This
paper presents WALL, a web application that integrates SonarQube and large
language models (LLMs) such as GPT-3.5 Turbo and GPT-4o to automate these
tasks. WALL comprises three modules: an issue extraction tool, code issues
reviser, and code comparison tool. Together, they enable a seamless pipeline
for detecting software issues, generating automated code revisions, and
evaluating the accuracy of revisions. Our experiments, conducted on 563 files
with over 7,599 issues, demonstrate WALL's effectiveness in reducing human
effort while maintaining high-quality revisions. Results show that employing a
hybrid approach of cost-effective and advanced LLMs can significantly lower
costs and improve revision rates. Future work aims to enhance WALL's
capabilities by integrating open-source LLMs and eliminating human
intervention, paving the way for fully automated code quality management.

</details>


### [157] [Toward Green Code: Prompting Small Language Models for Energy-Efficient Code Generation](https://arxiv.org/abs/2509.09947)
*Humza Ashraf,Syed Muhammad Danish,Zeeshan Sattar*

Main category: cs.SE

TL;DR: 研究调查了提示工程如何提高小型语言模型在代码生成任务中的能源效率，发现CoT提示策略能为某些模型带来一致的能源节省效果


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件开发中带来高能消和碳踹痕，小型语言模型作为更可持续的替代方案，需要研究如何通过提示工程提高其能源效率

Method: 评估四个开源SLM模型（StableCode-Instruct-3B, Qwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, Phi-3-Mini-4K-Instruct）在150道Python问题上的表现，测量运行时间、内存使用和能消而且比较与人工编写基准线，采用四种提示策略（角色提示、零样本、少样本、思维链）

Result: 思维链（CoT）提示为Qwen2.5-Coder和StableCode-3B模型带来一致的能源节省，而CodeLlama-7B和Phi-3-Mini-4K在任何提示策略下都无法超过基准线

Conclusion: 提示工程的好处具有模型依赖性，细心设计的提示可以引导SLM向更绿色的软件开发方向发展

Abstract: There is a growing concern about the environmental impact of large language
models (LLMs) in software development, particularly due to their high energy
use and carbon footprint. Small Language Models (SLMs) offer a more sustainable
alternative, requiring fewer computational resources while remaining effective
for fundamental programming tasks. In this study, we investigate whether prompt
engineering can improve the energy efficiency of SLMs in code generation. We
evaluate four open-source SLMs, StableCode-Instruct-3B,
Qwen2.5-Coder-3B-Instruct, CodeLlama-7B-Instruct, and Phi-3-Mini-4K-Instruct,
across 150 Python problems from LeetCode, evenly distributed into easy, medium,
and hard categories. Each model is tested under four prompting strategies: role
prompting, zero-shot, few-shot, and chain-of-thought (CoT). For every generated
solution, we measure runtime, memory usage, and energy consumption, comparing
the results with a human-written baseline. Our findings show that CoT prompting
provides consistent energy savings for Qwen2.5-Coder and StableCode-3B, while
CodeLlama-7B and Phi-3-Mini-4K fail to outperform the baseline under any
prompting strategy. These results highlight that the benefits of prompting are
model-dependent and that carefully designed prompts can guide SLMs toward
greener software development.

</details>


### [158] [Development of Automated Software Design Document Review Methods Using Large Language Models](https://arxiv.org/abs/2509.09975)
*Takasaburo Fukuda,Takao Nakagawa,Keisuke Miyazaki,Susumu Tokumoto*

Main category: cs.SE

TL;DR: 使用LLM自动化软件设计文档评审过程，通过分析11个评审视角并开发新技术，验证了LLM能够识别设计文档中的不一致性问题


<details>
  <summary>Details</summary>
Motivation: 探索利用大型语言模型自动化软件设计文档评审过程，提高评审效率和准确性

Method: 分析设计文档评审方法并组织11个评审视角，开发新技术使LLM能够理解包含表格数据的复杂设计文档，使用GPT评估不同设计文档间设计项和描述的一致性

Result: 实验证实LLM能够在评审过程中识别软件设计文档中的不一致性问题

Conclusion: 当前通用LLM可以替代人工完成部分设计文档评审工作，特别是在识别不一致性方面表现出良好效果

Abstract: In this study, we explored an approach to automate the review process of
software design documents by using LLM. We first analyzed the review methods of
design documents and organized 11 review perspectives. Additionally, we
analyzed the issues of utilizing LLMs for these 11 review perspectives and
determined which perspectives can be reviewed by current general-purpose LLMs
instead of humans. For the reviewable perspectives, we specifically developed
new techniques to enable LLMs to comprehend complex design documents that
include table data. For evaluation, we conducted experiments using GPT to
assess the consistency of design items and descriptions across different design
documents in the design process used in actual business operations. Our results
confirmed that LLMs can be utilized to identify inconsistencies in software
design documents during the review process.

</details>


### [159] [Sustaining Research Software: A Fitness Function Approach](https://arxiv.org/abs/2509.10085)
*Philipp Zech,Irdin Pekaric*

Main category: cs.SE

TL;DR: 通过引入适应性函数概念，提出一种新的研究软件可持续性提升方法，重点关注FAIR原则（可发现性、可访问性、可互操作性和可重用性）


<details>
  <summary>Details</summary>
Motivation: 研究软件面临维护性差、适应性不足和潜在遗产问题，需要一种系统化方法来确保其长期可持续性

Method: 借鉴进化架构中的适应性函数概念，定义一系列专门为研究软件设计的自动化评估指标，注重FAIR原则，并将其集成到开发生命周期中

Result: 案例研究和实验结果证明该方法能够有效提升研究软件的长期FAIR特性

Conclusion: 适应性函数方法为研究软件可持续性提供了有效解决方案，能够缩小短期项目开发与长期科学影响之间的差距

Abstract: The long-term sustainability of research software is a critical challenge, as
it usually suffers from poor maintainability, lack of adaptability, and
eventual obsolescence. This paper proposes a novel approach to addressing this
issue by leveraging the concept of fitness functions from evolutionary
architecture. Fitness functions are automated, continuously evaluated metrics
designed to ensure that software systems meet desired non-functional,
architectural qualities over time. We define a set of fitness functions
tailored to the unique requirements of research software, focusing on
findability, accessibility, interoperability and reusability (FAIR). These
fitness functions act as proactive safeguards, promoting practices such as
modular design, comprehensive documentation, version control, and compatibility
with evolving technological ecosystems. By integrating these metrics into the
development life cycle, we aim to foster a culture of sustainability within the
research community. Case studies and experimental results demonstrate the
potential of this approach to enhance the long-term FAIR of research software,
bridging the gap between ephemeral project-based development and enduring
scientific impact.

</details>


### [160] [Generating Energy-Efficient Code via Large-Language Models -- Where are we now?](https://arxiv.org/abs/2509.10099)
*Radu Apsan,Vincenzo Stoico,Michel Albonico,Rudra Dhar,Karthik Vaidhyanathan,Ivano Malavolta*

Main category: cs.SE

TL;DR: 大语言模型生成的Python代码在能源效率方面与人类开发者存在差距，绿色软件专家的代码能源效率最高


<details>
  <summary>Details</summary>
Motivation: 评估LLM生成的Python代码的能源效率，与人类开发者和绿色软件专家的代码进行对比

Method: 使用6个普遍LLM和4种提示技巧，在EvoEval基准的9个编码问题上测试363个解决方案，在3种硬件平台（服务器、PC、Raspberry Pi）上测量能消耗

Result: 人类解决方案在服务器上比LLM节能16%，在Raspberry Pi上节能3%，但LLM在PC上比人类节能25%。绿色软件专家的代码在所有平台上都比LLM节能17%-30%

Conclusion: 虽然LLM显示了较好的代码生成能力，但目前还无法超越经验丰富的绿色软件开发者，人类专业知识在开发能源效率高的Python代码中仍至关重要

Abstract: Context. The rise of Large Language Models (LLMs) has led to their widespread
adoption in development pipelines. Goal. We empirically assess the energy
efficiency of Python code generated by LLMs against human-written code and code
developed by a Green software expert. Method. We test 363 solutions to 9 coding
problems from the EvoEval benchmark using 6 widespread LLMs with 4 prompting
techniques, and comparing them to human-developed solutions. Energy consumption
is measured on three different hardware platforms: a server, a PC, and a
Raspberry Pi for a total of ~881h (36.7 days). Results. Human solutions are 16%
more energy-efficient on the server and 3% on the Raspberry Pi, while LLMs
outperform human developers by 25% on the PC. Prompting does not consistently
lead to energy savings, where the most energy-efficient prompts vary by
hardware platform. The code developed by a Green software expert is
consistently more energy-efficient by at least 17% to 30% against all LLMs on
all hardware platforms. Conclusions. Even though LLMs exhibit relatively good
code generation capabilities, no LLM-generated code was more energy-efficient
than that of an experienced Green software developer, suggesting that as of
today there is still a great need of human expertise for developing
energy-efficient Python code.

</details>


### [161] [Targeted Test Selection Approach in Continuous Integration](https://arxiv.org/abs/2509.10279)
*Pavel Plyusnin,Aleksey Antonov,Vasilii Ermakov,Aleksandr Khaybriev,Margarita Kikot,Ilseyar Alimova,Stanislav Moiseev*

Main category: cs.SE

TL;DR: T-TS是一种基于机器学习的工业测试选择方法，通过词袋表示代码变更文件，无需覆盖率映射，能选择15%的测试用例，减少5.9倍执行时间，检测95%以上的测试失败。


<details>
  <summary>Details</summary>
Motivation: 随着代码库扩展和测试套件增长，在高频率代码提交的情况下，高效管理测试过程变得日益困难，需要更智能的测试选择方法。

Method: 提出T-TS机器学习方法，使用变更文件的词袋表示，结合跨文件和其他预测特征，避免使用覆盖率映射。

Result: 在生产环境中，T-TS仅选择15%的测试用例，执行时间减少5.9倍，流水线加速5.6倍，检测超过95%的测试失败。

Conclusion: T-TS在工业环境中表现出色，提供了高效的测试选择解决方案，实现已公开可用以支持进一步研究和实际应用。

Abstract: In modern software development change-based testing plays a crucial role.
However, as codebases expand and test suites grow, efficiently managing the
testing process becomes increasingly challenging, especially given the high
frequency of daily code commits. We propose Targeted Test Selection (T-TS), a
machine learning approach for industrial test selection. Our key innovation is
a data representation that represent commits as Bags-of-Words of changed files,
incorporates cross-file and additional predictive features, and notably avoids
the use of coverage maps. Deployed in production, T-TS was comprehensively
evaluated against industry standards and recent methods using both internal and
public datasets, measuring time efficiency and fault detection. On live
industrial data, T-TS selects only 15% of tests, reduces execution time by
$5.9\times$, accelerates the pipeline by $5.6\times$, and detects over 95% of
test failures. The implementation is publicly available to support further
research and practical adoption.

</details>


### [162] [Developer-LLM Conversations: An Empirical Study of Interactions and Generated Code Quality](https://arxiv.org/abs/2509.10402)
*Suzhen Zhong,Ying Zou,Bram Adams*

Main category: cs.SE

TL;DR: 研究分析了82,845个开发者与LLM的实际对话，发现LLM响应长度是提示的14倍，68%为多轮对话，且不同语言的代码生成问题各异，但通过多轮交互可以改善错误修复效果。


<details>
  <summary>Details</summary>
Motivation: 虽然LLM在软件开发中广泛使用，但对开发者如何与LLM交互及对话动态对任务成果和代码质量的影响理解有限，需要系统性研究。

Method: 利用CodeChat数据集（来自WildChat），包含82,845个实际开发者-LLM对话和368,506个代码片段，涵盖20+编程语言。分析了对话长度、轮次、主题分布，并在5种主流语言中评估代码质量问题。

Result: 1）LLM响应长度中位数是提示的14倍
2）68%对话为多轮对话，通常因需求变化、提示不完整或需要清楚而演化
3）最常见任务为网页设计（9.6%）和神经网络训练（8.7%）
4）不同语言代码问题特异：Python/JS未定义变量（3.4%/75.3%）、Java缺少注释（75.9%）、C++激流头文件（41.1%）、C#未解决命名空间（49.2%）
5）多轮对话中：语法和导入错误持续，但Java文档质量提升14.7%，Python导入处理提升3.7%
6）最有效的提示方式是指出之前代码的错误并明确要求修复

Conclusion: 开发者与LLM的对话通常是多轮的、演化的，不同编程语言的代码生成有特定的质量问题。多轮交互能够逐步改善某些问题，特别是当开发者明确指出错误并要求修复时。这为改善LLM在软件开发中的应用提供了重要见解。

Abstract: Large Language Models (LLMs) are becoming integral to modern software
development workflows, assisting developers with code generation, API
explanation, and iterative problem-solving through natural language
conversations. Despite widespread adoption, there is limited understanding of
how developers interact with LLMs in practice and how these conversational
dynamics influence task outcomes, code quality, and software engineering
workflows. To address this, we leverage CodeChat, a large dataset comprising
82,845 real-world developer-LLM conversations, containing 368,506 code snippets
generated across over 20 programming languages, derived from the WildChat
dataset. We find that LLM responses are substantially longer than developer
prompts, with a median token-length ratio of 14:1. Multi-turn conversations
account for 68% of the dataset and often evolve due to shifting requirements,
incomplete prompts, or clarification requests. Topic analysis identifies web
design (9.6% of conversations) and neural network training (8.7% of
conversations) as the most frequent LLM-assisted tasks. Evaluation across five
languages (i.e., Python, JavaScript, C++, Java, and C#) reveals prevalent and
language-specific issues in LLM-generated code: generated Python and JavaScript
code often include undefined variables (83.4% and 75.3% of code snippets,
respectively); Java code lacks required comments (75.9%); C++ code frequently
omits headers (41.1%) and C# code shows unresolved namespaces (49.2%). During a
conversation, syntax and import errors persist across turns; however,
documentation quality in Java improves by up to 14.7%, and import handling in
Python improves by 3.7% over 5 turns. Prompts that point out mistakes in code
generated in prior turns and explicitly request a fix are most effective for
resolving errors.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [163] [Linear fractional relative risk aversion](https://arxiv.org/abs/2509.09865)
*Kristian Behrens,Yasusada Murata*

Main category: econ.GN

TL;DR: 本文通过高斯超几何函数刻画了满足线性分数相对风险厌恶(LFRRA)的效用函数族，并将其应用于垄断竞争模型，通过推广Lambert W函数得到了利润最大化价格的闭式解。


<details>
  <summary>Details</summary>
Motivation: 研究LFRRA效用函数族的特性，并将其应用于垄断竞争定价问题，以理解不同风险厌恶模式如何影响企业定价行为和加成率变化。

Method: 使用高斯超几何函数表征LFRRA效用函数族，推广Lambert W函数求解垄断竞争下的利润最大化价格，并利用企业层面数据进行实证检验。

Result: 得到了利润最大化价格的闭式解，发现相对风险厌恶的增减性决定了加成率随边际成本的变化方向（递减、递增或恒定）。

Conclusion: LFRRA效用函数族提供了一个统一框架来研究不同风险偏好下的定价行为，企业数据可以实证确定各行业或整体经济中的风险厌恶模式及其对定价的影响。

Abstract: We characterize the family of utility functions satisfying linear fractional
relative risk aversion (LFRRA) in terms of the Gauss hypergeometric functions.
We apply this family, which nests various utility functions used in different
strands of literature, to monopolistic competition and obtain a closed-form
solution for the profit-maximizing price by generalizing the Lambert W
function. We let firm-level data decide whether the RRA in each sector or in
the aggregate economy is increasing, decreasing, or constant, which in turn
determines whether markups are decreasing, increasing, or constant with respect
to marginal costs.

</details>


### [164] [Robo-Advisors Beyond Automation: Principles and Roadmap for AI-Driven Financial Planning](https://arxiv.org/abs/2509.09922)
*Runhuan Feng,Hong Li,Ming Liu*

Main category: econ.GN

TL;DR: 本文提出了一个负责任AI在财务规划中的框架，包含五大原则：受托责任、自适应个性化、技术稳健性、伦理公平约束和可审计性，旨在解决AI可能加剧的市场效率低下问题。


<details>
  <summary>Details</summary>
Motivation: AI正在改变财务规划，但缺乏明确保障措施的数字平台可能重现市场效率低下的问题，如信息不对称、激励错配和系统性脆弱性。

Method: 开发了一个负责任AI框架，基于五大原则，并通过案例研究说明风险和机遇，将框架扩展为五级AI金融中介路线图。

Result: 通过将技术设计与经济理论联系起来，展示了AI既可以放大脆弱性，也可以创建更具韧性、可信赖的金融中介形式。

Conclusion: 提出了一个系统性的负责任AI框架，为AI在财务规划中的可持续发展提供了理论指导和实践路径。

Abstract: Artificial intelligence (AI) is transforming financial planning by expanding
access, lowering costs, and enabling dynamic, data-driven advice. Yet without
clear safeguards, digital platforms risk reproducing longstanding market
inefficiencies such as information asymmetry, misaligned incentives, and
systemic fragility. This paper develops a framework for responsible AI in
financial planning, anchored in five principles: fiduciary duty, adaptive
personalization, technical robustness, ethical and fairness constraints, and
auditability. We illustrate these risks and opportunities through case studies,
and extend the framework into a five-level roadmap of AI financial
intermediaries. By linking technological design to economic theory, we show how
AI can either amplify vulnerabilities or create more resilient, trustworthy
forms of financial intermediation.

</details>


### [165] [Price Formation in a Highly-Renewable, Sector-Coupled Energy System](https://arxiv.org/abs/2509.10092)
*Julian Geis,Fabian Neumann,Michael Lindner,Philipp Härtel,Tom Brown*

Main category: econ.GN

TL;DR: 这篇论文提出了一种新方法来分析变可再生能源体系下的电价形成机制，通过双变量映射构建供需曲线，并在德国PyPSA-DE模型中进行验证。研究发现从化石燃料主导的分层价格向变可再生能源和存储设备主导的平滑价格曲线迁移，虽然价格波动增加但仍能在75%时间以非零价格清算。


<details>
  <summary>Details</summary>
Motivation: 随着变可再生能源增加和需求电气化，批发电力市场价格形成机制将从化石燃料发电主导迁移到由存储和需求管理的机会成本主导，需要新方法来分析这种迁移过程。

Method: 提出一种基于能源系统优化问题双变量的新方法，将双变量映射到电力供应商和消费者的报价上，从而构建每小时的完整供需曲线。在德国PyPSA-DE模型中进行高时间分辨率分析，时间范围从2020年到2045年完全脱碳化。

Result: 发现电价形成从明显的化石燃料价格层次迁移到由变可再生能源、电池和水解水设备定价的更平滑价格曲线。虽然价格波动性增加，但完全脱碳化的系统在75%的时间里以非零价格完成清算。

Conclusion: 灵活性和跨部门需求报价在气候中性未来的电价稳定中发挥着关键作用。这些发现对投资决策和政策制定具有重要意义，特别是在支持动态价格、多时间尺度能源存储扩录以及可再生能源与灵活性技术协调发展方面。

Abstract: As variable renewable energy increases and more demand is electrified, we
expect price formation in wholesale electricity markets to transition from
being dominated by fossil fuel generators to being dominated by the opportunity
costs of storage and demand management. In order to analyse this transition, we
introduce a new method to investigate price formation based on a mapping from
the dual variables of the energy system optimisation problem to the bids and
asks of electricity suppliers and consumers. This allows us to build the full
supply and demand curves in each hour. We use this method to analyse price
formation in a sector-coupled, climate-neutral energy system model for Germany,
PyPSA-DE, with high temporal resolution and myopic foresight in 5-year steps
from 2020 until full decarbonisation in 2045. We find a clear transition from
distinct price levels, corresponding to fossil fuels, to a smoother price curve
set by variable renewable energy sources, batteries and electrolysis. Despite
higher price volatility, the fully decarbonised system clears with non-zero
prices in 75% of all hours. Our results suggest that flexibility and
cross-sectoral demand bidding play a vital role in stabilising electricity
prices in a climate-neutral future. These findings are highly relevant for
guiding investment decisions and informing policy, particularly in support of
dynamic pricing, the expansion of energy storage across multiple timescales,
and the coordinated development of renewable and flexibility technologies.

</details>


### [166] [The anatomy of Green AI technologies: structure, evolution, and impact](https://arxiv.org/abs/2509.10109)
*Lorenzo Emer,Andrea Mina,Andrea Vandin*

Main category: econ.GN

TL;DR: 本研究通过分析约63,000项绿色AI专利，揭示了AI在气候适应和减缓技术中的应用趋势，发现从传统技术向新兴领域（如数据处理、微电网）的转变，并指出某些关键领域需要政策干预来促进创新。


<details>
  <summary>Details</summary>
Motivation: 调查AI在气候适应和减缓技术中的创新作用，通过专利分析了解绿色AI技术的发展趋势、企业所有权格局、地理分布及其对后续发明和市场价值的影响。

Method: 使用BERTopic主题建模方法分析专利数据集，识别16个主要技术领域，追踪其随时间演变，并评估其相对影响力。分析专利趋势、企业所有权、地理分布、技术影响和市场价值。

Result: 发现从传统燃烧发动机技术向新兴领域（数据处理、微电网、农业水资源管理）的明显转变；企业专利集中度增加但专利企业数量快速增长；某些绿色AI领域技术影响与市场价值兼具，而其他关键气候领域私人创新激励较弱。

Conclusion: 尽管AI是气候创新的关键推动者，但某些对气候适应和减缓策略重要的技术领域缺乏足够的私人创新激励，需要政策干预来促进新绿色AI应用的产生和使用。

Abstract: Artificial intelligence (AI) is a key enabler of innovation against climate
change. In this study, we investigate the intersection of AI and climate
adaptation and mitigation technologies through patent analyses of a novel
dataset of approximately 63 000 Green AI patents. We analyze patenting trends,
corporate ownership of the technology, the geographical distributions of
patents, their impact on follow-on inventions and their market value. We use
topic modeling (BERTopic) to identify 16 major technological domains, track
their evolution over time, and identify their relative impact. We uncover a
clear shift from legacy domains such as combustion engines technology to
emerging areas like data processing, microgrids, and agricultural water
management. We find evidence of growing concentration in corporate patenting
against a rapidly increasing number of patenting firms. Looking at the
technological and economic impact of patents, while some Green AI domains
combine technological impact and market value, others reflect weaker private
incentives for innovation, despite their relevance for climate adaptation and
mitigation strategies. This is where policy intervention might be required to
foster the generation and use of new Green AI applications.

</details>


### [167] [Evaluating the Economic Feasibility of Labor Replacement Through Robotics and Automation in Qatar](https://arxiv.org/abs/2509.10152)
*Tariq Eldakruri,Edip Senyurek*

Main category: econ.GN

TL;DR: 卡塔尔制造业和服务业人工智能替代的经济可行性分析，识别有利的自动化领域和挑战


<details>
  <summary>Details</summary>
Motivation: 评估在卡塔尔制造业和服务业用机器人和自动化替代人力劳动的经济可行性

Method: 分析劳动成本、生产力增长和实施费用，评估机器人集成的财务影响和投资回报率

Result: 确定了自动化在经济上可行的行业领域，识别了劳动力适应、政策和基础设施方面的挑战

Conclusion: 为政策制定者和业界利益相关方提供了关于卡塔尔自动化策略的指导性见解

Abstract: This paper investigates the economic feasibility of replacing human labor
with robotics and automation in Qatar's manufacturing and service sectors. By
analyzing labor costs, productivity gains, and implementation expenses, the
study assesses the potential financial impact and return on investment of
robotic integration. Results indicate the sectors where automation is
economically viable and identify challenges related to workforce adaptation,
policy, and infrastructure. These insights provide guidance for policymakers
and industry stakeholders considering automation strategies in Qatar.

</details>


### [168] [The temporary impact of permanent hiring incentives: Evidence from Italy](https://arxiv.org/abs/2509.10193)
*Michele Cantarella,Maria Cristina Maurizio,Francesco Serti*

Main category: econ.GN

TL;DR: 这篇论文通过差异之差和回归断点设计分析了意大利图斯卡尼地区的聘用激励政策，发现该政策在短期内提高了临时合同转为固定合同的概率，但长期效果为零，主要是预期转换的影响。


<details>
  <summary>Details</summary>
Motivation: 评估通过社会缘金免除来促进临时合同永久转换的聘用激励政策的短期和中期效果，以了解该政策是否真正有效提高稳定就业。

Method: 使用意大利图斯卡尼地区的细粒度行政数据，采用差异之差和回归断点设计来利用2018年资格标准的独特变化进行实证分析。

Result: 激励政策立即提高了合同转换概率，没有证据显示对非资格群体的替代效应。但这些积极效果是短暂的，长期对固定聘用的影响为零，主要反映了预期转换行为。

Conclusion: 聘用激励政策在短期内能够促进临时合同转换，但无法实现长期提高稳定就业的目标，政策效果主要是引发了合同转换时间的前置，而非真正增加了固定聘用数量。

Abstract: This paper evaluates the short and medium-term effectiveness of hiring
incentives aimed at promoting the permanent conversion of temporary contracts
through social contribution exemptions. Using rich administrative data from
Tuscany, providing detailed employment histories, we use difference in
differences and regression discontinuity designs to exploit a unique change in
eligibility criteria in 2018. We find that the incentives immediately increased
the probability of conversion, with no evidence of substitution against
non-eligible cohorts. However, these positive effects were short-lived and
appear to reflect anticipated conversions, as we find null longer-term effects
on permanent hirings.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [169] [Targeted Advertising in Elections](https://arxiv.org/abs/2509.10422)
*Maria Titova*

Main category: econ.TH

TL;DR: 定向广告使挑战者能够通过向不同选民策略性披露不同信息来说服偏好相反的选民，从而影响选举结果，甚至能在现状位于中位选民理想点时获胜。


<details>
  <summary>Details</summary>
Motivation: 研究定向广告如何影响选举结果，探讨挑战者如何通过信息策略改变选民投票行为。

Method: 建立一维空间投票模型，分析挑战者如何向不同选民策略性披露可验证信息来进行说服。

Result: 定向广告使挑战者能够说服偏好相反的选民并影响选举结果，即使在现状位于中位选民理想点时也能获胜。

Conclusion: 公开所有政治广告可以减轻定向广告的负面影响，帮助选民集体做出正确选择。

Abstract: How does targeted advertising influence electoral outcomes? This paper
presents a one-dimensional spatial model of voting in which a privately
informed challenger persuades voters to support him over the status quo. I show
that targeted advertising enables the challenger to persuade voters with
opposing preferences and swing elections decided by such voters; under simple
majority, the challenger can defeat the status quo even when it is located at
the median voter's bliss point. Ex-ante commitment power is unnecessary -- the
challenger succeeds by strategically revealing different pieces of verifiable
information to different voters. Publicizing all political ads would mitigate
the negative effects of targeted advertising and help voters collectively make
the right choice.

</details>
