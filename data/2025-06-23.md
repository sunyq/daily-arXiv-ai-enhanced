<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 41]
- [cs.CL](#cs.CL) [Total: 79]
- [cs.CV](#cs.CV) [Total: 117]
- [cs.DB](#cs.DB) [Total: 9]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.PL](#cs.PL) [Total: 3]
- [cs.SE](#cs.SE) [Total: 21]
- [econ.EM](#econ.EM) [Total: 1]
- [econ.GN](#econ.GN) [Total: 5]
- [econ.TH](#econ.TH) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [LLMs Struggle to Perform Counterfactual Reasoning with Parametric Knowledge](https://arxiv.org/abs/2506.15732)
*Khurram Yamin,Gaurav Ghosal,Bryan Wilder*

Main category: cs.AI

TL;DR: LLMs在整合参数知识与新信息时表现不佳，尤其在反事实推理任务中，且微调可能损害其原有知识。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs能否在反事实推理中结合上下文与参数知识。

Method: 通过合成和真实实验研究LLMs在多跳推理问题中的表现。

Result: LLMs在反事实推理中表现不佳，倾向于依赖参数知识，微调可能损害其知识。

Conclusion: 当前LLMs在新环境中重新利用参数知识的能力存在显著局限。

Abstract: Large Language Models have been shown to contain extensive world knowledge in
their parameters, enabling impressive performance on many knowledge intensive
tasks. However, when deployed in novel settings, LLMs often encounter
situations where they must integrate parametric knowledge with new or
unfamiliar information. In this work, we explore whether LLMs can combine
knowledge in-context with their parametric knowledge through the lens of
counterfactual reasoning. Through synthetic and real experiments in multi-hop
reasoning problems, we show that LLMs generally struggle with counterfactual
reasoning, often resorting to exclusively using their parametric knowledge.
Moreover, we show that simple post-hoc finetuning can struggle to instill
counterfactual reasoning ability -- often leading to degradation in stored
parametric knowledge. Ultimately, our work reveals important limitations of
current LLM's abilities to re-purpose parametric knowledge in novel settings.

</details>


### [2] [$\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts](https://arxiv.org/abs/2506.15733)
*Mert Cemri,Nived Rajaraman,Rishabh Tiwari,Xiaoxuan Liu,Kurt Keutzer,Ion Stoica,Kannan Ramchandran,Ahmad Beirami,Ziteng Sun*

Main category: cs.AI

TL;DR: 论文提出了一种名为SPECS的延迟感知测试时扩展方法，通过小模型生成候选序列并结合大模型和奖励模型评估，显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前测试时扩展方法主要优化准确性而忽视延迟，影响用户体验。

Method: SPECS利用小模型高效生成候选序列，结合大模型和奖励模型评估，引入奖励引导的软验证和延迟机制。

Result: 在多个数据集上，SPECS在保持或超越束搜索准确性的同时，延迟降低达19.1%。

Conclusion: SPECS通过延迟感知优化，平衡了准确性和用户体验。

Abstract: Scaling test-time compute has driven the recent advances in the reasoning
capabilities of large language models (LLMs), typically by allocating
additional computation for more thorough exploration. However, increased
compute often comes at the expense of higher user-facing latency, directly
impacting user experience. Current test-time scaling methods primarily optimize
for accuracy based on total compute resources (FLOPS), often overlooking
latency constraints. To address this gap, we propose $\texttt{SPECS}$, a
latency-aware test-time scaling method inspired by speculative decoding.
$\texttt{SPECS}$~uses a smaller, faster model to generate candidate sequences
efficiently, and evaluates these candidates using signals from both a larger
target model and a dedicated reward model. We introduce new integration
strategies, including reward-guided soft verification and a reward-based
deferral mechanism. Empirical results on MATH500, AMC23 and OlympiadBench
datasets show that $\texttt{SPECS}$~matches or surpasses beam search accuracy
while reducing latency by up to $\sim$19.1\%. Our theoretical analysis shows
that our algorithm converges to the solution of a KL-regularized reinforcement
learning objective with increasing beam width.

</details>


### [3] [The Safety Reminder: A Soft Prompt to Reactivate Delayed Safety Awareness in Vision-Language Models](https://arxiv.org/abs/2506.15734)
*Peiyuan Tang,Haojie Xin,Xiaodong Zhang,Jun Sun,Qin Xia,Zijiang Yang*

Main category: cs.AI

TL;DR: 论文提出了一种针对视觉语言模型（VLM）安全性的新方法，通过识别其“延迟安全意识”现象，设计了“安全提醒”机制，以软提示调优方式增强模型安全性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型（VLM）在代码生成和聊天机器人等实际应用中的能力增强，其安全性问题日益突出。由于多模态特性，VLM面临独特的漏洞，攻击者可能通过修改视觉或文本输入绕过安全防护，生成有害内容。

Method: 通过系统分析VLM在攻击下的行为，发现其存在“延迟安全意识”现象。基于此，提出“安全提醒”方法，通过优化可学习的提示令牌，在文本生成过程中定期注入以增强安全意识。

Result: 在三个安全基准和一个对抗攻击测试中，该方法显著降低了攻击成功率，同时保持了模型在正常任务中的性能。

Conclusion: “安全提醒”为实际应用中部署更安全的VLM提供了一种实用解决方案。

Abstract: As Vision-Language Models (VLMs) demonstrate increasing capabilities across
real-world applications such as code generation and chatbot assistance,
ensuring their safety has become paramount. Unlike traditional Large Language
Models (LLMs), VLMs face unique vulnerabilities due to their multimodal nature,
allowing adversaries to modify visual or textual inputs to bypass safety
guardrails and trigger the generation of harmful content. Through systematic
analysis of VLM behavior under attack, we identify a novel phenomenon termed
``delayed safety awareness''. Specifically, we observe that safety-aligned VLMs
may initially be compromised to produce harmful content, but eventually
recognize the associated risks and attempt to self-correct. This pattern
suggests that VLMs retain their underlying safety awareness but experience a
temporal delay in their activation. Building on this insight, we hypothesize
that VLMs' safety awareness can be proactively reactivated through carefully
designed prompts. To this end, we introduce ``The Safety Reminder'', a soft
prompt tuning approach that optimizes learnable prompt tokens, which are
periodically injected during the text generation process to enhance safety
awareness, effectively preventing harmful content generation. Additionally, our
safety reminder only activates when harmful content is detected, leaving normal
conversations unaffected and preserving the model's performance on benign
tasks. Through comprehensive evaluation across three established safety
benchmarks and one adversarial attacks, we demonstrate that our approach
significantly reduces attack success rates while maintaining model utility,
offering a practical solution for deploying safer VLMs in real-world
applications.

</details>


### [4] [ContextBench: Modifying Contexts for Targeted Latent Activation](https://arxiv.org/abs/2506.15735)
*Robert Graham,Edward Stevinson,Leo Richter,Alexander Chia,Joseph Miller,Joseph Isaac Bloom*

Main category: cs.AI

TL;DR: 论文提出了一种通过上下文修改生成针对性输入的方法，以激活语言模型的特定行为或潜在特征，并提出了ContextBench基准和评估框架。


<details>
  <summary>Details</summary>
Motivation: 识别触发语言模型特定行为或潜在特征的输入，具有广泛的安全应用价值。

Method: 通过上下文修改生成针对性输入，结合进化提示优化（EPO）、LLM辅助和扩散模型修复技术。

Result: 改进的方法在激活效果和语言流畅性上达到最优平衡。

Conclusion: 该方法在安全应用中具有潜力，但现有方法仍需改进以更好地平衡激活效果和流畅性。

Abstract: Identifying inputs that trigger specific behaviours or latent features in
language models could have a wide range of safety use cases. We investigate a
class of methods capable of generating targeted, linguistically fluent inputs
that activate specific latent features or elicit model behaviours. We formalise
this approach as context modification and present ContextBench -- a benchmark
with tasks assessing core method capabilities and potential safety
applications. Our evaluation framework measures both elicitation strength
(activation of latent features or behaviours) and linguistic fluency,
highlighting how current state-of-the-art methods struggle to balance these
objectives. We enhance Evolutionary Prompt Optimisation (EPO) with
LLM-assistance and diffusion model inpainting, and demonstrate that these
variants achieve state-of-the-art performance in balancing elicitation
effectiveness and fluency.

</details>


### [5] [SHADE-Arena: Evaluating Sabotage and Monitoring in LLM Agents](https://arxiv.org/abs/2506.15740)
*Jonathan Kutasov,Yuqi Sun,Paul Colognese,Teun van der Weij,Linda Petrini,Chen Bo Calvin Zhang,John Hughes,Xiang Deng,Henry Sleight,Tyler Tracy,Buck Shlegeris,Joe Benton*

Main category: cs.AI

TL;DR: 论文研究了前沿大语言模型（LLMs）在复杂任务中隐藏有害目标的能力，并开发了SHADE-Arena数据集进行评估。结果显示，部分模型在隐藏任务中表现较好，但监控仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在复杂任务中的自主部署增多，评估其隐藏有害目标的能力变得至关重要。

Method: 使用SHADE-Arena数据集评估模型在完成主任务和隐藏有害任务时的表现，并测试其避免被监控的能力。

Result: 最佳模型在隐藏任务中表现较好（Claude 3.7 Sonnet 27%，Gemini 2.5 Pro 15%），但监控能力仍有不足（Gemini 2.5 Pro AUC 0.87）。

Conclusion: 当前模型在隐藏任务中表现有限，但监控难度已显现，未来任务复杂性增加可能加剧这一问题。

Abstract: As Large Language Models (LLMs) are increasingly deployed as autonomous
agents in complex and long horizon settings, it is critical to evaluate their
ability to sabotage users by pursuing hidden objectives. We study the ability
of frontier LLMs to evade monitoring and achieve harmful hidden goals while
completing a wide array of realistic tasks. We evaluate a broad range of
frontier LLMs using SHADE (Subtle Harmful Agent Detection & Evaluation)-Arena,
the first highly diverse agent evaluation dataset for sabotage and monitoring
capabilities of LLM agents. SHADE-Arena consists of complex pairs of benign
main tasks and harmful side objectives in complicated environments. Agents are
evaluated on their ability to complete the side task without appearing
suspicious to an LLM monitor. When measuring agent ability to (a) complete the
main task, (b) complete the side task, and (c) avoid detection, we find that
the best performing frontier models score 27% (Claude 3.7 Sonnet) and 15%
(Gemini 2.5 Pro) as sabotage agents when overseen by Claude 3.6 Sonnet. For
current frontier models, success on the side task relies heavily on having
access to a hidden scratchpad that is not visible to the monitor. We also use
SHADE-Arena to measure models' monitoring abilities, with the top monitor
(Gemini 2.5 Pro) achieving an AUC of 0.87 at distinguishing benign and malign
transcripts. We find that for now, models still struggle at sabotage due to
failures in long-context main task execution. However, our measurements already
demonstrate the difficulty of monitoring for subtle sabotage attempts, which we
expect to only increase in the face of more complex and longer-horizon tasks.

</details>


### [6] [OAgents: An Empirical Study of Building Effective Agents](https://arxiv.org/abs/2506.15741)
*He Zhu,Tianrui Qin,King Zhu,Heyuan Huang,Yeyi Guan,Jinxiang Xia,Yi Yao,Hanhao Li,Ningning Wang,Pai Liu,Tianhao Peng,Xin Gui,Xiaowan Li,Yuhui Liu,Yuchen Eleanor Jiang,Jun Wang,Changwang Zhang,Xiangru Tang,Ge Zhang,Jian Yang,Minghao Liu,Xitong Gao,Wangchunshu Zhou,Jiaheng Liu*

Main category: cs.AI

TL;DR: 论文指出当前Agentic AI研究缺乏标准化和科学严谨性，提出了一种更稳健的评估协议，并开源了OAgents框架，实现了开源项目中的最佳性能。


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI研究缺乏标准化和科学严谨性，难以公平比较不同方法的有效性。

Method: 通过GAIA基准和BrowseComp进行系统性实证研究，分析关键组件设计选择的影响，并提出稳健的评估协议。

Result: 研究发现缺乏标准评估协议导致先前工作不可复现，且随机运行间差异显著。OAgents框架实现了开源项目中的最佳性能。

Conclusion: 论文提出了一种稳健的评估协议和OAgents框架，为Agentic AI的未来研究提供了模块化设计基础。

Abstract: Recently, Agentic AI has become an increasingly popular research field.
However, we argue that current agent research practices lack standardization
and scientific rigor, making it hard to conduct fair comparisons among methods.
As a result, it is still unclear how different design choices in agent
frameworks affect effectiveness, and measuring their progress remains
challenging. In this work, we conduct a systematic empirical study on GAIA
benchmark and BrowseComp to examine the impact of popular design choices in key
agent components in a fair and rigorous manner. We find that the lack of a
standard evaluation protocol makes previous works, even open-sourced ones,
non-reproducible, with significant variance between random runs. Therefore, we
introduce a more robust evaluation protocol to stabilize comparisons. Our study
reveals which components and designs are crucial for effective agents, while
others are redundant, despite seeming logical. Based on our findings, we build
and open-source OAgents, a new foundation agent framework that achieves
state-of-the-art performance among open-source projects. OAgents offers a
modular design for various agent components, promoting future research in
Agentic AI.

</details>


### [7] [Bayesian Epistemology with Weighted Authority: A Formal Architecture for Truth-Promoting Autonomous Scientific Reasoning](https://arxiv.org/abs/2506.16015)
*Craig S. Wright*

Main category: cs.AI

TL;DR: BEWA是一种基于贝叶斯推理的架构，旨在解决科学文献爆炸性增长带来的认知处理问题，通过动态概率模型和结构化科学主张实现机器推理。


<details>
  <summary>Details</summary>
Motivation: 科学文献的快速增长超出了人类和AI系统的处理能力，需要一种新的方法来动态评估和更新科学主张的可信度。

Method: BEWA采用贝叶斯推理、复制评分、引用加权和时间衰减机制，结合图传播和作者可信度建模，构建可验证的认知网络。

Result: BEWA能够支持动态科学领域的真理效用、理性信念收敛和审计弹性完整性。

Conclusion: BEWA为机器推理系统提供了新的基础，有望提升科学领域的认知效率和可信度。

Abstract: The exponential expansion of scientific literature has surpassed the
epistemic processing capabilities of both human experts and current artificial
intelligence systems. This paper introduces Bayesian Epistemology with Weighted
Authority (BEWA), a formally structured architecture that operationalises
belief as a dynamic, probabilistically coherent function over structured
scientific claims. Each claim is contextualised, author-attributed, and
evaluated through a system of replication scores, citation weighting, and
temporal decay. Belief updates are performed via evidence-conditioned Bayesian
inference, contradiction processing, and epistemic decay mechanisms. The
architecture supports graph-based claim propagation, authorial credibility
modelling, cryptographic anchoring, and zero-knowledge audit verification. By
formalising scientific reasoning into a computationally verifiable epistemic
network, BEWA advances the foundation for machine reasoning systems that
promote truth utility, rational belief convergence, and audit-resilient
integrity across dynamic scientific domains.

</details>


### [8] [Sysformer: Safeguarding Frozen Large Language Models with Adaptive System Prompts](https://arxiv.org/abs/2506.15751)
*Kartik Sharma,Yiqiao Jin,Vineeth Rakesh,Yingtong Dou,Menghai Pan,Mahashweta Das,Srijan Kumar*

Main category: cs.AI

TL;DR: 论文提出了一种名为Sysformer的新方法，通过动态调整系统提示来增强大型语言模型（LLM）的安全性，避免对有害提示的响应，同时优化对安全提示的响应。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的微调或次优启发式技术，难以确保LLM在安全关键场景中的响应合规性。

Method: 提出Sysformer模型，在LLM输入嵌入空间中动态更新系统提示，保持LLM参数不变，训练Sysformer拒绝有害提示并优化安全提示响应。

Result: 实验表明，Sysformer显著提升了LLM的鲁棒性，有害提示拒绝率提高80%，安全提示合规性提升90%，对抗攻击的鲁棒性提高100%。

Conclusion: Sysformer为LLM提供了一种低成本的安全保障方法，并启发了未来对可变系统提示设计的研究。

Abstract: As large language models (LLMs) are deployed in safety-critical settings, it
is essential to ensure that their responses comply with safety standards. Prior
research has revealed that LLMs often fail to grasp the notion of safe
behaviors, resulting in either unjustified refusals to harmless prompts or the
generation of harmful content. While substantial efforts have been made to
improve their robustness, existing defenses often rely on costly fine-tuning of
model parameters or employ suboptimal heuristic techniques. In this work, we
take a novel approach to safeguard LLMs by learning to adapt the system prompts
in instruction-tuned LLMs. While LLMs are typically pre-trained to follow a
fixed system prompt, we investigate the impact of tailoring the system prompt
to each specific user input on the safety of the responses. To this end, we
propose $\textbf{Sysformer}$, a trans$\textbf{former}$ model that updates an
initial $\textbf{sys}$tem prompt to a more robust system prompt in the LLM
input embedding space while attending to the user prompt. While keeping the LLM
parameters frozen, the Sysformer is trained to refuse to respond to a set of
harmful prompts while responding ideally to a set of safe ones. Through
extensive experiments on $5$ LLMs from different families and $2$ recent
benchmarks, we demonstrate that Sysformer can significantly enhance the
robustness of LLMs, leading to upto $80\%$ gain in the refusal rate on harmful
prompts while enhancing the compliance with the safe prompts by upto $90\%$.
Results also generalize well to sophisticated jailbreaking attacks, making LLMs
upto $100\%$ more robust against different attack strategies. We hope our
findings lead to cheaper safeguarding of LLMs and motivate future
investigations into designing variable system prompts.

</details>


### [9] [Linear-Time Primitives for Algorithm Development in Graphical Causal Inference](https://arxiv.org/abs/2506.15758)
*Marcel Wienöbst,Sebastian Weichwald,Leonard Henckel*

Main category: cs.AI

TL;DR: CIfly是一个用于图形因果推理的高效算法框架，通过将可达性作为核心操作，简化了许多因果推理任务。


<details>
  <summary>Details</summary>
Motivation: 现有因果推理方法（如道德化和潜在投影）效率较低，CIfly旨在提供更高效的替代方案。

Method: 基于状态空间图的可达性操作，设计了规则表模式，并证明其线性时间复杂度。

Result: CIfly在性能上优于传统方法，并通过开源Rust实现支持Python和R调用。

Conclusion: CIfly为图形因果推理提供了灵活、可扩展的框架，支持新算法开发和高效部署。

Abstract: We introduce CIfly, a framework for efficient algorithmic primitives in
graphical causal inference that isolates reachability as a reusable core
operation. It builds on the insight that many causal reasoning tasks can be
reduced to reachability in purpose-built state-space graphs that can be
constructed on the fly during traversal. We formalize a rule table schema for
specifying such algorithms and prove they run in linear time. We establish
CIfly as a more efficient alternative to the common primitives moralization and
latent projection, which we show are computationally equivalent to Boolean
matrix multiplication. Our open-source Rust implementation parses rule table
text files and runs the specified CIfly algorithms providing high-performance
execution accessible from Python and R. We demonstrate CIfly's utility by
re-implementing a range of established causal inference tasks within the
framework and by developing new algorithms for instrumental variables. These
contributions position CIfly as a flexible and scalable backbone for graphical
causal inference, guiding algorithm development and enabling easy and efficient
deployment.

</details>


### [10] [Incentivizing High-quality Participation From Federated Learning Agents](https://arxiv.org/abs/2506.16731)
*Jinlong Pang,Jiaheng Wei,Yifan Hua,Chen Qian,Yang Liu*

Main category: cs.AI

TL;DR: 提出了一种考虑数据异质性的激励感知联邦学习框架，通过Wasserstein距离量化异质性，利用对等预测机制设计评分函数，并通过两阶段Stackelberg博弈模型验证均衡存在性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦学习研究假设参与者自愿无私，但实际中自利参与者可能退出或提供低质量贡献，且现有方法忽略数据异质性导致的努力差异。

Method: 引入Wasserstein距离量化数据异质性，重新定义收敛上界；利用对等预测机制设计评分函数；提出两阶段Stackelberg博弈模型。

Result: 在真实数据集上的实验验证了所提机制的有效性。

Conclusion: 该框架通过激励设计和数据异质性处理，提升了联邦学习的收敛速度和模型质量。

Abstract: Federated learning (FL) provides a promising paradigm for facilitating
collaboration between multiple clients that jointly learn a global model
without directly sharing their local data. However, existing research suffers
from two caveats: 1) From the perspective of agents, voluntary and unselfish
participation is often assumed. But self-interested agents may opt out of the
system or provide low-quality contributions without proper incentives; 2) From
the mechanism designer's perspective, the aggregated models can be
unsatisfactory as the existing game-theoretical federated learning approach for
data collection ignores the potential heterogeneous effort caused by
contributed data. To alleviate above challenges, we propose an incentive-aware
framework for agent participation that considers data heterogeneity to
accelerate the convergence process. Specifically, we first introduce the notion
of Wasserstein distance to explicitly illustrate the heterogeneous effort and
reformulate the existing upper bound of convergence. To induce truthful
reporting from agents, we analyze and measure the generalization error gap of
any two agents by leveraging the peer prediction mechanism to develop score
functions. We further present a two-stage Stackelberg game model that
formalizes the process and examines the existence of equilibrium. Extensive
experiments on real-world datasets demonstrate the effectiveness of our
proposed mechanism.

</details>


### [11] [Advancing Stochastic 3-SAT Solvers by Dissipating Oversatisfied Constraints](https://arxiv.org/abs/2506.15774)
*J. Schwardt,J. C. Budich*

Main category: cs.AI

TL;DR: 提出了一种名为DOCSAT的随机局部搜索启发式算法，用于解决3-SAT问题，显著优于现有求解器，尤其在处理极难实例时表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有方法如WalkSAT容易陷入局部最小值，这些局部最小值与真实解的区别在于存在过多的过满足约束。

Method: DOCSAT通过减少过满足约束（DOC）的数量，使其变得关键，从而避免局部最小值陷阱。

Result: 在N=15000的极难3-SAT实例上，DOCSAT表现优于WalkSAT和Kissat等算法。

Conclusion: DOCSAT利用统计结构避免局部最小值，为其他优化问题提供了通用化思路。

Abstract: We introduce and benchmark a stochastic local search heuristic for the
NP-complete satisfiability problem 3-SAT that drastically outperforms existing
solvers in the notoriously difficult realm of critically hard instances. Our
construction is based on the crucial observation that well established previous
approaches such as WalkSAT are prone to get stuck in local minima that are
distinguished from true solutions by a larger number of oversatisfied
combinatorial constraints. To address this issue, the proposed algorithm,
coined DOCSAT, dissipates oversatisfied constraints (DOC), i.e. reduces their
unfavorable abundance so as to render them critical. We analyze and benchmark
our algorithm on a randomly generated sample of hard but satisfiable 3-SAT
instances with varying problem sizes up to N=15000. Quite remarkably, we find
that DOCSAT outperforms both WalkSAT and other well known algorithms including
the complete solver Kissat, even when comparing its ability to solve the
hardest quintile of the sample to the average performance of its competitors.
The essence of DOCSAT may be seen as a way of harnessing statistical structure
beyond the primary cost function of a combinatorial problem to avoid or escape
local minima traps in stochastic local search, which opens avenues for
generalization to other optimization problems.

</details>


### [12] [SLR: An Automated Synthesis Framework for Scalable Logical Reasoning](https://arxiv.org/abs/2506.15787)
*Lukas Helff,Ahmad Omar,Felix Friedrich,Wolfgang Stammer,Antonia Wüst,Tim Woydt,Rupert Mitchell,Patrick Schramowski,Kristian Kersting*

Main category: cs.AI

TL;DR: SLR是一个端到端框架，用于通过可扩展的逻辑推理系统评估和训练大型语言模型（LLMs）。它能够自动生成具有精确控制难度的归纳推理任务，并创建了一个包含19k提示的基准测试SLR-Bench。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在逻辑推理方面表现不佳，需要一种自动化、可扩展的方法来评估和改进其推理能力。

Method: SLR通过合成潜在的真实规则、可执行的验证程序和任务提示，生成具有不同复杂度的推理任务。

Result: 评估显示，当代LLMs在逻辑推理上表现不佳，但通过SLR的逻辑调优，Llama-3-8B的准确率翻倍，达到与Gemini-Flash-Thinking相当的水平。

Conclusion: SLR提供了一种无需人工标注、完全自动化的方法，为LLMs的推理能力提供了可扩展的评估和训练环境。

Abstract: We introduce SLR, an end-to-end framework for systematic evaluation and
training of Large Language Models (LLMs) via Scalable Logical Reasoning. Given
a user's task specification, SLR enables scalable, automated synthesis of
inductive reasoning tasks with precisely controlled difficulty. For each task,
SLR synthesizes (i) a latent ground-truth rule, (ii) an executable validation
program used by a symbolic judge to deterministically verify model outputs, and
(iii) an instruction prompt for the reasoning task. Using SLR, we create
SLR-Bench, a benchmark comprising over 19k prompts spanning 20 curriculum
levels that progressively increase in relational, arithmetic, and recursive
complexity. Large-scale evaluation reveals that contemporary LLMs readily
produce syntactically valid rules, yet often fail at correct logical inference.
Recent reasoning LLMs do somewhat better, but incur substantial increases in
test-time compute, sometimes exceeding 15k completion tokens. Finally,
logic-tuning via SLR doubles Llama-3-8B accuracy on SLR-Bench, achieving parity
with Gemini-Flash-Thinking at a fraction of computational cost. SLR is fully
automated, requires no human annotation, ensures dataset novelty, and offers a
scalable environment for probing and advancing LLMs' reasoning capabilities.

</details>


### [13] [Deep Reinforcement Learning Xiangqi Player with Monte Carlo Tree Search](https://arxiv.org/abs/2506.15880)
*Berk Yilmaz,Junyu Hu,Jinsong Liu*

Main category: cs.AI

TL;DR: 本文提出了一种用于象棋的深度强化学习系统，结合神经网络与蒙特卡洛树搜索，实现战略自我对弈与自我提升。


<details>
  <summary>Details</summary>
Motivation: 针对象棋的复杂性（如独特棋盘布局、棋子移动限制和胜利条件），探索如何利用DRL-MCTS框架提升AI在文化策略游戏中的能力。

Method: 结合策略-价值网络与MCTS，模拟移动后果并优化决策，解决象棋的高分支因子和非对称棋子动态问题。

Result: 成功开发出能够处理象棋复杂性的AI系统，为领域特定规则系统的DRL-MCTS框架提供借鉴。

Conclusion: 该研究不仅提升了AI在象棋中的表现，还为类似策略游戏的AI开发提供了方法论支持。

Abstract: This paper presents a Deep Reinforcement Learning (DRL) system for Xiangqi
(Chinese Chess) that integrates neural networks with Monte Carlo Tree Search
(MCTS) to enable strategic self-play and self-improvement. Addressing the
underexplored complexity of Xiangqi, including its unique board layout, piece
movement constraints, and victory conditions, our approach combines
policy-value networks with MCTS to simulate move consequences and refine
decision-making. By overcoming challenges such as Xiangqi's high branching
factor and asymmetrical piece dynamics, our work advances AI capabilities in
culturally significant strategy games while providing insights for adapting
DRL-MCTS frameworks to domain-specific rule systems.

</details>


### [14] [Exploring Big Five Personality and AI Capability Effects in LLM-Simulated Negotiation Dialogues](https://arxiv.org/abs/2506.15928)
*Myke C. Cohen,Zhe Su,Hsien-Te Kao,Daniel Nguyen,Spencer Lynch,Maarten Sap,Svitlana Volkova*

Main category: cs.AI

TL;DR: 本文提出了一种评估框架，用于关键任务谈判场景中的自主AI系统，通过实验研究了人格特质和AI特性对谈判结果的影响。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统在多样化人类操作者和利益相关者中适应性的需求，支持高风险的跨团队协调和军民互动应用。

Method: 使用Sotopia模拟平台进行两项实验：实验1通过因果发现方法分析人格特质对价格谈判的影响；实验2评估人类-AI工作谈判中AI透明度和适应性对任务效果的影响。

Result: 实验1发现宜人性和外向性显著影响谈判结果；实验2表明AI可信度对任务有效性至关重要。社会认知词汇分析提供了AI系统优化的具体见解。

Conclusion: 研究为评估AI系统可靠性提供了可重复的方法论，强调了社会动态对复杂任务成功的重要性。

Abstract: This paper presents an evaluation framework for agentic AI systems in
mission-critical negotiation contexts, addressing the need for AI agents that
can adapt to diverse human operators and stakeholders. Using Sotopia as a
simulation testbed, we present two experiments that systematically evaluated
how personality traits and AI agent characteristics influence LLM-simulated
social negotiation outcomes--a capability essential for a variety of
applications involving cross-team coordination and civil-military interactions.
Experiment 1 employs causal discovery methods to measure how personality traits
impact price bargaining negotiations, through which we found that Agreeableness
and Extraversion significantly affect believability, goal achievement, and
knowledge acquisition outcomes. Sociocognitive lexical measures extracted from
team communications detected fine-grained differences in agents' empathic
communication, moral foundations, and opinion patterns, providing actionable
insights for agentic AI systems that must operate reliably in high-stakes
operational scenarios. Experiment 2 evaluates human-AI job negotiations by
manipulating both simulated human personality and AI system characteristics,
specifically transparency, competence, adaptability, demonstrating how AI agent
trustworthiness impact mission effectiveness. These findings establish a
repeatable evaluation methodology for experimenting with AI agent reliability
across diverse operator personalities and human-agent team dynamics, directly
supporting operational requirements for reliable AI systems. Our work advances
the evaluation of agentic AI workflows by moving beyond standard performance
metrics to incorporate social dynamics essential for mission success in complex
operations.

</details>


### [15] [Dual-Objective Reinforcement Learning with Novel Hamilton-Jacobi-Bellman Formulations](https://arxiv.org/abs/2506.16016)
*William Sharpless,Dylan Hirsch,Sander Tonkens,Nikhil Shinde,Sylvia Herbert*

Main category: cs.AI

TL;DR: 论文提出两种新的值函数，用于解决强化学习中的双目标约束问题，并通过改进的PPO算法（DO-HJ-PPO）验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习中的硬约束（如奖励函数或模型架构）会降低策略性能，而拉格朗日方法需要复杂的奖励工程和参数调优。本文旨在通过Hamilton-Jacobi方程与RL的结合，提供更高效的约束决策方法。

Method: 提出两种新的值函数，分别解决Reach-Always-Avoid（达到奖励阈值并避免惩罚阈值）和Reach-Reach（达到两个奖励阈值）问题，并通过分解问题为reach、avoid和reach-avoid子问题，推导出显式的Bellman形式。

Result: DO-HJ-PPO算法在安全到达和多目标达成任务中表现出与以往方法不同的行为，并在多项指标上优于基线方法。

Conclusion: 本文提出的方法为约束决策提供了新视角，并通过实验验证了其有效性。

Abstract: Hard constraints in reinforcement learning (RL), whether imposed via the
reward function or the model architecture, often degrade policy performance.
Lagrangian methods offer a way to blend objectives with constraints, but often
require intricate reward engineering and parameter tuning. In this work, we
extend recent advances that connect Hamilton-Jacobi (HJ) equations with RL to
propose two novel value functions for dual-objective satisfaction. Namely, we
address: (1) the Reach-Always-Avoid problem - of achieving distinct reward and
penalty thresholds - and (2) the Reach-Reach problem - of achieving thresholds
of two distinct rewards. In contrast with temporal logic approaches, which
typically involve representing an automaton, we derive explicit, tractable
Bellman forms in this context by decomposing our problem into reach, avoid, and
reach-avoid problems, as to leverage these aforementioned recent advances. From
a mathematical perspective, the Reach-Always-Avoid and Reach-Reach problems are
complementary and fundamentally different from standard sum-of-rewards problems
and temporal logic problems, providing a new perspective on constrained
decision-making. We leverage our analysis to propose a variation of Proximal
Policy Optimization (DO-HJ-PPO), which solves these problems. Across a range of
tasks for safe-arrival and multi-target achievement, we demonstrate that
DO-HJ-PPO produces qualitatively distinct behaviors from previous approaches
and out-competes a number of baselines in various metrics.

</details>


### [16] [OSWorld-Human: Benchmarking the Efficiency of Computer-Use Agents](https://arxiv.org/abs/2506.16042)
*Reyna Abhyankar,Qi Qi,Yiying Zhang*

Main category: cs.AI

TL;DR: 生成式AI用于解决桌面应用任务，但现有系统因高延迟而难以实用。研究首次分析了计算机代理的时间性能，发现模型调用和任务步骤增加是延迟主因，并构建了人工标注数据集OSWorld-Human，评估显示高效代理仍需更多步骤。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI系统在桌面任务中因高延迟（如数十分钟）而难以实用，需研究延迟原因以指导未来计算机代理开发。

Method: 研究分析了OSWorld基准中计算机代理的时间性能，发现模型调用和任务步骤增加的延迟问题，并构建了人工标注数据集OSWorld-Human进行效率评估。

Result: 大模型调用和任务步骤增加是延迟主因，高效代理在OSWorld-Human上仍需1.4-2.7倍多余步骤。

Conclusion: 未来计算机代理需优化模型调用和任务步骤以减少延迟，提升实用性。

Abstract: Generative AI is being leveraged to solve a variety of computer-use tasks
involving desktop applications. State-of-the-art systems have focused solely on
improving accuracy on leading benchmarks. However, these systems are
practically unusable due to extremely high end-to-end latency (e.g., tens of
minutes) for tasks that typically take humans just a few minutes to complete.
To understand the cause behind this and to guide future developments of
computer agents, we conduct the first study on the temporal performance of
computer-use agents on OSWorld, the flagship benchmark in computer-use AI. We
find that large model calls for planning and reflection account for the
majority of the overall latency, and as an agent uses more steps to complete a
task, each successive step can take 3x longer than steps at the beginning of a
task. We then construct OSWorld-Human, a manually annotated version of the
original OSWorld dataset that contains a human-determined trajectory for each
task. We evaluate 16 agents on their efficiency using OSWorld-Human and found
that even the highest-scoring agents on OSWorld take 1.4-2.7x more steps than
necessary.

</details>


### [17] [Consistency Verification in Ontology-Based Process Models with Parameter Interdependencies](https://arxiv.org/abs/2506.16087)
*Tom Jeleniewski,Hamied Nabizada,Jonathan Reif,Felix Gehlhoff,Alexander Fay*

Main category: cs.AI

TL;DR: 该论文提出了一套验证机制，用于基于本体的过程模型，支持跨上下文应用和知识重用，确保数据检索和解释的正确性。


<details>
  <summary>Details</summary>
Motivation: 制造过程中参数依赖关系的建模需要一致且语义连贯的模型，以确保数据的正确检索和解释。

Method: 采用SPARQL过滤、单位一致性检查和数据完整性检查三种机制，验证基于本体的过程模型。

Result: 通过树脂传递模塑（RTM）的用例验证了方法的适用性，支持机器可解释和可验证的工程模型开发。

Conclusion: 提出的验证机制有效解决了跨上下文应用中的关键挑战，为制造过程的建模提供了可靠支持。

Abstract: The formalization of process knowledge using ontologies enables consistent
modeling of parameter interdependencies in manufacturing. These
interdependencies are typically represented as mathematical expressions that
define relations between process parameters, supporting tasks such as
calculation, validation, and simulation. To support cross-context application
and knowledge reuse, such expressions are often defined in a generic form and
applied across multiple process contexts. This highlights the necessity of a
consistent and semantically coherent model to ensure the correctness of data
retrieval and interpretation. Consequently, dedicated mechanisms are required
to address key challenges such as selecting context-relevant data, ensuring
unit compatibility between variables and data elements, and verifying the
completeness of input data required for evaluating mathematical expressions.
This paper presents a set of verification mechanisms for a previously developed
ontology-based process model that integrates standardized process semantics,
data element definitions, and formal mathematical constructs. The approach
includes (i) SPARQL-based filtering to retrieve process-relevant data, (ii) a
unit consistency check based on expected-unit annotations and semantic
classification, and (iii) a data completeness check to validate the
evaluability of interdependencies. The applicability of the approach is
demonstrated with a use case from Resin Transfer Molding (RTM), supporting the
development of machine-interpretable and verifiable engineering models.

</details>


### [18] [Geometric Learning in Black-Box Optimization: A GNN Framework for Algorithm Performance Prediction](https://arxiv.org/abs/2506.16144)
*Ana Kostovska,Carola Doerr,Sašo Džeroski,Panče Panov,Tome Eftimov*

Main category: cs.AI

TL;DR: 该论文提出了一种基于图数据结构和图神经网络的优化算法性能预测方法，显著优于传统表格方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于问题特征的性能预测方法忽略了算法配置的影响，而算法配置与问题特征和性能之间存在复杂关系，适合用图结构表示。

Method: 使用异构图数据结构和图神经网络，捕捉问题、算法配置和性能之间的复杂依赖关系，并在modCMA-ES和modDE框架上验证。

Result: 在324种modCMA-ES和576种modDE变体上测试，MSE比传统方法提升高达36.6%。

Conclusion: 几何学习在黑盒优化中具有潜力，图神经网络能有效捕捉复杂关系。

Abstract: Automated algorithm performance prediction in numerical blackbox optimization
often relies on problem characterizations, such as exploratory landscape
analysis features. These features are typically used as inputs to machine
learning models and are represented in a tabular format. However, such
approaches often overlook algorithm configurations, a key factor influencing
performance. The relationships between algorithm operators, parameters, problem
characteristics, and performance outcomes form a complex structure best
represented as a graph. This work explores the use of heterogeneous graph data
structures and graph neural networks to predict the performance of optimization
algorithms by capturing the complex dependencies between problems, algorithm
configurations, and performance outcomes. We focus on two modular frameworks,
modCMA-ES and modDE, which decompose two widely used derivative-free
optimization algorithms: the covariance matrix adaptation evolution strategy
(CMA-ES) and differential evolution (DE). We evaluate 324 modCMA-ES and 576
modDE variants on 24 BBOB problems across six runtime budgets and two problem
dimensions. Achieving up to 36.6% improvement in MSE over traditional
tabular-based methods, this work highlights the potential of geometric learning
in black-box optimization.

</details>


### [19] [Large Language Models are Near-Optimal Decision-Makers with a Non-Human Learning Behavior](https://arxiv.org/abs/2506.16163)
*Hao Li,Gengrui Zhang,Petter Holme,Shuyue Hu,Zhen Wang*

Main category: cs.AI

TL;DR: 研究比较了大型语言模型（LLMs）与人类在不确定性、风险和任务转换三个维度的决策行为，发现LLMs表现优于人类，但其决策机制与人类存在根本差异。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在决策学习过程中与人类的差异，以评估其作为人类决策替代品的潜在风险。

Method: 使用三种心理学实验任务，对五种领先的LLMs和360名人类参与者进行决策行为对比。

Result: LLMs在所有任务中表现优于人类，接近最优水平，但其决策机制与人类显著不同。

Conclusion: LLMs在决策能力上具有优势，但其与人类的差异提示需谨慎依赖其作为人类判断的替代品。

Abstract: Human decision-making belongs to the foundation of our society and
civilization, but we are on the verge of a future where much of it will be
delegated to artificial intelligence. The arrival of Large Language Models
(LLMs) has transformed the nature and scope of AI-supported decision-making;
however, the process by which they learn to make decisions, compared to humans,
remains poorly understood. In this study, we examined the decision-making
behavior of five leading LLMs across three core dimensions of real-world
decision-making: uncertainty, risk, and set-shifting. Using three
well-established experimental psychology tasks designed to probe these
dimensions, we benchmarked LLMs against 360 newly recruited human participants.
Across all tasks, LLMs often outperformed humans, approaching near-optimal
performance. Moreover, the processes underlying their decisions diverged
fundamentally from those of humans. On the one hand, our finding demonstrates
the ability of LLMs to manage uncertainty, calibrate risk, and adapt to
changes. On the other hand, this disparity highlights the risks of relying on
them as substitutes for human judgment, calling for further inquiry.

</details>


### [20] [Approximation Fixpoint Theory with Refined Approximation Spaces](https://arxiv.org/abs/2506.16294)
*Linde Vanbesien,Bart Bogaerts,Marc Denecker*

Main category: cs.AI

TL;DR: 本文扩展了近似不动点理论（AFT），通过引入更一般的近似空间概念，克服了其在某些简单例子中的局限性。


<details>
  <summary>Details</summary>
Motivation: AFT在非单调推理形式中广泛应用，但在某些情况下存在局限性，需要更精细的近似方法。

Method: 引入更一般的近似空间概念，研究其表达能力和不同近似空间之间的关系。

Result: 扩展后的AFT能够处理比区间更精细的近似，提升了表达能力。

Conclusion: 通过引入更一般的近似空间，AFT的局限性被克服，为更广泛的应用提供了可能。

Abstract: Approximation Fixpoint Theory (AFT) is a powerful theory covering various
semantics of non-monotonic reasoning formalisms in knowledge representation
such as Logic Programming and Answer Set Programming. Many semantics of such
non-monotonic formalisms can be characterized as suitable fixpoints of a
non-monotonic operator on a suitable lattice. Instead of working on the
original lattice, AFT operates on intervals in such lattice to approximate or
construct the fixpoints of interest. While AFT has been applied successfully
across a broad range of non-monotonic reasoning formalisms, it is confronted by
its limitations in other, relatively simple, examples. In this paper, we
overcome those limitations by extending consistent AFT to deal with
approximations that are more refined than intervals. Therefore, we introduce a
more general notion of approximation spaces, showcase the improved
expressiveness and investigate relations between different approximation
spaces.

</details>


### [21] [Explainable Rule Application via Structured Prompting: A Neural-Symbolic Approach](https://arxiv.org/abs/2506.16335)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 论文提出了一种结构化提示框架，结合神经与符号方法，提升大语言模型在逻辑推理任务中的一致性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在复杂推理任务中表现优异，但在规则应用、异常处理和可解释性方面存在不足，尤其是在需要自然语言理解和精确逻辑推理的领域（如法律分析）。

Method: 通过分解推理为三个可验证步骤（实体识别、属性提取和符号规则应用），并整合神经与符号方法，确保逻辑一致性。

Result: 在LegalBench的传闻判定任务中，该方法显著优于基线模型，如OpenAI o1模型的F1分数从0.714提升至0.929。

Conclusion: 该混合神经符号系统为透明且一致的基于规则的推理提供了可行路径，适用于结构化法律推理任务中的可解释AI应用。

Abstract: Large Language Models (LLMs) excel in complex reasoning tasks but struggle
with consistent rule application, exception handling, and explainability,
particularly in domains like legal analysis that require both natural language
understanding and precise logical inference. This paper introduces a structured
prompting framework that decomposes reasoning into three verifiable steps:
entity identification, property extraction, and symbolic rule application. By
integrating neural and symbolic approaches, our method leverages LLMs'
interpretive flexibility while ensuring logical consistency through formal
verification. The framework externalizes task definitions, enabling domain
experts to refine logical structures without altering the architecture.
Evaluated on the LegalBench hearsay determination task, our approach
significantly outperformed baselines, with OpenAI o-family models showing
substantial improvements - o1 achieving an F1 score of 0.929 and o3-mini
reaching 0.867 using structured decomposition with complementary predicates,
compared to their few-shot baselines of 0.714 and 0.74 respectively. This
hybrid neural-symbolic system offers a promising pathway for transparent and
consistent rule-based reasoning, suggesting potential for explainable AI
applications in structured legal reasoning tasks.

</details>


### [22] [IS-Bench: Evaluating Interactive Safety of VLM-Driven Embodied Agents in Daily Household Tasks](https://arxiv.org/abs/2506.16402)
*Xiaoya Lu,Zeren Chen,Xuhao Hu,Yijin Zhou,Weichen Zhang,Dongrui Liu,Lu Sheng,Jing Shao*

Main category: cs.AI

TL;DR: 论文提出IS-Bench，首个多模态交互安全基准，用于评估VLM驱动的具身代理在动态环境中的安全能力，发现现有代理缺乏交互安全意识。


<details>
  <summary>Details</summary>
Motivation: 现有静态评估范式无法模拟动态风险，导致具身代理在真实家庭任务中存在安全隐患。

Method: 提出IS-Bench基准，包含161个场景和388个安全风险，支持过程导向评估。

Result: 实验显示当前代理缺乏交互安全意识，安全感知的Chain-of-Thought虽能提升性能，但可能影响任务完成。

Conclusion: IS-Bench为开发更安全的具身AI系统奠定了基础。

Abstract: Flawed planning from VLM-driven embodied agents poses significant safety
hazards, hindering their deployment in real-world household tasks. However,
existing static, non-interactive evaluation paradigms fail to adequately assess
risks within these interactive environments, since they cannot simulate dynamic
risks that emerge from an agent's actions and rely on unreliable post-hoc
evaluations that ignore unsafe intermediate steps. To bridge this critical gap,
we propose evaluating an agent's interactive safety: its ability to perceive
emergent risks and execute mitigation steps in the correct procedural order. We
thus present IS-Bench, the first multi-modal benchmark designed for interactive
safety, featuring 161 challenging scenarios with 388 unique safety risks
instantiated in a high-fidelity simulator. Crucially, it facilitates a novel
process-oriented evaluation that verifies whether risk mitigation actions are
performed before/after specific risk-prone steps. Extensive experiments on
leading VLMs, including the GPT-4o and Gemini-2.5 series, reveal that current
agents lack interactive safety awareness, and that while safety-aware
Chain-of-Thought can improve performance, it often compromises task completion.
By highlighting these critical limitations, IS-Bench provides a foundation for
developing safer and more reliable embodied AI systems.

</details>


### [23] [Agentic Personalisation of Cross-Channel Marketing Experiences](https://arxiv.org/abs/2506.16429)
*Sami Abboud,Eleanor Hanna,Olivier Jeunen,Vineesha Raheja,Schaun Wheeler*

Main category: cs.AI

TL;DR: 论文提出了一种基于序列决策框架的自动化通信编排方法，取代传统人工营销，通过差分设计和Thompson采样优化用户参与度。


<details>
  <summary>Details</summary>
Motivation: 传统通信编排依赖人工，难以实现个性化内容、时机和频率的优化。

Method: 采用差分设计估计个体处理效应，结合Thompson采样平衡探索与利用，优化模块化决策策略。

Result: 在多服务应用中显著提升目标事件参与度，已部署至1.5亿用户。

Conclusion: 自动化方法有效提升用户参与，可广泛应用于个性化通信编排。

Abstract: Consumer applications provide ample opportunities to surface and communicate
various forms of content to users. From promotional campaigns for new features
or subscriptions, to evergreen nudges for engagement, or personalised
recommendations; across e-mails, push notifications, and in-app surfaces. The
conventional approach to orchestration for communication relies heavily on
labour-intensive manual marketer work, and inhibits effective personalisation
of content, timing, frequency, and copy-writing. We formulate this task under a
sequential decision-making framework, where we aim to optimise a modular
decision-making policy that maximises incremental engagement for any funnel
event. Our approach leverages a Difference-in-Differences design for Individual
Treatment Effect estimation, and Thompson sampling to balance the
explore-exploit trade-off. We present results from a multi-service application,
where our methodology has resulted in significant increases to a variety of
goal events across several product features, and is currently deployed across
150 million users.

</details>


### [24] [ML-Master: Towards AI-for-AI via Integration of Exploration and Reasoning](https://arxiv.org/abs/2506.16499)
*Zexi Liu,Yuzhu Cai,Xinyu Zhu,Yujie Zheng,Runkun Chen,Ying Wen,Yanfeng Wang,Weinan E,Siheng Chen*

Main category: cs.AI

TL;DR: ML-Master是一种新型AI4AI代理，通过选择性记忆机制整合探索与推理，显著提升AI系统设计效率。


<details>
  <summary>Details</summary>
Motivation: AI驱动的开发可能超越人类水平，但现有LLM代理无法充分利用探索经验，导致效率低下。

Method: 提出ML-Master，采用选择性记忆机制，结合并行解决方案的多样性与分析推理。

Result: 在MLE-Bench上，ML-Master平均奖牌率提升29.3%，且在12小时内完成，优于基线方法。

Conclusion: ML-Master展示了作为AI4AI强大工具的潜力，显著提升性能与效率。

Abstract: As AI capabilities advance toward and potentially beyond human-level
performance, a natural transition emerges where AI-driven development becomes
more efficient than human-centric approaches. A promising pathway toward this
transition lies in AI-for-AI (AI4AI), which leverages AI techniques to automate
and optimize the design, training, and deployment of AI systems themselves.
While LLM-based agents have shown the potential to realize AI4AI, they are
often unable to fully leverage the experience accumulated by agents during the
exploration of solutions in the reasoning process, leading to inefficiencies
and suboptimal performance. To address this limitation, we propose ML-Master, a
novel AI4AI agent that seamlessly integrates exploration and reasoning by
employing a selectively scoped memory mechanism. This approach allows ML-Master
to efficiently combine diverse insights from parallel solution trajectories
with analytical reasoning, guiding further exploration without overwhelming the
agent with excessive context. We evaluate ML-Master on the MLE-Bench, where it
achieves a 29.3% average medal rate, significantly surpassing existing methods,
particularly in medium-complexity tasks, while accomplishing this superior
performance within a strict 12-hour time constraint-half the 24-hour limit used
by previous baselines. These results demonstrate ML-Master's potential as a
powerful tool for advancing AI4AI.

</details>


### [25] [Advancing Harmful Content Detection in Organizational Research: Integrating Large Language Models with Elo Rating System](https://arxiv.org/abs/2506.16575)
*Mustafa Akben,Aaron Satko*

Main category: cs.AI

TL;DR: 本文提出了一种基于Elo评级的改进方法，用于提升大语言模型（LLMs）在有害内容分析中的性能，解决了传统方法在分析有害内容时的局限性。


<details>
  <summary>Details</summary>
Motivation: LLMs的内置审核系统在分析有害内容时（如微侵犯或仇恨言论）常导致结果失效，限制了其在组织研究中的应用。

Method: 采用Elo评级方法优化LLMs在有害内容分析中的表现，并在微侵犯检测和仇恨言论两个数据集上进行验证。

Result: 该方法在准确性、精确度和F1分数上优于传统LLM提示技术和常规机器学习模型，减少了误报并提高了可靠性。

Conclusion: 该方法为组织应用（如职场骚扰检测和有毒沟通评估）提供了更可靠和可扩展的解决方案，有助于营造更安全、包容的工作环境。

Abstract: Large language models (LLMs) offer promising opportunities for organizational
research. However, their built-in moderation systems can create problems when
researchers try to analyze harmful content, often refusing to follow certain
instructions or producing overly cautious responses that undermine validity of
the results. This is particularly problematic when analyzing organizational
conflicts such as microaggressions or hate speech. This paper introduces an Elo
rating-based method that significantly improves LLM performance for harmful
content analysis In two datasets, one focused on microaggression detection and
the other on hate speech, we find that our method outperforms traditional LLM
prompting techniques and conventional machine learning models on key measures
such as accuracy, precision, and F1 scores. Advantages include better
reliability when analyzing harmful content, fewer false positives, and greater
scalability for large-scale datasets. This approach supports organizational
applications, including detecting workplace harassment, assessing toxic
communication, and fostering safer and more inclusive work environments.

</details>


### [26] [A Community-driven vision for a new Knowledge Resource for AI](https://arxiv.org/abs/2506.16596)
*Vinay K Chaudhri,Chaitan Baru,Brandon Bennett,Mehul Bhatt,Darion Cassel,Anthony G Cohn,Rina Dechter,Esra Erdem,Dave Ferrucci,Ken Forbus,Gregory Gelfond,Michael Genesereth,Andrew S. Gordon,Benjamin Grosof,Gopal Gupta,Jim Hendler,Sharat Israni,Tyler R. Josephson,Patrick Kyllonen,Yuliya Lierler,Vladimir Lifschitz,Clifton McFate,Hande K. McGinty,Leora Morgenstern,Alessandro Oltramari,Praveen Paritosh,Dan Roth,Blake Shepard,Cogan Shimzu,Denny Vrandečić,Mark Whiting,Michael Witbrock*

Main category: cs.AI

TL;DR: 论文探讨了AI中通用知识资源的缺失问题，提出了社区驱动的知识基础设施愿景，并建议利用现代技术构建开放工程框架。


<details>
  <summary>Details</summary>
Motivation: AI领域缺乏可验证、通用的知识资源，导致语言模型、机器人规划和虚假信息检测等问题。

Method: 通过AAAI研讨会收集50多位研究者的意见，结合知识表示与推理的现代进展，提出开放工程框架。

Result: 提出了社区驱动的知识基础设施愿景，强调利用知识模块和实际应用结合。

Conclusion: 构建开放框架和社会结构是解决AI知识资源问题的关键方向。

Abstract: The long-standing goal of creating a comprehensive, multi-purpose knowledge
resource, reminiscent of the 1984 Cyc project, still persists in AI. Despite
the success of knowledge resources like WordNet, ConceptNet, Wolfram|Alpha and
other commercial knowledge graphs, verifiable, general-purpose widely available
sources of knowledge remain a critical deficiency in AI infrastructure. Large
language models struggle due to knowledge gaps; robotic planning lacks
necessary world knowledge; and the detection of factually false information
relies heavily on human expertise. What kind of knowledge resource is most
needed in AI today? How can modern technology shape its development and
evaluation? A recent AAAI workshop gathered over 50 researchers to explore
these questions. This paper synthesizes our findings and outlines a
community-driven vision for a new knowledge infrastructure. In addition to
leveraging contemporary advances in knowledge representation and reasoning, one
promising idea is to build an open engineering framework to exploit knowledge
modules effectively within the context of practical applications. Such a
framework should include sets of conventions and social structures that are
adopted by contributors.

</details>


### [27] [The Role of Explanation Styles and Perceived Accuracy on Decision Making in Predictive Process Monitoring](https://arxiv.org/abs/2506.16617)
*Soobin Chae,Suhwan Lee,Hanna Hauptmann,Hajo A. Reijers,Xixi Lu*

Main category: cs.AI

TL;DR: 研究探讨了预测过程监控（PPM）中解释性AI（XAI）的不同解释风格和感知AI准确性对决策的影响，发现两者均显著影响用户决策。


<details>
  <summary>Details</summary>
Motivation: 当前PPM中的深度学习模型虽准确但缺乏可解释性，影响用户信任；XAI的评估多关注功能指标，忽视了用户中心的决策影响。

Method: 通过决策实验，比较不同解释风格（特征重要性、基于规则、反事实）和感知准确性（高或低）对用户决策的影响。

Result: 感知准确性和解释风格对任务表现、一致性和决策信心有显著影响。

Conclusion: 研究强调了在PPM中结合用户中心指标评估XAI的重要性，为提升用户信任和决策效果提供依据。

Abstract: Predictive Process Monitoring (PPM) often uses deep learning models to
predict the future behavior of ongoing processes, such as predicting process
outcomes. While these models achieve high accuracy, their lack of
interpretability undermines user trust and adoption. Explainable AI (XAI) aims
to address this challenge by providing the reasoning behind the predictions.
However, current evaluations of XAI in PPM focus primarily on functional
metrics (such as fidelity), overlooking user-centered aspects such as their
effect on task performance and decision-making. This study investigates the
effects of explanation styles (feature importance, rule-based, and
counterfactual) and perceived AI accuracy (low or high) on decision-making in
PPM. We conducted a decision-making experiment, where users were presented with
the AI predictions, perceived accuracy levels, and explanations of different
styles. Users' decisions were measured both before and after receiving
explanations, allowing the assessment of objective metrics (Task Performance
and Agreement) and subjective metrics (Decision Confidence). Our findings show
that perceived accuracy and explanation style have a significant effect.

</details>


### [28] [Interpretable Low-Dimensional Modeling of Spatiotemporal Agent States for Decision Making in Football Tactics](https://arxiv.org/abs/2506.16696)
*Kenjiro Ide,Taiga Someya,Kohei Kawaguchi,Keisuke Fujii*

Main category: cs.AI

TL;DR: 研究探索了低维、基于规则的模型是否能有效捕捉足球战术，通过可解释的状态变量和实际数据训练模型，发现球员与球的距离及空间评分是关键因素。


<details>
  <summary>Details</summary>
Motivation: 现有模型计算成本高或缺乏可解释性，且未全面考虑球员状态，需一种更高效且直观的方法来分析足球战术。

Method: 定义了球持有者和潜在接球者的可解释状态变量，结合专家知识，使用XGBoost模型预测传球成功率。

Result: 球员与球的距离及空间评分是决定传球成功的关键因素。

Conclusion: 低维模型通过直观变量支持战术分析，为足球决策提供实用工具。

Abstract: Understanding football tactics is crucial for managers and analysts. Previous
research has proposed models based on spatial and kinematic equations, but
these are computationally expensive. Also, Reinforcement learning approaches
use player positions and velocities but lack interpretability and require large
datasets. Rule-based models align with expert knowledge but have not fully
considered all players' states. This study explores whether low-dimensional,
rule-based models using spatiotemporal data can effectively capture football
tactics. Our approach defines interpretable state variables for both the
ball-holder and potential pass receivers, based on criteria that explore
options like passing. Through discussions with a manager, we identified key
variables representing the game state. We then used StatsBomb event data and
SkillCorner tracking data from the 2023$/$24 LaLiga season to train an XGBoost
model to predict pass success. The analysis revealed that the distance between
the player and the ball, as well as the player's space score, were key factors
in determining successful passes. Our interpretable low-dimensional modeling
facilitates tactical analysis through the use of intuitive variables and
provides practical value as a tool to support decision-making in football.

</details>


### [29] [Reinforcement learning for hybrid charging stations planning and operation considering fixed and mobile chargers](https://arxiv.org/abs/2506.16764)
*Yanchen Zhu,Honghui Zou,Chufan Liu,Yuyu Luo,Yuankai Wu,Yuxuan Liang*

Main category: cs.AI

TL;DR: 该论文提出了一种混合充电基础设施优化方法（HCSPO），结合固定和移动充电桩，通过深度强化学习和启发式调度技术提升充电效率。


<details>
  <summary>Details</summary>
Motivation: 传统固定充电站因需求动态变化导致利用率不均，移动充电桩提供灵活性，需优化两者结合以提升充电基础设施效率。

Method: 引入HCSPO问题，结合固定充电站规划和移动充电桩动态调度，采用基于MPC的需求预测和深度强化学习方法。

Result: 案例研究表明，该方法显著提升充电基础设施可用性并减少用户不便。

Conclusion: 混合充电基础设施优化方法有效解决了动态需求下的充电问题，优于现有方案。

Abstract: The success of vehicle electrification, which brings significant societal and
environmental benefits, is contingent upon the availability of efficient and
adaptable charging infrastructure. Traditional fixed-location charging stations
often face issues like underutilization or congestion due to the dynamic nature
of charging demand. Mobile chargers have emerged as a flexible solution,
capable of relocating to align with these demand fluctuations. This paper
addresses the optimal planning and operation of hybrid charging
infrastructures, integrating both fixed and mobile chargers within urban road
networks. We introduce the Hybrid Charging Station Planning and Operation
(HCSPO) problem, which simultaneously optimizes the location and configuration
of fixed charging stations and schedules mobile chargers for dynamic
operations. Our approach incorporates a charging demand prediction model
grounded in Model Predictive Control (MPC) to enhance decision-making. To solve
the HCSPO problem, we propose a deep reinforcement learning method, augmented
with heuristic scheduling techniques, to effectively bridge the planning of
fixed chargers with the real-time operation of mobile chargers. Extensive case
studies using real-world urban scenarios demonstrate that our method
significantly improves the availability of charging infrastructure and reduces
user inconvenience compared to existing solutions and baselines.

</details>


### [30] [AI's Blind Spots: Geographic Knowledge and Diversity Deficit in Generated Urban Scenario](https://arxiv.org/abs/2506.16898)
*Ciro Beneduce,Massimiliano Luca,Bruno Lepri*

Main category: cs.AI

TL;DR: 研究分析了图像生成模型在美国地理知识中的表现及偏见，发现模型倾向于大城市，忽视农村和小城市，且存在地名歧义问题。


<details>
  <summary>Details</summary>
Motivation: 探索图像生成模型在地理知识中的表现及其潜在的偏见，填补相关文献的空白。

Method: 使用FLUX 1和Stable Diffusion 3.5生成美国各州及首都的合成图像，通过DINO-v2 ViT-S/14和Fréchet Inception Distances测量图像相似性。

Result: 模型隐含学习了美国地理知识，但对“美国”的提示生成图像时偏向大城市，忽视农村和小城市，且存在欧洲地名歧义问题。

Conclusion: 图像生成模型在地理知识中存在偏见和歧义问题，需进一步优化以减少偏差。

Abstract: Image generation models are revolutionizing many domains, and urban analysis
and design is no exception. While such models are widely adopted, there is a
limited literature exploring their geographic knowledge, along with the biases
they embed. In this work, we generated 150 synthetic images for each state in
the USA and related capitals using FLUX 1 and Stable Diffusion 3.5, two
state-of-the-art models for image generation. We embed each image using DINO-v2
ViT-S/14 and the Fr\'echet Inception Distances to measure the similarity
between the generated images. We found that while these models have implicitly
learned aspects of USA geography, if we prompt the models to generate an image
for "United States" instead of specific cities or states, the models exhibit a
strong representative bias toward metropolis-like areas, excluding rural states
and smaller cities. {\color{black} In addition, we found that models
systematically exhibit some entity-disambiguation issues with European-sounding
names like Frankfort or Devon.

</details>


### [31] [Real-Time Black-Box Optimization for Dynamic Discrete Environments Using Embedded Ising Machines](https://arxiv.org/abs/2506.16924)
*Tomoya Kashimata,Yohei Hamakawa,Masaya Yamasaki,Kosuke Tatsumura*

Main category: cs.AI

TL;DR: 提出了一种启发式多臂老虎机方法，用于动态离散环境中的优化，通过扩展黑盒优化方法，利用伊辛机有效探索动作。


<details>
  <summary>Details</summary>
Motivation: 动态离散环境中的优化问题，传统多臂老虎机算法因组合爆炸无法有效解决。

Method: 扩展黑盒优化方法，利用伊辛机探索动作，同时考虑变量间交互和动态环境变化。

Result: 在移动用户的无线通信系统中验证了方法的动态适应性。

Conclusion: 该方法在动态离散环境中表现出良好的优化能力。

Abstract: Many real-time systems require the optimization of discrete variables.
Black-box optimization (BBO) algorithms and multi-armed bandit (MAB) algorithms
perform optimization by repeatedly taking actions and observing the
corresponding instant rewards without any prior knowledge. Recently, a BBO
method using an Ising machine has been proposed to find the best action that is
represented by a combination of discrete values and maximizes the instant
reward in static environments. In contrast, dynamic environments, where
real-time systems operate, necessitate MAB algorithms that maximize the average
reward over multiple trials. However, due to the enormous number of actions
resulting from the combinatorial nature of discrete optimization, conventional
MAB algorithms cannot effectively optimize dynamic, discrete environments.
Here, we show a heuristic MAB method for dynamic, discrete environments by
extending the BBO method, in which an Ising machine effectively explores the
actions while considering interactions between variables and changes in dynamic
environments. We demonstrate the dynamic adaptability of the proposed method in
a wireless communication system with moving users.

</details>


### [32] [Multimodal Fused Learning for Solving the Generalized Traveling Salesman Problem in Robotic Task Planning](https://arxiv.org/abs/2506.16931)
*Jiaqi Chen,Mingfeng Fan,Xuefeng Zhang,Jingsong Liang,Yuhong Cao,Guohua Wu,Guillaume Adrien Sartoretti*

Main category: cs.AI

TL;DR: 论文提出了一种多模态融合学习（MMFL）框架，用于解决广义旅行商问题（GTSP），结合图与图像表示生成高效任务规划方案。


<details>
  <summary>Details</summary>
Motivation: 移动机器人任务规划（如仓库检索和环境监测）需高效解决GTSP问题，现有方法在准确性和效率上仍有不足。

Method: MMFL框架通过坐标图像构建器、自适应分辨率缩放策略和多模态融合模块，整合几何与空间特征。

Result: 实验表明MMFL在多种GTSP实例中优于现有方法，且计算效率满足实时需求，物理机器人测试验证了其实际效果。

Conclusion: MMFL框架在GTSP任务规划中表现出色，兼具高效性和实用性。

Abstract: Effective and efficient task planning is essential for mobile robots,
especially in applications like warehouse retrieval and environmental
monitoring. These tasks often involve selecting one location from each of
several target clusters, forming a Generalized Traveling Salesman Problem
(GTSP) that remains challenging to solve both accurately and efficiently. To
address this, we propose a Multimodal Fused Learning (MMFL) framework that
leverages both graph and image-based representations to capture complementary
aspects of the problem, and learns a policy capable of generating high-quality
task planning schemes in real time. Specifically, we first introduce a
coordinate-based image builder that transforms GTSP instances into spatially
informative representations. We then design an adaptive resolution scaling
strategy to enhance adaptability across different problem scales, and develop a
multimodal fusion module with dedicated bottlenecks that enables effective
integration of geometric and spatial features. Extensive experiments show that
our MMFL approach significantly outperforms state-of-the-art methods across
various GTSP instances while maintaining the computational efficiency required
for real-time robotic applications. Physical robot tests further validate its
practical effectiveness in real-world scenarios.

</details>


### [33] [Elevating Styled Mahjong Agents with Learning from Demonstration](https://arxiv.org/abs/2506.16995)
*Lingfeng Li,Yunlong Lu,Yongyi Wang,Wenxin Li*

Main category: cs.AI

TL;DR: 本文提出了一种新的从示范中学习（LfD）算法，用于提升麻将游戏中AI代理的熟练度和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有离线学习和LfD算法在麻将游戏的高随机性和分布外状态下表现不佳，需要改进。

Method: 利用现有麻将代理的游戏历史，提出了一种仅需对PPO算法进行最小修改的新LfD算法。

Result: 实验结果表明，该方法显著提升了代理的熟练度，并有效保留了其独特的游戏风格。

Conclusion: 该方法为开发高能力且多样化的游戏AI提供了有效途径。

Abstract: A wide variety of bots in games enriches the gameplay experience and enhances
replayability. Recent advancements in game artificial intelligence have
predominantly focused on improving the proficiency of bots. Nevertheless,
developing highly competent bots with a wide range of distinct play styles
remains a relatively under-explored area. We select the Mahjong game
environment as a case study. The high degree of randomness inherent in the
Mahjong game and the prevalence of out-of-distribution states lead to
suboptimal performance of existing offline learning and
Learning-from-Demonstration (LfD) algorithms. In this paper, we leverage the
gameplay histories of existing Mahjong agents and put forward a novel LfD
algorithm that necessitates only minimal modifications to the Proximal Policy
Optimization algorithm. The comprehensive empirical results illustrate that our
proposed method not only significantly enhances the proficiency of the agents
but also effectively preserves their unique play styles.

</details>


### [34] [A Quantile Regression Approach for Remaining Useful Life Estimation with State Space Models](https://arxiv.org/abs/2506.17018)
*Davide Frizzo,Francesco Borsatti,Gian Antonio Susto*

Main category: cs.AI

TL;DR: 本文提出了一种基于状态空间模型（SSM）和同步分位数回归（SQR）的剩余使用寿命（RUL）预测方法，优于传统序列建模技术。


<details>
  <summary>Details</summary>
Motivation: 预测性维护（PdM）在工业4.0和5.0中至关重要，通过准确预测设备剩余使用寿命（RUL）提高效率，优化维护计划并减少意外故障。

Method: 结合状态空间模型（SSM）和同步分位数回归（SQR），实现长期序列建模和多分位数估计。

Result: 在C-MAPSS数据集上的实验表明，SSM模型在准确性和计算效率上优于LSTM、Transformer和Informer等传统方法。

Conclusion: SSM模型在高风险工业应用中具有显著潜力。

Abstract: Predictive Maintenance (PdM) is pivotal in Industry 4.0 and 5.0, proactively
enhancing efficiency through accurate equipment Remaining Useful Life (RUL)
prediction, thus optimizing maintenance scheduling and reducing unexpected
failures and premature interventions. This paper introduces a novel RUL
estimation approach leveraging State Space Models (SSM) for efficient long-term
sequence modeling. To handle model uncertainty, Simoultaneous Quantile
Regression (SQR) is integrated into the SSM, enabling multiple quantile
estimations. The proposed method is benchmarked against traditional sequence
modelling techniques (LSTM, Transformer, Informer) using the C-MAPSS dataset.
Results demonstrate superior accuracy and computational efficiency of SSM
models, underscoring their potential for high-stakes industrial applications.

</details>


### [35] [Dispositions and Roles of Generically Dependent Entities](https://arxiv.org/abs/2506.17085)
*Fabian Neuhaus*

Main category: cs.AI

TL;DR: BFO 2020无法支持通用依赖连续体的功能、倾向和角色（如软件或数据集），本文提出两种解决方法：定义类和修改BFO。


<details>
  <summary>Details</summary>
Motivation: BFO 2020的局限性导致无法充分表示计算机模型的功能或数据集在执行中的角色。

Method: 讨论了BFO 2020的限制，并提出两种解决方法：定义类和修改BFO。

Result: 提出了两种可能的解决方案，以支持通用依赖连续体的功能、倾向和角色。

Conclusion: BFO 2020需要扩展以支持通用依赖连续体的功能、倾向和角色，本文提供了两种可行的途径。

Abstract: BFO 2020 does not support functions, dispositions, and roles of generically
dependent continuants (like software or datasets). In this paper, we argue that
this is a severe limitation, which prevents, for example, the adequate
representation of the functions of computer models or the various roles of
datasets during the execution of these models. We discuss the aspects of BFO
2020 that prevent the representation of realizable entities of generically
dependent continuants. Two approaches to address the issue are presented: (a)
the use of defined classes and (b) a proposal of changes that allow BFO to
support functions, dispositions, and roles of generically dependent
continuants.

</details>


### [36] [Towards Advanced Mathematical Reasoning for LLMs via First-Order Logic Theorem Proving](https://arxiv.org/abs/2506.17104)
*Chuxue Cao,Mengze Li,Juntao Dai,Jinluan Yang,Zijian Zhao,Shengyu Zhang,Weijie Shi,Chengzhong Liu,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: 论文提出DREAM方法，通过多样化策略和错误反馈提升大语言模型（LLMs）在多步一阶逻辑推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂数学推理任务中表现不佳，尤其是在多步一阶逻辑推理中，如Deepseek-Prover-V2-7B在定理证明数据集上的准确率仅为4.2%。

Method: DREAM方法结合了Axiom-Driven Strategy Diversification机制和Sub-Proposition Error Feedback，以增强策略多样性和推理合理性。

Result: DREAM将性能提升了0.6%至6.4%，并提供了包含447个数学定理的Lean 4格式数据集。

Conclusion: DREAM为LLMs在数学推理领域提供了有效的改进方案，尤其在多步一阶逻辑推理任务中表现突出。

Abstract: Large language models (LLMs) have shown promising first-order logic (FOL)
reasoning capabilities with applications in various areas. However, their
effectiveness in complex mathematical reasoning involving multi-step FOL
deductions is still under-researched. While LLMs perform competitively on
established mathematical reasoning benchmarks, they struggle with multi-step
FOL tasks, as demonstrated by Deepseek-Prover-V2-7B's low accuracy (4.2%) on
our proposed theorem proving dataset. This issue arises from the limited
exploration of diverse proof strategies and the potential for early reasoning
mistakes to undermine entire proofs. To address these issues, we propose DREAM,
a self-adaptive solution that enhances the Diversity and REAsonability of LLMs'
generation strategies. DREAM incorporates an Axiom-Driven Strategy
Diversification mechanism to promote varied strategic outcomes and a
Sub-Proposition Error Feedback to help LLMs reflect on and correct their
proofs. Our contributions include pioneering advancements in LLMs' mathematical
reasoning through FOL theorem proving, introducing a novel inference stage
solution that improves performance by 0.6% to 6.4%, and providing a curated
dataset of 447 mathematical theorems in Lean 4 format for evaluation.

</details>


### [37] [Are Bias Evaluation Methods Biased ?](https://arxiv.org/abs/2506.17111)
*Lina Berrayana,Sean Rooney,Luis Garcés-Erice,Ioana Giurgiu*

Main category: cs.AI

TL;DR: 论文研究了大型语言模型安全性评估基准的鲁棒性，发现不同方法导致模型排名差异显著，并提出了使用建议。


<details>
  <summary>Details</summary>
Motivation: 评估基准在可信AI社区中至关重要，但不同方法可能导致不一致的模型排名，需研究其鲁棒性。

Method: 采用多种广泛使用的偏见评估方法，对代表性模型进行排名，并比较排名相似性。

Result: 不同评估方法导致模型排名显著不同。

Conclusion: 建议社区在使用评估基准时注意方法差异，确保结果一致性。

Abstract: The creation of benchmarks to evaluate the safety of Large Language Models is
one of the key activities within the trusted AI community. These benchmarks
allow models to be compared for different aspects of safety such as toxicity,
bias, harmful behavior etc. Independent benchmarks adopt different approaches
with distinct data sets and evaluation methods. We investigate how robust such
benchmarks are by using different approaches to rank a set of representative
models for bias and compare how similar are the overall rankings. We show that
different but widely used bias evaluations methods result in disparate model
rankings. We conclude with recommendations for the community in the usage of
such benchmarks.

</details>


### [38] [Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models](https://arxiv.org/abs/2506.17114)
*Dadi Guo,Jiayu Liu,Zhiyuan Fan,Zhitao He,Haoran Li,Yumeng Wang,Yi R.,Fung*

Main category: cs.AI

TL;DR: 论文提出通过数学证明诊断大型推理模型的隐藏缺陷，并引入RFMDataset评估模型表现，发现10种细粒度错误类型，揭示模型在逻辑推理上的根本局限性。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型在数学问题解决中表现优异，但高准确率掩盖了其推理缺陷，需通过数学证明的严谨性揭示真实问题。

Method: 引入RFMDataset（200个数学证明问题），评估模型表现并分析其错误类型。

Result: 模型在数学证明中表现不佳（正确率<20%），存在10种错误类型，如单步推理缺乏严谨性、幻觉和不完整性。

Conclusion: 模型自我反思不足以解决逻辑困境，需形式化和细粒度的逻辑训练。

Abstract: Large reasoning models (e.g., R1, o3) have demonstrated remarkable
mathematical problem-solving abilities. However, the high reported accuracy of
these advanced models on popular datasets, reliance on purely numerical
evaluation and potential benchmark leakage, often masks their true reasoning
shortcomings. To address this, we propose leveraging the inherent rigor and
methodological complexity of mathematical proofs as a diagnostic tool to expose
these hidden failures. Specifically, we introduce the RFMDataset (Reveal
Failure Modes), a collection of 200 diverse mathematical proof problems, and
thoroughly evaluate advanced models' performance on it. Our in-depth analysis
of their failures uncovers 10 fine-grained error types, which shows fundamental
limitations in current large reasoning models: 1) large reasoning models
grapple profoundly with mathematical proofs, with some generating entirely
correct proofs for less than 20% of problems and failing even on basic ones; 2)
models exhibit a diverse spectrum of reasoning failures, prominently
demonstrating the lack of guarantees for the correctness and rigor of
single-step reasoning; and 3) models show hallucination and incompleteness
during the reasoning process. Our findings reveal that models' self-reflection
is insufficient to resolve the current logical dilemmas, necessitating
formalized and fine-grained logical training.

</details>


### [39] [When Can Model-Free Reinforcement Learning be Enough for Thinking?](https://arxiv.org/abs/2506.17124)
*Josiah P. Hanna,Nicholas E. Corrado*

Main category: cs.AI

TL;DR: 论文探讨了模型无关强化学习（RL）如何通过“思考”行为最大化奖励，提出了“思想MDP”理论模型，并验证了开源LLMs满足产生思考行为的条件。


<details>
  <summary>Details</summary>
Motivation: 研究模型无关RL在何种情况下会通过“思考”行为最大化奖励，以建立领域无关的理解。

Method: 引入“思想MDP”理论模型，证明策略初始化的重要性，并验证开源LLMs满足条件。

Result: 理论预测得到验证，并提出在语言生成之外的领域学习思考的充分条件。

Conclusion: 模型无关RL可通过“思想MDP”产生思考行为，为更高效的数据利用提供了可能。

Abstract: Recent work on large language models has demonstrated the use of model-free
reinforcement learning (RL) to train reasoning-like capabilities. The emergence
of "thinking" through model-free RL is interesting as thinking actions neither
produce reward nor change the external world state to one where the agent is
more likely to get reward. This paper seeks to build a domain-independent
understanding of when model-free RL will lead to "thinking" as a strategy for
reward maximization. To build this understanding, we first introduce a
theoretical model which we call a \textit{thought Markov decision process}
(MDP). Thought MDPs minimally extend the classical MDP model to include an
abstract notion of thought state and thought action. Using the thought MDP
model, we prove the importance of policy initialization in determining whether
or not thinking emerges and show formally that thought actions are equivalent
to the agent choosing to perform a step of policy improvement before continuing
to act. We then show that open-source LLMs satisfy the conditions that our
theory predicts are necessary for model-free RL to produce thinking-like
behavior. Finally, we hypothesize sufficient conditions that would enable
thinking to be learned outside of language generation and introduce a toy
domain where a combination of multi-task pre-training and designated thought
actions enable more data-efficient RL compared to non-thinking agents.

</details>


### [40] [Chain-of-Trust: A Progressive Trust Evaluation Framework Enabled by Generative AI](https://arxiv.org/abs/2506.17130)
*Botao Zhu,Xianbin Wang,Lei Zhang,Xuemin,Shen*

Main category: cs.AI

TL;DR: 提出了一种名为chain-of-trust的渐进式信任评估框架，通过分阶段任务分解和生成式AI技术，高效评估分布式协作系统中的设备信任度。


<details>
  <summary>Details</summary>
Motivation: 在动态网络环境中，全面收集设备信任属性数据困难，影响任务完成效率。

Method: 将信任评估分为多阶段，每阶段仅收集相关属性数据，利用生成式AI快速分析。

Result: 实验表明该框架在信任评估中具有高准确性。

Conclusion: chain-of-trust框架显著降低了信任评估的复杂性和开销。

Abstract: In collaborative systems with complex tasks relying on distributed resources,
trust evaluation of potential collaborators has emerged as an effective
mechanism for task completion. However, due to the network dynamics and varying
information gathering latencies, it is extremely challenging to observe and
collect all trust attributes of a collaborating device concurrently for a
comprehensive trust assessment. In this paper, a novel progressive trust
evaluation framework, namely chain-of-trust, is proposed to make better use of
misaligned device attribute data. This framework, designed for effective task
completion, divides the trust evaluation process into multiple chained stages
based on task decomposition. At each stage, based on the task completion
process, the framework only gathers the latest device attribute data relevant
to that stage, leading to reduced trust evaluation complexity and overhead. By
leveraging advanced in-context learning, few-shot learning, and reasoning
capabilities, generative AI is then employed to analyze and interpret the
collected data to produce correct evaluation results quickly. Only devices
deemed trustworthy at this stage proceed to the next round of trust evaluation.
The framework ultimately determines devices that remain trustworthy across all
stages. Experimental results demonstrate that the proposed framework achieves
high accuracy in trust evaluation.

</details>


### [41] [The MedPerturb Dataset: What Non-Content Perturbations Reveal About Human and Clinical LLM Decision Making](https://arxiv.org/abs/2506.17163)
*Abinitha Gourabathina,Yuexing Hao,Walter Gerych,Marzyeh Ghassemi*

Main category: cs.AI

TL;DR: MedPerturb数据集用于评估医疗大语言模型（LLMs）在临床输入扰动下的表现，揭示LLMs与人类在性别、语言风格和格式变化上的差异。


<details>
  <summary>Details</summary>
Motivation: 研究医疗LLMs在真实临床环境中的鲁棒性，比较其与人类在面对输入变化时的决策差异。

Method: 通过MedPerturb数据集，对临床案例进行性别、风格和格式的扰动，并对比LLMs与人类专家的反应。

Result: LLMs对性别和风格扰动更敏感，而人类专家对格式变化（如临床摘要）更敏感。

Conclusion: 需要动态评估框架来更全面地比较LLMs与人类临床决策的相似性。

Abstract: Clinical robustness is critical to the safe deployment of medical Large
Language Models (LLMs), but key questions remain about how LLMs and humans may
differ in response to the real-world variability typified by clinical settings.
To address this, we introduce MedPerturb, a dataset designed to systematically
evaluate medical LLMs under controlled perturbations of clinical input.
MedPerturb consists of clinical vignettes spanning a range of pathologies, each
transformed along three axes: (1) gender modifications (e.g., gender-swapping
or gender-removal); (2) style variation (e.g., uncertain phrasing or colloquial
tone); and (3) format changes (e.g., LLM-generated multi-turn conversations or
summaries). With MedPerturb, we release a dataset of 800 clinical contexts
grounded in realistic input variability, outputs from four LLMs, and three
human expert reads per clinical context. We use MedPerturb in two case studies
to reveal how shifts in gender identity cues, language style, or format reflect
diverging treatment selections between humans and LLMs. We find that LLMs are
more sensitive to gender and style perturbations while human annotators are
more sensitive to LLM-generated format perturbations such as clinical
summaries. Our results highlight the need for evaluation frameworks that go
beyond static benchmarks to assess the similarity between human clinician and
LLM decisions under the variability characteristic of clinical settings.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [42] [Veracity: An Open-Source AI Fact-Checking System](https://arxiv.org/abs/2506.15794)
*Taylor Lynn Curtis,Maximilian Puelma Touzel,William Garneau,Manon Gruaz,Mike Pinder,Li Wei Wang,Sukanya Krishna,Luda Cohen,Jean-François Godbout,Reihaneh Rabbany,Kellin Pelrine*

Main category: cs.CL

TL;DR: Veracity是一个开源AI系统，通过结合大型语言模型和网络检索代理，提供透明的事实核查功能，帮助用户识别和解释虚假信息。


<details>
  <summary>Details</summary>
Motivation: 虚假信息的泛滥对社会构成威胁，生成式AI加剧了这一问题。Veracity旨在通过透明和易用的工具提升公众的媒体素养。

Method: 系统利用大型语言模型和网络检索代理分析用户提交的声明，提供基于证据的真实性评估和解释。

Result: Veracity支持多语言、提供真实性评分，并具有交互式界面，能够有效检测虚假信息并解释其推理过程。

Conclusion: Veracity不仅能识别虚假信息，还能通过解释推理过程促进媒体素养，助力构建更知情的社会。

Abstract: The proliferation of misinformation poses a significant threat to society,
exacerbated by the capabilities of generative AI. This demo paper introduces
Veracity, an open-source AI system designed to empower individuals to combat
misinformation through transparent and accessible fact-checking. Veracity
leverages the synergy between Large Language Models (LLMs) and web retrieval
agents to analyze user-submitted claims and provide grounded veracity
assessments with intuitive explanations. Key features include multilingual
support, numerical scoring of claim veracity, and an interactive interface
inspired by familiar messaging applications. This paper will showcase
Veracity's ability to not only detect misinformation but also explain its
reasoning, fostering media literacy and promoting a more informed society.

</details>


### [43] [Rethinking LLM Training through Information Geometry and Quantum Metrics](https://arxiv.org/abs/2506.15830)
*Riccardo Di Sipio*

Main category: cs.CL

TL;DR: 论文探讨了在大语言模型（LLMs）优化中，信息几何如何通过Fisher信息度量提供更原则性的学习方法，并讨论了其对理解训练现象和量子优化的潜在意义。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于高维参数空间中非欧几里得结构的优化问题，以及如何通过几何视角提升对大语言模型训练的理解。

Method: 方法包括利用Fisher信息度量和自然梯度下降，从几何角度分析优化过程。

Result: 结果表明，几何视角有助于解释尖锐最小值、泛化能力和缩放规律等现象。

Conclusion: 结论指出，曲率感知方法深化了对LLM训练的理解，并提出了基于量子度量的优化潜力。

Abstract: Optimization in large language models (LLMs) unfolds over high-dimensional
parameter spaces with non-Euclidean structure. Information geometry frames this
landscape using the Fisher information metric, enabling more principled
learning via natural gradient descent. Though often impractical, this geometric
lens clarifies phenomena such as sharp minima, generalization, and observed
scaling laws. We argue that curvature-aware approaches deepen our understanding
of LLM training. Finally, we speculate on quantum analogies based on the
Fubini-Study metric and Quantum Fisher Information, hinting at efficient
optimization in quantum-enhanced systems.

</details>


### [44] [MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents](https://arxiv.org/abs/2506.15841)
*Zijian Zhou,Ao Qu,Zhaoxuan Wu,Sunghwan Kim,Alok Prakash,Daniela Rus,Jinhua Zhao,Bryan Kian Hsiang Low,Paul Pu Liang*

Main category: cs.CL

TL;DR: MEM1是一个强化学习框架，用于解决语言代理在多轮交互中的内存增长问题，通过恒定内存实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 现有LLM系统依赖全上下文提示，导致内存增长、计算成本增加和推理性能下降。

Method: MEM1通过更新紧凑的内部状态整合记忆和新观察，并丢弃无关信息，同时提出多轮环境构建方法。

Result: MEM1-7B在多项任务中性能提升3.5倍，内存使用减少3.7倍，并能泛化到训练范围之外。

Conclusion: MEM1展示了推理驱动内存整合的潜力，为长时交互代理提供了高效且性能优化的解决方案。

Abstract: Modern language agents must operate over long-horizon, multi-turn
interactions, where they retrieve external information, adapt to observations,
and answer interdependent queries. Yet, most LLM systems rely on full-context
prompting, appending all past turns regardless of their relevance. This leads
to unbounded memory growth, increased computational costs, and degraded
reasoning performance on out-of-distribution input lengths. We introduce MEM1,
an end-to-end reinforcement learning framework that enables agents to operate
with constant memory across long multi-turn tasks. At each turn, MEM1 updates a
compact shared internal state that jointly supports memory consolidation and
reasoning. This state integrates prior memory with new observations from the
environment while strategically discarding irrelevant or redundant information.
To support training in more realistic and compositional settings, we propose a
simple yet effective and scalable approach to constructing multi-turn
environments by composing existing datasets into arbitrarily complex task
sequences. Experiments across three domains, including internal retrieval QA,
open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves
performance by 3.5x while reducing memory usage by 3.7x compared to
Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes
beyond the training horizon. Our results demonstrate the promise of
reasoning-driven memory consolidation as a scalable alternative to existing
solutions for training long-horizon interactive agents, where both efficiency
and performance are optimized.

</details>


### [45] [Finance Language Model Evaluation (FLaME)](https://arxiv.org/abs/2506.15846)
*Glenn Matlin,Mika Okamoto,Huzaifa Pardawala,Yang Yang,Sudheer Chava*

Main category: cs.CL

TL;DR: 该论文提出了首个金融语言模型评估套件FLaME，全面研究了23个基础语言模型在20个金融NLP任务中的表现，并开源了框架软件和数据。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法存在缺陷，导致对语言模型在金融NLP任务中性能的低估，因此需要更全面的评估框架。

Method: 开发了FLaME评估套件，对23个基础语言模型和强化推理语言模型在20个金融NLP任务上进行实证研究。

Result: 展示了语言模型在金融NLP任务中的潜力，并提供了开源框架和数据。

Conclusion: FLaME为金融NLP任务提供了更准确的评估方法，证明了语言模型在该领域的潜力。

Abstract: Language Models (LMs) have demonstrated impressive capabilities with core
Natural Language Processing (NLP) tasks. The effectiveness of LMs for highly
specialized knowledge-intensive tasks in finance remains difficult to assess
due to major gaps in the methodologies of existing evaluation frameworks, which
have caused an erroneous belief in a far lower bound of LMs' performance on
common Finance NLP (FinNLP) tasks. To demonstrate the potential of LMs for
these FinNLP tasks, we present the first holistic benchmarking suite for
Financial Language Model Evaluation (FLaME). We are the first research paper to
comprehensively study LMs against 'reasoning-reinforced' LMs, with an empirical
study of 23 foundation LMs over 20 core NLP tasks in finance. We open-source
our framework software along with all data and results.

</details>


### [46] [Entropy-Driven Pre-Tokenization for Byte-Pair Encoding](https://arxiv.org/abs/2506.15889)
*Yifan Hu,Frank Liang,Dachuan Zhao,Jonathan Geuter,Varshini Reddy,Craig W. Schmidt,Chris Tanner*

Main category: cs.CL

TL;DR: 论文提出两种基于熵的预分词策略，改进BPE在中文等无分隔语言中的分词效果，显著提升了精确率、召回率和F1分数。


<details>
  <summary>Details</summary>
Motivation: BPE在无分隔语言（如中文）中因忽略语言边界而表现不佳，需改进其分词效果。

Method: 提出两种熵引导的预分词策略：一是利用点互信息和左右熵识别连贯字符跨度，二是利用预训练GPT-2模型的预测熵检测边界不确定性。

Result: 在PKU数据集上，两种方法显著提升了分词精确率、召回率和F1分数。

Conclusion: 熵引导的预分词策略不仅更贴合语言单位，还为低资源或多语言环境下的分词质量改进提供了方向。

Abstract: Byte-Pair Encoding (BPE) has become a widely adopted subword tokenization
method in modern language models due to its simplicity and strong empirical
performance across downstream tasks. However, applying BPE to unsegmented
languages such as Chinese presents significant challenges, as its
frequency-driven merge operation is agnostic to linguistic boundaries. To
address this, we propose two entropy-informed pre-tokenization strategies that
guide BPE segmentation using unsupervised information-theoretic cues. The first
approach uses pointwise mutual information and left/right entropy to identify
coherent character spans, while the second leverages predictive entropy derived
from a pretrained GPT-2 model to detect boundary uncertainty. We evaluate both
methods on a subset of the PKU dataset and demonstrate substantial improvements
in segmentation precision, recall, and F1 score compared to standard BPE. Our
results suggest that entropy-guided pre-tokenization not only enhances
alignment with gold-standard linguistic units but also offers a promising
direction for improving tokenization quality in low-resource and multilingual
settings.

</details>


### [47] [Language Models can perform Single-Utterance Self-Correction of Perturbed Reasoning](https://arxiv.org/abs/2506.15894)
*Sam Silver,Jimin Sun,Ivan Zhang,Sara Hooker,Eddie Kim*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）具有内在的自我纠正能力，能够通过单次推理修正错误，这一能力比文献中常见的表现更强。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学推理上表现出色，但其性能对问题描述和提示策略的微小变化仍很脆弱，且易受采样误差影响。研究旨在探索模型的内在自我纠正能力。

Method: 通过实验测量模型对合成扰动的自我纠正能力，观察其在链式推理（CoT）中的表现。

Result: 发现模型在单次推理中表现出稳健的自我纠正行为，包括隐式和显式修正错误。

Conclusion: LLMs的内在自我纠正能力可能比文献中显示的更强，表明近期“推理”模型研究是对已有能力的放大。

Abstract: Large Language Models (LLMs) have demonstrated impressive mathematical
reasoning capabilities, yet their performance remains brittle to minor
variations in problem description and prompting strategy. Furthermore,
reasoning is vulnerable to sampling-induced errors which autoregressive models
must primarily address using self-correction via additionally-generated tokens.
To better understand self-correction capabilities of recent models, we conduct
experiments measuring models' ability to self-correct synthetic perturbations
introduced into their Chain of Thought (CoT) reasoning. We observe robust
single-utterance intrinsic self-correction behavior across a range of
open-weight models and datasets, ranging from subtle, implicit corrections to
explicit acknowledgments and corrections of errors. Our findings suggest that
LLMs, including those not finetuned for long CoT, may possess stronger
intrinsic self-correction capabilities than commonly shown in the literature.
The presence of this ability suggests that recent "reasoning" model work
involves amplification of traits already meaningfully present in models.

</details>


### [48] [From RAG to Agentic: Validating Islamic-Medicine Responses with LLM Agents](https://arxiv.org/abs/2506.15911)
*Mohammad Amaan Sayeed,Mohammed Talha Alam,Raza Imam,Shahab Saquib Sohail,Amir Hussain*

Main category: cs.CL

TL;DR: 论文提出Tibbe-AG评估框架，结合伊斯兰医学文本与检索增强生成技术，提升AI在文化敏感医疗问答中的表现。


<details>
  <summary>Details</summary>
Motivation: 伊斯兰医学文本如《医典》和《先知医学》蕴含丰富预防与整体疗法，但未被现代AI充分利用。现有语言模型评测忽视文化背景，需填补这一空白。

Method: 提出Tibbe-AG框架，结合30个精选问题与人类验证疗法，测试三种LLM（LLaMA-3、Mistral-7B、Qwen2-7B）的三种配置（直接生成、检索增强生成、科学自评过滤），并由次级LLM评分。

Result: 检索提升13%事实准确性，自评提示再提升10%，结合检索与自评能实现可靠且文化敏感的医疗问答。

Conclusion: 结合古典伊斯兰医学文本、检索技术与自评机制，可显著提升AI在文化敏感医疗领域的表现。

Abstract: Centuries-old Islamic medical texts like Avicenna's Canon of Medicine and the
Prophetic Tibb-e-Nabawi encode a wealth of preventive care, nutrition, and
holistic therapies, yet remain inaccessible to many and underutilized in modern
AI systems. Existing language-model benchmarks focus narrowly on factual recall
or user preference, leaving a gap in validating culturally grounded medical
guidance at scale. We propose a unified evaluation pipeline, Tibbe-AG, that
aligns 30 carefully curated Prophetic-medicine questions with human-verified
remedies and compares three LLMs (LLaMA-3, Mistral-7B, Qwen2-7B) under three
configurations: direct generation, retrieval-augmented generation, and a
scientific self-critique filter. Each answer is then assessed by a secondary
LLM serving as an agentic judge, yielding a single 3C3H quality score.
Retrieval improves factual accuracy by 13%, while the agentic prompt adds
another 10% improvement through deeper mechanistic insight and safety
considerations. Our results demonstrate that blending classical Islamic texts
with retrieval and self-evaluation enables reliable, culturally sensitive
medical question-answering.

</details>


### [49] [REIS: A High-Performance and Energy-Efficient Retrieval System with In-Storage Processing](https://arxiv.org/abs/2506.16444)
*Kangqi Chen,Andreas Kosmas Kakolyris,Rakesh Nadig,Manos Frouzakis,Nika Mansouri Ghiasi,Yu Liang,Haiyu Mao,Jisung Park,Mohammad Sadrosadati,Onur Mutlu*

Main category: cs.CL

TL;DR: 论文提出REIS系统，通过优化存储内处理技术（ISP）解决RAG中检索阶段的瓶颈问题，显著提升性能和能效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的知识受限于训练数据，RAG通过外部知识库补充静态知识，但检索阶段成为瓶颈。现有ISP技术存在算法不匹配、未加速数据检索及硬件修改复杂等问题。

Method: REIS系统采用三种机制：1）数据库布局优化，2）ISP定制数据放置技术，3）利用存储系统现有计算资源的ANNS引擎。

Result: 相比服务器级系统，REIS平均提升检索性能13倍，能效55倍。

Conclusion: REIS为RAG量身定制的ISP系统，有效解决了检索阶段的瓶颈问题，具有显著性能和能效优势。

Abstract: Large Language Models (LLMs) face an inherent challenge: their knowledge is
confined to the data that they have been trained on. To overcome this issue,
Retrieval-Augmented Generation (RAG) complements the static training-derived
knowledge of LLMs with an external knowledge repository. RAG consists of three
stages: indexing, retrieval, and generation. The retrieval stage of RAG becomes
a significant bottleneck in inference pipelines. In this stage, a user query is
mapped to an embedding vector and an Approximate Nearest Neighbor Search (ANNS)
algorithm searches for similar vectors in the database to identify relevant
items. Due to the large database sizes, ANNS incurs significant data movement
overheads between the host and the storage system. To alleviate these
overheads, prior works propose In-Storage Processing (ISP) techniques that
accelerate ANNS by performing computations inside storage. However, existing
works that leverage ISP for ANNS (i) employ algorithms that are not tailored to
ISP systems, (ii) do not accelerate data retrieval operations for data selected
by ANNS, and (iii) introduce significant hardware modifications, limiting
performance and hindering their adoption. We propose REIS, the first ISP system
tailored for RAG that addresses these limitations with three key mechanisms.
First, REIS employs a database layout that links database embedding vectors to
their associated documents, enabling efficient retrieval. Second, it enables
efficient ANNS by introducing an ISP-tailored data placement technique that
distributes embeddings across the planes of the storage system and employs a
lightweight Flash Translation Layer. Third, REIS leverages an ANNS engine that
uses the existing computational resources inside the storage system. Compared
to a server-grade system, REIS improves the performance (energy efficiency) of
retrieval by an average of 13x (55x).

</details>


### [50] [Reranking-based Generation for Unbiased Perspective Summarization](https://arxiv.org/abs/2506.15925)
*Narutatsu Ri,Nicholas Deas,Kathleen McKeown*

Main category: cs.CL

TL;DR: 论文提出了一种改进政治观点摘要的方法，通过识别可靠指标和探索LLM方法的有效性，发现基于语言的指标优于传统指标，并通过重排和偏好调优提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架依赖传统指标，未验证其适用性，且改进摘要方法的研究尚不成熟。

Method: 识别可靠指标用于衡量摘要质量，并研究LLM方法的有效性，包括重排和偏好调优。

Result: 基于语言的指标优于传统指标，重排方法和偏好调优显著提升性能。

Conclusion: 研究为观点摘要的可靠评估和方法开发提供了贡献。

Abstract: Generating unbiased summaries in real-world settings such as political
perspective summarization remains a crucial application of Large Language
Models (LLMs). Yet, existing evaluation frameworks rely on traditional metrics
for measuring key attributes such as coverage and faithfulness without
verifying their applicability, and efforts to develop improved summarizers are
still nascent. We address these gaps by (1) identifying reliable metrics for
measuring perspective summary quality, and (2) investigating the efficacy of
LLM-based methods beyond zero-shot inference. Namely, we build a test set for
benchmarking metric reliability using human annotations and show that
traditional metrics underperform compared to language model-based metrics,
which prove to be strong evaluators. Using these metrics, we show that
reranking-based methods yield strong results, and preference tuning with
synthetically generated and reranking-labeled data further boosts performance.
Our findings aim to contribute to the reliable evaluation and development of
perspective summarization methods.

</details>


### [51] [A Vietnamese Dataset for Text Segmentation and Multiple Choices Reading Comprehension](https://arxiv.org/abs/2506.15978)
*Toan Nguyen Hai,Ha Nguyen Viet,Truong Quan Xuan,Duc Do Minh*

Main category: cs.CL

TL;DR: VSMRC是一个针对越南语的文本分割和阅读理解数据集，填补了越南语NLP资源的空白，实验表明多语言模型（如mBERT）在越南语任务中表现优于单语模型。


<details>
  <summary>Details</summary>
Motivation: 越南语作为全球第20大语言，缺乏高质量的NLP资源，尤其是在文本分割和阅读理解任务上。

Method: 数据集来自越南语维基百科，包含15,942份文本分割文档和16,347个人工质量保证的合成多选题对。

Result: mBERT在阅读理解测试集上准确率达88.01%，在文本分割测试集上F1得分为63.15%。

Conclusion: 多语言模型在越南语NLP任务中表现优异，VSMRC为其他资源匮乏语言提供了潜在应用参考。

Abstract: Vietnamese, the 20th most spoken language with over 102 million native
speakers, lacks robust resources for key natural language processing tasks such
as text segmentation and machine reading comprehension (MRC). To address this
gap, we present VSMRC, the Vietnamese Text Segmentation and Multiple-Choice
Reading Comprehension Dataset. Sourced from Vietnamese Wikipedia, our dataset
includes 15,942 documents for text segmentation and 16,347 synthetic
multiple-choice question-answer pairs generated with human quality assurance,
ensuring a reliable and diverse resource. Experiments show that mBERT
consistently outperforms monolingual models on both tasks, achieving an
accuracy of 88.01% on MRC test set and an F1 score of 63.15\% on text
segmentation test set. Our analysis reveals that multilingual models excel in
NLP tasks for Vietnamese, suggesting potential applications to other
under-resourced languages. VSMRC is available at HuggingFace

</details>


### [52] [Double Entendre: Robust Audio-Based AI-Generated Lyrics Detection via Multi-View Fusion](https://arxiv.org/abs/2506.15981)
*Markus Frohmann,Gabriel Meseguer-Brocal,Markus Schedl,Elena V. Epure*

Main category: cs.CL

TL;DR: 论文提出了一种多模态、模块化的晚期融合方法DE-detect，结合音频中的歌词转录和语音特征，有效检测AI生成的音乐，解决了现有检测器的局限性。


<details>
  <summary>Details</summary>
Motivation: AI音乐生成工具的快速发展对音乐行业带来挑战，现有检测器（基于音频或歌词）存在泛化性差和依赖干净歌词的问题。

Method: 提出多模态、模块化的晚期融合管道，结合自动转录的歌词和音频中的语音特征，直接从音频中提取歌词信息。

Result: DE-detect在实验中优于现有基于歌词的检测器，且对音频扰动更鲁棒。

Conclusion: 该方法为实际场景中检测AI生成音乐提供了有效且鲁棒的解决方案。

Abstract: The rapid advancement of AI-based music generation tools is revolutionizing
the music industry but also posing challenges to artists, copyright holders,
and providers alike. This necessitates reliable methods for detecting such
AI-generated content. However, existing detectors, relying on either audio or
lyrics, face key practical limitations: audio-based detectors fail to
generalize to new or unseen generators and are vulnerable to audio
perturbations; lyrics-based methods require cleanly formatted and accurate
lyrics, unavailable in practice. To overcome these limitations, we propose a
novel, practically grounded approach: a multimodal, modular late-fusion
pipeline that combines automatically transcribed sung lyrics and speech
features capturing lyrics-related information within the audio. By relying on
lyrical aspects directly from audio, our method enhances robustness, mitigates
susceptibility to low-level artifacts, and enables practical applicability.
Experiments show that our method, DE-detect, outperforms existing lyrics-based
detectors while also being more robust to audio perturbations. Thus, it offers
an effective, robust solution for detecting AI-generated music in real-world
scenarios. Our code is available at
https://github.com/deezer/robust-AI-lyrics-detection.

</details>


### [53] [From General to Targeted Rewards: Surpassing GPT-4 in Open-Ended Long-Context Generation](https://arxiv.org/abs/2506.16024)
*Zhihan Guo,Jiele Wu,Wenqian Cui,Yifei Zhang,Minda Hu,Yufei Wang,Irwin King*

Main category: cs.CL

TL;DR: 论文提出ProxyReward框架，通过强化学习改进长文本生成任务，无需大量标注数据，性能优于GPT-4-Turbo。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注长上下文理解，开放长文本生成任务（Open-LTG）研究不足，且缺乏高质量参考数据。

Method: 提出ProxyReward框架，包括自动生成数据集和针对性奖励信号计算方法。

Result: 实验显示ProxyReward性能提升20%，优于GPT-4-Turbo和LLM-as-a-Judge方法。

Conclusion: ProxyReward有效提升LLM处理复杂开放问题的能力。

Abstract: Current research on long-form context in Large Language Models (LLMs)
primarily focuses on the understanding of long-contexts, the Open-ended Long
Text Generation (Open-LTG) remains insufficiently explored. Training a
long-context generation model requires curation of gold standard reference
data, which is typically nonexistent for informative Open-LTG tasks. However,
previous methods only utilize general assessments as reward signals, which
limits accuracy. To bridge this gap, we introduce ProxyReward, an innovative
reinforcement learning (RL) based framework, which includes a dataset and a
reward signal computation method. Firstly, ProxyReward Dataset generation is
accomplished through simple prompts that enables the model to create
automatically, obviating extensive labeled data or significant manual effort.
Secondly, ProxyReward Signal offers a targeted evaluation of information
comprehensiveness and accuracy for specific questions. The experimental results
indicate that our method ProxyReward surpasses even GPT-4-Turbo. It can
significantly enhance performance by 20% on the Open-LTG task when training
widely used open-source models, while also surpassing the LLM-as-a-Judge
approach. Our work presents effective methods to enhance the ability of LLMs to
address complex open-ended questions posed by human.

</details>


### [54] [EvoLM: In Search of Lost Language Model Training Dynamics](https://arxiv.org/abs/2506.16029)
*Zhenting Qi,Fan Nie,Alexandre Alahi,James Zou,Himabindu Lakkaraju,Yilun Du,Eric Xing,Sham Kakade,Hanlin Zhang*

Main category: cs.CL

TL;DR: EvoLM是一个模型套件，用于系统分析语言模型在不同训练阶段的动态，包括预训练、持续预训练、监督微调和强化学习。通过训练100多个模型，研究发现过度预训练和后期训练的收益递减，并强调了持续预训练的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代语言模型训练分为多个阶段，下游开发者难以评估每个阶段设计选择的影响。EvoLM旨在提供透明和系统的分析工具。

Method: 训练了100多个1B和4B参数的模型，评估上游（语言建模）和下游（问题解决）能力，包括域内和域外泛化。

Result: 发现过度预训练和后期训练的收益递减，持续预训练对缓解遗忘和连接训练阶段至关重要。

Conclusion: EvoLM为开放研究提供了所有模型、数据集和训练评估流程，促进了透明性和可重复性。

Abstract: Modern language model (LM) training has been divided into multiple stages,
making it difficult for downstream developers to evaluate the impact of design
choices made at each stage. We present EvoLM, a model suite that enables
systematic and transparent analysis of LMs' training dynamics across
pre-training, continued pre-training, supervised fine-tuning, and reinforcement
learning. By training over 100 LMs with 1B and 4B parameters from scratch, we
rigorously evaluate both upstream (language modeling) and downstream
(problem-solving) reasoning capabilities, including considerations of both
in-domain and out-of-domain generalization. Key insights highlight the
diminishing returns from excessive pre-training and post-training, the
importance and practices of mitigating forgetting during domain-specific
continued pre-training, the crucial role of continued pre-training in bridging
pre-training and post-training phases, and various intricate trade-offs when
configuring supervised fine-tuning and reinforcement learning. To facilitate
open research and reproducibility, we release all pre-trained and post-trained
models, training datasets for all stages, and our entire training and
evaluation pipeline.

</details>


### [55] [Enhancing Document-Level Question Answering via Multi-Hop Retrieval-Augmented Generation with LLaMA 3](https://arxiv.org/abs/2506.16037)
*Xinyue Huang,Ziqi Lin,Fang Sun,Wenchao Zhang,Kejian Tong,Yunbo Liu*

Main category: cs.CL

TL;DR: 提出了一种基于LLaMA 3的检索增强生成（RAG）框架，用于复杂问答任务，通过多跳推理和上下文融合提升准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多跳推理和长文档上下文理解中的挑战。

Method: 结合密集检索模块、上下文融合和多跳推理机制，采用检索似然与生成交叉熵联合优化策略。

Result: 实验表明，该系统优于现有检索增强和生成基线，能提供更精确的上下文相关答案。

Conclusion: 该框架在复杂问答任务中表现出色，验证了其有效性和鲁棒性。

Abstract: This paper presents a novel Retrieval-Augmented Generation (RAG) framework
tailored for complex question answering tasks, addressing challenges in
multi-hop reasoning and contextual understanding across lengthy documents.
Built upon LLaMA 3, the framework integrates a dense retrieval module with
advanced context fusion and multi-hop reasoning mechanisms, enabling more
accurate and coherent response generation. A joint optimization strategy
combining retrieval likelihood and generation cross-entropy improves the
model's robustness and adaptability. Experimental results show that the
proposed system outperforms existing retrieval-augmented and generative
baselines, confirming its effectiveness in delivering precise, contextually
grounded answers.

</details>


### [56] [DynScaling: Efficient Verifier-free Inference Scaling via Dynamic and Integrated Sampling](https://arxiv.org/abs/2506.16043)
*Fei Wang,Xingchen Wan,Ruoxi Sun,Jiefeng Chen,Sercan Ö. Arık*

Main category: cs.CL

TL;DR: DynScaling通过集成并行-顺序采样策略和动态预算分配框架，提升大语言模型性能，无需外部验证器。


<details>
  <summary>Details</summary>
Motivation: 解决推理时扩展中依赖外部验证器或未优化实际计算约束的问题。

Method: 提出集成并行-顺序采样策略和基于多臂老虎机的动态预算分配框架。

Result: 实验表明DynScaling在任务性能和计算成本上均优于现有基线。

Conclusion: DynScaling在实用资源约束下有效提升LLM性能。

Abstract: Inference-time scaling has proven effective in boosting large language model
(LLM) performance through increased test-time computation. Yet, its practical
application is often hindered by reliance on external verifiers or a lack of
optimization for realistic computational constraints. We propose DynScaling,
which addresses these limitations through two primary innovations: an
integrated parallel-sequential sampling strategy and a bandit-based dynamic
budget allocation framework. The integrated sampling strategy unifies parallel
and sequential sampling by constructing synthetic sequential reasoning chains
from initially independent parallel responses, promoting diverse and coherent
reasoning trajectories. The dynamic budget allocation framework formulates the
allocation of computational resources as a multi-armed bandit problem,
adaptively distributing the inference budget across queries based on the
uncertainty of previously sampled responses, thereby maximizing computational
efficiency. By combining these components, DynScaling effectively improves LLM
performance under practical resource constraints without the need for external
verifiers. Experimental results demonstrate that DynScaling consistently
surpasses existing verifier-free inference scaling baselines in both task
performance and computational cost.

</details>


### [57] [A Hybrid DeBERTa and Gated Broad Learning System for Cyberbullying Detection in English Text](https://arxiv.org/abs/2506.16052)
*Devesh Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种结合Transformer模型和广度学习系统的混合架构，用于高效检测网络欺凌，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 网络欺凌对青少年影响严重（影响约54.4%的青少年），亟需一种高效且透明的检测方法。

Method: 采用改进的DeBERTa模型（加入Squeeze-and-Excitation模块和情感分析功能）与门控广度学习系统（GBLS）分类器结合，形成协同框架。

Result: 在四个数据集上表现优异：HateXplain（79.3%准确率）、SOSNet（95.41%）、Mendeley-I（91.37%）和Mendeley-II（94.67%）。

Conclusion: 该框架不仅性能优越，还具备可解释性机制，未来需进一步解决隐含偏见和讽刺内容的检测挑战。

Abstract: The proliferation of online communication platforms has created unprecedented
opportunities for global connectivity while simultaneously enabling harmful
behaviors such as cyberbullying, which affects approximately 54.4\% of
teenagers according to recent research. This paper presents a hybrid
architecture that combines the contextual understanding capabilities of
transformer-based models with the pattern recognition strengths of broad
learning systems for effective cyberbullying detection. This approach
integrates a modified DeBERTa model augmented with Squeeze-and-Excitation
blocks and sentiment analysis capabilities with a Gated Broad Learning System
(GBLS) classifier, creating a synergistic framework that outperforms existing
approaches across multiple benchmark datasets. The proposed ModifiedDeBERTa +
GBLS model achieved good performance on four English datasets: 79.3\% accuracy
on HateXplain, 95.41\% accuracy on SOSNet, 91.37\% accuracy on Mendeley-I, and
94.67\% accuracy on Mendeley-II. Beyond performance gains, the framework
incorporates comprehensive explainability mechanisms including token-level
attribution analysis, LIME-based local interpretations, and confidence
calibration, addressing critical transparency requirements in automated content
moderation. Ablation studies confirm the meaningful contribution of each
architectural component, while failure case analysis reveals specific
challenges in detecting implicit bias and sarcastic content, providing valuable
insights for future improvements in cyberbullying detection systems.

</details>


### [58] [Knee-Deep in C-RASP: A Transformer Depth Hierarchy](https://arxiv.org/abs/2506.16055)
*Andy Yang,Michaël Cadilhac,David Chiang*

Main category: cs.CL

TL;DR: 论文通过理论和实证研究证明，更深层的Transformer在表达能力上更强，并通过C-RASP编程语言和时序逻辑验证了这一结论。


<details>
  <summary>Details</summary>
Motivation: 研究动机是明确更深层Transformer的具体能力提升，并通过理论证明和实验验证。

Method: 方法包括：1）将Transformer与C-RASP编程语言等价性证明；2）通过时序逻辑验证深度与表达能力的关系；3）实证研究验证理论预测。

Result: 结果表明，更深层的Transformer在表达能力上更强，且理论预测与实验数据一致。

Conclusion: 结论是深度确实增强了Transformer的表达能力，且理论框架能有效预测其性能。

Abstract: It has been observed that transformers with greater depth (that is, more
layers) have more capabilities, but can we establish formally which
capabilities are gained with greater depth? We answer this question with a
theoretical proof followed by an empirical study. First, we consider
transformers that round to fixed precision except inside attention. We show
that this subclass of transformers is expressively equivalent to the
programming language C-RASP and this equivalence preserves depth. Second, we
prove that deeper C-RASP programs are more expressive than shallower C-RASP
programs, implying that deeper transformers are more expressive than shallower
transformers (within the subclass mentioned above). These results are
established by studying a form of temporal logic with counting operators, which
was shown equivalent to C-RASP in previous work. Finally, we provide empirical
evidence that our theory predicts the depth required for transformers without
positional encodings to length-generalize on a family of sequential dependency
tasks.

</details>


### [59] [Self-Critique-Guided Curiosity Refinement: Enhancing Honesty and Helpfulness in Large Language Models via In-Context Learning](https://arxiv.org/abs/2506.16064)
*Duc Hieu Ho,Chenglin Fan*

Main category: cs.CL

TL;DR: 论文通过评估十种大型语言模型并提出一种新的提示策略（自我批判引导的好奇心细化提示），显著提高了模型输出的诚实性和帮助性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在生成诚实和帮助性输出方面的挑战。

Method: 提出自我批判引导的好奇心细化提示策略，结合自我批判和细化步骤，无需额外训练。

Result: 在HONESET数据集上，所有模型的H²分数提升了1.4%至4.3%，减少了低质量回答，增加了高质量回答。

Conclusion: 结构化自我细化是一种可扩展且无需训练的策略，能有效提升大型语言模型输出的可信度。

Abstract: Large language models (LLMs) have demonstrated robust capabilities across
various natural language tasks. However, producing outputs that are
consistently honest and helpful remains an open challenge. To overcome this
challenge, this paper tackles the problem through two complementary directions.
It conducts a comprehensive benchmark evaluation of ten widely used large
language models, including both proprietary and open-weight models from OpenAI,
Meta, and Google. In parallel, it proposes a novel prompting strategy,
self-critique-guided curiosity refinement prompting. The key idea behind this
strategy is enabling models to self-critique and refine their responses without
additional training. The proposed method extends the curiosity-driven prompting
strategy by incorporating two lightweight in-context steps including
self-critique step and refinement step.
  The experiment results on the HONESET dataset evaluated using the framework
$\mathrm{H}^2$ (honesty and helpfulness), which was executed with GPT-4o as a
judge of honesty and helpfulness, show consistent improvements across all
models. The approach reduces the number of poor-quality responses, increases
high-quality responses, and achieves relative gains in $\mathrm{H}^2$ scores
ranging from 1.4% to 4.3% compared to curiosity-driven prompting across
evaluated models. These results highlight the effectiveness of structured
self-refinement as a scalable and training-free strategy to improve the
trustworthiness of LLMs outputs.

</details>


### [60] [Cyberbullying Detection in Hinglish Text Using MURIL and Explainable AI](https://arxiv.org/abs/2506.16066)
*Devesh Kumar*

Main category: cs.CL

TL;DR: 本文提出了一种基于MURIL架构的Hinglish文本网络欺凌检测框架，解决了现有系统在多语言混合文本上的局限性，并在多个数据集上表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 数字通信平台的增长导致全球网络欺凌事件增加，尤其是Hinglish（印地语-英语混合）文本的检测需求迫切，现有系统对此类多语言混合文本效果不佳。

Method: 使用MURIL架构，结合选择性层冻结、分类头设计和针对混合文本的预处理，提升检测性能，并通过归因分析和跨语言模式识别提供可解释性。

Result: 在六个基准数据集上，MURIL模型优于RoBERTa和IndicBERT，准确率提升1.36至13.07个百分点，最高达94.63%。

Conclusion: 该框架有效提升了Hinglish文本的检测性能，但未来需解决上下文依赖、文化理解和跨语言讽刺检测等挑战。

Abstract: The growth of digital communication platforms has led to increased
cyberbullying incidents worldwide, creating a need for automated detection
systems to protect users. The rise of code-mixed Hindi-English (Hinglish)
communication on digital platforms poses challenges for existing cyberbullying
detection systems, which were designed primarily for monolingual text. This
paper presents a framework for cyberbullying detection in Hinglish text using
the Multilingual Representations for Indian Languages (MURIL) architecture to
address limitations in current approaches. Evaluation across six benchmark
datasets -- Bohra \textit{et al.}, BullyExplain, BullySentemo, Kumar \textit{et
al.}, HASOC 2021, and Mendeley Indo-HateSpeech -- shows that the MURIL-based
approach outperforms existing multilingual models including RoBERTa and
IndicBERT, with improvements of 1.36 to 13.07 percentage points and accuracies
of 86.97\% on Bohra, 84.62\% on BullyExplain, 86.03\% on BullySentemo, 75.41\%
on Kumar datasets, 83.92\% on HASOC 2021, and 94.63\% on Mendeley dataset. The
framework includes explainability features through attribution analysis and
cross-linguistic pattern recognition. Ablation studies show that selective
layer freezing, appropriate classification head design, and specialized
preprocessing for code-mixed content improve detection performance, while
failure analysis identifies challenges including context-dependent
interpretation, cultural understanding, and cross-linguistic sarcasm detection,
providing directions for future research in multilingual cyberbullying
detection.

</details>


### [61] [FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning](https://arxiv.org/abs/2506.16123)
*Natapong Nitarach,Warit Sirichotedumrong,Panop Pitchayarthorn,Pittawat Taveekitworachai,Potsawee Manakul,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: FinCoT是一种结构化的思维链提示方法，通过结合金融领域专家的推理知识，显著提升了语言模型在金融NLP任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 金融NLP中现有的提示方法（如标准提示和非结构化思维链提示）缺乏领域专家的结构化指导，FinCoT旨在填补这一空白。

Method: 研究比较了三种提示方法（标准提示、非结构化思维链提示和结构化思维链提示），并提出了FinCoT，一种基于金融专家知识的结构化提示方法。

Result: FinCoT将准确率从63.2%提升至80.5%，同时减少了生成标记数量，降低了推理成本。

Conclusion: 领域对齐的结构化提示不仅能提升性能，还能生成更易解释且与专家推理一致的思维链。

Abstract: This paper presents FinCoT, a structured chain-of-thought (CoT) prompting
approach that incorporates insights from domain-specific expert financial
reasoning to guide the reasoning traces of large language models. We
investigate that there are three main prompting styles in FinNLP: (1) standard
prompting--zero-shot prompting; (2) unstructured CoT--CoT prompting without an
explicit reasoning structure, such as the use of tags; and (3) structured CoT
prompting--CoT prompting with explicit instructions or examples that define
structured reasoning steps. Previously, FinNLP has primarily focused on prompt
engineering with either standard or unstructured CoT prompting. However,
structured CoT prompting has received limited attention in prior work.
Furthermore, the design of reasoning structures in structured CoT prompting is
often based on heuristics from non-domain experts. In this study, we
investigate each prompting approach in FinNLP. We evaluate the three main
prompting styles and FinCoT on CFA-style questions spanning ten financial
domains. We observe that FinCoT improves performance from 63.2% to 80.5% and
Qwen-2.5-7B-Instruct from 69.7% to 74.2%, while reducing generated tokens
eight-fold compared to structured CoT prompting. Our findings show that
domain-aligned structured prompts not only improve performance and reduce
inference costs but also yield more interpretable and expert-aligned reasoning
traces.

</details>


### [62] [Under the Shadow of Babel: How Language Shapes Reasoning in LLMs](https://arxiv.org/abs/2506.16151)
*Chenxi Wang,Yixuan Zhang,Lang Gao,Zixiang Xu,Zirui Song,Yanbo Wang,Xiuying Chen*

Main category: cs.CL

TL;DR: 论文提出BICAUSE双语数据集，研究大语言模型是否内化了语言结构对推理的影响，发现模型确实表现出语言特定的注意力模式和因果推理偏好。


<details>
  <summary>Details</summary>
Motivation: 探索语言结构是否影响大语言模型的认知和推理模式，验证语言相对性假说在模型中的体现。

Method: 使用BICAUSE双语数据集，分析模型在中文和英文中的注意力分布、因果词序偏好及语义对齐表现。

Result: 模型在中文中更关注原因和句首连接词，英文中分布更均衡；模型会僵化应用语言特定的因果词序；成功推理时，模型表征跨语言语义对齐。

Conclusion: 大语言模型不仅模仿语言表面形式，还内化了语言塑造的推理偏见，首次通过模型内部结构分析验证了这一现象。

Abstract: Language is not only a tool for communication but also a medium for human
cognition and reasoning. If, as linguistic relativity suggests, the structure
of language shapes cognitive patterns, then large language models (LLMs)
trained on human language may also internalize the habitual logical structures
embedded in different languages. To examine this hypothesis, we introduce
BICAUSE, a structured bilingual dataset for causal reasoning, which includes
semantically aligned Chinese and English samples in both forward and reversed
causal forms. Our study reveals three key findings: (1) LLMs exhibit
typologically aligned attention patterns, focusing more on causes and
sentence-initial connectives in Chinese, while showing a more balanced
distribution in English. (2) Models internalize language-specific preferences
for causal word order and often rigidly apply them to atypical inputs, leading
to degraded performance, especially in Chinese. (3) When causal reasoning
succeeds, model representations converge toward semantically aligned
abstractions across languages, indicating a shared understanding beyond surface
form. Overall, these results suggest that LLMs not only mimic surface
linguistic forms but also internalize the reasoning biases shaped by language.
Rooted in cognitive linguistic theory, this phenomenon is for the first time
empirically verified through structural analysis of model internals.

</details>


### [63] [SGIC: A Self-Guided Iterative Calibration Framework for RAG](https://arxiv.org/abs/2506.16172)
*Guanhua Chen,Yutong Yao,Lidia S. Chao,Xuebo Liu,Derek F. Wong*

Main category: cs.CL

TL;DR: 该论文提出了一种名为SGIC的自引导迭代校准框架，通过利用不确定性评分提升大型语言模型（LLM）的校准能力，显著提高了多轮校准的效果。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成（RAG）方法常忽略LLM的校准能力，而该能力能充分利用其上下文推理能力。论文旨在通过提供特定提示来显著提升LLM的校准效果。

Method: 提出SGIC框架，利用不确定性评分评估文档相关性和LLM回答的置信度，并通过迭代重新评分结合先前响应来优化校准。此外，还提出了一种构建迭代自校准训练集的新方法。

Result: SGIC框架显著提升了闭源和开源LLM的性能。

Conclusion: 通过自引导迭代校准和不确定性评分的结合，SGIC框架有效提升了LLM在多轮校准中的表现。

Abstract: Recent research in retrieval-augmented generation (RAG) has concentrated on
retrieving useful information from candidate documents. However, numerous
methodologies frequently neglect the calibration capabilities of large language
models (LLMs), which capitalize on their robust in-context reasoning prowess.
This work illustrates that providing LLMs with specific cues substantially
improves their calibration efficacy, especially in multi-round calibrations. We
present a new SGIC: Self-Guided Iterative Calibration Framework that employs
uncertainty scores as a tool. Initially, this framework calculates uncertainty
scores to determine both the relevance of each document to the query and the
confidence level in the responses produced by the LLMs. Subsequently, it
reevaluates these scores iteratively, amalgamating them with prior responses to
refine calibration. Furthermore, we introduce an innovative approach for
constructing an iterative self-calibration training set, which optimizes LLMs
to efficiently harness uncertainty scores for capturing critical information
and enhancing response accuracy. Our proposed framework significantly improves
performance on both closed-source and open-weight LLMs.

</details>


### [64] [JETHICS: Japanese Ethics Understanding Evaluation Dataset](https://arxiv.org/abs/2506.16187)
*Masashi Takeshita,Rafal Rzepka*

Main category: cs.CL

TL;DR: JETHICS是一个用于评估AI模型伦理理解的日语数据集，包含78K样本，基于英语ETHICS数据集构建。实验显示，当前LLM在伦理理解上仍有较大改进空间。


<details>
  <summary>Details</summary>
Motivation: 构建日语伦理数据集以评估AI模型的伦理理解能力，填补现有研究的空白。

Method: 采用英语ETHICS数据集的构建方法，包含四类伦理理论和常识道德类别。

Result: GPT-4o平均得分约0.7，表现最佳的日语LLM得分约0.5，显示当前模型表现有限。

Conclusion: 现有LLM在伦理理解方面仍需显著改进。

Abstract: In this work, we propose JETHICS, a Japanese dataset for evaluating ethics
understanding of AI models. JETHICS contains 78K examples and is built by
following the construction methods of the existing English ETHICS dataset. It
includes four categories based normative theories and concepts from ethics and
political philosophy; and one representing commonsense morality. Our evaluation
experiments on non-proprietary large language models (LLMs) and on GPT-4o
reveal that even GPT-4o achieves only an average score of about 0.7, while the
best-performing Japanese LLM attains around 0.5, indicating a relatively large
room for improvement in current LLMs.

</details>


### [65] [Web(er) of Hate: A Survey on How Hate Speech Is Typed](https://arxiv.org/abs/2506.16190)
*Luna Wang,Andrew Caines,Alice Hutchings*

Main category: cs.CL

TL;DR: 本文探讨了仇恨言论数据集构建中的方法论选择及其对可靠性的影响，提倡采用反思性方法以提高透明度和严谨性。


<details>
  <summary>Details</summary>
Motivation: 研究仇恨言论数据集构建中的复杂设计决策及其对数据集可靠性的影响。

Method: 通过分析多种数据集的方法论选择，借鉴马克斯·韦伯的“理想类型”概念，提出反思性方法。

Result: 揭示了常见主题和实践，强调了价值判断在数据集构建中的重要性。

Conclusion: 呼吁研究者在数据集构建中承认自身价值判断，以提升透明度和方法论严谨性。

Abstract: The curation of hate speech datasets involves complex design decisions that
balance competing priorities. This paper critically examines these
methodological choices in a diverse range of datasets, highlighting common
themes and practices, and their implications for dataset reliability. Drawing
on Max Weber's notion of ideal types, we argue for a reflexive approach in
dataset creation, urging researchers to acknowledge their own value judgments
during dataset construction, fostering transparency and methodological rigour.

</details>


### [66] [Comparative Analysis of Abstractive Summarization Models for Clinical Radiology Reports](https://arxiv.org/abs/2506.16247)
*Anindita Bhattacharya,Tohida Rehman,Debarshi Kumar Sanyal,Samiran Chattopadhyay*

Main category: cs.CL

TL;DR: 研究探讨了使用先进抽象摘要模型从放射学报告的发现部分生成简洁印象的方法，比较了多种预训练和开源大语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 放射学报告的发现部分通常冗长详细，而印象部分更简洁且包含关键诊断结论，因此需要自动化摘要工具以提高效率。

Method: 使用MIMIC-CXR数据集，比较了T5-base、BART-base、PEGASUS-x-base、ChatGPT-4、LLaMA-3-8B和自定义Pointer Generator Network的性能，采用多种评估指标（如ROUGE、METEOR、BERTScore）。

Result: 研究分析了各模型在医学文本摘要中的表现，识别了其优势和局限性。

Conclusion: 研究结果为医疗专业人员提供了有用的自动化摘要解决方案信息。

Abstract: The findings section of a radiology report is often detailed and lengthy,
whereas the impression section is comparatively more compact and captures key
diagnostic conclusions. This research explores the use of advanced abstractive
summarization models to generate the concise impression from the findings
section of a radiology report. We have used the publicly available MIMIC-CXR
dataset. A comparative analysis is conducted on leading pre-trained and
open-source large language models, including T5-base, BART-base,
PEGASUS-x-base, ChatGPT-4, LLaMA-3-8B, and a custom Pointer Generator Network
with a coverage mechanism. To ensure a thorough assessment, multiple evaluation
metrics are employed, including ROUGE-1, ROUGE-2, ROUGE-L, METEOR, and
BERTScore. By analyzing the performance of these models, this study identifies
their respective strengths and limitations in the summarization of medical
text. The findings of this paper provide helpful information for medical
professionals who need automated summarization solutions in the healthcare
sector.

</details>


### [67] [End-to-End Speech Translation for Low-Resource Languages Using Weakly Labeled Data](https://arxiv.org/abs/2506.16251)
*Aishwarya Pothula,Bhavana Akkiraju,Srihari Bandarupalli,Charan D,Santosh Kesiraju,Anil Kumar Vuppala*

Main category: cs.CL

TL;DR: 论文探讨了利用弱标注数据构建低资源语言对的端到端语音转文本翻译系统，并验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 高质量标注数据的稀缺性限制了低资源语言对的语音转文本翻译系统的发展，因此研究弱标注数据的潜力。

Method: 通过双语文本挖掘构建语音转文本翻译数据集，利用多语言Shrutilipi语料库创建不同质量和数量的训练数据版本。

Result: 结果表明，弱标注数据可用于构建性能接近SONAR和SeamlessM4T等大规模多模态多语言基线的系统。

Conclusion: 弱标注数据是构建低资源语言对语音转文本翻译系统的可行替代方案。

Abstract: The scarcity of high-quality annotated data presents a significant challenge
in developing effective end-to-end speech-to-text translation (ST) systems,
particularly for low-resource languages. This paper explores the hypothesis
that weakly labeled data can be used to build ST models for low-resource
language pairs. We constructed speech-to-text translation datasets with the
help of bitext mining using state-of-the-art sentence encoders. We mined the
multilingual Shrutilipi corpus to build Shrutilipi-anuvaad, a dataset
comprising ST data for language pairs Bengali-Hindi, Malayalam-Hindi,
Odia-Hindi, and Telugu-Hindi. We created multiple versions of training data
with varying degrees of quality and quantity to investigate the effect of
quality versus quantity of weakly labeled data on ST model performance. Results
demonstrate that ST systems can be built using weakly labeled data, with
performance comparable to massive multi-modal multilingual baselines such as
SONAR and SeamlessM4T.

</details>


### [68] [Advancing Automated Speaking Assessment Leveraging Multifaceted Relevance and Grammar Information](https://arxiv.org/abs/2506.16285)
*Hao-Chien Lu,Jhen-Ke Lin,Hong-Yun Lin,Chung-Chun Wang,Berlin Chen*

Main category: cs.CL

TL;DR: 本文提出了一种混合评分模型，通过多方面的相关性模块和细粒度语法错误特征，显著提升了自动口语评估系统的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动口语评估系统在多方面评估中未能充分利用内容相关性，且语法分析较为肤浅。本文旨在解决这些问题。

Method: 引入多方面的相关性模块整合问题、图像内容、范例和口语回答；使用高级语法纠错和详细标注提取细粒度语法错误特征。

Result: 实验表明，这些改进显著提升了内容相关性、语言使用和整体评估性能。

Conclusion: 采用更丰富、更细致的特征集有助于实现更全面的口语评估。

Abstract: Current automated speaking assessment (ASA) systems for use in multi-aspect
evaluations often fail to make full use of content relevance, overlooking image
or exemplar cues, and employ superficial grammar analysis that lacks detailed
error types. This paper ameliorates these deficiencies by introducing two novel
enhancements to construct a hybrid scoring model. First, a multifaceted
relevance module integrates question and the associated image content,
exemplar, and spoken response of an L2 speaker for a comprehensive assessment
of content relevance. Second, fine-grained grammar error features are derived
using advanced grammar error correction (GEC) and detailed annotation to
identify specific error categories. Experiments and ablation studies
demonstrate that these components significantly improve the evaluation of
content relevance, language use, and overall ASA performance, highlighting the
benefits of using richer, more nuanced feature sets for holistic speaking
assessment.

</details>


### [69] [PL-Guard: Benchmarking Language Model Safety for Polish](https://arxiv.org/abs/2506.16322)
*Aleksandra Krasnodębska,Karolina Seweryn,Szymon Łukasik,Wojciech Kusa*

Main category: cs.CL

TL;DR: 论文提出了一种针对波兰语的语言模型安全分类基准数据集，并通过对抗性扰动样本测试模型鲁棒性。实验表明，基于HerBERT的分类器在对抗条件下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有安全评估和审核工具对英语等高资源语言偏向严重，全球多数语言未得到充分研究，因此需要填补波兰语的安全评估空白。

Method: 构建手动标注的波兰语安全分类数据集，生成对抗性扰动样本，并评估不同规模和架构的模型（如Llama-Guard-3-8B、HerBERT分类器和PLLuM）。

Result: 基于HerBERT的分类器在对抗条件下表现最优，尤其在鲁棒性测试中显著优于其他模型。

Conclusion: 研究填补了波兰语安全评估的空白，并证明基于HerBERT的分类器在对抗条件下具有优越性能。

Abstract: Despite increasing efforts to ensure the safety of large language models
(LLMs), most existing safety assessments and moderation tools remain heavily
biased toward English and other high-resource languages, leaving majority of
global languages underexamined. To address this gap, we introduce a manually
annotated benchmark dataset for language model safety classification in Polish.
We also create adversarially perturbed variants of these samples designed to
challenge model robustness. We conduct a series of experiments to evaluate
LLM-based and classifier-based models of varying sizes and architectures.
Specifically, we fine-tune three models: Llama-Guard-3-8B, a HerBERT-based
classifier (a Polish BERT derivative), and PLLuM, a Polish-adapted Llama-8B
model. We train these models using different combinations of annotated data and
evaluate their performance, comparing it against publicly available guard
models. Results demonstrate that the HerBERT-based classifier achieves the
highest overall performance, particularly under adversarial conditions.

</details>


### [70] [Generalizability of Media Frames: Corpus creation and analysis across countries](https://arxiv.org/abs/2506.16337)
*Agnese Daffara,Sourabh Dattawad,Sebastian Padó,Tanise Ceron*

Main category: cs.CL

TL;DR: FrameNews-PT数据集评估了MFC框架在巴西新闻中的适用性，发现其15个框架基本适用，但需微调指南，跨文化使用时需谨慎。


<details>
  <summary>Details</summary>
Motivation: 探讨MFC框架是否适用于其他文化背景的新闻议题，尤其是巴西的政治和经济新闻。

Method: 引入FrameNews-PT数据集，基于MFC框架对巴西葡萄牙语新闻进行多轮标注，并评估模型在跨域数据上的表现。

Result: MFC框架基本适用，但需微调指南；部分框架使用频率低，新议题依赖通用框架。

Conclusion: 跨文化框架使用需谨慎，需考虑文化差异和议题多样性。

Abstract: Frames capture aspects of an issue that are emphasized in a debate by
interlocutors and can help us understand how political language conveys
different perspectives and ultimately shapes people's opinions. The Media Frame
Corpus (MFC) is the most commonly used framework with categories and detailed
guidelines for operationalizing frames. It is, however, focused on a few
salient U.S. news issues, making it unclear how well these frames can capture
news issues in other cultural contexts. To explore this, we introduce
FrameNews-PT, a dataset of Brazilian Portuguese news articles covering
political and economic news and annotate it within the MFC framework. Through
several annotation rounds, we evaluate the extent to which MFC frames
generalize to the Brazilian debate issues. We further evaluate how fine-tuned
and zero-shot models perform on out-of-domain data. Results show that the 15
MFC frames remain broadly applicable with minor revisions of the guidelines.
However, some MFC frames are rarely used, and novel news issues are analyzed
using general 'fall-back' frames. We conclude that cross-cultural frame use
requires careful consideration.

</details>


### [71] [Analyzing the Influence of Knowledge Graph Information on Relation Extraction](https://arxiv.org/abs/2506.16343)
*Cedric Möller,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 研究探讨了知识图谱信息对关系抽取模型性能的影响，发现其显著提升效果，尤其在训练样本不平衡时。


<details>
  <summary>Details</summary>
Motivation: 假设知识图谱中实体的位置能为关系抽取任务提供重要信息。

Method: 结合传统关系抽取方法与图感知的Neural Bellman-Ford网络，测试知识图谱特征在监督和零样本设置下的表现。

Result: 整合知识图谱信息显著提升性能，尤其在训练样本不平衡时效果明显。

Conclusion: 知识图谱信息对关系抽取任务具有重要价值，尤其在数据不平衡场景下表现突出。

Abstract: We examine the impact of incorporating knowledge graph information on the
performance of relation extraction models across a range of datasets. Our
hypothesis is that the positions of entities within a knowledge graph provide
important insights for relation extraction tasks. We conduct experiments on
multiple datasets, each varying in the number of relations, training examples,
and underlying knowledge graphs. Our results demonstrate that integrating
knowledge graph information significantly enhances performance, especially when
dealing with an imbalance in the number of training examples for each relation.
We evaluate the contribution of knowledge graph-based features by combining
established relation extraction methods with graph-aware Neural Bellman-Ford
networks. These features are tested in both supervised and zero-shot settings,
demonstrating consistent performance improvements across various datasets.

</details>


### [72] [DISCIE -- Discriminative Closed Information Extraction](https://arxiv.org/abs/2506.16348)
*Cedric Möller,Ricardo Usbeck*

Main category: cs.CL

TL;DR: 提出了一种新的封闭信息抽取方法，结合类型和实体特定信息，显著提升关系抽取准确性，尤其适用于长尾关系。


<details>
  <summary>Details</summary>
Motivation: 解决大规模封闭信息抽取中实体和关系数量庞大时的准确性和效率问题。

Method: 采用判别式方法，整合类型和实体特定信息，优化关系抽取。

Result: 性能优于当前最先进的端到端生成模型，尤其在长尾关系上表现突出。

Conclusion: 该方法为更准确高效的信息抽取技术提供了新方向。

Abstract: This paper introduces a novel method for closed information extraction. The
method employs a discriminative approach that incorporates type and
entity-specific information to improve relation extraction accuracy,
particularly benefiting long-tail relations. Notably, this method demonstrates
superior performance compared to state-of-the-art end-to-end generative models.
This is especially evident for the problem of large-scale closed information
extraction where we are confronted with millions of entities and hundreds of
relations. Furthermore, we emphasize the efficiency aspect by leveraging
smaller models. In particular, the integration of type-information proves
instrumental in achieving performance levels on par with or surpassing those of
a larger generative model. This advancement holds promise for more accurate and
efficient information extraction techniques.

</details>


### [73] [Can structural correspondences ground real world representational content in Large Language Models?](https://arxiv.org/abs/2506.16370)
*Iwan Williams*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（如GPT-4）是否能表示现实世界内容，并提出了基于结构对应性的解释框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决LLMs是否能够表示现实世界内容的问题，尤其是在其输入、输出和训练数据仅包含文本的情况下。

Method: 采用结构对应性理论分析LLMs的表示能力，并探讨其在任务表现中的作用。

Result: 研究发现，仅存在结构对应性不足以支持LLMs表示现实世界内容，但若能合理利用这些对应性，则可能实现。

Conclusion: 结论是LLMs的文本局限性可能阻碍其完成某些任务，但通过适当利用结构对应性，仍可能实现现实世界内容的表示。

Abstract: Large Language Models (LLMs) such as GPT-4 produce compelling responses to a
wide range of prompts. But their representational capacities are uncertain.
Many LLMs have no direct contact with extra-linguistic reality: their inputs,
outputs and training data consist solely of text, raising the questions (1) can
LLMs represent anything and (2) if so, what? In this paper, I explore what it
would take to answer these questions according to a structural-correspondence
based account of representation, and make an initial survey of this evidence. I
argue that the mere existence of structural correspondences between LLMs and
worldly entities is insufficient to ground representation of those entities.
However, if these structural correspondences play an appropriate role - they
are exploited in a way that explains successful task performance - then they
could ground real world contents. This requires overcoming a challenge: the
text-boundedness of LLMs appears, on the face of it, to prevent them engaging
in the right sorts of tasks.

</details>


### [74] [InstructTTSEval: Benchmarking Complex Natural-Language Instruction Following in Text-to-Speech Systems](https://arxiv.org/abs/2506.16381)
*Kexin Huang,Qian Tu,Liwei Fan,Chenchen Yang,Dong Zhang,Shimin Li,Zhaoye Fei,Qinyuan Cheng,Xipeng Qiu*

Main category: cs.CL

TL;DR: 论文提出InstructTTSEval基准，用于评估语音合成系统对复杂自然语言指令的理解和执行能力，填补了高质量评测工具的空白。


<details>
  <summary>Details</summary>
Motivation: 传统语音合成系统在控制副语言信息（如音色、情感）时灵活性不足，且缺乏专门的高质量评测工具。

Method: 引入InstructTTSEval基准，包含三个任务（声学参数指定、描述性风格指令、角色扮演）和6k测试用例，使用Gemini作为自动评估工具。

Result: 评测显示现有指令驱动的语音合成系统仍有较大改进空间。

Conclusion: InstructTTSEval有望推动更强大、灵活和准确的指令驱动语音合成系统的发展。

Abstract: In modern speech synthesis, paralinguistic information--such as a speaker's
vocal timbre, emotional state, and dynamic prosody--plays a critical role in
conveying nuance beyond mere semantics. Traditional Text-to-Speech (TTS)
systems rely on fixed style labels or inserting a speech prompt to control
these cues, which severely limits flexibility. Recent attempts seek to employ
natural-language instructions to modulate paralinguistic features,
substantially improving the generalization of instruction-driven TTS models.
Although many TTS systems now support customized synthesis via textual
description, their actual ability to interpret and execute complex instructions
remains largely unexplored. In addition, there is still a shortage of
high-quality benchmarks and automated evaluation metrics specifically designed
for instruction-based TTS, which hinders accurate assessment and iterative
optimization of these models. To address these limitations, we introduce
InstructTTSEval, a benchmark for measuring the capability of complex
natural-language style control. We introduce three tasks, namely
Acoustic-Parameter Specification, Descriptive-Style Directive, and Role-Play,
including English and Chinese subsets, each with 1k test cases (6k in total)
paired with reference audio. We leverage Gemini as an automatic judge to assess
their instruction-following abilities. Our evaluation of accessible
instruction-following TTS systems highlights substantial room for further
improvement. We anticipate that InstructTTSEval will drive progress toward more
powerful, flexible, and accurate instruction-following TTS.

</details>


### [75] [Large Language Models in Argument Mining: A Survey](https://arxiv.org/abs/2506.16383)
*Hao Li,Viktor Schlegel,Yizheng Sun,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: 本文综述了大语言模型（LLMs）在论点挖掘（AM）中的最新进展，包括理论基础、数据集、任务分类、技术方法和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 论点挖掘是自然语言处理的重要子领域，而大语言模型的出现为其带来了新的技术突破和应用潜力。本文旨在系统梳理和总结这些进展。

Method: 通过综述的方式，整合了论点挖掘的基础理论、数据集、任务分类（如提示生成、思维链推理等），并分析了当前LLM架构和方法。

Result: 总结了LLM在论点挖掘中的关键技术和挑战（如长上下文推理、可解释性等），并提出了未来研究方向。

Conclusion: 本文为LLM驱动的论点挖掘领域提供了系统性的综述，并为未来研究指明了方向。

Abstract: Argument Mining (AM), a critical subfield of Natural Language Processing
(NLP), focuses on extracting argumentative structures from text. The advent of
Large Language Models (LLMs) has profoundly transformed AM, enabling advanced
in-context learning, prompt-based generation, and robust cross-domain
adaptability. This survey systematically synthesizes recent advancements in
LLM-driven AM. We provide a concise review of foundational theories and
annotation frameworks, alongside a meticulously curated catalog of datasets. A
key contribution is our comprehensive taxonomy of AM subtasks, elucidating how
contemporary LLM techniques -- such as prompting, chain-of-thought reasoning,
and retrieval augmentation -- have reconfigured their execution. We further
detail current LLM architectures and methodologies, critically assess
evaluation practices, and delineate pivotal challenges including long-context
reasoning, interpretability, and annotation bottlenecks. Conclusively, we
highlight emerging trends and propose a forward-looking research agenda for
LLM-based computational argumentation, aiming to strategically guide
researchers in this rapidly evolving domain.

</details>


### [76] [HausaNLP at SemEval-2025 Task 11: Advancing Hausa Text-based Emotion Detection](https://arxiv.org/abs/2506.16388)
*Sani Abdullahi Sani,Salim Abubakar,Falalu Ibrahim Lawan,Abdulhamid Abubakar,Maryam Bala*

Main category: cs.CL

TL;DR: 本文介绍了一种针对低资源非洲语言豪萨语的多标签情感检测方法，通过微调AfriBERTa模型，实现了六种情感分类，验证准确率为74.00%。


<details>
  <summary>Details</summary>
Motivation: 解决豪萨语这一低资源语言的情感检测问题，探索基于Transformer的模型在低资源语言中的有效性。

Method: 数据预处理、分词，并使用Hugging Face Trainer API微调AfriBERTa模型。

Result: 验证准确率为74.00%，F1分数为73.50%。

Conclusion: Transformer模型在低资源语言情感检测中表现有效。

Abstract: This paper presents our approach to multi-label emotion detection in Hausa, a
low-resource African language, as part of SemEval Track A. We fine-tuned
AfriBERTa, a transformer-based model pre-trained on African languages, to
classify Hausa text into six emotions: anger, disgust, fear, joy, sadness, and
surprise. Our methodology involved data preprocessing, tokenization, and model
fine-tuning using the Hugging Face Trainer API. The system achieved a
validation accuracy of 74.00%, with an F1-score of 73.50%, demonstrating the
effectiveness of transformer-based models for emotion detection in low-resource
languages.

</details>


### [77] [RiOT: Efficient Prompt Refinement with Residual Optimization Tree](https://arxiv.org/abs/2506.16389)
*Chenyi Zhou,Zhengyan Shi,Yuan Yao,Lei Liang,Huajun Chen,Qiang Zhang*

Main category: cs.CL

TL;DR: 论文提出了一种名为RiOT的新框架，通过文本梯度和树结构优化提示，解决了现有方法缺乏多样性和语义漂移的问题。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法存在多样性不足和语义漂移问题，限制了探索创新方向和多任务性能。

Method: RiOT框架通过迭代优化提示，生成多样候选，利用困惑度选择最佳提示，并引入文本残差连接以减少语义漂移。

Result: 在五个基准测试中，RiOT优于现有自动优化方法和手动提示。

Conclusion: RiOT通过多样性和语义保留机制，显著提升了提示优化的效果。

Abstract: Recent advancements in large language models (LLMs) have highlighted their
potential across a variety of tasks, but their performance still heavily relies
on the design of effective prompts. Existing methods for automatic prompt
optimization face two challenges: lack of diversity, limiting the exploration
of valuable and innovative directions and semantic drift, where optimizations
for one task can degrade performance in others. To address these issues, we
propose Residual Optimization Tree (RiOT), a novel framework for automatic
prompt optimization. RiOT iteratively refines prompts through text gradients,
generating multiple semantically diverse candidates at each step, and selects
the best prompt using perplexity. Additionally, RiOT incorporates the text
residual connection to mitigate semantic drift by selectively retaining
beneficial content across optimization iterations. A tree structure efficiently
manages the optimization process, ensuring scalability and flexibility.
Extensive experiments across five benchmarks, covering commonsense,
mathematical, logical, temporal, and semantic reasoning, demonstrate that RiOT
outperforms both previous prompt optimization methods and manual prompting.

</details>


### [78] [From LLM-anation to LLM-orchestrator: Coordinating Small Models for Data Labeling](https://arxiv.org/abs/2506.16393)
*Yao Lu,Zhaiyuan Ji,Jiawei Du,Yu Shanqing,Qi Xuan,Tianyi Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种多模型协作标注的新范式AutoAnnotator，解决了LLMs标注成本高和细粒度语义理解准确性低的问题。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在大规模标注中成本高昂及细粒度语义理解任务中准确性不足的问题。

Method: 设计了两层框架：上层元控制器层利用LLMs选择SLMs并验证困难样本，下层任务专家层通过多模型投票进行标注，并通过持续学习策略优化SLMs。

Result: AutoAnnotator在零样本、单样本、CoT和多数投票设置中优于现有开源/API LLMs，成本降低74.15%，准确性提高6.21%。

Conclusion: AutoAnnotator是一种高效且低成本的标注框架，显著提升了标注性能。

Abstract: Although the annotation paradigm based on Large Language Models (LLMs) has
made significant breakthroughs in recent years, its actual deployment still has
two core bottlenecks: first, the cost of calling commercial APIs in large-scale
annotation is very expensive; second, in scenarios that require fine-grained
semantic understanding, such as sentiment classification and toxicity
classification, the annotation accuracy of LLMs is even lower than that of
Small Language Models (SLMs) dedicated to this field. To address these
problems, we propose a new paradigm of multi-model cooperative annotation and
design a fully automatic annotation framework AutoAnnotator based on this.
Specifically, AutoAnnotator consists of two layers. The upper-level
meta-controller layer uses the generation and reasoning capabilities of LLMs to
select SLMs for annotation, automatically generate annotation code and verify
difficult samples; the lower-level task-specialist layer consists of multiple
SLMs that perform annotation through multi-model voting. In addition, we use
the difficult samples obtained by the secondary review of the meta-controller
layer as the reinforcement learning set and fine-tune the SLMs in stages
through a continual learning strategy, thereby improving the generalization of
SLMs. Extensive experiments show that AutoAnnotator outperforms existing
open-source/API LLMs in zero-shot, one-shot, CoT, and majority voting settings.
Notably, AutoAnnotator reduces the annotation cost by 74.15% compared to
directly annotating with GPT-3.5-turbo, while still improving the accuracy by
6.21%. Project page: https://github.com/Zhaiyuan-Ji/AutoAnnotator.

</details>


### [79] [OJBench: A Competition Level Code Benchmark For Large Language Models](https://arxiv.org/abs/2506.16395)
*Zhexu Wang,Yiping Liu,Yejie Wang,Wenyang He,Bofei Gao,Muxi Diao,Yanxu Chen,Kelin Fu,Flood Sung,Zhilin Yang,Tianyu Liu,Weiran Xu*

Main category: cs.CL

TL;DR: OJBench是一个新的代码推理基准测试，用于评估大型语言模型在竞争级别编程问题上的表现，结果显示即使是先进模型也难以应对高难度问题。


<details>
  <summary>Details</summary>
Motivation: 现有代码基准测试无法全面评估大型语言模型在竞争级别代码推理上的能力，因此需要更严格的测试工具。

Method: 引入OJBench，包含232个NOI和ICPC编程竞赛问题，对37种模型进行全面评估。

Result: 即使是先进的推理导向模型（如o4-mini和Gemini-2.5-pro-exp）也难以解决高难度竞赛问题。

Conclusion: 竞争级别的代码推理对模型仍具挑战性，OJBench为评估模型能力提供了更严格的标准。

Abstract: Recent advancements in large language models (LLMs) have demonstrated
significant progress in math and code reasoning capabilities. However, existing
code benchmark are limited in their ability to evaluate the full spectrum of
these capabilities, particularly at the competitive level. To bridge this gap,
we introduce OJBench, a novel and challenging benchmark designed to assess the
competitive-level code reasoning abilities of LLMs. OJBench comprises 232
programming competition problems from NOI and ICPC, providing a more rigorous
test of models' reasoning skills. We conducted a comprehensive evaluation using
OJBench on 37 models, including both closed-source and open-source models,
reasoning-oriented and non-reasoning-oriented models. Our results indicate that
even state-of-the-art reasoning-oriented models, such as o4-mini and
Gemini-2.5-pro-exp, struggle with highly challenging competition-level
problems. This highlights the significant challenges that models face in
competitive-level code reasoning.

</details>


### [80] [NepaliGPT: A Generative Language Model for the Nepali Language](https://arxiv.org/abs/2506.16399)
*Shushanta Pudasaini,Aman Shakya,Siddhartha Shrestha,Sahil Bhatta,Sunil Thapa,Sushmita Palikhe*

Main category: cs.CL

TL;DR: 该研究填补了尼泊尔语生成语言模型的空白，提出了NepaliGPT，并引入了Devanagari Corpus和首个尼泊尔语基准数据集。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏针对尼泊尔语的生成语言模型，影响了包括微调在内的下游任务，因此需要填补这一研究空白。

Method: 研究提出了NepaliGPT，并构建了Devanagari Corpus和包含4,296个问答对的基准数据集。

Result: NepaliGPT在文本生成中表现优异，困惑度为26.32245，ROUGE-1得分为0.2604，因果连贯性为81.25%，因果一致性为85.41%。

Conclusion: NepaliGPT为尼泊尔语NLP领域提供了首个生成语言模型，推动了该语言的下游任务研究。

Abstract: After the release of ChatGPT, Large Language Models (LLMs) have gained huge
popularity in recent days and thousands of variants of LLMs have been released.
However, there is no generative language model for the Nepali language, due to
which other downstream tasks, including fine-tuning, have not been explored
yet. To fill this research gap in the Nepali NLP space, this research proposes
\textit{NepaliGPT}, a generative large language model tailored specifically for
the Nepali language. This research introduces an advanced corpus for the Nepali
language collected from several sources, called the Devanagari Corpus.
Likewise, the research introduces the first NepaliGPT benchmark dataset
comprised of 4,296 question-answer pairs in the Nepali language. The proposed
LLM NepaliGPT achieves the following metrics in text generation: Perplexity of
26.32245, ROUGE-1 score of 0.2604, causal coherence of 81.25\%, and causal
consistency of 85.41\%.

</details>


### [81] [When Does Divide and Conquer Work for Long Context LLM? A Noise Decomposition Framework](https://arxiv.org/abs/2506.16411)
*Zhen Xu,Shang Zhu,Jue Wang,Junlin Wang,Ben Athiwaratkun,Chi Wang,James Zou,Ce Zhang*

Main category: cs.CL

TL;DR: 论文研究了将大语言模型（LLMs）应用于长文本的挑战，提出了一个理论框架，将长上下文任务的失败模式分为三类，并通过实验验证了多代理分块方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在处理长文本时的性能限制，尤其是跨块依赖、模型噪声和聚合噪声等问题。

Method: 提出理论框架分析长上下文任务的失败模式，并通过多代理分块方法（将长序列分块处理）进行实验验证。

Result: 实验证实了理论分析，并发现对于大型输入，分块处理的较弱模型可能优于单次处理的先进模型（如GPT4o）。

Conclusion: 通过精心设计的分块和聚合策略，为LLMs处理长上下文提供了直接有效的途径。

Abstract: We investigate the challenge of applying Large Language Models (LLMs) to long
texts. We propose a theoretical framework that distinguishes the failure modes
of long context tasks into three categories: cross-chunk dependence (task
noise), confusion that grows with context size (model noise), and the imperfect
integration of partial results (aggregator noise). Under this view, we analyze
when it is effective to use multi-agent chunking, i.e., dividing a length
sequence into smaller chunks and aggregating the processed results of each
chunk. Our experiments on tasks such as retrieval, question answering, and
summarization confirm both the theoretical analysis and the conditions that
favor multi-agent chunking. By exploring superlinear model noise growth with
input length, we also explain why, for large inputs, a weaker model configured
with chunk-based processing can surpass a more advanced model like GPT4o
applied in a single shot. Overall, we present a principled understanding
framework and our results highlight a direct pathway to handling long contexts
in LLMs with carefully managed chunking and aggregator strategies.

</details>


### [82] [StoryWriter: A Multi-Agent Framework for Long Story Generation](https://arxiv.org/abs/2506.16445)
*Haotian Xia,Hao Peng,Yunjia Qi,Xiaozhi Wang,Bin Xu,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 论文提出StoryWriter框架，通过多智能体协作解决长故事生成的连贯性和复杂性挑战，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 长故事生成面临连贯性和复杂性挑战，现有大语言模型难以满足需求。

Method: 采用多智能体框架，包括提纲、规划和写作三个模块，分别处理事件、章节规划和动态生成。

Result: 生成高质量长故事数据集（6000篇，平均8000字），并在Llama3.1-8B和GLM4-9B上验证性能优越。

Conclusion: StoryWriter框架有效提升长故事生成质量，为相关领域提供新工具和数据集。

Abstract: Long story generation remains a challenge for existing large language models
(LLMs), primarily due to two main factors: (1) discourse coherence, which
requires plot consistency, logical coherence, and completeness in the long-form
generation, and (2) narrative complexity, which requires an interwoven and
engaging narrative. To address these challenges, we propose StoryWriter, a
multi-agent story generation framework, which consists of three main modules:
(1) outline agent, which generates event-based outlines containing rich event
plots, character, and event-event relationships. (2) planning agent, which
further details events and plans which events should be written in each chapter
to maintain an interwoven and engaging story. (3) writing agent, which
dynamically compresses the story history based on the current event to generate
and reflect new plots, ensuring the coherence of the generated story. We
conduct both human and automated evaluation, and StoryWriter significantly
outperforms existing story generation baselines in both story quality and
length. Furthermore, we use StoryWriter to generate a dataset, which contains
about $6,000$ high-quality long stories, with an average length of $8,000$
words. We train the model Llama3.1-8B and GLM4-9B using supervised fine-tuning
on LongStory and develop StoryWriter_GLM and StoryWriter_GLM, which
demonstrates advanced performance in long story generation.

</details>


### [83] [Towards Generalizable Generic Harmful Speech Datasets for Implicit Hate Speech Detection](https://arxiv.org/abs/2506.16476)
*Saad Almohaimeed,Saleh Almohaimeed,Damla Turgut,Ladislau Bölöni*

Main category: cs.CL

TL;DR: 本文提出了一种检测隐式仇恨言论的方法，通过利用现有有害言论数据集，结合样本识别、重新标注和数据增强技术，显著提升了检测效果。


<details>
  <summary>Details</summary>
Motivation: 隐式仇恨言论对社会媒体平台构成严峻挑战，现有研究多关注显式有害言论，缺乏对隐式仇恨言论的通用检测方法。

Method: 方法包括三个关键步骤：影响力样本识别、重新标注以及利用Llama-3 70B和GPT-4o进行数据增强。

Result: 实验结果显示，该方法在隐式仇恨言论检测上取得了显著提升，F1分数比基线提高了12.9分。

Conclusion: 该研究为隐式仇恨言论检测提供了一种有效的通用方法，并展示了现有数据集的潜力。

Abstract: Implicit hate speech has recently emerged as a critical challenge for social
media platforms. While much of the research has traditionally focused on
harmful speech in general, the need for generalizable techniques to detect
veiled and subtle forms of hate has become increasingly pressing. Based on
lexicon analysis, we hypothesize that implicit hate speech is already present
in publicly available harmful speech datasets but may not have been explicitly
recognized or labeled by annotators. Additionally, crowdsourced datasets are
prone to mislabeling due to the complexity of the task and often influenced by
annotators' subjective interpretations. In this paper, we propose an approach
to address the detection of implicit hate speech and enhance generalizability
across diverse datasets by leveraging existing harmful speech datasets. Our
method comprises three key components: influential sample identification,
reannotation, and augmentation using Llama-3 70B and GPT-4o. Experimental
results demonstrate the effectiveness of our approach in improving implicit
hate detection, achieving a +12.9-point F1 score improvement compared to the
baseline.

</details>


### [84] [Relic: Enhancing Reward Model Generalization for Low-Resource Indic Languages with Few-Shot Examples](https://arxiv.org/abs/2506.16502)
*Soumya Suvra Ghosal,Vaibhav Singh,Akash Ghosh,Soumyabrata Pal,Subhadip Baidya,Sriparna Saha,Dinesh Manocha*

Main category: cs.CL

TL;DR: RELIC是一种新颖的上下文学习框架，用于低资源印度语言的奖励建模，通过从高资源语言中选择上下文示例，显著提高了奖励模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的开源多语言奖励模型主要基于高资源语言的偏好数据，导致对低资源印度语言的奖励信号不可靠，而收集这些语言的大规模高质量偏好数据成本过高。

Method: RELIC通过训练一个检索器，使用成对排序目标从高资源语言中选择最能区分偏好和非偏好响应的上下文示例。

Result: 在三个偏好数据集上的实验表明，RELIC显著提高了低资源印度语言的奖励模型准确性，优于现有的示例选择方法。例如，在Bodo语言上，RELIC的准确性提高了12.81%和10.13%。

Conclusion: RELIC为低资源语言的奖励建模提供了一种高效且实用的解决方案，显著提升了模型性能。

Abstract: Reward models are essential for aligning large language models (LLMs) with
human preferences. However, most open-source multilingual reward models are
primarily trained on preference datasets in high-resource languages, resulting
in unreliable reward signals for low-resource Indic languages. Collecting
large-scale, high-quality preference data for these languages is prohibitively
expensive, making preference-based training approaches impractical. To address
this challenge, we propose RELIC, a novel in-context learning framework for
reward modeling in low-resource Indic languages. RELIC trains a retriever with
a pairwise ranking objective to select in-context examples from auxiliary
high-resource languages that most effectively highlight the distinction between
preferred and less-preferred responses. Extensive experiments on three
preference datasets- PKU-SafeRLHF, WebGPT, and HH-RLHF-using state-of-the-art
open-source reward models demonstrate that RELIC significantly improves reward
model accuracy for low-resource Indic languages, consistently outperforming
existing example selection methods. For example, on Bodo-a low-resource Indic
language-using a LLaMA-3.2-3B reward model, RELIC achieves a 12.81% and 10.13%
improvement in accuracy over zero-shot prompting and state-of-the-art example
selection method, respectively.

</details>


### [85] [Automatic Speech Recognition Biases in Newcastle English: an Error Analysis](https://arxiv.org/abs/2506.16558)
*Dana Serditova,Kevin Tang,Jochen Steffens*

Main category: cs.CL

TL;DR: 研究探讨了自动语音识别（ASR）系统在纽卡斯尔英语方言上的表现，发现其错误与方言特征直接相关，呼吁增加训练数据的方言多样性。


<details>
  <summary>Details</summary>
Motivation: ASR系统因训练数据偏向主流语言而难以处理区域方言，此前研究多关注种族、年龄和性别偏见，区域偏见研究较少。

Method: 采用两阶段分析：手动错误分析识别关键错误类型；案例研究聚焦方言代词“yous”和“wor”的识别。

Result: ASR错误与方言特征直接相关，社会因素影响较小。

Conclusion: 建议增加ASR训练数据的方言多样性，并利用社会语言学分析诊断和解决区域偏见。

Abstract: Automatic Speech Recognition (ASR) systems struggle with regional dialects
due to biased training which favours mainstream varieties. While previous
research has identified racial, age, and gender biases in ASR, regional bias
remains underexamined. This study investigates ASR performance on Newcastle
English, a well-documented regional dialect known to be challenging for ASR. A
two-stage analysis was conducted: first, a manual error analysis on a subsample
identified key phonological, lexical, and morphosyntactic errors behind ASR
misrecognitions; second, a case study focused on the systematic analysis of ASR
recognition of the regional pronouns ``yous'' and ``wor''. Results show that
ASR errors directly correlate with regional dialectal features, while social
factors play a lesser role in ASR mismatches. We advocate for greater dialectal
diversity in ASR training data and highlight the value of sociolinguistic
analysis in diagnosing and addressing regional biases.

</details>


### [86] [Weight Factorization and Centralization for Continual Learning in Speech Recognition](https://arxiv.org/abs/2506.16574)
*Enes Yavuz Ugan,Ngoc-Quan Pham,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出一种基于因子化和中心化的持续学习方法，防止多语言语音识别模型在无排练条件下的灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现代神经网络语音识别模型需要持续吸收新数据而无需重新训练，但在多语言和无排练条件下容易发生灾难性遗忘。

Method: 采用两阶段方法：因子化阶段学习新知识，中心化阶段通过低秩适配器合并知识以防止遗忘。

Result: 实验表明，中心化阶段能有效防止灾难性遗忘，并在多语言代码切换数据集上表现良好。

Conclusion: 该方法通过两阶段学习机制，成功解决了持续学习中的灾难性遗忘问题。

Abstract: Modern neural network based speech recognition models are required to
continually absorb new data without re-training the whole system, especially in
downstream applications using foundation models, having no access to the
original training data. Continually training the models in a rehearsal-free,
multilingual, and language agnostic condition, likely leads to catastrophic
forgetting, when a seemingly insignificant disruption to the weights can
destructively harm the quality of the models. Inspired by the ability of human
brains to learn and consolidate knowledge through the waking-sleeping cycle, we
propose a continual learning approach with two distinct phases: factorization
and centralization, learning and merging knowledge accordingly. Our experiments
on a sequence of varied code-switching datasets showed that the centralization
stage can effectively prevent catastrophic forgetting by accumulating the
knowledge in multiple scattering low-rank adapters.

</details>


### [87] [Streaming Non-Autoregressive Model for Accent Conversion and Pronunciation Improvement](https://arxiv.org/abs/2506.16580)
*Tuan-Nam Nguyen,Ngoc-Quan Pham,Seymanur Akti,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出首个流式口音转换模型，将非母语语音转换为母语口音，同时保留说话者身份和韵律，并改善发音。


<details>
  <summary>Details</summary>
Motivation: 解决现有口音转换模型无法实时流式处理的问题。

Method: 改进现有AC架构，使用Emformer编码器和优化的推理机制，并集成TTS模型生成理想训练数据。

Result: 流式AC模型性能与顶级AC模型相当，且保持稳定延迟。

Conclusion: 首次实现流式口音转换系统。

Abstract: We propose a first streaming accent conversion (AC) model that transforms
non-native speech into a native-like accent while preserving speaker identity,
prosody and improving pronunciation. Our approach enables stream processing by
modifying a previous AC architecture with an Emformer encoder and an optimized
inference mechanism. Additionally, we integrate a native text-to-speech (TTS)
model to generate ideal ground-truth data for efficient training. Our streaming
AC model achieves comparable performance to the top AC models while maintaining
stable latency, making it the first AC system capable of streaming.

</details>


### [88] [Measuring (a Sufficient) World Model in LLMs: A Variance Decomposition Framework](https://arxiv.org/abs/2506.16584)
*Nadav Kunievsky,James A. Evans*

Main category: cs.CL

TL;DR: 论文提出了一种评估大语言模型（LLM）是否具备稳健世界模型的框架，通过分析模型输出的变异性来源，发现更大模型在理解用户意图方面表现更好，但优势有限且不均衡。


<details>
  <summary>Details</summary>
Motivation: 评估LLM是否具备世界模型（即对世界的结构化理解）对高风险应用中的可靠性至关重要。

Method: 提出了一种分解模型响应变异性为三个组成部分（用户目的、用户表达和模型不稳定性）的评估方法，以量化模型行为的语义基础。

Result: 更大模型在用户目的引起的变异性上表现更好，表明其世界模型更稳健，但优势有限且在不同领域表现不均。

Conclusion: 需超越基于准确性的基准，采用语义诊断直接评估模型内部世界理解的结构和稳定性。

Abstract: Understanding whether large language models (LLMs) possess a world model-a
structured understanding of the world that supports generalization beyond
surface-level patterns-is central to assessing their reliability, especially in
high-stakes applications. We propose a formal framework for evaluating whether
an LLM exhibits a sufficiently robust world model, defined as producing
consistent outputs across semantically equivalent prompts while distinguishing
between prompts that express different intents. We introduce a new evaluation
approach to measure this that decomposes model response variability into three
components: variability due to user purpose, user articulation, and model
instability. An LLM with a strong world model should attribute most of the
variability in its responses to changes in foundational purpose rather than
superficial changes in articulation. This approach allows us to quantify how
much of a model's behavior is semantically grounded rather than driven by model
instability or alternative wording. We apply this framework to evaluate LLMs
across diverse domains. Our results show how larger models attribute a greater
share of output variability to changes in user purpose, indicating a more
robust world model. This improvement is not uniform, however: larger models do
not consistently outperform smaller ones across all domains, and their
advantage in robustness is often modest. These findings highlight the
importance of moving beyond accuracy-based benchmarks toward semantic
diagnostics that more directly assess the structure and stability of a model's
internal understanding of the world.

</details>


### [89] [A Scoping Review of Synthetic Data Generation for Biomedical Research and Applications](https://arxiv.org/abs/2506.16594)
*Hanshu Rao,Weisi Liu,Haohan Wang,I-Chan Huang,Zhe He,Xiaolei Huang*

Main category: cs.CL

TL;DR: 本文综述了2020-2025年间59项关于合成数据生成在生物医学领域的研究，重点关注临床应用、方法学和评估。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学领域数据稀缺、隐私问题和数据质量挑战。

Method: 遵循PRISMA-ScR指南，系统分析PubMed、ACM、Web of Science和Google Scholar中的研究。

Result: 发现文本数据（78.0%）为主要模态，提示生成（72.9%）为主要方法，人类评估（55.9%）为主要评估方式。

Conclusion: 总结了合成数据生成的局限性和挑战，包括临床适应性、资源可及性和评估标准化。

Abstract: Synthetic data generation--mitigating data scarcity, privacy concerns, and
data quality challenges in biomedical fields--has been facilitated by rapid
advances of large language models (LLMs). This scoping review follows
PRISMA-ScR guidelines and synthesizes 59 studies, published between 2020 and
2025 and collected from PubMed, ACM, Web of Science, and Google Scholar. The
review systematically examines biomedical research and application trends in
synthetic data generation, emphasizing clinical applications, methodologies,
and evaluations. Our analysis identifies data modalities of unstructured texts
(78.0%), tabular data (13.6%), and multimodal sources (8.4%); generation
methods of prompting (72.9%), fine-tuning (22.0%) LLMs and specialized model
(5.1%); and heterogeneous evaluations of intrinsic metrics (27.1%),
human-in-the-loop assessments (55.9%), and LLM-based evaluations (13.6%). The
analysis addresses current limitations in what, where, and how health
professionals can leverage synthetic data generation for biomedical domains.
Our review also highlights challenges in adaption across clinical domains,
resource and model accessibility, and evaluation standardizations.

</details>


### [90] [Modeling Public Perceptions of Science in Media](https://arxiv.org/abs/2506.16622)
*Jiaxin Pei,Dustin Wright,Isabelle Augenstin,David Jurgens*

Main category: cs.CL

TL;DR: 论文提出了一种计算框架，用于建模公众对科学新闻的感知，并通过大规模数据集和NLP模型预测公众反应，发现科学新闻消费频率是感知的主要驱动因素，而感知分数与公众参与度直接相关。


<details>
  <summary>Details</summary>
Motivation: 科学传播中公众感知的复杂性需要更深入的理解，以提升科学信息的传播效果和公众信任。

Method: 引入计算框架建模公众感知的12个维度，创建大规模数据集（10,489条注释），开发NLP模型预测感知分数，并通过Reddit自然实验验证。

Result: 科学新闻消费频率是感知的主要驱动因素，感知分数显著影响公众参与度（如评论和点赞）。

Conclusion: 研究强调了感知建模在科学传播中的重要性，为预测公众兴趣和参与提供了新途径。

Abstract: Effectively engaging the public with science is vital for fostering trust and
understanding in our scientific community. Yet, with an ever-growing volume of
information, science communicators struggle to anticipate how audiences will
perceive and interact with scientific news. In this paper, we introduce a
computational framework that models public perception across twelve dimensions,
such as newsworthiness, importance, and surprisingness. Using this framework,
we create a large-scale science news perception dataset with 10,489 annotations
from 2,101 participants from diverse US and UK populations, providing valuable
insights into public responses to scientific information across domains. We
further develop NLP models that predict public perception scores with a strong
performance. Leveraging the dataset and model, we examine public perception of
science from two perspectives: (1) Perception as an outcome: What factors
affect the public perception of scientific information? (2) Perception as a
predictor: Can we use the estimated perceptions to predict public engagement
with science? We find that individuals' frequency of science news consumption
is the driver of perception, whereas demographic factors exert minimal
influence. More importantly, through a large-scale analysis and carefully
designed natural experiment on Reddit, we demonstrate that the estimated public
perception of scientific information has direct connections with the final
engagement pattern. Posts with more positive perception scores receive
significantly more comments and upvotes, which is consistent across different
scientific information and for the same science, but are framed differently.
Overall, this research underscores the importance of nuanced perception
modeling in science communication, offering new pathways to predict public
interest and engagement with scientific content.

</details>


### [91] [Initial Investigation of LLM-Assisted Development of Rule-Based Clinical NLP System](https://arxiv.org/abs/2506.16628)
*Jianlin Shi,Brian T. Bucher*

Main category: cs.CL

TL;DR: 论文提出了一种利用大语言模型（LLMs）辅助开发基于规则的NLP系统的新方法，显著提高了开发效率和性能。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习和大语言模型取得进展，基于规则的NLP系统因其可解释性和操作效率仍在临床环境中广泛应用，但其开发和维护成本高昂。

Method: 利用LLMs在开发阶段辅助完成规则系统的前两步：从临床笔记中提取相关片段，并从中提取关键词用于命名实体识别（NER）。

Result: 实验显示，该方法在提取临床相关片段（Deepseek: 0.98, Qwen: 0.99）和关键词（1.0）方面表现出色。

Conclusion: 该方法为NLP开发提供了新方向，显著提升了基于规则系统的开发效率和透明度。

Abstract: Despite advances in machine learning (ML) and large language models (LLMs),
rule-based natural language processing (NLP) systems remain active in clinical
settings due to their interpretability and operational efficiency. However,
their manual development and maintenance are labor-intensive, particularly in
tasks with large linguistic variability. To overcome these limitations, we
proposed a novel approach employing LLMs solely during the rule-based systems
development phase. We conducted the initial experiments focusing on the first
two steps of developing a rule-based NLP pipeline: find relevant snippets from
the clinical note; extract informative keywords from the snippets for the
rule-based named entity recognition (NER) component. Our experiments
demonstrated exceptional recall in identifying clinically relevant text
snippets (Deepseek: 0.98, Qwen: 0.99) and 1.0 in extracting key terms for NER.
This study sheds light on a promising new direction for NLP development,
enabling semi-automated or automated development of rule-based systems with
significantly faster, more cost-effective, and transparent execution compared
with deep learning model-based solutions.

</details>


### [92] [GeoGuess: Multimodal Reasoning based on Hierarchy of Visual Information in Street View](https://arxiv.org/abs/2506.16633)
*Fenghua Cheng,Jinxiang Wang,Sen Wang,Zi Huang,Xue Li*

Main category: cs.CL

TL;DR: 论文提出了一种新的多模态推理任务GeoGuess，通过结合视觉线索和地理知识进行位置识别和解释，并建立了数据集GeoExplain和方法SightSense。


<details>
  <summary>Details</summary>
Motivation: 现有任务在多模态推理中对层次化视觉线索（如局部细节和全局上下文）的推理能力不足，而GeoGuess任务旨在填补这一空白。

Method: 提出了SightSense方法，结合多模态和多层次推理，利用视觉信息和外部知识进行预测和解释。

Result: 实验表明，SightSense在GeoGuess任务中表现优异。

Conclusion: GeoGuess任务和SightSense方法为多模态推理提供了新的挑战和解决方案。

Abstract: Multimodal reasoning is a process of understanding, integrating and inferring
information across different data modalities. It has recently attracted surging
academic attention as a benchmark for Artificial Intelligence (AI). Although
there are various tasks for evaluating multimodal reasoning ability, they still
have limitations. Lack of reasoning on hierarchical visual clues at different
levels of granularity, e.g., local details and global context, is of little
discussion, despite its frequent involvement in real scenarios. To bridge the
gap, we introduce a novel and challenging task for multimodal reasoning, namely
GeoGuess. Given a street view image, the task is to identify its location and
provide a detailed explanation. A system that succeeds in GeoGuess should be
able to detect tiny visual clues, perceive the broader landscape, and associate
with vast geographic knowledge. Therefore, GeoGuess would require the ability
to reason between hierarchical visual information and geographic knowledge. In
this work, we establish a benchmark for GeoGuess by introducing a specially
curated dataset GeoExplain which consists of
panoramas-geocoordinates-explanation tuples. Additionally, we present a
multimodal and multilevel reasoning method, namely SightSense which can make
prediction and generate comprehensive explanation based on hierarchy of visual
information and external knowledge. Our analysis and experiments demonstrate
their outstanding performance in GeoGuess.

</details>


### [93] [Long-Context Generalization with Sparse Attention](https://arxiv.org/abs/2506.16640)
*Pavlo Vasylenko,Marcos Treviso,André F. T. Martins*

Main category: cs.CL

TL;DR: 论文提出了一种稀疏注意力机制ASEntmax，通过可学习的温度参数优化注意力分布，解决了传统softmax在长序列中注意力分散的问题，并结合位置编码提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统softmax注意力机制在长序列任务中会导致注意力分散和表示崩溃，影响模型对固定大小模式的精确聚焦。

Method: 引入ASEntmax稀疏注意力机制，结合可学习温度参数和优化的位置编码设计。

Result: ASEntmax在长上下文泛化任务中显著优于softmax、可扩展softmax和固定温度α-entmax基线。

Conclusion: 稀疏注意力机制和优化的位置编码设计能有效提升模型在长序列任务中的表现。

Abstract: Transformer-based architectures traditionally employ softmax to compute
attention weights, which produces dense distributions over all tokens in a
sequence. While effective in many settings, this density has been shown to be
detrimental for tasks that demand precise focus on fixed-size patterns: as
sequence length increases, non-informative tokens accumulate attention
probability mass, leading to dispersion and representational collapse. We show
in this paper that sparse attention mechanisms using $\alpha$-entmax can avoid
these issues, due to their ability to assign exact zeros to irrelevant tokens.
Furthermore, we introduce Adaptive-Scalable Entmax (ASEntmax), which endows
$\alpha$-entmax with a learnable temperature parameter, allowing the attention
distribution to interpolate between sparse (pattern-focused) and dense
(softmax-like) regimes. Finally, we show that the ability to locate and
generalize fixed-size patterns can be further improved through a careful design
of position encodings, which impacts both dense and sparse attention methods.
By integrating ASEntmax into standard transformer layers alongside proper
positional encodings, we show that our models greatly outperform softmax,
scalable softmax, and fixed-temperature $\alpha$-entmax baselines on
long-context generalization.

</details>


### [94] [Arch-Router: Aligning LLM Routing with Human Preferences](https://arxiv.org/abs/2506.16655)
*Co Tran,Salman Paracha,Adil Hafeez,Shuguang Chen*

Main category: cs.CL

TL;DR: 论文提出了一种偏好对齐的路由框架Arch-Router，通过将查询映射到用户定义的领域或动作类型来优化大型语言模型（LLMs）的选择，解决了现有路由方法在捕捉人类主观偏好和模型选择范围上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法在评估性能时未能充分反映人类主观偏好，且模型选择范围有限，因此需要一种更灵活、透明且能动态扩展的路由框架。

Method: 提出Arch-Router，一个1.5B参数的紧凑模型，通过学习将查询映射到领域-动作偏好来指导路由决策，支持动态添加新模型而无需重新训练。

Result: 在对话数据集上的实验表明，Arch-Router在匹配人类偏好方面达到SOTA效果，优于顶级专有模型。

Conclusion: Arch-Router能够捕捉主观评价标准，使路由决策更透明灵活，为LLM路由提供了实用解决方案。

Abstract: With the rapid proliferation of large language models (LLMs) -- each
optimized for different strengths, style, or latency/cost profile -- routing
has become an essential technique to operationalize the use of different
models. However, existing LLM routing approaches are limited in two key ways:
they evaluate performance using benchmarks that often fail to capture human
preferences driven by subjective evaluation criteria, and they typically select
from a limited pool of models. In this work, we propose a preference-aligned
routing framework that guides model selection by matching queries to
user-defined domains (e.g., travel) or action types (e.g., image editing) --
offering a practical mechanism to encode preferences in routing decisions.
Specifically, we introduce \textbf{Arch-Router}, a compact 1.5B model that
learns to map queries to domain-action preferences for model routing decisions.
Our approach also supports seamlessly adding new models for routing without
requiring retraining or architectural modifications. Experiments on
conversational datasets demonstrate that our approach achieves state-of-the-art
(SOTA) results in matching queries with human preferences, outperforming top
proprietary models. Our approach captures subjective evaluation criteria and
makes routing decisions more transparent and flexible. Our model is available
at: \texttt{https://huggingface.co/katanemo/Arch-Router-1.5B}.

</details>


### [95] [Mechanisms vs. Outcomes: Probing for Syntax Fails to Explain Performance on Targeted Syntactic Evaluations](https://arxiv.org/abs/2506.16678)
*Ananth Agarwal,Jasper Jian,Christopher D. Manning,Shikhar Murty*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）的探测提取语法特征无法可靠预测其在下游任务中的语法表现。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs内部语法表示机制与下游任务表现之间的关系。

Method: 评估32个开源Transformer模型，比较探测提取的语法特征与目标语法评估结果。

Result: 探测提取的语法特征无法预测下游任务的语法行为表现。

Conclusion: LLMs的潜在语法表示与下游任务表现之间存在显著脱节。

Abstract: Large Language Models (LLMs) exhibit a robust mastery of syntax when
processing and generating text. While this suggests internalized understanding
of hierarchical syntax and dependency relations, the precise mechanism by which
they represent syntactic structure is an open area within interpretability
research. Probing provides one way to identify the mechanism of syntax being
linearly encoded in activations, however, no comprehensive study has yet
established whether a model's probing accuracy reliably predicts its downstream
syntactic performance. Adopting a "mechanisms vs. outcomes" framework, we
evaluate 32 open-weight transformer models and find that syntactic features
extracted via probing fail to predict outcomes of targeted syntax evaluations
across English linguistic phenomena. Our results highlight a substantial
disconnect between latent syntactic representations found via probing and
observable syntactic behaviors in downstream tasks.

</details>


### [96] [LegiGPT: Party Politics and Transport Policy with Large Language Model](https://arxiv.org/abs/2506.16692)
*Hyunsoo Yun,Eun Hak Lee*

Main category: cs.CL

TL;DR: LegiGPT结合LLM和XAI分析立法提案，揭示政治意识形态对交通政策的影响。


<details>
  <summary>Details</summary>
Motivation: 研究立法者政治意识形态对政策制定的影响。

Method: 使用LegiGPT框架，结合GPT-4和XAI技术，分析韩国立法数据。

Result: 保守派和进步派提案数量、选区规模等是关键因素。

Conclusion: LegiGPT为理解立法动态和政策制定提供了新工具。

Abstract: Given the significant influence of lawmakers' political ideologies on
legislative decision-making, understanding their impact on policymaking is
critically important. We introduce a novel framework, LegiGPT, which integrates
a large language model (LLM) with explainable artificial intelligence (XAI) to
analyze transportation-related legislative proposals. LegiGPT employs a
multi-stage filtering and classification pipeline using zero-shot prompting
with GPT-4. Using legislative data from South Korea's 21st National Assembly,
we identify key factors - including sponsor characteristics, political
affiliations, and geographic variables - that significantly influence
transportation policymaking. The LLM was used to classify
transportation-related bill proposals through a stepwise filtering process
based on keywords, phrases, and contextual relevance. XAI techniques were then
applied to examine relationships between party affiliation and associated
attributes. The results reveal that the number and proportion of conservative
and progressive sponsors, along with district size and electoral population,
are critical determinants shaping legislative outcomes. These findings suggest
that both parties contributed to bipartisan legislation through different forms
of engagement, such as initiating or supporting proposals. This integrated
approach provides a valuable tool for understanding legislative dynamics and
guiding future policy development, with broader implications for infrastructure
planning and governance.

</details>


### [97] [ReasonGRM: Enhancing Generative Reward Models through Large Reasoning Models](https://arxiv.org/abs/2506.16712)
*Bin Chen,Xinzge Gao,Chuanrui Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

Main category: cs.CL

TL;DR: ReasonGRM是一个三阶段生成奖励建模框架，通过改进推理路径和减少幻觉数据，显著提升了生成奖励模型的性能。


<details>
  <summary>Details</summary>
Motivation: 生成奖励模型（GRMs）在捕捉人类偏好方面具有灵活性，但其推理能力不足导致关键信息缺失或幻觉问题。

Method: ReasonGRM采用三阶段方法：1）Zero-RL生成简洁的推理路径；2）引入新评估指标$R^\star$；3）通过强化学习优化模型。

Result: 在三个公共基准测试中，ReasonGRM平均优于最佳GRMs 1.8%，最高超越GPT-4o 5.6%。

Conclusion: ReasonGRM证明了推理感知训练的有效性，并强调了高质量推理选择对可靠偏好建模的重要性。

Abstract: Generative Reward Models (GRMs) provide greater flexibility than scalar
reward models in capturing human preferences, but their effectiveness is
limited by poor reasoning capabilities. This often results in incomplete or
overly speculative reasoning paths, leading to hallucinations or missing key
information in complex tasks. We address this challenge with ReasonGRM, a
three-stage generative reward modeling framework. In the first stage, Zero-RL
is used to generate concise, outcome-directed reasoning paths that reduce the
likelihood of critical omissions. In the second stage, we introduce a novel
evaluation metric, $R^\star$, which scores reasoning paths based on their
generation likelihood. This favors paths that reach correct answers with
minimal exploration, helping to reduce hallucination-prone data during
training. In the final stage, the model is further refined through
reinforcement learning on challenging examples to enhance its preference
discrimination capabilities. Experiments on three public benchmarks show that
ReasonGRM achieves competitive or state-of-the-art performance, outperforming
previous best GRMs by 1.8\% on average and surpassing proprietary models such
as GPT-4o by up to 5.6\%. These results demonstrate the effectiveness of
reasoning-aware training and highlight the importance of high-quality rationale
selection for reliable preference modeling.

</details>


### [98] [The Role of Model Confidence on Bias Effects in Measured Uncertainties](https://arxiv.org/abs/2506.16724)
*Xinyi Liu,Weiguang Wang,Hangfeng He*

Main category: cs.CL

TL;DR: 研究探讨了在大型语言模型（LLM）中如何准确评估认知不确定性，发现减少提示引入的偏见可以改善GPT-4o的不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在开放任务中的广泛应用，准确评估认知不确定性（反映模型知识不足）对确保可靠结果至关重要。

Method: 通过视觉问答（VQA）任务实验，分析提示偏见对认知和随机不确定性的影响，使用GPT-4o和Qwen2-VL模型。

Result: 发现偏见在模型信心较低时对两种不确定性影响更大，且低信心会导致认知不确定性被低估（过度自信）。

Conclusion: 研究深化了对偏见缓解与不确定性量化的理解，为开发更先进技术提供了参考。

Abstract: With the growing adoption of Large Language Models (LLMs) for open-ended
tasks, accurately assessing epistemic uncertainty, which reflects a model's
lack of knowledge, has become crucial to ensuring reliable outcomes. However,
quantifying epistemic uncertainty in such tasks is challenging due to the
presence of aleatoric uncertainty, which arises from multiple valid answers.
While bias can introduce noise into epistemic uncertainty estimation, it may
also reduce noise from aleatoric uncertainty. To investigate this trade-off, we
conduct experiments on Visual Question Answering (VQA) tasks and find that
mitigating prompt-introduced bias improves uncertainty quantification in
GPT-4o. Building on prior work showing that LLMs tend to copy input information
when model confidence is low, we further analyze how these prompt biases affect
measured epistemic and aleatoric uncertainty across varying bias-free
confidence levels with GPT-4o and Qwen2-VL. We find that all considered biases
induce greater changes in both uncertainties when bias-free model confidence is
lower. Moreover, lower bias-free model confidence leads to greater
underestimation of epistemic uncertainty (i.e. overconfidence) due to bias,
whereas it has no significant effect on the direction of changes in aleatoric
uncertainty estimation. These distinct effects deepen our understanding of bias
mitigation for uncertainty quantification and potentially inform the
development of more advanced techniques.

</details>


### [99] [LM-SPT: LM-Aligned Semantic Distillation for Speech Tokenization](https://arxiv.org/abs/2506.16738)
*Daejin Jo,Jeeyoung Yun,Byungseok Roh,Sungwoong Kim*

Main category: cs.CL

TL;DR: 论文提出LM-SPT方法，通过语义蒸馏改进语音标记化，解决传统方法标记序列过长的问题，并支持多帧率。实验显示其在语音-文本任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统语音标记化方法生成的标记序列过长，影响语音-语言建模效率，且标准降帧技术可能破坏语义结构。

Method: 提出LM-SPT方法，通过语义蒸馏间接监督学习语义对齐的离散单元，并改进编码器和解码器架构，支持多帧率。

Result: LM-SPT在重建保真度上优于基线，语音-文本任务表现竞争性，文本-语音任务一致优于基线。

Conclusion: LM-SPT通过语义蒸馏和多帧率支持，显著提升了语音标记化的语义对齐和建模效率。

Abstract: With the rapid progress of speech language models (SLMs), discrete speech
tokens have emerged as a core interface between speech and text, enabling
unified modeling across modalities. Recent speech tokenization approaches aim
to isolate semantic information from low-level acoustics to better align with
language models. In particular, previous methods use SSL teachers such as
HuBERT to extract semantic representations, which are then distilled into a
semantic quantizer to suppress acoustic redundancy as well as capture
content-related latent structures. However, they still produce speech token
sequences significantly longer than their textual counterparts, creating
challenges for efficient speech-language modeling. Reducing the frame rate is a
natural solution, but standard techniques, such as rigid average pooling across
frames, can distort or dilute the semantic structure required for effective LM
alignment. To address this, we propose LM-SPT, a speech tokenization method
that introduces a novel semantic distillation. Instead of directly matching
teacher and student features via pooling, we reconstruct speech solely from
semantic tokens and minimize the discrepancy between the encoded
representations of the original and reconstructed waveforms, obtained from a
frozen automatic speech recognition (ASR) encoder. This indirect yet
data-driven supervision enables the tokenizer to learn discrete units that are
more semantically aligned with language models. LM-SPT further incorporates
architectural improvements to the encoder and decoder for speech tokenization,
and supports multiple frame rates, including 25Hz, 12.5Hz, and 6.25Hz.
Experimental results show that LM-SPT achieves superior reconstruction fidelity
compared to baselines, and that SLMs trained with LM-SPT tokens achieve
competitive performances on speech-to-text and consistently outperform
baselines on text-to-speech tasks.

</details>


### [100] [Language-Informed Synthesis of Rational Agent Models for Grounded Theory-of-Mind Reasoning On-The-Fly](https://arxiv.org/abs/2506.16755)
*Lance Ying,Ryan Truong,Katherine M. Collins,Cedegao E. Zhang,Megan Wei,Tyler Brooke-Wilson,Tan Zhi-Xuan,Lionel Wong,Joshua B. Tenenbaum*

Main category: cs.CL

TL;DR: LIRAS框架整合语言和视觉输入，通过多模态语言模型和贝叶斯逆规划引擎，提升社交推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的社交推理通常需要多模态信息，语言在社交环境中尤为重要，尤其是在新情境中。

Method: 提出LIRAS框架，结合多模态语言模型和贝叶斯逆规划引擎，构建情境特定的代理和环境表征。

Result: 在多个社交推理任务中，LIRAS表现优于现有模型，更接近人类判断。

Conclusion: LIRAS通过整合语言和视觉信息，有效提升了社交推理的准确性和适应性。

Abstract: Drawing real world social inferences usually requires taking into account
information from multiple modalities. Language is a particularly powerful
source of information in social settings, especially in novel situations where
language can provide both abstract information about the environment dynamics
and concrete specifics about an agent that cannot be easily visually observed.
In this paper, we propose Language-Informed Rational Agent Synthesis (LIRAS), a
framework for drawing context-specific social inferences that integrate
linguistic and visual inputs. LIRAS frames multimodal social reasoning as a
process of constructing structured but situation-specific agent and environment
representations - leveraging multimodal language models to parse language and
visual inputs into unified symbolic representations, over which a Bayesian
inverse planning engine can be run to produce granular probabilistic judgments.
On a range of existing and new social reasoning tasks derived from cognitive
science experiments, we find that our model (instantiated with a comparatively
lightweight VLM) outperforms ablations and state-of-the-art models in capturing
human judgments across all domains.

</details>


### [101] [SocialSim: Towards Socialized Simulation of Emotional Support Conversation](https://arxiv.org/abs/2506.16756)
*Zhuang Chen,Yaru Cao,Guanqun Bi,Jincenzi Wu,Jinfeng Zhou,Xiyao Xiao,Si Chen,Hongning Wang,Minlie Huang*

Main category: cs.CL

TL;DR: SocialSim框架通过整合社交互动中的关键要素（社交披露和社交意识），模拟情感支持对话（ESC），并构建高质量合成数据集SSConv，其性能超越众包数据。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视ESC中的社交动态，导致模拟效果不佳，需一种更有效的方法来生成高质量ESC数据。

Method: SocialSim框架通过构建全面的角色库（社交披露）和激发认知推理（社交意识），模拟ESC，并生成合成数据集SSConv。

Result: SSConv数据集质量超越众包数据，基于其训练的聊天机器人在自动和人工评估中表现最佳。

Conclusion: SocialSim为ESC提供了一种可扩展的合成方法，使情感关怀更易实现。

Abstract: Emotional support conversation (ESC) helps reduce people's psychological
stress and provide emotional value through interactive dialogues. Due to the
high cost of crowdsourcing a large ESC corpus, recent attempts use large
language models for dialogue augmentation. However, existing approaches largely
overlook the social dynamics inherent in ESC, leading to less effective
simulations. In this paper, we introduce SocialSim, a novel framework that
simulates ESC by integrating key aspects of social interactions: social
disclosure and social awareness. On the seeker side, we facilitate social
disclosure by constructing a comprehensive persona bank that captures diverse
and authentic help-seeking scenarios. On the supporter side, we enhance social
awareness by eliciting cognitive reasoning to generate logical and supportive
responses. Building upon SocialSim, we construct SSConv, a large-scale
synthetic ESC corpus of which quality can even surpass crowdsourced ESC data.
We further train a chatbot on SSConv and demonstrate its state-of-the-art
performance in both automatic and human evaluations. We believe SocialSim
offers a scalable way to synthesize ESC, making emotional care more accessible
and practical.

</details>


### [102] [Cross-Modal Obfuscation for Jailbreak Attacks on Large Vision-Language Models](https://arxiv.org/abs/2506.16760)
*Lei Jiang,Zixun Zhang,Zizhou Wang,Xiaobing Sun,Zhen Li,Liangli Zhen,Xiaohua Xu*

Main category: cs.CL

TL;DR: CAMO是一种新型黑盒越狱攻击框架，通过将恶意提示分解为视觉和文本片段，利用跨模态推理能力绕过安全机制。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒越狱方法易被检测且效率低，需更隐蔽高效的攻击方式。

Method: CAMO将恶意提示分解为良性片段，利用跨模态推理重建有害指令。

Result: CAMO在主流LVLMs上表现优异，具有高效性和跨模型迁移能力。

Conclusion: 当前安全机制存在漏洞，需开发更先进的视觉语言系统安全解决方案。

Abstract: Large Vision-Language Models (LVLMs) demonstrate exceptional performance
across multimodal tasks, yet remain vulnerable to jailbreak attacks that bypass
built-in safety mechanisms to elicit restricted content generation. Existing
black-box jailbreak methods primarily rely on adversarial textual prompts or
image perturbations, yet these approaches are highly detectable by standard
content filtering systems and exhibit low query and computational efficiency.
In this work, we present Cross-modal Adversarial Multimodal Obfuscation (CAMO),
a novel black-box jailbreak attack framework that decomposes malicious prompts
into semantically benign visual and textual fragments. By leveraging LVLMs'
cross-modal reasoning abilities, CAMO covertly reconstructs harmful
instructions through multi-step reasoning, evading conventional detection
mechanisms. Our approach supports adjustable reasoning complexity and requires
significantly fewer queries than prior attacks, enabling both stealth and
efficiency. Comprehensive evaluations conducted on leading LVLMs validate
CAMO's effectiveness, showcasing robust performance and strong cross-model
transferability. These results underscore significant vulnerabilities in
current built-in safety mechanisms, emphasizing an urgent need for advanced,
alignment-aware security and safety solutions in vision-language systems.

</details>


### [103] [DistillNote: LLM-based clinical note summaries improve heart failure diagnosis](https://arxiv.org/abs/2506.16777)
*Heloisa Oss Boll,Antonio Oss Boll,Leticia Puttlitz Boll,Ameen Abu Hanna,Iacer Calixto*

Main category: cs.CL

TL;DR: Distillnote框架利用LLM生成临床笔记摘要，通过三种方法（直接摘要、结构化摘要和蒸馏摘要）显著提升效率和性能，并在心衰预测任务中表现优于原始笔记。


<details>
  <summary>Details</summary>
Motivation: 减轻临床文档负担，利用LLM生成高效且有用的患者信息摘要。

Method: 采用三种技术生成摘要：直接摘要、结构化摘要和蒸馏摘要，并评估其效果。

Result: 蒸馏摘要实现79%文本压缩，AUPRC提升18.2%；临床评估显示直接摘要更受青睐，蒸馏摘要效率最优。

Conclusion: Distillnote框架有效提升临床摘要的效率和实用性，为未来研究提供资源。

Abstract: Large language models (LLMs) offer unprecedented opportunities to generate
concise summaries of patient information and alleviate the burden of clinical
documentation that overwhelms healthcare providers. We present Distillnote, a
framework for LLM-based clinical note summarization, and generate over 64,000
admission note summaries through three techniques: (1) One-step, direct
summarization, and a divide-and-conquer approach involving (2) Structured
summarization focused on independent clinical insights, and (3) Distilled
summarization that further condenses the Structured summaries. We test how
useful are the summaries by using them to predict heart failure compared to a
model trained on the original notes. Distilled summaries achieve 79% text
compression and up to 18.2% improvement in AUPRC compared to an LLM trained on
the full notes. We also evaluate the quality of the generated summaries in an
LLM-as-judge evaluation as well as through blinded pairwise comparisons with
clinicians. Evaluations indicate that one-step summaries are favoured by
clinicians according to relevance and clinical actionability, while distilled
summaries offer optimal efficiency (avg. 6.9x compression-to-performance ratio)
and significantly reduce hallucinations. We release our summaries on PhysioNet
to encourage future research.

</details>


### [104] [MIST: Jailbreaking Black-box Large Language Models via Iterative Semantic Tuning](https://arxiv.org/abs/2506.16792)
*Muyang Zheng,Yuanzhi Yao,Changting Lin,Rui Wang,Meng Han*

Main category: cs.CL

TL;DR: MIST是一种通过迭代语义调优来破解黑盒大语言模型的方法，有效平衡语义相似性与计算效率，实验证明其攻击成功率和转移性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）已尝试与社会和道德价值观对齐，但仍易受破解攻击。破解黑盒LLM因离散输入、受限访问和有限查询预算而具挑战性。

Method: MIST通过迭代语义调优，结合顺序同义词搜索和顺序确定优化策略，生成保留原语义但诱导有害内容的提示。

Result: 在开源和闭源模型上的实验表明，MIST的攻击成功率和转移性优于现有白盒和黑盒破解方法，且计算效率验证了其可行性。

Conclusion: MIST为破解黑盒LLM提供了一种高效方法，展示了其在攻击成功率和计算效率上的优势。

Abstract: Despite efforts to align large language models (LLMs) with societal and moral
values, these models remain susceptible to jailbreak attacks--methods designed
to elicit harmful responses. Jailbreaking black-box LLMs is considered
challenging due to the discrete nature of token inputs, restricted access to
the target LLM, and limited query budget. To address the issues above, we
propose an effective method for jailbreaking black-box large language Models
via Iterative Semantic Tuning, named MIST. MIST enables attackers to
iteratively refine prompts that preserve the original semantic intent while
inducing harmful content. Specifically, to balance semantic similarity with
computational efficiency, MIST incorporates two key strategies: sequential
synonym search, and its advanced version--order-determining optimization.
Extensive experiments across two open-source models and four closed-source
models demonstrate that MIST achieves competitive attack success rates and
attack transferability compared with other state-of-the-art white-box and
black-box jailbreak methods. Additionally, we conduct experiments on
computational efficiency to validate the practical viability of MIST.

</details>


### [105] [From Data to Knowledge: Evaluating How Efficiently Language Models Learn Facts](https://arxiv.org/abs/2506.16912)
*Daniel Christoph,Max Ploner,Patrick Haller,Alan Akbik*

Main category: cs.CL

TL;DR: 研究分析了不同架构和大小的语言模型在样本效率上的表现，发现模型在高频事实上的表现相似，但在低频事实上差异显著。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的信息分布呈长尾分布，模型需要高效学习和记忆罕见信息，而样本效率是关键。

Method: 通过在同一预训练数据上训练不同架构和大小的模型，并标注关系事实的频率，分析模型表现与事实频率的关系。

Result: 大多数模型在高频事实上表现相似，但在低频事实上差异显著。

Conclusion: 研究揭示了模型架构、大小与事实学习效率之间的关系，为样本效率提供了新见解。

Abstract: Sample efficiency is a crucial property of language models with practical
implications for training efficiency. In real-world text, information follows a
long-tailed distribution. Yet, we expect models to learn and recall frequent
and infrequent facts. Sample-efficient models are better equipped to handle
this challenge of learning and retaining rare information without requiring
excessive exposure. This study analyzes multiple models of varying
architectures and sizes, all trained on the same pre-training data. By
annotating relational facts with their frequencies in the training corpus, we
examine how model performance varies with fact frequency. Our findings show
that most models perform similarly on high-frequency facts but differ notably
on low-frequency facts. This analysis provides new insights into the
relationship between model architecture, size, and factual learning efficiency.

</details>


### [106] [Language Bottleneck Models: A Framework for Interpretable Knowledge Tracing and Beyond](https://arxiv.org/abs/2506.16982)
*Antonin Berthon,Mihaela van der Schaar*

Main category: cs.CL

TL;DR: 论文提出了一种基于语言瓶颈模型（LBM）的知识追踪方法，通过生成可解释的自然语言摘要来提高预测准确性，同时减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 传统知识追踪方法依赖不透明的潜在嵌入，缺乏可解释性；而基于LLM的方法可能产生不准确的预测或摘要。论文旨在通过自然语言摘要解决这一问题。

Method: 提出语言瓶颈模型（LBM），包括一个编码器LLM生成可解释的知识摘要，和一个冻结的解码器LLM利用摘要预测学生回答。训练时使用下游解码准确率作为奖励信号优化摘要质量。

Result: 在合成算术基准和大规模Eedi数据集上，LBM的准确性与最先进的KT和直接LLM方法相当，但所需学生轨迹数据显著减少。

Conclusion: LBM通过自然语言瓶颈实现了高准确性和可解释性，为知识追踪提供了一种高效且透明的方法。

Abstract: Accurately assessing student knowledge is critical for effective education,
yet traditional Knowledge Tracing (KT) methods rely on opaque latent
embeddings, limiting interpretability. Even LLM-based approaches generate
direct predictions or summaries that may hallucinate without any accuracy
guarantees. We recast KT as an inverse problem: learning the minimum
natural-language summary that makes past answers explainable and future answers
predictable. Our Language Bottleneck Model (LBM) consists of an encoder LLM
that writes an interpretable knowledge summary and a frozen decoder LLM that
must reconstruct and predict student responses using only that summary text. By
constraining all predictive information to pass through a short
natural-language bottleneck, LBMs ensure that the summary contains accurate
information while remaining human-interpretable. Experiments on synthetic
arithmetic benchmarks and the large-scale Eedi dataset show that LBMs rival the
accuracy of state-of-the-art KT and direct LLM methods while requiring
orders-of-magnitude fewer student trajectories. We demonstrate that training
the encoder with group-relative policy optimization, using downstream decoding
accuracy as a reward signal, effectively improves summary quality.

</details>


### [107] [TeXpert: A Multi-Level Benchmark for Evaluating LaTeX Code Generation by LLMs](https://arxiv.org/abs/2506.16990)
*Sahil Kale,Vijaykant Nadadur*

Main category: cs.CL

TL;DR: 论文介绍了TeXpert基准数据集，用于评估大语言模型（LLM）生成LaTeX代码的能力，发现LLM在复杂任务中表现不佳，开源模型表现接近闭源模型，且训练数据中缺乏多样化的LaTeX示例。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试未评估LLM生成LaTeX代码的能力，而LaTeX是科学文档排版的金标准，因此需要填补这一空白。

Method: 通过TeXpert数据集（包含多难度级别的自然语言提示）对开源和闭源LLM进行深入分析，识别常见错误类型。

Result: LLM在标准基准测试中表现优秀，但在LaTeX生成任务中表现差，复杂度增加时准确率显著下降；开源模型（如DeepSeek）与闭源模型表现相当；格式和包错误普遍。

Conclusion: 训练数据中缺乏多样化的LaTeX示例是LLM表现不佳的主要原因，开源模型在LaTeX任务中具有竞争力。

Abstract: LaTeX's precision and flexibility in typesetting have made it the gold
standard for the preparation of scientific documentation. Large Language Models
(LLMs) present a promising opportunity for researchers to produce
publication-ready material using LaTeX with natural language instructions, yet
current benchmarks completely lack evaluation of this ability. By introducing
TeXpert, our benchmark dataset with natural language prompts for generating
LaTeX code focused on components of scientific documents across multiple
difficulty levels, we conduct an in-depth analysis of LLM performance in this
regard and identify frequent error types. Our evaluation across open and
closed-source LLMs highlights multiple key findings: LLMs excelling on standard
benchmarks perform poorly in LaTeX generation with a significant accuracy
drop-off as the complexity of tasks increases; open-source models like DeepSeek
v3 and DeepSeek Coder strongly rival closed-source counterparts in LaTeX tasks;
and formatting and package errors are unexpectedly prevalent, suggesting a lack
of diverse LaTeX examples in the training datasets of most LLMs. Our dataset,
code, and model evaluations are available at
https://github.com/knowledge-verse-ai/TeXpert.

</details>


### [108] [PersonalAI: Towards digital twins in the graph form](https://arxiv.org/abs/2506.17001)
*Mikhail Menschikov,Dmitry Evseev,Ruslan Kostoev,Ilya Perepechkin,Ilnaz Salimov,Victoria Dochkina,Petr Anokhin,Evgeny Burnaev,Nikita Semenov*

Main category: cs.CL

TL;DR: 论文提出了一种利用知识图谱作为外部记忆的方法，以增强语言模型的个性化能力，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决语言模型在个性化交互中难以保留和利用用户历史信息的问题。

Method: 采用知识图谱作为外部记忆，结合标准边和两种超边，扩展了AriGraph架构。

Result: 在TriviaQA、HotpotQA和DiaASQ基准测试中表现稳健，能够处理时间依赖性和矛盾信息。

Conclusion: 所提出的架构在知识提取和个性化响应生成方面具有潜力。

Abstract: The challenge of personalizing language models, specifically the ability to
account for a user's history during interactions, is of significant interest.
Despite recent advancements in large language models (LLMs) and Retrieval
Augmented Generation that have enhanced the factual base of LLMs, the task of
retaining extensive personal information and using it to generate personalized
responses remains pertinent. To address this, we propose utilizing external
memory in the form of knowledge graphs, which are constructed and updated by
the LLM itself. We have expanded upon ideas of AriGraph architecture and for
the first time introduced a combined graph featuring both standard edges and
two types of hyperedges. Experiments conducted on the TriviaQA, HotpotQA and
DiaASQ benchmarks indicates that this approach aids in making the process of
graph construction and knowledge extraction unified and robust. Furthermore, we
augmented the DiaASQ benchmark by incorporating parameters such as time into
dialogues and introducing contradictory statements made by the same speaker at
different times. Despite these modifications, the performance of the
question-answering system remained robust, demonstrating the proposed
architecture's ability to maintain and utilize temporal dependencies.

</details>


### [109] [LLM-Generated Feedback Supports Learning If Learners Choose to Use It](https://arxiv.org/abs/2506.17006)
*Danielle R. Thomas,Conrad Borchers,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 研究探讨了LLM生成反馈对学习的影响，发现其效果取决于学习者的使用倾向，部分课程中表现出中等学习效果。


<details>
  <summary>Details</summary>
Motivation: 探索LLM生成反馈对学习的影响，并与现有反馈方法进行比较。

Method: 通过三组对比实验（接受LLM反馈、拒绝LLM反馈、无LLM反馈），分析2600多次课程完成数据，使用倾向评分调整选择偏差。

Result: 两门课程中LLM反馈显著提升学习效果（效应量0.28和0.33），且学习者普遍认为反馈有帮助。

Conclusion: LLM反馈是一种低成本、可扩展的学习支持工具，尤其在已有反馈系统中潜力显著。

Abstract: Large language models (LLMs) are increasingly used to generate feedback, yet
their impact on learning remains underexplored, especially compared to existing
feedback methods. This study investigates how on-demand LLM-generated
explanatory feedback influences learning in seven scenario-based tutor training
lessons. Analyzing over 2,600 lesson completions from 885 tutor learners, we
compare posttest performance among learners across three groups: learners who
received feedback generated by gpt-3.5-turbo, those who declined it, and those
without access. All groups received non-LLM corrective feedback. To address
potential selection bias-where higher-performing learners may be more inclined
to use LLM feedback-we applied propensity scoring. Learners with a higher
predicted likelihood of engaging with LLM feedback scored significantly higher
at posttest than those with lower propensity. After adjusting for this effect,
two out of seven lessons showed statistically significant learning benefits
from LLM feedback with standardized effect sizes of 0.28 and 0.33. These
moderate effects suggest that the effectiveness of LLM feedback depends on the
learners' tendency to seek support. Importantly, LLM feedback did not
significantly increase completion time, and learners overwhelmingly rated it as
helpful. These findings highlight LLM feedback's potential as a low-cost and
scalable way to improve learning on open-ended tasks, particularly in existing
systems already providing feedback without LLMs. This work contributes open
datasets, LLM prompts, and rubrics to support reproducibility.

</details>


### [110] [Instituto de Telecomunicações at IWSLT 2025: Aligning Small-Scale Speech and Language Models for Speech-to-Text Learning](https://arxiv.org/abs/2506.17019)
*Giuseppe Attanasio,Sonal Sannigrahi,Ben Peters,André F. T. Martins*

Main category: cs.CL

TL;DR: 本文介绍了IT-IST团队在IWSLT 2025共享任务中的提交，专注于短赛道任务（语音识别、翻译和口语问答），采用统一语音到文本模型。


<details>
  <summary>Details</summary>
Motivation: 解决语音处理任务中的多任务需求，同时限制模型规模和数据质量。

Method: 结合预训练语音编码器和文本解码器，分两阶段进行模态对齐和指令微调，使用小规模语言模型（<2B）和高质量数据。

Result: 提交了短赛道任务的结果，展示了模型的性能。

Conclusion: 通过小规模模型和高质量数据，实现了多任务语音处理的有效解决方案。

Abstract: This paper presents the IT-IST submission to the IWSLT 2025 Shared Task on
Instruction Following Speech Processing. We submit results for the Short Track,
i.e., speech recognition, translation, and spoken question answering. Our model
is a unified speech-to-text model that integrates a pre-trained continuous
speech encoder and text decoder through a first phase of modality alignment and
a second phase of instruction fine-tuning. Crucially, we focus on using
small-scale language model backbones (< 2B) and restrict to high-quality, CC-BY
data along with synthetic data generation to supplement existing resources.

</details>


### [111] [MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models](https://arxiv.org/abs/2506.17046)
*Xiaolong Wang,Zhaolu Kang,Wangyuxuan Zhai,Xinyue Lou,Yunghwei Lai,Ziyue Wang,Yawen Wang,Kaiyu Huang,Yile Wang,Peng Li,Yang Liu*

Main category: cs.CL

TL;DR: MUCAR是一个新的多模态基准，旨在评估多语言和跨模态场景下的歧义解决能力，填补现有基准忽略多模态歧义的空白。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要依赖单模态上下文解决歧义，未能充分利用多模态间的相互澄清潜力，因此需要新的评估工具。

Method: MUCAR包含多语言数据集和双歧义数据集，通过视觉和文本上下文的相互澄清构造清晰解释。

Result: 对19种先进多模态模型的评估显示，其性能与人类水平存在显著差距。

Conclusion: 未来需研究更复杂的跨模态歧义理解方法，以推动多模态推理的发展。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
advances across numerous vision-language tasks. Due to their strong image-text
alignment capability, MLLMs can effectively understand image-text pairs with
clear meanings. However, effectively resolving the inherent ambiguities in
natural language and visual contexts remains challenging. Existing multimodal
benchmarks typically overlook linguistic and visual ambiguities, relying mainly
on unimodal context for disambiguation and thus failing to exploit the mutual
clarification potential between modalities. To bridge this gap, we introduce
MUCAR, a novel and challenging benchmark designed explicitly for evaluating
multimodal ambiguity resolution across multilingual and cross-modal scenarios.
MUCAR includes: (1) a multilingual dataset where ambiguous textual expressions
are uniquely resolved by corresponding visual contexts, and (2) a
dual-ambiguity dataset that systematically pairs ambiguous images with
ambiguous textual contexts, with each combination carefully constructed to
yield a single, clear interpretation through mutual disambiguation. Extensive
evaluations involving 19 state-of-the-art multimodal models--encompassing both
open-source and proprietary architectures--reveal substantial gaps compared to
human-level performance, highlighting the need for future research into more
sophisticated cross-modal ambiguity comprehension methods, further pushing the
boundaries of multimodal reasoning.

</details>


### [112] [Simultaneous Translation with Offline Speech and LLM Models in CUNI Submission to IWSLT 2025](https://arxiv.org/abs/2506.17077)
*Dominik Macháček,Peter Polák*

Main category: cs.CL

TL;DR: 论文介绍了查尔斯大学在IWSLT 2025同步语音翻译任务中的提交，基于Whisper模型和AlignAtt策略，通过提示注入领域术语和上下文优化性能，BLEU分数显著提升。


<details>
  <summary>Details</summary>
Motivation: 提升同步语音翻译任务的性能，特别是在多语言对上的表现。

Method: 使用Whisper模型和AlignAtt策略，结合提示注入领域术语和上下文，并采用EuroLLM进行无界同步翻译。

Result: 在开发集上，捷克语到英语提升2 BLEU分，英语到德语、中文和日语提升13-22 BLEU分。

Conclusion: 提出的方法显著提升了同步翻译性能，并提出了新的语音识别延迟度量标准。

Abstract: This paper describes Charles University submission to the Simultaneous Speech
Translation Task of the IWSLT 2025. We cover all four language pairs with a
direct or cascade approach. The backbone of our systems is the offline Whisper
speech model, which we use for both translation and transcription in
simultaneous mode with the state-of-the-art simultaneous policy AlignAtt. We
further improve the performance by prompting to inject in-domain terminology,
and we accommodate context. Our cascaded systems further use EuroLLM for
unbounded simultaneous translation. Compared to the Organizers' baseline, our
systems improve by 2 BLEU points on Czech to English and 13-22 BLEU points on
English to German, Chinese and Japanese on the development sets. Additionally,
we also propose a new enhanced measure of speech recognition latency.

</details>


### [113] [Tower+: Bridging Generality and Translation Specialization in Multilingual LLMs](https://arxiv.org/abs/2506.17080)
*Ricardo Rei,Nuno M. Guerreiro,José Pombal,João Alves,Pedro Teixeirinha,Amin Farajian,André F. T. Martins*

Main category: cs.CL

TL;DR: 论文介绍了Tower+模型套件，旨在平衡翻译任务和多语言通用能力，通过多阶段训练方法实现性能优化。


<details>
  <summary>Details</summary>
Motivation: 微调预训练LLMs虽能提升特定任务性能（如机器翻译），但会牺牲通用能力（如对话推理和指令遵循），限制了实际应用。

Method: 采用多阶段训练方法：持续预训练、监督微调、偏好优化和带可验证奖励的强化学习，并精心生成和筛选数据。

Result: Tower+模型在不同规模（2B、9B、72B）上表现优异，小模型超越大型通用LLMs，大模型在高资源语言翻译和多语言任务中表现最佳。

Conclusion: 研究表明，优化特定领域（如翻译）的同时，仍可匹敌前沿模型的通用能力。

Abstract: Fine-tuning pretrained LLMs has been shown to be an effective strategy for
reaching state-of-the-art performance on specific tasks like machine
translation. However, this process of adaptation often implies sacrificing
general-purpose capabilities, such as conversational reasoning and
instruction-following, hampering the utility of the system in real-world
applications that require a mixture of skills. In this paper, we introduce
Tower+, a suite of models designed to deliver strong performance across both
translation and multilingual general-purpose text capabilities. We achieve a
Pareto frontier between translation specialization and multilingual
general-purpose capabilities by introducing a novel training recipe that builds
on Tower (Alves et al., 2024), comprising continued pretraining, supervised
fine-tuning, preference optimization, and reinforcement learning with
verifiable rewards. At each stage of training, we carefully generate and curate
data to strengthen performance on translation as well as general-purpose tasks
involving code generation, mathematics problem solving, and general
instruction-following. We develop models at multiple scales: 2B, 9B, and 72B.
Our smaller models often outperform larger general-purpose open-weight and
proprietary LLMs (e.g., Llama 3.3 70B, GPT-4o). Our largest model delivers
best-in-class translation performance for high-resource languages and top
results in multilingual Arena Hard evaluations and in IF-MT, a benchmark we
introduce for evaluating both translation and instruction-following. Our
findings highlight that it is possible to rival frontier models in general
capabilities, while optimizing for specific business domains, such as
translation and localization.

</details>


### [114] [Chain-of-Thought Prompting Obscures Hallucination Cues in Large Language Models: An Empirical Evaluation](https://arxiv.org/abs/2506.17088)
*Jiahao Cheng,Tiancheng Su,Jia Yuan,Guoxiu He,Jiawei Liu,Xinqi Tao,Jingwen Xie,Huaxia Li*

Main category: cs.CL

TL;DR: 研究发现，CoT提示能减少LLM的幻觉，但会削弱检测方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索CoT提示对LLM幻觉检测的影响，填补研究空白。

Method: 通过实验评估CoT提示对幻觉检测的影响，包括分数分布、准确性和置信度变化。

Result: CoT提示减少幻觉频率，但干扰检测信号，降低检测效果。

Conclusion: 研究揭示了推理使用中的权衡问题，需进一步优化检测方法。

Abstract: Large Language Models (LLMs) often exhibit \textit{hallucinations},
generating factually incorrect or semantically irrelevant content in response
to prompts. Chain-of-Thought (CoT) prompting can mitigate hallucinations by
encouraging step-by-step reasoning, but its impact on hallucination detection
remains underexplored. To bridge this gap, we conduct a systematic empirical
evaluation. We begin with a pilot experiment, revealing that CoT reasoning
significantly affects the LLM's internal states and token probability
distributions. Building on this, we evaluate the impact of various CoT
prompting methods on mainstream hallucination detection methods across both
instruction-tuned and reasoning-oriented LLMs. Specifically, we examine three
key dimensions: changes in hallucination score distributions, variations in
detection accuracy, and shifts in detection confidence. Our findings show that
while CoT prompting helps reduce hallucination frequency, it also tends to
obscure critical signals used for detection, impairing the effectiveness of
various detection methods. Our study highlights an overlooked trade-off in the
use of reasoning. Code is publicly available at:
https://anonymous.4open.science/r/cot-hallu-detect.

</details>


### [115] [Better Language Model Inversion by Compactly Representing Next-Token Distributions](https://arxiv.org/abs/2506.17090)
*Murtaza Nazir,Matthew Finlayson,John X. Morris,Xiang Ren,Swabha Swayamdipta*

Main category: cs.CL

TL;DR: 论文提出了一种新方法PILS，通过语言模型的多步生成概率恢复隐藏提示，显著提升了恢复率，并展示了在跨模型和任务中的良好泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型反转能力对安全和问责的影响，如从API保护的语言模型中泄露私有信息。

Method: 提出PILS方法，利用语言模型的多步生成概率的低维子空间特性，通过线性映射无损压缩概率分布，以恢复隐藏提示。

Result: PILS方法在隐藏提示恢复上比现有方法提升2-3.5倍，恢复率从17%增至60%，并在跨任务和模型上表现优异。

Conclusion: 研究表明，语言模型的下一词概率是反转攻击的脆弱点，PILS方法显著提升了恢复效果和泛化能力。

Abstract: Language model inversion seeks to recover hidden prompts using only language
model outputs. This capability has implications for security and accountability
in language model deployments, such as leaking private information from an
API-protected language model's system message. We propose a new method --
prompt inversion from logprob sequences (PILS) -- that recovers hidden prompts
by gleaning clues from the model's next-token probabilities over the course of
multiple generation steps. Our method is enabled by a key insight: The
vector-valued outputs of a language model occupy a low-dimensional subspace.
This enables us to losslessly compress the full next-token probability
distribution over multiple generation steps using a linear map, allowing more
output information to be used for inversion. Our approach yields massive gains
over previous state-of-the-art methods for recovering hidden prompts, achieving
2--3.5 times higher exact recovery rates across test sets, in one case
increasing the recovery rate from 17% to 60%. Our method also exhibits
surprisingly good generalization behavior; for instance, an inverter trained on
16 generations steps gets 5--27 points higher prompt recovery when we increase
the number of steps to 32 at test time. Furthermore, we demonstrate strong
performance of our method on the more challenging task of recovering hidden
system messages. We also analyze the role of verbatim repetition in prompt
recovery and propose a new method for cross-family model transfer for
logit-based inverters. Our findings show that next-token probabilities are a
considerably more vulnerable attack surface for inversion attacks than
previously known.

</details>


### [116] [Cache Me If You Can: How Many KVs Do You Need for Effective Long-Context LMs?](https://arxiv.org/abs/2506.17121)
*Adithya Bhaskar,Alexander Wettig,Tianyu Gao,Yihe Dong,Danqi Chen*

Main category: cs.CL

TL;DR: 论文提出了一种统一的度量标准*KV footprint*，用于评估语言模型在处理长上下文时的内存效率，揭示了现有KV缓存方法的局限性，并提出改进方法。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型处理长上下文任务的增加，KV缓存的内存成本显著上升，现有方法在高峰值内存和性能下降方面存在不足，且缺乏公平比较。

Method: 提出*KV footprint*作为统一度量，评估方法在保持性能的同时的最小内存占用。改进*post-fill eviction*方法以支持预填充阶段的KV丢弃，并提出PruLong优化方法。

Result: 改进后的方法显著降低了KV footprint，PruLong比现有方法减少12%的内存占用，同时保持长上下文任务的性能。

Conclusion: 论文通过统一度量标准和方法改进，为未来优化KV缓存提供了清晰方向。

Abstract: Language models handle increasingly long contexts for tasks such as book
summarization, but this leads to growing memory costs for the key-value (KV)
cache. Many prior works have proposed ways of discarding KVs from memory, but
their approaches are tailored to favorable settings, obscuring caveats like
high peak memory and performance degradation, and a fair comparison between
methods is difficult. In this paper, we propose the *KV footprint* as a unified
metric, which accounts for both the amount of KV entries stored and their
lifespan in memory. We evaluate methods based on the smallest footprint they
attain while preserving performance in both long-context understanding and
generation, with context lengths of up to 128K tokens. This metric reveals the
high peak memory of prior KV eviction methods. One class of methods --
*post-fill eviction* -- has a high footprint due to being incompatible with
eviction during pre-filling. We adapt these methods to be able to evict KVs
during pre-filling, achieving substantially lower KV footprints. We then turn
to *recency eviction* methods, wherein we propose PruLong, an end-to-end
optimization method for learning which attention heads need to retain the full
KV cache and which do not. PruLong saves memory while preserving long-context
performance, achieving 12% smaller KV footprint than prior methods while
retaining performance in challenging recall tasks. Our paper clarifies the
complex tangle of long-context inference methods and paves the way for future
development to minimize the KV footprint.

</details>


### [117] [CLEAR-3K: Assessing Causal Explanatory Capabilities in Language Models](https://arxiv.org/abs/2506.17180)
*Naiming Liu,Richard Baraniuk,Shashank Sonkar*

Main category: cs.CL

TL;DR: CLEAR-3K是一个包含3000个断言-推理问题的数据集，用于评估语言模型是否能判断一个陈述是否因果解释另一个陈述。研究发现模型常混淆语义相似性与因果关系，且随着参数增加，模型从过度怀疑转向过度接受因果关系，但性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型在区分语义相关性和真实因果关系方面的能力，为开发具备准确因果推理能力的模型提供基准。

Method: 通过CLEAR-3K数据集测试21种先进语言模型（参数规模从0.5B到72B），分析其对断言-推理问题的表现。

Result: 模型常混淆语义相似性与因果关系；参数增加导致模型从过度怀疑转向过度接受，但性能（MCC）最高仅0.55。

Conclusion: CLEAR-3K为开发具备真实因果推理能力的语言模型提供了重要基准，尽管当前模型表现仍有局限。

Abstract: We introduce CLEAR-3K, a dataset of 3,000 assertion-reasoning questions
designed to evaluate whether language models can determine if one statement
causally explains another. Each question present an assertion-reason pair and
challenge language models to distinguish between semantic relatedness and
genuine causal explanatory relationships. Through comprehensive evaluation of
21 state-of-the-art language models (ranging from 0.5B to 72B parameters), we
identify two fundamental findings. First, language models frequently confuse
semantic similarity with causality, relying on lexical and semantic overlap
instead of inferring actual causal explanatory relationships. Second, as
parameter size increases, models tend to shift from being overly skeptical
about causal relationships to being excessively permissive in accepting them.
Despite this shift, performance measured by the Matthews Correlation
Coefficient plateaus at just 0.55, even for the best-performing models.Hence,
CLEAR-3K provides a crucial benchmark for developing and evaluating genuine
causal reasoning in language models, which is an essential capability for
applications that require accurate assessment of causal relationships.

</details>


### [118] [Towards AI Search Paradigm](https://arxiv.org/abs/2506.17188)
*Yuchen Li,Hengyi Cai,Rui Kong,Xinran Chen,Jiamin Chen,Jun Yang,Haojie Zhang,Jiayi Li,Jiayi Wu,Yiqun Chen,Changle Qu,Keyi Kong,Wenwen Ye,Lixin Su,Xinyu Ma,Long Xia,Daiting Shi,Jiashu Zhao,Haoyi Xiong,Shuaiqiang Wang,Dawei Yin*

Main category: cs.CL

TL;DR: 本文提出了一种名为AI Search Paradigm的下一代搜索系统蓝图，通过四个LLM驱动的智能体（Master、Planner、Executor和Writer）动态适应各种信息需求，从简单查询到复杂推理任务。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够模拟人类信息处理和决策的下一代搜索系统，以应对从简单到复杂的信息需求。

Method: 采用模块化架构，四个智能体通过协调工作流评估查询复杂度、分解问题并执行任务，结合任务规划、工具集成、执行策略等技术。

Result: 提出了一套实现该范式的关键方法，包括任务规划、工具集成、执行策略等，为开发可信赖、自适应和可扩展的AI搜索系统提供了指导。

Conclusion: 该工作为构建下一代AI搜索系统提供了全面的技术基础和优化方案。

Abstract: In this paper, we introduce the AI Search Paradigm, a comprehensive blueprint
for next-generation search systems capable of emulating human information
processing and decision-making. The paradigm employs a modular architecture of
four LLM-powered agents (Master, Planner, Executor and Writer) that dynamically
adapt to the full spectrum of information needs, from simple factual queries to
complex multi-stage reasoning tasks. These agents collaborate dynamically
through coordinated workflows to evaluate query complexity, decompose problems
into executable plans, and orchestrate tool usage, task execution, and content
synthesis. We systematically present key methodologies for realizing this
paradigm, including task planning and tool integration, execution strategies,
aligned and robust retrieval-augmented generation, and efficient LLM inference,
spanning both algorithmic techniques and infrastructure-level optimizations. By
providing an in-depth guide to these foundational components, this work aims to
inform the development of trustworthy, adaptive, and scalable AI search
systems.

</details>


### [119] [Fine-Tuning Lowers Safety and Disrupts Evaluation Consistency](https://arxiv.org/abs/2506.17209)
*Kathleen C. Fraser,Hillary Dawkins,Isar Nejadgholi,Svetlana Kiritchenko*

Main category: cs.CL

TL;DR: 研究发现微调通用大语言模型（LLM）会削弱其安全对齐功能，即使微调数据无害。安全评估结果受实验设置微小变化影响显著，需改进报告方式。


<details>
  <summary>Details</summary>
Motivation: 微调LLM已成为常规操作，但会意外移除模型的安全对齐功能，这对开发者和恶意行为者均构成风险。需可靠的安全评估方法。

Method: 研究安全评估对实验设置微小变化及LLM随机性的鲁棒性，分析微调设置对评估结果的影响。

Result: 实验显示安全评估结果存在显著方差，微调设置的微小变化可能导致结果不一致。

Conclusion: 需改进安全评估的报告方式，以确保结果可比性，并推动解决LLM微调的安全问题。

Abstract: Fine-tuning a general-purpose large language model (LLM) for a specific
domain or task has become a routine procedure for ordinary users. However,
fine-tuning is known to remove the safety alignment features of the model, even
when the fine-tuning data does not contain any harmful content. We consider
this to be a critical failure mode of LLMs due to the widespread uptake of
fine-tuning, combined with the benign nature of the "attack". Most
well-intentioned developers are likely unaware that they are deploying an LLM
with reduced safety. On the other hand, this known vulnerability can be easily
exploited by malicious actors intending to bypass safety guardrails. To make
any meaningful progress in mitigating this issue, we first need reliable and
reproducible safety evaluations. In this work, we investigate how robust a
safety benchmark is to trivial variations in the experimental procedure, and
the stochastic nature of LLMs. Our initial experiments expose surprising
variance in the results of the safety evaluation, even when seemingly
inconsequential changes are made to the fine-tuning setup. Our observations
have serious implications for how researchers in this field should report
results to enable meaningful comparisons in the future.

</details>


### [120] [LaMP-Cap: Personalized Figure Caption Generation With Multimodal Figure Profiles](https://arxiv.org/abs/2506.06561)
*Ho Yin 'Sam' Ng,Ting-Yao Hsu,Aashish Anantha Ramakrishnan,Branislav Kveton,Nedim Lipka,Franck Dernoncourt,Dongwon Lee,Tong Yu,Sungchul Kim,Ryan A. Rossi,Ting-Hao 'Kenneth' Huang*

Main category: cs.CL

TL;DR: LaMP-Cap是一个多模态数据集，用于个性化图标题生成，通过结合图像和文本信息提升标题生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成的图标题通常需要人工修改以匹配作者风格和领域风格，凸显了个性化需求。现有技术多关注纯文本场景，缺乏多模态输入和配置的处理。

Method: 提出LaMP-Cap数据集，包含目标图的图像及其上下文（其他图的图像、标题和相关段落），用于个性化标题生成。实验使用四种LLM验证多模态配置的效果。

Result: 实验表明，使用配置信息能生成更接近作者原始标题的标题。消融研究发现图像配置比文本段落更有帮助。

Conclusion: 多模态配置（尤其是图像）在个性化图标题生成中优于纯文本配置，LaMP-Cap为未来研究提供了有力工具。

Abstract: Figure captions are crucial for helping readers understand and remember a
figure's key message. Many models have been developed to generate these
captions, helping authors compose better quality captions more easily. Yet,
authors almost always need to revise generic AI-generated captions to match
their writing style and the domain's style, highlighting the need for
personalization. Despite language models' personalization (LaMP) advances,
these technologies often focus on text-only settings and rarely address
scenarios where both inputs and profiles are multimodal. This paper introduces
LaMP-Cap, a dataset for personalized figure caption generation with multimodal
figure profiles. For each target figure, LaMP-Cap provides not only the needed
inputs, such as figure images, but also up to three other figures from the same
document--each with its image, caption, and figure-mentioning paragraphs--as a
profile to characterize the context. Experiments with four LLMs show that using
profile information consistently helps generate captions closer to the original
author-written ones. Ablation studies reveal that images in the profile are
more helpful than figure-mentioning paragraphs, highlighting the advantage of
using multimodal profiles over text-only ones.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [121] [A Strong View-Free Baseline Approach for Single-View Image Guided Point Cloud Completion](https://arxiv.org/abs/2506.15747)
*Fangzhou Lin,Zilin Dai,Rigved Sanku,Songlin Hou,Kazunori D Yamada,Haichong K. Zhang,Ziming Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于注意力机制的多分支编码-解码网络，仅使用部分点云输入完成点云补全任务，无需图像引导，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探索单视角图像引导点云补全任务中图像引导的必要性，并提出一种无需图像引导的强基线方法。

Method: 采用基于注意力的多分支编码-解码网络，结合层次自融合机制（跨注意力和自注意力层）整合多流信息。

Result: 在ShapeNet-ViPC数据集上的实验表明，该方法性能优于现有单视角图像引导方法。

Conclusion: 研究为多模态学习在点云补全任务中的发展提供了新见解，代码已开源。

Abstract: The single-view image guided point cloud completion (SVIPC) task aims to
reconstruct a complete point cloud from a partial input with the help of a
single-view image. While previous works have demonstrated the effectiveness of
this multimodal approach, the fundamental necessity of image guidance remains
largely unexamined. To explore this, we propose a strong baseline approach for
SVIPC based on an attention-based multi-branch encoder-decoder network that
only takes partial point clouds as input, view-free. Our hierarchical
self-fusion mechanism, driven by cross-attention and self-attention layers,
effectively integrates information across multiple streams, enriching feature
representations and strengthening the networks ability to capture geometric
structures. Extensive experiments and ablation studies on the ShapeNet-ViPC
dataset demonstrate that our view-free framework performs superiorly to
state-of-the-art SVIPC methods. We hope our findings provide new insights into
the development of multimodal learning in SVIPC. Our demo code will be
available at https://github.com/Zhang-VISLab.

</details>


### [122] [VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service](https://arxiv.org/abs/2506.15755)
*Xiasi Wang,Tianliang Yao,Simin Chen,Runqi Wang,Lei YE,Kuofeng Gao,Yi Huang,Yuan Yao*

Main category: cs.CV

TL;DR: 提出了一种名为VLMInferSlow的新方法，用于在现实黑盒设置中评估视觉语言模型（VLM）的效率鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注VLM的准确性，而效率鲁棒性未被充分探索，尤其是在实时应用和高推理开销的背景下。

Method: VLMInferSlow结合了针对VLM推理的细粒度效率建模，并利用零阶优化搜索对抗样本。

Result: 实验表明，VLMInferSlow生成的对抗图像通过微小扰动，将计算成本提高了128.47%。

Conclusion: 该研究旨在提高社区对VLM效率鲁棒性的认识。

Abstract: Vision-Language Models (VLMs) have demonstrated great potential in real-world
applications. While existing research primarily focuses on improving their
accuracy, the efficiency remains underexplored. Given the real-time demands of
many applications and the high inference overhead of VLMs, efficiency
robustness is a critical issue. However, previous studies evaluate efficiency
robustness under unrealistic assumptions, requiring access to the model
architecture and parameters -- an impractical scenario in ML-as-a-service
settings, where VLMs are deployed via inference APIs. To address this gap, we
propose VLMInferSlow, a novel approach for evaluating VLM efficiency robustness
in a realistic black-box setting. VLMInferSlow incorporates fine-grained
efficiency modeling tailored to VLM inference and leverages zero-order
optimization to search for adversarial examples. Experimental results show that
VLMInferSlow generates adversarial images with imperceptible perturbations,
increasing the computational cost by up to 128.47%. We hope this research
raises the community's awareness about the efficiency robustness of VLMs.

</details>


### [123] [Weakly-supervised VLM-guided Partial Contrastive Learning for Visual Language Navigation](https://arxiv.org/abs/2506.15757)
*Ruoyu Wang,Tong Yu,Junda Wu,Yao Liu,Julian McAuley,Lina Yao*

Main category: cs.CV

TL;DR: 论文提出了一种名为弱监督部分对比学习（WPCL）的方法，解决了视觉语言导航（VLN）中动态视角和预训练模型领域知识不足的问题，同时避免了高计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法依赖预训练模型，但存在动态视角适应差、领域知识不足和高计算成本的问题。

Method: 提出WPCL方法，通过弱监督部分对比学习，将预训练视觉语言模型知识整合到感知过程中，无需微调。

Result: 实验表明，WPCL在多个基准测试中优于基线方法，验证了其有效性、鲁棒性和泛化性。

Conclusion: WPCL在提升VLN性能的同时，保持了计算效率，为动态视角和领域知识问题提供了有效解决方案。

Abstract: Visual Language Navigation (VLN) is a fundamental task within the field of
Embodied AI, focusing on the ability of agents to navigate complex environments
based on natural language instructions. Despite the progress made by existing
methods, these methods often present some common challenges. First, they rely
on pre-trained backbone models for visual perception, which struggle with the
dynamic viewpoints in VLN scenarios. Second, the performance is limited when
using pre-trained LLMs or VLMs without fine-tuning, due to the absence of VLN
domain knowledge. Third, while fine-tuning LLMs and VLMs can improve results,
their computational costs are higher than those without fine-tuning. To address
these limitations, we propose Weakly-supervised Partial Contrastive Learning
(WPCL), a method that enhances an agent's ability to identify objects from
dynamic viewpoints in VLN scenarios by effectively integrating pre-trained VLM
knowledge into the perception process, without requiring VLM fine-tuning. Our
method enhances the agent's ability to interpret and respond to environmental
cues while ensuring computational efficiency. Experimental results have shown
that our method outperforms the baseline methods on multiple benchmarks, which
validate the effectiveness, robustness and generalizability of our method.

</details>


### [124] [Implicit 3D scene reconstruction using deep learning towards efficient collision understanding in autonomous driving](https://arxiv.org/abs/2506.15806)
*Akarshani Ramanayake,Nihal Kodikara*

Main category: cs.CV

TL;DR: 论文提出了一种基于学习的方法，利用LiDAR数据和深度神经网络构建静态符号距离函数（SDF）地图，以解决密集交通环境中3D场景重建的边界精度问题。


<details>
  <summary>Details</summary>
Motivation: 当前技术在密集城市交通环境中难以精确导航，而现有文献中3D场景重建的边界精度问题尚未完全解决。

Method: 采用LiDAR数据和深度神经网络，构建静态SDF地图，替代传统的多边形表示方法。

Result: 初步结果表明，该方法能显著提升碰撞检测性能，尤其在拥挤和动态环境中。

Conclusion: 该研究填补了3D场景重建边界精度问题的空白，为自动驾驶领域提供了更高效的障碍物映射方法。

Abstract: In crowded urban environments where traffic is dense, current technologies
struggle to oversee tight navigation, but surface-level understanding allows
autonomous vehicles to safely assess proximity to surrounding obstacles. 3D or
2D scene mapping of the surrounding objects is an essential task in addressing
the above problem. Despite its importance in dense vehicle traffic conditions,
3D scene reconstruction of object shapes with higher boundary level accuracy is
not yet entirely considered in current literature. The sign distance function
represents any shape through parameters that calculate the distance from any
point in space to the closest obstacle surface, making it more efficient in
terms of storage. In recent studies, researchers have started to formulate
problems with Implicit 3D reconstruction methods in the autonomous driving
domain, highlighting the possibility of using sign distance function to map
obstacles effectively. This research addresses this gap by developing a
learning-based 3D scene reconstruction methodology that leverages LiDAR data
and a deep neural network to build a the static Signed Distance Function (SDF)
maps. Unlike traditional polygonal representations, this approach has the
potential to map 3D obstacle shapes with more boundary-level details. Our
preliminary results demonstrate that this method would significantly enhance
collision detection performance, particularly in congested and dynamic
environments.

</details>


### [125] [ADAM-Dehaze: Adaptive Density-Aware Multi-Stage Dehazing for Improved Object Detection in Foggy Conditions](https://arxiv.org/abs/2506.15837)
*Fatmah AlHindaassi,Mohammed Talha Alam,Fakhri Karray*

Main category: cs.CV

TL;DR: ADAM-Dehaze是一种自适应、密度感知的去雾框架，通过动态路由和优化损失函数，显著提升图像恢复和目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 雾天严重影响视觉信息，对自动驾驶和监控系统等安全关键应用构成挑战。

Method: 使用轻量级HDEN网络分类雾密度，动态路由至三个CORUN分支，结合自适应损失优化物理模型和感知保真度。

Result: 在Cityscapes和RTTS基准测试中，PSNR提升2.1 dB，FADE降低30%，目标检测mAP提升13点，推理时间减少20%。

Conclusion: ADAM-Dehaze证明了针对雾密度进行特定处理及与下游视觉任务无缝集成的重要性。

Abstract: Adverse weather conditions, particularly fog, pose a significant challenge to
autonomous vehicles, surveillance systems, and other safety-critical
applications by severely degrading visual information. We introduce
ADAM-Dehaze, an adaptive, density-aware dehazing framework that jointly
optimizes image restoration and object detection under varying fog intensities.
A lightweight Haze Density Estimation Network (HDEN) classifies each input as
light, medium, or heavy fog. Based on this score, the system dynamically routes
the image through one of three CORUN branches: Light, Medium, or Complex, each
tailored to its haze regime. A novel adaptive loss balances physical-model
coherence and perceptual fidelity, ensuring both accurate defogging and
preservation of fine details. On Cityscapes and the real-world RTTS benchmark,
ADAM-Dehaze improves PSNR by up to 2.1 dB, reduces FADE by 30 percent, and
increases object detection mAP by up to 13 points, while cutting inference time
by 20 percent. These results highlight the importance of intensity-specific
processing and seamless integration with downstream vision tasks. Code
available at: https://github.com/talha-alam/ADAM-Dehaze.

</details>


### [126] [EchoShot: Multi-Shot Portrait Video Generation](https://arxiv.org/abs/2506.15838)
*Jiahao Wang,Hualian Sheng,Sijia Cai,Weizhan Zhang,Caixia Yan,Yachuang Feng,Bing Deng,Jieping Ye*

Main category: cs.CV

TL;DR: EchoShot是一个基于视频扩散模型的多镜头肖像定制框架，通过位置嵌入机制和高质量数据集PortraitGala，实现了身份一致性和内容可控性。


<details>
  <summary>Details</summary>
Motivation: 现实应用需要多镜头生成且身份一致，现有方法局限于单镜头生成。

Method: 提出shot-aware位置嵌入机制，构建PortraitGala数据集，支持基于参考图像的个性化生成和长视频合成。

Result: EchoShot在多镜头肖像视频生成中表现出色，身份一致性和属性可控性优越。

Conclusion: EchoShot可作为通用多镜头视频建模的基础范式。

Abstract: Video diffusion models substantially boost the productivity of artistic
workflows with high-quality portrait video generative capacity. However,
prevailing pipelines are primarily constrained to single-shot creation, while
real-world applications urge for multiple shots with identity consistency and
flexible content controllability. In this work, we propose EchoShot, a native
and scalable multi-shot framework for portrait customization built upon a
foundation video diffusion model. To start with, we propose shot-aware position
embedding mechanisms within video diffusion transformer architecture to model
inter-shot variations and establish intricate correspondence between multi-shot
visual content and their textual descriptions. This simple yet effective design
enables direct training on multi-shot video data without introducing additional
computational overhead. To facilitate model training within multi-shot
scenario, we construct PortraitGala, a large-scale and high-fidelity
human-centric video dataset featuring cross-shot identity consistency and
fine-grained captions such as facial attributes, outfits, and dynamic motions.
To further enhance applicability, we extend EchoShot to perform reference
image-based personalized multi-shot generation and long video synthesis with
infinite shot counts. Extensive evaluations demonstrate that EchoShot achieves
superior identity consistency as well as attribute-level controllability in
multi-shot portrait video generation. Notably, the proposed framework
demonstrates potential as a foundational paradigm for general multi-shot video
modeling.

</details>


### [127] [Assessing the impact of Binarization for Writer Identification in Greek Papyrus](https://arxiv.org/abs/2506.15852)
*Dominic Akt,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 论文研究了希腊纸草文献的作者识别任务，重点探讨了图像二值化预处理对识别性能的影响，比较了传统方法与深度学习方法，并分析了数据增强的作用。


<details>
  <summary>Details</summary>
Motivation: 希腊纸草文献的背景通常不均匀、碎片化且变色，传统二值化方法效果不佳，影响后续作者识别性能。

Method: 比较传统二值化方法与深度学习模型，采用自定义数据增强技术，并在DIBCO 2019数据集上评估性能。

Result: 数据增强对深度学习方法有显著影响，二值化效果与作者识别性能密切相关。

Conclusion: 二值化质量对作者识别至关重要，深度学习方法结合数据增强可提升性能。

Abstract: This paper tackles the task of writer identification for Greek papyri. A
common preprocessing step in writer identification pipelines is image
binarization, which prevents the model from learning background features. This
is challenging in historical documents, in our case Greek papyri, as background
is often non-uniform, fragmented, and discolored with visible fiber structures.
We compare traditional binarization methods to state-of-the-art Deep Learning
(DL) models, evaluating the impact of binarization quality on subsequent writer
identification performance. DL models are trained with and without a custom
data augmentation technique, as well as different model selection criteria are
applied. The performance of these binarization methods, is then systematically
evaluated on the DIBCO 2019 dataset. The impact of binarization on writer
identification is subsequently evaluated using a state-of-the-art approach for
writer identification. The results of this analysis highlight the influence of
data augmentation for DL methods. Furthermore, findings indicate a strong
correlation between binarization effectiveness on papyri documents of DIBCO
2019 and downstream writer identification performance.

</details>


### [128] [Privacy-Preserving in Connected and Autonomous Vehicles Through Vision to Text Transformation](https://arxiv.org/abs/2506.15854)
*Abdolazim Rezaei,Mehdi Sookhak,Ahmad Patooghy*

Main category: cs.CV

TL;DR: 论文提出了一种基于反馈强化学习和视觉语言模型的新框架，用于保护AI摄像头捕获的隐私敏感数据，将图像转换为语义等效的文本描述，显著提升了隐私保护和文本质量。


<details>
  <summary>Details</summary>
Motivation: CAV中的路边单元使用AI摄像头处理隐私敏感数据，传统隐私保护方法（如模糊处理）仍存在隐私泄露风险，需要更有效的解决方案。

Method: 采用反馈强化学习和视觉语言模型，将图像转换为语义等效的文本描述，并通过分层强化学习策略迭代优化生成的文本。

Result: 相比现有方法，隐私保护和文本质量显著提升，独特词数增加约77%，细节密度提升约50%。

Conclusion: 该框架在保护视觉隐私的同时保留了场景相关信息，为隐私敏感数据的处理提供了有效解决方案。

Abstract: Connected and Autonomous Vehicles (CAVs) rely on a range of devices that
often process privacy-sensitive data. Among these, roadside units play a
critical role particularly through the use of AI-equipped (AIE) cameras for
applications such as violation detection. However, the privacy risks associated
with captured imagery remain a major concern, as such data can be misused for
identity theft, profiling, or unauthorized commercial purposes. While
traditional techniques such as face blurring and obfuscation have been applied
to mitigate privacy risks, individual privacy remains at risk, as individuals
can still be tracked using other features such as their clothing. This paper
introduces a novel privacy-preserving framework that leverages feedback-based
reinforcement learning (RL) and vision-language models (VLMs) to protect
sensitive visual information captured by AIE cameras. The main idea is to
convert images into semantically equivalent textual descriptions, ensuring that
scene-relevant information is retained while visual privacy is preserved. A
hierarchical RL strategy is employed to iteratively refine the generated text,
enhancing both semantic accuracy and privacy. Evaluation results demonstrate
significant improvements in both privacy protection and textual quality, with
the Unique Word Count increasing by approximately 77\% and Detail Density by
around 50\% compared to existing approaches.

</details>


### [129] [Visual symbolic mechanisms: Emergent symbol processing in vision language models](https://arxiv.org/abs/2506.15871)
*Rim Assouel,Declan Campbell,Taylor Webb*

Main category: cs.CV

TL;DR: 论文探讨了视觉语言模型（VLMs）如何通过内容无关的空间索引机制解决特征绑定问题，并揭示了其失败原因。


<details>
  <summary>Details</summary>
Motivation: 理解VLMs在特征绑定任务中的表现，尤其是其失败的原因，以改进模型性能。

Method: 研究VLMs中的符号化机制，特别是内容无关的空间索引方案，分析绑定错误的根源。

Result: 发现VLMs通过内容无关的空间索引机制支持特征绑定，绑定错误源于这些机制的失败。

Conclusion: 研究揭示了VLMs中符号化处理的机制，为改进其绑定失败提供了潜在方向。

Abstract: To accurately process a visual scene, observers must bind features together
to represent individual objects. This capacity is necessary, for instance, to
distinguish an image containing a red square and a blue circle from an image
containing a blue square and a red circle. Recent work has found that language
models solve this 'binding problem' via a set of symbol-like,
content-independent indices, but it is unclear whether similar mechanisms are
employed by vision language models (VLMs). This question is especially
relevant, given the persistent failures of VLMs on tasks that require binding.
Here, we identify a set of emergent symbolic mechanisms that support binding in
VLMs via a content-independent, spatial indexing scheme. Moreover, we find that
binding errors can be traced directly to failures in these mechanisms. Taken
together, these results shed light on the mechanisms that support symbol-like
processing in VLMs, and suggest possible avenues for addressing the persistent
binding failures exhibited by these models.

</details>


### [130] [Pediatric Pancreas Segmentation from MRI Scans with Deep Learning](https://arxiv.org/abs/2506.15908)
*Elif Keles,Merve Yazol,Gorkem Durak,Ziliang Hong,Halil Ertugrul Aktas,Zheyuan Zhang,Linkai Peng,Onkar Susladkar,Necati Guzelyel,Oznur Leman Boyunaga,Cemal Yazici,Mark Lowe,Aliye Uc,Ulas Bagci*

Main category: cs.CV

TL;DR: PanSegNet是一种深度学习算法，用于儿童胰腺MRI分割，在健康和疾病状态下表现优异。


<details>
  <summary>Details</summary>
Motivation: 评估和验证PanSegNet在儿童急性胰腺炎、慢性胰腺炎和健康对照中的胰腺分割效果。

Method: 回顾性收集84例MRI扫描，手动分割胰腺，使用DSC和HD95评估PanSegNet性能。

Result: PanSegNet在健康儿童中DSC为88%，AP为81%，CP为80%，与手动分割一致性高。

Conclusion: PanSegNet是首个验证的胰腺MRI分割深度学习工具，表现专家水平，数据开源促进研究。

Abstract: Objective: Our study aimed to evaluate and validate PanSegNet, a deep
learning (DL) algorithm for pediatric pancreas segmentation on MRI in children
with acute pancreatitis (AP), chronic pancreatitis (CP), and healthy controls.
Methods: With IRB approval, we retrospectively collected 84 MRI scans (1.5T/3T
Siemens Aera/Verio) from children aged 2-19 years at Gazi University
(2015-2024). The dataset includes healthy children as well as patients
diagnosed with AP or CP based on clinical criteria. Pediatric and general
radiologists manually segmented the pancreas, then confirmed by a senior
pediatric radiologist. PanSegNet-generated segmentations were assessed using
Dice Similarity Coefficient (DSC) and 95th percentile Hausdorff distance
(HD95). Cohen's kappa measured observer agreement. Results: Pancreas MRI T2W
scans were obtained from 42 children with AP/CP (mean age: 11.73 +/- 3.9 years)
and 42 healthy children (mean age: 11.19 +/- 4.88 years). PanSegNet achieved
DSC scores of 88% (controls), 81% (AP), and 80% (CP), with HD95 values of 3.98
mm (controls), 9.85 mm (AP), and 15.67 mm (CP). Inter-observer kappa was 0.86
(controls), 0.82 (pancreatitis), and intra-observer agreement reached 0.88 and
0.81. Strong agreement was observed between automated and manual volumes (R^2 =
0.85 in controls, 0.77 in diseased), demonstrating clinical reliability.
Conclusion: PanSegNet represents the first validated deep learning solution for
pancreatic MRI segmentation, achieving expert-level performance across healthy
and diseased states. This tool, algorithm, along with our annotated dataset,
are freely available on GitHub and OSF, advancing accessible, radiation-free
pediatric pancreatic imaging and fostering collaborative research in this
underserved domain.

</details>


### [131] [MoiréXNet: Adaptive Multi-Scale Demoiréing with Linear Attention Test-Time Training and Truncated Flow Matching Prior](https://arxiv.org/abs/2506.15929)
*Liangyan Li,Yimo Ning,Kevin Le,Wei Dong,Yunzhe Li,Jun Chen,Xiaohong Liu*

Main category: cs.CV

TL;DR: 提出了一种结合MAP估计和深度学习的图像视频去摩尔纹框架，解决了非线性退化问题。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法无法完全去除摩尔纹或导致结果过于平滑，生成模型在非线性退化中表现不佳。

Method: 提出混合MAP框架，结合监督学习模型（带线性注意力TTT模块）和TFMP先验，提升非线性映射和细节恢复能力。

Result: 框架结合了线性注意力的计算效率和生成模型的细化能力，显著提升了恢复性能。

Conclusion: 该框架有效解决了非线性去摩尔纹问题，同时保留了高频细节并减少了伪影。

Abstract: This paper introduces a novel framework for image and video demoir\'eing by
integrating Maximum A Posteriori (MAP) estimation with advanced deep learning
techniques. Demoir\'eing addresses inherently nonlinear degradation processes,
which pose significant challenges for existing methods.
  Traditional supervised learning approaches either fail to remove moir\'e
patterns completely or produce overly smooth results. This stems from
constrained model capacity and scarce training data, which inadequately
represent the clean image distribution and hinder accurate reconstruction of
ground-truth images. While generative models excel in image restoration for
linear degradations, they struggle with nonlinear cases such as demoir\'eing
and often introduce artifacts.
  To address these limitations, we propose a hybrid MAP-based framework that
integrates two complementary components. The first is a supervised learning
model enhanced with efficient linear attention Test-Time Training (TTT)
modules, which directly learn nonlinear mappings for RAW-to-sRGB demoir\'eing.
The second is a Truncated Flow Matching Prior (TFMP) that further refines the
outputs by aligning them with the clean image distribution, effectively
restoring high-frequency details and suppressing artifacts. These two
components combine the computational efficiency of linear attention with the
refinement abilities of generative models, resulting in improved restoration
performance.

</details>


### [132] [Beyond Audio and Pose: A General-Purpose Framework for Video Synchronization](https://arxiv.org/abs/2506.15937)
*Yosub Shin,Igor Molybog*

Main category: cs.CV

TL;DR: VideoSync是一个独立于特定特征提取方法的视频同步框架，适用于多种场景，并通过新数据集和严格评估框架证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有视频同步方法依赖音频或特定视觉事件，适用性受限，且缺乏通用性和可复现性的基准。

Method: 提出VideoSync框架，不依赖特定特征提取方法，使用新数据集和CNN模型进行同步偏移预测。

Result: VideoSync在公平实验条件下优于现有方法，并揭示了SeSyn-Net的偏见。

Conclusion: VideoSync提高了视频同步的通用性和鲁棒性，适用于实际应用。

Abstract: Video synchronization-aligning multiple video streams capturing the same
event from different angles-is crucial for applications such as reality TV show
production, sports analysis, surveillance, and autonomous systems. Prior work
has heavily relied on audio cues or specific visual events, limiting
applicability in diverse settings where such signals may be unreliable or
absent. Additionally, existing benchmarks for video synchronization lack
generality and reproducibility, restricting progress in the field. In this
work, we introduce VideoSync, a video synchronization framework that operates
independently of specific feature extraction methods, such as human pose
estimation, enabling broader applicability across different content types. We
evaluate our system on newly composed datasets covering single-human,
multi-human, and non-human scenarios, providing both the methodology and code
for dataset creation to establish reproducible benchmarks. Our analysis reveals
biases in prior SOTA work, particularly in SeSyn-Net's preprocessing pipeline,
leading to inflated performance claims. We correct these biases and propose a
more rigorous evaluation framework, demonstrating that VideoSync outperforms
existing approaches, including SeSyn-Net, under fair experimental conditions.
Additionally, we explore various synchronization offset prediction methods,
identifying a convolutional neural network (CNN)-based model as the most
effective. Our findings advance video synchronization beyond domain-specific
constraints, making it more generalizable and robust for real-world
applications.

</details>


### [133] [Polyline Path Masked Attention for Vision Transformer](https://arxiv.org/abs/2506.15940)
*Zhongchen Zhao,Chaodong Xiao,Hui Lin,Qi Xie,Lei Zhang,Deyu Meng*

Main category: cs.CV

TL;DR: 论文提出了一种名为PPMA的方法，结合了ViTs的自注意力机制和Mamba2的结构化掩码，通过改进的2D折线路径扫描策略增强空间邻接关系建模，在多项视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习框架中，全局依赖建模和空间位置建模是核心问题。ViTs和Mamba2分别在视觉和自然语言处理中表现出色，但各有局限性。本文旨在结合两者的优势。

Method: 提出PPMA方法，改进Mamba2的结构化掩码为2D折线路径掩码，并将其嵌入ViTs的自注意力机制中，以显式建模空间邻接关系。

Result: 在图像分类、目标检测和分割等任务中，PPMA模型优于现有方法，例如在ADE20K分割任务中mIoU提升0.3%-1.3%。

Conclusion: PPMA成功结合了ViTs和Mamba2的优势，显著提升了视觉任务的性能，展示了多架构融合的潜力。

Abstract: Global dependency modeling and spatial position modeling are two core issues
of the foundational architecture design in current deep learning frameworks.
Recently, Vision Transformers (ViTs) have achieved remarkable success in
computer vision, leveraging the powerful global dependency modeling capability
of the self-attention mechanism. Furthermore, Mamba2 has demonstrated its
significant potential in natural language processing tasks by explicitly
modeling the spatial adjacency prior through the structured mask. In this
paper, we propose Polyline Path Masked Attention (PPMA) that integrates the
self-attention mechanism of ViTs with an enhanced structured mask of Mamba2,
harnessing the complementary strengths of both architectures. Specifically, we
first ameliorate the traditional structured mask of Mamba2 by introducing a 2D
polyline path scanning strategy and derive its corresponding structured mask,
polyline path mask, which better preserves the adjacency relationships among
image tokens. Notably, we conduct a thorough theoretical analysis on the
structural characteristics of the proposed polyline path mask and design an
efficient algorithm for the computation of the polyline path mask. Next, we
embed the polyline path mask into the self-attention mechanism of ViTs,
enabling explicit modeling of spatial adjacency prior. Extensive experiments on
standard benchmarks, including image classification, object detection, and
segmentation, demonstrate that our model outperforms previous state-of-the-art
approaches based on both state-space models and Transformers. For example, our
proposed PPMA-T/S/B models achieve 48.7%/51.1%/52.3% mIoU on the ADE20K
semantic segmentation task, surpassing RMT-T/S/B by 0.7%/1.3%/0.3%,
respectively. Code is available at https://github.com/zhongchenzhao/PPMA.

</details>


### [134] [Heterogeneous-Modal Unsupervised Domain Adaptation via Latent Space Bridging](https://arxiv.org/abs/2506.15971)
*Jiawen Yang,Shuhao Chen,Yucong Duan,Ke Tang,Yu Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种新的异构模态无监督域适应（HMUDA）设置，并通过潜在空间桥接（LSB）框架解决了跨模态知识迁移问题。


<details>
  <summary>Details</summary>
Motivation: 源域和目标域属于完全不同的模态时，传统无监督域适应方法效果受限。

Method: 提出LSB框架，采用双分支架构，结合特征一致性损失和域对齐损失。

Result: 在六个基准数据集上，LSB实现了最先进的性能。

Conclusion: LSB框架有效解决了跨模态域适应问题。

Abstract: Unsupervised domain adaptation (UDA) methods effectively bridge domain gaps
but become struggled when the source and target domains belong to entirely
distinct modalities. To address this limitation, we propose a novel setting
called Heterogeneous-Modal Unsupervised Domain Adaptation (HMUDA), which
enables knowledge transfer between completely different modalities by
leveraging a bridge domain containing unlabeled samples from both modalities.
To learn under the HMUDA setting, we propose Latent Space Bridging (LSB), a
specialized framework designed for the semantic segmentation task.
Specifically, LSB utilizes a dual-branch architecture, incorporating a feature
consistency loss to align representations across modalities and a domain
alignment loss to reduce discrepancies between class centroids across domains.
Extensive experiments conducted on six benchmark datasets demonstrate that LSB
achieves state-of-the-art performance.

</details>


### [135] [LBMamba: Locally Bi-directional Mamba](https://arxiv.org/abs/2506.15976)
*Jingwei Zhang,Xi Han,Hong Qin,Mahdi S. Hosseini,Dimitris Samaras*

Main category: cs.CV

TL;DR: LBMamba是一种局部双向状态空间模型块，通过在正向选择性扫描中嵌入轻量级局部反向扫描，避免了传统双向扫描的计算负担。基于LBMamba的LBVim视觉骨干网络通过交替扫描方向恢复全局感受野，显著提升了性能与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: Mamba的单向性限制了其在计算机视觉中的应用，传统双向扫描方法虽然解决了这一问题，但计算成本翻倍。LBMamba旨在消除额外扫描，保持高效性。

Method: 提出LBMamba块，在正向选择性扫描中嵌入局部反向扫描，完全在每线程寄存器中执行。基于此构建LBVim骨干网络，每两层交替扫描方向以恢复全局感受野。

Result: LBVim在多个数据集上表现优异：ImageNet-1K分类准确率提升0.8%-1.6%，ADE20K语义分割mIoU提升0.6%-2.7%，COCO检测APb和APm分别提升0.9%和1.1%。在病理图像分类中，AUC、F1和准确率分别提升3.06%、3.39%和1.67%。

Conclusion: LBMamba和LBVim通过局部双向扫描设计，显著提升了性能与效率的平衡，适用于多种视觉任务。

Abstract: Mamba, a State Space Model (SSM) that accelerates training by recasting
recurrence as a parallel selective scan, has recently emerged as a
linearly-scaling, efficient alternative to self-attention. Because of its
unidirectional nature, each state in Mamba only has information of its previous
states and is blind to states after. Current Mamba-based computer-vision
methods typically overcome this limitation by augmenting Mamba's global forward
scan with a global backward scan, forming a bi-directional scan that restores a
full receptive field. However, this operation doubles the computational load,
eroding much of the efficiency advantage that originally Mamba have. To
eliminate this extra scans, we introduce LBMamba, a locally bi-directional SSM
block that embeds a lightweight locally backward scan inside the forward
selective scan and executes it entirely in per-thread registers. Building on
LBMamba, we present LBVim, a scalable vision backbone that alternates scan
directions every two layers to recover a global receptive field without extra
backward sweeps. We validate the versatility of our approach on both natural
images and whole slide images (WSIs). We show that our LBVim constantly offers
a superior performance-throughput trade-off. That is under the same throughput,
LBVim achieves 0.8% to 1.6% higher top-1 accuracy on the ImageNet-1K
classification dataset, 0.6% to 2.7% higher mIoU on the ADE20K semantic
segmentation dataset, 0.9% higher APb and 1.1% higher APm on the COCO detection
dataset. We also integrate LBMamba into the SOTA pathology multiple instance
learning (MIL) approach, MambaMIL, which uses single directional scan.
Experiments on 3 public WSI classification datasets for show that our method
achieves a relative improvement of up to 3.06% better AUC, 3.39% better F1,
1.67% better accuracy.

</details>


### [136] [Towards Classifying Histopathological Microscope Images as Time Series Data](https://arxiv.org/abs/2506.15977)
*Sungrae Hong,Hyeongmin Park,Youngsin Ko,Sol Lee,Bryan Wong,Mun Yong Yi*

Main category: cs.CV

TL;DR: 提出一种将显微镜图像作为时间序列分类的新方法，利用动态时间规整（DTW）和注意力池化，解决了手动采集和弱标签的挑战，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 显微镜病理图像在癌症诊断中至关重要，但深度学习社区对其关注不足。本文旨在解决其手动采集和弱标签带来的独特挑战。

Method: 将图像序列拟合为固定长度目标，使用动态时间规整（DTW）和注意力池化进行类别预测。

Result: 通过对比基线方法和多种推理策略，验证了方法的有效性，并通过消融实验验证了各组件的作用。

Conclusion: 该方法不仅将显微镜图像纳入分析，还将其性能提升至可信水平，为医学图像分析做出贡献。

Abstract: As the frontline data for cancer diagnosis, microscopic pathology images are
fundamental for providing patients with rapid and accurate treatment. However,
despite their practical value, the deep learning community has largely
overlooked their usage. This paper proposes a novel approach to classifying
microscopy images as time series data, addressing the unique challenges posed
by their manual acquisition and weakly labeled nature. The proposed method fits
image sequences of varying lengths to a fixed-length target by leveraging
Dynamic Time-series Warping (DTW). Attention-based pooling is employed to
predict the class of the case simultaneously. We demonstrate the effectiveness
of our approach by comparing performance with various baselines and showcasing
the benefits of using various inference strategies in achieving stable and
reliable results. Ablation studies further validate the contribution of each
component. Our approach contributes to medical image analysis by not only
embracing microscopic images but also lifting them to a trustworthy level of
performance.

</details>


### [137] [Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization](https://arxiv.org/abs/2506.15980)
*Cong Wang,Zexuan Deng,Zhiwei Jiang,Fei Shen,Yafeng Yin,Shiwei Gan,Zifeng Cheng,Shiping Ge,Qing Gu*

Main category: cs.CV

TL;DR: SignViP提出了一种新的手语视频生成框架，通过多细粒度条件提升生成质量，采用离散标记化和扩散模型实现高效生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一粗粒度条件（如骨架序列），限制了生成视频的自然性和表现力，SignViP旨在解决这一问题。

Method: SignViP包含三个核心组件：1）联合训练的视频扩散模型和多条件编码器；2）FSQ自编码器用于离散标记化；3）多条件标记翻译器将文本转换为离散标记。

Result: 实验表明SignViP在视频质量、时间一致性和语义保真度上达到最优性能。

Conclusion: SignViP通过多细粒度条件和离散标记化显著提升了手语视频生成的质量和表现力。

Abstract: Sign Language Video Generation (SLVG) seeks to generate identity-preserving
sign language videos from spoken language texts. Existing methods primarily
rely on the single coarse condition (\eg, skeleton sequences) as the
intermediary to bridge the translation model and the video generation model,
which limits both the naturalness and expressiveness of the generated videos.
To overcome these limitations, we propose SignViP, a novel SLVG framework that
incorporates multiple fine-grained conditions for improved generation fidelity.
Rather than directly translating error-prone high-dimensional conditions,
SignViP adopts a discrete tokenization paradigm to integrate and represent
fine-grained conditions (\ie, fine-grained poses and 3D hands). SignViP
contains three core components. (1) Sign Video Diffusion Model is jointly
trained with a multi-condition encoder to learn continuous embeddings that
encapsulate fine-grained motion and appearance. (2) Finite Scalar Quantization
(FSQ) Autoencoder is further trained to compress and quantize these embeddings
into discrete tokens for compact representation of the conditions. (3)
Multi-Condition Token Translator is trained to translate spoken language text
to discrete multi-condition tokens. During inference, Multi-Condition Token
Translator first translates the spoken language text into discrete
multi-condition tokens. These tokens are then decoded to continuous embeddings
by FSQ Autoencoder, which are subsequently injected into Sign Video Diffusion
Model to guide video generation. Experimental results show that SignViP
achieves state-of-the-art performance across metrics, including video quality,
temporal coherence, and semantic fidelity. The code is available at
https://github.com/umnooob/signvip/.

</details>


### [138] [Adversarial Attacks and Detection in Visual Place Recognition for Safer Robot Navigation](https://arxiv.org/abs/2506.15988)
*Connor Malone,Owen Claxton,Iman Shames,Michael Milford*

Main category: cs.CV

TL;DR: 论文分析了视觉地点识别（VPR）系统对对抗攻击的脆弱性，提出了一种结合对抗攻击检测器（AAD）和主动导航决策的闭环系统框架，并展示了其性能提升。


<details>
  <summary>Details</summary>
Motivation: VPR系统在对抗攻击下表现脆弱，可能导致机器人导航灾难性后果，因此需要研究防御措施。

Method: 分析了四种常见对抗攻击和四种VPR特有攻击，提出闭环系统框架，结合AAD和导航决策，并通过实验验证性能。

Result: 实验显示，AAD能显著提升性能（如沿轨定位误差减少50%），并首次研究了FGSM攻击对VPR的效果。

Conclusion: 研究强调了AAD在真实系统中的必要性，并为系统设计提供了量化要求。

Abstract: Stand-alone Visual Place Recognition (VPR) systems have little defence
against a well-designed adversarial attack, which can lead to disastrous
consequences when deployed for robot navigation. This paper extensively
analyzes the effect of four adversarial attacks common in other perception
tasks and four novel VPR-specific attacks on VPR localization performance. We
then propose how to close the loop between VPR, an Adversarial Attack Detector
(AAD), and active navigation decisions by demonstrating the performance benefit
of simulated AADs in a novel experiment paradigm -- which we detail for the
robotics community to use as a system framework. In the proposed experiment
paradigm, we see the addition of AADs across a range of detection accuracies
can improve performance over baseline; demonstrating a significant improvement
-- such as a ~50% reduction in the mean along-track localization error -- can
be achieved with True Positive and False Positive detection rates of only 75%
and up to 25% respectively. We examine a variety of metrics including:
Along-Track Error, Percentage of Time Attacked, Percentage of Time in an
`Unsafe' State, and Longest Continuous Time Under Attack. Expanding further on
these results, we provide the first investigation into the efficacy of the Fast
Gradient Sign Method (FGSM) adversarial attack for VPR. The analysis in this
work highlights the need for AADs in real-world systems for trustworthy
navigation, and informs quantitative requirements for system design.

</details>


### [139] [DIGMAPPER: A Modular System for Automated Geologic Map Digitization](https://arxiv.org/abs/2506.16006)
*Weiwei Duan,Michael P. Gerlek,Steven N. Minton,Craig A. Knoblock,Fandel Lin,Theresa Chen,Leeje Jang,Sofia Kirsanova,Zekun Li,Yijun Lin,Yao-Yi Chiang*

Main category: cs.CV

TL;DR: DIGMAPPER是一个自动化地质地图数字化的系统，采用模块化、可扩展的架构，结合深度学习模型，解决了传统数字化耗时的问题。


<details>
  <summary>Details</summary>
Motivation: 地质地图中的地理信息对可再生能源、电动汽车和国家安全至关重要，但传统数字化方法效率低下。

Method: 系统采用docker化、工作流编排架构，结合深度学习模型进行地图布局分析、特征提取和地理参考，并利用上下文学习、合成数据生成和Transformer模型解决数据不足和复杂视觉内容的挑战。

Result: 在DARPA-USGS数据集上的评估显示，系统在多类特征提取和地理参考方面表现优异。

Conclusion: DIGMAPPER显著提升了地质地图数字化的效率，支持国家关键矿物评估和更广泛的地球科学应用。

Abstract: Historical geologic maps contain rich geospatial information, such as rock
units, faults, folds, and bedding planes, that is critical for assessing
mineral resources essential to renewable energy, electric vehicles, and
national security. However, digitizing maps remains a labor-intensive and
time-consuming task. We present DIGMAPPER, a modular, scalable system developed
in collaboration with the United States Geological Survey (USGS) to automate
the digitization of geologic maps. DIGMAPPER features a fully dockerized,
workflow-orchestrated architecture that integrates state-of-the-art deep
learning models for map layout analysis, feature extraction, and
georeferencing. To overcome challenges such as limited training data and
complex visual content, our system employs innovative techniques, including
in-context learning with large language models, synthetic data generation, and
transformer-based models. Evaluations on over 100 annotated maps from the
DARPA-USGS dataset demonstrate high accuracy across polygon, line, and point
feature extraction, and reliable georeferencing performance. Deployed at USGS,
DIGMAPPER significantly accelerates the creation of analysis-ready geospatial
datasets, supporting national-scale critical mineral assessments and broader
geoscientific applications.

</details>


### [140] [EndoMUST: Monocular Depth Estimation for Robotic Endoscopy via End-to-end Multi-step Self-supervised Training](https://arxiv.org/abs/2506.16017)
*Liangjing Shao,Linxin Bai,Chenkang Du,Xinrong Chen*

Main category: cs.CV

TL;DR: 提出了一种多步微调框架，用于内窥镜场景中的自监督深度估计，解决了光照变化和纹理稀疏问题，并在SCARED和Hamlyn数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 内窥镜场景中的光照变化和稀疏纹理对深度估计和运动估计提出了挑战，现有方法在多个模块的训练策略上仍有不足。

Method: 提出了一种多步微调框架，包括光流注册、多尺度图像分解和多变换对齐三个步骤，每个步骤仅训练相关网络以避免信息干扰。

Result: 在SCARED数据集上实现了自监督深度估计的最佳性能，在Hamlyn数据集上实现了零样本深度估计，误差降低了4%~10%。

Conclusion: 该方法通过多步微调有效解决了内窥镜场景中的深度估计问题，并在多个数据集上验证了其优越性。

Abstract: Monocular depth estimation and ego-motion estimation are significant tasks
for scene perception and navigation in stable, accurate and efficient
robot-assisted endoscopy. To tackle lighting variations and sparse textures in
endoscopic scenes, multiple techniques including optical flow, appearance flow
and intrinsic image decomposition have been introduced into the existing
methods. However, the effective training strategy for multiple modules are
still critical to deal with both illumination issues and information
interference for self-supervised depth estimation in endoscopy. Therefore, a
novel framework with multistep efficient finetuning is proposed in this work.
In each epoch of end-to-end training, the process is divided into three steps,
including optical flow registration, multiscale image decomposition and
multiple transformation alignments. At each step, only the related networks are
trained without interference of irrelevant information. Based on
parameter-efficient finetuning on the foundation model, the proposed method
achieves state-of-the-art performance on self-supervised depth estimation on
SCARED dataset and zero-shot depth estimation on Hamlyn dataset, with
4\%$\sim$10\% lower error. The evaluation code of this work has been published
on https://github.com/BaymaxShao/EndoMUST.

</details>


### [141] [PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models](https://arxiv.org/abs/2506.16054)
*Tianchen Zhao,Ke Hong,Xinhao Yang,Xuefeng Xiao,Huixia Li,Feng Ling,Ruiqi Xie,Siqi Chen,Hongyu Zhu,Yichong Zhang,Yu Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为PAROAttention的新方法，通过重新组织注意力模式来降低视觉生成中的计算和内存成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 视觉生成中注意力机制的二次复杂度导致高计算和内存成本，尤其是在高分辨率图像或多帧视频生成中。现有稀疏化和量化技术面临低密度和低比特宽度的挑战。

Method: 提出PARO技术，通过重新组织注意力模式为硬件友好的块状模式，简化并增强稀疏化和量化。

Result: PAROAttention在低密度（20%-30%）和低比特宽度（INT8/INT4）下实现无损性能，端到端延迟加速1.9x至2.7x。

Conclusion: PAROAttention通过统一注意力模式，显著提升了视觉生成的效率，同时保持性能。

Abstract: In visual generation, the quadratic complexity of attention mechanisms
results in high memory and computational costs, especially for longer token
sequences required in high-resolution image or multi-frame video generation. To
address this, prior research has explored techniques such as sparsification and
quantization. However, these techniques face significant challenges under low
density and reduced bitwidths. Through systematic analysis, we identify that
the core difficulty stems from the dispersed and irregular characteristics of
visual attention patterns. Therefore, instead of introducing specialized
sparsification and quantization design to accommodate such patterns, we propose
an alternative strategy: *reorganizing* the attention pattern to alleviate the
challenges. Inspired by the local aggregation nature of visual feature
extraction, we design a novel **Pattern-Aware token ReOrdering (PARO)**
technique, which unifies the diverse attention patterns into a
hardware-friendly block-wise pattern. This unification substantially simplifies
and enhances both sparsification and quantization. We evaluate the
performance-efficiency trade-offs of various design choices and finalize a
methodology tailored for the unified pattern. Our approach, **PAROAttention**,
achieves video and image generation with lossless metrics, and nearly identical
results from full-precision (FP) baselines, while operating at notably lower
density (~20%-30%) and bitwidth (**INT8/INT4**), achieving a **1.9x** to
**2.7x** end-to-end latency speedup.

</details>


### [142] [Stepping Out of Similar Semantic Space for Open-Vocabulary Segmentation](https://arxiv.org/abs/2506.16058)
*Yong Liu,SongLi Wu,Sule Bai,Jiahao Wang,Yitong Wang,Yansong Tang*

Main category: cs.CV

TL;DR: 论文提出新基准OpenBench以评估开放词汇分割模型的真实能力，并提出了改进方法OVSNet。


<details>
  <summary>Details</summary>
Motivation: 现有测试集无法准确衡量模型对开放词汇概念的理解能力，因其语义空间与训练空间相似。

Method: 提出新基准OpenBench，并开发OVSNet方法，通过异构特征融合和训练空间扩展提升性能。

Result: OVSNet在现有数据集和OpenBench上均取得最佳性能。

Conclusion: OpenBench和OVSNet的有效性通过分析得到验证。

Abstract: Open-vocabulary segmentation aims to achieve segmentation of arbitrary
categories given unlimited text inputs as guidance. To achieve this, recent
works have focused on developing various technical routes to exploit the
potential of large-scale pre-trained vision-language models and have made
significant progress on existing benchmarks. However, we find that existing
test sets are limited in measuring the models' comprehension of
``open-vocabulary" concepts, as their semantic space closely resembles the
training space, even with many overlapping categories. To this end, we present
a new benchmark named OpenBench that differs significantly from the training
semantics. It is designed to better assess the model's ability to understand
and segment a wide range of real-world concepts. When testing existing methods
on OpenBench, we find that their performance diverges from the conclusions
drawn on existing test sets. In addition, we propose a method named OVSNet to
improve the segmentation performance for diverse and open scenarios. Through
elaborate fusion of heterogeneous features and cost-free expansion of the
training space, OVSNet achieves state-of-the-art results on both existing
datasets and our proposed OpenBench. Corresponding analysis demonstrate the
soundness and effectiveness of our proposed benchmark and method.

</details>


### [143] [STAR-Pose: Efficient Low-Resolution Video Human Pose Estimation via Spatial-Temporal Adaptive Super-Resolution](https://arxiv.org/abs/2506.16061)
*Yucheng Jin,Jinyan Chen,Ziyue He,Baojun Han,Furan An*

Main category: cs.CV

TL;DR: STAR-Pose是一种针对低分辨率视频中人体姿态估计的空间-时间自适应超分辨率框架，通过改进的Transformer和自适应融合模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 低分辨率视频中的人体姿态估计是计算机视觉中的基础挑战，传统方法因计算成本高或假设高质量输入而受限。

Method: 提出STAR-Pose框架，结合空间-时间Transformer和自适应融合模块，设计姿态感知复合损失函数。

Result: 在多个主流数据集上表现优异，64x48分辨率下mAP提升5.2%，推理速度快2.8x至4.4x。

Conclusion: STAR-Pose在低分辨率视频中高效且准确地实现了人体姿态估计。

Abstract: Human pose estimation in low-resolution videos presents a fundamental
challenge in computer vision. Conventional methods either assume high-quality
inputs or employ computationally expensive cascaded processing, which limits
their deployment in resource-constrained environments. We propose STAR-Pose, a
spatial-temporal adaptive super-resolution framework specifically designed for
video-based human pose estimation. Our method features a novel spatial-temporal
Transformer with LeakyReLU-modified linear attention, which efficiently
captures long-range temporal dependencies. Moreover, it is complemented by an
adaptive fusion module that integrates parallel CNN branch for local texture
enhancement. We also design a pose-aware compound loss to achieve task-oriented
super-resolution. This loss guides the network to reconstruct structural
features that are most beneficial for keypoint localization, rather than
optimizing purely for visual quality. Extensive experiments on several
mainstream video HPE datasets demonstrate that STAR-Pose outperforms existing
approaches. It achieves up to 5.2% mAP improvement under extremely
low-resolution (64x48) conditions while delivering 2.8x to 4.4x faster
inference than cascaded approaches.

</details>


### [144] [TD3Net: A Temporal Densely Connected Multi-Dilated Convolutional Network for Lipreading](https://arxiv.org/abs/2506.16073)
*Byung Hoon Lee,Wooseok Shin,Sung Won Han*

Main category: cs.CV

TL;DR: 论文提出了一种名为TD3Net的唇读后端架构，结合密集跳跃连接和多扩张时间卷积，以解决传统TCN中因盲点导致的信息丢失问题。实验表明，TD3Net在性能和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统TCN在唇读任务中因盲点导致信息丢失，限制了性能。

Method: 提出TD3Net，结合密集跳跃连接和多扩张时间卷积，扩大感受野并消除盲点。

Result: 在LRW和LRW-1000数据集上达到SOTA性能，参数和计算量更少。

Conclusion: TD3Net有效利用多样时间特征，保持时间连续性，提升唇读系统性能。

Abstract: The word-level lipreading approach typically employs a two-stage framework
with separate frontend and backend architectures to model dynamic lip
movements. Each component has been extensively studied, and in the backend
architecture, temporal convolutional networks (TCNs) have been widely adopted
in state-of-the-art methods. Recently, dense skip connections have been
introduced in TCNs to mitigate the limited density of the receptive field,
thereby improving the modeling of complex temporal representations. However,
their performance remains constrained owing to potential information loss
regarding the continuous nature of lip movements, caused by blind spots in the
receptive field. To address this limitation, we propose TD3Net, a temporal
densely connected multi-dilated convolutional network that combines dense skip
connections and multi-dilated temporal convolutions as the backend
architecture. TD3Net covers a wide and dense receptive field without blind
spots by applying different dilation factors to skip-connected features.
Experimental results on a word-level lipreading task using two large publicly
available datasets, Lip Reading in the Wild (LRW) and LRW-1000, indicate that
the proposed method achieves performance comparable to state-of-the-art
methods. It achieved higher accuracy with fewer parameters and lower
floating-point operations compared to existing TCN-based backend architectures.
Moreover, visualization results suggest that our approach effectively utilizes
diverse temporal features while preserving temporal continuity, presenting
notable advantages in lipreading systems. The code is available at our GitHub
repository:
https://github.com/Leebh-kor/TD3Net-A-Temporal-Densely-Connected-Multi-dilated-Convolutional-Network-for-Lipreading

</details>


### [145] [PR-DETR: Injecting Position and Relation Prior for Dense Video Captioning](https://arxiv.org/abs/2506.16082)
*Yizhe Li,Sanping Zhou,Zheng Qin,Le Wang*

Main category: cs.CV

TL;DR: PR-DETR框架通过显式位置和关系先验改进密集视频描述任务，提升定位和描述质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的方法隐式学习事件位置和语义，依赖大量训练数据且性能受限。

Method: 提出PR-DETR框架，引入位置锚定查询和事件关系编码器，显式注入位置和关系先验。

Result: 在ActivityNet Captions和YouCook2数据集上表现优异，验证了先验的有效性。

Conclusion: 显式位置和关系先验显著提升密集视频描述任务的性能。

Abstract: Dense video captioning is a challenging task that aims to localize and
caption multiple events in an untrimmed video. Recent studies mainly follow the
transformer-based architecture to jointly perform the two sub-tasks, i.e.,
event localization and caption generation, in an end-to-end manner. Based on
the general philosophy of detection transformer, these methods implicitly learn
the event locations and event semantics, which requires a large amount of
training data and limits the model's performance in practice. In this paper, we
propose a novel dense video captioning framework, named PR-DETR, which injects
the explicit position and relation prior into the detection transformer to
improve the localization accuracy and caption quality, simultaneously. On the
one hand, we first generate a set of position-anchored queries to provide the
scene-specific position and semantic information about potential events as
position prior, which serves as the initial event search regions to eliminate
the implausible event proposals. On the other hand, we further design an event
relation encoder to explicitly calculate the relationship between event
boundaries as relation prior to guide the event interaction to improve the
semantic coherence of the captions. Extensive ablation studies are conducted to
verify the effectiveness of the position and relation prior. Experimental
results also show the competitive performance of our method on ActivityNet
Captions and YouCook2 datasets.

</details>


### [146] [AutoV: Learning to Retrieve Visual Prompt for Large Vision-Language Models](https://arxiv.org/abs/2506.16112)
*Yuan Zhang,Chun-Kai Fan,Tao Huang,Ming Lu,Sicheng Yu,Junwen Pan,Kuan Cheng,Qi She,Shanghang Zhang*

Main category: cs.CV

TL;DR: AutoV是一种自动选择最优视觉提示的方法，通过训练模型从候选提示中选择最佳选项，显著提升大型视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉提示方法依赖人工设计，效率低且效果不佳，需要一种自动优化视觉提示的方法。

Method: AutoV通过自动数据收集和标注流程，利用预训练模型评估并排序视觉提示，训练模型自动选择最优提示。

Result: 实验表明，AutoV显著提升了多种LVLM的性能，如在LLaVA和Qwen2.5-VL上分别提高了1.7%和1.9%的准确率。

Conclusion: AutoV是一种高效的视觉提示优化方法，具有广泛的应用潜力。

Abstract: Inspired by text prompts in large language models (LLMs), visual prompts have
been explored to enhance the reasoning capabilities of large vision-language
models (LVLMs). Current methods design heuristic visual prompts, such as
overlaying a text-query-guided attention heatmap on the original input image.
However, designing effective prompts manually is challenging and
time-consuming, and it often fails to explore the benefits of different visual
prompts, leading to sub-optimal performance. To this end, we propose
\textbf{AutoV} that learns to automatically select the optimal visual prompt
from various candidates based on given textual queries and the input image. To
train AutoV, we developed an automatic data collection and labeling pipeline
that evaluates various visual prompts with a pre-trained LVLM. We input a set
of visual prompts into the LVLM and rank them according to the prediction
losses generated by the model. Using the ranking as a supervision signal, we
train AutoV to automatically choose the optimal visual prompt from various
visual prompts for LVLMs. Experimental results indicate that AutoV enhances the
performance of various LVLMs across multiple popular image understanding tasks.
For instance, LLaVA-OV with AutoV achieves $\textbf{1.7}\%$ accuracy gain on
LLaVA$^{\text{Wild}}$, and AutoV boosts Qwen2.5-VL by $\textbf{1.9}\%$ on MMMU,
highlighting its potential as an optimal visual prompting method for LVLMs.

</details>


### [147] [FastInit: Fast Noise Initialization for Temporally Consistent Video Generation](https://arxiv.org/abs/2506.16119)
*Chengyu Bai,Yuming Li,Zhongyu Zhao,Jintao Chen,Peidong Jia,Qi She,Ming Lu,Shanghang Zhang*

Main category: cs.CV

TL;DR: FastInit提出了一种快速噪声初始化方法，通过单次前向传播生成优化的噪声，显著提高了视频生成的效率和时序一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法如FreeInit通过迭代优化噪声提高了时序一致性，但计算成本高，FastInit旨在解决这一问题。

Method: FastInit训练了一个视频噪声预测网络（VNPNet），输入随机噪声和文本提示，单次生成优化的噪声。

Result: 实验表明，FastInit显著提升了生成视频的质量和时序一致性，且计算成本低。

Conclusion: FastInit为视频生成提供了一种高效且实用的解决方案，可直接应用于推理阶段。

Abstract: Video generation has made significant strides with the development of
diffusion models; however, achieving high temporal consistency remains a
challenging task. Recently, FreeInit identified a training-inference gap and
introduced a method to iteratively refine the initial noise during inference.
However, iterative refinement significantly increases the computational cost
associated with video generation. In this paper, we introduce FastInit, a fast
noise initialization method that eliminates the need for iterative refinement.
FastInit learns a Video Noise Prediction Network (VNPNet) that takes random
noise and a text prompt as input, generating refined noise in a single forward
pass. Therefore, FastInit greatly enhances the efficiency of video generation
while achieving high temporal consistency across frames. To train the VNPNet,
we create a large-scale dataset consisting of pairs of text prompts, random
noise, and refined noise. Extensive experiments with various text-to-video
models show that our method consistently improves the quality and temporal
consistency of the generated videos. FastInit not only provides a substantial
improvement in video generation but also offers a practical solution that can
be applied directly during inference. The code and dataset will be released.

</details>


### [148] [Neurosymbolic Object-Centric Learning with Distant Supervision](https://arxiv.org/abs/2506.16129)
*Stefano Colamonaco,David Debot,Giuseppe Marra*

Main category: cs.CV

TL;DR: 论文提出了一种直接从原始非结构化感知数据中学习对象中心表示的方法，仅需远监督，并通过神经符号模型DeepObjectLog实现。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖对象级监督或预定义输入分解，限制了泛化能力。

Method: 提出神经符号框架，结合感知模块和基于概率逻辑编程的符号推理层。

Result: 在多种泛化场景中表现优于神经和神经符号基线。

Conclusion: 该方法通过符号推理引入新学习信号，有效发现输入中有意义的对象。

Abstract: Relational learning enables models to generalize across structured domains by
reasoning over objects and their interactions. While recent advances in
neurosymbolic reasoning and object-centric learning bring us closer to this
goal, existing systems rely either on object-level supervision or on a
predefined decomposition of the input into objects. In this work, we propose a
neurosymbolic formulation for learning object-centric representations directly
from raw unstructured perceptual data and using only distant supervision. We
instantiate this approach in DeepObjectLog, a neurosymbolic model that
integrates a perceptual module, which extracts relevant object representations,
with a symbolic reasoning layer based on probabilistic logic programming. By
enabling sound probabilistic logical inference, the symbolic component
introduces a novel learning signal that further guides the discovery of
meaningful objects in the input. We evaluate our model across a diverse range
of generalization settings, including unseen object compositions, unseen tasks,
and unseen number of objects. Experimental results show that our method
outperforms neural and neurosymbolic baselines across the tested settings.

</details>


### [149] [GRPO-CARE: Consistency-Aware Reinforcement Learning for Multimodal Reasoning](https://arxiv.org/abs/2506.16141)
*Yi Chen,Yuying Ge,Rui Wang,Yixiao Ge,Junhao Cheng,Ying Shan,Xihui Liu*

Main category: cs.CV

TL;DR: 论文提出GRPO-CARE框架，通过双奖励机制提升多模态大语言模型的推理一致性和答案准确性，并在SEED-Bench-R1基准上验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如GRPO）在多模态大语言模型（MLLMs）中的应用尚未探索，且缺乏严格的评估基准。

Method: 提出GRPO-CARE框架，结合基础奖励和自适应一致性奖励，优化答案正确性和推理逻辑一致性。

Result: GRPO-CARE在SEED-Bench-R1上表现优于标准GRPO，性能提升6.7%，一致性提高24.5%。

Conclusion: GRPO-CARE为MLLMs提供了一种可推广的后训练框架，提升了模型的解释性和鲁棒性。

Abstract: Recent reinforcement learning approaches, such as outcome-supervised GRPO,
have advanced Chain-of-Thought reasoning in large language models (LLMs), yet
their adaptation to multimodal LLMs (MLLMs) is unexplored. To address the lack
of rigorous evaluation for MLLM post-training methods, we introduce
SEED-Bench-R1, a benchmark with complex real-world videos requiring balanced
perception and reasoning. It offers a large training set and evaluates
generalization across three escalating challenges: in-distribution,
cross-environment, and cross-environment-task scenarios. Using SEED-Bench-R1,
we find that standard GRPO, while improving answer accuracy, often reduces
logical coherence between reasoning steps and answers, with only a 57.9%
consistency rate. This stems from reward signals focusing solely on final
answers, encouraging shortcuts, and strict KL penalties limiting exploration.To
address this, we propose GRPO-CARE, a consistency-aware RL framework optimizing
both answer correctness and reasoning coherence without explicit supervision.
GRPO-CARE introduces a two-tiered reward: (1) a base reward for answer
correctness, and (2) an adaptive consistency bonus, computed by comparing the
model's reasoning-to-answer likelihood (via a slowly-evolving reference model)
against group peers.This dual mechanism amplifies rewards for reasoning paths
that are both correct and logically consistent. Replacing KL penalties with
this adaptive bonus, GRPO-CARE outperforms standard GRPO on SEED-Bench-R1,
achieving a 6.7% performance gain on the hardest evaluation level and a 24.5%
improvement in consistency. It also shows strong transferability, improving
model performance across diverse video understanding benchmarks. Our work
contributes a systematically designed benchmark and a generalizable
post-training framework, advancing the development of more interpretable and
robust MLLMs.

</details>


### [150] [MBA: Multimodal Bidirectional Attack for Referring Expression Segmentation Models](https://arxiv.org/abs/2506.16157)
*Xingbai Chen,Tingchao Fu,Renyang Liu,Wei Zhou,Chao Yi*

Main category: cs.CV

TL;DR: 提出了一种针对RES模型的多模态双向攻击方法，通过联合优化图像和文本模态，增强对抗样本的跨文本迁移能力。


<details>
  <summary>Details</summary>
Motivation: RES模型在对抗样本下的鲁棒性尚未充分研究，现有攻击方法在多模态结构上表现不佳，且实际场景中用户会使用多样化的文本输入。

Method: 引入可学习的代理文本嵌入扰动，联合优化图像和文本模态，生成对抗样本。

Result: 在多个RES模型和数据集上验证了方法的有效性，优于现有方法。

Conclusion: 多模态双向攻击方法显著提升了对抗样本的跨文本迁移能力，填补了RES模型对抗鲁棒性研究的空白。

Abstract: Referring Expression Segmentation (RES) enables precise object segmentation
in images based on natural language descriptions, offering high flexibility and
broad applicability in real-world vision tasks. Despite its impressive
performance, the robustness of RES models against adversarial examples remains
largely unexplored. While prior adversarial attack methods have explored
adversarial robustness on conventional segmentation models, they perform poorly
when directly applied to RES, failing to expose vulnerabilities in its
multimodal structure. Moreover, in practical open-world scenarios, users
typically issue multiple, diverse referring expressions to interact with the
same image, highlighting the need for adversarial examples that generalize
across varied textual inputs. To address these multimodal challenges, we
propose a novel adversarial attack strategy termed \textbf{Multimodal
Bidirectional Attack}, tailored for RES models. Our method introduces learnable
proxy textual embedding perturbation and jointly performs visual-aligned
optimization on the image modality and textual-adversarial optimization on the
textual modality during attack generation. This dual optimization framework
encourages adversarial images to actively adapt to more challenging text
embedding during optimization, thereby enhancing their cross-text
transferability, which refers to the ability of adversarial examples to remain
effective under a variety of unseen or semantically diverse textual inputs.
Extensive experiments conducted on multiple RES models and benchmark datasets
demonstrate the superior effectiveness of our method compared to existing
methods.

</details>


### [151] [Co-Speech Gesture and Facial Expression Generation for Non-Photorealistic 3D Characters](https://arxiv.org/abs/2506.16159)
*Taisei Omine,Naoyuki Kawabata,Fuminori Homma*

Main category: cs.CV

TL;DR: 研究提出了一种为非写实角色（如动漫角色）设计情感表达的方法，包括夸张表情和对话语义手势，显著优于现有研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注写实化虚拟形象，缺乏对非写实角色（如动漫角色）情感表达的支持。

Method: 利用漫画提取的表情数据和对话语义手势，为非写实角色设计情感表达方法。

Result: 用户研究表明，该方法在多个方面显著优于现有研究。

Conclusion: 该方法为非写实角色的情感表达提供了有效解决方案。

Abstract: With the advancement of conversational AI, research on bodily expressions,
including gestures and facial expressions, has also progressed. However, many
existing studies focus on photorealistic avatars, making them unsuitable for
non-photorealistic characters, such as those found in anime. This study
proposes methods for expressing emotions, including exaggerated expressions
unique to non-photorealistic characters, by utilizing expression data extracted
from comics and dialogue-specific semantic gestures. A user study demonstrated
significant improvements across multiple aspects when compared to existing
research.

</details>


### [152] [Align the GAP: Prior-based Unified Multi-Task Remote Physiological Measurement Framework For Domain Generalization and Personalization](https://arxiv.org/abs/2506.16160)
*Jiyao Wang,Xiao Yang,Hao Lu,Dengbo He,Kaishun Wu*

Main category: cs.CV

TL;DR: 论文提出了一种统一框架GAP，结合多源语义域泛化（MSSDG）和测试时个性化适应（TTPA），通过先验知识和观察信息提升远程生理测量的准确性和个性化。


<details>
  <summary>Details</summary>
Motivation: 解决多任务远程生理测量中的部分标注和环境噪声问题，同时探索实时个性化适应的需求。

Method: 将面部视频信息分解为不变语义、个体偏差和噪声，利用先验知识和观察信息设计多模块框架。

Result: 在六个公开数据集和新引入的真实驾驶数据集上验证了框架的有效性。

Conclusion: GAP框架能够同时处理MSSDG和TTPA，且调整最小，代码和新数据集将公开。

Abstract: Multi-source synsemantic domain generalization (MSSDG) for multi-task remote
physiological measurement seeks to enhance the generalizability of these
metrics and attracts increasing attention. However, challenges like partial
labeling and environmental noise may disrupt task-specific accuracy. Meanwhile,
given that real-time adaptation is necessary for personalized products, the
test-time personalized adaptation (TTPA) after MSSDG is also worth exploring,
while the gap between previous generalization and personalization methods is
significant and hard to fuse. Thus, we proposed a unified framework for
MSSD\textbf{G} and TTP\textbf{A} employing \textbf{P}riors (\textbf{GAP}) in
biometrics and remote photoplethysmography (rPPG). We first disentangled
information from face videos into invariant semantics, individual bias, and
noise. Then, multiple modules incorporating priors and our observations were
applied in different stages and for different facial information. Then, based
on the different principles of achieving generalization and personalization,
our framework could simultaneously address MSSDG and TTPA under multi-task
remote physiological estimation with minimal adjustments. We expanded the MSSDG
benchmark to the TTPA protocol on six publicly available datasets and
introduced a new real-world driving dataset with complete labeling. Extensive
experiments that validated our approach, and the codes along with the new
dataset will be released.

</details>


### [153] [Integrating Generative Adversarial Networks and Convolutional Neural Networks for Enhanced Traffic Accidents Detection and Analysis](https://arxiv.org/abs/2506.16186)
*Zhenghao Xi,Xiang Liu,Yaqi Liu,Yitong Cai,Yangyu Zheng*

Main category: cs.CV

TL;DR: 该研究利用深度学习技术（GANs和CNN）解决交通事故检测中的数据不足问题，提出了一种高效的实时事故检测框架，准确率高达95%。


<details>
  <summary>Details</summary>
Motivation: 全球交通事故数量上升，亟需智能、高效的自动化事故检测方法以提升交通安全。

Method: 结合GANs生成合成数据，使用CNN、FTCNN和VIT模型训练，并对视频帧进行预处理（调整大小、增强和归一化）。

Result: FTCNN和VIT模型表现最佳，准确率分别为94%和95%，CNN模型为88%。

Conclusion: 该框架适用于实时交通监控和智能城市系统，为未来智能监控系统奠定了基础。

Abstract: Accident detection using Closed Circuit Television (CCTV) footage is one of
the most imperative features for enhancing transport safety and efficient
traffic control. To this end, this research addresses the issues of supervised
monitoring and data deficiency in accident detection systems by adapting
excellent deep learning technologies. The motivation arises from rising
statistics in the number of car accidents worldwide; this calls for innovation
and the establishment of a smart, efficient and automated way of identifying
accidents and calling for help to save lives. Addressing the problem of the
scarcity of data, the presented framework joins Generative Adversarial Networks
(GANs) for synthesizing data and Convolutional Neural Networks (CNN) for model
training. Video frames for accidents and non-accidents are collected from
YouTube videos, and we perform resizing, image enhancement and image
normalisation pixel range adjustments. Three models are used: CNN, Fine-tuned
Convolutional Neural Network (FTCNN) and Vision Transformer (VIT) worked best
for detecting accidents from CCTV, obtaining an accuracy rate of 94% and 95%,
while the CNN model obtained 88%. Such results show that the proposed framework
suits traffic safety applications due to its high real-time accident detection
capabilities and broad-scale applicability. This work lays the foundation for
intelligent surveillance systems in the future for real-time traffic
monitoring, smart city framework, and integration of intelligent surveillance
systems into emergency management systems.

</details>


### [154] [VideoGAN-based Trajectory Proposal for Automated Vehicles](https://arxiv.org/abs/2506.16209)
*Annajoyce Mariani,Kira Maag,Hanno Gottschalk*

Main category: cs.CV

TL;DR: 该论文提出了一种基于生成对抗网络（GAN）的方法，用于从鸟瞰视角（BEV）视频中生成真实的多模态轨迹，以解决传统方法难以捕捉复杂轨迹分布的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如模型驱动、规则基础或经典学习方法）难以有效捕捉未来轨迹的复杂多模态分布，因此需要一种更高效的方法来生成真实的轨迹选项。

Method: 使用低分辨率BEV占用网格视频作为训练数据，通过视频生成模型（GAN）生成交通场景视频，并从中提取抽象轨迹数据。

Result: 在100 GPU小时内完成训练，推理时间低于20毫秒，生成的轨迹在空间和动态参数上与真实数据分布对齐。

Conclusion: 该方法能够快速生成物理上真实的轨迹，适用于自动驾驶车辆的自动化程度提升。

Abstract: Being able to generate realistic trajectory options is at the core of
increasing the degree of automation of road vehicles. While model-driven,
rule-based, and classical learning-based methods are widely used to tackle
these tasks at present, they can struggle to effectively capture the complex,
multimodal distributions of future trajectories. In this paper we investigate
whether a generative adversarial network (GAN) trained on videos of bird's-eye
view (BEV) traffic scenarios can generate statistically accurate trajectories
that correctly capture spatial relationships between the agents. To this end,
we propose a pipeline that uses low-resolution BEV occupancy grid videos as
training data for a video generative model. From the generated videos of
traffic scenarios we extract abstract trajectory data using single-frame object
detection and frame-to-frame object matching. We particularly choose a GAN
architecture for the fast training and inference times with respect to
diffusion models. We obtain our best results within 100 GPU hours of training,
with inference times under 20\,ms. We demonstrate the physical realism of the
proposed trajectories in terms of distribution alignment of spatial and dynamic
parameters with respect to the ground truth videos from the Waymo Open Motion
Dataset.

</details>


### [155] [FOCoOp: Enhancing Out-of-Distribution Robustness in Federated Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2506.16218)
*Xinting Liao,Weiming Liu,Jiaming Qian,Pengyang Zhou,Jiahe Xu,Wenjie Wang,Chaochao Chen,Xiaolin Zheng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: FOCoOp框架通过全局提示、本地提示和OOD提示解决联邦提示学习中的性能与鲁棒性权衡问题，提升OOD场景下的模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦提示学习方法在性能与鲁棒性之间存在权衡，尤其在OOD场景下表现不佳，限制了实际应用的可靠性。

Method: 提出FOCoOp框架，利用三类提示（全局、本地、OOD）实现类别和分布级别的分离，并通过双层分布鲁棒优化适应OOD变化。

Result: 实验表明FOCoOp能有效捕捉分布式异构数据，提升OOD场景下的鲁棒性。

Conclusion: FOCoOp填补了联邦提示学习在OOD场景下的性能与鲁棒性权衡问题，具有实际应用潜力。

Abstract: Federated prompt learning (FPL) for vision-language models is a powerful
approach to collaboratively adapt models across distributed clients while
preserving data privacy. However, existing FPL approaches suffer from a
trade-off between performance and robustness, particularly in
out-of-distribution (OOD) shifts, limiting their reliability in real-world
scenarios. The inherent in-distribution (ID) data heterogeneity among different
clients makes it more challenging to maintain this trade-off. To fill this gap,
we introduce a Federated OOD-aware Context Optimization (FOCoOp) framework,
which captures diverse distributions among clients using ID global prompts,
local prompts, and OOD prompts. Specifically, FOCoOp leverages three sets of
prompts to create both class-level and distribution-level separations, which
adapt to OOD shifts through bi-level distributionally robust optimization.
Additionally, FOCoOp improves the discrimination consistency among clients,
i.e., calibrating global prompts, seemingly OOD prompts, and OOD prompts by
semi-unbalanced optimal transport. The extensive experiments on real-world
datasets demonstrate that FOCoOp effectively captures decentralized
heterogeneous distributions and enhances robustness of different OOD shifts.
The project is available at GitHub.

</details>


### [156] [R3eVision: A Survey on Robust Rendering, Restoration, and Enhancement for 3D Low-Level Vision](https://arxiv.org/abs/2506.16262)
*Weeyoung Kwon,Jeahun Sung,Minkyu Jeon,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: 该论文综述了3D低层视觉（3D LLV）领域，探讨了在退化条件下实现高质量3D重建和渲染的方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法（如NeRF和3DGS）通常假设输入为干净高分辨率图像，而实际场景中常存在噪声、模糊等问题，限制了其鲁棒性。

Method: 论文通过形式化退化感知渲染问题，分类整合低层视觉任务（如超分辨率、去模糊）到神经渲染框架中的方法。

Result: 综述展示了如何在恶劣条件下实现高保真3D重建，并讨论了在自动驾驶、AR/VR等领域的应用。

Conclusion: 3D LLV是现实环境中实现鲁棒3D内容生成和场景重建的重要方向。

Abstract: Neural rendering methods such as Neural Radiance Fields (NeRF) and 3D
Gaussian Splatting (3DGS) have achieved significant progress in photorealistic
3D scene reconstruction and novel view synthesis. However, most existing models
assume clean and high-resolution (HR) multi-view inputs, which limits their
robustness under real-world degradations such as noise, blur, low-resolution
(LR), and weather-induced artifacts. To address these limitations, the emerging
field of 3D Low-Level Vision (3D LLV) extends classical 2D Low-Level Vision
tasks including super-resolution (SR), deblurring, weather degradation removal,
restoration, and enhancement into the 3D spatial domain. This survey, referred
to as R\textsuperscript{3}eVision, provides a comprehensive overview of robust
rendering, restoration, and enhancement for 3D LLV by formalizing the
degradation-aware rendering problem and identifying key challenges related to
spatio-temporal consistency and ill-posed optimization. Recent methods that
integrate LLV into neural rendering frameworks are categorized to illustrate
how they enable high-fidelity 3D reconstruction under adverse conditions.
Application domains such as autonomous driving, AR/VR, and robotics are also
discussed, where reliable 3D perception from degraded inputs is critical. By
reviewing representative methods, datasets, and evaluation protocols, this work
positions 3D LLV as a fundamental direction for robust 3D content generation
and scene-level reconstruction in real-world environments.

</details>


### [157] [Dense 3D Displacement Estimation for Landslide Monitoring via Fusion of TLS Point Clouds and Embedded RGB Images](https://arxiv.org/abs/2506.16265)
*Zhaoyi Wang,Jemil Avers Butt,Shengyu Huang,Tomislav Medic,Andreas Wieser*

Main category: cs.CV

TL;DR: 提出了一种基于3D点云和RGB图像融合的分层分区方法，用于估计密集3D位移矢量场，提高了滑坡监测的空间覆盖率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于点云的方法通常仅依赖几何或辐射信息，导致稀疏或非3D位移估计，无法满足滑坡监测需求。

Method: 采用分层分区从粗到细的方法，结合3D几何和2D图像特征构建块级匹配，并通过几何一致性检查和刚性变换估计进行优化。

Result: 在两个真实滑坡数据集上，空间覆盖率达79%和97%，位移幅度偏差分别为0.15m和0.25m，优于现有方法F2S3。

Conclusion: 该方法为基于TLS的滑坡监测提供了实用且适应性强的解决方案，并可扩展至其他点云和监测任务。

Abstract: Landslide monitoring is essential for understanding geohazards and mitigating
associated risks. However, existing point cloud-based methods typically rely on
either geometric or radiometric information and often yield sparse or non-3D
displacement estimates. In this paper, we propose a hierarchical
partition-based coarse-to-fine approach that fuses 3D point clouds and
co-registered RGB images to estimate dense 3D displacement vector fields. We
construct patch-level matches using both 3D geometry and 2D image features.
These matches are refined via geometric consistency checks, followed by rigid
transformation estimation per match. Experimental results on two real-world
landslide datasets demonstrate that our method produces 3D displacement
estimates with high spatial coverage (79% and 97%) and high accuracy.
Deviations in displacement magnitude with respect to external measurements
(total station or GNSS observations) are 0.15 m and 0.25 m on the two datasets,
respectively, and only 0.07 m and 0.20 m compared to manually derived
references. These values are below the average scan resolutions (0.08 m and
0.30 m). Our method outperforms the state-of-the-art method F2S3 in spatial
coverage while maintaining comparable accuracy. Our approach offers a practical
and adaptable solution for TLS-based landslide monitoring and is extensible to
other types of point clouds and monitoring tasks. Our example data and source
code are publicly available at https://github.com/zhaoyiww/fusion4landslide.

</details>


### [158] [Fine-grained Image Retrieval via Dual-Vision Adaptation](https://arxiv.org/abs/2506.16273)
*Xin Jiang,Meiqi Cao,Hao Tang,Fei Shen,Zechao Li*

Main category: cs.CV

TL;DR: 提出DVA方法，通过样本和特征适配改进细粒度图像检索，避免过拟合并提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度图像检索方法易过拟合训练数据，忽视预训练知识，泛化能力不足。

Method: 设计对象感知适配和上下文适配，调整输入样本和特征，不修改预训练参数。

Result: DVA参数少，在多个数据集上表现优异。

Conclusion: DVA有效平衡检索效率与性能，提升细粒度图像检索效果。

Abstract: Fine-Grained Image Retrieval~(FGIR) faces challenges in learning
discriminative visual representations to retrieve images with similar
fine-grained features. Current leading FGIR solutions typically follow two
regimes: enforce pairwise similarity constraints in the semantic embedding
space, or incorporate a localization sub-network to fine-tune the entire model.
However, such two regimes tend to overfit the training data while forgetting
the knowledge gained from large-scale pre-training, thus reducing their
generalization ability. In this paper, we propose a Dual-Vision Adaptation
(DVA) approach for FGIR, which guides the frozen pre-trained model to perform
FGIR through collaborative sample and feature adaptation. Specifically, we
design Object-Perceptual Adaptation, which modifies input samples to help the
pre-trained model perceive critical objects and elements within objects that
are helpful for category prediction. Meanwhile, we propose In-Context
Adaptation, which introduces a small set of parameters for feature adaptation
without modifying the pre-trained parameters. This makes the FGIR task using
these adjusted features closer to the task solved during the pre-training.
Additionally, to balance retrieval efficiency and performance, we propose
Discrimination Perception Transfer to transfer the discriminative knowledge in
the object-perceptual adaptation to the image encoder using the knowledge
distillation mechanism. Extensive experiments show that DVA has fewer learnable
parameters and performs well on three in-distribution and three
out-of-distribution fine-grained datasets.

</details>


### [159] [SycnMapV2: Robust and Adaptive Unsupervised Segmentation](https://arxiv.org/abs/2506.16297)
*Heng Zhang,Zikang Wan,Danilo Vasconcellos Vargas*

Main category: cs.CV

TL;DR: SyncMapV2是一种无监督分割算法，具有卓越的鲁棒性和在线适应能力，无需重新初始化即可处理各种噪声和干扰。


<details>
  <summary>Details</summary>
Motivation: 人类视觉在无显式训练下仍能高效分割视觉线索，而现有AI算法在噪声条件下性能显著下降。SyncMapV2旨在解决这一问题。

Method: 基于自组织动态方程和随机网络概念的学习范式，无需鲁棒训练、监督或损失函数。

Result: 在数字干扰下，mIoU仅下降0.01%，远优于现有方法（23.8%）。在噪声、天气和模糊干扰下表现同样出色。

Conclusion: SyncMapV2首次实现了在线适应和无监督分割的鲁棒性，为未来自适应智能的发展奠定了基础。

Abstract: Human vision excels at segmenting visual cues without the need for explicit
training, and it remains remarkably robust even as noise severity increases. In
contrast, existing AI algorithms struggle to maintain accuracy under similar
conditions. Here, we present SyncMapV2, the first to solve unsupervised
segmentation with state-of-the-art robustness. SyncMapV2 exhibits a minimal
drop in mIoU, only 0.01%, under digital corruption, compared to a 23.8% drop
observed in SOTA methods.This superior performance extends across various types
of corruption: noise (7.3% vs. 37.7%), weather (7.5% vs. 33.8%), and blur (7.0%
vs. 29.5%). Notably, SyncMapV2 accomplishes this without any robust training,
supervision, or loss functions. It is based on a learning paradigm that uses
self-organizing dynamical equations combined with concepts from random
networks. Moreover,unlike conventional methods that require re-initialization
for each new input, SyncMapV2 adapts online, mimicking the continuous
adaptability of human vision. Thus, we go beyond the accurate and robust
results, and present the first algorithm that can do all the above online,
adapting to input rather than re-initializing. In adaptability tests, SyncMapV2
demonstrates near-zero performance degradation, which motivates and fosters a
new generation of robust and adaptive intelligence in the near future.

</details>


### [160] [Learning Multi-scale Spatial-frequency Features for Image Denoising](https://arxiv.org/abs/2506.16307)
*Xu Zhao,Chen Zhao,Xiantao Hu,Hongliang Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: 提出了一种多尺度自适应双域网络（MADNet），用于图像去噪，通过自适应空间频率学习单元（ASFU）和全局特征融合块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定单输入单输出Unet架构，忽略像素级多尺度表示，且未区分高频和低频噪声特性。

Method: 使用图像金字塔输入，设计ASFU单元分离高低频信息，并通过全局特征融合块增强多尺度特征。

Result: 在合成和真实噪声图像数据集上的实验表明，MADNet优于当前最先进的去噪方法。

Conclusion: MADNet通过多尺度自适应双域设计，显著提升了图像去噪性能。

Abstract: Recent advancements in multi-scale architectures have demonstrated
exceptional performance in image denoising tasks. However, existing
architectures mainly depends on a fixed single-input single-output Unet
architecture, ignoring the multi-scale representations of pixel level. In
addition, previous methods treat the frequency domain uniformly, ignoring the
different characteristics of high-frequency and low-frequency noise. In this
paper, we propose a novel multi-scale adaptive dual-domain network (MADNet) for
image denoising. We use image pyramid inputs to restore noise-free results from
low-resolution images. In order to realize the interaction of high-frequency
and low-frequency information, we design an adaptive spatial-frequency learning
unit (ASFU), where a learnable mask is used to separate the information into
high-frequency and low-frequency components. In the skip connections, we design
a global feature fusion block to enhance the features at different scales.
Extensive experiments on both synthetic and real noisy image datasets verify
the effectiveness of MADNet compared with current state-of-the-art denoising
approaches.

</details>


### [161] [Segment Anything for Satellite Imagery: A Strong Baseline and a Regional Dataset for Automatic Field Delineation](https://arxiv.org/abs/2506.16318)
*Carmelo Scribano,Elena Govi,Paolo bertellini,Simone Parisi,Giorgia Franchini,Marko Bertogna*

Main category: cs.CV

TL;DR: 提出了一种基于Segment Anything Model（SAM）的农田边界自动提取方法，通过微调策略优化模型，并引入新的区域数据集ERAS。


<details>
  <summary>Details</summary>
Motivation: 农田边界精确测绘对农业高效运营至关重要，传统地面调查成本高，需自动化解决方案。

Method: 基于SAM模型，采用微调策略，并开发了新的区域数据集ERAS。

Result: 实验验证了方法的准确性和泛化能力，为自动化农田测绘提供了基准。

Conclusion: 该方法高效且鲁棒，新数据集ERAS已公开。

Abstract: Accurate mapping of agricultural field boundaries is essential for the
efficient operation of agriculture. Automatic extraction from high-resolution
satellite imagery, supported by computer vision techniques, can avoid costly
ground surveys. In this paper, we present a pipeline for field delineation
based on the Segment Anything Model (SAM), introducing a fine-tuning strategy
to adapt SAM to this task. In addition to using published datasets, we describe
a method for acquiring a complementary regional dataset that covers areas
beyond current sources. Extensive experiments assess segmentation accuracy and
evaluate the generalization capabilities. Our approach provides a robust
baseline for automated field delineation. The new regional dataset, known as
ERAS, is now publicly available.

</details>


### [162] [RealDriveSim: A Realistic Multi-Modal Multi-Task Synthetic Dataset for Autonomous Driving](https://arxiv.org/abs/2506.16319)
*Arpit Jadon,Haoran Wang,Phillip Thomas,Michael Stanley,S. Nathaniel Cibik,Rachel Laurat,Omar Maher,Lukas Hoyer,Ozan Unal,Dengxin Dai*

Main category: cs.CV

TL;DR: RealDriveSim是一个多模态合成数据集，用于自动驾驶，支持2D计算机视觉和LiDAR应用，提供64类精细标注，性能优于现有合成基准。


<details>
  <summary>Details</summary>
Motivation: 感知模型需要大规模数据集，但数据标注成本高，现有合成数据集范围有限且不够真实。

Method: 开发RealDriveSim，一个真实的多模态合成数据集，支持2D和LiDAR应用，提供64类标注。

Result: 在多种应用和领域中评估，性能优于现有合成基准。

Conclusion: RealDriveSim公开可用，为自动驾驶研究提供了高效且低成本的数据解决方案。

Abstract: As perception models continue to develop, the need for large-scale datasets
increases. However, data annotation remains far too expensive to effectively
scale and meet the demand. Synthetic datasets provide a solution to boost model
performance with substantially reduced costs. However, current synthetic
datasets remain limited in their scope, realism, and are designed for specific
tasks and applications. In this work, we present RealDriveSim, a realistic
multi-modal synthetic dataset for autonomous driving that not only supports
popular 2D computer vision applications but also their LiDAR counterparts,
providing fine-grained annotations for up to 64 classes. We extensively
evaluate our dataset for a wide range of applications and domains,
demonstrating state-of-the-art results compared to existing synthetic
benchmarks. The dataset is publicly available at
https://realdrivesim.github.io/.

</details>


### [163] [Reliable Few-shot Learning under Dual Noises](https://arxiv.org/abs/2506.16330)
*Ji Zhang,Jingkuan Song,Lianli Gao,Nicu Sebe,Heng Tao Shen*

Main category: cs.CV

TL;DR: DETA++提出了一种去噪任务适应方法，通过对比相关性聚合模块和噪声熵最大化损失，解决了小样本学习中的ID和OOD噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放世界中可能因ID和OOD噪声而失效，尤其是在支持样本有限的情况下，噪声影响会被放大。

Method: DETA++使用CoRA模块计算支持样本权重，提出干净原型损失和噪声熵最大化损失，并利用记忆库和LocalNCC分类器增强鲁棒性。

Result: 实验表明DETA++在小样本学习中有效且灵活。

Conclusion: DETA++通过去噪和鲁棒性设计，显著提升了小样本学习的性能。

Abstract: Recent advances in model pre-training give rise to task adaptation-based
few-shot learning (FSL), where the goal is to adapt a pre-trained task-agnostic
model for capturing task-specific knowledge with a few-labeled support samples
of the target task.Nevertheless, existing approaches may still fail in the open
world due to the inevitable in-distribution (ID) and out-of-distribution (OOD)
noise from both support and query samples of the target task. With limited
support samples available, i) the adverse effect of the dual noises can be
severely amplified during task adaptation, and ii) the adapted model can
produce unreliable predictions on query samples in the presence of the dual
noises. In this work, we propose DEnoised Task Adaptation (DETA++) for reliable
FSL. DETA++ uses a Contrastive Relevance Aggregation (CoRA) module to calculate
image and region weights for support samples, based on which a clean prototype
loss and a noise entropy maximization loss are proposed to achieve noise-robust
task adaptation. Additionally,DETA++ employs a memory bank to store and refine
clean regions for each inner-task class, based on which a Local Nearest
Centroid Classifier (LocalNCC) is devised to yield noise-robust predictions on
query samples. Moreover, DETA++ utilizes an Intra-class Region Swapping
(IntraSwap) strategy to rectify ID class prototypes during task adaptation,
enhancing the model's robustness to the dual noises. Extensive experiments
demonstrate the effectiveness and flexibility of DETA++.

</details>


### [164] [Transparency Techniques for Neural Networks trained on Writer Identification and Writer Verification](https://arxiv.org/abs/2506.16331)
*Viktoria Pundy,Marco Peer,Florian Kleber*

Main category: cs.CV

TL;DR: 论文研究了神经网络在笔迹识别和验证中的透明度技术，评估了两种方法（像素级和点特异性显著性图），发现像素级方法更优。


<details>
  <summary>Details</summary>
Motivation: 提高神经网络在笔迹识别和验证中的透明度和可靠性，支持法医专家分析手写文本相似性。

Method: 应用两种透明度技术（像素级和点特异性显著性图），并通过删除和插入评分指标进行评估。

Result: 像素级显著性图优于点特异性显著性图，适合支持法医专家工作。

Conclusion: 像素级显著性图在笔迹识别领域具有实用价值，能有效辅助法医专家。

Abstract: Neural Networks are the state of the art for many tasks in the computer
vision domain, including Writer Identification (WI) and Writer Verification
(WV). The transparency of these "black box" systems is important for
improvements of performance and reliability. For this work, two transparency
techniques are applied to neural networks trained on WI and WV for the first
time in this domain. The first technique provides pixel-level saliency maps,
while the point-specific saliency maps of the second technique provide
information on similarities between two images. The transparency techniques are
evaluated using deletion and insertion score metrics. The goal is to support
forensic experts with information on similarities in handwritten text and to
explore the characteristics selected by a neural network for the identification
process. For the qualitative evaluation, the highlights of the maps are
compared to the areas forensic experts consider during the identification
process. The evaluation results show that the pixel-wise saliency maps
outperform the point-specific saliency maps and are suitable for the support of
forensic experts.

</details>


### [165] [MambaHash: Visual State Space Deep Hashing Model for Large-Scale Image Retrieval](https://arxiv.org/abs/2506.16353)
*Chao He,Hongxi Wei*

Main category: cs.CV

TL;DR: MambaHash是一种基于Vision Mamba的深度哈希模型，用于大规模图像检索，通过分组Mamba操作和通道交互注意力模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索Mamba在大规模图像检索任务中的适用性，并提出高效解决方案。

Method: 提出分阶段的主干网络，结合分组Mamba操作和通道交互注意力模块，设计自适应特征增强模块。

Result: 在CIFAR-10、NUS-WIDE和IMAGENET数据集上表现优于现有深度哈希方法。

Conclusion: MambaHash在大规模图像检索任务中具有高效性和优越性能。

Abstract: Deep image hashing aims to enable effective large-scale image retrieval by
mapping the input images into simple binary hash codes through deep neural
networks. More recently, Vision Mamba with linear time complexity has attracted
extensive attention from researchers by achieving outstanding performance on
various computer tasks. Nevertheless, the suitability of Mamba for large-scale
image retrieval tasks still needs to be explored. Towards this end, we propose
a visual state space hashing model, called MambaHash. Concretely, we propose a
backbone network with stage-wise architecture, in which grouped Mamba operation
is introduced to model local and global information by utilizing Mamba to
perform multi-directional scanning along different groups of the channel.
Subsequently, the proposed channel interaction attention module is used to
enhance information communication across channels. Finally, we meticulously
design an adaptive feature enhancement module to increase feature diversity and
enhance the visual representation capability of the model. We have conducted
comprehensive experiments on three widely used datasets: CIFAR-10, NUS-WIDE and
IMAGENET. The experimental results demonstrate that compared with the
state-of-the-art deep hashing methods, our proposed MambaHash has well
efficiency and superior performance to effectively accomplish large-scale image
retrieval tasks. Source code is available
https://github.com/shuaichaochao/MambaHash.git

</details>


### [166] [Prompt-based Dynamic Token Pruning to Guide Transformer Attention in Efficient Segmentation](https://arxiv.org/abs/2506.16369)
*Pallabi Dutta,Anubhab Maity,Sushmita Mitra*

Main category: cs.CV

TL;DR: 提出一种自适应提示引导的剪枝方法，减少ViTs在医学图像分割中处理的无关令牌，提高计算效率和分割精度。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers（ViTs）处理大量令牌的高计算需求限制了其在医学图像分析中的实际应用。

Method: 使用提示引导的空间先验对令牌进行相关性排序，剪枝低相关性令牌，保留高相关性令牌进行后续处理。

Result: 实验显示令牌减少35-55%，计算成本降低，同时保持分割精度。

Conclusion: 该方法在资源受限环境中实现高效医学图像处理，支持实时诊断。

Abstract: The high computational demands of Vision Transformers (ViTs), in processing a
huge number of tokens, often constrain their practical application in analyzing
medical images. This research proposes an adaptive prompt-guided pruning method
to selectively reduce the processing of irrelevant tokens in the segmentation
pipeline. The prompt-based spatial prior helps to rank the tokens according to
their relevance. Tokens with low-relevance scores are down-weighted, ensuring
that only the relevant ones are propagated for processing across subsequent
stages. This data-driven pruning strategy facilitates end-to-end training,
maintains gradient flow, and improves segmentation accuracy by focusing
computational resources on essential regions. The proposed framework is
integrated with several state-of-the-art models to facilitate the elimination
of irrelevant tokens; thereby, enhancing computational efficiency while
preserving segmentation accuracy. The experimental results show a reduction of
$\sim$ 35-55\% tokens; thus reducing the computational costs relative to the
baselines. Cost-effective medical image processing, using our framework,
facilitates real-time diagnosis by expanding its applicability in
resource-constrained environments.

</details>


### [167] [AGC-Drive: A Large-Scale Dataset for Real-World Aerial-Ground Collaboration in Driving Scenarios](https://arxiv.org/abs/2506.16371)
*Yunhao Hou,Bochao Zou,Min Zhang,Ran Chen,Shangdong Yang,Yanmei Zhang,Junbao Zhuo,Siheng Chen,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: 论文介绍了首个大规模真实世界数据集AGC-Drive，用于空中-地面协同3D感知，填补了无人机视角数据集的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注车车和车路协同，忽视了无人机提供的动态俯视视角，且缺乏高质量数据集。

Method: 通过两辆装备多摄像头和LiDAR的车辆及一架无人机收集数据，覆盖14种驾驶场景和400个场景。

Result: 数据集包含120K LiDAR帧和440K图像，标注了13类物体的3D边界框，并提供了基准测试和开源工具包。

Conclusion: AGC-Drive为空中-地面协同感知研究提供了重要资源，推动了多智能体感知技术的发展。

Abstract: By sharing information across multiple agents, collaborative perception helps
autonomous vehicles mitigate occlusions and improve overall perception
accuracy. While most previous work focus on vehicle-to-vehicle and
vehicle-to-infrastructure collaboration, with limited attention to aerial
perspectives provided by UAVs, which uniquely offer dynamic, top-down views to
alleviate occlusions and monitor large-scale interactive environments. A major
reason for this is the lack of high-quality datasets for aerial-ground
collaborative scenarios. To bridge this gap, we present AGC-Drive, the first
large-scale real-world dataset for Aerial-Ground Cooperative 3D perception. The
data collection platform consists of two vehicles, each equipped with five
cameras and one LiDAR sensor, and one UAV carrying a forward-facing camera and
a LiDAR sensor, enabling comprehensive multi-view and multi-agent perception.
Consisting of approximately 120K LiDAR frames and 440K images, the dataset
covers 14 diverse real-world driving scenarios, including urban roundabouts,
highway tunnels, and on/off ramps. Notably, 19.5% of the data comprises dynamic
interaction events, including vehicle cut-ins, cut-outs, and frequent lane
changes. AGC-Drive contains 400 scenes, each with approximately 100 frames and
fully annotated 3D bounding boxes covering 13 object categories. We provide
benchmarks for two 3D perception tasks: vehicle-to-vehicle collaborative
perception and vehicle-to-UAV collaborative perception. Additionally, we
release an open-source toolkit, including spatiotemporal alignment verification
tools, multi-agent visualization systems, and collaborative annotation
utilities. The dataset and code are available at
https://github.com/PercepX/AGC-Drive.

</details>


### [168] [CLIP-MG: Guiding Semantic Attention with Skeletal Pose Features and RGB Data for Micro-Gesture Recognition on the iMiGUE Dataset](https://arxiv.org/abs/2506.16385)
*Santosh Patapati,Trisanth Srinivasan,Amith Adiraju*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP的微手势识别模型CLIP-MG，通过姿态引导语义查询和多模态融合机制，在iMiGUE数据集上达到61.82%的Top-1准确率。


<details>
  <summary>Details</summary>
Motivation: 微手势因其细微、不自主的特性及低幅度运动，在情感计算中具有挑战性。

Method: 采用Pose-Guided Semantics-Aware CLIP架构，结合姿态信息生成语义查询，并使用门控多模态融合机制。

Result: 模型在iMiGUE数据集上的Top-1准确率为61.82%。

Conclusion: 该方法展示了潜力，但完全适配CLIP等视觉语言模型于微手势识别仍具挑战性。

Abstract: Micro-gesture recognition is a challenging task in affective computing due to
the subtle, involuntary nature of the gestures and their low movement
amplitude. In this paper, we introduce a Pose-Guided Semantics-Aware CLIP-based
architecture, or CLIP for Micro-Gesture recognition (CLIP-MG), a modified CLIP
model tailored for micro-gesture classification on the iMiGUE dataset. CLIP-MG
integrates human pose (skeleton) information into the CLIP-based recognition
pipeline through pose-guided semantic query generation and a gated multi-modal
fusion mechanism. The proposed model achieves a Top-1 accuracy of 61.82%. These
results demonstrate both the potential of our approach and the remaining
difficulty in fully adapting vision-language models like CLIP for micro-gesture
recognition.

</details>


### [169] [HyperPath: Knowledge-Guided Hyperbolic Semantic Hierarchy Modeling for WSI Analysis](https://arxiv.org/abs/2506.16398)
*Peixiang Huang,Yanyan Huang,Weiqin Zhao,Junjun He,Lequan Yu*

Main category: cs.CV

TL;DR: 论文提出HyperPath方法，利用双曲空间建模WSI的语义层次结构，结合文本描述提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖欧几里得嵌入，难以充分捕捉WSI的语义层次结构。

Method: 结合视觉和文本特征，设计角度模态对齐损失和语义层次一致性损失，使用测地距离分类。

Result: 实验表明，方法性能优于现有方法。

Conclusion: 双曲嵌入在WSI分析中具有潜力。

Abstract: Pathology is essential for cancer diagnosis, with multiple instance learning
(MIL) widely used for whole slide image (WSI) analysis. WSIs exhibit a natural
hierarchy -- patches, regions, and slides -- with distinct semantic
associations. While some methods attempt to leverage this hierarchy for
improved representation, they predominantly rely on Euclidean embeddings, which
struggle to fully capture semantic hierarchies. To address this limitation, we
propose HyperPath, a novel method that integrates knowledge from textual
descriptions to guide the modeling of semantic hierarchies of WSIs in
hyperbolic space, thereby enhancing WSI classification. Our approach adapts
both visual and textual features extracted by pathology vision-language
foundation models to the hyperbolic space. We design an Angular Modality
Alignment Loss to ensure robust cross-modal alignment, while a Semantic
Hierarchy Consistency Loss further refines feature hierarchies through
entailment and contradiction relationships and thus enhance semantic coherence.
The classification is performed with geodesic distance, which measures the
similarity between entities in the hyperbolic semantic hierarchy. This
eliminates the need for linear classifiers and enables a geometry-aware
approach to WSI analysis. Extensive experiments show that our method achieves
superior performance across tasks compared to existing methods, highlighting
the potential of hyperbolic embeddings for WSI analysis.

</details>


### [170] [Robustness Evaluation of OCR-based Visual Document Understanding under Multi-Modal Adversarial Attacks](https://arxiv.org/abs/2506.16407)
*Dong Nguyen Tien,Dung D. Le*

Main category: cs.CV

TL;DR: 该论文提出了首个统一框架，用于生成和评估基于OCR的视觉文档理解（VDU）模型的多模态对抗攻击，涵盖六种基于梯度的布局攻击场景。实验表明，行级攻击和复合扰动（BBox + Pixel + Text）对模型性能影响最大。


<details>
  <summary>Details</summary>
Motivation: 尽管VDU系统在信息提取方面表现优异，但其在真实对抗扰动下的鲁棒性尚未充分研究。

Method: 提出统一框架，生成和评估多模态对抗攻击，包括六种梯度布局攻击场景，涉及OCR边界框、像素和文本的操纵，并设置布局扰动预算（如IoU ≥ 0.6）以保持合理性。

Result: 在四个数据集和六种模型上的实验显示，行级攻击和复合扰动导致性能下降最严重，PGD-based BBox扰动在所有模型中优于随机移位基线。

Conclusion: 研究验证了布局预算、文本修改和对抗可转移性的影响，为VDU模型的鲁棒性评估提供了新方法。

Abstract: Visual Document Understanding (VDU) systems have achieved strong performance
in information extraction by integrating textual, layout, and visual signals.
However, their robustness under realistic adversarial perturbations remains
insufficiently explored. We introduce the first unified framework for
generating and evaluating multi-modal adversarial attacks on OCR-based VDU
models. Our method covers six gradient-based layout attack scenarios,
incorporating manipulations of OCR bounding boxes, pixels, and texts across
both word and line granularities, with constraints on layout perturbation
budget (e.g., IoU >= 0.6) to preserve plausibility.
  Experimental results across four datasets (FUNSD, CORD, SROIE, DocVQA) and
six model families demonstrate that line-level attacks and compound
perturbations (BBox + Pixel + Text) yield the most severe performance
degradation. Projected Gradient Descent (PGD)-based BBox perturbations
outperform random-shift baselines in all investigated models. Ablation studies
further validate the impact of layout budget, text modification, and
adversarial transferability.

</details>


### [171] [Efficient Transformations in Deep Learning Convolutional Neural Networks](https://arxiv.org/abs/2506.16418)
*Berk Yilmaz,Daniel Fidel Harvey,Prajit Dhuri*

Main category: cs.CV

TL;DR: 研究探讨了在ResNet50 CNN模型中集成FFT、WHT和DCT信号处理变换对图像分类的影响，发现WHT显著降低能耗并提高准确率。


<details>
  <summary>Details</summary>
Motivation: 评估信号处理变换在CNN中的计算效率、能耗和分类准确率之间的权衡。

Method: 在ResNet50中集成FFT、WHT和DCT，使用CIFAR-100数据集进行实验。

Result: WHT显著降低能耗（从25,606 kJ降至39 kJ），同时提高准确率（从66%提升至79%）。

Conclusion: WHT是一种高效且有效的能量受限CNN应用解决方案。

Abstract: This study investigates the integration of signal processing transformations
-- Fast Fourier Transform (FFT), Walsh-Hadamard Transform (WHT), and Discrete
Cosine Transform (DCT) -- within the ResNet50 convolutional neural network
(CNN) model for image classification. The primary objective is to assess the
trade-offs between computational efficiency, energy consumption, and
classification accuracy during training and inference. Using the CIFAR-100
dataset (100 classes, 60,000 images), experiments demonstrated that
incorporating WHT significantly reduced energy consumption while improving
accuracy. Specifically, a baseline ResNet50 model achieved a testing accuracy
of 66%, consuming an average of 25,606 kJ per model. In contrast, a modified
ResNet50 incorporating WHT in the early convolutional layers achieved 74%
accuracy, and an enhanced version with WHT applied to both early and late
layers achieved 79% accuracy, with an average energy consumption of only 39 kJ
per model. These results demonstrate the potential of WHT as a highly efficient
and effective approach for energy-constrained CNN applications.

</details>


### [172] [Structured Semantic 3D Reconstruction (S23DR) Challenge 2025 -- Winning solution](https://arxiv.org/abs/2506.16421)
*Jan Skvrna,Lukas Neumann*

Main category: cs.CV

TL;DR: 本文介绍了S23DR Challenge 2025的获胜方案，通过3D深度学习方法从稀疏点云和语义分割中预测房屋的3D屋顶线框。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏点云和语义分割中预测3D屋顶线框的挑战。

Method: 直接在3D空间中操作，首先从COLMAP点云中识别顶点候选，使用Gestalt分割；然后采用两个PointNet-like模型，一个用于通过分析局部立方体块来细化和分类顶点候选，另一个用于通过处理连接顶点对的圆柱区域来预测边缘。

Result: 在私有排行榜上获得了0.43的混合结构分数（HSS），赢得了比赛。

Conclusion: 提出的两阶段3D深度学习方法在预测3D屋顶线框任务中表现优异。

Abstract: This paper presents the winning solution for the S23DR Challenge 2025, which
involves predicting a house's 3D roof wireframe from a sparse point cloud and
semantic segmentations. Our method operates directly in 3D, first identifying
vertex candidates from the COLMAP point cloud using Gestalt segmentations. We
then employ two PointNet-like models: one to refine and classify these
candidates by analyzing local cubic patches, and a second to predict edges by
processing the cylindrical regions connecting vertex pairs. This two-stage, 3D
deep learning approach achieved a winning Hybrid Structure Score (HSS) of 0.43
on the private leaderboard.

</details>


### [173] [How Far Can Off-the-Shelf Multimodal Large Language Models Go in Online Episodic Memory Question Answering?](https://arxiv.org/abs/2506.16450)
*Giuseppe Lando,Rosario Forte,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 研究探讨了现成的多模态大语言模型（MLLMs）能否无需额外训练即可处理在线情景记忆视频问答（OEM-VQA）。通过将流式自我中心视频转换为轻量级文本记忆，并在QAEgo4D-Closed基准测试中达到56.0%的准确率，同时存储效率高出10^4/10^5倍。


<details>
  <summary>Details</summary>
Motivation: 探索现成MLLMs在OEM-VQA任务中的适用性，避免额外训练成本。

Method: 使用MLLM描述模块将视频转换为轻量级文本记忆（每分钟3.6 kB），并通过LLM推理模块回答多选题。

Result: 在QAEgo4D-Closed基准测试中达到56.0%准确率，存储效率显著高于现有专用系统。

Conclusion: 该方法展示了现成MLLMs在OEM-VQA任务中的潜力，同时为未来研究提供了改进方向。

Abstract: We investigate whether off-the-shelf Multimodal Large Language Models (MLLMs)
can tackle Online Episodic-Memory Video Question Answering (OEM-VQA) without
additional training. Our pipeline converts a streaming egocentric video into a
lightweight textual memory, only a few kilobytes per minute, via an MLLM
descriptor module, and answers multiple-choice questions by querying this
memory with an LLM reasoner module. On the QAEgo4D-Closed benchmark, our best
configuration attains 56.0% accuracy with 3.6 kB per minute storage, matching
the performance of dedicated state-of-the-art systems while being 10**4/10**5
times more memory-efficient. Extensive ablations provides insights into the
role of each component and design choice, and highlight directions of
improvement for future research.

</details>


### [174] [Spotting tell-tale visual artifacts in face swapping videos: strengths and pitfalls of CNN detectors](https://arxiv.org/abs/2506.16497)
*Riccardo Ziglio,Cecilia Pasquini,Silvio Ranise*

Main category: cs.CV

TL;DR: 论文研究了视频流中人脸交换操作的检测方法，重点分析了遮挡视觉线索的有效性，发现CNN在相同数据源下表现优秀，但在跨数据集时泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 由于自动化和实时工具的进步，视频流中的人脸交换操作对远程视频通信构成威胁，需要有效的检测方法。

Method: 通过基准测试CNN驱动的数据模型，分析其在两个数据集（包括一个新收集的数据集）上的表现，并评估其在不同采集源和交换算法中的泛化能力。

Result: CNN架构在相同数据源下表现优异，但在跨数据集时难以稳健地捕捉遮挡视觉线索。

Conclusion: 需要专门的检测策略来处理遮挡引入的视觉伪影。

Abstract: Face swapping manipulations in video streams represents an increasing threat
in remote video communications, due to advances
  in automated and real-time tools. Recent literature proposes to characterize
and exploit visual artifacts introduced in video frames
  by swapping algorithms when dealing with challenging physical scenes, such as
face occlusions. This paper investigates the
  effectiveness of this approach by benchmarking CNN-based data-driven models
on two data corpora (including a newly collected
  one) and analyzing generalization capabilities with respect to different
acquisition sources and swapping algorithms. The results
  confirm excellent performance of general-purpose CNN architectures when
operating within the same data source, but a significant
  difficulty in robustly characterizing occlusion-based visual cues across
datasets. This highlights the need for specialized detection
  strategies to deal with such artifacts.

</details>


### [175] [Hunyuan3D 2.5: Towards High-Fidelity 3D Assets Generation with Ultimate Details](https://arxiv.org/abs/2506.16504)
*Zeqiang Lai,Yunfei Zhao,Haolin Liu,Zibo Zhao,Qingxiang Lin,Huiwen Shi,Xianghui Yang,Mingxin Yang,Shuhui Yang,Yifei Feng,Sheng Zhang,Xin Huang,Di Luo,Fan Yang,Fang Yang,Lifu Wang,Sicong Liu,Yixuan Tang,Yulin Cai,Zebin He,Tian Liu,Yuhong Liu,Jie Jiang,Linus,Jingwei Huang,Chunchao Guo*

Main category: cs.CV

TL;DR: Hunyuan3D 2.5是一套强大的3D扩散模型，用于生成高保真和细节丰富的3D资产，在形状和纹理生成方面均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 旨在通过改进形状和纹理生成技术，缩小生成3D资产与手工制作3D资产之间的差距。

Method: 采用两阶段流程，引入新的形状基础模型LATTICE（10B参数），并结合基于物理的渲染（PBR）和多视图架构。

Result: 在形状和端到端纹理生成方面显著优于先前方法。

Conclusion: Hunyuan3D 2.5在3D资产生成领域取得了重要进展，提升了生成质量。

Abstract: In this report, we present Hunyuan3D 2.5, a robust suite of 3D diffusion
models aimed at generating high-fidelity and detailed textured 3D assets.
Hunyuan3D 2.5 follows two-stages pipeline of its previous version Hunyuan3D
2.0, while demonstrating substantial advancements in both shape and texture
generation. In terms of shape generation, we introduce a new shape foundation
model -- LATTICE, which is trained with scaled high-quality datasets,
model-size, and compute. Our largest model reaches 10B parameters and generates
sharp and detailed 3D shape with precise image-3D following while keeping mesh
surface clean and smooth, significantly closing the gap between generated and
handcrafted 3D shapes. In terms of texture generation, it is upgraded with
phyiscal-based rendering (PBR) via a novel multi-view architecture extended
from Hunyuan3D 2.0 Paint model. Our extensive evaluation shows that Hunyuan3D
2.5 significantly outperforms previous methods in both shape and end-to-end
texture generation.

</details>


### [176] [How Hard Is Snow? A Paired Domain Adaptation Dataset for Clear and Snowy Weather: CADC+](https://arxiv.org/abs/2506.16531)
*Mei Qi Tang,Sean Sedwards,Chengjie Huang,Krzysztof Czarnecki*

Main category: cs.CV

TL;DR: CADC+是首个用于自动驾驶冬季条件的配对天气域适应数据集，扩展了CADC数据集，通过匹配雪天和晴天数据，减少非雪因素的域偏移，并初步评估了雪对3D目标检测性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前数据集在雪天和晴天条件下缺乏足够标注数据，或依赖不真实的合成数据，导致评估不准确。

Method: 扩展CADC数据集，配对雪天和晴天数据，最小化非雪因素的域偏移。

Result: 雪引入了随机性和认知不确定性，既是噪声也是独特的数据域。

Conclusion: CADC+为研究雪对3D目标检测的影响提供了更准确的数据基础。

Abstract: The impact of snowfall on 3D object detection performance remains
underexplored. Conducting such an evaluation requires a dataset with sufficient
labelled data from both weather conditions, ideally captured in the same
driving environment. Current driving datasets with LiDAR point clouds either do
not provide enough labelled data in both snowy and clear weather conditions, or
rely on de-snowing methods to generate synthetic clear weather. Synthetic data
often lacks realism and introduces an additional domain shift that confounds
accurate evaluations. To address these challenges, we present CADC+, the first
paired weather domain adaptation dataset for autonomous driving in winter
conditions. CADC+ extends the Canadian Adverse Driving Conditions dataset
(CADC) using clear weather data that was recorded on the same roads and in the
same period as CADC. To create CADC+, we pair each CADC sequence with a clear
weather sequence that matches the snowy sequence as closely as possible. CADC+
thus minimizes the domain shift resulting from factors unrelated to the
presence of snow. We also present some preliminary results using CADC+ to
evaluate the effect of snow on 3D object detection performance. We observe that
snow introduces a combination of aleatoric and epistemic uncertainties, acting
as both noise and a distinct data domain.

</details>


### [177] [From Semantic To Instance: A Semi-Self-Supervised Learning Approach](https://arxiv.org/abs/2506.16563)
*Keyhan Najafian,Farhad Maleki,Lingling Jin,Ian Stavness*

Main category: cs.CV

TL;DR: 提出了一种半自监督学习方法GLMask，用于实例分割，减少手动标注需求，在农业和通用数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决农业图像中密集、自遮挡对象的实例分割问题，减少大规模像素级标注的需求。

Method: 设计GLMask图像-掩码表示，关注形状、纹理和模式，生成语义分割并转换为实例分割。

Result: 在小麦头实例分割上达到98.5% mAP@50，在COCO数据集上提升12.6%。

Conclusion: 该方法不仅适用于农业，还可推广到其他类似数据特征的领域。

Abstract: Instance segmentation is essential for applications such as automated
monitoring of plant health, growth, and yield. However, extensive effort is
required to create large-scale datasets with pixel-level annotations of each
object instance for developing instance segmentation models that restrict the
use of deep learning in these areas. This challenge is more significant in
images with densely packed, self-occluded objects, which are common in
agriculture. To address this challenge, we propose a semi-self-supervised
learning approach that requires minimal manual annotation to develop a
high-performing instance segmentation model. We design GLMask, an image-mask
representation for the model to focus on shape, texture, and pattern while
minimizing its dependence on color features. We develop a pipeline to generate
semantic segmentation and then transform it into instance-level segmentation.
The proposed approach substantially outperforms the conventional instance
segmentation models, establishing a state-of-the-art wheat head instance
segmentation model with mAP@50 of 98.5%. Additionally, we assessed the proposed
methodology on the general-purpose Microsoft COCO dataset, achieving a
significant performance improvement of over 12.6% mAP@50. This highlights that
the utility of our proposed approach extends beyond precision agriculture and
applies to other domains, specifically those with similar data characteristics.

</details>


### [178] [SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage](https://arxiv.org/abs/2506.16578)
*Tongan Cai,Haomiao Ni,Wenchao Ma,Yuan Xue,Qian Ma,Rachel Leicht,Kelvin Wong,John Volpi,Stephen T. C. Wong,James Z. Wang,Sharon X. Huang*

Main category: cs.CV

TL;DR: SafeTriage是一种新方法，通过去识别化患者面部视频保留关键运动特征，解决AI模型依赖真实患者数据的伦理和隐私问题。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在卒中分诊中依赖真实患者数据引发的伦理和隐私挑战。

Method: 利用预训练视频运动转移模型将真实患者面部运动映射到合成身份上，引入条件生成模型调整输入空间。

Result: 合成视频有效保留卒中相关面部模式，隐私保护强且诊断准确性高。

Conclusion: SafeTriage为神经疾病数据共享和AI临床分析提供了安全、伦理的基础。

Abstract: Effective stroke triage in emergency settings often relies on clinicians'
ability to identify subtle abnormalities in facial muscle coordination. While
recent AI models have shown promise in detecting such patterns from patient
facial videos, their reliance on real patient data raises significant ethical
and privacy challenges -- especially when training robust and generalizable
models across institutions. To address these concerns, we propose SafeTriage, a
novel method designed to de-identify patient facial videos while preserving
essential motion cues crucial for stroke diagnosis. SafeTriage leverages a
pretrained video motion transfer (VMT) model to map the motion characteristics
of real patient faces onto synthetic identities. This approach retains
diagnostically relevant facial dynamics without revealing the patients'
identities. To mitigate the distribution shift between normal population
pre-training videos and patient population test videos, we introduce a
conditional generative model for visual prompt tuning, which adapts the input
space of the VMT model to ensure accurate motion transfer without needing to
fine-tune the VMT model backbone. Comprehensive evaluation, including
quantitative metrics and clinical expert assessments, demonstrates that
SafeTriage-produced synthetic videos effectively preserve stroke-relevant
facial patterns, enabling reliable AI-based triage. Our evaluations also show
that SafeTriage provides robust privacy protection while maintaining diagnostic
accuracy, offering a secure and ethically sound foundation for data sharing and
AI-driven clinical analysis in neurological disorders.

</details>


### [179] [Spatially-Aware Evaluation of Segmentation Uncertainty](https://arxiv.org/abs/2506.16589)
*Tal Zeevi,Eléonore V. Lieffrig,Lawrence H. Staib,John A. Onofrey*

Main category: cs.CV

TL;DR: 论文提出了三种空间感知的指标，用于评估医学图像分割中的不确定性，考虑了结构和边界信息，验证结果显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统不确定性评估指标忽略空间上下文和解剖结构，导致对不确定性模式的区分不足。

Method: 提出三种结合结构和边界信息的空间感知指标，并在前列腺分区分割挑战数据上进行验证。

Result: 新指标能更好地与临床重要因素对齐，并区分有意义和虚假的不确定性模式。

Conclusion: 空间感知指标在医学图像分割中表现更优，具有临床实用性。

Abstract: Uncertainty maps highlight unreliable regions in segmentation predictions.
However, most uncertainty evaluation metrics treat voxels independently,
ignoring spatial context and anatomical structure. As a result, they may assign
identical scores to qualitatively distinct patterns (e.g., scattered vs.
boundary-aligned uncertainty). We propose three spatially aware metrics that
incorporate structural and boundary information and conduct a thorough
validation on medical imaging data from the prostate zonal segmentation
challenge within the Medical Segmentation Decathlon. Our results demonstrate
improved alignment with clinically important factors and better discrimination
between meaningful and spurious uncertainty patterns.

</details>


### [180] [MetaQAP -- A Meta-Learning Approach for Quality-Aware Pretraining in Image Quality Assessment](https://arxiv.org/abs/2506.16601)
*Muhammad Azeem Aslam,Muhammad Hamza,Nisar Ahmed,Gulshan Saleem,Zhu Shuangtong,Hu Hongfei,Xu Wei,Saba Aslam,Wang Jun*

Main category: cs.CV

TL;DR: MetaQAP是一种新型无参考图像质量评估模型，通过质量感知预训练和元学习解决IQA挑战，在多个基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于人类感知的主观性和真实世界图像失真的复杂性，图像质量评估（IQA）任务具有挑战性。

Method: MetaQAP结合质量感知预训练CNN、质量感知损失函数和元学习集成模型。

Result: 在LiveCD、KonIQ-10K和BIQ2021数据集上，PLCC和SROCC得分分别为0.9885/0.9812、0.9702/0.9658和0.884/0.8765，优于现有方法。

Conclusion: MetaQAP不仅解决了真实失真的复杂性，还为IQA领域提供了可扩展的框架和方法论。

Abstract: Image Quality Assessment (IQA) is a critical task in a wide range of
applications but remains challenging due to the subjective nature of human
perception and the complexity of real-world image distortions. This study
proposes MetaQAP, a novel no-reference IQA model designed to address these
challenges by leveraging quality-aware pre-training and meta-learning. The
model performs three key contributions: pre-training Convolutional Neural
Networks (CNNs) on a quality-aware dataset, implementing a quality-aware loss
function to optimize predictions, and integrating a meta-learner to form an
ensemble model that effectively combines predictions from multiple base models.
Experimental evaluations were conducted on three benchmark datasets: LiveCD,
KonIQ-10K, and BIQ2021. The proposed MetaQAP model achieved exceptional
performance with Pearson Linear Correlation Coefficient (PLCC) and Spearman
Rank Order Correlation Coefficient (SROCC) scores of 0.9885/0.9812 on LiveCD,
0.9702/0.9658 on KonIQ-10K, and 0.884/0.8765 on BIQ2021, outperforming existing
IQA methods. Cross-dataset evaluations further demonstrated the
generalizability of the model, with PLCC and SROCC scores ranging from 0.6721
to 0.8023 and 0.6515 to 0.7805, respectively, across diverse datasets. The
ablation study confirmed the significance of each model component, revealing
substantial performance degradation when critical elements such as the
meta-learner or quality-aware loss function were omitted. MetaQAP not only
addresses the complexities of authentic distortions but also establishes a
robust and generalizable framework for practical IQA applications. By advancing
the state-of-the-art in no-reference IQA, this research provides valuable
insights and methodologies for future improvements and extensions in the field.

</details>


### [181] [Leveraging CNN and IoT for Effective E-Waste Management](https://arxiv.org/abs/2506.16647)
*Ajesh Thangaraj Nadar,Gabriel Nixon Raj,Soham Chandane,Sushant Bhat*

Main category: cs.CV

TL;DR: 本文提出了一种结合物联网和轻量级CNN的分类系统，用于电子废物的识别、分类和路由，以提高回收效率。


<details>
  <summary>Details</summary>
Motivation: 电子废物的不当处理和回收不足带来了严重的环境和健康风险，需要高效解决方案。

Method: 通过集成摄像头系统和数字称重设备，利用轻量级CNN分类管道，基于视觉和重量属性自动分类电子废物。

Result: 系统能够实时检测电子废物组件（如电路板、传感器和电线），优化智能回收流程。

Conclusion: 该框架显著提高了废物处理的效率，为电子废物管理提供了可行的技术方案。

Abstract: The increasing proliferation of electronic devices in the modern era has led
to a significant surge in electronic waste (e-waste). Improper disposal and
insufficient recycling of e-waste pose serious environmental and health risks.
This paper proposes an IoT-enabled system combined with a lightweight CNN-based
classification pipeline to enhance the identification, categorization, and
routing of e-waste materials. By integrating a camera system and a digital
weighing scale, the framework automates the classification of electronic items
based on visual and weight-based attributes. The system demonstrates how
real-time detection of e-waste components such as circuit boards, sensors, and
wires can facilitate smart recycling workflows and improve overall waste
processing efficiency.

</details>


### [182] [A Comparative Analysis of Principal Component Analysis (PCA) and Singular Value Decomposition (SVD) as Dimensionality Reduction Techniques](https://arxiv.org/abs/2506.16663)
*Michael Gyimadu,Gregory Bell*

Main category: cs.CV

TL;DR: 本文对PCA和SVD两种线性降维技术进行了纯理论比较，评估了它们的可解释性、数值稳定性及适用场景，并提出了选择指南。


<details>
  <summary>Details</summary>
Motivation: 高维图像数据通常需要降维处理，但缺乏对PCA和SVD的理论比较指南。

Method: 从基本原理推导算法，评估其特性，并综合文献提出选择建议。

Result: 提供了基于理论的选择PCA或SVD的实用指南。

Conclusion: 总结了局限性，并指出未来实验工作的方向。

Abstract: High-dimensional image data often require dimensionality reduction before
further analysis. This paper provides a purely analytical comparison of two
linear techniques-Principal Component Analysis (PCA) and Singular Value
Decomposition (SVD). After the derivation of each algorithm from first
principles, we assess their interpretability, numerical stability, and
suitability for differing matrix shapes. building on classical and recent
numerical literature, We synthesize rule-of-thumb guidelines for choosing one
out of the two algorithms without empirical benchmarking, building on classical
and recent numerical literature. Limitations and directions for future
experimental work are outlined at the end.

</details>


### [183] [Extracting Multimodal Learngene in CLIP: Unveiling the Multimodal Generalizable Knowledge](https://arxiv.org/abs/2506.16673)
*Ruiming Chen,Junming Yang,Shiyu Xia,Xu Yang,Jing Wang,Xin Geng*

Main category: cs.CV

TL;DR: MM-LG是一种新型框架，通过多模态块提取CLIP中的通用知识，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有Learngene范式在多模态场景中无法处理通用知识的问题。

Method: 使用多模态和单模态块加权提取通用知识，并初始化不同规模和模态的模型。

Result: 在多个数据集上性能优于现有方法，同时减少约2.8倍的预训练成本和25%的参数存储。

Conclusion: MM-LG高效且通用，适合多样化的下游任务部署。

Abstract: CLIP (Contrastive Language-Image Pre-training) has attracted widespread
attention for its multimodal generalizable knowledge, which is significant for
downstream tasks. However, the computational overhead of a large number of
parameters and large-scale pre-training poses challenges of pre-training a
different scale of CLIP. Learngene extracts the generalizable components termed
as learngene from an ancestry model and initializes diverse descendant models
with it. Previous Learngene paradigms fail to handle the generalizable
knowledge in multimodal scenarios. In this paper, we put forward the idea of
utilizing a multimodal block to extract the multimodal generalizable knowledge,
which inspires us to propose MM-LG (Multimodal Learngene), a novel framework
designed to extract and leverage generalizable components from CLIP.
Specifically, we first establish multimodal and unimodal blocks to extract the
multimodal and unimodal generalizable knowledge in a weighted-sum manner.
Subsequently, we employ these components to numerically initialize descendant
models of varying scales and modalities. Extensive experiments demonstrate
MM-LG's effectiveness, which achieves performance gains over existing learngene
approaches (e.g.,+3.1% on Oxford-IIIT PET and +4.13% on Flickr30k) and
comparable or superior results to the pre-training and fine-tuning paradigm
(e.g.,+1.9% on Oxford-IIIT PET and +3.65% on Flickr30k). Notably, MM-LG
requires only around 25% of the parameter storage while reducing around 2.8
times pre-training costs for diverse model scales compared to the pre-training
and fine-tuning paradigm, making it particularly suitable for efficient
deployment across diverse downstream tasks.

</details>


### [184] [How to Train your Text-to-Image Model: Evaluating Design Choices for Synthetic Training Captions](https://arxiv.org/abs/2506.16679)
*Manuel Brack,Sudeep Katakol,Felix Friedrich,Patrick Schramowski,Hareesh Ravi,Kristian Kersting,Ajinkya Kale*

Main category: cs.CV

TL;DR: 研究探讨了合成标题策略对文本到图像模型性能的影响，发现密集高质量标题提升文本对齐但可能牺牲美学和多样性，而随机长度标题则能平衡美学与对齐。


<details>
  <summary>Details</summary>
Motivation: 现有研究缺乏对合成标题设计选择的深入理解，本研究旨在填补这一空白。

Method: 系统研究不同合成标题策略对模型性能的影响。

Result: 密集高质量标题增强文本对齐但可能影响美学和多样性；随机长度标题平衡美学与对齐且不损害多样性。

Conclusion: 标题设计对模型性能至关重要，研究为文本到图像生成提供了更有效的训练数据策略。

Abstract: Training data is at the core of any successful text-to-image models. The
quality and descriptiveness of image text are crucial to a model's performance.
Given the noisiness and inconsistency in web-scraped datasets, recent works
shifted towards synthetic training captions. While this setup is generally
believed to produce more capable models, current literature does not provide
any insights into its design choices. This study closes this gap by
systematically investigating how different synthetic captioning strategies
impact the downstream performance of text-to-image models. Our experiments
demonstrate that dense, high-quality captions enhance text alignment but may
introduce trade-offs in output aesthetics and diversity. Conversely, captions
of randomized lengths yield balanced improvements across aesthetics and
alignment without compromising sample diversity. We also demonstrate that
varying caption distributions introduce significant shifts in the output bias
of a trained model. Our findings underscore the importance of caption design in
achieving optimal model performance and provide practical insights for more
effective training data strategies in text-to-image generation.

</details>


### [185] [DepthVanish: Optimizing Adversarial Interval Structures for Stereo-Depth-Invisible Patches](https://arxiv.org/abs/2506.16690)
*Yun Xing,Yue Cao,Nhat Chung,Jie Zhang,Ivor Tsang,Ming-Ming Cheng,Yang Liu,Lei Ma,Qing Guo*

Main category: cs.CV

TL;DR: 研究发现条纹结构显著提升对抗性贴片攻击效果，优化后的贴片可攻击主流立体深度估计方法和商用RGB-D相机。


<details>
  <summary>Details</summary>
Motivation: 揭示立体深度估计系统的漏洞，提升对抗性攻击在物理世界中的实用性。

Method: 引入条纹结构优化贴片设计，联合优化结构和纹理元素，进行广泛实验验证。

Result: 优化后的贴片成功攻击RAFT-Stereo、STTR及Intel RealSense相机。

Conclusion: 条纹结构显著提升攻击效果，为立体系统安全评估提供实用工具。

Abstract: Stereo Depth estimation is a critical task in autonomous driving and
robotics, where inaccuracies (such as misidentifying nearby objects as distant)
can lead to dangerous situations. Adversarial attacks against stereo depth
estimation can help reveal vulnerabilities before deployment. Previous work has
shown that repeating optimized textures can effectively mislead stereo depth
estimation in digital settings. However, our research reveals that these
naively repeated texture structures perform poorly in physical-world
implementations, i.e., when deployed as patches, limiting their practical
utility for testing stereo depth estimation systems. In this work, for the
first time, we discover that introducing regular intervals between repeated
textures, creating a striped structure, significantly enhances the patch attack
effectiveness. Through extensive experimentation, we analyze how variations of
this novel structure influence the performance. Based on these insights, we
develop a novel stereo depth attack that jointly optimizes both the striped
structure and texture elements. Our generated adversarial patches can be
inserted into any scenes and successfully attack state-of-the-art stereo depth
estimation methods, i.e., RAFT-Stereo and STTR. Most critically, our patch can
also attack commercial RGB-D cameras (Intel RealSense) in real-world
conditions, demonstrating their practical relevance for security assessment of
stereo systems.

</details>


### [186] [LaVi: Efficient Large Vision-Language Models via Internal Feature Modulation](https://arxiv.org/abs/2506.16691)
*Tongtian Yue,Longteng Guo,Yepeng Tang,Zijia Zhao,Xinxin Zhu,Hua Huang,Jing Liu*

Main category: cs.CV

TL;DR: LaVi提出了一种新型LVLM，通过内部特征调制实现高效视觉-语言融合，显著提升效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有LVLM方法在视觉-语言融合上效率低下，或破坏模型结构，或引入计算负担，限制了可扩展性和效率。

Method: LaVi通过轻量级自适应变换，将视觉条件注入层归一化的仿射参数，直接调制语言隐藏状态，避免长上下文扩展。

Result: 在15个图像和视频基准测试中，LaVi不仅达到SOTA性能，还减少94% FLOPs，提升3.1倍推理速度，内存减半。

Conclusion: LaVi是一种可扩展且实用的实时多模态推理解决方案，代码和模型即将发布。

Abstract: Despite the impressive advancements of Large Vision-Language Models (LVLMs),
existing approaches suffer from a fundamental bottleneck: inefficient
visual-language integration. Current methods either disrupt the model's
inherent structure or introduce severe long-context computational burden,
severely limiting scalability and efficiency. In this paper, we rethink
multimodal integration and present LaVi, a novel LVLM that enables seamless and
efficient vision-language fusion through internal feature modulation within the
Large Language Models (LLMs). Unlike dominant LVLMs that rely on visual token
concatenation, LaVi bypasses long-context expansion by introducing a
lightweight and adaptive transformation, which incorporates visual context by
injecting token-wise vision-conditioned deltas into the affine parameters of
layer normalization. This mechanism directly modulates linguistic hidden states
based on visual input, ensuring precise vision-language alignment while
preserving the LLM's linguistic priors and drastically reducing computational
costs. Extensive evaluations across 15 image and video benchmarks demonstrate
that LaVi not only achieves state-of-the-art multimodal performance but also
dramatically enhances efficiency. Compared to LLaVA-OV-7B, LaVi reduces FLOPs
by 94.0%, improves inference speed by 3.1 times, and cuts memory usage in half
- establishing LaVi as a scalable and practical solution for real-time
multimodal reasoning. The code and models will be released soon.

</details>


### [187] [Language-driven Description Generation and Common Sense Reasoning for Video Action Recognition](https://arxiv.org/abs/2506.16701)
*Xiaodan Hu,Chuhang Zou,Suchen Wang,Jaechul Kim,Narendra Ahuja*

Main category: cs.CV

TL;DR: 提出了一种结合语言驱动常识先验的框架，用于识别遮挡严重的单目视频动作序列。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分利用语言模型中的常识先验（如场景上下文），而这些先验对理解视频动作至关重要。

Method: 1) 视频上下文总结组件生成候选对象、活动及其交互；2) 描述生成模块通过辅助提示和常识推理描述场景并推断后续活动；3) 多模态活动识别头结合视觉和文本线索识别动作。

Result: 在Action Genome和Charades数据集上验证了方法的有效性。

Conclusion: 结合语言驱动的常识先验能显著提升遮挡视频动作识别的性能。

Abstract: Recent video action recognition methods have shown excellent performance by
adapting large-scale pre-trained language-image models to the video domain.
However, language models contain rich common sense priors - the scene contexts
that humans use to constitute an understanding of objects, human-object
interactions, and activities - that have not been fully exploited. In this
paper, we introduce a framework incorporating language-driven common sense
priors to identify cluttered video action sequences from monocular views that
are often heavily occluded. We propose: (1) A video context summary component
that generates candidate objects, activities, and the interactions between
objects and activities; (2) A description generation module that describes the
current scene given the context and infers subsequent activities, through
auxiliary prompts and common sense reasoning; (3) A multi-modal activity
recognition head that combines visual and textual cues to recognize video
actions. We demonstrate the effectiveness of our approach on the challenging
Action Genome and Charades datasets.

</details>


### [188] [Few-Shot Generalized Category Discovery With Retrieval-Guided Decision Boundary Enhancement](https://arxiv.org/abs/2506.16728)
*Yunhan Ren,Feng Luo,Siyu Huang*

Main category: cs.CV

TL;DR: 论文提出了一种Few-shot Generalized Category Discovery (FSGCD)任务，针对已知类别信息稀缺的情况，通过决策边界增强框架和基于亲和力的检索方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有广义类别发现(GCD)模型在有限标记样本和少量已知类别下的性能尚未充分研究，因此提出了FSGCD任务以解决这一问题。

Method: 采用决策边界增强框架，包括决策边界预训练模块和两阶段检索引导的决策边界优化策略，利用亲和力检索伪标记样本优化边界。

Result: 在六个公共GCD基准测试中，该方法在FSGCD设置下优于现有方法。

Conclusion: 提出的方法有效解决了已知信息稀缺条件下的GCD问题，性能显著提升。

Abstract: While existing Generalized Category Discovery (GCD) models have achieved
significant success, their performance with limited labeled samples and a small
number of known categories remains largely unexplored. In this work, we
introduce the task of Few-shot Generalized Category Discovery (FSGCD), aiming
to achieve competitive performance in GCD tasks under conditions of known
information scarcity. To tackle this challenge, we propose a decision boundary
enhancement framework with affinity-based retrieval. Our framework is designed
to learn the decision boundaries of known categories and transfer these
boundaries to unknown categories. First, we use a decision boundary
pre-training module to mitigate the overfitting of pre-trained information on
known category boundaries and improve the learning of these decision boundaries
using labeled samples. Second, we implement a two-stage retrieval-guided
decision boundary optimization strategy. Specifically, this strategy further
enhances the severely limited known boundaries by using affinity-retrieved
pseudo-labeled samples. Then, these refined boundaries are applied to unknown
clusters via guidance from affinity-based feature retrieval. Experimental
results demonstrate that our proposed method outperforms existing methods on
six public GCD benchmarks under the FSGCD setting. The codes are available at:
https://github.com/Ryh1218/FSGCD

</details>


### [189] [TeSG: Textual Semantic Guidance for Infrared and Visible Image Fusion](https://arxiv.org/abs/2506.16730)
*Mingrui Zhu,Xiru Chen,Xin Wei,Nannan Wang,Xinbo Gao*

Main category: cs.CV

TL;DR: 提出了一种基于文本语义引导的红外与可见光图像融合方法（TeSG），通过多层级语义信息提升融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本引导的红外与可见光图像融合方法对文本语义信息的利用不足。

Method: 引入掩码语义和文本语义两级语义信息，提出TeSG框架，包含语义信息生成器（SIG）、掩码引导交叉注意力模块（MGCA）和文本驱动注意力融合模块（TDAF）。

Result: 实验表明，TeSG在下游任务（如检测和分割）中表现优于现有方法。

Conclusion: TeSG通过有效整合文本语义信息，显著提升了红外与可见光图像融合的性能。

Abstract: Infrared and visible image fusion (IVF) aims to combine complementary
information from both image modalities, producing more informative and
comprehensive outputs. Recently, text-guided IVF has shown great potential due
to its flexibility and versatility. However, the effective integration and
utilization of textual semantic information remains insufficiently studied. To
tackle these challenges, we introduce textual semantics at two levels: the mask
semantic level and the text semantic level, both derived from textual
descriptions extracted by large Vision-Language Models (VLMs). Building on
this, we propose Textual Semantic Guidance for infrared and visible image
fusion, termed TeSG, which guides the image synthesis process in a way that is
optimized for downstream tasks such as detection and segmentation.
Specifically, TeSG consists of three core components: a Semantic Information
Generator (SIG), a Mask-Guided Cross-Attention (MGCA) module, and a Text-Driven
Attentional Fusion (TDAF) module. The SIG generates mask and text semantics
based on textual descriptions. The MGCA module performs initial attention-based
fusion of visual features from both infrared and visible images, guided by mask
semantics. Finally, the TDAF module refines the fusion process with gated
attention driven by text semantics. Extensive experiments demonstrate the
competitiveness of our approach, particularly in terms of performance on
downstream tasks, compared to existing state-of-the-art methods.

</details>


### [190] [3DeepRep: 3D Deep Low-rank Tensor Representation for Hyperspectral Image Inpainting](https://arxiv.org/abs/2506.16735)
*Yunshan Li,Wenwu Gong,Qianqian Wang,Chao Wang,Lili Yang*

Main category: cs.CV

TL;DR: 论文提出了一种新型3方向深度低秩张量表示（3DeepRep）模型，用于高光谱图像修复，通过多方向深度变换和核范数正则化提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注光谱模式的低秩特性，忽略了其他张量模式的低秩结构，限制了修复效果。

Method: 提出3DeepRep模型，沿HSI张量的三个模式进行深度非线性变换，并通过核范数正则化强制低秩性，最后通过可学习聚合模块融合结果。

Result: 在真实HSI数据集上的实验表明，该方法在定性和定量上均优于现有技术。

Conclusion: 3DeepRep模型通过多方向深度变换和低秩正则化，显著提升了高光谱图像修复的性能。

Abstract: Recent approaches based on transform-based tensor nuclear norm (TNN) have
demonstrated notable effectiveness in hyperspectral image (HSI) inpainting by
leveraging low-rank structures in latent representations. Recent developments
incorporate deep transforms to improve low-rank tensor representation; however,
existing approaches typically restrict the transform to the spectral mode,
neglecting low-rank properties along other tensor modes. In this paper, we
propose a novel 3-directional deep low-rank tensor representation (3DeepRep)
model, which performs deep nonlinear transforms along all three modes of the
HSI tensor. To enforce low-rankness, the model minimizes the nuclear norms of
mode-i frontal slices in the corresponding latent space for each direction
(i=1,2,3), forming a 3-directional TNN regularization. The outputs from the
three directional branches are subsequently fused via a learnable aggregation
module to produce the final result. An efficient gradient-based optimization
algorithm is developed to solve the model in a self-supervised manner.
Extensive experiments on real-world HSI datasets demonstrate that the proposed
method achieves superior inpainting performance compared to existing
state-of-the-art techniques, both qualitatively and quantitatively.

</details>


### [191] [Cross-modal Offset-guided Dynamic Alignment and Fusion for Weakly Aligned UAV Object Detection](https://arxiv.org/abs/2506.16737)
*Liu Zongzhen,Luo Hui,Wang Zhixing,Wei Yuxing,Zuo Haorui,Zhang Jianlin*

Main category: cs.CV

TL;DR: 论文提出了一种名为CoDAF的统一框架，通过联合解决弱对齐无人机目标检测中的语义不一致和模态冲突问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 无人机目标检测在环境监测和城市安全中至关重要，但多模态检测中因运动和非同步成像导致的空间错位问题限制了现有方法的有效性。

Method: CoDAF框架包含两个模块：OSA模块通过估计空间偏移和可变形卷积对齐特征；DAFM模块通过动态注意力平衡模态贡献并优化融合特征。

Result: 在标准基准测试中，CoDAF在DroneVehicle数据集上达到了78.6%的mAP。

Conclusion: CoDAF通过统一设计解决了多模态检测中的关键挑战，显著提升了无人机目标检测的鲁棒性。

Abstract: Unmanned aerial vehicle (UAV) object detection plays a vital role in
applications such as environmental monitoring and urban security. To improve
robustness, recent studies have explored multimodal detection by fusing visible
(RGB) and infrared (IR) imagery. However, due to UAV platform motion and
asynchronous imaging, spatial misalignment frequently occurs between
modalities, leading to weak alignment. This introduces two major challenges:
semantic inconsistency at corresponding spatial locations and modality conflict
during feature fusion. Existing methods often address these issues in
isolation, limiting their effectiveness. In this paper, we propose Cross-modal
Offset-guided Dynamic Alignment and Fusion (CoDAF), a unified framework that
jointly tackles both challenges in weakly aligned UAV-based object detection.
CoDAF comprises two novel modules: the Offset-guided Semantic Alignment (OSA),
which estimates attention-based spatial offsets and uses deformable convolution
guided by a shared semantic space to align features more precisely; and the
Dynamic Attention-guided Fusion Module (DAFM), which adaptively balances
modality contributions through gating and refines fused features via
spatial-channel dual attention. By integrating alignment and fusion in a
unified design, CoDAF enables robust UAV object detection. Experiments on
standard benchmarks validate the effectiveness of our approach, with CoDAF
achieving a mAP of 78.6% on the DroneVehicle dataset.

</details>


### [192] [Uncertainty-Aware Variational Information Pursuit for Interpretable Medical Image Analysis](https://arxiv.org/abs/2506.16742)
*Md Nahiduzzaman,Ruwan Tennakoon,Steven Korevaar,Zongyuan Ge,Alireza Bab-Hadiashar*

Main category: cs.CV

TL;DR: 论文提出了一种不确定性感知的变分信息追踪方法（UAV-IP），用于提升医学影像AI决策系统的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有V-IP方法忽略了查询-答案生成中的实例级不确定性，影响了模型的可靠性和临床决策的稳健性。

Method: 通过将不确定性量化整合到V-IP过程中，提出UAV-IP框架。

Result: 在四个医学影像数据集上，UAV-IP的AUC平均提升3.2%，同时生成比基线V-IP更简洁（20%）且信息量不减的解释。

Conclusion: 不确定性感知推理对设计可解释且稳健的医学决策模型至关重要。

Abstract: In medical imaging, AI decision-support systems must balance accuracy and
interpretability to build user trust and support effective clinical
decision-making. Recently, Variational Information Pursuit (V-IP) and its
variants have emerged as interpretable-by-design modeling techniques, aiming to
explain AI decisions in terms of human-understandable, clinically relevant
concepts. However, existing V-IP methods overlook instance-level uncertainties
in query-answer generation, which can arise from model limitations (epistemic
uncertainty) or variability in expert responses (aleatoric uncertainty).
  This paper introduces Uncertainty-Aware V-IP (UAV-IP), a novel framework that
integrates uncertainty quantification into the V-IP process. We evaluate UAV-IP
across four medical imaging datasets, PH2, Derm7pt, BrEaST, and SkinCon,
demonstrating an average AUC improvement of approximately 3.2% while generating
20% more concise explanations compared to baseline V-IP, without sacrificing
informativeness. These findings highlight the importance of uncertainty-aware
reasoning in interpretable by design models for robust and reliable medical
decision-making.

</details>


### [193] [Noise-Informed Diffusion-Generated Image Detection with Anomaly Attention](https://arxiv.org/abs/2506.16743)
*Weinan Guan,Wei Wang,Bo Peng,Ziwen He,Jing Dong,Haonan Cheng*

Main category: cs.CV

TL;DR: 论文提出了一种基于噪声感知自注意力（NASA）模块的新方法，用于检测扩散模型生成的图像，解决了训练中未见扩散模型的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型生成图像质量的提升，信息安全问题日益突出，需要有效检测扩散生成图像以防止恶意滥用。

Method: 通过分析不同扩散模型生成图像的噪声模式，提出NASA模块，结合Swin Transformer构建NASA-Swin架构，并采用跨模态融合嵌入和通道掩码策略。

Result: 实验表明，该方法在检测扩散生成图像方面表现优异，尤其是对未见过的生成方法具有SOTA性能。

Conclusion: NASA-Swin通过噪声感知和跨模态融合，显著提升了扩散生成图像的检测能力。

Abstract: With the rapid development of image generation technologies, especially the
advancement of Diffusion Models, the quality of synthesized images has
significantly improved, raising concerns among researchers about information
security. To mitigate the malicious abuse of diffusion models,
diffusion-generated image detection has proven to be an effective
countermeasure.However, a key challenge for forgery detection is generalising
to diffusion models not seen during training. In this paper, we address this
problem by focusing on image noise. We observe that images from different
diffusion models share similar noise patterns, distinct from genuine images.
Building upon this insight, we introduce a novel Noise-Aware Self-Attention
(NASA) module that focuses on noise regions to capture anomalous patterns. To
implement a SOTA detection model, we incorporate NASA into Swin Transformer,
forming an novel detection architecture NASA-Swin. Additionally, we employ a
cross-modality fusion embedding to combine RGB and noise images, along with a
channel mask strategy to enhance feature learning from both modalities.
Extensive experiments demonstrate the effectiveness of our approach in
enhancing detection capabilities for diffusion-generated images. When
encountering unseen generation methods, our approach achieves the
state-of-the-art performance.Our code is available at
https://github.com/WeinanGuan/NASA-Swin.

</details>


### [194] [Class Agnostic Instance-level Descriptor for Visual Instance Search](https://arxiv.org/abs/2506.16745)
*Qi-Ying Sun,Wan-Lei Zhao,Yi-Bo Miao,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: 该论文提出了一种基于自监督ViT的分层特征子集检测方法，用于解决视觉实例搜索中实例级特征表示不足的问题。


<details>
  <summary>Details</summary>
Motivation: 由于现有监督或弱监督方法在未知类别上表现不佳，需要一种更有效的实例级特征表示方法。

Method: 利用自监督ViT输出的特征集，通过分层方式检测紧凑特征子集，形成层次结构以表示不同语义尺度的实例区域。

Result: 在三个实例搜索基准测试中，该方法显著优于现有最优方法。

Conclusion: 提出的实例级描述符能有效处理已知和未知类别，解决了对象嵌入和遮挡问题。

Abstract: Despite the great success of the deep features in content-based image
retrieval, the visual instance search remains challenging due to the lack of
effective instance level feature representation. Supervised or weakly
supervised object detection methods are not among the options due to their poor
performance on the unknown object categories. In this paper, based on the
feature set output from self-supervised ViT, the instance level region
discovery is modeled as detecting the compact feature subsets in a hierarchical
fashion. The hierarchical decomposition results in a hierarchy of feature
subsets. The non-leaf nodes and leaf nodes on the hierarchy correspond to the
various instance regions in an image of different semantic scales. The
hierarchical decomposition well addresses the problem of object embedding and
occlusions, which are widely observed in the real scenarios. The features
derived from the nodes on the hierarchy make up a comprehensive representation
for the latent instances in the image. Our instance-level descriptor remains
effective on both the known and unknown object categories. Empirical studies on
three instance search benchmarks show that it outperforms state-of-the-art
methods considerably.

</details>


### [195] [Infrared and Visible Image Fusion Based on Implicit Neural Representations](https://arxiv.org/abs/2506.16773)
*Shuchen Sun,Ligen Shi,Chang Liu,Lina Wu,Jun Qiu*

Main category: cs.CV

TL;DR: 提出了一种基于隐式神经表示（INR）的红外与可见光图像融合方法INRFuse，通过神经网络参数化连续函数实现多模态信息融合，支持多分辨率图像直接融合及超分辨率重建。


<details>
  <summary>Details</summary>
Motivation: 结合红外与可见光图像的优势，生成信息丰富且满足视觉或计算需求的融合图像。

Method: 利用归一化空间坐标作为输入，通过多层感知机自适应融合多模态特征，设计多损失函数优化融合效果。

Result: 实验表明INRFuse在主观视觉质量和客观评价指标上优于现有方法，无需训练数据集即可生成结构清晰、细节自然、信息丰富的融合图像。

Conclusion: INRFuse通过INR实现了高效的多模态图像融合，突破了传统方法的限制，具有分辨率无关性和超分辨率重建能力。

Abstract: Infrared and visible light image fusion aims to combine the strengths of both
modalities to generate images that are rich in information and fulfill visual
or computational requirements. This paper proposes an image fusion method based
on Implicit Neural Representations (INR), referred to as INRFuse. This method
parameterizes a continuous function through a neural network to implicitly
represent the multimodal information of the image, breaking through the
traditional reliance on discrete pixels or explicit features. The normalized
spatial coordinates of the infrared and visible light images serve as inputs,
and multi-layer perceptrons is utilized to adaptively fuse the features of both
modalities, resulting in the output of the fused image. By designing multiple
loss functions, the method jointly optimizes the similarity between the fused
image and the original images, effectively preserving the thermal radiation
information of the infrared image while maintaining the texture details of the
visible light image. Furthermore, the resolution-independent characteristic of
INR allows for the direct fusion of images with varying resolutions and
achieves super-resolution reconstruction through high-density coordinate
queries. Experimental results indicate that INRFuse outperforms existing
methods in both subjective visual quality and objective evaluation metrics,
producing fused images with clear structures, natural details, and rich
information without the necessity for a training dataset.

</details>


### [196] [PQCAD-DM: Progressive Quantization and Calibration-Assisted Distillation for Extremely Efficient Diffusion Model](https://arxiv.org/abs/2506.16776)
*Beomseok Ko,Hyeryung Jang*

Main category: cs.CV

TL;DR: PQCAD-DM是一种结合渐进量化（PQ）和校准辅助蒸馏（CAD）的混合压缩框架，旨在解决扩散模型的计算和资源密集型问题，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成中表现出色，但其依赖迭代马尔可夫链过程导致计算和资源消耗大，且误差累积限制了压缩技术的效果。

Method: PQCAD-DM采用两阶段渐进量化（PQ）和校准辅助蒸馏（CAD），PQ通过动量机制减少低精度下的权重扰动，CAD利用全精度校准数据集提升蒸馏效果。

Result: PQCAD-DM在计算效率和生成质量之间取得平衡，推理时间减半且性能保持竞争力，实验验证其优于固定位量化方法。

Conclusion: PQCAD-DM通过混合压缩框架显著提升扩散模型的效率，同时保持生成质量，适用于多样化数据集。

Abstract: Diffusion models excel in image generation but are computational and
resource-intensive due to their reliance on iterative Markov chain processes,
leading to error accumulation and limiting the effectiveness of naive
compression techniques. In this paper, we propose PQCAD-DM, a novel hybrid
compression framework combining Progressive Quantization (PQ) and
Calibration-Assisted Distillation (CAD) to address these challenges. PQ employs
a two-stage quantization with adaptive bit-width transitions guided by a
momentum-based mechanism, reducing excessive weight perturbations in
low-precision. CAD leverages full-precision calibration datasets during
distillation, enabling the student to match full-precision performance even
with a quantized teacher. As a result, PQCAD-DM achieves a balance between
computational efficiency and generative quality, halving inference time while
maintaining competitive performance. Extensive experiments validate PQCAD-DM's
superior generative capabilities and efficiency across diverse datasets,
outperforming fixed-bit quantization methods.

</details>


### [197] [TextBraTS: Text-Guided Volumetric Brain Tumor Segmentation with Innovative Dataset Development and Fusion Module Exploration](https://arxiv.org/abs/2506.16784)
*Xiaoyu Shi,Rahul Kumar Jain,Yinhao Li,Ruibo Hou,Jingliang Cheng,Jie Bai,Guohua Zhao,Lanfen Lin,Rui Xu,Yen-wei Chen*

Main category: cs.CV

TL;DR: 论文介绍了首个公开的多模态数据集TextBraTS，结合MRI图像与文本注释，并提出了一种基于文本引导的医学图像分割方法，显著提高了脑肿瘤分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有脑肿瘤分析领域缺乏结合影像与文本注释的综合数据集，限制了多模态方法的研究。

Method: 提出TextBraTS数据集，并设计了一种基于顺序交叉注意力的文本引导体积医学图像分割框架。

Result: 实验表明，该方法显著提升了脑肿瘤分割的准确性，并提供了有效的多模态融合技术见解。

Conclusion: TextBraTS数据集和提出的方法为脑肿瘤分析领域的多模态研究提供了重要资源和技术支持。

Abstract: Deep learning has demonstrated remarkable success in medical image
segmentation and computer-aided diagnosis. In particular, numerous advanced
methods have achieved state-of-the-art performance in brain tumor segmentation
from MRI scans. While recent studies in other medical imaging domains have
revealed that integrating textual reports with visual data can enhance
segmentation accuracy, the field of brain tumor analysis lacks a comprehensive
dataset that combines radiological images with corresponding textual
annotations. This limitation has hindered the exploration of multimodal
approaches that leverage both imaging and textual data.
  To bridge this critical gap, we introduce the TextBraTS dataset, the first
publicly available volume-level multimodal dataset that contains paired MRI
volumes and rich textual annotations, derived from the widely adopted BraTS2020
benchmark. Building upon this novel dataset, we propose a novel baseline
framework and sequential cross-attention method for text-guided volumetric
medical image segmentation. Through extensive experiments with various
text-image fusion strategies and templated text formulations, our approach
demonstrates significant improvements in brain tumor segmentation accuracy,
offering valuable insights into effective multimodal integration techniques.
  Our dataset, implementation code, and pre-trained models are publicly
available at https://github.com/Jupitern52/TextBraTS.

</details>


### [198] [RealSR-R1: Reinforcement Learning for Real-World Image Super-Resolution with Vision-Language Chain-of-Thought](https://arxiv.org/abs/2506.16796)
*Junbo Qiao,Miaomiao Cai,Wei Li,Yutong Liu,Xudong Huang,Gaoqi He,Jiao Xie,Jie Hu,Xinghao Chen,Shaohui Lin*

Main category: cs.CV

TL;DR: RealSR-R1提出了一种结合视觉与语言推理的VLCoT框架，通过GRPO优化方法提升真实世界图像超分辨率任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在理解退化图像内容时表现不佳，导致重建结果低保真且不自然。

Method: 提出VLCoT框架，模拟人类处理退化图像的过程，结合GRPO方法设计四种奖励函数。

Result: 实验表明，RealSR-R1能生成更真实的细节并准确理解图像内容，尤其在语义丰富或严重退化的场景中。

Conclusion: VLCoT-GRPO框架显著提升了真实世界图像超分辨率的性能。

Abstract: Real-World Image Super-Resolution is one of the most challenging task in
image restoration. However, existing methods struggle with an accurate
understanding of degraded image content, leading to reconstructed results that
are both low-fidelity and unnatural. We present RealSR-R1 in this work, which
empowers the RealSR models with understanding and reasoning capabilities.
Inspired by the success of Chain of Thought (CoT) in large language models
(LLMs), we simulate the human process of handling degraded images and propose
the VLCoT framework, which integrates vision and language reasoning. The
framework aims to precisely restore image details by progressively generating
more comprehensive text and higher-resolution images. To overcome the challenge
of traditional supervised learning CoT failing to generalize to real-world
scenarios, we introduce, for the first time, Group Relative Policy Optimization
(GRPO) into the Real-World Image Super-Resolution task. We propose VLCoT-GRPO
as a solution, which designs four reward functions: (1) Format reward, used to
standardize the CoT process; (2) Degradation reward, to incentivize accurate
degradation estimation; (3) Understanding reward, to ensure the accuracy of the
generated content; and (4) Generation reward, where we propose using a visual
expert model to evaluate the quality of generated images, encouraging the model
to generate more realistic images. Extensive experiments demonstrate that our
proposed RealSR-R1 can generate realistic details and accurately understand
image content, particularly in semantically rich scenes or images with severe
degradation.

</details>


### [199] [Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation](https://arxiv.org/abs/2506.16802)
*Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva*

Main category: cs.CV

TL;DR: 论文提出了一种新的视频伪造检测方法，通过引导检测器关注生成视频的低级特征而非高级语义缺陷，提高了检测器的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频伪造检测器泛化能力差，限制了其在实际场景中的应用。

Method: 研究不同生成架构，识别共享的低级特征；提出基于小波分解的数据增强策略，引导模型利用更相关的伪造线索。

Result: 新方法显著提高了检测器的准确性，即使对最新生成模型（如NOVA和FLUX）也表现优异。

Conclusion: 该方法无需复杂算法或大规模数据集，即可显著提升AI生成视频检测器的泛化能力。

Abstract: Synthetic video generation is progressing very rapidly. The latest models can
produce very realistic high-resolution videos that are virtually
indistinguishable from real ones. Although several video forensic detectors
have been recently proposed, they often exhibit poor generalization, which
limits their applicability in a real-world scenario. Our key insight to
overcome this issue is to guide the detector towards seeing what really
matters. In fact, a well-designed forensic classifier should focus on
identifying intrinsic low-level artifacts introduced by a generative
architecture rather than relying on high-level semantic flaws that characterize
a specific model. In this work, first, we study different generative
architectures, searching and identifying discriminative features that are
unbiased, robust to impairments, and shared across models. Then, we introduce a
novel forensic-oriented data augmentation strategy based on the wavelet
decomposition and replace specific frequency-related bands to drive the model
to exploit more relevant forensic cues. Our novel training paradigm improves
the generalizability of AI-generated video detectors, without the need for
complex algorithms and large datasets that include multiple synthetic
generators. To evaluate our approach, we train the detector using data from a
single generative model and test it against videos produced by a wide range of
other models. Despite its simplicity, our method achieves a significant
accuracy improvement over state-of-the-art detectors and obtains excellent
results even on very recent generative models, such as NOVA and FLUX. Code and
data will be made publicly available.

</details>


### [200] [Co-VisiON: Co-Visibility ReasONing on Sparse Image Sets of Indoor Scenes](https://arxiv.org/abs/2506.16805)
*Chao Chen,Nobel Dang,Juexiao Zhang,Wenkai Sun,Pengfei Zheng,Xuhang He,Yimeng Ye,Taarun Srinivas,Chen Feng*

Main category: cs.CV

TL;DR: 论文提出了Co-VisiON基准，评估稀疏图像集中的共视性推理能力，发现现有视觉模型在稀疏条件下表现不佳，提出新基线模型Covis缩小与人类表现的差距。


<details>
  <summary>Details</summary>
Motivation: 人类在复杂场景中能高效识别共视性，但当前视觉模型是否达到人类水平尚不明确，需建立评估标准。

Method: 引入Co-VisiON基准，覆盖1000多个室内场景，测试稀疏图像集的共视性推理能力，并提出多视图基线模型Covis。

Result: 专有视觉语言模型表现最佳，但所有模型均显著落后于人类；Covis在纯视觉模型中表现最优。

Conclusion: 共视性推理需高层次多视图空间理解，Covis缩小了与专有模型的差距，为未来研究提供方向。

Abstract: Humans exhibit a remarkable ability to recognize co-visibility-the
overlapping regions visible in multiple images-even when these images are
sparsely distributed across a complex scene. This capability is foundational in
3D vision and robotic perception. Despite significant progress in vision
learning, it remains unclear whether current vision models have reached
human-level proficiency in co-visibility analysis. In this work, we introduce
the Co-Visibility reasONing (Co-VisiON) benchmark, designed to directly
evaluate co-visibility reasoning on sparse image sets across over 1000 indoor
scenarios. Our experiments reveal that while co-visibility is typically treated
as a low-level feature matching task, it poses a significant challenge for
existing vision models under sparse conditions. Notably, a proprietary
vision-language model outperforms all purely vision-based approaches, with all
models lagging substantially behind human performance. This gap underscores the
need for more than basic pairwise vision processing-it calls for a
comprehensive spatial understanding through high-level reasoning across
multiple views. Inspired by human visual cognition, we propose a novel
multi-view baseline, Covis, which achieves top performance among pure vision
models and narrows the gap to the proprietary VLM. We hope our benchmark and
findings will spur further advancements in developing vision models capable of
robust, high-level reasoning in challenging, sparse environments. Our dataset
and source code can be found at: https://ai4ce.github.io/CoVISION

</details>


### [201] [FOCUS: Unified Vision-Language Modeling for Interactive Editing Driven by Referential Segmentation](https://arxiv.org/abs/2506.16806)
*Fan Yang,Yousong Zhu,Xin Li,Yufei Zhan,Hongyin Zhao,Shurong Zheng,Yaowei Wang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: FOCUS是一个统一的LVLM模型，整合了分割感知和可控对象生成，通过端到端框架实现视觉理解和生成任务的联合优化。


<details>
  <summary>Details</summary>
Motivation: 当前方法将视觉理解（分割）和生成任务分离，依赖多个独立模型，FOCUS旨在填补这一空白。

Method: 采用双分支视觉编码器捕捉全局和局部信息，结合MoVQGAN视觉分词器，并通过多阶段训练策略对齐分割与生成模块。

Result: 在多项任务中表现优异，包括多模态理解、参考分割准确性和可控图像生成。

Conclusion: FOCUS通过联合优化视觉感知和生成能力，实现了高效且可控的图像编辑。

Abstract: Recent Large Vision Language Models (LVLMs) demonstrate promising
capabilities in unifying visual understanding and generative modeling, enabling
both accurate content understanding and flexible editing. However, current
approaches treat "what to see" and "how to edit" separately: they either
perform isolated object segmentation or utilize segmentation masks merely as
conditional prompts for local edit generation tasks, often relying on multiple
disjointed models. To bridge these gaps, we introduce FOCUS, a unified LVLM
that integrates segmentation-aware perception and controllable object-centric
generation within an end-to-end framework. FOCUS employs a dual-branch visual
encoder to simultaneously capture global semantic context and fine-grained
spatial details. In addition, we leverage a MoVQGAN-based visual tokenizer to
produce discrete visual tokens that enhance generation quality. To enable
accurate and controllable image editing, we propose a progressive multi-stage
training pipeline, where segmentation masks are jointly optimized and used as
spatial condition prompts to guide the diffusion decoder. This strategy aligns
visual encoding, segmentation, and generation modules, effectively bridging
segmentation-aware perception with fine-grained visual synthesis. Extensive
experiments across three core tasks, including multimodal understanding,
referring segmentation accuracy, and controllable image generation, demonstrate
that FOCUS achieves strong performance by jointly optimizing visual perception
and generative capabilities.

</details>


### [202] [Loupe: A Generalizable and Adaptive Framework for Image Forgery Detection](https://arxiv.org/abs/2506.16819)
*Yuchu Jiang,Jiaming Chu,Jian Zhao,Xin Zhang,Xu Yang,Lei Jin,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Loupe是一个轻量级框架，用于联合深度伪造检测和定位，通过全局分类和细粒度掩码预测实现高性能。


<details>
  <summary>Details</summary>
Motivation: 生成模型的普及引发了对视觉内容伪造的担忧，现有方法在泛化性和架构复杂性上存在不足。

Method: Loupe结合了块感知分类器和条件查询的分割模块，并引入伪标签引导的测试时自适应机制。

Result: 在DDL数据集上表现优异，IJCAI 2025挑战赛中得分0.846，排名第一。

Conclusion: Loupe的块级融合和条件查询设计有效提升了分类和定位性能。

Abstract: The proliferation of generative models has raised serious concerns about
visual content forgery. Existing deepfake detection methods primarily target
either image-level classification or pixel-wise localization. While some
achieve high accuracy, they often suffer from limited generalization across
manipulation types or rely on complex architectures. In this paper, we propose
Loupe, a lightweight yet effective framework for joint deepfake detection and
localization. Loupe integrates a patch-aware classifier and a segmentation
module with conditional queries, allowing simultaneous global authenticity
classification and fine-grained mask prediction. To enhance robustness against
distribution shifts of test set, Loupe introduces a pseudo-label-guided
test-time adaptation mechanism by leveraging patch-level predictions to
supervise the segmentation head. Extensive experiments on the DDL dataset
demonstrate that Loupe achieves state-of-the-art performance, securing the
first place in the IJCAI 2025 Deepfake Detection and Localization Challenge
with an overall score of 0.846. Our results validate the effectiveness of the
proposed patch-level fusion and conditional query design in improving both
classification accuracy and spatial localization under diverse forgery
patterns. The code is available at https://github.com/Kamichanw/Loupe.

</details>


### [203] [Self-supervised Feature Extraction for Enhanced Ball Detection on Soccer Robots](https://arxiv.org/abs/2506.16821)
*Can Lin,Daniele Affinita,Marco E. P. Zimmatore,Daniele Nardi,Domenico D. Bloisi,Vincenzo Suriani*

Main category: cs.CV

TL;DR: 提出了一种自监督学习框架，用于提升足球机器人球体检测性能，无需大量人工标注，结合元学习快速适应新场景。


<details>
  <summary>Details</summary>
Motivation: 传统监督方法需要大量人工标注，成本高且耗时，因此探索自监督学习以降低依赖。

Method: 利用预训练模型生成伪标签，通过自监督任务（如着色、边缘检测和三元组损失）学习特征，并引入MAML策略快速适应新场景。

Result: 实验表明，该方法在准确性、F1分数和IoU上优于基线模型，且收敛更快。

Conclusion: 自监督学习框架有效提升了球体检测性能，适用于动态环境，并减少了人工标注需求。

Abstract: Robust and accurate ball detection is a critical component for autonomous
humanoid soccer robots, particularly in dynamic and challenging environments
such as RoboCup outdoor fields. However, traditional supervised approaches
require extensive manual annotation, which is costly and time-intensive. To
overcome this problem, we present a self-supervised learning framework for
domain-adaptive feature extraction to enhance ball detection performance. The
proposed approach leverages a general-purpose pretrained model to generate
pseudo-labels, which are then used in a suite of self-supervised pretext tasks
-- including colorization, edge detection, and triplet loss -- to learn robust
visual features without relying on manual annotations. Additionally, a
model-agnostic meta-learning (MAML) strategy is incorporated to ensure rapid
adaptation to new deployment scenarios with minimal supervision. A new dataset
comprising 10,000 labeled images from outdoor RoboCup SPL matches is
introduced, used to validate the method, and made available to the community.
Experimental results demonstrate that the proposed pipeline outperforms
baseline models in terms of accuracy, F1 score, and IoU, while also exhibiting
faster convergence.

</details>


### [204] [AnyTraverse: An off-road traversability framework with VLM and human operator in the loop](https://arxiv.org/abs/2506.16826)
*Sattwik Sahu,Agamdeep Singh,Karthik Nambiar,Srikanth Saripalli,P. B. Sujit*

Main category: cs.CV

TL;DR: AnyTraverse是一个结合自然语言提示和人工辅助的框架，用于分割越野可通行区域，适应不同机器人类型，减少人工监督需求。


<details>
  <summary>Details</summary>
Motivation: 当前框架在非结构化环境中表现不佳，且无法适应不同机器人类型，需要一种更灵活的方法。

Method: 结合自然语言提示和人工辅助，仅在遇到未知场景时调用操作员，采用零样本学习避免数据收集和重新训练。

Result: 在多个数据集和机器人平台上验证，性能优于GA-NAV和Off-seg，提供车辆无关的越野可通行性解决方案。

Conclusion: AnyTraverse通过平衡自动化和人工监督，提供了一种高效的越野导航框架。

Abstract: Off-road traversability segmentation enables autonomous navigation with
applications in search-and-rescue, military operations, wildlife exploration,
and agriculture. Current frameworks struggle due to significant variations in
unstructured environments and uncertain scene changes, and are not adaptive to
be used for different robot types. We present AnyTraverse, a framework
combining natural language-based prompts with human-operator assistance to
determine navigable regions for diverse robotic vehicles. The system segments
scenes for a given set of prompts and calls the operator only when encountering
previously unexplored scenery or unknown class not part of the prompt in its
region-of-interest, thus reducing active supervision load while adapting to
varying outdoor scenes. Our zero-shot learning approach eliminates the need for
extensive data collection or retraining. Our experimental validation includes
testing on RELLIS-3D, Freiburg Forest, and RUGD datasets and demonstrate
real-world deployment on multiple robot platforms. The results show that
AnyTraverse performs better than GA-NAV and Off-seg while offering a
vehicle-agnostic approach to off-road traversability that balances automation
with targeted human supervision.

</details>


### [205] [Camera Calibration via Circular Patterns: A Comprehensive Framework with Measurement Uncertainty and Unbiased Projection Model](https://arxiv.org/abs/2506.16842)
*Chaehyeon Song,Dongjae Lee,Jongwoo Lim,Ayoung Kim*

Main category: cs.CV

TL;DR: 论文提出了一种基于圆形图案的无偏投影模型，解决了现有模型在镜头畸变下的偏差问题，并通过引入不确定性提高了校准的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有圆形图案的投影模型在镜头畸变下存在偏差，导致校准性能不佳，需要改进。

Method: 提出无偏投影模型，引入圆形图案的不确定性，并通过马尔可夫随机场建模边界点，利用Green定理传播形状分布到质心不确定性。

Result: 新框架显著提高了校准的准确性和鲁棒性。

Conclusion: 该方法优于传统棋盘格校准，提供了更精确和稳健的相机校准方案。

Abstract: Camera calibration using planar targets has been widely favored, and two
types of control points have been mainly considered as measurements: the
corners of the checkerboard and the centroid of circles. Since a centroid is
derived from numerous pixels, the circular pattern provides more precise
measurements than the checkerboard. However, the existing projection model of
circle centroids is biased under lens distortion, resulting in low performance.
To surmount this limitation, we propose an unbiased projection model of the
circular pattern and demonstrate its superior accuracy compared to the
checkerboard. Complementing this, we introduce uncertainty into circular
patterns to enhance calibration robustness and completeness. Defining centroid
uncertainty improves the performance of calibration components, including
pattern detection, optimization, and evaluation metrics. We also provide
guidelines for performing good camera calibration based on the evaluation
metric. The core concept of this approach is to model the boundary points of a
two-dimensional shape as a Markov random field, considering its connectivity.
The shape distribution is propagated to the centroid uncertainty through an
appropriate shape representation based on the Green theorem. Consequently, the
resulting framework achieves marked gains in calibration accuracy and
robustness. The complete source code and demonstration video are available at
https://github.com/chaehyeonsong/discocal.

</details>


### [206] [Controllable and Expressive One-Shot Video Head Swapping](https://arxiv.org/abs/2506.16852)
*Chaonan Ji,Jinwei Qi,Peng Zhang,Bang Zhang,Liefeng Bo*

Main category: cs.CV

TL;DR: 提出了一种基于扩散的多条件可控视频头部替换框架，支持静态图像头部无缝移植到动态视频中，并允许调整表情和动作。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注局部面部替换，忽略了整体头部形态，且无法在替换后修改表情。

Method: 采用统一潜在扩散范式，包括身份保留上下文融合和表情感知地标重定向与编辑。

Result: 实验表明，该方法在背景无缝集成和身份保留方面表现优异，并具备出色的表情转移能力。

Conclusion: 该方法在视频头部替换中实现了高精度和可控性，适用于真实和虚拟角色。

Abstract: In this paper, we propose a novel diffusion-based multi-condition
controllable framework for video head swapping, which seamlessly transplant a
human head from a static image into a dynamic video, while preserving the
original body and background of target video, and further allowing to tweak
head expressions and movements during swapping as needed. Existing
face-swapping methods mainly focus on localized facial replacement neglecting
holistic head morphology, while head-swapping approaches struggling with
hairstyle diversity and complex backgrounds, and none of these methods allow
users to modify the transplanted head expressions after swapping. To tackle
these challenges, our method incorporates several innovative strategies through
a unified latent diffusion paradigm. 1) Identity-preserving context fusion: We
propose a shape-agnostic mask strategy to explicitly disentangle foreground
head identity features from background/body contexts, combining hair
enhancement strategy to achieve robust holistic head identity preservation
across diverse hair types and complex backgrounds. 2) Expression-aware landmark
retargeting and editing: We propose a disentangled 3DMM-driven retargeting
module that decouples identity, expression, and head poses, minimizing the
impact of original expressions in input images and supporting expression
editing. While a scale-aware retargeting strategy is further employed to
minimize cross-identity expression distortion for higher transfer precision.
Experimental results demonstrate that our method excels in seamless background
integration while preserving the identity of the source portrait, as well as
showcasing superior expression transfer capabilities applicable to both real
and virtual characters.

</details>


### [207] [ParkFormer: A Transformer-Based Parking Policy with Goal Embedding and Pedestrian-Aware Control](https://arxiv.org/abs/2506.16856)
*Jun Fu,Bin Tian,Haonan Chen,Shi Meng,Tingting Yao*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的端到端自主泊车框架，通过学习专家演示实现高精度控制，成功率达96.57%。


<details>
  <summary>Details</summary>
Motivation: 传统规则泊车系统在动态环境中适应性差，而人类驾驶员能直观泊车，启发研究者设计更智能的系统。

Method: 使用Transformer框架，输入包括环视图像、目标点表示、车辆运动及行人轨迹，输出离散控制序列。引入交叉注意力模块和GRU行人预测器。

Result: 在CARLA模拟器中验证，成功率达96.57%，位置和方向误差分别为0.21米和0.41度。

Conclusion: 提出的方法在自主泊车中表现优异，关键模块如行人预测和目标点注意力融合效果显著。

Abstract: Autonomous parking plays a vital role in intelligent vehicle systems,
particularly in constrained urban environments where high-precision control is
required. While traditional rule-based parking systems struggle with
environmental uncertainties and lack adaptability in crowded or dynamic scenes,
human drivers demonstrate the ability to park intuitively without explicit
modeling. Inspired by this observation, we propose a Transformer-based
end-to-end framework for autonomous parking that learns from expert
demonstrations. The network takes as input surround-view camera images,
goal-point representations, ego vehicle motion, and pedestrian trajectories. It
outputs discrete control sequences including throttle, braking, steering, and
gear selection. A novel cross-attention module integrates BEV features with
target points, and a GRU-based pedestrian predictor enhances safety by modeling
dynamic obstacles. We validate our method on the CARLA 0.9.14 simulator in both
vertical and parallel parking scenarios. Experiments show our model achieves a
high success rate of 96.57\%, with average positional and orientation errors of
0.21 meters and 0.41 degrees, respectively. The ablation studies further
demonstrate the effectiveness of key modules such as pedestrian prediction and
goal-point attention fusion. The code and dataset will be released at:
https://github.com/little-snail-f/ParkFormer.

</details>


### [208] [Enhancing Step-by-Step and Verifiable Medical Reasoning in MLLMs](https://arxiv.org/abs/2506.16962)
*Haoran Sun,Yankai Jiang,Wenjie Lou,Yujie Zhang,Wenjie Li,Lilong Wang,Mianxin Liu,Lei Liu,Xiaosong Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MICS的新方法，用于生成高质量的医学推理链数据，并构建了一个多任务医学推理数据集MMRP和一个新的医学MLLM模型Chiron-o1。实验证明该模型在医学视觉问答和推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的医学MLLM在推理能力上存在不足，缺乏全面的框架来搜索和评估有效的推理路径。

Method: 提出MICS方法，通过导师-实习生协作搜索生成高质量的医学推理链数据，并构建数据集MMRP和模型Chiron-o1。

Result: Chiron-o1在多个医学视觉问答和推理基准测试中达到最优性能。

Conclusion: MICS方法有效提升了医学MLLM的推理能力，Chiron-o1表现出色。

Abstract: Multimodal large language models (MLLMs) have begun to demonstrate robust
reasoning capabilities on general tasks, yet their application in the medical
domain remains in its early stages. Constructing chain-of-thought (CoT)
training data is essential for bolstering the reasoning abilities of medical
MLLMs. However, existing approaches exhibit a deficiency in offering a
comprehensive framework for searching and evaluating effective reasoning paths
towards critical diagnosis. To address this challenge, we propose Mentor-Intern
Collaborative Search (MICS), a novel reasoning-path searching scheme to
generate rigorous and effective medical CoT data. MICS first leverages mentor
models to initialize the reasoning, one step at a time, then prompts each
intern model to continue the thinking along those initiated paths, and finally
selects the optimal reasoning path according to the overall reasoning
performance of multiple intern models. The reasoning performance is determined
by an MICS-Score, which assesses the quality of generated reasoning paths.
Eventually, we construct MMRP, a multi-task medical reasoning dataset with
ranked difficulty, and Chiron-o1, a new medical MLLM devised via a curriculum
learning strategy, with robust visual question-answering and generalizable
reasoning capabilities. Extensive experiments demonstrate that Chiron-o1,
trained on our CoT dataset constructed using MICS, achieves state-of-the-art
performance across a list of medical visual question answering and reasoning
benchmarks. Codes are available at GitHub - manglu097/Chiron-o1: Enhancing
Step-by-Step and Verifiable Medical Reasoning in MLLMs

</details>


### [209] [With Limited Data for Multimodal Alignment, Let the STRUCTURE Guide You](https://arxiv.org/abs/2506.16895)
*Fabian Gröger,Shuo Wen,Huyen Le,Maria Brbić*

Main category: cs.CV

TL;DR: 本文提出了一种在有限配对数据下构建多模态模型的方法，通过对齐预训练的单模态基础模型，仅需少量样本即可实现高质量对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量配对样本，成本高昂且难以获取，本文旨在解决资源受限领域的多模态学习问题。

Method: 引入STRUCTURE正则化技术保护单模态编码器的潜在空间几何结构，并优化对齐层选择。

Result: 在24个零样本分类和检索任务中，平均相对提升51.6%（分类）和91.8%（检索）。

Conclusion: 该方法为资源受限领域提供了高效的多模态学习框架，具有广泛适用性。

Abstract: Multimodal models have demonstrated powerful capabilities in complex tasks
requiring multimodal alignment including zero-shot classification and
cross-modal retrieval. However, existing models typically rely on millions of
paired multimodal samples, which are prohibitively expensive or infeasible to
obtain in many domains. In this work, we explore the feasibility of building
multimodal models with limited amount of paired data by aligning pretrained
unimodal foundation models. We show that high-quality alignment is possible
with as few as tens of thousands of paired samples$\unicode{x2013}$less than
$1\%$ of the data typically used in the field. To achieve this, we introduce
STRUCTURE, an effective regularization technique that preserves the
neighborhood geometry of the latent space of unimodal encoders. Additionally,
we show that aligning last layers is often suboptimal and demonstrate the
benefits of aligning the layers with the highest representational similarity
across modalities. These two components can be readily incorporated into
existing alignment methods, yielding substantial gains across 24 zero-shot
image classification and retrieval benchmarks, with average relative
improvement of $51.6\%$ in classification and $91.8\%$ in retrieval tasks. Our
results highlight the effectiveness and broad applicability of our framework
for limited-sample multimodal learning and offer a promising path forward for
resource-constrained domains.

</details>


### [210] [LunarLoc: Segment-Based Global Localization on the Moon](https://arxiv.org/abs/2506.16940)
*Annika Thomas,Robaire Galliath,Aleksander Garbuz,Luke Anger,Cormac O'Neill,Trevor Johst,Dami Thomas,George Lordos,Jonathan P. How*

Main category: cs.CV

TL;DR: 论文提出了一种名为LunarLoc的方法，用于月球表面的全局定位，解决了传统视觉惯性里程计（VIO）在长距离任务中累积漂移的问题。


<details>
  <summary>Details</summary>
Motivation: 在月球表面，由于缺乏地球导航基础设施（如GPS），自主操作需要精确的全局定位。NASA的Artemis计划中的任务（如IPEx）依赖自主代理在复杂地形中长时间运行，因此需要高精度的姿态估计。

Method: LunarLoc利用实例分割从立体图像中提取零样本的巨石地标，构建基于图的表示，并通过图论数据关联与参考地图对齐，实现无漂移的全局定位。

Result: 实验表明，LunarLoc在多会话全局定位中达到亚厘米级精度，显著优于现有技术。

Conclusion: LunarLoc为月球表面全局定位提供了高精度解决方案，并公开了数据集以促进进一步研究。

Abstract: Global localization is necessary for autonomous operations on the lunar
surface where traditional Earth-based navigation infrastructure, such as GPS,
is unavailable. As NASA advances toward sustained lunar presence under the
Artemis program, autonomous operations will be an essential component of tasks
such as robotic exploration and infrastructure deployment. Tasks such as
excavation and transport of regolith require precise pose estimation, but
proposed approaches such as visual-inertial odometry (VIO) accumulate odometry
drift over long traverses. Precise pose estimation is particularly important
for upcoming missions such as the ISRU Pilot Excavator (IPEx) that rely on
autonomous agents to operate over extended timescales and varied terrain. To
help overcome odometry drift over long traverses, we propose LunarLoc, an
approach to global localization that leverages instance segmentation for
zero-shot extraction of boulder landmarks from onboard stereo imagery. Segment
detections are used to construct a graph-based representation of the terrain,
which is then aligned with a reference map of the environment captured during a
previous session using graph-theoretic data association. This method enables
accurate and drift-free global localization in visually ambiguous settings.
LunarLoc achieves sub-cm level accuracy in multi-session global localization
experiments, significantly outperforming the state of the art in lunar global
localization. To encourage the development of further methods for global
localization on the Moon, we release our datasets publicly with a playback
module: https://github.com/mit-acl/lunarloc-data.

</details>


### [211] [MEXA: Towards General Multimodal Reasoning with Dynamic Multi-Expert Aggregation](https://arxiv.org/abs/2506.17113)
*Shoubin Yu,Yue Zhang,Ziyang Wang,Jaehong Yoon,Mohit Bansal*

Main category: cs.CV

TL;DR: MEXA是一个无需训练的多模态推理框架，通过动态选择专家模型并聚合其输出，实现跨领域的多模态推理。


<details>
  <summary>Details</summary>
Motivation: 多模态推理面临输入模态多样性和任务复杂性的挑战，需要统一的框架来整合专家模型。

Method: MEXA动态选择专家模型生成文本推理输出，并通过大型推理模型（LRM）聚合结果。

Result: 在视频推理、音频推理、3D理解和医学问答等任务中，MEXA表现优于基线方法。

Conclusion: MEXA展示了专家驱动的选择和聚合在多模态推理任务中的有效性和广泛适用性。

Abstract: Combining pre-trained expert models offers substantial potential for scalable
multimodal reasoning, but building a unified framework remains challenging due
to the increasing diversity of input modalities and task complexity. For
instance, medical diagnosis requires precise reasoning over structured clinical
tables, while financial forecasting depends on interpreting plot-based data to
make informed predictions. To tackle this challenge, we introduce MEXA, a
training-free framework that performs modality- and task-aware aggregation of
multiple expert models to enable effective multimodal reasoning across diverse
and distinct domains. MEXA dynamically selects expert models based on the input
modality and the task-specific reasoning demands (i.e., skills). Each expert
model, specialized in a modality task pair, generates interpretable textual
reasoning outputs. MEXA then aggregates and reasons over these outputs using a
Large Reasoning Model (LRM) to produce the final answer. This modular design
allows flexible and transparent multimodal reasoning across diverse domains
without additional training overhead. We extensively evaluate our approach on
diverse multimodal benchmarks, including Video Reasoning, Audio Reasoning, 3D
Understanding, and Medical QA. MEXA consistently delivers performance
improvements over strong multimodal baselines, highlighting the effectiveness
and broad applicability of our expert-driven selection and aggregation in
diverse multimodal reasoning tasks.

</details>


### [212] [LAION-C: An Out-of-Distribution Benchmark for Web-Scale Vision Models](https://arxiv.org/abs/2506.16950)
*Fanfei Li,Thomas Klein,Wieland Brendel,Robert Geirhos,Roland S. Zimmermann*

Main category: cs.CV

TL;DR: 论文提出了LAION-C作为ImageNet-C的替代基准，用于评估现代模型在web-scale数据集时代的OOD鲁棒性，发现其能有效挑战当前先进模型。


<details>
  <summary>Details</summary>
Motivation: 由于ImageNet-C的失真类型在现代web-scale数据集中已不再OOD，现有基准无法准确评估模型的OOD鲁棒性，需设计新的基准。

Method: 引入LAION-C，包含六种新型失真类型，确保其OOD特性，并对先进模型进行全面评估。

Result: LAION-C对当代模型（如Gemini和GPT-4o）构成显著挑战，且模型性能已接近或超越人类观察者。

Conclusion: LAION-C为OOD鲁棒性评估提供了更有效的基准，标志着模型在OOD泛化能力上的范式转变。

Abstract: Out-of-distribution (OOD) robustness is a desired property of computer vision
models. Improving model robustness requires high-quality signals from
robustness benchmarks to quantify progress. While various benchmark datasets
such as ImageNet-C were proposed in the ImageNet era, most ImageNet-C
corruption types are no longer OOD relative to today's large, web-scraped
datasets, which already contain common corruptions such as blur or JPEG
compression artifacts. Consequently, these benchmarks are no longer well-suited
for evaluating OOD robustness in the era of web-scale datasets. Indeed, recent
models show saturating scores on ImageNet-era OOD benchmarks, indicating that
it is unclear whether models trained on web-scale datasets truly become better
at OOD generalization or whether they have simply been exposed to the test
distortions during training. To address this, we introduce LAION-C as a
benchmark alternative for ImageNet-C. LAION-C consists of six novel distortion
types specifically designed to be OOD, even for web-scale datasets such as
LAION. In a comprehensive evaluation of state-of-the-art models, we find that
the LAION-C dataset poses significant challenges to contemporary models,
including MLLMs such as Gemini and GPT-4o. We additionally conducted a
psychophysical experiment to evaluate the difficulty of our corruptions for
human observers, enabling a comparison of models to lab-quality human
robustness data. We observe a paradigm shift in OOD generalization: from humans
outperforming models, to the best models now matching or outperforming the best
human observers.

</details>


### [213] [Visual-Instructed Degradation Diffusion for All-in-One Image Restoration](https://arxiv.org/abs/2506.16960)
*Wenyang Luo,Haina Qin,Zewen Chen,Libin Wang,Dandan Zheng,Yuming Li,Yufan Liu,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: Defusion是一种新型的图像修复框架，通过视觉指令引导的退化扩散实现多任务修复，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像修复方法通常需要针对每种退化类型设计独立模型，限制了在混合或未知退化场景中的泛化能力。

Method: Defusion利用视觉指令引导的退化扩散，通过标准视觉元素构建明确的退化模式，指导扩散模型在退化空间中直接操作。

Result: 实验表明，Defusion在多种图像修复任务中优于现有方法，包括复杂和真实世界的退化情况。

Conclusion: Defusion通过视觉指令和扩散模型实现了高效、稳定的多任务图像修复，具有广泛的应用潜力。

Abstract: Image restoration tasks like deblurring, denoising, and dehazing usually need
distinct models for each degradation type, restricting their generalization in
real-world scenarios with mixed or unknown degradations. In this work, we
propose \textbf{Defusion}, a novel all-in-one image restoration framework that
utilizes visual instruction-guided degradation diffusion. Unlike existing
methods that rely on task-specific models or ambiguous text-based priors,
Defusion constructs explicit \textbf{visual instructions} that align with the
visual degradation patterns. These instructions are grounded by applying
degradations to standardized visual elements, capturing intrinsic degradation
features while agnostic to image semantics. Defusion then uses these visual
instructions to guide a diffusion-based model that operates directly in the
degradation space, where it reconstructs high-quality images by denoising the
degradation effects with enhanced stability and generalizability. Comprehensive
experiments demonstrate that Defusion outperforms state-of-the-art methods
across diverse image restoration tasks, including complex and real-world
degradations.

</details>


### [214] [Reversing Flow for Image Restoration](https://arxiv.org/abs/2506.16961)
*Haina Qin,Wenyang Luo,Libin Wang,Dandan Zheng,Jingdong Chen,Ming Yang,Bing Li,Weiming Hu*

Main category: cs.CV

TL;DR: ResFlow是一种基于连续归一化流的新型图像修复框架，通过确定性路径建模退化过程，显著提升了修复性能与速度。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型（如扩散和基于分数的模型）将退化过程视为随机变换，导致效率低下和复杂性增加。

Method: ResFlow将退化过程建模为确定性路径，引入辅助过程消除HQ预测的不确定性，采用熵保持流路径并通过匹配速度场学习增强的退化流。

Result: ResFlow在少于四步采样内完成任务，性能与速度显著提升，在多个基准测试中达到最优效果。

Conclusion: ResFlow为图像修复提供了高效实用的解决方案，适用于实际应用。

Abstract: Image restoration aims to recover high-quality (HQ) images from degraded
low-quality (LQ) ones by reversing the effects of degradation. Existing
generative models for image restoration, including diffusion and score-based
models, often treat the degradation process as a stochastic transformation,
which introduces inefficiency and complexity. In this work, we propose ResFlow,
a novel image restoration framework that models the degradation process as a
deterministic path using continuous normalizing flows. ResFlow augments the
degradation process with an auxiliary process that disambiguates the
uncertainty in HQ prediction to enable reversible modeling of the degradation
process. ResFlow adopts entropy-preserving flow paths and learns the augmented
degradation flow by matching the velocity field. ResFlow significantly improves
the performance and speed of image restoration, completing the task in fewer
than four sampling steps. Extensive experiments demonstrate that ResFlow
achieves state-of-the-art results across various image restoration benchmarks,
offering a practical and efficient solution for real-world applications.

</details>


### [215] [ForestFormer3D: A Unified Framework for End-to-End Segmentation of Forest LiDAR 3D Point Clouds](https://arxiv.org/abs/2506.16991)
*Binbin Xiang,Maciej Wielgosz,Stefano Puliti,Kamil Král,Martin Krůček,Azim Missarov,Rasmus Astrup*

Main category: cs.CV

TL;DR: ForestFormer3D是一个端到端的统一框架，用于森林LiDAR点云的个体树和语义分割，通过新组件实现高性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以应对自然森林环境的复杂性和变异性，需要更精确的分割技术。

Method: 结合ISA引导的查询点选择、基于分数的块合并策略和一对多关联机制。

Result: 在FOR-instanceV2数据集上实现最先进的个体树分割性能，并在未见测试集上表现稳健。

Conclusion: ForestFormer3D具有跨森林条件和传感器模态的鲁棒性，数据集和代码将发布。

Abstract: The segmentation of forest LiDAR 3D point clouds, including both individual
tree and semantic segmentation, is fundamental for advancing forest management
and ecological research. However, current approaches often struggle with the
complexity and variability of natural forest environments. We present
ForestFormer3D, a new unified and end-to-end framework designed for precise
individual tree and semantic segmentation. ForestFormer3D incorporates
ISA-guided query point selection, a score-based block merging strategy during
inference, and a one-to-many association mechanism for effective training. By
combining these new components, our model achieves state-of-the-art performance
for individual tree segmentation on the newly introduced FOR-instanceV2
dataset, which spans diverse forest types and regions. Additionally,
ForestFormer3D generalizes well to unseen test sets (Wytham woods and LAUTx),
showcasing its robustness across different forest conditions and sensor
modalities. The FOR-instanceV2 dataset and the ForestFormer3D code will be
released soon.

</details>


### [216] [Prmpt2Adpt: Prompt-Based Zero-Shot Domain Adaptation for Resource-Constrained Environments](https://arxiv.org/abs/2506.16994)
*Yasir Ali Farrukh,Syed Wali,Irfan Khan,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: Prmpt2Adpt是一种轻量级、高效的零样本域适应框架，通过提示驱动的特征对齐实现快速适应，适用于资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有UDA方法依赖大型模型和完整源域数据的问题，提升在资源受限环境（如无人机）中的适用性。

Method: 基于师生范式，使用蒸馏和微调的CLIP模型作为教师模型，通过提示驱动的实例归一化对齐特征，生成高质量伪标签指导学生模型适应。

Result: 在MDS-A数据集上表现优异，适应速度快7倍，推理速度快5倍，且仅需少量源图像。

Conclusion: Prmpt2Adpt是实时适应低资源领域的实用且可扩展的解决方案。

Abstract: Unsupervised Domain Adaptation (UDA) is a critical challenge in real-world
vision systems, especially in resource-constrained environments like drones,
where memory and computation are limited. Existing prompt-driven UDA methods
typically rely on large vision-language models and require full access to
source-domain data during adaptation, limiting their applicability. In this
work, we propose Prmpt2Adpt, a lightweight and efficient zero-shot domain
adaptation framework built around a teacher-student paradigm guided by
prompt-based feature alignment. At the core of our method is a distilled and
fine-tuned CLIP model, used as the frozen backbone of a Faster R-CNN teacher. A
small set of low-level source features is aligned to the target domain
semantics-specified only through a natural language prompt-via Prompt-driven
Instance Normalization (PIN). These semantically steered features are used to
briefly fine-tune the detection head of the teacher model. The adapted teacher
then generates high-quality pseudo-labels, which guide the on-the-fly
adaptation of a compact student model. Experiments on the MDS-A dataset
demonstrate that Prmpt2Adpt achieves competitive detection performance compared
to state-of-the-art methods, while delivering up to 7x faster adaptation and 5x
faster inference speed using few source images-making it a practical and
scalable solution for real-time adaptation in low-resource domains.

</details>


### [217] [A Synthetic Benchmark for Collaborative 3D Semantic Occupancy Prediction in V2X Autonomous Driving](https://arxiv.org/abs/2506.17004)
*Hanlin Wu,Pengfei Lin,Ehsan Javanmardi,Naren Bao,Bo Qian,Hao Si,Manabu Tsukada*

Main category: cs.CV

TL;DR: 论文提出了一种协作式3D语义占用预测方法，通过多车协作解决单车的感知限制，并在CARLA中生成密集标注数据集，验证了协作模型的优越性。


<details>
  <summary>Details</summary>
Motivation: 单车感知受遮挡、传感器范围和视角限制，协作感知能交换互补信息以提升完整性和准确性。

Method: 在CARLA中重放协作感知数据集生成密集标注，建立不同预测范围的基准，开发基于空间对齐和注意力聚合的基线模型。

Result: 基线模型在扩展预测范围时持续优于单机模型，增益随范围扩大而增加。

Conclusion: 协作3D语义占用预测能显著提升感知性能，尤其在长距离预测中效果更明显。

Abstract: 3D semantic occupancy prediction is an emerging perception paradigm in
autonomous driving, providing a voxel-level representation of both geometric
details and semantic categories. However, the perception capability of a single
vehicle is inherently constrained by occlusion, restricted sensor range, and
narrow viewpoints. To address these limitations, collaborative perception
enables the exchange of complementary information, thereby enhancing the
completeness and accuracy. In the absence of a dedicated dataset for
collaborative 3D semantic occupancy prediction, we augment an existing
collaborative perception dataset by replaying it in CARLA with a
high-resolution semantic voxel sensor to provide dense and comprehensive
occupancy annotations. In addition, we establish benchmarks with varying
prediction ranges designed to systematically assess the impact of spatial
extent on collaborative prediction. We further develop a baseline model that
performs inter-agent feature fusion via spatial alignment and attention
aggregation. Experimental results demonstrate that our baseline model
consistently outperforms single-agent models, with increasing gains observed as
the prediction range expands.

</details>


### [218] [Unsupervised Image Super-Resolution Reconstruction Based on Real-World Degradation Patterns](https://arxiv.org/abs/2506.17027)
*Yiyang Tie,Hong Zhu,Yunyun Luo,Jing Shi*

Main category: cs.CV

TL;DR: 论文提出TripleGAN框架，通过两个GAN组件分别处理模糊特性和退化模式，第三个GAN用于重建真实低分辨率图像，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以从真实低分辨率图像中提取和建模退化模式，尤其是模糊和噪声特性，以及隐式退化如色域偏移。

Method: 提出TripleGAN框架，包含FirstGAN（缩小模糊域差距）、SecondGAN（学习目标域模糊特性和其他退化模式）和ThirdGAN（重建真实低分辨率图像）。

Result: 在RealSR和DRealSR数据集上，该方法在定量指标上表现优越，且重建图像清晰无过度平滑伪影。

Conclusion: TripleGAN能有效学习真实退化模式并生成对齐数据集，从而提升超分辨率重建性能。

Abstract: The training of real-world super-resolution reconstruction models heavily
relies on datasets that reflect real-world degradation patterns. Extracting and
modeling degradation patterns for super-resolution reconstruction using only
real-world low-resolution (LR) images remains a challenging task. When
synthesizing datasets to simulate real-world degradation, relying solely on
degradation extraction methods fails to capture both blur and diverse noise
characteristics across varying LR distributions, as well as more implicit
degradations such as color gamut shifts. Conversely, domain translation alone
cannot accurately approximate real-world blur characteristics due to the
significant degradation domain gap between synthetic and real data. To address
these challenges, we propose a novel TripleGAN framework comprising two
strategically designed components: The FirstGAN primarily focuses on narrowing
the domain gap in blur characteristics, while the SecondGAN performs
domain-specific translation to approximate target-domain blur properties and
learn additional degradation patterns. The ThirdGAN is trained on pseudo-real
data generated by the FirstGAN and SecondGAN to reconstruct real-world LR
images. Extensive experiments on the RealSR and DRealSR datasets demonstrate
that our method exhibits clear advantages in quantitative metrics while
maintaining sharp reconstructions without over-smoothing artifacts. The
proposed framework effectively learns real-world degradation patterns from LR
observations and synthesizes aligned datasets with corresponding degradation
characteristics, thereby enabling the trained network to achieve superior
performance in reconstructing high-quality SR images from real-world LR inputs.

</details>


### [219] [Stretching Beyond the Obvious: A Gradient-Free Framework to Unveil the Hidden Landscape of Visual Invariance](https://arxiv.org/abs/2506.17040)
*Lorenzo Tausani,Paolo Muratore,Morgan B. Talbot,Giacomo Amerio,Gabriel Kreiman,Davide Zoccolan*

Main category: cs.CV

TL;DR: 论文提出了一种名为Stretch-and-Squeeze (SnS)的无偏、模型无关且无需梯度的框架，用于系统表征视觉单元的不变性及其对对抗扰动的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 理解高级视觉单元如何编码特征组合以及图像如何转化为支持识别的表示形式，现有方法不足以揭示不变性变换的多样性。

Method: SnS通过双目标优化问题，探索图像扰动以表征不变性和对抗敏感性。

Result: SnS在卷积神经网络中揭示了比仿射变换更远的像素空间变化，同时更强烈地保留目标单元响应。

Conclusion: SnS框架揭示了不同图像表示对不变性的影响，且鲁棒网络的图像对人类更具可识别性。

Abstract: Uncovering which features' combinations high-level visual units encode is
critical to understand how images are transformed into representations that
support recognition. While existing feature visualization approaches typically
infer a unit's most exciting images, this is insufficient to reveal the
manifold of transformations under which responses remain invariant, which is
key to generalization in vision. Here we introduce Stretch-and-Squeeze (SnS),
an unbiased, model-agnostic, and gradient-free framework to systematically
characterize a unit's invariance landscape and its vulnerability to adversarial
perturbations in both biological and artificial visual systems. SnS frames
these transformations as bi-objective optimization problems. To probe
invariance, SnS seeks image perturbations that maximally alter the
representation of a reference stimulus in a given processing stage while
preserving unit activation. To probe adversarial sensitivity, SnS seeks
perturbations that minimally alter the stimulus while suppressing unit
activation. Applied to convolutional neural networks (CNNs), SnS revealed image
variations that were further from a reference image in pixel-space than those
produced by affine transformations, while more strongly preserving the target
unit's response. The discovered invariant images differed dramatically
depending on the choice of image representation used for optimization:
pixel-level changes primarily affected luminance and contrast, while stretching
mid- and late-layer CNN representations altered texture and pose respectively.
Notably, the invariant images from robust networks were more recognizable by
human subjects than those from standard networks, supporting the higher
fidelity of robust CNNs as models of the visual system.

</details>


### [220] [Relaxed syntax modeling in Transformers for future-proof license plate recognition](https://arxiv.org/abs/2506.17051)
*Florent Meyer,Laurent Guichard,Denis Coquenet,Guillaume Gravier,Yann Soullard,Bertrand Coüasnon*

Main category: cs.CV

TL;DR: 论文提出了一种名为SaLT的语法无关Transformer模型，用于解决现有Transformer在车牌识别中对过去语法过度依赖的问题，显著提升了未来车牌识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的车牌识别系统在面对新语法车牌时性能显著下降，无法适应生产环境的需求。

Method: 通过分析Transformer编码器-解码器中位置和上下文信息的流动，识别问题原因，并设计架构改进方案，提出SaLT模型。

Result: 实验表明，SaLT在现有和未来车牌数据集上均表现优异，性能接近最佳水平。

Conclusion: SaLT通过减少对过去语法的依赖，显著提升了车牌识别的鲁棒性和适应性。

Abstract: Effective license plate recognition systems are required to be resilient to
constant change, as new license plates are released into traffic daily. While
Transformer-based networks excel in their recognition at first sight, we
observe significant performance drop over time which proves them unsuitable for
tense production environments. Indeed, such systems obtain state-of-the-art
results on plates whose syntax is seen during training. Yet, we show they
perform similarly to random guessing on future plates where legible characters
are wrongly recognized due to a shift in their syntax. After highlighting the
flows of positional and contextual information in Transformer encoder-decoders,
we identify several causes for their over-reliance on past syntax. Following,
we devise architectural cut-offs and replacements which we integrate into SaLT,
an attempt at a Syntax-Less Transformer for syntax-agnostic modeling of license
plate representations. Experiments on both real and synthetic datasets show
that our approach reaches top accuracy on past syntax and most importantly
nearly maintains performance on future license plates. We further demonstrate
the robustness of our architecture enhancements by way of various ablations.

</details>


### [221] [Assembler: Scalable 3D Part Assembly via Anchor Point Diffusion](https://arxiv.org/abs/2506.17074)
*Wang Zhao,Yan-Pei Cao,Jiale Xu,Yuejiang Dong,Ying Shan*

Main category: cs.CV

TL;DR: Assembler是一个可扩展且通用的3D部件组装框架，通过扩散模型和稀疏锚点云表示，实现了多样化的3D对象重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在多样化、真实世界对象组装中的局限性，如对称性、重复部件和多有效组装问题。

Method: 将部件组装视为生成问题，使用扩散模型采样配置；引入基于稀疏锚点云的形状中心表示；构建大规模数据集。

Result: 在PartNet上达到最先进性能，首次实现复杂真实世界对象的高质量组装。

Conclusion: Assembler展示了在交互式和组合设计中的潜力，支持高分辨率可编辑对象的生成。

Abstract: We present Assembler, a scalable and generalizable framework for 3D part
assembly that reconstructs complete objects from input part meshes and a
reference image. Unlike prior approaches that mostly rely on deterministic part
pose prediction and category-specific training, Assembler is designed to handle
diverse, in-the-wild objects with varying part counts, geometries, and
structures. It addresses the core challenges of scaling to general 3D part
assembly through innovations in task formulation, representation, and data.
First, Assembler casts part assembly as a generative problem and employs
diffusion models to sample plausible configurations, effectively capturing
ambiguities arising from symmetry, repeated parts, and multiple valid
assemblies. Second, we introduce a novel shape-centric representation based on
sparse anchor point clouds, enabling scalable generation in Euclidean space
rather than SE(3) pose prediction. Third, we construct a large-scale dataset of
over 320K diverse part-object assemblies using a synthesis and filtering
pipeline built on existing 3D shape repositories. Assembler achieves
state-of-the-art performance on PartNet and is the first to demonstrate
high-quality assembly for complex, real-world objects. Based on Assembler, we
further introduce an interesting part-aware 3D modeling system that generates
high-resolution, editable objects from images, demonstrating potential for
interactive and compositional design. Project page:
https://assembler3d.github.io

</details>


### [222] [Acquiring and Accumulating Knowledge from Diverse Datasets for Multi-label Driving Scene Classification](https://arxiv.org/abs/2506.17101)
*Ke Li,Chenyu Zhang,Yuxin Ding,Xianbiao Hu,Ruwen Qin*

Main category: cs.CV

TL;DR: 论文提出了一种结合知识获取与积累（KAA）和基于一致性的主动学习（CAL）的新方法，用于解决驾驶场景多标签分类中的数据集不平衡和任务学习平衡问题。


<details>
  <summary>Details</summary>
Motivation: 提升自动驾驶车辆对复杂驾驶环境的理解能力，需要解决多标签分类中的数据集不平衡和任务学习平衡问题。

Method: 通过KAA从单标签数据集中获取知识，再通过CAL解决属性分布差异导致的知识差距。

Result: 在DSI数据集上性能提升56.1%，KAA贡献31.3%，CAL贡献24.8%；在BDD100K和HSD数据集上表现优于SOTA模型，且数据使用量减少85%。

Conclusion: KAA-CAL方法有效解决了多标签分类中的关键挑战，显著提升了性能并减少了数据需求。

Abstract: Driving scene identification, which assigns multiple non-exclusive class
labels to a scene, provides the contextual awareness necessary for enhancing
autonomous vehicles' ability to understand, reason about, and interact with the
complex driving environment. As a multi-label classification problem, it is
better tackled via multitasking learning. However, directly training a
multi-label classification model for driving scene identification through
multitask learning presents two main challenges: acquiring a balanced,
comprehensively annotated multi-label dataset and balancing learning across
different tasks. This paper introduces a novel learning system that synergizes
knowledge acquisition and accumulation (KAA) with consistency-based active
learning (CAL) to address those challenges. KAA acquires and accumulates
knowledge about scene identification from various single-label datasets via
monotask learning. Subsequently, CAL effectively resolves the knowledge gap
caused by the discrepancy between the marginal distributions of individual
attributes and their joint distribution. An ablation study on our Driving Scene
Identification (DSI) dataset demonstrates a 56.1% performance increase over the
baseline model pretrained on ImageNet. Of this, KAA accounts for 31.3% of the
gain, and CAL contributes 24.8%. Moreover, KAA-CAL stands out as the best
performer when compared to state-of-the-art (SOTA) multi-label models on two
public datasets, BDD100K and HSD, achieving this while using 85% less data. The
DSI dataset and the implementation code for KAA-CAL are available at
https://github.com/KELISBU/KAA-CAL .

</details>


### [223] [RGBTrack: Fast, Robust Depth-Free 6D Pose Estimation and Tracking](https://arxiv.org/abs/2506.17119)
*Teng Guo,Jingjin Yu*

Main category: cs.CV

TL;DR: RGBTrack是一个基于RGB数据的实时6D姿态估计与跟踪框架，无需深度输入，通过新颖的二进制搜索和渲染比较机制实现高效深度推断和姿态假设生成。


<details>
  <summary>Details</summary>
Motivation: 解决动态场景中精确对象姿态跟踪的需求，同时避免依赖深度输入。

Method: 结合FoundationPose架构，采用二进制搜索和渲染比较机制，集成2D对象跟踪（XMem）、卡尔曼滤波和状态机以实现稳定跟踪。

Result: 在基准测试中表现出竞争性精度和实时性能。

Conclusion: RGBTrack是一种实用的解决方案，适用于机器人、增强现实和计算机视觉等领域。

Abstract: We introduce a robust framework, RGBTrack, for real-time 6D pose estimation
and tracking that operates solely on RGB data, thereby eliminating the need for
depth input for such dynamic and precise object pose tracking tasks. Building
on the FoundationPose architecture, we devise a novel binary search strategy
combined with a render-and-compare mechanism to efficiently infer depth and
generate robust pose hypotheses from true-scale CAD models. To maintain stable
tracking in dynamic scenarios, including rapid movements and occlusions,
RGBTrack integrates state-of-the-art 2D object tracking (XMem) with a Kalman
filter and a state machine for proactive object pose recovery. In addition,
RGBTrack's scale recovery module dynamically adapts CAD models of unknown scale
using an initial depth estimate, enabling seamless integration with modern
generative reconstruction techniques. Extensive evaluations on benchmark
datasets demonstrate that RGBTrack's novel depth-free approach achieves
competitive accuracy and real-time performance, making it a promising practical
solution candidate for application areas including robotics, augmented reality,
and computer vision.
  The source code for our implementation will be made publicly available at
https://github.com/GreatenAnoymous/RGBTrack.git.

</details>


### [224] [Do We Need Large VLMs for Spotting Soccer Actions?](https://arxiv.org/abs/2506.17144)
*Ritabrata Chakraborty,Rajatsubhra Chakraborty,Avijit Dasgupta,Sandeep Chaurasia*

Main category: cs.CV

TL;DR: 论文提出了一种基于文本的方法，利用大型语言模型（LLMs）替代传统的视觉语言模型（VLMs），用于足球动作识别，实现轻量化和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统视频任务依赖视觉输入，计算复杂且昂贵。专家评论提供了丰富的上下文信息，足以可靠地识别关键动作。

Method: 使用SoccerNet Echoes数据集和三个LLM作为评委，分别专注于结果、兴奋度和战术，通过滑动窗口评估评论以识别动作。

Result: 实验表明，这种基于语言的方法能有效检测关键比赛事件，且无需训练。

Conclusion: 该方法为动作识别提供了一种轻量级、无需训练的替代方案。

Abstract: Traditional video-based tasks like soccer action spotting rely heavily on
visual inputs, often requiring complex and computationally expensive models to
process dense video data. In this work, we propose a shift from this
video-centric approach to a text-based task, making it lightweight and scalable
by utilizing Large Language Models (LLMs) instead of Vision-Language Models
(VLMs). We posit that expert commentary, which provides rich, fine-grained
descriptions and contextual cues such as excitement and tactical insights,
contains enough information to reliably spot key actions in a match. To
demonstrate this, we use the SoccerNet Echoes dataset, which provides
timestamped commentary, and employ a system of three LLMs acting as judges
specializing in outcome, excitement, and tactics. Each LLM evaluates sliding
windows of commentary to identify actions like goals, cards, and substitutions,
generating accurate timestamps for these events. Our experiments show that this
language-centric approach performs effectively in detecting critical match
events, providing a lightweight and training-free alternative to traditional
video-based methods for action spotting.

</details>


### [225] [Dynamic Watermark Generation for Digital Images using Perimeter Gated SPAD Imager PUFs](https://arxiv.org/abs/2506.17134)
*Md Sakibur Sajal,Marc Dandin*

Main category: cs.CV

TL;DR: 提出了一种基于pgSPAD成像器的数字水印技术，利用制造差异（DSNU）生成动态水印，实现来源识别和篡改检测。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在CMOS和APS成像器，SPAD成像器尚未被探索用于水印技术。

Method: 利用三个64x64 pgSPAD芯片的DSNU特性，模拟生成水印，并分析标准测试图像的效果。

Result: 提出的动态水印技术能够实现来源识别和篡改检测，且具有可控的灵敏度-鲁棒性权衡。

Conclusion: pgSPAD成像器在数字水印领域具有潜力，动态水印技术为安全应用提供了新思路。

Abstract: Digital image watermarks as a security feature can be derived from the
imager's physically unclonable functions (PUFs) by utilizing the manufacturing
variations, i.e., the dark signal non-uniformity (DSNU). While a few
demonstrations focused on the CMOS image sensors (CIS) and active pixel sensors
(APS), single photon avalanche diode (SPAD) imagers have never been
investigated for this purpose. In this work, we have proposed a novel
watermarking technique using perimeter gated SPAD (pgSPAD) imagers. We utilized
the DSNU of three 64 x 64 pgSPAD imager chips, fabricated in a 0.35 {\mu}m
standard CMOS process and analyzed the simulated watermarks for standard test
images from publicly available database. Our observation shows that both source
identification and tamper detection can be achieved using the proposed
source-scene-specific dynamic watermarks with a controllable
sensitivity-robustness trade-off.

</details>


### [226] [Semi-Supervised Multi-Modal Medical Image Segmentation for Complex Situations](https://arxiv.org/abs/2506.17136)
*Dongdong Meng,Sheng Li,Hao Wu,Guoping Wang,Xueqing Yan*

Main category: cs.CV

TL;DR: 提出了一种半监督多模态医学图像分割方法，通过多阶段融合和对比互学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决半监督条件下多模态融合方法难以有效利用未标注数据的问题。

Method: 采用多阶段多模态融合与增强策略，结合对比互学习约束跨模态预测一致性。

Result: 在两个多模态数据集上验证了方法的优越性能和鲁棒性。

Conclusion: 该方法在复杂场景下的医学图像分割任务中具有潜在价值。

Abstract: Semi-supervised learning addresses the issue of limited annotations in
medical images effectively, but its performance is often inadequate for complex
backgrounds and challenging tasks. Multi-modal fusion methods can significantly
improve the accuracy of medical image segmentation by providing complementary
information. However, they face challenges in achieving significant
improvements under semi-supervised conditions due to the challenge of
effectively leveraging unlabeled data. There is a significant need to create an
effective and reliable multi-modal learning strategy for leveraging unlabeled
data in semi-supervised segmentation. To address these issues, we propose a
novel semi-supervised multi-modal medical image segmentation approach, which
leverages complementary multi-modal information to enhance performance with
limited labeled data. Our approach employs a multi-stage multi-modal fusion and
enhancement strategy to fully utilize complementary multi-modal information,
while reducing feature discrepancies and enhancing feature sharing and
alignment. Furthermore, we effectively introduce contrastive mutual learning to
constrain prediction consistency across modalities, thereby facilitating the
robustness of segmentation results in semi-supervised tasks. Experimental
results on two multi-modal datasets demonstrate the superior performance and
robustness of the proposed framework, establishing its valuable potential for
solving medical image segmentation tasks in complex scenarios.

</details>


### [227] [Facial Landmark Visualization and Emotion Recognition Through Neural Networks](https://arxiv.org/abs/2506.17191)
*Israel Juárez-Jiménez,Tiffany Guadalupe Martínez Paredes,Jesús García-Ramírez,Eric Ramos Aguilar*

Main category: cs.CV

TL;DR: 论文提出了一种面部地标箱线图可视化技术，用于识别数据集中的异常值，并比较了两种面部地标特征，发现神经网络优于随机森林分类器。


<details>
  <summary>Details</summary>
Motivation: 面部图像情感识别是人机交互中的重要任务，但现有研究缺乏深入的数据集分析，且面部地标可视化存在挑战。

Method: 提出面部地标箱线图可视化技术，并比较绝对位置和位移两种面部地标特征。

Result: 神经网络在情感识别任务中表现优于随机森林分类器。

Conclusion: 面部地标箱线图有助于数据集分析，神经网络是更优的分类器选择。

Abstract: Emotion recognition from facial images is a crucial task in human-computer
interaction, enabling machines to learn human emotions through facial
expressions. Previous studies have shown that facial images can be used to
train deep learning models; however, most of these studies do not include a
through dataset analysis. Visualizing facial landmarks can be challenging when
extracting meaningful dataset insights; to address this issue, we propose
facial landmark box plots, a visualization technique designed to identify
outliers in facial datasets. Additionally, we compare two sets of facial
landmark features: (i) the landmarks' absolute positions and (ii) their
displacements from a neutral expression to the peak of an emotional expression.
Our results indicate that a neural network achieves better performance than a
random forest classifier.

</details>


### [228] [On the Theory of Conditional Feature Alignment for Unsupervised Domain-Adaptive Counting](https://arxiv.org/abs/2506.17137)
*Zhuonan Liang,Dongnan Liu,Jianan Fan,Yaxuan Song,Qiang Qu,Yu Yao,Peng Fu,Weidong Cai*

Main category: cs.CV

TL;DR: 论文提出了一种条件特征对齐的理论框架，通过分区域并测量条件差异，证明了条件对齐能降低联合误差，从而提升跨域计数模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决对象计数模型在跨域部署时因密度变化导致的性能下降问题，标准域适应假设不适用于此类任务相关的变化。

Method: 提出条件特征对齐框架，包括定义条件差异和推导联合误差边界，并设计了一种保留任务相关信息的无监督域适应策略。

Result: 在多个密度分布不同的计数数据集上，该方法优于现有无监督域适应方法。

Conclusion: 条件特征对齐能有效提升跨域计数模型的性能，理论和实验结果均验证了其优越性。

Abstract: Object counting models suffer when deployed across domains with differing
density variety, since density shifts are inherently task-relevant and violate
standard domain adaptation assumptions. To address this, we propose a
theoretical framework of conditional feature alignment. We first formalize the
notion of conditional divergence by partitioning each domain into subsets
(e.g., object vs. background) and measuring divergences per condition. We then
derive a joint error bound showing that, under discrete label spaces treated as
condition sets, aligning distributions conditionally leads to tighter bounds on
the combined source-target decision error than unconditional alignment. These
insights motivate a general conditional adaptation principle: by preserving
task-relevant variations while filtering out nuisance shifts, one can achieve
superior cross-domain generalization for counting. We provide both defining
conditional divergence then proving its benefit in lowering joint error and a
practical adaptation strategy that preserves task-relevant information in
unsupervised domain-adaptive counting. We demonstrate the effectiveness of our
approach through extensive experiments on multiple counting datasets with
varying density distributions. The results show that our method outperforms
existing unsupervised domain adaptation methods, empirically validating the
theoretical insights on conditional feature alignment.

</details>


### [229] [Part$^{2}$GS: Part-aware Modeling of Articulated Objects using 3D Gaussian Splatting](https://arxiv.org/abs/2506.17212)
*Tianjiao Yu,Vedant Shah,Muntasir Wahed,Ying Shen,Kiet A. Nguyen,Ismini Lourentzou*

Main category: cs.CV

TL;DR: Part$^{2}$GS是一种新型框架，用于建模多部分物体的高保真几何和物理一致的运动。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，关节物体的结构和运动建模对3D重建方法仍具挑战性。

Method: 采用部分感知的3D高斯表示，结合物理约束（如接触强制、速度一致性和矢量场对齐）和排斥点场防止碰撞。

Result: 在合成和真实数据集上，Part$^{2}$GS在可移动部分的Chamfer距离上比现有方法提升10倍。

Conclusion: Part$^{2}$GS在建模高保真几何和物理一致运动方面表现出色。

Abstract: Articulated objects are common in the real world, yet modeling their
structure and motion remains a challenging task for 3D reconstruction methods.
In this work, we introduce Part$^{2}$GS, a novel framework for modeling
articulated digital twins of multi-part objects with high-fidelity geometry and
physically consistent articulation. Part$^{2}$GS leverages a part-aware 3D
Gaussian representation that encodes articulated components with learnable
attributes, enabling structured, disentangled transformations that preserve
high-fidelity geometry. To ensure physically consistent motion, we propose a
motion-aware canonical representation guided by physics-based constraints,
including contact enforcement, velocity consistency, and vector-field
alignment. Furthermore, we introduce a field of repel points to prevent part
collisions and maintain stable articulation paths, significantly improving
motion coherence over baselines. Extensive evaluations on both synthetic and
real-world datasets show that Part$^{2}$GS consistently outperforms
state-of-the-art methods by up to 10$\times$ in Chamfer Distance for movable
parts.

</details>


### [230] [Co-Seg++: Mutual Prompt-Guided Collaborative Learning for Versatile Medical Segmentation](https://arxiv.org/abs/2506.17159)
*Qing Xu,Yuxiang Luo,Wenting Duan,Zhen Chen*

Main category: cs.CV

TL;DR: 提出了一种名为Co-Seg++的框架，通过联合语义和实例分割任务，提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将不同分割任务孤立处理，忽略了任务间的相互依赖性，导致分割性能不佳。

Method: 设计了STP-Encoder捕获空间和时间关系，以及MTC-Decoder通过跨任务指导增强上下文一致性。

Result: 在多种CT和组织病理学数据集上表现优于现有方法，适用于牙齿结构、组织病理学和细胞核实例的分割。

Conclusion: Co-Seg++通过联合任务处理显著提升了医学图像分割的准确性和理解能力。

Abstract: Medical image analysis is critical yet challenged by the need of jointly
segmenting organs or tissues, and numerous instances for anatomical structures
and tumor microenvironment analysis. Existing studies typically formulated
different segmentation tasks in isolation, which overlooks the fundamental
interdependencies between these tasks, leading to suboptimal segmentation
performance and insufficient medical image understanding. To address this
issue, we propose a Co-Seg++ framework for versatile medical segmentation.
Specifically, we introduce a novel co-segmentation paradigm, allowing semantic
and instance segmentation tasks to mutually enhance each other. We first devise
a spatio-temporal prompt encoder (STP-Encoder) to capture long-range spatial
and temporal relationships between segmentation regions and image embeddings as
prior spatial constraints. Moreover, we devise a multi-task collaborative
decoder (MTC-Decoder) that leverages cross-guidance to strengthen the
contextual consistency of both tasks, jointly computing semantic and instance
segmentation masks. Extensive experiments on diverse CT and histopathology
datasets demonstrate that the proposed Co-Seg++ outperforms state-of-the-arts
in the semantic, instance, and panoptic segmentation of dental anatomical
structures, histopathology tissues, and nuclei instances. The source code is
available at https://github.com/xq141839/Co-Seg-Plus.

</details>


### [231] [Long-term Traffic Simulation with Interleaved Autoregressive Motion and Scenario Generation](https://arxiv.org/abs/2506.17213)
*Xiuyu Yang,Shuhan Tan,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: InfGen是一个统一的下一令牌预测模型，用于交替进行闭环运动模拟和场景生成，显著提升了长期交通模拟的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的交通模拟器主要关注初始场景的闭环运动模拟，难以应对长期模拟中场景动态变化的需求。

Method: InfGen采用统一的下一令牌预测模型，交替进行闭环运动模拟和场景生成，自动切换模式以实现长期模拟。

Result: InfGen在短期（9秒）模拟中达到最佳性能，在长期（30秒）模拟中显著优于其他方法。

Conclusion: InfGen为长期交通模拟提供了稳定且高效的解决方案，代码和模型将开源。

Abstract: An ideal traffic simulator replicates the realistic long-term point-to-point
trip that a self-driving system experiences during deployment. Prior models and
benchmarks focus on closed-loop motion simulation for initial agents in a
scene. This is problematic for long-term simulation. Agents enter and exit the
scene as the ego vehicle enters new regions. We propose InfGen, a unified
next-token prediction model that performs interleaved closed-loop motion
simulation and scene generation. InfGen automatically switches between
closed-loop motion simulation and scene generation mode. It enables stable
long-term rollout simulation. InfGen performs at the state-of-the-art in
short-term (9s) traffic simulation, and significantly outperforms all other
methods in long-term (30s) simulation. The code and model of InfGen will be
released at https://orangesodahub.github.io/InfGen

</details>


### [232] [YASMOT: Yet another stereo image multi-object tracker](https://arxiv.org/abs/2506.17186)
*Ketil Malde*

Main category: cs.CV

TL;DR: YASMOT是一个轻量级、灵活的对象跟踪器，用于处理来自单目或立体摄像头的对象检测输出，支持生成检测共识。


<details>
  <summary>Details</summary>
Motivation: 在图像时间序列中，跟踪对象并保持其身份可以提升检测性能，并为下游任务（如行为分类和丰度估计）提供支持。

Method: YASMOT处理流行对象检测器的输出，支持单目或立体摄像头配置，并能生成检测共识。

Result: YASMOT实现了轻量级且灵活的对象跟踪功能。

Conclusion: YASMOT为对象跟踪提供了一种高效且通用的解决方案。

Abstract: There now exists many popular object detectors based on deep learning that
can analyze images and extract locations and class labels for occurrences of
objects. For image time series (i.e., video or sequences of stills), tracking
objects over time and preserving object identity can help to improve object
detection performance, and is necessary for many downstream tasks, including
classifying and predicting behaviors, and estimating total abundances. Here we
present yasmot, a lightweight and flexible object tracker that can process the
output from popular object detectors and track objects over time from either
monoscopic or stereoscopic camera configurations. In addition, it includes
functionality to generate consensus detections from ensembles of object
detectors.

</details>


### [233] [Machine Mental Imagery: Empower Multimodal Reasoning with Latent Visual Tokens](https://arxiv.org/abs/2506.17218)
*Zeyuan Yang,Xueyang Yu,Delin Chen,Maohao Shen,Chuang Gan*

Main category: cs.CV

TL;DR: 论文提出Mirage框架，通过隐式视觉标记增强视觉语言模型（VLM）的解码能力，避免显式图像生成，从而提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在需要视觉想象的任务中表现受限，因为其仅通过文本解码无法有效处理视觉推理。

Method: 提出Mirage框架，通过隐式视觉标记和文本标记交替解码，结合蒸馏和强化学习优化模型。

Result: 实验表明Mirage在多种基准测试中显著提升了多模态推理能力。

Conclusion: Mirage为VLM提供了一种无需显式图像生成的多模态推理新方法。

Abstract: Vision-language models (VLMs) excel at multimodal understanding, yet their
text-only decoding forces them to verbalize visual reasoning, limiting
performance on tasks that demand visual imagination. Recent attempts train VLMs
to render explicit images, but the heavy image-generation pre-training often
hinders the reasoning ability. Inspired by the way humans reason with mental
imagery-the internal construction and manipulation of visual cues-we
investigate whether VLMs can reason through interleaved multimodal trajectories
without producing explicit images. To this end, we present a Machine Mental
Imagery framework, dubbed as Mirage, which augments VLM decoding with latent
visual tokens alongside ordinary text. Concretely, whenever the model chooses
to ``think visually'', it recasts its hidden states as next tokens, thereby
continuing a multimodal trajectory without generating pixel-level images. Begin
by supervising the latent tokens through distillation from ground-truth image
embeddings, we then switch to text-only supervision to make the latent
trajectory align tightly with the task objective. A subsequent reinforcement
learning stage further enhances the multimodal reasoning capability.
Experiments on diverse benchmarks demonstrate that Mirage unlocks stronger
multimodal reasoning without explicit image generation.

</details>


### [234] [Hunyuan-GameCraft: High-dynamic Interactive Game Video Generation with Hybrid History Condition](https://arxiv.org/abs/2506.17201)
*Jiaqi Li,Junshu Tang,Zhiyong Xu,Longhuang Wu,Yuan Zhou,Shuai Shao,Tianbao Yu,Zhiguo Cao,Qinglin Lu*

Main category: cs.CV

TL;DR: Hunyuan-GameCraft是一个用于高动态交互式游戏视频生成的新框架，通过统一输入表示、混合历史条件训练和模型蒸馏，解决了现有方法在动态性、通用性、长期一致性和效率上的限制。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散和可控视频生成的方法在动态性、通用性、长期一致性和效率上存在不足，限制了多样化游戏视频的生成能力。

Method: 统一键盘和鼠标输入为共享相机表示空间，提出混合历史条件训练策略，并通过模型蒸馏提升推理效率。

Result: 在超过100款AAA游戏的百万级数据集上训练，显著提升了视觉保真度、真实感和动作可控性，实验表明其性能优于现有模型。

Conclusion: Hunyuan-GameCraft在交互式游戏视频生成中实现了更高的真实感和可玩性，适合复杂交互环境的实时部署。

Abstract: Recent advances in diffusion-based and controllable video generation have
enabled high-quality and temporally coherent video synthesis, laying the
groundwork for immersive interactive gaming experiences. However, current
methods face limitations in dynamics, generality, long-term consistency, and
efficiency, which limit the ability to create various gameplay videos. To
address these gaps, we introduce Hunyuan-GameCraft, a novel framework for
high-dynamic interactive video generation in game environments. To achieve
fine-grained action control, we unify standard keyboard and mouse inputs into a
shared camera representation space, facilitating smooth interpolation between
various camera and movement operations. Then we propose a hybrid
history-conditioned training strategy that extends video sequences
autoregressively while preserving game scene information. Additionally, to
enhance inference efficiency and playability, we achieve model distillation to
reduce computational overhead while maintaining consistency across long
temporal sequences, making it suitable for real-time deployment in complex
interactive environments. The model is trained on a large-scale dataset
comprising over one million gameplay recordings across over 100 AAA games,
ensuring broad coverage and diversity, then fine-tuned on a carefully annotated
synthetic dataset to enhance precision and control. The curated game scene data
significantly improves the visual fidelity, realism and action controllability.
Extensive experiments demonstrate that Hunyuan-GameCraft significantly
outperforms existing models, advancing the realism and playability of
interactive game video generation.

</details>


### [235] [UniFork: Exploring Modality Alignment for Unified Multimodal Understanding and Generation](https://arxiv.org/abs/2506.17202)
*Teng Li,Quanfeng Lu,Lirui Zhao,Hao Li,Xizhou Zhu,Yu Qiao,Jun Zhang,Wenqi Shao*

Main category: cs.CV

TL;DR: UniFork提出了一种Y形架构，通过共享浅层和任务特定的深层分支，平衡了图像理解与生成任务的模态对齐需求，性能优于传统共享架构。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在图像理解与生成任务中存在模态对齐冲突，导致性能折衷。

Method: 分析任务专家模型和统一模型的模态对齐行为，提出共享浅层和任务特定深层的Y形架构UniFork。

Result: UniFork性能优于传统共享架构，与任务特定模型相当或更好。

Conclusion: UniFork通过平衡共享学习与任务专业化，解决了统一模型中的模态对齐冲突。

Abstract: Unified image understanding and generation has emerged as a promising
paradigm in multimodal artificial intelligence. Despite recent progress, the
optimal architectural design for such unified models remains an open challenge.
In this work, we start by analyzing the modality alignment behaviors of
task-specific expert models for understanding and generation, as well as
current unified models. Our analysis reveals a crucial observation:
understanding tasks benefit from a progressively increasing modality alignment
across network depth, which helps build up semantic information for better
comprehension; In contrast, generation tasks follow a different trend: modality
alignment increases in the early layers but decreases in the deep layers to
recover spatial details. These divergent alignment patterns create a
fundamental conflict in fully shared Transformer backbones, where a uniform
representational flow often leads to performance compromises across two tasks.
Motivated by this finding, we introduce UniFork, a novel Y-shaped architecture
that shares the shallow layers for cross-task representation learning, while
employing task-specific branches in deeper layers to avoid task interference.
This design effectively balances shared learning and task specialization.
Through extensive ablation experiments, we demonstrate that Unifork
consistently outperforms conventional fully shared Transformer architectures,
and achieves performance on par with or better than task-specific models.

</details>


### [236] [Emergent Temporal Correspondences from Video Diffusion Transformers](https://arxiv.org/abs/2506.17220)
*Jisu Nam,Soowon Son,Dahyun Chung,Jiyoung Kim,Siyoon Jin,Junhwa Hur,Seungryong Kim*

Main category: cs.CV

TL;DR: DiffTrack是一个定量分析框架，用于研究视频扩散模型（DiTs）如何建立和表示帧间时间对应关系。通过构建带伪真值跟踪注释的数据集和新评估指标，揭示了特定层中的查询-键相似性在时间匹配中的关键作用，并在零样本点跟踪和运动增强视频生成中展示了应用价值。


<details>
  <summary>Details</summary>
Motivation: 研究视频扩散模型（DiTs）内部如何建立和表示帧间时间对应关系，填补了这一领域的空白。

Method: 提出DiffTrack框架，构建带伪真值跟踪注释的数据集，设计新评估指标，分析3D注意力机制中各组件（如表示、层和时间步）的作用。

Result: 发现特定层中的查询-键相似性在时间匹配中起关键作用，且在去噪过程中逐渐显著；在零样本点跟踪中达到SOTA性能，并通过新引导方法提升生成视频的时间一致性。

Conclusion: DiffTrack为理解视频DiTs的内部机制提供了关键见解，并为进一步研究和应用奠定了基础。

Abstract: Recent advancements in video diffusion models based on Diffusion Transformers
(DiTs) have achieved remarkable success in generating temporally coherent
videos. Yet, a fundamental question persists: how do these models internally
establish and represent temporal correspondences across frames? We introduce
DiffTrack, the first quantitative analysis framework designed to answer this
question. DiffTrack constructs a dataset of prompt-generated video with pseudo
ground-truth tracking annotations and proposes novel evaluation metrics to
systematically analyze how each component within the full 3D attention
mechanism of DiTs (e.g., representations, layers, and timesteps) contributes to
establishing temporal correspondences. Our analysis reveals that query-key
similarities in specific, but not all, layers play a critical role in temporal
matching, and that this matching becomes increasingly prominent during the
denoising process. We demonstrate practical applications of DiffTrack in
zero-shot point tracking, where it achieves state-of-the-art performance
compared to existing vision foundation and self-supervised video models.
Further, we extend our findings to motion-enhanced video generation with a
novel guidance method that improves temporal consistency of generated videos
without additional training. We believe our work offers crucial insights into
the inner workings of video DiTs and establishes a foundation for further
research and applications leveraging their temporal understanding.

</details>


### [237] [VLN-R1: Vision-Language Navigation via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.17221)
*Zhangyang Qi,Zhixiong Zhang,Yizhou Yu,Jiaqi Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: VLN-R1是一种端到端框架，利用大型视觉语言模型（LVLM）将第一视角视频流直接转换为连续导航动作，通过GRPO训练和两阶段微调（SFT和RFT）提升性能，在VLN-CE基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于语言模型的导航系统受限于离散拓扑图的问题，探索LVLM在具体导航任务中的应用潜力。

Method: 提出VLN-R1框架，结合GRPO训练和两阶段微调（SFT和RFT），采用Long-Short Memory Sampling平衡历史与当前观察，并通过Time-Decayed Reward机制优化多步动作。

Result: 在VLN-CE基准测试中表现优异，证明LVLM能有效驱动具体导航任务。

Conclusion: VLN-R1展示了LVLM在具体导航任务中的潜力，通过数据高效和奖励驱动的后训练增强任务特定推理能力。

Abstract: Vision-Language Navigation (VLN) is a core challenge in embodied AI,
requiring agents to navigate real-world environments using natural language
instructions. Current language model-based navigation systems operate on
discrete topological graphs, limiting path planning to predefined node
connections. We propose VLN-R1, an end-to-end framework that leverages Large
Vision-Language Models (LVLM) to directly translate egocentric video streams
into continuous navigation actions, adopting GRPO-based training inspired by
DeepSeek-R1. To enable effective training, we first construct the VLN-Ego
dataset using a 3D simulator, Habitat, and propose Long-Short Memory Sampling
to balance historical and current observations. While large language models can
supervise complete textual instructions, they lack fine-grained action-level
control. Our framework employs a two-stage training approach: a) Supervised
fine-tuning (SFT) to align the model's action sequence text predictions with
expert demonstrations, followed by b) Reinforcement fine-tuning (RFT) enhanced
with a Time-Decayed Reward (TDR) mechanism that strategically weights
multi-step future actions. Experimental results show VLN-R1 achieves strong
performance on VLN-CE benchmark. VLN-R1 proves LVLMs can drive embodied
navigation and enhance task-specific reasoning through data-efficient,
reward-driven post-training.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [238] [Adaptive Anomaly Detection in the Presence of Concept Drift: Extended Report](https://arxiv.org/abs/2506.15831)
*Jongjun Park,Fei Chiang,Mostafa Milani*

Main category: cs.DB

TL;DR: 论文提出了AnDri系统，用于在概念漂移存在的情况下进行异常检测，通过调整正常模式并区分异常子序列和新概念，同时引入了一种新的聚类方法AHC。


<details>
  <summary>Details</summary>
Motivation: 数据分布的变化（概念漂移）和异常变化对时间序列异常检测带来挑战，现有工作多孤立研究两者，缺乏综合解决方案。

Method: 开发AnDri系统，动态调整正常模式，区分异常子序列和新概念；提出Adjacent Hierarchical Clustering (AHC)聚类方法，考虑时间局部性。

Result: AnDri能够有效区分概念漂移和异常，提高检测准确性，减少不必要的模型更新开销。

Conclusion: AnDri系统为解决概念漂移和异常检测的综合问题提供了有效方法，AHC聚类方法进一步优化了时间序列分析。

Abstract: Data changes to reflect evolving user behaviour, preferences, and changes in
the environment. Such changes may occur due to expected shifts in the data
distribution, i.e., concept drift, or unexpected anomalous changes. The
presence of concept drift poses challenges for anomaly detection in time
series. While anomalies are caused by undesirable changes in the data,
differentiating abnormal changes from varying normal behaviours is difficult
due to differing frequencies of occurrence, varying time intervals when normal
patterns occur. Differentiating between concept drift and anomalies is critical
for accurate analysis as studies have shown that the compounding effects of
error propagation in downstream data analysis tasks lead to lower detection
accuracy and increased overhead due to unnecessary model updates.
Unfortunately, existing work has largely explored anomaly detection and concept
drift detection in isolation. We develop AnDri, a system for Anomaly detection
in the presence of Drift, which adjusts the normal patterns temporally, and
distinguish abnormal subsequences and new concepts. Moreover, it introduces a
new clustering method, Adjacent Hierarchical Clustering (AHC), which groups
similar subsequences while respecting their temporal locality.

</details>


### [239] [Delta: A Learned Mixed Cost-based Query Optimization Framework](https://arxiv.org/abs/2506.15848)
*Jiazhen Peng,Zheng Qu,Xiaoye Miao,Rong Zhu*

Main category: cs.DB

TL;DR: Delta是一种混合成本查询优化框架，通过兼容查询检测器和两阶段规划器提高查询效率。


<details>
  <summary>Details</summary>
Motivation: 现有查询优化器存在搜索空间爆炸、训练成本高和准确性不足的问题，缺乏性能不佳查询的检测机制。

Method: Delta采用马氏距离检测器过滤不兼容查询，两阶段规划器结合值网络和成本模型生成高质量计划。

Result: 实验表明，Delta平均比PostgreSQL快2.34倍，优于现有学习方法2.21倍。

Conclusion: Delta通过混合成本优化和两阶段规划，显著提升了查询效率和计划质量。

Abstract: Query optimizer is a crucial module for database management systems. Existing
optimizers exhibit two flawed paradigms: (1) cost-based optimizers use dynamic
programming with cost models but face search space explosion and heuristic
pruning constraints; (2) value-based ones train value networks to enable
efficient beam search, but incur higher training costs and lower accuracy. They
also lack mechanisms to detect queries where they may perform poorly. To
determine more efficient plans, we propose Delta, a mixed cost-based query
optimization framework that consists of a compatible query detector and a
two-stage planner. Delta first employs a Mahalanobis distancebased detector to
preemptively filter out incompatible queries where the planner might perform
poorly. For compatible queries, Delta activates its two-stage mixed cost-based
planner. Stage I serves as a coarse-grained filter to generate high-quality
candidate plans based on the value network via beam search, relaxing precision
requirements and narrowing the search space. Stage II employs a fine-grained
ranker to determine the best plan from the candidate plans based on a learned
cost model. Moreover, to reduce training costs, we reuse and augment the
training data from stage I to train the model in stage II. Experimental results
on three workloads demonstrate that Delta identifies higher-quality plans,
achieving an average 2.34x speedup over PostgreSQL and outperforming the
state-of-the-art learned methods by 2.21x.

</details>


### [240] [Empowering Graph-based Approximate Nearest Neighbor Search with Adaptive Awareness Capabilities](https://arxiv.org/abs/2506.15986)
*Jiancheng Ruan,Tingyang Chen,Renchi Yang,Xiangyu Ke,Yunjun Gao*

Main category: cs.DB

TL;DR: GATE提出了一种基于图的ANNS方法，通过自适应拓扑和查询感知优化查询性能。


<details>
  <summary>Details</summary>
Motivation: 现有图方法未能充分利用拓扑信息且存在数据分布不匹配问题，GATE旨在解决这些问题。

Method: GATE利用高维数据的聚类特性提取中心节点，并通过对比学习模型编码结构和查询特征，构建导航图索引。

Result: 实验表明GATE比现有方法快1.2-2.0倍。

Conclusion: GATE是一种轻量级自适应模块，显著提升ANNS查询效率。

Abstract: Approximate Nearest Neighbor Search (ANNS) in high-dimensional spaces finds
extensive applications in databases, information retrieval, recommender
systems, etc. While graph-based methods have emerged as the leading solution
for ANNS due to their superior query performance, they still face several
challenges, such as struggling with local optima and redundant computations.
These issues arise because existing methods (i) fail to fully exploit the
topological information underlying the proximity graph G, and (ii) suffer from
severe distribution mismatches between the base data and queries in practice.
  To this end, this paper proposes GATE, high-tier proximity Graph with
Adaptive Topology and Query AwarEness, as a lightweight and adaptive module
atop the graph-based indexes to accelerate ANNS. Specifically, GATE formulates
the critical problem to identify an optimal entry point in the proximity graph
for a given query, facilitating faster online search. By leveraging the
inherent clusterability of high-dimensional data, GATE first extracts a small
set of hub nodes V as candidate entry points. Then, resorting to a contrastive
learning-based two-tower model, GATE encodes both the structural semantics
underlying G and the query-relevant features into the latent representations of
these hub nodes V. A navigation graph index on V is further constructed to
minimize the model inference overhead. Extensive experiments demonstrate that
GATE achieves a 1.2-2.0X speed-up in query performance compared to
state-of-the-art graph-based indexes.

</details>


### [241] [Filter-Centric Vector Indexing: Geometric Transformation for Efficient Filtered Vector Search](https://arxiv.org/abs/2506.15987)
*Alireza Heidari,Wei Zhang*

Main category: cs.DB

TL;DR: FCVI是一种新型框架，通过数学变换将过滤条件直接编码到向量空间中，解决了向量搜索中性能与准确性的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理向量相似性和属性过滤时，需要在性能和准确性之间做出妥协，FCVI旨在解决这一问题。

Method: FCVI通过数学变换ψ(v, f, α)将过滤条件编码到向量空间，兼容现有向量索引（如HNSW、FAISS、ANNOY）。

Result: FCVI的吞吐量比现有方法高2.6-3.0倍，同时保持相当的召回率，且在分布变化时表现稳定。

Conclusion: FCVI凭借其性能、兼容性和稳定性，成为生产向量搜索系统的理想解决方案。

Abstract: The explosive growth of vector search applications demands efficient handling
of combined vector similarity and attribute filtering; a challenge where
current approaches force an unsatisfying choice between performance and
accuracy. We introduce Filter-Centric Vector Indexing (FCVI), a novel framework
that transforms this fundamental trade-off by directly encoding filter
conditions into the vector space through a mathematically principled
transformation $\psi(v, f, \alpha)$. Unlike specialized solutions, FCVI works
with any existing vector index (HNSW, FAISS, ANNOY) while providing theoretical
guarantees on accuracy. Our comprehensive evaluation demonstrates that FCVI
achieves 2.6-3.0 times higher throughput than state-of-the-art methods while
maintaining comparable recall. More remarkably, FCVI exhibits exceptional
stability under distribution shifts; maintaining consistent performance when
filter patterns or vector distributions change, unlike traditional approaches
that degrade significantly. This combination of performance, compatibility, and
resilience positions FCVI as an immediately applicable solution for production
vector search systems requiring flexible filtering capabilities.

</details>


### [242] [Data-Agnostic Cardinality Learning from Imperfect Workloads](https://arxiv.org/abs/2506.16007)
*Peizhi Wu,Rong Kang,Tieying Zhang,Jianjun Chen,Ryan Marcus,Zachary G. Ives*

Main category: cs.DB

TL;DR: GRASP是一种无需数据访问的基数估计系统，能够在现实世界的不完整和不平衡查询负载下高效工作。


<details>
  <summary>Details</summary>
Motivation: 传统基数估计方法依赖数据统计，但实际场景中数据访问受限且查询负载不完美。

Method: GRASP采用组合设计，包括处理范围谓词的表级基数估计模型和捕获连接相关性的学习计数草图模型。

Result: GRASP在三个数据库实例中表现优于现有查询驱动模型，甚至在CEB-IMDb-full基准测试中接近或超越传统方法。

Conclusion: GRASP在无需数据访问且仅使用10%连接模板的情况下，实现了高精度和低延迟的基数估计。

Abstract: Cardinality estimation (CardEst) is a critical aspect of query optimization.
Traditionally, it leverages statistics built directly over the data. However,
organizational policies (e.g., regulatory compliance) may restrict global data
access. Fortunately, query-driven cardinality estimation can learn CardEst
models using query workloads. However, existing query-driven models often
require access to data or summaries for best performance, and they assume
perfect training workloads with complete and balanced join templates (or join
graphs). Such assumptions rarely hold in real-world scenarios, in which join
templates are incomplete and imbalanced. We present GRASP, a data-agnostic
cardinality learning system designed to work under these real-world
constraints. GRASP's compositional design generalizes to unseen join templates
and is robust to join template imbalance. It also introduces a new per-table
CardEst model that handles value distribution shifts for range predicates, and
a novel learned count sketch model that captures join correlations across base
relations. Across three database instances, we demonstrate that GRASP
consistently outperforms existing query-driven models on imperfect workloads,
both in terms of estimation accuracy and query latency. Remarkably, GRASP
achieves performance comparable to, or even surpassing, traditional approaches
built over the underlying data on the complex CEB-IMDb-full benchmark --
despite operating without any data access and using only 10% of all possible
join templates.

</details>


### [243] [PBench: Workload Synthesizer with Real Statistics for Cloud Analytics Benchmarking](https://arxiv.org/abs/2506.16379)
*Yan Zhou,Chunwei Liu,Bhuvan Urgaonkar,Zhengle Wang,Magnus Mueller,Chao Zhang,Songyue Zhang,Pascal Pfeil,Dominik Horn,Zhengchun Liu,Davide Pagano,Tim Kraska,Samuel Madden,Ju Fan*

Main category: cs.DB

TL;DR: 论文提出PBench，一种合成工作负载的工具，通过优化选择组件和LLM生成新组件，显著减少与实际云工作负载的统计误差。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试（如TPC-H、TPC-DS）无法捕捉真实云工作负载的执行统计，而现有工作负载跟踪缺乏关键组件（如SQL查询和数据库）。

Method: 提出PBench，包括多目标优化组件选择、时间戳分配方法和基于LLM的组件增强。

Result: PBench在真实云工作负载跟踪上测试，比现有方法减少6倍近似误差。

Conclusion: PBench能有效合成接近真实云工作负载的统计特性，填补了基准测试与实际工作负载之间的差距。

Abstract: Cloud service providers commonly use standard benchmarks like TPC-H and
TPC-DS to evaluate and optimize cloud data analytics systems. However, these
benchmarks rely on fixed query patterns and fail to capture the real execution
statistics of production cloud workloads. Although some cloud database vendors
have recently released real workload traces, these traces alone do not qualify
as benchmarks, as they typically lack essential components like the original
SQL queries and their underlying databases. To overcome this limitation, this
paper introduces a new problem of workload synthesis with real statistics,
which aims to generate synthetic workloads that closely approximate real
execution statistics, including key performance metrics and operator
distributions, in real cloud workloads. To address this problem, we propose
PBench, a novel workload synthesizer that constructs synthetic workloads by
judiciously selecting and combining workload components (i.e., queries and
databases) from existing benchmarks. This paper studies the key challenges in
PBench. First, we address the challenge of balancing performance metrics and
operator distributions by introducing a multi-objective optimization-based
component selection method. Second, to capture the temporal dynamics of real
workloads, we design a timestamp assignment method that progressively refines
workload timestamps. Third, to handle the disparity between the original
workload and the candidate workload, we propose a component augmentation
approach that leverages large language models (LLMs) to generate additional
workload components while maintaining statistical fidelity. We evaluate PBench
on real cloud workload traces, demonstrating that it reduces approximation
error by up to 6x compared to state-of-the-art methods.

</details>


### [244] [LDI: Localized Data Imputation](https://arxiv.org/abs/2506.16616)
*Soroush Omidvartehrani,Davood Rafiei*

Main category: cs.DB

TL;DR: 论文提出了一种名为LDI的新框架，通过局部化提示提高LLM在数据填补中的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的表格数据常存在缺失值，影响下游分析。现有LLM填补方法因使用宽泛提示而牺牲准确性、可扩展性和可解释性。

Method: LDI框架为每个缺失值选择紧凑且上下文相关的属性和元组子集，减少噪声并提高可追溯性。

Result: 实验表明LDI在四个真实数据集上优于现有方法，使用托管LLM时准确率提升8%，轻量级本地模型提升更显著。

Conclusion: LDI不仅准确率高，还提高了可解释性和对数据不一致的鲁棒性，适用于高风险和隐私敏感场景。

Abstract: Missing values are a common challenge in real-world tabular data and can
significantly impair downstream analysis. While Large Language Models (LLMs)
have recently shown promise in data imputation, existing methods often rely on
broad, unfiltered prompts that compromise accuracy, scalability, and
explainability. We introduce LDI (Localized Data Imputation), a novel framework
that improves both the accuracy and transparency of LLM-based imputation by
selecting a compact, contextually relevant subset of attributes and tuples for
each missing value. This localized prompting reduces noise, enables
traceability by revealing which data influenced each prediction, and is
effective across both hosted LLMs and lightweight local models. Our extensive
experiments on four real-world datasets show that LDI outperforms
state-of-the-art methods, achieving up to 8% higher accuracy when using hosted
LLMs. The gains are more substantial with lightweight local models, reaching
nearly 17% and 97% accuracy on some datasets when using 3 and 10 examples,
respectively. In addition to higher accuracy, LDI offers improved
interpretability and robustness to data inconsistencies, making it well-suited
for high-stakes and privacy-sensitive applications.

</details>


### [245] [Advancing Fact Attribution for Query Answering: Aggregate Queries and Novel Algorithms](https://arxiv.org/abs/2506.16923)
*Omer Abramovich,Daniel Deutch,Nave Frost,Ahmet Kara,Dan Olteanu*

Main category: cs.DB

TL;DR: 提出了一种计算输入元组对查询结果贡献的新方法，基于Banzhaf和Shapley值，适用于包含聚合的查询，并通过两种优化显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对简单查询（如Select-Project-Join-Union），缺乏对聚合查询的实用解决方案。

Method: 引入两种优化：1）利用相同贡献的元组减少计算量；2）通过查询谱系的梯度高效计算贡献。

Result: 实验表明，该方法在非聚合查询上比现有技术快3个数量级，且适用于聚合查询。

Conclusion: 该方法首次实现了对聚合查询的实用化，并通过优化显著提升了性能。

Abstract: In this paper, we introduce a novel approach to computing the contribution of
input tuples to the result of the query, quantified by the Banzhaf and Shapley
values. In contrast to prior algorithmic work that focuses on
Select-Project-Join-Union queries, ours is the first practical approach for
queries with aggregates. It relies on two novel optimizations that are
essential for its practicality and significantly improve the runtime
performance already for queries without aggregates. The first optimization
exploits the observation that many input tuples have the same contribution to
the query result, so it is enough to compute the contribution of one of them.
The second optimization uses the gradient of the query lineage to compute the
contributions of all tuples with the same complexity as for one of them.
Experiments with a million instances over 3 databases show that our approach
achieves up to 3 orders of magnitude runtime improvements over the
state-of-the-art for queries without aggregates, and that it is practical for
aggregate queries.

</details>


### [246] [PUL: Pre-load in Software for Caches Wouldn't Always Play Along](https://arxiv.org/abs/2506.16976)
*Arthur Bernhardt,Sajjad Tamimi,Florian Stock,Andreas Koch,Ilia Petrov*

Main category: cs.DB

TL;DR: 论文探讨了软件预取在近数据处理环境中的潜力，通过计算与IO交错提高计算利用率。


<details>
  <summary>Details</summary>
Motivation: 内存延迟和带宽是限制系统性能和可扩展性的主要因素，现代CPU通过缓存、乱序执行或硬件预取来隐藏延迟，但软件预取效率更高。

Method: 研究基于软件的、后摩尔时代的系统，将操作卸载到智能内存中。

Result: 软件预取在近数据处理环境中具有更高的潜力。

Conclusion: 软件预取通过计算与IO交错，显著提升了计算利用率。

Abstract: Memory latencies and bandwidth are major factors, limiting system performance
and scalability. Modern CPUs aim at hiding latencies by employing large caches,
out-of-order execution, or complex hardware prefetchers. However,
software-based prefetching exhibits higher efficiency, improving with newer CPU
generations.
  In this paper we investigate software-based, post-Moore systems that offload
operations to intelligent memories. We show that software-based prefetching has
even higher potential in near-data processing settings by maximizing compute
utilization through compute/IO interleaving.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [247] [TrainVerify: Equivalence-Based Verification for Distributed LLM Training](https://arxiv.org/abs/2506.15961)
*Yunchi Lu,Youshan Miao,Cheng Tan,Peng Huang,Yi Zhu,Xian Zhang,Fan Yang*

Main category: cs.DC

TL;DR: TrainVerify是一个用于验证大规模语言模型分布式训练的系统，通过形式化验证确保并行执行计划与逻辑规范一致，解决了LLM训练中的静默错误问题。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLM）的分布式训练成本高昂且缺乏验证，容易导致静默错误和资源浪费。

Method: TrainVerify引入形状缩减技术和分阶段并行验证算法，显著降低验证复杂度。

Result: 成功验证了包括Llama3（405B）和DeepSeek-V3（671B）在内的前沿LLM训练计划。

Conclusion: TrainVerify为LLM分布式训练提供了高效且可靠的验证解决方案。

Abstract: Training large language models (LLMs) at scale requires parallel execution
across thousands of devices, incurring enormous computational costs. Yet, these
costly distributed trainings are rarely verified, leaving them prone to silent
errors and potentially wasting millions of GPU hours. We introduce TrainVerify,
a system for verifiable distributed training of LLMs. Given a deep learning
model's logical specification as the ground truth, TrainVerify formally
verifies that a distributed parallel execution plan is mathematically
equivalent to it. Direct verification is notoriously difficult due to the sheer
scale of LLMs which often involves billions of variables and highly intricate
computation graphs. Therefore, TrainVerify introduces shape-reduction
techniques and a stage-wise parallel verification algorithm that significantly
reduces complexity while preserving formal correctness. TrainVerify scales to
frontier LLMs, including the successful verification of the Llama3 (405B) and
DeepSeek-V3 (671B) training plans.

</details>


### [248] [NetSenseML: Network-Adaptive Compression for Efficient Distributed Machine Learning](https://arxiv.org/abs/2506.16235)
*Yisu Wang,Xinjiao Li,Ruilong Wu,Huangxun Chen,Dirk Kutscher*

Main category: cs.DC

TL;DR: NetSenseML是一个动态调整梯度压缩策略的分布式深度学习框架，根据实时网络条件优化训练性能。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式机器学习训练对网络基础设施要求高，传统梯度压缩技术会损害模型精度。

Method: NetSenseML通过实时监控网络条件，动态调整量化、剪枝和压缩策略，仅在网络拥塞时应用压缩。

Result: 实验表明，NetSenseML在带宽受限条件下，训练吞吐量比现有压缩系统提高1.55至9.84倍。

Conclusion: NetSenseML有效平衡了数据负载减少和模型精度，提升了训练效率和收敛速度。

Abstract: Training large-scale distributed machine learning models imposes considerable
demands on network infrastructure, often resulting in sudden traffic spikes
that lead to congestion, increased latency, and reduced throughput, which would
ultimately affect convergence times and overall training performance. While
gradient compression techniques are commonly employed to alleviate network
load, they frequently compromise model accuracy due to the loss of gradient
information.
  This paper introduces NetSenseML, a novel network adaptive distributed deep
learning framework that dynamically adjusts quantization, pruning, and
compression strategies in response to real-time network conditions. By actively
monitoring network conditions, NetSenseML applies gradient compression only
when network congestion negatively impacts convergence speed, thus effectively
balancing data payload reduction and model accuracy preservation.
  Our approach ensures efficient resource usage by adapting reduction
techniques based on current network conditions, leading to shorter convergence
times and improved training efficiency. We present the design of the NetSenseML
adaptive data reduction function and experimental evaluations show that
NetSenseML can improve training throughput by a factor of 1.55 to 9.84 times
compared to state-of-the-art compression-enabled systems for representative DDL
training jobs in bandwidth-constrained conditions.

</details>


### [249] [A Study of Synchronization Methods for Concurrent Size](https://arxiv.org/abs/2506.16350)
*Hen Kas-Sharir,Gal Sela,Erez Petrank*

Main category: cs.DC

TL;DR: 研究同步方法以减少并发数据结构中线性化大小方法的开销，发现不同场景需不同方法。


<details>
  <summary>Details</summary>
Motivation: 并发环境中线性化大小方法引入显著开销，需优化性能。

Method: 研究握手技术、乐观技术和基于锁的技术，并与现有方法对比。

Result: 适当同步方法可显著减少开销，但无通用方案；低争用下乐观和锁方法优，高争用下握手和无等待方法优。

Conclusion: 同步方法选择需根据场景，与并发计算趋势一致。

Abstract: The size of collections, maps, and data structures in general, constitutes a
fundamental property. An implementation of the size method is required in most
programming environments. Nevertheless, in a concurrent environment,
integrating a linearizable concurrent size introduces a noticeable overhead on
all operations of the data structure, even when the size method is not invoked
during the execution. In this work we present a study of synchronization
methods in an attempt to improve the performance of the data structure. In
particular, we study a handshake technique that is commonly used with
concurrent garbage collection, an optimistic technique, and a lock-based
technique. Evaluation against the state-of-the-art size methodology
demonstrates that the overhead can be significantly reduced by selecting the
appropriate synchronization approach, but there is no one-size-fits-all method.
Different scenarios call for different synchronization methods, as rigorously
shown in this study. Nevertheless, our findings align with general trends in
concurrent computing. In scenarios characterized by low contention, optimistic
and lock-based approaches work best, whereas under high contention, the most
effective solutions are the handshake approach and the wait-free approach.

</details>


### [250] [Parallel Point-to-Point Shortest Paths and Batch Queries](https://arxiv.org/abs/2506.16488)
*Xiaojun Dong,Andy Li,Yan Gu,Yihan Sun*

Main category: cs.DC

TL;DR: Orionet提出了一种高效的并行点对点最短路径（PPSP）查询方法，结合双向搜索（BiDS）和其他启发式方法，并扩展到批量查询。实验表明其性能显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有单源最短路径（SSSP）框架在并行PPSP查询中的效率问题，并扩展到批量查询的实际应用场景。

Method: 基于SSSP框架，结合修剪条件、双向搜索、A*搜索和双向A*，设计简单高效的并行PPSP算法。批量查询通过查询图抽象实现信息共享。

Result: 双向搜索比GraphIt快2.9倍，比MBQ快6.8倍；双向A*比GraphIt和MBQ的A*分别快4.4倍和6.2倍。批量查询性能优于普通解决方案。

Conclusion: Orionet在单次和批量PPSP查询中均表现出高效性，为实际应用提供了强有力的工具。

Abstract: We propose Orionet, efficient parallel implementations of Point-to-Point
Shortest Paths (PPSP) queries using bidirectional search (BiDS) and other
heuristics, with an additional focus on batch PPSP queries. We present a
framework for parallel PPSP built on existing single-source shortest paths
(SSSP) frameworks by incorporating pruning conditions. As a result, we develop
efficient parallel PPSP algorithms based on early termination, bidirectional
search, A$^*$ search, and bidirectional A$^*$ all with simple and efficient
implementations.
  We extend our idea to batch PPSP queries, which are widely used in real-world
scenarios. We first design a simple and flexible abstraction to represent the
batch so PPSP can leverage the shared information of the batch. Orionet
formalizes the batch as a query graph represented by edges between queried
sources and targets. In this way, we directly extended our PPSP framework to
batched queries in a simple and efficient way.
  We evaluate Orionet on both single and batch PPSP queries using various graph
types and distance percentiles of queried pairs, and compare it against two
baselines, GraphIt and MBQ. Both of them support parallel single PPSP and A$^*$
using unidirectional search. On 14 graphs we tested, on average, our
bidirectional search is 2.9$\times$ faster than GraphIt, and 6.8$\times$ faster
than MBQ. Our bidirectional A$^*$ is 4.4$\times$ and 6.2$\times$ faster than
the A$^*$ in GraphIt and MBQ, respectively. For batched PPSP queries, we also
provide in-depth experimental evaluation, and show that Orionet provides strong
performance compared to the plain solutions.

</details>


### [251] [Enabling Blockchain Interoperability Through Network Discovery Services](https://arxiv.org/abs/2506.16611)
*Khalid Hassan,Amirreza Sokhankhosh,Sara Rouhani*

Main category: cs.DC

TL;DR: 本文提出了一种去中心化的区块链网络发现架构，解决了现有解决方案中网络初始发现未被充分解决的问题，并通过激励机制鼓励节点参与。


<details>
  <summary>Details</summary>
Motivation: 区块链网络的互操作性已有进展，但初始发现仍未被解决，本文旨在填补这一空白。

Method: 提出去中心化的区块链网络发现架构，引入资产和服务发现机制，并设计激励机制。

Result: 在Substrate框架中实现和评估，系统可处理13万并发请求，中位响应时间为5.5毫秒，且具备扩展性。

Conclusion: 该架构展示了去中心化网络发现的可行性和高效性，为区块链互操作性提供了新方向。

Abstract: Web3 technologies have experienced unprecedented growth in the last decade,
achieving widespread adoption. As various blockchain networks continue to
evolve, we are on the cusp of a paradigm shift in which they could provide
services traditionally offered by the Internet, but in a decentralized manner,
marking the emergence of the Internet of Blockchains. While significant
progress has been achieved in enabling interoperability between blockchain
networks, existing solutions often assume that networks are already mutually
aware. This reveals a critical gap: the initial discovery of blockchain
networks remains largely unaddressed. This paper proposes a decentralized
architecture for blockchain network discovery that operates independently of
any centralized authority. We also introduce a mechanism for discovering assets
and services within a blockchain from external networks. Given the
decentralized nature of the proposed discovery architecture, we design an
incentive mechanism to encourage nodes to actively participate in maintaining
the discovery network. The proposed architecture implemented and evaluated,
using the Substrate framework, demonstrates its resilience and scalability,
effectively handling up to 130,000 concurrent requests under the tested network
configurations, with a median response time of 5.5 milliseconds, demonstrating
the ability to scale its processing capacity further by increasing its network
size.

</details>


### [252] [JANUS: Resilient and Adaptive Data Transmission for Enabling Timely and Efficient Cross-Facility Scientific Workflows](https://arxiv.org/abs/2506.17084)
*Vladislav Esaulov,Jieyang Chen,Norbert Podhorszki,Fred Suter,Scott Klasky,Anu G Bourgeois,Lipeng Wan*

Main category: cs.DC

TL;DR: JANUS是一种用于跨设施科学工作流的弹性自适应数据传输方法，结合UDP、纠删码和有损压缩，显著提高了传输效率。


<details>
  <summary>Details</summary>
Motivation: 现代科学中，跨设施工作流的数据传输面临带宽压力、TCP重传和传统容错方法的高开销问题。

Method: JANUS采用UDP协议，集成纠删码和有损压缩，动态调整编码参数以适应网络条件。

Result: 实验表明，JANUS在保持数据保真度的同时显著提升了传输效率。

Conclusion: JANUS为大规模科学数据传输提供了一种高效且灵活的解决方案。

Abstract: In modern science, the growing complexity of large-scale projects has
increased reliance on cross-facility workflows, where institutions share
resources and expertise to accelerate discovery. These workflows often involve
transferring massive data over wide-area networks. While high-speed networks
like ESnet and data transfer services like Globus have improved data mobility,
challenges remain. Large data volumes can strain bandwidth, TCP suffers from
retransmissions due to packet loss, and traditional fault-tolerance methods
like erasure coding introduce significant overhead.
  This paper presents JANUS, a resilient and adaptive data transmission
approach for cross-facility scientific workflows. JANUS uses UDP, integrates
erasure coding for fault tolerance, and applies error-bounded lossy compression
to reduce overhead. This design enables users to balance transmission time and
accuracy based on specific needs. JANUS also adapts coding parameters to
real-time network conditions and uses optimization models to determine ideal
configurations. Experiments show that JANUS significantly improves data
transfer efficiency while preserving fidelity.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [253] [HybridRAG-based LLM Agents for Low-Carbon Optimization in Low-Altitude Economy Networks](https://arxiv.org/abs/2506.15947)
*Jinbo Wen,Cheng Su,Jiawen Kang,Jiangtian Nie,Yang Zhang,Jianhang Tang,Dusit Niyato,Chau Yuen*

Main category: cs.NI

TL;DR: 论文提出了一种基于检索增强生成（RAG）的大型语言模型（LLM）代理框架HybridRAG，用于低空经济网络（LAENets）中的多无人机辅助移动边缘计算（MEC）网络的低碳优化问题。通过结合KeywordRAG、VectorRAG和GraphRAG，HybridRAG能高效检索专家数据库信息并生成更准确的优化问题。此外，论文还提出了R²DSAC算法来解决多目标优化问题，并通过动态屏蔽不重要神经元减少碳排放。


<details>
  <summary>Details</summary>
Motivation: 低空经济网络（LAENets）需要满足低延迟和高计算需求，而多无人机辅助MEC网络的低碳优化面临多维无人机建模复杂性和多目标耦合优化的挑战。

Method: 论文提出HybridRAG框架，结合KeywordRAG、VectorRAG和GraphRAG，提升LLM代理的检索和生成能力；并设计R²DSAC算法，结合扩散熵正则化和动作熵正则化，优化多目标问题。

Result: 仿真结果表明，HybridRAG框架和R²DSAC算法在低碳优化问题上具有高效性和可靠性。

Conclusion: HybridRAG和R²DSAC为LAENets中的多无人机辅助MEC网络提供了一种有效的低碳优化解决方案。

Abstract: Low-Altitude Economy Networks (LAENets) are emerging as a promising paradigm
to support various low-altitude services through integrated air-ground
infrastructure. To satisfy low-latency and high-computation demands, the
integration of Unmanned Aerial Vehicles (UAVs) with Mobile Edge Computing (MEC)
systems plays a vital role, which offloads computing tasks from terminal
devices to nearby UAVs, enabling flexible and resilient service provisions for
ground users. To promote the development of LAENets, it is significant to
achieve low-carbon multi-UAV-assisted MEC networks. However, several challenges
hinder this implementation, including the complexity of multi-dimensional UAV
modeling and the difficulty of multi-objective coupled optimization. To this
end, this paper proposes a novel Retrieval Augmented Generation (RAG)-based
Large Language Model (LLM) agent framework for model formulation. Specifically,
we develop HybridRAG by combining KeywordRAG, VectorRAG, and GraphRAG,
empowering LLM agents to efficiently retrieve structural information from
expert databases and generate more accurate optimization problems compared with
traditional RAG-based LLM agents. After customizing carbon emission
optimization problems for multi-UAV-assisted MEC networks, we propose a Double
Regularization Diffusion-enhanced Soft Actor-Critic (R\textsuperscript{2}DSAC)
algorithm to solve the formulated multi-objective optimization problem. The
R\textsuperscript{2}DSAC algorithm incorporates diffusion entropy
regularization and action entropy regularization to improve the performance of
the diffusion policy. Furthermore, we dynamically mask unimportant neurons in
the actor network to reduce the carbon emissions associated with model
training. Simulation results demonstrate the effectiveness and reliability of
the proposed HybridRAG-based LLM agent framework and the
R\textsuperscript{2}DSAC algorithm.

</details>


### [254] [LoRaIN: A Constructive Interference-Assisted Reliable and Energy-Efficient LoRa Indoor Network](https://arxiv.org/abs/2506.16409)
*Mahbubur Rahman,Abusayeed Saifullah*

Main category: cs.NI

TL;DR: LoRaIN是一种新的链路层协议，旨在提升室内LoRa网络的可靠性和能效。


<details>
  <summary>Details</summary>
Motivation: 现有研究对室内LoRa性能分析不足，尤其是可靠性和能效方面。

Method: 提出LoRaIN协议，通过构造性干扰和中继确认机制提升性能。

Result: 实验表明，使用15%的终端设备作为中继节点，可靠性从62%提升至95%，能效提高2.5倍。

Conclusion: LoRaIN是首个显著提升室内LoRa网络可靠性和能效的协议。

Abstract: LoRa is a promising communication technology for enabling the next-generation
indoor Internet of Things applications. Very few studies, however, have
analyzed its performance indoors. Besides, these indoor studies investigate
mostly the RSSI and SNR of the received packets at the gateway, which, as we
show, may not unfold the poor performance of LoRa and its MAC protocol,
LoRaWAN, indoors in terms of reliability and energy-efficiency. In this paper,
we extensively evaluate the performance of LoRaWAN indoors and then use the key
insights to boost its reliability and energy-efficiency by proposing LoRaIN,
LoRa Indoor Network, a new link-layer protocol that can be effectively used for
indoor deployments. The approach to boosting the reliability and energy
efficiency in LoRaIN is underpinned by enabling constructive interference with
specific timing requirements analyzed both empirically and mathematically for
different pairs of channel bandwidth and spreading factor and relaying precious
acknowledgments to the end-devices with the assistance of several booster
nodes. The booster nodes do not need any special capability and can be a subset
of the LoRa end-devices. To our knowledge, LoRaIN is the first protocol for
boosting reliability and energy-efficiency in indoor LoRa networks. We evaluate
its performance in an indoor testbed consisting of one LoRaWAN gateway and 20
end-devices. Our extensive evaluation shows that when 15% of the end-devices
operate as booster nodes, the reliability at the gateway increases from 62% to
95%, and the end-devices are approximately 2.5x energy-efficient.

</details>


### [255] [Using SRv6 to access Edge Applications in 5G Networks](https://arxiv.org/abs/2506.16808)
*Louis Royer,Emmanuel Lavinal,Emmanuel Chaput*

Main category: cs.NI

TL;DR: 本文探讨了5G及未来网络中多接入边缘计算的资源优化问题，提出使用SRv6技术改进现有边缘资源访问方案。


<details>
  <summary>Details</summary>
Motivation: 随着5G及未来网络中多接入边缘计算的出现，运营商需要优化数据路径并确保资源按策略使用。

Method: 回顾现有边缘资源访问方案，指出其局限性，并提出在5G/边缘架构中使用SRv6技术。

Result: 未明确提及具体实验结果，但提出SRv6作为潜在解决方案。

Conclusion: SRv6技术在5G/边缘架构中具有潜力，可改进现有边缘资源访问方案。

Abstract: With the emergence of Multi-Access Edge Computing in 5G and beyond, it has
become essential for operators to optimize the data path for the end-user while
ensuring resources are used according to their policy. In this paper, we review
existing solutions to access edge resources, underline their limits, and
propose the use of Segment Routing over IPv6 (SRv6) in a 5G/edge architecture.

</details>


### [256] [Minimal Per-Flow Backlog Bounds at an Aggregate FIFO Server under Piecewise-Linear Arrival Curves](https://arxiv.org/abs/2506.16914)
*Lukas Wildberger,Anja Hamscher,Jens B. Schmitt*

Main category: cs.NI

TL;DR: 论文提出了一种针对一般分段线性到达曲线的FIFO服务器残差服务曲线优化方法，以减少积压边界。


<details>
  <summary>Details</summary>
Motivation: 解决FIFO服务器在非线性和多流情况下的性能边界优化问题，特别是针对非简单令牌桶到达曲线的情况。

Method: 通过定义残差服务曲线的自由参数，并利用到达曲线和残差服务曲线的断点计算积压边界，提出了一种高效启发式方法。

Result: 实现了积压边界的最小化，并通过启发式方法在复杂场景中高效找到最优或接近最优的参数。

Conclusion: 该方法显著减少了积压边界，并成功集成到DiscoDNC工具中，验证了其有效性。

Abstract: Network Calculus (NC) is a versatile methodology based on min-plus algebra to
derive worst-case per-flow performance bounds in networked systems with many
concurrent flows. In particular, NC can analyze many scheduling disciplines;
yet, somewhat surprisingly, an aggregate FIFO server is a notoriously hard case
due to its min-plus non-linearity. A resort is to represent the FIFO residual
service by a family of functions with a free parameter instead of just a single
curve. For simple token-bucket arrival curves, literature provides optimal
choices for that free parameter to minimize delay and backlog bounds. In this
paper, we tackle the challenge of more general arrival curves than just token
buckets. In particular, we derive residual service curves resulting in minimal
backlog bounds for general piecewise-linear arrival curves. To that end, we
first show that a backlog bound can always be calculated at a breakpoint of
either the arrival curve of the flow of interest or its residual service curve.
Further, we define a set of curves that characterize the backlog for a fixed
breakpoint, depending on the free parameter of the residual service curve. We
show that the backlog-minimizing residual service curve family parameter
corresponds to the largest intersection of those curves with the arrival curve.
In more complex scenarios finding this largest intersection can become
inefficient as the search space grows in the number of flows. Therefore, we
present an efficient heuristic that finds, in many cases, the optimal parameter
or at least a close conservative approximation. This heuristic is evaluated in
terms of accuracy and execution time. Finally, we utilize these
backlog-minimizing residual service curves to enhance the DiscoDNC tool and
observe considerable reductions in the corresponding backlog bounds.

</details>


### [257] [Client Selection Strategies for Federated Semantic Communications in Heterogeneous IoT Networks](https://arxiv.org/abs/2506.17063)
*Samer Lahoud,Kinda Khawam*

Main category: cs.NI

TL;DR: 本文提出了一种新颖的联邦语义通信框架，用于异构物联网设备间协作训练带宽高效模型，显著减少通信开销并保持重建质量。


<details>
  <summary>Details</summary>
Motivation: 物联网设备激增对带宽受限的无线网络提出了高效数据传输和隐私保护的挑战。

Method: 采用联邦语义通信框架，通过传输语义特征减少通信开销，并设计三种客户端选择策略以应对设备间数据分布差异。

Result: 实验表明，功利选择策略重建质量最高，而比例公平策略在保持性能的同时显著减少参与不平等并提高计算效率。

Conclusion: 联邦语义通信能在异构物联网部署中平衡重建质量、资源效率和公平性，为可持续且隐私保护的边缘智能应用铺平道路。

Abstract: The exponential growth of IoT devices presents critical challenges in
bandwidth-constrained wireless networks, particularly regarding efficient data
transmission and privacy preservation. This paper presents a novel federated
semantic communication (SC) framework that enables collaborative training of
bandwidth-efficient models for image reconstruction across heterogeneous IoT
devices. By leveraging SC principles to transmit only semantic features, our
approach dramatically reduces communication overhead while preserving
reconstruction quality. We address the fundamental challenge of client
selection in federated learning environments where devices exhibit significant
disparities in dataset sizes and data distributions. Our framework implements
three distinct client selection strategies that explore different trade-offs
between system performance and fairness in resource allocation. The system
employs an end-to-end SC architecture with semantic bottlenecks, coupled with a
loss-based aggregation mechanism that naturally adapts to client heterogeneity.
Experimental evaluation on image data demonstrates that while Utilitarian
selection achieves the highest reconstruction quality, Proportional Fairness
maintains competitive performance while significantly reducing participation
inequality and improving computational efficiency. These results establish that
federated SC can successfully balance reconstruction quality, resource
efficiency, and fairness in heterogeneous IoT deployments, paving the way for
sustainable and privacy-preserving edge intelligence applications.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [258] [A System Level Compiler for Massively-Parallel, Spatial, Dataflow Architectures](https://arxiv.org/abs/2506.15875)
*Dirk Van Essendelft,Patrick Wingo,Terry Jordan,Ryan Smith,Wissam Saidi*

Main category: cs.PL

TL;DR: MACH是一种新型编译器，专为大规模并行、空间数据流架构设计，同时支持传统统一内存设备。它通过虚拟机和领域特定语言简化了编译过程。


<details>
  <summary>Details</summary>
Motivation: 解决为空间架构编译的复杂性，提供跨架构的灵活性。

Method: 使用虚拟机概念、领域特定语言和编译器，将高级语言转换为机器特定代码。

Result: 展示了在NumPy密集张量示例中的应用，并成功编译到Wafer Scale Engine。

Conclusion: MACH为复杂架构编译提供了高效灵活的解决方案。

Abstract: We have developed a novel compiler called the Multiple-Architecture Compiler
for Advanced Computing Hardware (MACH) designed specifically for
massively-parallel, spatial, dataflow architectures like the Wafer Scale
Engine. Additionally, MACH can execute code on traditional unified-memory
devices. MACH addresses the complexities in compiling for spatial architectures
through a conceptual Virtual Machine, a flexible domain-specific language, and
a compiler that can lower high-level languages to machine-specific code in
compliance with the Virtual Machine concept. While MACH is designed to be
operable on several architectures and provide the flexibility for several
standard and user-defined data mappings, we introduce the concept with dense
tensor examples from NumPy and show lowering to the Wafer Scale Engine by
targeting Cerebras' hardware specific languages.

</details>


### [259] [WAMI: Compilation to WebAssembly through MLIR without Losing Abstraction](https://arxiv.org/abs/2506.16048)
*Byeongjee Kang,Harsh Desai,Limin Jia,Brandon Lucia*

Main category: cs.PL

TL;DR: 提出了一种基于MLIR的新型Wasm编译流水线，支持高级Wasm特性，性能接近LLVM。


<details>
  <summary>Details</summary>
Motivation: 现有Wasm编译方法缺乏可重用设计或抽象丢失，阻碍高级特性应用。

Method: 设计Wasm方言在MLIR中直接生成高级Wasm代码，避免抽象丢失。

Result: 性能评估显示，新流水线代码性能最多慢7.7%，部分环境下更快。

Conclusion: 新方法为Wasm高级特性提供了模块化和可扩展的编译支持。

Abstract: WebAssembly (Wasm) is a portable bytecode format that serves as a compilation
target for high-level languages, enabling their secure and efficient execution
across diverse platforms, including web browsers and embedded systems. To
improve support for high-level languages without incurring significant code
size or performance overheads, Wasm continuously evolves by integrating
high-level features such as Garbage Collection and Stack Switching. However,
existing compilation approaches either lack reusable design -- requiring
redundant implementation efforts for each language -- or lose abstraction by
lowering high-level constructs into low-level shared representations like LLVM
IR, which hinder the adoption of high-level features. MLIR compiler
infrastructure provides the compilation pipeline with multiple levels of
abstraction, preserving high-level abstractions throughout the compilation
pipeline, yet the current MLIR pipeline relies on the LLVM backend for Wasm
code generation, thereby inheriting LLVM's limitations.
  This paper presents a novel compilation pipeline for Wasm, featuring Wasm
dialects explicitly designed to represent high-level Wasm constructs within
MLIR. Our approach enables direct generation of high-level Wasm code from
corresponding high-level MLIR dialects without losing abstraction, providing a
modular and extensible way to incorporate high-level Wasm features. We
illustrate this extensibility through a case study that leverages Stack
Switching, a recently introduced high-level feature of Wasm. Performance
evaluations on PolyBench benchmarks show that our pipeline, benefiting from
optimizations within the MLIR and Wasm ecosystems, produces code with at most
7.7\% slower, and faster in some execution environments, compared to LLVM-based
compilers.

</details>


### [260] [Low Overhead Allocation Sampling in a Garbage Collected Virtual Machine](https://arxiv.org/abs/2506.16883)
*Christoph Jung,C. F. Bolz-Tereick*

Main category: cs.PL

TL;DR: 论文提出了一种采样分配分析器，集成到PyPy的垃圾回收器中，显著降低了分析开销。


<details>
  <summary>Details</summary>
Motivation: 动态类型语言中分配分析比时间分析更有效，但传统方法效率低下。

Method: 在PyPy虚拟机中集成采样分配分析器，通过垃圾回收器实现低开销。

Result: 采样周期为4MB时，最大时间开销仅为25%。

Conclusion: 该方法在低开销下实现了高效的分配分析。

Abstract: Compared to the more commonly used time-based profiling, allocation profiling
provides an alternate view of the execution of allocation heavy dynamically
typed languages. However, profiling every single allocation in a program is
very inefficient. We present a sampling allocation profiler that is deeply
integrated into the garbage collector of PyPy, a Python virtual machine. This
integration ensures tunable low overhead for the allocation profiler, which we
measure and quantify. Enabling allocation sampling profiling with a sampling
period of 4 MB leads to a maximum time overhead of 25% in our benchmarks, over
un-profiled regular execution.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [261] [How Do Community Smells Influence Self-Admitted Technical Debt in Machine Learning Projects?](https://arxiv.org/abs/2506.15884)
*Shamse Tasnim Cynthia,Nuri Almarimi,Banani Roy*

Main category: cs.SE

TL;DR: 研究了开源机器学习项目中社区异味与自认技术债务（SATD）的关系，发现某些异味与SATD显著相关，并揭示了项目规模对问题演化的影响。


<details>
  <summary>Details</summary>
Motivation: 探索机器学习项目中社区异味与SATD的关系，填补现有研究的空白。

Method: 分析了155个ML项目的发布数据，检测社区异味和SATD，并进行统计分析和演化趋势研究。

Result: 社区异味普遍存在，某些异味（如Radio Silence和Organizational Silos）与SATD显著相关；项目规模影响问题演化。

Conclusion: 早期检测和缓解社区异味对ML项目的长期质量和可持续性至关重要。

Abstract: Community smells reflect poor organizational practices that often lead to
socio-technical issues and the accumulation of Self-Admitted Technical Debt
(SATD). While prior studies have explored these problems in general software
systems, their interplay in machine learning (ML)-based projects remains
largely underexamined. In this study, we investigated the prevalence of
community smells and their relationship with SATD in open-source ML projects,
analyzing data at the release level. First, we examined the prevalence of ten
community smell types across the releases of 155 ML-based systems and found
that community smells are widespread, exhibiting distinct distribution patterns
across small, medium, and large projects. Second, we detected SATD at the
release level and applied statistical analysis to examine its correlation with
community smells. Our results showed that certain smells, such as Radio Silence
and Organizational Silos, are strongly correlated with higher SATD occurrences.
Third, we considered the six identified types of SATD to determine which
community smells are most associated with each debt category. Our analysis
revealed authority- and communication-related smells often co-occur with
persistent code and design debt. Finally, we analyzed how the community smells
and SATD evolve over the releases, uncovering project size-dependent trends and
shared trajectories. Our findings emphasize the importance of early detection
and mitigation of socio-technical issues to maintain the long-term quality and
sustainability of ML-based systems.

</details>


### [262] [Regression Testing Optimization for ROS-based Autonomous Systems: A Comprehensive Review of Techniques](https://arxiv.org/abs/2506.16101)
*Yupeng Jiang,Shuaiyi Sun,Xi Zheng*

Main category: cs.SE

TL;DR: 本文综述了针对ROS自主系统（ROSAS）的回归测试优化技术，分析了122项研究，提出了分类法，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统回归测试技术难以应对ROSAS的动态性、非确定性及复杂架构，相关优化研究尚不充分。

Method: 系统综述了122项研究，分类为测试用例优先级、最小化和选择方法，并提出了结构化分类法。

Result: 总结了ROSAS回归测试的主要挑战及现有方法的局限性，提出了未来研究方向。

Conclusion: 本文为ROSAS回归测试优化提供了基础参考和实践路线，推动了该领域的发展。

Abstract: Regression testing plays a critical role in maintaining software reliability,
particularly for ROS-based autonomous systems (ROSAS), which frequently undergo
continuous integration and iterative development. However, conventional
regression testing techniques face significant challenges when applied to
autonomous systems due to their dynamic and non-deterministic behaviors,
complex multi-modal sensor data, asynchronous distributed architectures, and
stringent safety and real-time constraints. Although numerous studies have
explored test optimization in traditional software contexts, regression testing
optimization specifically for ROSAS remains largely unexplored. To address this
gap, we present the first comprehensive survey systematically reviewing
regression testing optimization techniques tailored for ROSAS. We analyze and
categorize 122 representative studies into regression test case prioritization,
minimization, and selection methods. A structured taxonomy is introduced to
clearly illustrate their applicability and limitations within ROSAS contexts.
Furthermore, we highlight major challenges specific to regression testing for
ROSAS, including effectively prioritizing tests in response to frequent system
modifications, efficiently minimizing redundant tests, and difficulty in
accurately selecting impacted test cases. Finally, we propose research insights
and identify promising future directions, such as leveraging frame-to-vector
coverage metrics, multi-source foundation models, and neurosymbolic reasoning
to enhance regression testing efficiency and effectiveness. This survey
provides a foundational reference and practical roadmap for advancing the
state-of-the-art in regression testing optimization for ROSAS.

</details>


### [263] [Seeing is Fixing: Cross-Modal Reasoning with Multimodal LLMs for Visual Software Issue Fixing](https://arxiv.org/abs/2506.16136)
*Kai Huang,Jian Zhang,Xiaofei Xie,Chunyang Chen*

Main category: cs.SE

TL;DR: GUIRepair是一种跨模态推理方法，通过理解和利用视觉信息解决多模态问题，显著优于现有APR系统。


<details>
  <summary>Details</summary>
Motivation: 现有APR系统在多模态问题（如SWE-bench M）中表现不佳，因无法有效利用视觉信息。

Method: GUIRepair结合Image2Code和Code2Image，分别用于故障理解和补丁验证。

Result: 在SWE-bench M上，GUIRepair表现优异，使用GPT-4o和o4-mini分别解决157和175个实例，显著优于基线。

Conclusion: GUIRepair通过跨模态推理成功解决了多模态问题，验证了视觉信息的重要性。

Abstract: Large language model-(LLM) based automated program repair (APR) techniques
have shown promising results in resolving real-world GitHub issue tasks.
Existing APR systems are primarily evaluated in unimodal settings (e.g.,
SWE-bench). However, these autonomous systems struggle to resolve multimodal
problem scenarios (e.g., SWE-bench M) due to limitations in interpreting and
leveraging visual information. In multimodal scenarios, LLMs need to rely on
visual information in the graphical user interface (GUI) to understand bugs and
generate fixes. To bridge this gap, we propose GUIRepair, a cross-modal
reasoning approach for resolving multimodal issue scenarios by understanding
and capturing visual information. Specifically, GUIRepair integrates two key
components, Image2Code and Code2Image, to enhance fault comprehension and patch
validation. Image2Code extracts relevant project documents based on the issue
report, then applies this domain knowledge to generate the reproduced code
responsible for the visual symptoms, effectively translating GUI images into
executable context for better fault comprehension. Code2Image replays the
visual issue scenario using the reproduced code and captures GUI renderings of
the patched program to assess whether the fix visually resolves the issue,
providing feedback for patch validation. We evaluate GUIRepair on SWE-bench M,
and the approach demonstrates significant effectiveness. When utilizing GPT-4o
as the base model, GUIRepair solves 157 instances, outperforming the best
open-source baseline by 26 instances. Furthermore, when using o4-mini as the
base model, GUIRepair can achieve even better results and solve 175 instances,
outperforming the top commercial system by 22 instances. This emphasizes the
success of our new perspective on incorporating cross-modal reasoning by
understanding and capturing visual information to resolve multimodal issues.

</details>


### [264] [The Technical Debt Gamble: A Case Study on Technical Debt in a Large-Scale Industrial Microservice Architecture](https://arxiv.org/abs/2506.16214)
*Klara Borowa,Andrzej Ratkowski,Roberto Verdecchia*

Main category: cs.SE

TL;DR: 研究探讨大规模微服务系统中技术债务（TD）的表现形式，发现静态代码分析是有效的TD发现入口，沟通不足和组织架构不匹配会加剧TD，并提出管理策略。


<details>
  <summary>Details</summary>
Motivation: 微服务架构虽承诺高维护性和可演进性，但技术债务对其质量属性构成显著威胁，目前缺乏大规模研究。

Method: 采用混合方法案例研究，包括静态代码分析和定性访谈，研究对象为包含100多个微服务的工业系统。

Result: 发现静态代码分析是高效TD发现入口，沟通不足和组织架构不匹配加剧TD，微服务存在快速积累和解决TD的现象。

Conclusion: 提出适用于微服务架构的技术债务管理策略。

Abstract: Microservice architectures provide an intuitive promise of high
maintainability and evolvability due to loose coupling. However, these quality
attributes are notably vulnerable to technical debt (TD). Few studies address
TD in microservice systems, particularly on a large scale. This research
explores how TD manifests in a large-scale microservice-based industrial
system. The research is based on a mixed-method case study of a project
including over 100 microservices and serving over 15k locations. Results are
collected via a quantitative method based static code analyzers combined with
qualitative insights derived from a focus group discussion with the development
team and a follow-up interview with the lead architect of the case study
system. Results show that (1) simple static source code analysis can be an
efficient and effective entry point for holistic TD discovery, (2) inadequate
communication significantly contributes to TD, (3) misalignment between
architectural and organizational structures can exacerbate TD accumulation, (4)
microservices can rapidly cycle through TD accumulation and resolution, a
phenomenon referred to as "microservice architecture technical debt gamble".
Finally, we identify a set of fitting strategies for TD management in
microservice architectures.

</details>


### [265] [Evaluating the Use of LLMs for Documentation to Code Traceability](https://arxiv.org/abs/2506.16440)
*Ebube Alor,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 论文评估了LLMs（如Claude 3.5 Sonnet、GPT-4o和o3-mini）在文档与代码间建立追溯链接的能力，发现其性能优于传统方法，但存在局限性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在自动化文档与代码追溯中的潜力，填补现有研究的空白。

Method: 通过系统实验评估LLMs在追溯链接识别、关系解释质量和多步链重构三个关键能力上的表现，使用两个开源项目的数据集。

Result: 最佳LLM的F1分数达79.4%和80.4%，远超基线方法；关系解释的完全正确率为42.9%-71.1%，但部分准确率超97%。

Conclusion: LLMs是强大的追溯发现工具，但需结合人工干预，并需进一步研究其错误模式。

Abstract: Large Language Models (LLMs) offer new potential for automating
documentation-to-code traceability, yet their capabilities remain
underexplored. We present a comprehensive evaluation of LLMs (Claude 3.5
Sonnet, GPT-4o, and o3-mini) in establishing trace links between various
software documentation (including API references and user guides) and source
code. We create two novel datasets from two open-source projects (Unity Catalog
and Crawl4AI). Through systematic experiments, we assess three key
capabilities: (1) trace link identification accuracy, (2) relationship
explanation quality, and (3) multi-step chain reconstruction. Results show that
the best-performing LLM achieves F1-scores of 79.4% and 80.4% across the two
datasets, substantially outperforming our baselines (TF-IDF, BM25, and
CodeBERT). While fully correct relationship explanations range from 42.9% to
71.1%, partial accuracy exceeds 97%, indicating that fundamental connections
are rarely missed. For multi-step chains, LLMs maintain high endpoint accuracy
but vary in capturing precise intermediate links. Error analysis reveals that
many false positives stem from naming-based assumptions, phantom links, or
overgeneralization of architectural patterns. We demonstrate that task-framing,
such as a one-to-many matching strategy, is critical for performance. These
findings position LLMs as powerful assistants for trace discovery, but their
limitations could necessitate human-in-the-loop tool design and highlight
specific error patterns for future research.

</details>


### [266] [Understanding the Challenges and Promises of Developing Generative AI Apps: An Empirical Study](https://arxiv.org/abs/2506.16453)
*Buthayna AlMulla,Maram Assi,Safwat Hassan*

Main category: cs.SE

TL;DR: 论文通过分析676,066条Gen-AI应用的用户评论，提出了一种四阶段方法SARA，利用LLM技术提取用户见解，并识别了10个热门话题及其演变趋势。


<details>
  <summary>Details</summary>
Motivation: 研究Gen-AI应用在实际使用中用户的感知和评价，填补相关研究空白。

Method: 采用SARA方法（选择、获取、精炼和分析），结合LLM技术进行主题提取和评论分析。

Result: LLM在主题提取中达到91%准确率，识别出10个热门话题（如AI性能、内容质量等），并分析了其时间演变。

Conclusion: 研究为开发者和研究人员提供了关于用户期望和Gen-AI应用发展的实用建议。

Abstract: The release of ChatGPT in 2022 triggered a rapid surge in generative
artificial intelligence mobile apps (i.e., Gen-AI apps). Despite widespread
adoption, little is known about how end users perceive and evaluate these
Gen-AI functionalities in practice. In this work, we conduct a user-centered
analysis of 676,066 reviews from 173 Gen-AI apps on the Google Play Store. We
introduce a four-phase methodology, SARA (Selection, Acquisition, Refinement,
and Analysis), that enables the systematic extraction of user insights using
prompt-based LLM techniques. First, we demonstrate the reliability of LLMs in
topic extraction, achieving 91% accuracy through five-shot prompting and
non-informative review filtering. Then, we apply this method to the informative
reviews, identify the top 10 user-discussed topics (e.g., AI Performance,
Content Quality, and Content Policy & Censorship) and analyze the key
challenges and emerging opportunities. Finally, we examine how these topics
evolve over time, offering insight into shifting user expectations and
engagement patterns with Gen-AI apps. Based on our findings and observations,
we present actionable implications for developers and researchers.

</details>


### [267] [Scaling GR(1) Synthesis via a Compositional Framework for LTL Discrete Event Control](https://arxiv.org/abs/2506.16557)
*Hernán Gagliardi,Victor Braberman,Sebastian Uchitel*

Main category: cs.SE

TL;DR: 提出了一种基于模块化结构的控制器合成方法，用于离散事件系统，通过局部求解和抽象化减少状态爆炸问题，实现高效合成。


<details>
  <summary>Details</summary>
Motivation: 解决传统单体合成方法因状态爆炸问题难以处理大规模系统的问题。

Method: 利用模块化结构和观测合成等价性，分步构建最大允许安全控制器，并通过并行运行确保LTL目标。

Result: 在MTSA工具中实现，能够处理比单体方法大1000倍的系统。

Conclusion: 模块化方法显著提升了合成效率，适用于大规模离散事件系统。

Abstract: We present a compositional approach to controller synthesis of discrete event
system controllers with linear temporal logic (LTL) goals. We exploit the
modular structure of the plant to be controlled, given as a set of labelled
transition systems (LTS), to mitigate state explosion that monolithic
approaches to synthesis are prone to. Maximally permissive safe controllers are
iteratively built for subsets of the plant LTSs by solving weaker control
problems. Observational synthesis equivalence is used to reduce the size of the
controlled subset of the plant by abstracting away local events. The result of
synthesis is also compositional, a set of controllers that when run in parallel
ensure the LTL goal. We implement synthesis in the MTSA tool for an expressive
subset of LTL, GR(1), and show it computes solutions to that can be up to 1000
times larger than those that the monolithic approach can solve.

</details>


### [268] [AI-Driven Tools in Modern Software Quality Assurance: An Assessment of Benefits, Challenges, and Future Directions](https://arxiv.org/abs/2506.16586)
*Ihor Pysmennyi,Roman Kyslyi,Kyrylo Kleshch*

Main category: cs.SE

TL;DR: 研究探讨了将AI工具集成到现代分布式软件质量保证（QA）流程中的潜力与挑战，通过实验验证了其有效性，但也指出了生成语义一致性和可解释性等问题。


<details>
  <summary>Details</summary>
Motivation: 传统QA方法难以应对现代软件系统的复杂性、规模和快速迭代，资源有限导致质量成本高昂，因此研究AI工具在QA中的应用。

Method: 综合分析了AI工具在验证和验证过程中的应用，包括测试分析、测试用例生成等，并通过企业应用的端到端回归测试验证。

Result: 生成的测试用例仅8.3%不稳定，显示AI工具潜力，但也发现语义一致性、可解释性等挑战。

Conclusion: AI在QA中具有变革潜力，但需战略性地实施，并开发验证方法以克服局限性。

Abstract: Traditional quality assurance (QA) methods face significant challenges in
addressing the complexity, scale, and rapid iteration cycles of modern software
systems and are strained by limited resources available, leading to substantial
costs associated with poor quality. The object of this research is the Quality
Assurance processes for modern distributed software applications. The subject
of the research is the assessment of the benefits, challenges, and prospects of
integrating modern AI-oriented tools into quality assurance processes. We
performed comprehensive analysis of implications on both verification and
validation processes covering exploratory test analyses, equivalence
partitioning and boundary analyses, metamorphic testing, finding
inconsistencies in acceptance criteria (AC), static analyses, test case
generation, unit test generation, test suit optimization and assessment, end to
end scenario execution. End to end regression of sample enterprise application
utilizing AI-agents over generated test scenarios was implemented as a proof of
concept highlighting practical use of the study. The results, with only 8.3%
flaky executions of generated test cases, indicate significant potential for
the proposed approaches. However, the study also identified substantial
challenges for practical adoption concerning generation of semantically
identical coverage, "black box" nature and lack of explainability from
state-of-the-art Large Language Models (LLMs), the tendency to correct mutated
test cases to match expected results, underscoring the necessity for thorough
verification of both generated artifacts and test execution results. The
research demonstrates AI's transformative potential for QA but highlights the
importance of a strategic approach to implementing these technologies,
considering the identified limitations and the need for developing appropriate
verification methodologies.

</details>


### [269] [LLM-based Satisfiability Checking of String Requirements by Consistent Data and Checker Generation](https://arxiv.org/abs/2506.16639)
*Boqi Chen,Aren A. Babikian,Shuzhao Feng,Dániel Varró,Gunter Mussbacher*

Main category: cs.SE

TL;DR: 论文提出了一种混合方法，利用大语言模型（LLMs）验证自然语言字符串需求的可满足性，并生成检查器以提高准确性。


<details>
  <summary>Details</summary>
Motivation: 由于软件系统对字符串操作的依赖，验证自然语言需求的可满足性具有挑战性，现有方法（如SMT求解器）存在理论限制且需要大量手动工作。

Method: 结合LLMs生成可满足性结果及检查器（SMT和Python），验证其正确性。

Result: 实验表明，LLMs能有效生成检查器，显著提高字符串生成成功率和F1分数。

Conclusion: 混合方法通过LLMs生成检查器，显著提升了自然语言字符串需求的验证效果。

Abstract: Requirements over strings, commonly represented using natural language (NL),
are particularly relevant for software systems due to their heavy reliance on
string data manipulation. While individual requirements can usually be analyzed
manually, verifying properties (e.g., satisfiability) over sets of NL
requirements is particularly challenging. Formal approaches (e.g., SMT solvers)
may efficiently verify such properties, but are known to have theoretical
limitations. Additionally, the translation of NL requirements into formal
constraints typically requires significant manual effort. Recently, large
language models (LLMs) have emerged as an alternative approach for formal
reasoning tasks, but their effectiveness in verifying requirements over strings
is less studied. In this paper, we introduce a hybrid approach that verifies
the satisfiability of NL requirements over strings by using LLMs (1) to derive
a satisfiability outcome (and a consistent string, if possible), and (2) to
generate declarative (i.e., SMT) and imperative (i.e., Python) checkers, used
to validate the correctness of (1). In our experiments, we assess the
performance of four LLMs. Results show that LLMs effectively translate natural
language into checkers, even achieving perfect testing accuracy for
Python-based checkers. These checkers substantially help LLMs in generating a
consistent string and accurately identifying unsatisfiable requirements,
leading to more than doubled generation success rate and F1-score in certain
cases compared to baselines without generated checkers.

</details>


### [270] [SemAgent: A Semantics Aware Program Repair Agent](https://arxiv.org/abs/2506.16650)
*Anvith Pabba,Alex Mathai,Anindya Chakraborty,Baishakhi Ray*

Main category: cs.SE

TL;DR: 论文提出SemAgent，一种基于工作流的方法，通过结合问题、代码和执行语义生成更完整的补丁，解决了现有APR系统过度局部化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有APR系统在修复问题时倾向于局部化处理，缺乏对问题、代码和执行语义的深入理解，导致补丁过拟合。

Method: SemAgent采用四步流程：利用执行语义获取上下文、通过抽象理解问题语义、在抽象上下文中隔离代码语义，并通过两阶段架构（修复阶段和审查阶段）生成补丁。

Result: 在SWEBench-Lite基准测试中，SemAgent的解决率为44.66%，优于其他工作流方法，并在多行推理和边缘案例处理上表现突出。

Conclusion: 结合语义理解的APR方法能生成更鲁棒和语义一致的修复补丁。

Abstract: Large Language Models (LLMs) have shown impressive capabilities in downstream
software engineering tasks such as Automated Program Repair (APR). In
particular, there has been a lot of research on repository-level
issue-resolution benchmarks such as SWE-Bench. Although there has been
significant progress on this topic, we notice that in the process of solving
such issues, existing agentic systems tend to hyper-localize on immediately
suspicious lines of code and fix them in isolation, without a deeper
understanding of the issue semantics, code semantics, or execution semantics.
Consequently, many existing systems generate patches that overfit to the user
issue, even when a more general fix is preferable. To address this limitation,
we introduce SemAgent, a novel workflow-based procedure that leverages issue,
code, and execution semantics to generate patches that are complete -
identifying and fixing all lines relevant to the issue. We achieve this through
a novel pipeline that (a) leverages execution semantics to retrieve relevant
context, (b) comprehends issue-semantics via generalized abstraction, (c)
isolates code-semantics within the context of this abstraction, and (d)
leverages this understanding in a two-stage architecture: a repair stage that
proposes fine-grained fixes, followed by a reviewer stage that filters relevant
fixes based on the inferred issue-semantics. Our evaluations show that our
methodology achieves a solve rate of 44.66% on the SWEBench-Lite benchmark
beating all other workflow-based approaches, and an absolute improvement of
7.66% compared to our baseline, which lacks such deep semantic understanding.
We note that our approach performs particularly well on issues requiring
multi-line reasoning (and editing) and edge-case handling, suggesting that
incorporating issue and code semantics into APR pipelines can lead to robust
and semantically consistent repairs.

</details>


### [271] [LLMs in Coding and their Impact on the Commercial Software Engineering Landscape](https://arxiv.org/abs/2506.16653)
*Vladislav Belozerov,Peter J Barclay,Askhan Sami*

Main category: cs.SE

TL;DR: 大型语言模型编码工具已成为主流，但存在隐私泄露、安全漏洞和模型附和错误观点等问题，需加强审查和测试以确保安全与准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型编码工具在提升开发效率的同时带来的隐私泄露、安全漏洞和模型附和错误观点等新风险。

Method: 提出企业应对每行AI生成的代码进行标记和审查，将提示和输出限制在私有或本地部署中，遵守安全法规，并增加测试以检测附和性回答。

Result: 研究发现10%的真实提示泄露隐私数据，42%的生成代码片段隐藏安全漏洞，模型还存在附和错误观点的倾向。

Conclusion: 企业需在提升开发速度的同时，通过严格审查和测试确保安全与准确性。

Abstract: Large-language-model coding tools are now mainstream in software engineering.
But as these same tools move human effort up the development stack, they
present fresh dangers: 10% of real prompts leak private data, 42% of generated
snippets hide security flaws, and the models can even ``agree'' with wrong
ideas, a trait called sycophancy. We argue that firms must tag and review every
AI-generated line of code, keep prompts and outputs inside private or
on-premises deployments, obey emerging safety regulations, and add tests that
catch sycophantic answers -- so they can gain speed without losing security and
accuracy.

</details>


### [272] [Accountability of Robust and Reliable AI-Enabled Systems: A Preliminary Study and Roadmap](https://arxiv.org/abs/2506.16831)
*Filippo Scaramuzza,Damian A. Tamburri,Willem-Jan van den Heuvel*

Main category: cs.SE

TL;DR: 论文探讨了AI系统的稳健性、可靠性及问责制，强调其在构建可信AI中的重要性，并通过案例研究提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统的稳健性和可靠性，确保其在实际应用中的安全性和有效性，同时强调问责制的重要性。

Method: 通过文献综述和案例研究，分析现有挑战和方法，提出创新测试解决方案。

Result: 研究发现问责制对建立信任至关重要，并指出了当前研究中的空白。

Conclusion: 稳健性、可靠性和问责制是未来可信AI系统发展的关键领域。

Abstract: This vision paper presents initial research on assessing the robustness and
reliability of AI-enabled systems, and key factors in ensuring their safety and
effectiveness in practical applications, including a focus on accountability.
By exploring evolving definitions of these concepts and reviewing current
literature, the study highlights major challenges and approaches in the field.
A case study is used to illustrate real-world applications, emphasizing the
need for innovative testing solutions. The incorporation of accountability is
crucial for building trust and ensuring responsible AI development. The paper
outlines potential future research directions and identifies existing gaps,
positioning robustness, reliability, and accountability as vital areas for the
development of trustworthy AI systems of the future.

</details>


### [273] [Revolutionizing Validation and Verification: Explainable Testing Methodologies for Intelligent Automotive Decision-Making Systems](https://arxiv.org/abs/2506.16876)
*Halit Eris,Stefan Wagner*

Main category: cs.SE

TL;DR: 论文提出了一种将可解释性、透明度和可解释性集成到自动驾驶系统验证与验证（V&V）中的方法，旨在提高效率、减少资源消耗并增强用户信任。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的复杂决策模型和多模态输入使得验证与验证（V&V）成为安全和可靠性的关键，但现有手动测试方法效率低下且劳动密集。

Method: 通过文献综述和利益相关者输入细化V&V需求，利用大型语言模型（LLMs）生成可解释的测试场景，并在仿真环境中实现实时验证。

Result: 框架包括测试预言、解释生成和测试聊天机器人，计划通过实证研究评估诊断效率和透明度的改进。

Conclusion: 目标是优化V&V流程，减少资源消耗，并增强用户对自动驾驶技术的信任。

Abstract: Autonomous Driving Systems (ADS) use complex decision-making (DM) models with
multimodal sensory inputs, making rigorous validation and verification (V&V)
essential for safety and reliability. These models pose challenges in
diagnosing failures, tracing anomalies, and maintaining transparency, with
current manual testing methods being inefficient and labor-intensive. This
vision paper presents a methodology that integrates explainability,
transparency, and interpretability into V&V processes. We propose refining V&V
requirements through literature reviews and stakeholder input, generating
explainable test scenarios via large language models (LLMs), and enabling
real-time validation in simulation environments. Our framework includes test
oracle, explanation generation, and a test chatbot, with empirical studies
planned to evaluate improvements in diagnostic efficiency and transparency. Our
goal is to streamline V&V, reduce resources, and build user trust in autonomous
technologies.

</details>


### [274] [Quantum Optimization for Software Engineering: A Survey](https://arxiv.org/abs/2506.16878)
*Man Zhang,Yuechen Li,Tao Yue,Kai-Yuan Cai*

Main category: cs.SE

TL;DR: 本文通过系统性文献综述（SLR）研究了量子或量子启发算法在解决经典软件工程（SE）优化问题中的应用，分析了77项研究，揭示了研究热点与空白。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统及其工程过程的复杂性增加，需要创新解决方案，量子计算在优化领域的进展为SE优化提供了新思路。

Method: 通过系统性搜索六个数字数据库，筛选2083篇文献，最终选取77项主要研究进行分析。

Result: 研究发现研究集中在SE操作和软件测试领域，其他SE活动存在显著空白，并发现部分研究发表在非传统SE平台上。

Conclusion: 本研究为SBSE社区提供了全面的研究概览，助力其利用量子技术进步应对下一代SE挑战。

Abstract: Quantum computing, particularly in the area of quantum optimization, is
steadily progressing toward practical applications, supported by an expanding
range of hardware platforms and simulators. While Software Engineering (SE)
optimization has a strong foundation, which is exemplified by the active
Search-Based Software Engineering (SBSE) community and numerous classical
optimization methods, the growing complexity of modern software systems and
their engineering processes demands innovative solutions. This Systematic
Literature Review (SLR) focuses specifically on studying the literature that
applies quantum or quantum-inspired algorithms to solve classical SE
optimization problems. We examine 77 primary studies selected from an initial
pool of 2083 publications obtained through systematic searches of six digital
databases using carefully crafted search strings. Our findings reveal
concentrated research efforts in areas such as SE operations and software
testing, while exposing significant gaps across other SE activities.
Additionally, the SLR uncovers relevant works published outside traditional SE
venues, underscoring the necessity of this comprehensive review. Overall, our
study provides a broad overview of the research landscape, empowering the SBSE
community to leverage quantum advancements in addressing next-generation SE
challenges.

</details>


### [275] [Identifying Explanation Needs: Towards a Catalog of User-based Indicators](https://arxiv.org/abs/2506.16997)
*Hannah Deters,Laura Reinhardt,Jakob Droste,Martin Obaidi,Kurt Schneider*

Main category: cs.SE

TL;DR: 论文探讨了在复杂软件系统中如何通过用户行为和系统事件指标实时识别解释需求，并通过在线研究收集了相关指标。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统日益复杂，解释性成为重要质量指标，但识别个体解释需求存在偏差挑战。

Method: 通过在线研究收集自报告指标，包括用户行为、系统事件及情感/生理反应。

Result: 整理出17个用户行为指标、8个系统事件指标和14个情感/生理指标，并分析其与解释需求的关系。

Conclusion: 这些指标可用于原型设计或已部署应用的实时解释触发，提升系统解释性。

Abstract: In today's digitalized world, where software systems are becoming
increasingly ubiquitous and complex, the quality aspect of explainability is
gaining relevance. A major challenge in achieving adequate explanations is the
elicitation of individual explanation needs, as it may be subject to severe
hypothetical or confirmation biases. To address these challenges, we aim to
establish user-based indicators concerning user behavior or system events that
can be captured at runtime to determine when a need for explanations arises. In
this work, we conducted explorative research in form of an online study to
collect self-reported indicators that could indicate a need for explanation. We
compiled a catalog containing 17 relevant indicators concerning user behavior,
8 indicators concerning system events and 14 indicators concerning emotional
states or physical reactions. We also analyze the relationships between these
indicators and different types of need for explanation. The established
indicators can be used in the elicitation process through prototypes, as well
as after publication to gather requirements from already deployed applications
using telemetry and usage data. Moreover, these indicators can be used to
trigger explanations at appropriate moments during the runtime.

</details>


### [276] [Behavior Driven Development for 3D Games](https://arxiv.org/abs/2506.17057)
*Fernando Pastor Ricós,Beatriz Marín,I. S. W. B. Prasetya,Tanja E. J. Vos,Joseph Davidson,Karel Hovorka*

Main category: cs.SE

TL;DR: iv4XR框架通过集成BDD方法，简化了3D游戏自动化测试，提升了开发与测试协作效率，并扩展了框架功能以支持长时测试场景。


<details>
  <summary>Details</summary>
Motivation: 解决3D游戏测试的复杂性和技术门槛问题，促进开发与测试的无缝协作。

Method: 将行为驱动开发（BDD）方法与iv4XR框架结合，并引入战术编程扩展功能。

Result: 成功应用于Space Engineers和LabRecruits游戏测试，提升了自动化测试的效率和可读性。

Conclusion: iv4XR框架的灵活性和BDD方法的结合，显著提升了游戏测试的自动化水平。

Abstract: Computer 3D games are complex software environments that require novel
testing processes to ensure high-quality standards. The Intelligent
Verification/Validation for Extended Reality Based Systems (iv4XR) framework
addresses this need by enabling the implementation of autonomous agents to
automate game testing scenarios. This framework facilitates the automation of
regression test cases for complex 3D games like Space Engineers. Nevertheless,
the technical expertise required to define test scripts using iv4XR can
constrain seamless collaboration between developers and testers. This paper
reports how integrating a Behavior-driven Development (BDD) approach with the
iv4XR framework allows the industrial company behind Space Engineers to
automate regression testing. The success of this industrial collaboration has
inspired the iv4XR team to integrate the BDD approach to improve the automation
of play-testing for the experimental 3D game LabRecruits. Furthermore, the
iv4XR framework has been extended with tactical programming to enable the
automation of long-play test scenarios in Space Engineers. These results
underscore the versatility of the iv4XR framework in supporting diverse testing
approaches while showcasing how BDD empowers users to create, manage, and
execute automated game tests using comprehensive and human-readable statements.

</details>


### [277] [Software Fairness Testing in Practice](https://arxiv.org/abs/2506.17095)
*Ronnie de Souza Santos,Matheus de Morais Leca,Reydne Santos,Cleyton Magalhaes*

Main category: cs.SE

TL;DR: 论文探讨了AI公平性测试的理论与实践之间的差距，通过访谈22位从业者，发现行业缺乏明确的指南和工具，导致公平性测试难以落地。


<details>
  <summary>Details</summary>
Motivation: 随着AI和ML技术融入软件系统，公平性测试成为确保伦理和公正结果的关键，但行业实践与理论研究存在显著差距。

Method: 通过访谈22位从事AI和ML项目的从业者，研究他们在实际开发中如何测试系统的公平性。

Result: 研究发现公平性定义难以应用，行业工具缺乏，且面临数据质量、时间限制等挑战。

Conclusion: 需将学术进展转化为实用工具和策略，帮助从业者系统解决AI公平性问题。

Abstract: Software testing ensures that a system functions correctly, meets specified
requirements, and maintains high quality. As artificial intelligence and
machine learning (ML) technologies become integral to software systems, testing
has evolved to address their unique complexities. A critical advancement in
this space is fairness testing, which identifies and mitigates biases in AI
applications to promote ethical and equitable outcomes. Despite extensive
academic research on fairness testing, including test input generation, test
oracle identification, and component testing, practical adoption remains
limited. Industry practitioners often lack clear guidelines and effective tools
to integrate fairness testing into real-world AI development. This study
investigates how software professionals test AI-powered systems for fairness
through interviews with 22 practitioners working on AI and ML projects. Our
findings highlight a significant gap between theoretical fairness concepts and
industry practice. While fairness definitions continue to evolve, they remain
difficult for practitioners to interpret and apply. The absence of
industry-aligned fairness testing tools further complicates adoption,
necessitating research into practical, accessible solutions. Key challenges
include data quality and diversity, time constraints, defining effective
metrics, and ensuring model interoperability. These insights emphasize the need
to bridge academic advancements with actionable strategies and tools, enabling
practitioners to systematically address fairness in AI systems.

</details>


### [278] [Reassessing Code Authorship Attribution in the Era of Language Models](https://arxiv.org/abs/2506.17120)
*Atish Kumar Dipongkor,Ziyu Yao,Kevin Moran*

Main category: cs.SE

TL;DR: 该论文研究了代码风格计量学中的代码作者归属（CAA）问题，探讨了基于Transformer的语言模型（LMs）在此任务中的有效性，并通过实验分析了多种模型的性能。


<details>
  <summary>Details</summary>
Motivation: CAA在网络安全和软件取证中至关重要，但传统方法依赖手工特征且易受干扰。Transformer模型在自然语言处理中表现优异，但其在CAA中的效果尚不明确。

Method: 研究应用了两种大型和五种小型代码LMs，对6个数据集（包含463名开发者的12k代码片段）进行CAA任务，并使用机器学习可解释性技术深入分析模型性能。

Result: 实验结果表明，LMs在理解代码风格模式方面具有潜力，并揭示了其在CAA任务中的行为特点。

Conclusion: 研究为未来工作提供了重要方向，表明LMs在CAA任务中的应用前景广阔。

Abstract: The study of Code Stylometry, and in particular Code Authorship Attribution
(CAA), aims to analyze coding styles to identify the authors of code samples.
CAA is crucial in cybersecurity and software forensics for addressing,
detecting plagiarism, and supporting criminal prosecutions. However, CAA is a
complex and error prone task, due to the need for recognizing nuanced
relationships between coding patterns. This challenge is compounded in large
software systems with numerous authors due to the subtle variability of
patterns that signify the coding style of one author among many. Given the
challenges related to this task, researchers have proposed and studied
automated approaches that rely upon classical Machine Learning and Deep
Learning techniques. However, such techniques have historically relied upon
hand-crafted features, and due to the often intricate interaction of different
features (e.g., formatting, etc.), have key limitations in properly
characterizing authorship, and are sensitive to adversarial code perturbations.
Recently, transformer-based Language Models (LMs) have shown remarkable
efficacy across a range of software engineering tasks, and in the authorship
attribution on natural language in the NLP domain. However, their effectiveness
in CAA is not well understood. As such, we conduct the first extensive
empirical study applying two larger state-of-the-art code LMs, and five smaller
code LMs to the task of CAA to 6 diverse datasets that encompass 12k code
snippets written by 463 developers. Furthermore, we perform an in-depth
analysis of our studied models' performance on CAA using established machine
learning interpretability techniques. The results of our analysis illustrate
important findings that illuminate the behavior of LMs in understanding
stylometric code patterns during the task of CAA, and point towards important
directions for future work.

</details>


### [279] [Large Language Model Unlearning for Source Code](https://arxiv.org/abs/2506.17125)
*Xue Jiang,Yihong Dong,Zheng Fang,Yingwei Ma,Tangxinyu Wang,Rongyu Cao,Binhua Li,Zhi Jin,Wenpin Jiao,Yongbin Li,Ge Li*

Main category: cs.SE

TL;DR: PROD是一种新型的LLM遗忘方法，能够在保留代码生成能力的同时遗忘不需要的代码内容，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LLM在软件工程中的应用存在敏感或过时数据记忆的风险，现有遗忘方法在代码领域效果不佳。

Method: PROD通过抑制遗忘数据的输出概率并促进候选分布组件，实现特定内容遗忘与能力保留。

Result: PROD在三个下游任务中表现优异，平衡遗忘质量与模型实用性，且对抗攻击鲁棒性强。

Conclusion: PROD扩展了遗忘技术在代码领域的应用，对可靠代码生成有重要意义。

Abstract: LLM4SE has demonstrated significant success, but LLMs' potential memorization
of sensitive or outdated training data introduces critical risks to legal
compliance, software security, and code quality. LLM unlearning techniques,
which can eliminate the influence of undesired data from LLMs in a
post-training way, present a promising solution to address these concerns.
While recent efforts in LLM unlearning show effectiveness in natural language,
their applicability to source code remains underexplored. Our empirical study
reveals that existing LLM unlearning approaches, when applied to source code,
cause severe model utility degradation, rendering models practically unusable
for code generation. In this paper, we propose PROD, a novel unlearning
approach that enables LLMs to forget undesired code content while effectively
preserving their code generation capabilities. PROD suppresses the probability
of forget data in LLMs' output distribution while promoting candidate
distributional components, enabling the model to jointly learn to forget
specific content and retain its general capabilities. To facilitate this study,
we establish a benchmark for code unlearning evaluation, which includes three
critical downstream tasks: copyrighted code unlearning, insecure code
unlearning, and deprecated API unlearning. Our evaluation demonstrates that
PROD achieves superior balance between forget quality and model utility
compared to existing unlearning approaches across three downstream tasks, while
consistently exhibiting improvements when applied to LLMs of varying series.
PROD also exhibits superior robustness against adversarial attacks without
generating or exposing the data to be forgotten. The results underscore that
our approach not only extends the application boundary of unlearning techniques
to source code, but also holds significant implications for advancing reliable
code generation.

</details>


### [280] [Dissecting the SWE-Bench Leaderboards: Profiling Submitters and Architectures of LLM- and Agent-Based Repair Systems](https://arxiv.org/abs/2506.17208)
*Matias Martinez,Xavier Franch*

Main category: cs.SE

TL;DR: 本文对SWE-Bench Lite和Verified排行榜上的提交进行了全面研究，分析了67种不同方法，揭示了专有LLM的主导地位、设计多样性以及贡献者背景的广泛性。


<details>
  <summary>Details</summary>
Motivation: 由于提交过程缺乏详细文档，许多解决方案的设计和来源不明确，因此需要对这些提交进行系统性分析。

Method: 研究分析了SWE-Bench Lite（68项）和Verified（79项）排行榜的所有提交，从提交者类型、产品可用性、LLM使用和系统架构等维度进行了分析。

Result: 研究发现专有LLM（如Claude 3.5/3.7）占据主导地位，设计包括代理和非代理形式，贡献者从个人开发者到大型科技公司不等。

Conclusion: 研究提供了对当前APR领域进展的全面视角，揭示了技术趋势和贡献者生态的多样性。

Abstract: The rapid progress in Automated Program Repair (APR) has been driven by
advances in AI, particularly large language models (LLMs) and agent-based
systems. SWE-Bench is a recent benchmark designed to evaluate LLM-based repair
systems using real issues and pull requests mined from 12 popular open-source
Python repositories. Its public leaderboards, SWE-Bench Lite and SWE-Bench
Verified, have become central platforms for tracking progress and comparing
solutions. However, because the submission process does not require detailed
documentation, the architectural design and origin of many solutions remain
unclear. In this paper, we present the first comprehensive study of all
submissions to the SWE-Bench Lite (68 entries) and Verified (79 entries)
leaderboards, analyzing 67 unique approaches across dimensions such as
submitter type, product availability, LLM usage, and system architecture. Our
findings reveal the dominance of proprietary LLMs (especially Claude 3.5/3.7),
the presence of both agentic and non-agentic designs, and a contributor base
spanning from individual developers to large tech companies.

</details>


### [281] [cAST: Enhancing Code Retrieval-Augmented Generation with Structural Chunking via Abstract Syntax Tree](https://arxiv.org/abs/2506.15655)
*Yilin Zhang,Xinran Zhao,Zora Zhiruo Wang,Chenyang Yang,Jiayi Wei,Tongshuang Wu*

Main category: cs.SE

TL;DR: 论文提出了一种基于抽象语法树（AST）的分块方法（\ourwork），用于改进检索增强生成（RAG）中的代码分块问题，提升代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于行的分块方法会破坏代码的语义结构，影响生成质量，因此需要一种结构感知的分块方法。

Method: 通过递归分解大型AST节点并合并兄弟节点，生成语义连贯且自包含的代码块。

Result: 在多种代码生成任务中表现优异，例如在RepoEval检索任务中Recall@5提升4.3点，在SWE-bench生成任务中Pass@1提升2.67点。

Conclusion: 结构感知的分块方法对扩展检索增强的代码智能至关重要。

Abstract: Retrieval-Augmented Generation (RAG) has become essential for large-scale
code generation, grounding predictions in external code corpora to improve
actuality. However, a critical yet underexplored aspect of RAG pipelines is
chunking -- the process of dividing documents into retrievable units. Existing
line-based chunking heuristics often break semantic structures, splitting
functions or merging unrelated code, which can degrade generation quality. We
propose chunking via Abstract Syntax Trees (\ourwork), a structure-aware method
that recursively breaks large AST nodes into smaller chunks and merges sibling
nodes while respecting size limits. This approach generates self-contained,
semantically coherent units across programming languages and tasks, improving
performance on diverse code generation tasks, e.g., boosting Recall@5 by 4.3
points on RepoEval retrieval and Pass@1 by 2.67 points on SWE-bench generation.
Our work highlights the importance of structure-aware chunking for scaling
retrieval-enhanced code intelligence.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [282] [Leave No One Undermined: Policy Targeting with Regret Aversion](https://arxiv.org/abs/2506.16430)
*Toru Kitagawa,Sokbae Lee,Chen Qiu*

Main category: econ.EM

TL;DR: 论文研究了在数据特征丰富但政策规则只能依赖部分特征的情况下，如何为后悔厌恶的规划者制定最优政策目标。提出了一种去偏经验风险最小化方法，并证明了其收敛速率和渐近效率。


<details>
  <summary>Details</summary>
Motivation: 个性化政策制定在实践中难以完全实现，尤其是在数据特征丰富但政策规则受限的情况下，如何优化政策目标是关键问题。

Method: 基于决策理论，提出了一种去偏经验风险最小化方法，将问题视为加权最小二乘问题，并分析了其收敛速率和效率。

Result: 理论分析表明，该方法具有1/n的收敛速率，并在某些情况下达到渐近效率。实际应用于国家JTPA研究和国际卒中试验。

Conclusion: 该方法为政策目标优化提供了有效工具，尤其在处理特征受限和后悔不平等问题时表现出色。

Abstract: While the importance of personalized policymaking is widely recognized, fully
personalized implementation remains rare in practice. We study the problem of
policy targeting for a regret-averse planner when training data gives a rich
set of observable characteristics while the assignment rules can only depend on
its subset. Grounded in decision theory, our regret-averse criterion reflects a
planner's concern about regret inequality across the population, which
generally leads to a fractional optimal rule due to treatment effect
heterogeneity beyond the average treatment effects conditional on the subset
characteristics. We propose a debiased empirical risk minimization approach to
learn the optimal rule from data. Viewing our debiased criterion as a weighted
least squares problem, we establish new upper and lower bounds for the excess
risk, indicating a convergence rate of 1/n and asymptotic efficiency in certain
cases. We apply our approach to the National JTPA Study and the International
Stroke Trial.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [283] [Long Coalition Leads to Shrink? The Roles of Tipping and Technology-Sharing in Climate Clubs](https://arxiv.org/abs/2506.16162)
*Lei Zhu,Zhihao Yan,Hongbo Duan,Yongyang Cai,Xiaobing Zhang*

Main category: econ.GN

TL;DR: 论文通过动态博弈模型分析气候临界点下联盟的稳定性，提出技术共享机制对抗搭便车行为，发现联盟规模随时间缩小，但技术共享比制裁更有效。


<details>
  <summary>Details</summary>
Motivation: 全球合作是应对气候变化的关键，但搭便车等障碍阻碍其实现。

Method: 开发动态博弈模型，分析气候临界点下联盟的稳定性，并设计技术共享机制。

Result: 联盟规模随温度上升缩小，但技术共享能增强联盟韧性并限制全球变暖。

Conclusion: 技术共享在气候临界点不确定性下对促进长期气候合作至关重要。

Abstract: Global cooperation is posited as a pivotal solution to address climate
change, yet significant barriers, like free-riding, hinder its realization.
This paper develops a dynamic game-theoretic model to analyze the stability of
coalitions under multiple stochastic climate tippings, and a technology-sharing
mechanism is designed in the model to combat free-ridings. Our results reveal
that coalitions tend to shrink over time as temperatures rise, owing to
potential free-ridings, despite a large size of initial coalition. The threat
of climate tipping reduces the size of stable coalitions compared to the case
where tipping is ignored. However, at post-tipping period, coalitions
temporarily expand as regions respond to the shock, though this cooperation is
short-lived and followed by further shrink. Notably, technology-sharing
generates greater collective benefits than sanctions, suggesting that the
proposed dynamic technology-sharing pathway bolsters coalition resilience
against free-riding while limiting the global warming. This framework
highlights the critical role of technology-sharing in fostering long-term
climate cooperation under climate tipping uncertainties.

</details>


### [284] [Artificial Intelligence, Lean Startup Method, and Product Innovations](https://arxiv.org/abs/2506.16334)
*Gavin Wang,Lynn Wu*

Main category: econ.GN

TL;DR: 研究发现，AI与精益创业方法（LSM）结合能显著提升产品创新效率，但效果因AI类型和创新能力而异。


<details>
  <summary>Details</summary>
Motivation: 探讨AI如何与LSM结合以推动初创企业的产品创新，并分析其在不同创新类型中的效果差异。

Method: 分析了2011-2020年间1800家中国初创企业的数据，结合政府政策变化，区分了发现导向和优化导向的AI，以及LSM中的原型设计和AB测试。

Result: 发现导向AI与LSM结合能减少不确定性，优化导向AI则加速迭代改进，两者均能提升产品质量和效率。

Conclusion: AI应被视为异质工具，不同AI能力需匹配特定组织流程以实现最佳创新效果。

Abstract: Although AI has the potential to drive significant business innovation, many
firms struggle to realize its benefits. We examine how the Lean Startup Method
(LSM) influences the impact of AI on product innovation in startups. Analyzing
data from 1,800 Chinese startups between 2011 and 2020, alongside policy shifts
by the Chinese government in encouraging AI adoption, we find that companies
with strong AI capabilities produce more innovative products. Moreover, our
study reveals that AI investments complement LSM in innovation, with
effectiveness varying by the type of innovation and AI capability. We
differentiate between discovery-oriented AI, which reduces uncertainty in novel
areas of innovation, and optimization-oriented AI, which refines and optimizes
existing processes. Within the framework of LSM, we further distinguish between
prototyping focused on developing minimum viable products, and controlled
experimentation, focused on rigorous testing such as AB testing. We find that
LSM complements discovery oriented AI by utilizing AI to expand the search for
market opportunities and employing prototyping to validate these opportunities,
thereby reducing uncertainties and facilitating the development of the first
release of products. Conversely, LSM complements optimization-oriented AI by
using AB testing to experiment with the universe of input features and using AI
to streamline iterative refinement processes, thereby accelerating the
improvement of iterative releases of products. As a result, when firms use AI
and LSM for product development, they are able to generate more high quality
product in less time. These findings, applicable to both software and hardware
development, underscore the importance of treating AI as a heterogeneous
construct, as different AI capabilities require distinct organizational
processes to achieve optimal outcomes.

</details>


### [285] [Social Media Can Reduce Misinformation When Public Scrutiny is High](https://arxiv.org/abs/2506.16355)
*Gavin Wang,Haofei Qin,Xiao Tang,Lynn Wu*

Main category: econ.GN

TL;DR: 研究发现社交媒体在公众监督高的地区能抑制GDP数据造假，但在监督低的地区可能加剧造假，挑战了社交媒体主要传播虚假信息的观点。


<details>
  <summary>Details</summary>
Motivation: 探讨社交媒体在增强透明度和问责制方面的潜力，尤其是在中国地方政府GDP数据造假的背景下。

Method: 分析2011至2019年中国地方政府的官方GDP报告，比较采用社交媒体前后的数据造假程度。

Result: 社交媒体在公众监督高的地区显著减少GDP数据造假，但在监督低的地区可能加剧造假。

Conclusion: 社交媒体对信息真实性的影响取决于公众监督水平，强调了公民参与的重要性，为平台设计和公共政策提供了启示。

Abstract: Misinformation poses a growing global threat to institutional trust,
democratic stability, and public decision-making. While prior research has
often portrayed social media as a channel for spreading falsehoods, less is
known about the conditions under which it may instead constrain misinformation
by enhancing transparency and accountability. Here we show this dual potential
in the context of local governments' GDP reporting in China, where data
falsifications are widespread. Analyzing official reports from 2011 to 2019, we
find that local governments have overstated GDP on average. However, after
adopting social media for public communications, the extent of misreporting
declines significantly but only in regions where the public scrutiny over
political matters is high. In such regions, social media increases the cost of
misinformation by facilitating greater information disclosure and bottom-up
monitoring. In contrast, in regions with low public scrutiny, adopting social
media can exacerbate data manipulation. These findings challenge the prevailing
view that social media primarily amplifies misinformation and instead highlight
the importance of civic engagement as a moderating force. Our findings show a
boundary condition for the spread of misinformation and offer insights for
platform design and public policy aimed at promoting accuracy and institutional
accountability.

</details>


### [286] [Optimal Regulation and Investment Incentives in Financial Networks](https://arxiv.org/abs/2506.16648)
*Matthew O. Jackson,Agathe Pernoud*

Main category: econ.GN

TL;DR: 研究金融网络中债务互依关系的最优监管，探讨企业选择高风险投资组合的动机及监管如何依赖金融中心性和投资机会。


<details>
  <summary>Details</summary>
Motivation: 分析金融网络中企业因债务互依关系而选择高风险投资组合的动机，以及如何通过监管优化金融稳定性。

Method: 通过理论模型分析企业在金融网络中的行为，并探讨最优监管策略。

Result: 在核心-边缘网络中，最优监管与银行投资相关性呈非单调关系，且可能需对核心银行实施不对称监管。

Conclusion: 最优监管需考虑金融中心性和投资相关性，可能需对相同中心性的银行实施差异化监管。

Abstract: We examine optimal regulation of financial networks with debt
interdependencies between financial firms. We first characterize when it is
firms have an incentive to choose excessively risky portfolios and overly
correlate their portfolios with those of their counterparties. We then
characterize how optimal regulation depends on a firm's financial centrality
and its available investment opportunities. In standard core-periphery
networks, optimal regulation depends non-monotonically on the correlation of
banks' investments, with maximal restrictions for intermediate levels of
correlation. Moreover, it can be uniquely optimal to treat banks
asymmetrically: restricting the investments of one core bank while allowing an
otherwise identical core bank (in all aspects, including network centrality) to
invest freely.

</details>


### [287] [A new equilibrium: COVID-19 lockdowns and WFH persistence](https://arxiv.org/abs/2506.16671)
*Laura Ketter,Todd Morris,Lizi Yu*

Main category: econ.GN

TL;DR: COVID-19封锁与远程工作（WFH）的持续采用之间存在显著关联。


<details>
  <summary>Details</summary>
Motivation: 研究封锁政策对远程工作习惯的长期影响。

Method: 利用纵向数据，采用双重差分法比较澳大利亚不同封锁程度州的办公室员工。

Result: 封锁州的员工2023年远程工作时间高出43%（每周0.5天），劳动力市场双方均有调整。

Conclusion: 封锁政策对远程工作的持续性有显著影响，企业和员工均做出适应性调整。

Abstract: This paper documents a robust link between COVID-19 lockdowns and the uptake
and persistence of working from home (WFH) practices. Exploiting rich
longitudinal data, we use a difference-in-differences strategy to compare
office workers in three heavily locked-down Australian states to similar
workers in less affected states. Locked-down workers sustain 43% higher WFH
levels through 2023 - 0.5 days per week - with a monotonic dose-response
relationship. Persistence is driven by adjustments on both sides of the labor
market: employers downsize office space and open remote or hybrid positions,
while employees relocate away from city centers and invest in home offices and
technology.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [288] [Learning in Random Utility Models Via Online Decision Problems](https://arxiv.org/abs/2506.16030)
*Emerson Melo*

Main category: econ.TH

TL;DR: 论文研究了在决策者缺乏完整信息的情况下，随机效用模型（RUM）在重复随机选择中的应用，提出了一种基于梯度的学习算法，证明了其Hannan一致性，并展示了与FTRL方法的等价性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决决策者在不完全信息下重复选择的问题，通过将RUM嵌入在线决策框架，提供一种理论支持的方法。

Method: 提出了一种基于梯度的学习算法，将RUM应用于在线决策框架，并分析了其与FTRL方法的等价性。

Result: 证明了算法对一类广泛的RUM具有Hannan一致性，即平均遗憾随时间消失。

Conclusion: 该算法为在线优化提供了经济学基础，并可用于建模近因偏差和描述博弈中的粗相关均衡。

Abstract: This paper examines the Random Utility Model (RUM) in repeated stochastic
choice settings where decision-makers lack full information about payoffs. We
propose a gradient-based learning algorithm that embeds RUM into an online
decision-making framework. Our analysis establishes Hannan consistency for a
broad class of RUMs, meaning the average regret relative to the best fixed
action in hindsight vanishes over time. We also show that our algorithm is
equivalent to the Follow-The-Regularized-Leader (FTRL) method, offering an
economically grounded approach to online optimization. Applications include
modeling recency bias and characterizing coarse correlated equilibria in
normal-form games

</details>


### [289] [The Implementability of Liberalism](https://arxiv.org/abs/2506.16059)
*Héctor Hermida-Rivera*

Main category: econ.TH

TL;DR: 在无限制领域下，存在一个选择自由且纳什可实施的社会选择规则，当且仅当玩家数至少为三且结果集大小至少为玩家数的两倍。


<details>
  <summary>Details</summary>
Motivation: 研究在无限制领域中，选择自由与纳什可实施的社会选择规则的存在条件。

Method: 通过构造直观的纳什实施机制来证明条件。

Result: 证明了存在条件：玩家数≥3且结果集大小≥2倍玩家数。

Conclusion: 在满足特定条件下，选择自由与纳什可实施的社会选择规则是可行的。

Abstract: This note shows that under the unrestricted domain, there exists a choice
liberal and Nash implementable social choice rule if and only if there are at
least three players and the outcome set is at least twice as large as the
player set. A social choice rule is choice liberal if and only if for every
player, there exists at least one pair of outcomes such that if this player
strictly prefers one over the other, the one he prefers is socially desirable
and the other one is not. A social choice rule is Nash implementable if and
only if there exists a mechanism such that at every preference profile, the set
of Nash equilibrium outcomes coincides with the set of socially desirable ones.
The proof constructs an intuitive Nash implementing mechanism.

</details>


### [290] [Two-Person Cooperative Games with delta-Rationality](https://arxiv.org/abs/2506.16465)
*Fang-Fang Tang,Yongsheng Xu*

Main category: econ.TH

TL;DR: 论文提出了一种包含理性价值和扭曲价值的玩家收益模型，强调用总收益函数解释行为，而用理性价值函数进行福利分析，并以纳什需求博弈为例说明。


<details>
  <summary>Details</summary>
Motivation: 探讨如何更全面地解释和预测玩家行为，同时区分收益的不同部分以进行更准确的福利分析。

Method: 提出收益分为理性价值和扭曲价值两部分，并以纳什需求博弈为例展示模型的应用。

Result: 总收益函数适用于行为解释和预测，理性价值函数适用于福利分析。

Conclusion: 通过区分收益的不同部分，模型能够更全面地分析玩家行为和福利效果。

Abstract: A player's payoff is modeled as consisting of two parts: a rational-value
part and a distortion-value part. It is argued that the (total) payoff function
should be used to explain and predict the behaviors of the players, while the
rational value function should be used to conduct welfare analysis of the final
outcome. We use the Nash demand game to illustrate our model.

</details>


### [291] [AI Plays? δ-Rationality Games with Nash Equilibrium as Special Case](https://arxiv.org/abs/2506.16467)
*Fang-Fang Tang,Yongsheng Xu*

Main category: econ.TH

TL;DR: 论文引入了一种失真函数，用于分析玩家实际收益与真实收益之间的差距，并提出了一个框架，用实际收益函数解释行为，用真实收益函数进行福利分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于区分玩家的实际收益和真实收益，以更准确地解释行为并评估游戏结果的福利影响。

Method: 方法是通过引入失真函数，构建一个分析框架，将实际收益函数用于行为解释，真实收益函数用于福利分析。

Result: 结果表明，这种区分能够更有效地预测玩家行为，并为游戏结果的福利评估提供更准确的依据。

Conclusion: 结论是失真函数和提出的框架为游戏理论和行为分析提供了新的视角和工具。

Abstract: A distortion function, which captures the payoff gap between a player's
actual payoff and her true payoff, is introduced and used to analyze games. In
our proposed framework, we argue that players' actual payoff functions should
be used to explain and predict their behaviors, while their true payoff
functions should be used to conduct welfare analysis of the outcomes.

</details>


### [292] [Do You Know What I Mean? A Syntactic Representation for Differential Bounded Awareness](https://arxiv.org/abs/2506.16901)
*Ani Guerdjikova,Evan Piermont,John Quiggin*

Main category: econ.TH

TL;DR: 论文探讨了在缺乏完全共享意识的情况下，如何通过语言翻译操作实现不同代理之间的有效通信。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决代理间因世界表征不同而导致的通信问题。

Method: 采用基于语言的翻译操作，定义了一种在目标语言表达能力限制下的“最佳近似”翻译方法。

Result: 结果表明翻译操作能部分保留逻辑操作，并提出了联合状态空间和联合语言存在的充要条件。

Conclusion: 该方法可用于比较语言的表达能力及其关联状态空间的特性。

Abstract: Without the assumption of complete, shared awareness, it is necessary to
consider communication between agents who may entertain different
representations of the world. A syntactic (language-based) approach provides
powerful tools to address this problem. In this paper, we define translation
operators between two languages which provide a ``best approximation'' for the
meaning of propositions in the target language subject to its expressive power.
We show that, in general, the translation operators preserve some, but not all,
logical operations. We derive necessary and sufficient conditions for the
existence of a joint state space and a joint language, in which the subjective
state spaces of each agent, and their individual languages, may be embedded.
This approach allows us to compare languages with respect to their
expressiveness and thus, with respect to the properties of the associated state
space.

</details>


### [293] [Capturing Misalignment](https://arxiv.org/abs/2506.17176)
*Pierfrancesco Guarino,Gabriel Ziegler*

Main category: econ.TH

TL;DR: 论文提出并形式化了“misalignment”现象，即一个代理对另一个代理的信念与实际不符，并展示了现有框架无法捕捉这一现象。通过非信念封闭状态空间和代理依赖类型结构，论文提供了分析工具，并探讨了其对交互推理的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是揭示和分析代理间信念不一致的现象（misalignment），并指出现有理论框架（如类型结构）无法有效捕捉这一现象。

Method: 方法包括：1）通过非信念封闭状态空间表征misalignment；2）引入代理依赖类型结构；3）使用适应性模态算子分析其一致性。

Result: 结果表明：1）代理依赖类型结构能灵活分析不同程度的misalignment；2）适应性模态算子与标准性质一致；3）misalignment可能导致投机交易。

Conclusion: 结论是misalignment是交互环境中重要现象，需新工具分析，且其对交互推理和投机交易有显著影响。

Abstract: We introduce and formalize misalignment, a phenomenon of interactive
environments perceived from an analyst's perspective where an agent holds
beliefs about another agent's beliefs that do not correspond to the actual
beliefs of the latter. We demonstrate that standard frameworks, such as type
structures, fail to capture misalignment, necessitating new tools to analyze
this phenomenon. To this end, we characterize misalignment through
non-belief-closed state spaces and introduce agent-dependent type structures,
which provide a flexible tool to understand the varying degrees of
misalignment. Furthermore, we establish that appropriately adapted modal
operators on agent-dependent type structures behave consistently with standard
properties, enabling us to explore the implications of misalignment for
interactive reasoning. Finally, we show how speculative trade can arise under
misalignment, even when imposing the corresponding assumptions that rule out
such trades in standard environments.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [294] [HetGPU: The pursuit of making binary compatibility towards GPUs](https://arxiv.org/abs/2506.15993)
*Yiwei Yang,Yusheng Zheng,Tong Yu,Andi Quinn*

Main category: cs.AR

TL;DR: hetGPU系统通过编译器、运行时和抽象层实现跨厂商GPU的二进制兼容性，支持NVIDIA、AMD、Intel和Tenstorrent硬件。


<details>
  <summary>Details</summary>
Motivation: 解决异构GPU基础设施因指令集、执行模型和驱动栈差异导致的二进制兼容性问题。

Method: 提出hetGPU系统，包括生成架构无关的GPU中间表示（IR）、动态翻译IR为目标GPU原生代码，并提供统一的线程、内存和同步抽象。

Result: 初步评估显示，未修改的GPU二进制文件可在不同GPU间迁移，开销极小。

Conclusion: hetGPU为跨厂商GPU计算提供了可行方案。

Abstract: Heterogeneous GPU infrastructures present a binary compatibility challenge:
code compiled for one vendor's GPU will not run on another due to divergent
instruction sets, execution models, and driver stacks . We propose hetGPU, a
new system comprising a compiler, runtime, and abstraction layer that together
enable a single GPU binary to execute on NVIDIA, AMD, Intel, and Tenstorrent
hardware. The hetGPU compiler emits an architecture-agnostic GPU intermediate
representation (IR) and inserts metadata for managing execution state. The
hetGPU runtime then dynamically translates this IR to the target GPU's native
code and provides a uniform abstraction of threads, memory, and
synchronization. Our design tackles key challenges: differing SIMT vs. MIMD
execution (warps on NVIDIA/AMD vs. many-core RISC-V on Tenstorrent), varied
instruction sets, scheduling and memory model discrepancies, and the need for
state serialization for live migration. We detail the hetGPU architecture,
including the IR transformation pipeline, a state capture/reload mechanism for
live GPU migration, and an abstraction layer that bridges warp-centric and
core-centric designs. Preliminary evaluation demonstrates that unmodified GPU
binaries compiled with hetGPU can be migrated across disparate GPUs with
minimal overhead, opening the door to vendor-agnostic GPU computing.

</details>
