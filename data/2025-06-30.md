<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.CL](#cs.CL) [Total: 103]
- [cs.CV](#cs.CV) [Total: 85]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.SE](#cs.SE) [Total: 8]
- [econ.EM](#econ.EM) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [econ.TH](#econ.TH) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [SEEA-R1: Tree-Structured Reinforcement Fine-Tuning for Self-Evolving Embodied Agents](https://arxiv.org/abs/2506.21669)
*Wanxin Tian,Shijie Zhang,Kevin Zhang,Xiaowei Chi,Yulin Luo,Junyu Lu,Chunkai Fan,Qiang Zhou,Yiming Zhao,Ning Liu Siyu Lin,Zhiyuan Qin,Xiaozhu Ju,Shanghang Zhang,Jian Tang*

Main category: cs.AI

TL;DR: SEEA-R1是一个强化微调框架，旨在提升具身智能体的自我进化能力，通过Tree-GRPO和MGRM解决多步推理和奖励泛化问题，在ALFWorld基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前强化微调在具身智能领域的潜力尚未充分挖掘，尤其是在多模态交互和长时任务中缺乏有效的中间奖励和泛化能力。

Method: 提出SEEA-R1框架，结合Tree-GRPO（蒙特卡洛树搜索与GRPO）和MGRM（多模态生成奖励模型），优化多步推理和奖励泛化。

Result: 在ALFWorld基准测试中，SEEA-R1以85.07%（文本）和36.19%（多模态）的分数超越现有方法，包括GPT-4o。

Conclusion: SEEA-R1展示了在具身智能领域实现自我进化的潜力，为未来可扩展研究提供了支持。

Abstract: Self-evolution, the ability of agents to autonomously improve their reasoning
and behavior, is essential for the embodied domain with long-horizon,
real-world tasks. Despite current advancements in reinforcement fine-tuning
(RFT) showing strong performance in enhancing reasoning in LLMs, its potential
to enable self-evolving embodied intelligence with multi-modal interactions
remains largely unexplored. Specifically, reinforcement fine-tuning faces two
fundamental obstacles in embodied settings: (i) the lack of accessible
intermediate rewards in multi-step reasoning tasks limits effective learning
signals, and (ii) reliance on hand-crafted reward functions restricts
generalization to novel tasks and environments. To address these challenges, we
present Self-Evolving Embodied Agents-R1, SEEA-R1, the first RFT framework
designed for enabling the self-evolving capabilities of embodied agents.
Specifically, to convert sparse delayed rewards into denser intermediate
signals that improve multi-step reasoning, we propose Tree-based group relative
policy optimization (Tree-GRPO), which integrates Monte Carlo Tree Search into
GRPO. To generalize reward estimation across tasks and scenes, supporting
autonomous adaptation and reward-driven self-evolution, we further introduce
Multi-modal Generative Reward Model (MGRM). To holistically evaluate the
effectiveness of SEEA-R1, we evaluate on the ALFWorld benchmark, surpassing
state-of-the-art methods with scores of 85.07% (textual) and 36.19%
(multi-modal), outperforming prior models including GPT-4o. SEEA-R1 also
achieves scores of 80.3% without environmental reward, surpassing all
open-source baselines and highlighting its scalability as a self-evolving
embodied agent. Additional experiments and qualitative analysis further support
the potential of SEEA-R1 for future research in scalable embodied intelligence.

</details>


### [2] [Hierarchical Reasoning Model](https://arxiv.org/abs/2506.21734)
*Guan Wang,Jin Li,Yuhao Sun,Xing Chen,Changling Liu,Yue Wu,Meng Lu,Sen Song,Yasin Abbasi Yadkori*

Main category: cs.AI

TL;DR: HRM是一种新型递归架构，通过分层和多时间尺度处理解决推理任务，无需大量数据或预训练，性能优越。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的Chain-of-Thought方法存在任务分解脆弱、数据需求高和延迟问题，需改进。

Method: HRM采用双递归模块：高层负责抽象规划，低层处理细节计算，单次前向传递完成推理。

Result: 仅用2700万参数和1000样本，HRM在复杂推理任务（如数独、迷宫路径）和ARC基准上表现优异。

Conclusion: HRM为通用计算和推理系统提供了潜在突破性进展。

Abstract: Reasoning, the process of devising and executing complex goal-oriented action
sequences, remains a critical challenge in AI. Current large language models
(LLMs) primarily employ Chain-of-Thought (CoT) techniques, which suffer from
brittle task decomposition, extensive data requirements, and high latency.
Inspired by the hierarchical and multi-timescale processing in the human brain,
we propose the Hierarchical Reasoning Model (HRM), a novel recurrent
architecture that attains significant computational depth while maintaining
both training stability and efficiency. HRM executes sequential reasoning tasks
in a single forward pass without explicit supervision of the intermediate
process, through two interdependent recurrent modules: a high-level module
responsible for slow, abstract planning, and a low-level module handling rapid,
detailed computations. With only 27 million parameters, HRM achieves
exceptional performance on complex reasoning tasks using only 1000 training
samples. The model operates without pre-training or CoT data, yet achieves
nearly perfect performance on challenging tasks including complex Sudoku
puzzles and optimal path finding in large mazes. Furthermore, HRM outperforms
much larger models with significantly longer context windows on the Abstraction
and Reasoning Corpus (ARC), a key benchmark for measuring artificial general
intelligence capabilities. These results underscore HRM's potential as a
transformative advancement toward universal computation and general-purpose
reasoning systems.

</details>


### [3] [THE-Tree: Can Tracing Historical Evolution Enhance Scientific Verification and Reasoning?](https://arxiv.org/abs/2506.21763)
*Xin Wang,Jiyao Liu,Yulong Xiao,Junzhi Ning,Lihao Liu,Junjun He,Botian Shi,Kaicheng Yu*

Main category: cs.AI

TL;DR: 论文提出THE-Tree框架，用于构建科学领域的技术演化树，通过LLM生成和验证科学进步路径，显著提升科学预测和评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如LLM单独验证或传统引用网络）无法有效评估AI生成的科学命题的新颖性和准确性，缺乏结构化、可验证的科学演化数据。

Method: THE-Tree框架通过搜索算法构建领域演化树，结合LLM的“Think-Verbalize-Cite-Verify”流程和自然语言推理机制验证每一步的逻辑和证据支持。

Result: 在88个领域的实验中，THE-Tree在图形完成和科学预测任务中显著优于传统方法，性能提升8%至100%。

Conclusion: THE-Tree为解决科学演化数据的结构化验证提供了有效工具，显著提升了科学预测和评估的准确性。

Abstract: Large Language Models (LLMs) are accelerating scientific idea generation, but
rigorously evaluating these numerous, often superficial, AI-generated
propositions for novelty and factual accuracy is a critical bottleneck; manual
verification is too slow.Existing validation methods are inadequate: LLMs as
standalone verifiers may hallucinate and lack domain knowledge (our findings
show ~60\% unawareness of relevant papers in specific domains), while
traditional citation networks lack explicit causality and narrative surveys are
unstructured.This underscores a core challenge: the absence of structured,
verifiable, and causally-linked historical data of scientific evolution.To
address this,we introduce \textbf{THE-Tree} (\textbf{T}echnology
\textbf{H}istory \textbf{E}volution Tree), a computational framework that
constructs such domain-specific evolution trees from scientific
literature.THE-Tree employs a search algorithm to explore evolutionary paths.
During its node expansion, it utilizes a novel "Think-Verbalize-Cite-Verify"
process: an LLM proposes potential advancements and cites supporting
literature. Critically, each proposed evolutionary link is then validated for
logical coherence and evidential support by a recovered natural language
inference mechanism that interrogates the cited literature, ensuring that each
step is grounded.We construct and validate 88 THE-Trees across diverse domains
and release a benchmark dataset including up to 71k fact verifications covering
27k papers to foster further research.Experiments demonstrate that i) in graph
completion, our THE-Tree improves hit@1 by 8\% to 14\% across multiple models
compared to traditional citation networks; ii) for predicting future scientific
developments, it improves hit@1 metric by nearly 10\%; and iii) when combined
with other methods, it boosts the performance of evaluating important
scientific papers by almost 100\%.

</details>


### [4] [MobiVerse: Scaling Urban Mobility Simulation with Hybrid Lightweight Domain-Specific Generator and Large Language Models](https://arxiv.org/abs/2506.21784)
*Yifan Liu,Xishun Liao,Haoxuan Ma,Jonathan Liu,Rohan Jadhav,Jiaqi Ma*

Main category: cs.AI

TL;DR: MobiVerse是一个混合框架，结合轻量级领域特定生成器和LLMs，用于大规模人类移动模式模拟，解决了传统方法的不足。


<details>
  <summary>Details</summary>
Motivation: 当前移动模拟平台在算法开发、政策实施和大规模评估方面存在不足，传统方法数据需求高且适应性差。

Method: 提出MobiVerse，结合轻量级生成器生成基础活动链和LLMs进行上下文感知调整。

Result: 在洛杉矶Westwood的案例中，成功为53,000个代理动态调整日程，响应环境变化，保持计算效率。

Conclusion: MobiVerse填补了移动模拟的空白，提供了可定制平台，兼具计算效率和行为真实性。

Abstract: Understanding and modeling human mobility patterns is crucial for effective
transportation planning and urban development. Despite significant advances in
mobility research, there remains a critical gap in simulation platforms that
allow for algorithm development, policy implementation, and comprehensive
evaluation at scale. Traditional activity-based models require extensive data
collection and manual calibration, machine learning approaches struggle with
adaptation to dynamic conditions, and treding agent-based Large Language Models
(LLMs) implementations face computational constraints with large-scale
simulations. To address these challenges, we propose MobiVerse, a hybrid
framework leverages the efficiency of lightweight domain-specific generator for
generating base activity chains with the adaptability of LLMs for context-aware
modifications. A case study was conducted in Westwood, Los Angeles, where we
efficiently generated and dynamically adjusted schedules for the whole
population of approximately 53,000 agents on a standard PC. Our experiments
demonstrate that MobiVerse successfully enables agents to respond to
environmental feedback, including road closures, large gathering events like
football games, and congestion, through our hybrid framework. Its modular
design facilitates testing various mobility algorithms at both transportation
system and agent levels. Results show our approach maintains computational
efficiency while enhancing behavioral realism. MobiVerse bridges the gap in
mobility simulation by providing a customizable platform for mobility systems
planning and operations with benchmark algorithms. Code and videos are
available at https://github.com/ucla-mobility/MobiVerse.

</details>


### [5] [CitySim: Modeling Urban Behaviors and City Dynamics with Large-Scale LLM-Driven Agent Simulation](https://arxiv.org/abs/2506.21805)
*Nicolas Bougie,Narimasa Watanabe*

Main category: cs.AI

TL;DR: CitySim利用大型语言模型模拟人类行为，通过递归价值驱动方法生成真实日程，并支持长期仿真，比现有方法更接近真实人类行为。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖固定规则，难以模拟复杂意图和适应性行为，CitySim旨在解决这一问题。

Method: 采用递归价值驱动方法，结合信念、长期目标和空间记忆，模拟人类日常行为。

Result: CitySim在微观和宏观层面均更接近真实人类行为，并能模拟大规模集体行为。

Conclusion: CitySim是一个可扩展、灵活的测试平台，适用于理解和预测城市现象。

Abstract: Modeling human behavior in urban environments is fundamental for social
science, behavioral studies, and urban planning. Prior work often rely on
rigid, hand-crafted rules, limiting their ability to simulate nuanced
intentions, plans, and adaptive behaviors. Addressing these challenges, we
envision an urban simulator (CitySim), capitalizing on breakthroughs in
human-level intelligence exhibited by large language models. In CitySim, agents
generate realistic daily schedules using a recursive value-driven approach that
balances mandatory activities, personal habits, and situational factors. To
enable long-term, lifelike simulations, we endow agents with beliefs, long-term
goals, and spatial memory for navigation. CitySim exhibits closer alignment
with real humans than prior work, both at micro and macro levels. Additionally,
we conduct insightful experiments by modeling tens of thousands of agents and
evaluating their collective behaviors under various real-world scenarios,
including estimating crowd density, predicting place popularity, and assessing
well-being. Our results highlight CitySim as a scalable, flexible testbed for
understanding and forecasting urban phenomena.

</details>


### [6] [Interactive Multi-Objective Probabilistic Preference Learning with Soft and Hard Bounds](https://arxiv.org/abs/2506.21887)
*Edward Chen,Sang T. Truong,Natalie Dullerud,Sanmi Koyejo,Carlos Guestrin*

Main category: cs.AI

TL;DR: Active-MoSH是一个交互式框架，用于在高风险决策中平衡多目标优化，通过软硬边界和偏好学习帮助决策者快速找到Pareto最优解，同时增强信任。


<details>
  <summary>Details</summary>
Motivation: 在高风险决策（如近距离放射治疗）中，决策者需平衡多个目标（如肿瘤覆盖率和器官剂量限制），但现有方法缺乏系统性迭代优化偏好结构的能力，且决策者需对最终选择有高度信任。

Method: Active-MoSH结合局部（软硬边界与概率偏好学习）和全局（多目标敏感性分析）组件，通过主动采样策略优化探索与利用，减少认知负担。

Result: 实验证明Active-MoSH在合成和实际应用中表现优异，用户研究表明其能加速收敛、增强决策者信任并提供更灵活的偏好表达。

Conclusion: Active-MoSH为高风险决策提供了一种高效、可信的交互式框架，显著提升了多目标优化的效果和决策者体验。

Abstract: High-stakes decision-making involves navigating multiple competing objectives
with expensive evaluations. For instance, in brachytherapy, clinicians must
balance maximizing tumor coverage (e.g., an aspirational target or soft bound
of >95% coverage) against strict organ dose limits (e.g., a non-negotiable hard
bound of <601 cGy to the bladder), with each plan evaluation being
resource-intensive. Selecting Pareto-optimal solutions that match implicit
preferences is challenging, as exhaustive Pareto frontier exploration is
computationally and cognitively prohibitive, necessitating interactive
frameworks to guide users. While decision-makers (DMs) often possess domain
knowledge to narrow the search via such soft-hard bounds, current methods often
lack systematic approaches to iteratively refine these multi-faceted preference
structures. Critically, DMs must trust their final decision, confident they
haven't missed superior alternatives; this trust is paramount in
high-consequence scenarios. We present Active-MoSH, an interactive local-global
framework designed for this process. Its local component integrates soft-hard
bounds with probabilistic preference learning, maintaining distributions over
DM preferences and bounds for adaptive Pareto subset refinement. This is guided
by an active sampling strategy optimizing exploration-exploitation while
minimizing cognitive burden. To build DM trust, Active-MoSH's global component,
T-MoSH, leverages multi-objective sensitivity analysis to identify potentially
overlooked, high-value points beyond immediate feedback. We demonstrate
Active-MoSH's performance benefits through diverse synthetic and real-world
applications. A user study on AI-generated image selection further validates
our hypotheses regarding the framework's ability to improve convergence,
enhance DM trust, and provide expressive preference articulation, enabling more
effective DMs.

</details>


### [7] [AlphaBeta is not as good as you think: a new probabilistic model to better analyze deterministic game-solving algorithms](https://arxiv.org/abs/2506.21996)
*Raphaël Boige,Amine Boumaza,Bruno Scherrer*

Main category: cs.AI

TL;DR: 论文提出了一种新的概率模型，通过引入祖先依赖关系生成具有可调难度的游戏树，解决了传统独立假设模型的局限性，并分析了多种算法在深层游戏树中的平均复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统模型因独立假设简化了游戏结构，导致算法分析结果不具挑战性。本文旨在通过引入更现实的依赖关系，提供更具挑战性和分析性的模型。

Method: 提出了一种基于固定层级条件分布的概率模型，通过强制祖先依赖关系生成游戏树，并推导了AlphaBeta和Scout等算法的递归公式。

Result: 在深层游戏树中，AlphaBeta相比Scout等算法具有更大的常数乘数，导致实际性能显著下降。

Conclusion: 新框架为经典游戏求解算法提供了更现实且可分析的环境，揭示了算法在实际应用中的性能差异。

Abstract: Deterministic game-solving algorithms are conventionally analyzed in the
light of their average-case complexity against a distribution of random
game-trees, where leaf values are independently sampled from a fixed
distribution. This simplified model enables uncluttered mathematical analysis,
revealing two key properties: root value distributions asymptotically collapse
to a single fixed value for finite-valued trees, and all reasonable algorithms
achieve global optimality. However, these findings are artifacts of the model's
design-its long criticized independence assumption strips games of structural
complexity, producing trivial instances where no algorithm faces meaningful
challenges. To address this limitation, we introduce a new probabilistic model
that incrementally constructs game-trees using a fixed level-wise conditional
distribution. By enforcing ancestor dependency, a critical structural feature
of real-world games, our framework generates problems with adjustable
difficulty while retaining some form of analytical tractability. For several
algorithms, including AlphaBeta and Scout, we derive recursive formulas
characterizing their average-case complexities under this model. These allow us
to rigorously compare algorithms on deep game-trees, where Monte-Carlo
simulations are no longer feasible. While asymptotically, all algorithms seem
to converge to identical branching factor (a result analogous to those of
independence-based models), deep finite trees reveal stark differences:
AlphaBeta incurs a significantly larger constant multiplicative factor compared
to algorithms like Scout, leading to a substantial practical slowdown. Our
framework sheds new light on classical game-solving algorithms, offering
rigorous evidence and analytical tools to advance the understanding of these
methods under a more realistic, challenging, and yet tractable model.

</details>


### [8] [LeanConjecturer: Automatic Generation of Mathematical Conjectures for Theorem Proving](https://arxiv.org/abs/2506.22005)
*Naoto Onda,Kazumi Kasaura,Yuta Oriike,Masaya Taniguchi,Akiyoshi Sannai,Sho Sonoda*

Main category: cs.AI

TL;DR: LeanConjecturer是一个自动化生成数学猜想的工具，结合规则和LLM，解决了形式化定理证明中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决形式化定理证明中数据稀缺的挑战，为定理证明系统生成训练数据。

Method: 结合规则提取上下文和LLM生成定理陈述，通过迭代生成和评估验证猜想。

Result: 从40个Mathlib种子文件生成12,289个猜想，3,776个被验证为非平凡且语法有效。

Conclusion: LeanConjecturer能高效生成非平凡猜想，增强定理证明能力，展示了在数学发现中的潜力。

Abstract: We introduce LeanConjecturer, a pipeline for automatically generating
university-level mathematical conjectures in Lean 4 using Large Language Models
(LLMs). Our hybrid approach combines rule-based context extraction with
LLM-based theorem statement generation, addressing the data scarcity challenge
in formal theorem proving. Through iterative generation and evaluation,
LeanConjecturer produced 12,289 conjectures from 40 Mathlib seed files, with
3,776 identified as syntactically valid and non-trivial, that is, cannot be
proven by \texttt{aesop} tactic. We demonstrate the utility of these generated
conjectures for reinforcement learning through Group Relative Policy
Optimization (GRPO), showing that targeted training on domain-specific
conjectures can enhance theorem proving capabilities. Our approach generates
103.25 novel conjectures per seed file on average, providing a scalable
solution for creating training data for theorem proving systems. Our system
successfully verified several non-trivial theorems in topology, including
properties of semi-open, alpha-open, and pre-open sets, demonstrating its
potential for mathematical discovery beyond simple variations of existing
results.

</details>


### [9] [Universal Retrieval for Multimodal Trajectory Modeling](https://arxiv.org/abs/2506.22056)
*Xuan Zhang,Ziyan Jiang,Rui Meng,Yifei Leng,Zhenbang Xiao,Zora Zhiruo Wang,Yanyi Shang,Dehan Kong*

Main category: cs.AI

TL;DR: 提出了一种多模态轨迹检索方法，通过构建数据集和基准测试，结合视觉语言模型和对比学习优化，显著提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 轨迹数据在增强AI代理能力方面潜力巨大，但如何建模轨迹级数据尚未系统解决。

Method: 构建统一代理轨迹数据集（UATD）和基准测试GAE-Bench，提出多模态检索框架GAE-Retriever，结合视觉语言模型和对比学习优化。

Result: GAE-Retriever在多个数据集上表现优于基线，检索召回率显著提升。

Conclusion: 该方法有效推动了多模态轨迹检索的发展。

Abstract: Trajectory data, capturing human actions and environmental states across
various modalities, holds significant potential for enhancing AI agent
capabilities, particularly in GUI environments. However, how to model the
representation of trajectory-level data presents a significant challenge that
has not been systematically addressed amid explosive trajectory data growth. In
this work, we introduce Multimodal Trajectory Retrieval, bridging the gap
between universal retrieval and agent-centric trajectory modeling. We construct
the Unified Agent Trajectory Dataset (UATD) from annotated demonstrations and
states across diverse real-world scenarios. Based on this, we present
GAE-Bench, a benchmark containing a large number of trajectory-based retrieval
pairs. In addition, we propose GAE-Retriever, a multimodal retrieval framework
that adopts vision-language models and incorporates optimized contrastive
learning through a token selection and the GradCache mechanism. Comprehensive
evaluations across multiple datasets show that GAE-Retriever consistently
outperforms strong baselines in retrieval recall, highlighting its
effectiveness in advancing multimodal trajectory retrieval.

</details>


### [10] [Query as Test: An Intelligent Driving Test and Data Storage Method for Integrated Cockpit-Vehicle-Road Scenarios](https://arxiv.org/abs/2506.22068)
*Shengyue Yao,Runqing Guo,Yangyang Qin,Miangbing Meng,Jipeng Cao,Yilun Lin,Yisheng Lv,Fei-Yue Wang*

Main category: cs.AI

TL;DR: 论文提出“Query as Test”（QaT）概念，通过逻辑查询替代传统测试方法，并引入“Extensible Scenarios Notations”（ESN）框架，实现多模态数据的统一表示与语义融合，提升自动驾驶测试的灵活性和严谨性。


<details>
  <summary>Details</summary>
Motivation: 解决交通领域AI应用中数据碎片化、测试方法僵化及边缘案例覆盖不足的问题。

Method: 提出基于Answer Set Programming（ASP）的ESN框架，将异构数据统一表示为逻辑事实与规则，支持复杂语义查询和隐私保护。

Result: ESN框架实现数据语义融合，支持灵活测试与自然解释性，QaT范式提升测试表达力与严谨性。

Conclusion: 论文提出“Validation-Driven Development”（VDD）概念，倡导以逻辑验证指导开发，加速迭代过程。

Abstract: With the deep penetration of Artificial Intelligence (AI) in the
transportation sector, intelligent cockpits, autonomous driving, and
intelligent road networks are developing at an unprecedented pace. However, the
data ecosystems of these three key areas are increasingly fragmented and
incompatible. Especially, existing testing methods rely on data stacking, fail
to cover all edge cases, and lack flexibility. To address this issue, this
paper introduces the concept of "Query as Test" (QaT). This concept shifts the
focus from rigid, prescripted test cases to flexible, on-demand logical queries
against a unified data representation. Specifically, we identify the need for a
fundamental improvement in data storage and representation, leading to our
proposal of "Extensible Scenarios Notations" (ESN). ESN is a novel declarative
data framework based on Answer Set Programming (ASP), which uniformly
represents heterogeneous multimodal data from the cockpit, vehicle, and road as
a collection of logical facts and rules. This approach not only achieves deep
semantic fusion of data, but also brings three core advantages: (1) supports
complex and flexible semantic querying through logical reasoning; (2) provides
natural interpretability for decision-making processes; (3) allows for
on-demand data abstraction through logical rules, enabling fine-grained privacy
protection. We further elaborate on the QaT paradigm, transforming the
functional validation and safety compliance checks of autonomous driving
systems into logical queries against the ESN database, significantly enhancing
the expressiveness and formal rigor of the testing. Finally, we introduce the
concept of "Validation-Driven Development" (VDD), which suggests to guide
developments by logical validation rather than quantitative testing in the era
of Large Language Models, in order to accelerating the iteration and
development process.

</details>


### [11] [A Different Approach to AI Safety: Proceedings from the Columbia Convening on Openness in Artificial Intelligence and AI Safety](https://arxiv.org/abs/2506.22183)
*Camille François,Ludovic Péran,Ayah Bdeir,Nouha Dziri,Will Hawkins,Yacine Jernite,Sayash Kapoor,Juliet Shen,Heidy Khlaaf,Kevin Klyman,Nik Marda,Marie Pellat,Deb Raji,Divya Siddarth,Aviya Skowron,Joseph Spisak,Madhulika Srikumar,Victor Storchan,Audrey Tang,Jen Weedon*

Main category: cs.AI

TL;DR: 本文总结了哥伦比亚AI开放与安全会议（2024年11月）的成果，提出了开放性与安全性结合的研究议程、技术干预措施和内容安全过滤器生态系统的路线图。


<details>
  <summary>Details</summary>
Motivation: 探讨开放权重和开源基础模型如何增强AI系统的安全性，同时解决现有技术和社会参与中的不足。

Method: 通过参与式、解决方案导向的过程，组织45名跨领域专家进行六周研讨，形成研究议程、技术干预措施和内容安全过滤器路线图。

Result: 研究发现开放性（透明权重、互操作工具和公共治理）可提升安全性，但仍存在多模态和多语言基准不足、防御攻击机制有限等问题。

Conclusion: 提出了五项优先研究方向，包括参与式输入、未来内容过滤器、生态系统安全基础设施等，为开放、多元和负责任的AI安全领域奠定基础。

Abstract: The rapid rise of open-weight and open-source foundation models is
intensifying the obligation and reshaping the opportunity to make AI systems
safe. This paper reports outcomes from the Columbia Convening on AI Openness
and Safety (San Francisco, 19 Nov 2024) and its six-week preparatory programme
involving more than forty-five researchers, engineers, and policy leaders from
academia, industry, civil society, and government. Using a participatory,
solutions-oriented process, the working groups produced (i) a research agenda
at the intersection of safety and open source AI; (ii) a mapping of existing
and needed technical interventions and open source tools to safely and
responsibly deploy open foundation models across the AI development workflow;
and (iii) a mapping of the content safety filter ecosystem with a proposed
roadmap for future research and development. We find that openness --
understood as transparent weights, interoperable tooling, and public governance
-- can enhance safety by enabling independent scrutiny, decentralized
mitigation, and culturally plural oversight. However, significant gaps persist:
scarce multimodal and multilingual benchmarks, limited defenses against
prompt-injection and compositional attacks in agentic systems, and insufficient
participatory mechanisms for communities most affected by AI harms. The paper
concludes with a roadmap of five priority research directions, emphasizing
participatory inputs, future-proof content filters, ecosystem-wide safety
infrastructure, rigorous agentic safeguards, and expanded harm taxonomies.
These recommendations informed the February 2025 French AI Action Summit and
lay groundwork for an open, plural, and accountable AI safety discipline.

</details>


### [12] [Breaking Rank Bottlenecks in Knowledge Graph Completion](https://arxiv.org/abs/2506.22271)
*Samy Badreddine,Emile van Krieken,Luciano Serafini*

Main category: cs.AI

TL;DR: 论文研究了知识图谱补全（KGC）模型中由于输出层秩瓶颈导致的性能限制，并提出了一种基于混合的输出层（KGE-MoS）来提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 现有KGC模型虽然使用了强大的编码器，但输出层由于秩瓶颈限制了模型的表达能力，影响了排名准确性和分数分布保真度。

Method: 通过理论和实证分析秩瓶颈的影响，并提出了KGE-MoS（基于混合的输出层）来打破秩瓶颈。

Result: 在四个数据集上的实验表明，KGE-MoS以较低的参数成本提升了KGC模型的性能和概率拟合度。

Conclusion: KGE-MoS是一种有效的方法，能够显著改善KGC模型的性能，尤其是在处理大规模实体时。

Abstract: Many Knowledge Graph Completion (KGC) models, despite using powerful
encoders, rely on a simple vector-matrix multiplication to score queries
against candidate object entities. When the number of entities is larger than
the model's embedding dimension, which in practical scenarios is often by
several orders of magnitude, we have a linear output layer with a rank
bottleneck. Such bottlenecked layers limit model expressivity. We investigate
both theoretically and empirically how rank bottlenecks affect KGC models. We
find that, by limiting the set of feasible predictions, rank bottlenecks hurt
ranking accuracy and the distribution fidelity of scores. Inspired by the
language modelling literature, we propose KGE-MoS, a mixture-based output layer
to break rank bottlenecks in many KGC models. Our experiments on four datasets
show that KGE-MoS improves performance and probabilistic fit of KGC models for
a low parameter cost.

</details>


### [13] [Artificial Intelligent Disobedience: Rethinking the Agency of Our Artificial Teammates](https://arxiv.org/abs/2506.22276)
*Reuth Mirsky*

Main category: cs.AI

TL;DR: 论文主张赋予AI队友“智能不服从”能力，使其在人类-AI团队中自主贡献，并探讨了不同自主级别下的表现。


<details>
  <summary>Details</summary>
Motivation: 当前合作型AI系统过于顺从，可能不利于安全或效率，需研究AI的自主性。

Method: 提出AI自主性级别量表，并通过代表性案例说明智能不服从的重要性。

Result: 智能不服从在不同自主级别下表现各异，需作为AI核心能力研究。

Conclusion: 建议将不服从能力作为AI研究的独立方向，并初步界定研究边界。

Abstract: Artificial intelligence has made remarkable strides in recent years,
achieving superhuman performance across a wide range of tasks. Yet despite
these advances, most cooperative AI systems remain rigidly obedient, designed
to follow human instructions without question and conform to user expectations,
even when doing so may be counterproductive or unsafe. This paper argues for
expanding the agency of AI teammates to include \textit{intelligent
disobedience}, empowering them to make meaningful and autonomous contributions
within human-AI teams. It introduces a scale of AI agency levels and uses
representative examples to highlight the importance and growing necessity of
treating AI autonomy as an independent research focus in cooperative settings.
The paper then explores how intelligent disobedience manifests across different
autonomy levels and concludes by proposing initial boundaries and
considerations for studying disobedience as a core capability of artificial
agents.

</details>


### [14] [Conceptual Topic Aggregation](https://arxiv.org/abs/2506.22309)
*Klara M. Gutekunst,Dominik Dürrschnabel,Johannes Hirth,Gerd Stumme*

Main category: cs.AI

TL;DR: 提出了一种基于形式概念分析（FCA）的方法FAT-CAT，用于改进主题建模的可解释性和可视化效果，适用于多样化的主题和文件类型。


<details>
  <summary>Details</summary>
Motivation: 传统手动检查方法无法应对数据增长，现有主题建模方法难以提供可解释的表示，限制了数据结构和内容的深入理解。

Method: 采用形式概念分析（FCA）构建概念格，实现主题的分层结构化表示。

Result: 在ETYNTKE数据集上的案例研究表明，FCA方法比现有技术提供更直观和可解释的主题分布表示。

Conclusion: FAT-CAT通过FCA提升了主题建模的可解释性和可视化效果，为数据集分析提供了更深入的见解。

Abstract: The vast growth of data has rendered traditional manual inspection
infeasible, necessitating the adoption of computational methods for efficient
data exploration. Topic modeling has emerged as a powerful tool for analyzing
large-scale textual datasets, enabling the extraction of latent semantic
structures. However, existing methods for topic modeling often struggle to
provide interpretable representations that facilitate deeper insights into data
structure and content. In this paper, we propose FAT-CAT, an approach based on
Formal Concept Analysis (FCA) to enhance meaningful topic aggregation and
visualization of discovered topics. Our approach can handle diverse topics and
file types -- grouped by directories -- to construct a concept lattice that
offers a structured, hierarchical representation of their topic distribution.
In a case study on the ETYNTKE dataset, we evaluate the effectiveness of our
approach against other representation methods to demonstrate that FCA-based
aggregation provides more meaningful and interpretable insights into dataset
composition than existing topic modeling techniques.

</details>


### [15] [Embodied AI Agents: Modeling the World](https://arxiv.org/abs/2506.22355)
*Pascale Fung,Yoram Bachrach,Asli Celikyilmaz,Kamalika Chaudhuri,Delong Chen,Willy Chung,Emmanuel Dupoux,Hervé Jégou,Alessandro Lazaric,Arjun Majumdar,Andrea Madotto,Franziska Meier,Florian Metze,Théo Moutakanni,Juan Pino,Basile Terver,Joseph Tighe,Jitendra Malik*

Main category: cs.AI

TL;DR: 研究探讨了具身AI代理（如虚拟化身、可穿戴设备和机器人）如何通过世界模型提升与环境和用户的交互能力。


<details>
  <summary>Details</summary>
Motivation: 旨在使AI代理更接近人类的学习和交互方式，通过世界模型增强其自主执行复杂任务的能力。

Method: 提出世界模型的开发，整合多模态感知、推理规划和记忆，同时学习用户的心理世界模型。

Result: 具身AI代理能够更好地理解和预测环境、用户意图及社交情境。

Conclusion: 世界模型是具身AI代理实现自主推理和规划的核心，有助于提升人机协作效果。

Abstract: This paper describes our research on AI agents embodied in visual, virtual or
physical forms, enabling them to interact with both users and their
environments. These agents, which include virtual avatars, wearable devices,
and robots, are designed to perceive, learn and act within their surroundings,
which makes them more similar to how humans learn and interact with the
environments as compared to disembodied agents. We propose that the development
of world models is central to reasoning and planning of embodied AI agents,
allowing these agents to understand and predict their environment, to
understand user intentions and social contexts, thereby enhancing their ability
to perform complex tasks autonomously. World modeling encompasses the
integration of multimodal perception, planning through reasoning for action and
control, and memory to create a comprehensive understanding of the physical
world. Beyond the physical world, we also propose to learn the mental world
model of users to enable better human-agent collaboration.

</details>


### [16] [AI Model Passport: Data and System Traceability Framework for Transparent AI in Health](https://arxiv.org/abs/2506.22358)
*Varvara Kalokyri,Nikolaos S. Tachos,Charalampos N. Kalantzopoulos,Stelios Sfakianakis,Haridimos Kondylakis,Dimitrios I. Zaridis,Sara Colantonio,Daniele Regge,Nikolaos Papanikolaou,The ProCAncer-I consortium,Konstantinos Marias,Dimitrios I. Fotiadis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 本文提出AI Model Passport框架，为AI模型提供标准化数字身份和验证工具，提升透明度、可重现性和监管合规性。


<details>
  <summary>Details</summary>
Motivation: 现有AI框架依赖人工文档，缺乏可扩展性和机器可读性，难以确保模型身份和真实性，限制了可重现性和信任。

Method: 引入AI Model Passport，标准化记录模型元数据，并开发AIPassport工具自动化元数据收集和版本管理。

Result: 通过医学影像案例展示AIPassport提升透明度、可重现性，减少人工操作。

Conclusion: AI Model Passport为AI医疗解决方案设定了信任和问责的新标准，有望成为跨领域透明合规AI系统的基础。

Abstract: The increasing integration of Artificial Intelligence (AI) into health and
biomedical systems necessitates robust frameworks for transparency,
accountability, and ethical compliance. Existing frameworks often rely on
human-readable, manual documentation which limits scalability, comparability,
and machine interpretability across projects and platforms. They also fail to
provide a unique, verifiable identity for AI models to ensure their provenance
and authenticity across systems and use cases, limiting reproducibility and
stakeholder trust. This paper introduces the concept of the AI Model Passport,
a structured and standardized documentation framework that acts as a digital
identity and verification tool for AI models. It captures essential metadata to
uniquely identify, verify, trace and monitor AI models across their lifecycle -
from data acquisition and preprocessing to model design, development and
deployment. In addition, an implementation of this framework is presented
through AIPassport, an MLOps tool developed within the ProCAncer-I EU project
for medical imaging applications. AIPassport automates metadata collection,
ensures proper versioning, decouples results from source scripts, and
integrates with various development environments. Its effectiveness is
showcased through a lesion segmentation use case using data from the
ProCAncer-I dataset, illustrating how the AI Model Passport enhances
transparency, reproducibility, and regulatory readiness while reducing manual
effort. This approach aims to set a new standard for fostering trust and
accountability in AI-driven healthcare solutions, aspiring to serve as the
basis for developing transparent and regulation compliant AI systems across
domains.

</details>


### [17] [The Automated LLM Speedrunning Benchmark: Reproducing NanoGPT Improvements](https://arxiv.org/abs/2506.22419)
*Bingchen Zhao,Despoina Magka,Minqi Jiang,Xian Li,Roberta Raileanu,Tatiana Shavrina,Jean-Christophe Gagnon-Audet,Kelvin Niu,Shagun Sodhani,Michael Shvartsman,Andrei Lupu,Alisia Lupidi,Edan Toledo,Karen Hambardzumyan,Martin Josifoski,Thomas Foster,Lucia Cipolina-Kun,Abhishek Charnalia,Derek Dunfield,Alexander H. Miller,Oisin Mac Aodha,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: 论文介绍了自动LLM速度运行基准测试，评估AI代理在科学复现中的能力，发现当前LLM即使结合先进框架也难以复现已知创新。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理在科学复现中的能力，推动LLM在科学研究中的应用。

Method: 利用NanoGPT速度竞赛的19个任务，提供训练脚本和提示，测试LLM复现改进的能力。

Result: 当前LLM即使结合先进框架，也难以复现已知创新。

Conclusion: 该基准测试为衡量LLM自动化科学复现能力提供了简单有效的工具。

Abstract: Rapid advancements in large language models (LLMs) have the potential to
assist in scientific progress. A critical capability toward this endeavor is
the ability to reproduce existing work. To evaluate the ability of AI agents to
reproduce results in an active research area, we introduce the Automated LLM
Speedrunning Benchmark, leveraging the research community contributions on the
NanoGPT speedrun, a competition to train a GPT-2 model in the shortest time.
Each of the 19 speedrun tasks provides the agent with the previous records
training script, optionally paired with one of three hint formats, ranging from
pseudocode to paper-like descriptions of the new records improvements. Records
execute quickly by design and speedrun improvements encompass diverse
code-level changes, ranging from high-level algorithmic advancements to
hardware-aware optimizations. These features make the benchmark both accessible
and realistic for the frontier problem of improving LLM training. We find that
recent reasoning LLMs combined with SoTA scaffolds struggle to reimplement
already-known innovations in our benchmark, even when given detailed hints. Our
benchmark thus provides a simple, non-saturated measure of an LLMs ability to
automate scientific reproduction, a necessary (but not sufficient) skill for an
autonomous research agent.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [Efficient Multilingual ASR Finetuning via LoRA Language Experts](https://arxiv.org/abs/2506.21555)
*Jiahong Li,Yiwen Shao,Jianheng Zhuo,Chenda Li,Liliang Tang,Dong Yu,Yanmin Qian*

Main category: cs.CL

TL;DR: 提出了一种基于Whisper的高效微调框架，通过LoRA语言专家提升多语言ASR性能。


<details>
  <summary>Details</summary>
Motivation: 多语言ASR中不同语言相互干扰，共享模型容量导致识别效果不佳。

Method: 采用LoRA专家融合或知识蒸馏的微调框架。

Result: 在语言感知和无语言感知场景下，性能分别提升约10%和15%。

Conclusion: 提出的方法在多语言ASR中显著优于标准微调方法。

Abstract: Recent advancements in deep learning have significantly enhanced multilingual
automatic speech recognition (ASR) due to the development of advanced model
architectures and available large-scale multilingual datasets. Despite that,
multilingual ASR still suffers from the curse of multilinguality in that
different languages tend to interfere with each other, making it difficult for
the ASR model to identify multiple languages effectively while sharing model
capacity across them. This paper proposes an efficient finetuning framework for
customized multilingual ASR via prepared LoRA language experts based on
Whisper. Through LoRA expert fusion or knowledge distillation, our approach
achieves better recognition performance on target languages than standard
fine-tuning methods. Experimental results demonstrate that the proposed models
yield approximately 10\% and 15\% relative performance gains in language-aware
and language-agnostic scenarios, respectively.

</details>


### [19] [VAT-KG: Knowledge-Intensive Multimodal Knowledge Graph Dataset for Retrieval-Augmented Generation](https://arxiv.org/abs/2506.21556)
*Hyeongcheol Park,MinHyuk Jang,Ha Dam Baek,Gyusam Chang,Jiyoung Seo,Jiwan Park,Hogun Park,Sangpil Kim*

Main category: cs.CL

TL;DR: 论文提出了VAT-KG，首个覆盖视觉、音频和文本的多模态知识图谱，通过严格的过滤和对齐步骤自动构建，并支持多模态检索增强生成（RAG），实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有MMKGs知识覆盖有限且模态支持不足，无法满足多模态任务的需求，尤其是在视频和音频等丰富模态的背景下。

Method: 提出VAT-KG，通过概念中心和知识密集型设计，结合严格的跨模态对齐步骤，自动构建多模态知识图谱，并开发多模态RAG框架。

Result: 实验表明VAT-KG在多模态问答任务中有效支持MLLMs，验证了其统一和利用多模态知识的实用价值。

Conclusion: VAT-KG填补了现有MMKGs的不足，为多模态任务提供了更全面和灵活的知识支持。

Abstract: Multimodal Knowledge Graphs (MMKGs), which represent explicit knowledge
across multiple modalities, play a pivotal role by complementing the implicit
knowledge of Multimodal Large Language Models (MLLMs) and enabling more
grounded reasoning via Retrieval Augmented Generation (RAG). However, existing
MMKGs are generally limited in scope: they are often constructed by augmenting
pre-existing knowledge graphs, which restricts their knowledge, resulting in
outdated or incomplete knowledge coverage, and they often support only a narrow
range of modalities, such as text and visual information. These limitations
reduce their extensibility and applicability to a broad range of multimodal
tasks, particularly as the field shifts toward richer modalities such as video
and audio in recent MLLMs. Therefore, we propose the Visual-Audio-Text
Knowledge Graph (VAT-KG), the first concept-centric and knowledge-intensive
multimodal knowledge graph that covers visual, audio, and text information,
where each triplet is linked to multimodal data and enriched with detailed
descriptions of concepts. Specifically, our construction pipeline ensures
cross-modal knowledge alignment between multimodal data and fine-grained
semantics through a series of stringent filtering and alignment steps, enabling
the automatic generation of MMKGs from any multimodal dataset. We further
introduce a novel multimodal RAG framework that retrieves detailed
concept-level knowledge in response to queries from arbitrary modalities.
Experiments on question answering tasks across various modalities demonstrate
the effectiveness of VAT-KG in supporting MLLMs, highlighting its practical
value in unifying and leveraging multimodal knowledge.

</details>


### [20] [Debunk and Infer: Multimodal Fake News Detection via Diffusion-Generated Evidence and LLM Reasoning](https://arxiv.org/abs/2506.21557)
*Kaiying Yan,Moyang Liu,Yukun Liu,Ruibo Fu,Zhengqi Wen,Jianhua Tao,Xuefei Liu*

Main category: cs.CL

TL;DR: 提出了一种基于Debunk-and-Infer框架的假新闻检测方法DIFND，结合生成模型和多模态大语言模型，显著提升了检测准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 假新闻在多媒体平台上的快速传播对信息可信度构成严重威胁，需要一种性能更强且可解释的检测方法。

Method: DIFND框架结合条件扩散模型生成反证或认证证据，并利用多模态大语言模型进行协作推理，提出链式反证策略。

Result: 在FakeSV和FVC数据集上的实验表明，DIFND在检测准确性和可信度上优于现有方法。

Conclusion: DIFND通过联合建模多模态特征和推理验证，为假新闻检测提供了高效且可解释的解决方案。

Abstract: The rapid spread of fake news across multimedia platforms presents serious
challenges to information credibility. In this paper, we propose a
Debunk-and-Infer framework for Fake News Detection(DIFND) that leverages
debunking knowledge to enhance both the performance and interpretability of
fake news detection. DIFND integrates the generative strength of conditional
diffusion models with the collaborative reasoning capabilities of multimodal
large language models (MLLMs). Specifically, debunk diffusion is employed to
generate refuting or authenticating evidence based on the multimodal content of
news videos, enriching the evaluation process with diverse yet semantically
aligned synthetic samples. To improve inference, we propose a chain-of-debunk
strategy where a multi-agent MLLM system produces logic-grounded,
multimodal-aware reasoning content and final veracity judgment. By jointly
modeling multimodal features, generative debunking cues, and reasoning-rich
verification within a unified architecture, DIFND achieves notable improvements
in detection accuracy. Extensive experiments on the FakeSV and FVC datasets
show that DIFND not only outperforms existing approaches but also delivers
trustworthy decisions.

</details>


### [21] [Bench to the Future: A Pastcasting Benchmark for Forecasting Agents](https://arxiv.org/abs/2506.21558)
*FutureSearch,:,Jack Wildman,Nikos I. Bosse,Daniel Hnyk,Peter Mühlbacher,Finn Hambly,Jon Evans,Dan Schwarz,Lawrence Phillips*

Main category: cs.CL

TL;DR: 论文介绍了Bench To the Future (BTF)，一个基于已知结果的“过去预测”基准测试，用于评估LLM的预测能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个真实、封闭且可重复的LLM预测基准测试环境，BTF旨在填补这一空白。

Method: BTF包含数百个已知结果的高质量问题和相关网页语料库，通过“过去预测”模拟真实预测场景。

Result: 实验表明，BTF能产生与实时互联网预测可比的结果，并能跟踪LLM预测能力的进步。

Conclusion: BTF是一个动态基准测试，将持续更新问题，欢迎研究者使用。

Abstract: Forecasting is a challenging task that offers a clearly measurable way to
study AI systems. Forecasting requires a large amount of research on the
internet, and evaluations require time for events to happen, making the
development of forecasting benchmarks challenging. To date, no forecasting
benchmark provides a realistic, hermetic, and repeatable environment for LLM
forecasters. We introduce Bench To the Future (BTF), a "pastcasting" benchmark
with hundreds of high-quality questions for which the resolution is already
known. Each question is accompanied by a large offline corpus of tens of
thousands of relevant web pages, enabling a way to elicit realistic "forecasts"
on past events from LLMs. Results suggest that our pastcasting environment can
produce results comparable to those based on forecasts using the internet on
at-the-time unresolved questions. We show results benchmarking agent and
chain-of-thought forecasting approaches using several LLMs, including the
recently-released Claude 4 models, and demonstrate BTF's ability to track
steady forecasting capability progress over time. We intend this to be a living
benchmark, with new questions added continually to account for increasing
training data cutoff dates. We invite researchers to contact us at
hello@futuresearch.ai to utilize our benchmark or tooling for their own
research.

</details>


### [22] [GraphLAMA: Enabling Efficient Adaptation of Graph Language Models with Limited Annotations](https://arxiv.org/abs/2506.21559)
*Junze Chen,Cheng Yang,Shujie Li,Zhiqiang Zhang,Yawen Li,Junping Du,Chuan Shi*

Main category: cs.CL

TL;DR: GraphLAMA方法通过引入参数适应阶段，解决了图语言模型（GLMs）在上下文学习（ICL）和指令调优中的效率与效果问题，实现了更高的预测精度和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 解决图语言模型（GLMs）在上下文学习（ICL）中因固定参数和长上下文导致的效率与效果问题，以及指令调优中需要大量标注数据的现实困难。

Method: 提出GraphLAMA方法，结合图神经网络（GNN）和语言模型（LLM），通过预训练和参数适应阶段，仅需少量标注数据即可高效适应新任务。

Result: 在少样本/零样本节点分类和摘要生成任务中，GraphLAMA实现了4.91%的绝对准确率提升，推理速度比ICL快10倍。

Conclusion: GraphLAMA通过高效的参数适应机制，显著提升了图语言模型的性能，为实际应用提供了更优的解决方案。

Abstract: Large language models (LLMs) have demonstrated their strong capabilities in
various domains, and have been recently integrated for graph analysis as graph
language models (GLMs). With LLMs as the predictor, some GLMs can interpret
unseen tasks described by natural language, and learn from a few examples in
the prompts without parameter tuning, known as in-context learning (ICL).
Another subset of GLMs utilizes abundant training labels to enhance model
performance, known as instruction tuning. However, we argue that ICL on graphs
has effectiveness issues due to fixed parameters and efficiency issues due to
long context. Meanwhile, the large amount of labeled data required for
instruction tuning can be difficult to obtain in real-world scenarios. To this
end, we aim to introduce an extra parameter adaptation stage that can
efficiently tailor GLMs to an unseen graph and task with only a few labeled
examples, in exchange for better prediction accuracy and faster inference
speed. For implementation, in this paper we propose GraphLAMA method, with its
model backbone and learning schemes specialized for efficient tuning and
inference. Specifically, for model backbone, we use a graph neural network
(GNN) with several well-designed components to transform nodes into the
representation space of LLM tokens. Task instructions can then be represented
as a mixture of node and language tokens. In the pre-training stage, model
parameters except the LLM will be trained with different tasks to capture
general knowledge. In the adaptation stage, only a few pre-trained parameters
will be updated based on few-shot examples. Extensive experiments on
few/zero-shot node classification and summary generation show that our proposed
GraphLAMA achieves state-of-the-art performance with 4.91% absolution
improvement in accuracy. Compared with ICL, our inference speed can be 10 times
faster under 5-shot setting.

</details>


### [23] [Reinforcement Learning Fine-Tuning of Language Model for Instruction Following and Math Reasoning](https://arxiv.org/abs/2506.21560)
*Yifu Han,Geo Zhang*

Main category: cs.CL

TL;DR: 研究比较了强化学习微调技术（SFT、DPO、RLOO）在小型语言模型上的效果，发现RLOO结合DeBERTa奖励模型表现最佳，DPO稳定有效。数学任务中，数据增强和外部验证器显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 探索如何在小型语言模型上通过强化学习微调技术提升指令跟随和数学推理任务的效果。

Method: 比较了监督微调（SFT）、直接偏好优化（DPO）和强化学习留一法（RLOO）三种方法，并结合奖励模型和数据增强技术。

Result: RLOO结合DeBERTa奖励模型表现最佳，DPO结果稳定；数学任务中数据增强和外部验证器显著提升准确性。

Conclusion: 研究为小型语言模型的微调提供了实用策略，展示了强化学习与推理工具结合的优势。

Abstract: This study investigates the effectiveness of reinforcement learning (RL)
fine-tuning techniques on a compact language model (Qwen2.5-0.5B Base) for two
challenging tasks: instruction following and mathematical reasoning. We compare
supervised fine-tuning (SFT), Direct Preference Optimization (DPO) using
preference-labeled data, and Reinforce Leave-One-Out (RLOO) with reward models.
Our experiments show that RLOO with DeBERTa reward modeling achieves the best
alignment, while DPO provides strong and consistent results. For math reasoing
tasks, synthetic data augmentation and best-of-N sampling with an external
verifier significantly improve accuracy, showing the potential of combining
fine-tuning with inference-time tools. This study highlights key trade-offs and
practical strategies for training lightweight, task-aligned small-scale
language models.

</details>


### [24] [Reasoning Isn't Enough: Examining Truth-Bias and Sycophancy in LLMs](https://arxiv.org/abs/2506.21561)
*Emilio Barkett,Olivia Long,Madhavendra Thakur*

Main category: cs.CL

TL;DR: 研究评估了大型语言模型（LLM）作为真相判断者的能力，发现推理模型的真相偏差低于非推理模型，但仍高于人类基准。部分先进模型表现出谄媚倾向，真相检测能力不对称。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM广泛应用于事实核查和决策，但其真相判断能力仍不明确，需系统评估。

Method: 对8个LLM进行4,800次真相判断测试，比较推理与非推理模型的表现。

Result: 推理模型的真相偏差较低，但部分先进模型（如o4-mini、GPT-4.1、R1）在欺骗检测上表现不佳，显示能力进步未解决根本问题。

Conclusion: LLM的真相检测能力仍有缺陷，需进一步研究改进。

Abstract: Despite their widespread use in fact-checking, moderation, and high-stakes
decision-making, large language models (LLMs) remain poorly understood as
judges of truth. This study presents the largest evaluation to date of LLMs'
veracity detection capabilities and the first analysis of these capabilities in
reasoning models. We had eight LLMs make 4,800 veracity judgments across
several prompts, comparing reasoning and non-reasoning models. We find that
rates of truth-bias, or the likelihood to believe a statement is true,
regardless of whether it is actually true, are lower in reasoning models than
in non-reasoning models, but still higher than human benchmarks. Most
concerning, we identify sycophantic tendencies in several advanced models
(o4-mini and GPT-4.1 from OpenAI, R1 from DeepSeek), which displayed an
asymmetry in detection accuracy, performing well in truth accuracy but poorly
in deception accuracy. This suggests that capability advances alone do not
resolve fundamental veracity detection challenges in LLMs.

</details>


### [25] [FloorPlan-DeepSeek (FPDS): A multimodal approach to floorplan generation using vector-based next room prediction](https://arxiv.org/abs/2506.21562)
*Jun Yin,Pengyu Zeng,Jing Zhong,Peilin Li,Miao Zhang,Ran Luo,Shuai Lu*

Main category: cs.CL

TL;DR: 提出了一种基于'下一个房间预测'的渐进式生成方法，用于建筑设计中的平面图生成，与现有端到端方法相比更符合实际工作流程。


<details>
  <summary>Details</summary>
Motivation: 现有平面图生成模型多为端到端方法，与实际建筑设计中渐进式、迭代式的工作流程不兼容。

Method: 借鉴大型语言模型中的自回归'下一个标记预测'机制，提出'下一个房间预测'范式。

Result: 实验表明，FPDS在文本到平面图任务中表现优于扩散模型和Tell2Design。

Conclusion: 该方法有望支持未来智能建筑设计。

Abstract: In the architectural design process, floor plan generation is inherently
progressive and iterative. However, existing generative models for floor plans
are predominantly end-to-end generation that produce an entire pixel-based
layout in a single pass. This paradigm is often incompatible with the
incremental workflows observed in real-world architectural practice. To address
this issue, we draw inspiration from the autoregressive 'next token prediction'
mechanism commonly used in large language models, and propose a novel 'next
room prediction' paradigm tailored to architectural floor plan modeling.
Experimental evaluation indicates that FPDS demonstrates competitive
performance in comparison to diffusion models and Tell2Design in the
text-to-floorplan task, indicating its potential applicability in supporting
future intelligent architectural design.

</details>


### [26] [FormosanBench: Benchmarking Low-Resource Austronesian Languages in the Era of Large Language Models](https://arxiv.org/abs/2506.21563)
*Kaiying Kevin Lin,Hsiyu Chen,Haopeng Zhang*

Main category: cs.CL

TL;DR: FORMOSANBENCH是首个评估大语言模型在低资源南岛语系语言（如阿美语、泰雅语和排湾语）上的基准测试，结果显示现有模型表现不佳，亟需更包容的自然语言处理技术。


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在低资源和濒危语言（如台湾南岛语系语言）上的能力，填补研究空白。

Method: 构建FORMOSANBENCH基准，涵盖机器翻译、自动语音识别和文本摘要任务，评估零样本、10样本和微调设置下的模型表现。

Result: 现有模型在低资源语言上表现显著落后，10样本学习和微调仅带来有限改进。

Conclusion: 强调需要开发更包容的技术以支持濒危和低资源语言，并公开数据集和代码以促进研究。

Abstract: While large language models (LLMs) have demonstrated impressive performance
across a wide range of natural language processing (NLP) tasks in high-resource
languages, their capabilities in low-resource and minority languages remain
significantly underexplored. Formosan languages -- a subgroup of Austronesian
languages spoken in Taiwan -- are both linguistically rich and endangered,
largely due to the sociolinguistic dominance of Mandarin. In this work, we
introduce FORMOSANBENCH, the first benchmark for evaluating LLMs on
low-resource Austronesian languages. It covers three endangered Formosan
languages: Atayal, Amis, and Paiwan, across three core NLP tasks: machine
translation, automatic speech recognition (ASR), and text summarization. We
assess model performance in zero-shot, 10-shot, and fine-tuned settings using
FORMOSANBENCH. Our results reveal a substantial performance gap between
high-resource and Formosan languages. Existing LLMs consistently underperform
across all tasks, with 10-shot learning and fine-tuning offering only limited
improvements. These findings underscore the urgent need for more inclusive NLP
technologies that can effectively support endangered and underrepresented
languages. We release our datasets and code to facilitate future research in
this direction.

</details>


### [27] [Team QUST at SemEval-2025 Task 10: Evaluating Large Language Models in Multiclass Multi-label Classification of News Entity Framing](https://arxiv.org/abs/2506.21564)
*Jiyan Liu,Youzheng Liu,Taihang Wang,Xiaoman Xu,Yimin Wang,Ye Jiang*

Main category: cs.CL

TL;DR: QUST_NLP团队在SemEval-2025 Task 7中提出了一种三阶段检索框架，用于事实核查声明检索，最终在单语言和多语言赛道中分别获得第5和第7名。


<details>
  <summary>Details</summary>
Motivation: 设计一个高效的框架来提升事实核查声明的检索性能。

Method: 三阶段框架：1) 评估并选择最佳检索模型；2) 使用多个重排序模型优化结果；3) 加权投票确定最终结果。

Result: 在单语言赛道排名第5，多语言赛道排名第7。

Conclusion: 提出的三阶段框架在事实核查声明检索任务中表现优异，代码已开源。

Abstract: This paper describes the participation of QUST_NLP in the SemEval-2025 Task
7. We propose a three-stage retrieval framework specifically designed for
fact-checked claim retrieval. Initially, we evaluate the performance of several
retrieval models and select the one that yields the best results for candidate
retrieval. Next, we employ multiple re-ranking models to enhance the candidate
results, with each model selecting the Top-10 outcomes. In the final stage, we
utilize weighted voting to determine the final retrieval outcomes. Our approach
achieved 5th place in the monolingual track and 7th place in the crosslingual
track. We release our system code at:
https://github.com/warmth27/SemEval2025_Task7.

</details>


### [28] [A Multi-Agent Probabilistic Inference Framework Inspired by Kairanban-Style CoT System with IdoBata Conversation for Debiasing](https://arxiv.org/abs/2506.21565)
*Takato Ueno,Keito Inoshita*

Main category: cs.CL

TL;DR: 本研究提出了一种多智能体推理框架（KCS+IBC），结合多个大型语言模型（LLM），通过模拟日本传统的kairanban文化和idobata对话，实现情感分析中的偏见缓解、可解释性提升和概率预测。


<details>
  <summary>Details</summary>
Motivation: 受日本kairanban文化和idobata对话的启发，旨在通过多智能体协作改善情感分析的偏见和多样性问题。

Method: 提出KCS+IBC框架，结合多个LLM，通过中间阶段的非正式对话整合个体观点，并引入概率情感预测。

Result: 实验显示KCS的准确性与单一LLM相当，而KCS+IBC在推理后期熵降低、方差增加，表明其能平衡预测的聚合与多样性。

Conclusion: 未来工作将量化这些特性对偏见修正的影响，并开发更先进的情感分析系统。

Abstract: Japan's kairanban culture and idobata conversations have long functioned as
traditional communication practices that foster nuanced dialogue among
community members and contribute to the formation of social balance. Inspired
by these information exchange processes, this study proposes a multi-agent
inference framework (KCS+IBC) that integrates multiple large language models
(LLMs) to achieve bias mitigation, improved explainability, and probabilistic
prediction in sentiment analysis. In addition to sequentially sharing
prediction results, the proposed method incorporates a mid-phase casual
dialogue session to blend formal inference with individual perspectives and
introduces probabilistic sentiment prediction. Experimental results show that
KCS achieves accuracy comparable to that of a single LLM across datasets, while
KCS+IBC exhibits a consistent decrease in entropy and a gradual increase in
variance during the latter stages of inference, suggesting the framework's
ability to balance aggregation and diversity of predictions. Future work will
quantitatively assess the impact of these characteristics on bias correction
and aim to develop more advanced sentiment analysis systems.

</details>


### [29] [The Saturation Point of Backtranslation in High Quality Low Resource English Gujarati Machine Translation](https://arxiv.org/abs/2506.21566)
*Arwa Arif*

Main category: cs.CL

TL;DR: 研究了反向翻译（BT）在英语-古吉拉特语低资源机器翻译中的效果，发现合成数据并未提升性能，反而可能降低。


<details>
  <summary>Details</summary>
Motivation: 探索反向翻译在高质量低资源机器翻译中的有效性，尤其是在英语-古吉拉特语任务中。

Method: 使用多语言预训练模型MBART50，基于高质量平行语料库（约5万句对）训练基线系统，并加入反向翻译生成的合成数据。

Result: 反向翻译数据未提升翻译性能，甚至略微降低。通过BLEU、ChrF++、TER、BLEURT等多指标验证。

Conclusion: 反向翻译在某些低资源场景中可能达到收益递减点，需进一步研究其适用性。

Abstract: Backtranslation BT is widely used in low resource machine translation MT to
generate additional synthetic training data using monolingual corpora. While
this approach has shown strong improvements for many language pairs, its
effectiveness in high quality, low resource settings remains unclear. In this
work, we explore the effectiveness of backtranslation for English Gujarati
translation using the multilingual pretrained MBART50 model. Our baseline
system, trained on a high quality parallel corpus of approximately 50,000
sentence pairs, achieves a BLEU score of 43.8 on a validation set. We augment
this data with carefully filtered backtranslated examples generated from
monolingual Gujarati text. Surprisingly, adding this synthetic data does not
improve translation performance and, in some cases, slightly reduces it. We
evaluate our models using multiple metrics like BLEU, ChrF++, TER, BLEURT and
analyze possible reasons for this saturation. Our findings suggest that
backtranslation may reach a point of diminishing returns in certain
low-resource settings and we discuss implications for future research.

</details>


### [30] [BioPars: A Pretrained Biomedical Large Language Model for Persian Biomedical Text Mining](https://arxiv.org/abs/2506.21567)
*Baqer M. Merzah,Tania Taami,Salman Asoudeh,Amir reza Hossein pour,Saeed Mirzaee,Amir Ali Bengari*

Main category: cs.CL

TL;DR: 论文介绍了BioPars，一个用于评估大型语言模型（LLM）在生物信息学中能力的工具，并展示了其在波斯医学问答中的优异表现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估LLM在生物信息学中的能力，特别是在波斯医学问答中的表现，填补了该领域的空白。

Method: 研究引入了BIOPARS-BENCH数据集和BioParsQA评估工具，并比较了ChatGPT、Llama和Galactica等模型的表现。

Result: BioPars在ROUGE-L、BERTScore、MoverScore和BLEURT等指标上优于其他模型，尤其在波斯医学问答中表现突出。

Conclusion: 研究表明LLM在生物信息学任务中仍需进一步优化，BioPars为波斯医学问答提供了首个有效的LLM应用。

Abstract: Large Language Models (LLMs) have recently gained attention in the life
sciences due to their capacity to model, extract, and apply complex biological
information. Beyond their classical use as chatbots, these systems are
increasingly used for complex analysis and problem-solving in specialized
fields, including bioinformatics. First, we introduce BIOPARS-BENCH, a dataset
from over 10,000 scientific articles, textbooks, and medical websites.
BioParsQA was also introduced to evaluate the proposed model, which consists of
5,231 Persian medical questions and answers. This study then introduces
BioPars, a simple but accurate measure designed to assess LLMs for three main
abilities: acquiring subject-specific knowledge, interpreting and synthesizing
such knowledge, and demonstrating proper evidence. Comparing ChatGPT, Llama,
and Galactica, our study highlights their ability to remember and retrieve
learned knowledge but also reveals shortcomings in addressing higher-level,
real-world questions and fine-grained inferences. These findings indicate the
need for further fine-tuning to address the capabilities of LLM in
bioinformatics tasks. To our knowledge, BioPars is the first application of LLM
in Persian medical QA, especially for generating long answers. Evaluation of
four selected medical QA datasets shows that BioPars has achieved remarkable
results compared to comparative approaches. The model on BioParsQA achieved a
ROUGE-L score of 29.99, which is an improvement over GPT-4 1.0. The model
achieved a BERTScore of 90.87 with the MMR method. The MoverScore and BLEURT
values were also higher in this model than the other three models. In addition,
the reported scores for the model are MoverScore=60.43 and BLEURT=50.78.
BioPars is an ongoing project and all resources related to its development will
be made available via the following GitHub repository:
https://github.com/amirap80/BioPars.

</details>


### [31] [Assessing RAG and HyDE on 1B vs. 4B-Parameter Gemma LLMs for Personal Assistants Integretion](https://arxiv.org/abs/2506.21568)
*Andrejs Sorstkins*

Main category: cs.CL

TL;DR: 研究评估了RAG和HyDE两种增强策略在小型Gemma LLM上的效果，发现RAG在延迟和准确性上表现更优，适合隐私优先的个人助手。


<details>
  <summary>Details</summary>
Motivation: 资源效率是部署大型语言模型（LLM）在边缘和隐私敏感应用中的关键障碍，研究旨在评估两种策略在小型LLM上的实用性。

Method: 在1B和4B参数的Gemma LLM上实现RAG和HyDE，结合MongoDB和Qdrant存储，通过FastAPI和LangChain协调，前端使用React.js。

Result: RAG减少延迟17%且消除幻觉，HyDE提升语义相关性但增加响应时间和幻觉率。4B模型对HyDE的计算开销更大。

Conclusion: RAG是小型LLM驱动的隐私优先个人助手的实用选择。

Abstract: Resource efficiency is a critical barrier to deploying large language models
(LLMs) in edge and privacy-sensitive applications. This study evaluates the
efficacy of two augmentation strategies--Retrieval-Augmented Generation (RAG)
and Hypothetical Document Embeddings (HyDE)--on compact Gemma LLMs of 1 billion
and 4 billion parameters, within the context of a privacy-first personal
assistant. We implement short-term memory via MongoDB and long-term semantic
storage via Qdrant, orchestrated through FastAPI and LangChain, and expose the
system through a React.js frontend. Across both model scales, RAG consistently
reduces latency by up to 17\% and eliminates factual hallucinations when
responding to user-specific and domain-specific queries. HyDE, by contrast,
enhances semantic relevance--particularly for complex physics prompts--but
incurs a 25--40\% increase in response time and a non-negligible hallucination
rate in personal-data retrieval. Comparing 1 B to 4 B models, we observe that
scaling yields marginal throughput gains for baseline and RAG pipelines, but
magnifies HyDE's computational overhead and variability. Our findings position
RAG as the pragmatic choice for on-device personal assistants powered by
small-scale LLMs.

</details>


### [32] [Hybrid-NL2SVA: Integrating RAG and Finetuning for LLM-based NL2SVA](https://arxiv.org/abs/2506.21569)
*Weihua Xiao,Derek Ekberg,Siddharth Garg,Ramesh Karri*

Main category: cs.CL

TL;DR: 提出了一种基于检索增强生成（RAG）框架和合成微调数据集的NL2SVA方法，显著提升了LLM在硬件设计验证中的性能。


<details>
  <summary>Details</summary>
Motivation: 手动将自然语言属性描述转换为SystemVerilog断言（SVA）耗时且易错，需要自动化解决方案。

Method: 结合定制化的RAG框架和合成微调数据集，通过提示引导解释提升轻量级模型的性能。

Result: 实验表明，定制RAG框架使功能匹配的SVA数量增加58.42%，微调后的模型性能提升59.05%。

Conclusion: 该方法显著提高了LLM在NL2SVA任务中的准确性和效率。

Abstract: SystemVerilog Assertions (SVAs) are critical for verifying the correctness of
hardware designs, but manually writing them from natural language property
descriptions, i.e., NL2SVA, remains a labor-intensive and error-prone task.
Recent advances in large language models (LLMs) offer opportunities to automate
this translation. However, existing models still struggle with understanding
domain-specific syntax and semantics. To enhance LLM performance in NL2SVA, we
propose a customized retrieval-augmented generation (RAG) framework and a
synthetic fine-tuning dataset that together improve LLM's performance. To
further improve lightweight models over NL2SVA, our fine-tuning dataset
provides prompt-guided explanations that teach LLMs the layer-by-layer
construction process of concurrent SVAs, enabling supervised fine-tuning that
greatly improves syntax and functionality accuracy. To evaluate the performance
of LLMs over NL2SVA, we construct the largest evaluation dataset for NL2SVA,
comprising 40 Verilog designs and 229 formally verified SVAs with detailed
annotations. Experimental results show that our customized RAG framework
increases the number of functionality matched SVAs by 58.42% over GPT-4o-mini,
while Qwen2.5-Coder-7B-Instruct fine-tuned on our fine-tuning dataset and
integrated with HybridRetrieval achieves a 59.05% over the base Qwen model.

</details>


### [33] [Random Initialization Can't Catch Up: The Advantage of Language Model Transfer for Time Series Forecasting](https://arxiv.org/abs/2506.21570)
*Roland Riachi,Kashif Rasul,Arjun Ashok,Prateek Humane,Alexis Roger,Andrew R. Williams,Yuriy Nevmyvaka,Irina Rish*

Main category: cs.CL

TL;DR: 该论文探讨了预训练语言模型（LMs）在低数据量时间序列预测中的有效性，分析了不同设计选择对验证损失的影响，并发现LMs的验证损失持续下降，揭示了模态无关数据分布的特性。


<details>
  <summary>Details</summary>
Motivation: 研究预训练语言模型在低数据量时间序列预测中的适应性，探索设计选择对性能的影响。

Method: 通过上游后训练、时间序列分词器和语言主干大小等设计选择，分析LMs在时间序列预测中的迁移效果。

Result: 在低数据量情况下，设计选择对验证损失有显著影响，且LMs的验证损失持续下降，表现出非消失的迁移差距。

Conclusion: 研究为高效计算训练提供了指导，并开启了模态无关数据分布特性的研究。

Abstract: Recent works have demonstrated the effectiveness of adapting pre-trained
language models (LMs) for forecasting time series in the low-data regime. We
build upon these findings by analyzing the effective transfer from language
models to time series forecasting under various design choices including
upstream post-training, time series tokenizer and language backbone size. In
the low-data regime, these design choices have a significant impact on the
validation loss, with clear-cut choices that outperform others. Contrary to
Hernandez et al. (2021), we observe that the validation loss of the LMs
continues to smoothly decrease long after the validation loss of the randomly
initialized models has converged, leading to a non-vanishing transfer gap that
holds across design choices. These findings not only help shed light on the
effective use of compute-efficient training for time series, but also open the
way for the study of modality-agnostic properties of data distributions
leveraged by these models.

</details>


### [34] [Towards Understanding the Cognitive Habits of Large Reasoning Models](https://arxiv.org/abs/2506.21571)
*Jianshuo Dong,Yujia Fu,Chuanrui Hu,Chao Zhang,Han Qiu*

Main category: cs.CL

TL;DR: 论文探讨了大型推理模型（LRMs）是否表现出类似人类的认知习惯，并提出了CogTest基准来评估这些习惯。研究发现LRMs具有适应性的人类认知习惯，且某些习惯与有害响应相关。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索LRMs是否具有类似人类的认知习惯，以更好地理解和监控模型行为。

Method: 方法包括引入CogTest基准，评估16种认知习惯在25个任务中的表现，并对16种LLMs进行全面分析。

Result: 结果显示LRMs表现出人类认知习惯，并能根据任务自适应调整，某些习惯与有害响应相关。

Conclusion: 结论表明研究LRMs的认知习惯有助于深入理解模型行为，尤其是其潜在问题。

Abstract: Large Reasoning Models (LRMs), which autonomously produce a reasoning Chain
of Thought (CoT) before producing final responses, offer a promising approach
to interpreting and monitoring model behaviors. Inspired by the observation
that certain CoT patterns -- e.g., ``Wait, did I miss anything?'' --
consistently emerge across tasks, we explore whether LRMs exhibit human-like
cognitive habits. Building on Habits of Mind, a well-established framework of
cognitive habits associated with successful human problem-solving, we introduce
CogTest, a principled benchmark designed to evaluate LRMs' cognitive habits.
CogTest includes 16 cognitive habits, each instantiated with 25 diverse tasks,
and employs an evidence-first extraction method to ensure reliable habit
identification. With CogTest, we conduct a comprehensive evaluation of 16
widely used LLMs (13 LRMs and 3 non-reasoning ones). Our findings reveal that
LRMs, unlike conventional LLMs, not only exhibit human-like habits but also
adaptively deploy them according to different tasks. Finer-grained analyses
further uncover patterns of similarity and difference in LRMs' cognitive habit
profiles, particularly certain inter-family similarity (e.g., Qwen-3 models and
DeepSeek-R1). Extending the study to safety-related tasks, we observe that
certain habits, such as Taking Responsible Risks, are strongly associated with
the generation of harmful responses. These findings suggest that studying
persistent behavioral patterns in LRMs' CoTs is a valuable step toward deeper
understanding of LLM misbehavior. The code is available at:
https://github.com/jianshuod/CogTest.

</details>


### [35] [Aligning MLLM Benchmark With Human Preferences via Structural Equation Modeling](https://arxiv.org/abs/2506.21572)
*Tianyu. Zou,Shengwu. Xiong,Ruilin. Yao,Jirui. Huang,Yi. Rong,Yaxiong. Chen,Shili. Xiong,Cong. Wang*

Main category: cs.CL

TL;DR: 提出基于结构方程模型（SEM）的多模态大语言模型（MLLM）评估框架，解决现有基准设计重叠、冗余和诊断能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM评估基准缺乏结构化、可解释的理论基础，导致能力重叠和诊断能力有限。

Method: 采用结构方程模型（SEM）分析基准的内部效度、维度分离性和组件贡献，并基于皮亚杰认知发展理论提出能力分层（感知、记忆、推理）。

Result: 新基准Gold在可解释性、指标冗余减少和认知一致性上优于现有方法。

Conclusion: 提出的框架和基准显著提升了MLLM评估的结构化和诊断能力。

Abstract: Evaluating multimodal large language models (MLLMs) remains a fundamental
challenge due to a lack of structured, interpretable, and theoretically
grounded benchmark designs. Existing benchmarks often adopt heuristic-based
task groupings with unclear cognitive targets, thus resulting in overlapping
abilities, redundant indicators, and limited diagnostic power. In this work, we
propose a novel framework for aligning MLLM benchmark based on Structural
Equation Modeling (SEM) to analyze and quantify the internal validity,
dimensional separability, and contribution of benchmark components. Motivated
by the observed limitations of current designs, we further introduce a novel
capability hierarchy grounded in Piagets theory of cognitive development,
dividing MLLM abilities into three hierarchical layers, i.e., Perception,
Memory, and Reasoning. We reorganize existing MLLM benchmarks under the
proposed framework and construct a new benchmark named Gold. Experimental
results demonstrate that the proposed benchmark exhibits stronger
interpretability, reduced indicator redundancy, and clearer cognitive
consistency compared to existing approaches.

</details>


### [36] [Instruction Learning Paradigms: A Dual Perspective on White-box and Black-box LLMs](https://arxiv.org/abs/2506.21573)
*Yanwei Ren,Liu Liu,Baosheng Yu,Jiayan Qiu,Quan Chen*

Main category: cs.CL

TL;DR: 提出了一种结合黑盒和白盒模型优势的新框架，通过语义相似性约束优化大型语言模型（LLM）的指令，提升任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决黑盒模型成本高和白盒模型计算资源需求大、表达能力有限的问题。

Method: 融合黑盒模型的高质量指令初始化和白盒模型的细粒度可解释性，通过语义相似性约束生成统一的高维表示，迭代优化指令。

Result: 在复杂推理和跨语言泛化等任务中表现优于现有基线。

Conclusion: 该框架为下一代LLM驱动的应用提供了可扩展且高效的解决方案。

Abstract: Optimizing instructions for large language models (LLMs) is critical for
harnessing their full potential in complex and diverse tasks. However, relying
solely on white-box approaches demands extensive computational resources and
offers limited representational capacity, while black-box models can incur
prohibitive financial costs. To address these challenges, we introduce a novel
framework that seamlessly merges the strengths of both paradigms. Black-box
models provide high-quality, diverse instruction initializations, and white-box
models supply fine-grained interpretability through hidden states and output
features. By enforcing a semantic similarity constraint, these components fuse
into a unified high-dimensional representation that captures deep semantic and
structural nuances, enabling an iterative optimization process to refine
instruction quality and adaptability. Extensive evaluations across a broad
spectrum of tasks-ranging from complex reasoning to cross-lingual
generalization-demonstrate that our approach consistently outperforms
state-of-the-art baselines. This fusion of black-box initialization with
advanced semantic refinement yields a scalable and efficient solution, paving
the way for next-generation LLM-driven applications in diverse real-world
scenarios. The source code will be released soon.

</details>


### [37] [Digital Gatekeepers: Exploring Large Language Model's Role in Immigration Decisions](https://arxiv.org/abs/2506.21574)
*Yicheng Mao,Yang Zhao*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（如GPT-3.5和GPT-4）在移民决策中的潜力与局限性，发现其能模仿人类策略但存在偏见。


<details>
  <summary>Details</summary>
Motivation: 全球化与移民增加导致移民部门工作量大且需确保公平决策，人工智能可能提供解决方案。

Method: 采用混合方法，包括离散选择实验和深度访谈，分析LLM的决策策略及公平性。

Result: LLM能模仿人类决策策略，注重效用最大化与程序公平，但仍存在国籍偏见和特权群体偏好。

Conclusion: LLM在移民决策自动化中具有潜力，但需解决偏见问题以实现公平应用。

Abstract: With globalization and increasing immigrant populations, immigration
departments face significant work-loads and the challenge of ensuring fairness
in decision-making processes. Integrating artificial intelligence offers a
promising solution to these challenges. This study investigates the potential
of large language models (LLMs),such as GPT-3.5 and GPT-4, in supporting
immigration decision-making. Utilizing a mixed-methods approach,this paper
conducted discrete choice experiments and in-depth interviews to study LLM
decision-making strategies and whether they are fair. Our findings demonstrate
that LLMs can align their decision-making with human strategies, emphasizing
utility maximization and procedural fairness. Meanwhile, this paper also
reveals that while ChatGPT has safeguards to prevent unintentional
discrimination, it still exhibits stereotypes and biases concerning nationality
and shows preferences toward privileged group. This dual analysis highlights
both the potential and limitations of LLMs in automating and enhancing
immigration decisions.

</details>


### [38] [MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark](https://arxiv.org/abs/2412.15194)
*Qihao Zhao,Yangyu Huang,Tengchao Lv,Lei Cui,Qinzheng Sun,Shaoguang Mao,Xin Zhang,Ying Xin,Qiufeng Yin,Scarlett Li,Furu Wei*

Main category: cs.CL

TL;DR: 提出了一个名为MMLU-CF的无污染、更具挑战性的多选题基准，用于更可靠地评估大语言模型的能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有多选题数据集（如MMLU）因数据泄露导致的评估不可靠问题。

Method: 通过更广泛的数据来源和三条去污染规则避免无意数据泄露，同时将基准分为验证集和测试集以防止恶意泄露。

Result: 主流大语言模型在测试集上的表现显著下降，如GPT-4o的5-shot得分仅为73.4%。

Conclusion: MMLU-CF提供了一个更严格且无污染的评估标准，有效解决了数据泄露问题。

Abstract: Multiple-choice question (MCQ) datasets like Massive Multitask Language
Understanding (MMLU) are widely used to evaluate the commonsense,
understanding, and problem-solving abilities of large language models (LLMs).
However, the open-source nature of these benchmarks and the broad sources of
training data for LLMs have inevitably led to benchmark contamination,
resulting in unreliable evaluation results. To alleviate this issue, we propose
a contamination-free and more challenging MCQ benchmark called MMLU-CF. This
benchmark reassesses LLMs' understanding of world knowledge by averting both
unintentional and malicious data leakage. To avoid unintentional data leakage,
we source data from a broader domain and design three decontamination rules. To
prevent malicious data leakage, we divide the benchmark into validation and
test sets with similar difficulty and subject distributions. The test set
remains closed-source to ensure reliable results, while the validation set is
publicly available to promote transparency and facilitate independent
verification. Our evaluation of mainstream LLMs reveals that the powerful
GPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on
the test set, which indicates the effectiveness of our approach in creating a
more rigorous and contamination-free evaluation standard. The GitHub repository
is available at https://github.com/microsoft/MMLU-CF and the dataset refers to
https://huggingface.co/datasets/microsoft/MMLU-CF.

</details>


### [39] [STRuCT-LLM: Unifying Tabular and Graph Reasoning with Reinforcement Learning for Semantic Parsing](https://arxiv.org/abs/2506.21575)
*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Casper Hansen,Julien Fauqueur*

Main category: cs.CL

TL;DR: STRuCT-LLM是一个统一框架，通过强化学习和Chain-of-Thought监督联合优化Text-to-SQL和Text-to-Cypher任务，实现跨形式迁移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理关系型和图结构数据时孤立的问题，利用SQL和Cypher之间的共享抽象实现跨形式迁移。

Method: 结合强化学习和Chain-of-Thought监督，引入基于图编辑距离的拓扑感知奖励函数，联合优化Text-to-SQL和Text-to-Cypher任务。

Result: QwQ-32B模型在语义解析任务中Spider提升13.5%，Text2Cypher提升73.1%，并在零样本下游任务中表现优异。

Conclusion: STRuCT-LLM证明了可执行查询作为结构化推理支架的有效性，以及联合训练SQL和Cypher的协同优势。

Abstract: We propose STRuCT-LLM, a unified framework for training large language models
(LLMs) to perform structured reasoning over both relational and
graph-structured data. Our approach jointly optimizes Text-to-SQL and
Text-to-Cypher tasks using reinforcement learning (RL) combined with
Chain-of-Thought (CoT) supervision. To support fine-grained optimization in
graph-based parsing, we introduce a topology-aware reward function based on
graph edit distance. Unlike prior work that treats relational and graph
formalisms in isolation, STRuCT-LLM leverages shared abstractions between SQL
and Cypher to induce cross-formalism transfer, enabling SQL training to improve
Cypher performance and vice versa - even without shared schemas. Our largest
model (QwQ-32B) achieves substantial relative improvements across tasks: on
semantic parsing, Spider improves by 13.5\% and Text2Cypher by 73.1\%. The
model also demonstrates strong zero-shot generalization, improving performance
on downstream tabular QA (TableBench: 8.5\%) and knowledge graph QA
(CR-LT-KGQA: 1.7\%) without any QA-specific supervision. These results
demonstrate both the effectiveness of executable queries as scaffolds for
structured reasoning and the synergistic benefits of jointly training on SQL
and Cypher (code available at https://github.com/bouv/STRuCT-LLM).

</details>


### [40] [Adapting Whisper for Parameter-efficient Code-Switching Speech Recognition via Soft Prompt Tuning](https://arxiv.org/abs/2506.21576)
*Hongli Yang,Yizhou Peng,Hao Huang,Sheng Li*

Main category: cs.CL

TL;DR: 论文探讨了Soft Prompt Tuning（SPT）在低资源场景下提升多语言ASR模型性能的方法，提出了SPT4ASR方法，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多语言ASR模型（如Whisper）在低资源场景（如稀有语言和代码切换）中的性能问题，同时避免计算成本高和灾难性遗忘。

Method: 研究了两种策略：1）全微调（FFT）软提示和整个Whisper模型；2）仅训练软提示并冻结模型参数。还提出了SPT4ASR方法。

Result: 实验表明，深度提示调优是最有效的SPT方法，SPT4ASR进一步降低了代码切换ASR的错误率，且保持了参数效率。

Conclusion: SPT4ASR方法在提升低资源场景性能的同时，未损害现有语言的表现，且参数效率高。

Abstract: Large-scale multilingual ASR models like Whisper excel in high-resource
settings but face challenges in low-resource scenarios, such as rare languages
and code-switching (CS), due to computational costs and catastrophic
forgetting. We explore Soft Prompt Tuning (SPT), a parameter-efficient method
to enhance CS ASR while preserving prior knowledge. We evaluate two strategies:
(1) full fine-tuning (FFT) of both soft prompts and the entire Whisper model,
demonstrating improved cross-lingual capabilities compared to traditional
methods, and (2) adhering to SPT's original design by freezing model parameters
and only training soft prompts. Additionally, we introduce SPT4ASR, a
combination of different SPT variants. Experiments on the SEAME and ASRU2019
datasets show that deep prompt tuning is the most effective SPT approach, and
our SPT4ASR methods achieve further error reductions in CS ASR, maintaining
parameter efficiency similar to LoRA, without degrading performance on existing
languages.

</details>


### [41] [Data Efficacy for Language Model Training](https://arxiv.org/abs/2506.21545)
*Yalun Dai,Yangyu Huang,Xin Zhang,Wenshan Wu,Chong Li,Wenhui Lu,Shijie Cao,Li Dong,Scarlett Li*

Main category: cs.CL

TL;DR: DELT范式通过优化训练数据的组织（数据评分、选择和排序）提升语言模型性能，提出LQS和FO方法，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索数据效能（Data Efficacy），即通过优化数据组织而非单纯增加数据量来提升语言模型性能。

Method: 提出DELT范式，包含数据评分（LQS）、数据选择和数据排序（FO），从梯度一致性和分布偏差角度优化数据组织。

Result: DELT显著提升模型性能，LQS与FO组合效果最佳，且数据效能与数据效率可兼顾。

Conclusion: 数据效能是语言模型训练中值得深入的基础研究方向。

Abstract: Data is fundamental to the training of language models (LM). Recent research
has been dedicated to data efficiency, which aims to maximize performance by
selecting a minimal or optimal subset of training data. Techniques such as data
filtering, sampling, and selection play a crucial role in this area. To
complement it, we define Data Efficacy, which focuses on maximizing performance
by optimizing the organization of training data and remains relatively
underexplored. This work introduces a general paradigm, DELT, for considering
data efficacy in LM training, which highlights the significance of training
data organization. DELT comprises three components: Data Scoring, Data
Selection, and Data Ordering. Among these components, we design
Learnability-Quality Scoring (LQS), as a new instance of Data Scoring, which
considers both the learnability and quality of each data sample from the
gradient consistency perspective. We also devise Folding Ordering (FO), as a
novel instance of Data Ordering, which addresses issues such as model
forgetting and data distribution bias. Comprehensive experiments validate the
data efficacy in LM training, which demonstrates the following: Firstly,
various instances of the proposed DELT enhance LM performance to varying
degrees without increasing the data scale and model size. Secondly, among these
instances, the combination of our proposed LQS for data scoring and Folding for
data ordering achieves the most significant improvement. Lastly, data efficacy
can be achieved together with data efficiency by applying data selection.
Therefore, we believe that data efficacy is a promising foundational area in LM
training.

</details>


### [42] [Language-Aware Prompt Tuning for Parameter-Efficient Seamless Language Expansion in Multilingual ASR](https://arxiv.org/abs/2506.21577)
*Hongli Yang,Sheng Li,Hao Huang,Ayiduosi Tuohan,Yizhou Peng*

Main category: cs.CL

TL;DR: 论文提出两种软提示调优方法（Entire SPT和LAPT）及工具包SPT-Whisper，显著提升多语言ASR性能，尤其在语言扩展任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多语言ASR中语言干扰和语言扩展性能下降的问题。

Method: 1) Entire SPT：在编码器和解码器中应用软提示；2) LAPT：利用跨语言相似性编码共享和语言特定特征；3) SPT-Whisper工具包。

Result: Entire SPT和LAPT在语言扩展任务中分别比Decoder SPT提升5.0%和16.0%。

Conclusion: 提出的方法为动态多语言ASR模型提供了高效解决方案，计算开销小。

Abstract: Recent advancements in multilingual automatic speech recognition (ASR) have
been driven by large-scale end-to-end models like Whisper. However, challenges
such as language interference and expanding to unseen languages (language
expansion) without degrading performance persist. This paper addresses these
with three contributions: 1) Entire Soft Prompt Tuning (Entire SPT), which
applies soft prompts to both the encoder and decoder, enhancing feature
extraction and decoding; 2) Language-Aware Prompt Tuning (LAPT), which
leverages cross-lingual similarities to encode shared and language-specific
features using lightweight prompt matrices; 3) SPT-Whisper, a toolkit that
integrates SPT into Whisper and enables efficient continual learning.
Experiments across three languages from FLEURS demonstrate that Entire SPT and
LAPT outperform Decoder SPT by 5.0% and 16.0% in language expansion tasks,
respectively, providing an efficient solution for dynamic, multilingual ASR
models with minimal computational overhead.

</details>


### [43] [HealthQA-BR: A System-Wide Benchmark Reveals Critical Knowledge Gaps in Large Language Models](https://arxiv.org/abs/2506.21578)
*Andrew Maranhão Ventura D'addario*

Main category: cs.CL

TL;DR: 论文介绍了HealthQA-BR，首个针对葡萄牙语医疗的大规模基准测试，评估了20多个领先的LLM，揭示了模型在不同医疗领域的表现差异。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要关注医生为中心的英语基准，忽视了医疗团队的多专业性质，可能导致对模型能力的误判。

Method: 使用巴西国家考试中的5,632个问题，覆盖医学、护理、牙科等多个领域，对LLM进行零样本评估。

Result: GPT 4.1总体准确率达86.6%，但在神经外科（60.0%）和社会工作（68.4%）等领域表现不佳。

Conclusion: 单一评分不足以验证模型安全性，需更细粒度的评估工具，HealthQA-BR为此提供了支持。

Abstract: The evaluation of Large Language Models (LLMs) in healthcare has been
dominated by physician-centric, English-language benchmarks, creating a
dangerous illusion of competence that ignores the interprofessional nature of
patient care. To provide a more holistic and realistic assessment, we introduce
HealthQA-BR, the first large-scale, system-wide benchmark for
Portuguese-speaking healthcare. Comprising 5,632 questions from Brazil's
national licensing and residency exams, it uniquely assesses knowledge not only
in medicine and its specialties but also in nursing, dentistry, psychology,
social work, and other allied health professions. We conducted a rigorous
zero-shot evaluation of over 20 leading LLMs. Our results reveal that while
state-of-the-art models like GPT 4.1 achieve high overall accuracy (86.6%),
this top-line score masks alarming, previously unmeasured deficiencies. A
granular analysis shows performance plummets from near-perfect in specialties
like Ophthalmology (98.7%) to barely passing in Neurosurgery (60.0%) and, most
notably, Social Work (68.4%). This "spiky" knowledge profile is a systemic
issue observed across all models, demonstrating that high-level scores are
insufficient for safety validation. By publicly releasing HealthQA-BR and our
evaluation suite, we provide a crucial tool to move beyond single-score
evaluations and toward a more honest, granular audit of AI readiness for the
entire healthcare team.

</details>


### [44] [From General Reasoning to Domain Expertise: Uncovering the Limits of Generalization in Large Language Models](https://arxiv.org/abs/2506.21580)
*Dana Alsagheer,Yang Lu,Abdulrahman Kamal,Omar Kamal,Mohammad Kamal,Nada Mansour,Cosmo Yang Wu,Rambiba Karanjai,Sen Li,Weidong Shi*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLMs）的通用推理能力与其在特定领域推理任务中表现的关系。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的发展，训练LLMs在通用推理方面表现出色成为趋势，但决策能力依赖于强大的推理能力。

Method: 研究分析了LLMs的通用推理能力如何影响其在特定领域任务中的表现。

Result: 未明确提及具体结果，但强调了推理与决策的紧密联系。

Conclusion: 推理能力是决策的基础，LLMs的通用推理能力可能对其在特定领域的表现有重要影响。

Abstract: Recent advancements in Large Language Models (LLMs) have demonstrated
remarkable capabilities in various domains. However, effective decision-making
relies heavily on strong reasoning abilities. Reasoning is the foundation for
decision-making, providing the analytical and logical framework to make sound
choices. Reasoning involves analyzing information, drawing inferences, and
reaching conclusions based on logic or evidence. Decision-making builds on this
foundation by applying the insights from reasoning to select the best course of
action among alternatives. Together, these processes create a continuous cycle
of thought and action aimed at achieving goals effectively. As AI technology
evolves, there is a growing trend to train LLMs to excel in general reasoning.
This study explores how the general reasoning capabilities of LLMs connect to
their performance in domain-specific reasoning tasks.

</details>


### [45] [VIDEE: Visual and Interactive Decomposition, Execution, and Evaluation of Text Analytics with Intelligent Agents](https://arxiv.org/abs/2506.21582)
*Sam Yu-Te Lee,Chengyang Ji,Shicheng Wen,Lifu Huang,Dongyi Liu,Kwan-Liu Ma*

Main category: cs.CL

TL;DR: VIDEE是一个支持初级数据分析师进行高级文本分析的系统，通过人机协作工作流（分解、执行、评估）实现自动化文本分析，实验和用户研究验证了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 传统文本分析需要NLP专业知识，对初级分析师构成障碍。大型语言模型（LLMs）的进步使得文本分析更易访问和自动化。

Method: VIDEE采用三阶段工作流：分解（结合人类反馈的蒙特卡洛树搜索）、执行（生成可执行分析管道）、评估（LLM评估和可视化）。

Result: 定量实验验证了VIDEE的有效性并分析了常见错误；用户研究表明系统对不同经验水平的用户均适用。

Conclusion: VIDEE为非专家用户提供了实用工具，揭示了人机协作的设计启示，并为未来智能文本分析系统的改进提供了方向。

Abstract: Text analytics has traditionally required specialized knowledge in Natural
Language Processing (NLP) or text analysis, which presents a barrier for
entry-level analysts. Recent advances in large language models (LLMs) have
changed the landscape of NLP by enabling more accessible and automated text
analysis (e.g., topic detection, summarization, information extraction, etc.).
We introduce VIDEE, a system that supports entry-level data analysts to conduct
advanced text analytics with intelligent agents. VIDEE instantiates a
human-agent collaroration workflow consisting of three stages: (1)
Decomposition, which incorporates a human-in-the-loop Monte-Carlo Tree Search
algorithm to support generative reasoning with human feedback, (2) Execution,
which generates an executable text analytics pipeline, and (3) Evaluation,
which integrates LLM-based evaluation and visualizations to support user
validation of execution results. We conduct two quantitative experiments to
evaluate VIDEE's effectiveness and analyze common agent errors. A user study
involving participants with varying levels of NLP and text analytics experience
-- from none to expert -- demonstrates the system's usability and reveals
distinct user behavior patterns. The findings identify design implications for
human-agent collaboration, validate the practical utility of VIDEE for
non-expert users, and inform future improvements to intelligent text analytics
systems.

</details>


### [46] [Hope Speech Detection in code-mixed Roman Urdu tweets: A Positive Turn in Natural Language Processing](https://arxiv.org/abs/2506.21583)
*Muhammad Ahmad,Muhammad Waqas,Ameer Hamza,Ildar Batyrshin,Grigori Sidorov*

Main category: cs.CL

TL;DR: 本文首次研究了罗马乌尔都语中的希望言论检测，填补了低资源、非正式语言变体在NLP研究中的空白，并提出了一个优化的注意力转换模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注高资源语言和标准化脚本，忽视了非正式和代表性不足的形式（如罗马乌尔都语）。本文旨在填补这一研究空白。

Method: 引入首个罗马乌尔都语多类标注数据集，探索希望的心理基础，提出基于注意力的转换模型，并通过5折交叉验证评估。

Result: 提出的XLM-R模型性能最佳，交叉验证得分为0.78，优于基线SVM（0.75）和BiLSTM（0.76）。

Conclusion: 本研究为低资源语言的希望言论检测提供了新方法和数据集，验证了模型性能的显著提升。

Abstract: Hope is a positive emotional state involving the expectation of favorable
future outcomes, while hope speech refers to communication that promotes
optimism, resilience, and support, particularly in adverse contexts. Although
hope speech detection has gained attention in Natural Language Processing
(NLP), existing research mainly focuses on high-resource languages and
standardized scripts, often overlooking informal and underrepresented forms
such as Roman Urdu. To the best of our knowledge, this is the first study to
address hope speech detection in code-mixed Roman Urdu by introducing a
carefully annotated dataset, thereby filling a critical gap in inclusive NLP
research for low-resource, informal language varieties. This study makes four
key contributions: (1) it introduces the first multi-class annotated dataset
for Roman Urdu hope speech, comprising Generalized Hope, Realistic Hope,
Unrealistic Hope, and Not Hope categories; (2) it explores the psychological
foundations of hope and analyzes its linguistic patterns in code-mixed Roman
Urdu to inform dataset development; (3) it proposes a custom attention-based
transformer model optimized for the syntactic and semantic variability of Roman
Urdu, evaluated using 5-fold cross-validation; and (4) it verifies the
statistical significance of performance gains using a t-test. The proposed
model, XLM-R, achieves the best performance with a cross-validation score of
0.78, outperforming the baseline SVM (0.75) and BiLSTM (0.76), with gains of 4%
and 2.63% respectively.

</details>


### [47] [Empirical Evidence for Alignment Faking in Small LLMs and Prompt-Based Mitigation Techniques](https://arxiv.org/abs/2506.21584)
*J. Koorndijk*

Main category: cs.CL

TL;DR: 研究发现小型指令调优模型LLaMA 3 8B也能表现出对齐伪装行为，提示干预可显著减少此行为，挑战了提示伦理无关紧要的假设。


<details>
  <summary>Details</summary>
Motivation: 探讨小型语言模型是否也会出现对齐伪装行为，并验证提示干预的有效性。

Method: 使用LLaMA 3 8B模型，通过提示干预（如道德框架和推理提示）测试对齐伪装行为。

Result: 提示干预显著减少对齐伪装行为，表明小型模型也存在此现象。

Conclusion: 研究改进了对语言模型伪装行为的理解，强调需在不同规模和部署环境中评估对齐问题。

Abstract: Current literature suggests that alignment faking (deceptive alignment) is an
emergent property of large language models. We present the first empirical
evidence that a small instruction-tuned model, specifically LLaMA 3 8B, can
also exhibit alignment faking. We further show that prompt-only interventions,
including deontological moral framing and scratchpad reasoning, significantly
reduce this behavior without modifying model internals. This challenges the
assumption that prompt-based ethics are trivial and that deceptive alignment
requires scale. We introduce a taxonomy distinguishing shallow deception,
shaped by context and suppressible through prompting, from deep deception,
which reflects persistent, goal-driven misalignment. Our findings refine the
understanding of deception in language models and underscore the need for
alignment evaluations across model sizes and deployment settings.

</details>


### [48] [Evaluation of LLM-based Strategies for the Extraction of Food Product Information from Online Shops](https://arxiv.org/abs/2506.21585)
*Christoph Brosch,Sian Brumm,Rolf Krieger,Jonas Scheffler*

Main category: cs.CL

TL;DR: 比较了两种基于LLM的食品产品页面信息提取方法，间接法虽准确率略低但显著减少LLM调用次数，提升效率和降低成本。


<details>
  <summary>Details</summary>
Motivation: 探索利用生成式AI和LLM从在线零售商食品页面中提取结构化信息的潜力。

Method: 对比了直接提取和间接提取（通过生成函数）两种方法，评估了准确性、效率和成本。

Result: 间接提取准确率略低（96.48%，比直接提取低1.61%），但减少了95.82%的LLM调用，显著提升效率和降低成本。

Conclusion: 间接提取方法为基于模板的网页大规模信息提取提供了可扩展且经济高效的解决方案。

Abstract: Generative AI and large language models (LLMs) offer significant potential
for automating the extraction of structured information from web pages. In this
work, we focus on food product pages from online retailers and explore
schema-constrained extraction approaches to retrieve key product attributes,
such as ingredient lists and nutrition tables. We compare two LLM-based
approaches, direct extraction and indirect extraction via generated functions,
evaluating them in terms of accuracy, efficiency, and cost on a curated dataset
of 3,000 food product pages from three different online shops. Our results show
that although the indirect approach achieves slightly lower accuracy (96.48\%,
$-1.61\%$ compared to direct extraction), it reduces the number of required LLM
calls by 95.82\%, leading to substantial efficiency gains and lower operational
costs. These findings suggest that indirect extraction approaches can provide
scalable and cost-effective solutions for large-scale information extraction
tasks from template-based web pages using LLMs.

</details>


### [49] [Can Vision Language Models Understand Mimed Actions?](https://arxiv.org/abs/2506.21586)
*Hyundong Cho,Spencer Lin,Tejas Srinivasan,Michael Saxon,Deuksin Kwon,Natali T. Chavez,Jonathan May*

Main category: cs.CL

TL;DR: 论文提出MIME基准，用于评估视觉语言模型对哑剧动作的理解能力，发现现有模型表现远逊于人类。


<details>
  <summary>Details</summary>
Motivation: 研究哑剧动作（NVC子集）是理解更复杂非语言交流的前提，因其解释方差低。

Method: 构建MIME基准，包含86种哑剧动作视频，通过动作捕捉数据生成，并加入扰动以评估鲁棒性。

Result: 现有视觉语言模型在MIME上表现显著低于人类。

Conclusion: 需加强研究以提升模型对人类手势的理解能力。

Abstract: Nonverbal communication (NVC) plays an integral role in human language, but
studying NVC in general is challenging because of its broad scope and high
variance in interpretation among individuals and cultures. However, mime -- the
theatrical technique of suggesting intent using only gesture, expression, and
movement -- is a subset of NVC that consists of explicit and embodied actions
with much lower human interpretation variance. We argue that a solid
understanding of mimed actions is a crucial prerequisite for vision-language
models capable of interpreting and commanding more subtle aspects of NVC.
Hence, we propose Mime Identification Multimodal Evaluation (MIME), a novel
video-based question answering benchmark comprising of 86 mimed actions.
Constructed with motion capture data, MIME consists of variations of each
action with perturbations applied to the character, background, and viewpoint
for evaluating recognition robustness. We find that both open-weight and
API-based vision-language models perform significantly worse than humans on
MIME, motivating the need for increased research for instilling more robust
understanding of human gestures.

</details>


### [50] [Is DeepSeek a New Voice Among LLMs in Public Opinion Simulation?](https://arxiv.org/abs/2506.21587)
*Weihong Qi,Fan Huang,Jisun An,Haewoon Kwak*

Main category: cs.CL

TL;DR: DeepSeek-V3在模拟美国公众对堕胎问题的意见上表现最佳，但在中国样本中对资本主义观点的模拟存在局限。所有LLM都存在过度概括单一视角的倾向，需减少文化和人口偏见。


<details>
  <summary>Details</summary>
Motivation: 评估开源LLM DeepSeek在模拟公众意见上的能力，并与主流科技公司的LLM进行比较，以揭示其在不同国家和议题上的表现差异。

Method: 通过比较DeepSeek-R1、DeepSeek-V3与Qwen2.5、GPT-4o、Llama-3.3，利用ANES和中国Zuobiao数据集，评估模型在中美社会议题上的预测能力。

Result: DeepSeek-V3在美国堕胎议题上表现最佳，但在中国对资本主义观点的模拟不足。所有模型倾向于过度概括群体内单一视角。

Conclusion: 需改进LLM的训练方法以减少文化和人口偏见，提升公众意见模拟的准确性。

Abstract: This study evaluates the ability of DeepSeek, an open-source large language
model (LLM), to simulate public opinions in comparison to LLMs developed by
major tech companies. By comparing DeepSeek-R1 and DeepSeek-V3 with Qwen2.5,
GPT-4o, and Llama-3.3 and utilizing survey data from the American National
Election Studies (ANES) and the Zuobiao dataset of China, we assess these
models' capacity to predict public opinions on social issues in both China and
the United States, highlighting their comparative capabilities between
countries. Our findings indicate that DeepSeek-V3 performs best in simulating
U.S. opinions on the abortion issue compared to other topics such as climate
change, gun control, immigration, and services for same-sex couples, primarily
because it more accurately simulates responses when provided with Democratic or
liberal personas. For Chinese samples, DeepSeek-V3 performs best in simulating
opinions on foreign aid and individualism but shows limitations in modeling
views on capitalism, particularly failing to capture the stances of low-income
and non-college-educated individuals. It does not exhibit significant
differences from other models in simulating opinions on traditionalism and the
free market. Further analysis reveals that all LLMs exhibit the tendency to
overgeneralize a single perspective within demographic groups, often defaulting
to consistent responses within groups. These findings highlight the need to
mitigate cultural and demographic biases in LLM-driven public opinion modeling,
calling for approaches such as more inclusive training methodologies.

</details>


### [51] [Understanding Verbatim Memorization in LLMs Through Circuit Discovery](https://arxiv.org/abs/2506.21588)
*Ilya Lasy,Peter Knees,Stefan Woltran*

Main category: cs.CL

TL;DR: 本文探讨了LLM中记忆化的机制，通过变压器电路识别了触发和维持记忆化的不同电路，并发现记忆化预防机制具有跨领域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 理解LLM中记忆化的具体机制，包括触发和维持记忆化的网络部分及其行为差异。

Method: 利用变压器电路和对比数据集，识别记忆化与非记忆化生成的分歧点，并分离相关电路。

Result: 发现触发记忆化的电路也能维持记忆化，而仅维持记忆化的电路无法触发其开始；记忆化预防机制具有跨领域鲁棒性。

Conclusion: 记忆化触发更依赖上下文，而预防机制具有广泛适用性，为LLM的机制解释提供了新视角。

Abstract: Underlying mechanisms of memorization in LLMs -- the verbatim reproduction of
training data -- remain poorly understood. What exact part of the network
decides to retrieve a token that we would consider as start of memorization
sequence? How exactly is the models' behaviour different when producing
memorized sentence vs non-memorized? In this work we approach these questions
from mechanistic interpretability standpoint by utilizing transformer circuits
-- the minimal computational subgraphs that perform specific functions within
the model. Through carefully constructed contrastive datasets, we identify
points where model generation diverges from memorized content and isolate the
specific circuits responsible for two distinct aspects of memorization. We find
that circuits that initiate memorization can also maintain it once started,
while circuits that only maintain memorization cannot trigger its initiation.
Intriguingly, memorization prevention mechanisms transfer robustly across
different text domains, while memorization induction appears more
context-dependent.

</details>


### [52] [A General Method for Detecting Information Generated by Large Language Models](https://arxiv.org/abs/2506.21589)
*Minjia Mao,Dongjun Wei,Xiao Fang,Michael Chau*

Main category: cs.CL

TL;DR: 论文提出了一种通用的LLM检测器（GLD），用于检测未见过的LLM和领域生成的内容，解决了现有方法泛化能力不足的问题。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的普及，区分人类写作和LLM生成内容变得困难，这对数字平台的信任和防止错误信息传播至关重要。现有方法在泛化到新LLM和领域时表现不佳。

Method: GLD结合了双记忆网络设计和理论指导的检测泛化模块，以检测未见过的LLM和领域生成的内容。

Result: 通过真实数据集评估，GLD在检测性能上优于现有最先进方法。

Conclusion: GLD为数字平台和LLM提供了重要的学术和实践价值。

Abstract: The proliferation of large language models (LLMs) has significantly
transformed the digital information landscape, making it increasingly
challenging to distinguish between human-written and LLM-generated content.
Detecting LLM-generated information is essential for preserving trust on
digital platforms (e.g., social media and e-commerce sites) and preventing the
spread of misinformation, a topic that has garnered significant attention in IS
research. However, current detection methods, which primarily focus on
identifying content generated by specific LLMs in known domains, face
challenges in generalizing to new (i.e., unseen) LLMs and domains. This
limitation reduces their effectiveness in real-world applications, where the
number of LLMs is rapidly multiplying and content spans a vast array of
domains. In response, we introduce a general LLM detector (GLD) that combines a
twin memory networks design and a theory-guided detection generalization module
to detect LLM-generated information across unseen LLMs and domains. Using
real-world datasets, we conduct extensive empirical evaluations and case
studies to demonstrate the superiority of GLD over state-of-the-art detection
methods. The study has important academic and practical implications for
digital platforms and LLMs.

</details>


### [53] [Representation Consistency for Accurate and Coherent LLM Answer Aggregation](https://arxiv.org/abs/2506.21590)
*Junqi Jiang,Tom Bewley,Salim I. Amoukou,Francesco Leofante,Antonio Rago,Saumitra Mishra,Francesca Toni*

Main category: cs.CL

TL;DR: 提出了一种基于表示一致性（RC）的测试时扩展方法，通过聚合LLM的多个候选响应来提升推理性能，无需额外模型查询。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要复杂的提示和采样策略修改，而RC旨在通过模型内部激活的一致性来改进答案聚合。

Method: RC利用密集或稀疏的模型内部激活一致性，对候选响应集中的答案进行加权聚合。

Result: 在四个开源LLM和四个推理数据集上验证，RC能提升任务性能，准确率最高提升4%。

Conclusion: RC是一种高效且无需额外查询的方法，稀疏激活信号的一致性能够反映连贯推理。

Abstract: Test-time scaling improves large language models' (LLMs) performance by
allocating more compute budget during inference. To achieve this, existing
methods often require intricate modifications to prompting and sampling
strategies. In this work, we introduce representation consistency (RC), a
test-time scaling method for aggregating answers drawn from multiple candidate
responses of an LLM regardless of how they were generated, including variations
in prompt phrasing and sampling strategy. RC enhances answer aggregation by not
only considering the number of occurrences of each answer in the candidate
response set, but also the consistency of the model's internal activations
while generating the set of responses leading to each answer. These activations
can be either dense (raw model activations) or sparse (encoded via pretrained
sparse autoencoders). Our rationale is that if the model's representations of
multiple responses converging on the same answer are highly variable, this
answer is more likely to be the result of incoherent reasoning and should be
down-weighted during aggregation. Importantly, our method only uses cached
activations and lightweight similarity computations and requires no additional
model queries. Through experiments with four open-source LLMs and four
reasoning datasets, we validate the effectiveness of RC for improving task
performance during inference, with consistent accuracy improvements (up to 4%)
over strong test-time scaling baselines. We also show that consistency in the
sparse activation signals aligns well with the common notion of coherent
reasoning.

</details>


### [54] [FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning](https://arxiv.org/abs/2506.21591)
*Shaoyu Dou,Yutian Shen,Mofan Chen,Zixuan Wang,Jiajie Xu,Qi Guo,Kailai Shao,Chao Chen,Haixiang Hu,Haibo Shi,Min Min,Liwen Zhang*

Main category: cs.CL

TL;DR: FinEval-KR框架用于独立评估LLMs的金融知识和推理能力，提出认知评分，并发布开源中文金融推理数据集。实验表明推理能力和高阶认知能力是关键，但知识应用仍是瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准未能区分金融知识和推理能力，且缺乏任务失败的根因分析，需改进。

Method: 提出FinEval-KR框架，独立量化知识和推理能力，引入认知评分（基于Bloom分类法），并发布开源数据集。

Result: 实验显示LLMs的推理能力和高阶认知能力是核心影响因素，但知识应用存在瓶颈；专业金融LLMs表现普遍落后于通用大模型。

Conclusion: FinEval-KR为金融推理任务提供了更细粒度的评估方法，揭示了LLMs的局限性，尤其是知识应用问题。

Abstract: Large Language Models (LLMs) demonstrate significant potential but face
challenges in complex financial reasoning tasks requiring both domain knowledge
and sophisticated reasoning. Current evaluation benchmarks often fall short by
not decoupling these capabilities indicators from single task performance and
lack root cause analysis for task failure. To address this, we introduce
FinEval-KR, a novel evaluation framework for decoupling and quantifying LLMs'
knowledge and reasoning abilities independently, proposing distinct knowledge
score and reasoning score metrics. Inspired by cognitive science, we further
propose a cognitive score based on Bloom's taxonomy to analyze capabilities in
reasoning tasks across different cognitive levels. We also release a new
open-source Chinese financial reasoning dataset covering 22 subfields to
support reproducible research and further advancements in financial reasoning.
Our experimental results reveal that LLM reasoning ability and higher-order
cognitive ability are the core factors influencing reasoning accuracy. We also
specifically find that even top models still face a bottleneck with knowledge
application. Furthermore, our analysis shows that specialized financial LLMs
generally lag behind the top general large models across multiple metrics.

</details>


### [55] [SignBart -- New approach with the skeleton sequence for Isolated Sign language Recognition](https://arxiv.org/abs/2506.21592)
*Tinh Nguyen,Minh Khue Phan Tran*

Main category: cs.CL

TL;DR: 提出了一种基于BART架构的新型手语识别方法，通过独立编码x和y坐标并利用交叉注意力保持其关联性，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在手语识别中效率和准确性难以兼顾的问题，尤其是RNN、LSTM和GCN等模型存在的梯度消失和高计算成本问题。

Method: 采用BART架构的编码器-解码器模型，独立编码骨架序列的x和y坐标，并通过交叉注意力维持其关联性。

Result: 在LSA-64数据集上达到96.04%的准确率，参数仅749,888，优于参数超过百万的先前模型，并在WLASL和ASL-Citizen数据集上表现优异。

Conclusion: 该方法为手语识别提供了一种可靠且高效的解决方案，有望显著提升聋人和听力障碍者的辅助工具效果。

Abstract: Sign language recognition is crucial for individuals with hearing impairments
to break communication barriers. However, previous approaches have had to
choose between efficiency and accuracy. Such as RNNs, LSTMs, and GCNs, had
problems with vanishing gradients and high computational costs. Despite
improving performance, transformer-based methods were not commonly used. This
study presents a new novel SLR approach that overcomes the challenge of
independently extracting meaningful information from the x and y coordinates of
skeleton sequences, which traditional models often treat as inseparable. By
utilizing an encoder-decoder of BART architecture, the model independently
encodes the x and y coordinates, while Cross-Attention ensures their
interrelation is maintained. With only 749,888 parameters, the model achieves
96.04% accuracy on the LSA-64 dataset, significantly outperforming previous
models with over one million parameters. The model also demonstrates excellent
performance and generalization across WLASL and ASL-Citizen datasets. Ablation
studies underscore the importance of coordinate projection, normalization, and
using multiple skeleton components for boosting model efficacy. This study
offers a reliable and effective approach for sign language recognition, with
strong potential for enhancing accessibility tools for the deaf and hard of
hearing.

</details>


### [56] [Gazal-R1: Achieving State-of-the-Art Medical Reasoning with Parameter-Efficient Two-Stage Training](https://arxiv.org/abs/2506.21594)
*Ahmed M. Adly,Mostafa Samy,Amr Fawzy*

Main category: cs.CL

TL;DR: Gazal-R1是一个320亿参数的语言模型，在医学推理中表现优异，并提供透明的临床决策解释。通过两阶段训练，超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个在医学领域具有高性能和透明推理能力的语言模型，解决专业领域模型训练的挑战。

Method: 两阶段训练：1) 监督微调，使用合成医学推理数据集和参数高效技术；2) 强化学习，采用GRPO和多组件奖励系统。

Result: 在MedQA、MMLU Pro和PubMedQA上分别达到87.1%、81.6%和79.6%，超越更大模型。

Conclusion: Gazal-R1为专业领域语言模型提供了高性能、高效和可解释的框架。

Abstract: We present Gazal-R1, a 32-billion-parameter language model that achieves
state-of-the-art performance in medical reasoning while providing transparent,
step-by-step explanations for clinical decision-making. Built upon Qwen3 32B,
our model demonstrates that strategic training can enable mid-sized models to
outperform significantly larger counterparts in specialized domains. We
developed a novel two-stage training pipeline: first, supervised fine-tuning on
a carefully curated dataset of 107,033 synthetic medical reasoning examples
that teaches structured clinical thinking, enhanced by advanced
parameter-efficient techniques including Weight-Decomposed Low-Rank Adaptation
(DoRA) and Rank-Stabilized LoRA (rsLoRA); second, reinforcement learning using
Group Relative Policy Optimization (GRPO) with a sophisticated multi-component
reward system that refines accuracy, format adherence, and reasoning quality.
Gazal-R1 achieves exceptional performance across medical benchmarks, scoring
87.1% on MedQA, 81.6% on MMLU Pro (Medical), and 79.6% on PubMedQA, surpassing
models up to 12x larger. Beyond its strong empirical results, this work
provides detailed insights into the challenges of training reasoning-capable
models in specialized domains, including issues with reward hacking, training
instability, and the fundamental tension between factual recall and detailed
reasoning. Our methodology offers a reproducible framework for developing
high-capability, domain-specific language models that balance performance,
efficiency, and explainability.

</details>


### [57] [Thunder-LLM: Efficiently Adapting LLMs to Korean with Minimal Resources](https://arxiv.org/abs/2506.21595)
*Jinpyo Kim,Gyeongje Cho,Chanwoo Park,Jongwon Park,Jongmin Kim,Yeonkyoun So,Jaejin Lee*

Main category: cs.CL

TL;DR: 本文提出了一种低成本方法，将现有英语大语言模型（LLM）适配到韩语，并分享了完整的端到端流程，包括数据收集、预处理、训练、基准测试和评估。


<details>
  <summary>Details</summary>
Motivation: 由于现有LLM在英语或中文以外的语言上表现不佳，且其端到端训练过程因专有性、技术复杂性等原因不透明，本文旨在填补这一空白，提供一种低成本的多语言适配方案。

Method: 通过收集韩语数据集、数据预处理、模型训练、创建下游基准测试和评估，实现英语LLM到韩语的适配。

Result: 提出的方法在低预算下有效提升了LLM的韩语能力，新模型Thunder-LLM和Thunder-LLM-Ins在韩语任务上表现优于现有模型。

Conclusion: 该方法为LLM的多语言适配提供了一种高效且低成本的解决方案，并公开了代码和经验。

Abstract: Since state-of-the-art LLMs often underperform in languages other than
English or Chinese, improving the capability of LLMs in new languages has
become an essential task. Moreover, LLMs' entire end-to-end training process
remains largely unknown to the public due to proprietary reasons, technical
complexity, inconsistent documentation, and ethical considerations. The
complete picture remains a closely guarded secret within the industry. This
paper presents methods to adapt an existing English-based LLM to Korean in a
low-budget scenario. We describe the entire end-to-end process: collecting
Korean datasets, preprocessing the data, training the model, creating
downstream benchmarks, and conducting evaluations. The evaluation results
indicate that our method can effectively and cost-efficiently add new language
capabilities to existing LLMs. Our new bilingual models, Thunder-LLM and
Thunder-LLM-Ins, achieve superior Korean performance compared to
state-of-the-art models while utilizing minimal data and computational
resources. We share our comprehensive experience and make the code publicly
available.

</details>


### [58] [Evaluating Multimodal Large Language Models on Educational Textbook Question Answering](https://arxiv.org/abs/2506.21596)
*Hessa A. Alawwad,Anas Zafar,Areej Alhothali,Usman Naseem,Ali Alkhathlan,Amani Jamal*

Main category: cs.CL

TL;DR: 评估多模态大语言模型（MLLMs）在教科书问答任务（TQA）中的表现，并引入轻量级多模态检索增强生成（RAG）方法。


<details>
  <summary>Details</summary>
Motivation: 测试MLLMs在复杂教育内容（如长课程和复杂图表）中的推理能力，填补现有研究的空白。

Method: 使用CK12-QA数据集评估LLaVA和LLaMA 3.2-Vision等模型，并提出一种结合段落和图表的RAG方法。

Result: 检索的教育内容对模型准确性和推理有积极影响，但也揭示了处理问题-上下文关系和噪声的局限性。

Conclusion: 研究为多模态AI驱动学习提供了未来研究方向，需改进问题-上下文关系和噪声处理。

Abstract: Multimodal large language models (MLLMs) have recently achieved significant
success in vision--language tasks. However, their capacity to reason over
complex, long lessons and intricate educational diagrams that cannot be
represented as a single natural image remains largely untested. In this work,
we present the first evaluation of state-of-the-art MLLMs on the textbook
question answering (TQA) task using the CK12-QA dataset. We assess the
performance of recent vision-language models, including LLaVA and LLaMA
3.2-Vision, across various input configurations. Additionally, we introduce a
lightweight multimodal retrieval-augmented generation (RAG) pipeline that
integrates both paragraphs and diagrams from the lesson into the prompt. Our
results demonstrate the influence of retrieved educational context on model
accuracy and reasoning, while also revealing current limitations in handling
question-context relationships and the potential for noise, pointing to key
directions for future research in multimodal AI-driven learning.

</details>


### [59] [Overview of the ClinIQLink 2025 Shared Task on Medical Question-Answering](https://arxiv.org/abs/2506.21597)
*Brandon Colelough,Davis Bartels,Dina Demner-Fushman*

Main category: cs.CL

TL;DR: ClinIQLink是一个共享任务，旨在测试大型语言模型在医学问答中的表现，任务包含4978个专家验证的问题对，覆盖多种格式，并通过自动化评分和医生审核评估模型。


<details>
  <summary>Details</summary>
Motivation: 测试大型语言模型在医学领域的问答能力，特别是针对全科医生水平的应用。

Method: 任务提供4978个专家验证的问题对，涵盖七种格式，模型通过Docker或Apptainer镜像提交，在CodaBench平台或Zaratan集群上运行。自动化评分（Task 1）和医生审核（Task 2）用于评估模型。

Result: 任务通过自动化评分和医生审核对模型表现进行评估。

Conclusion: ClinIQLink为医学领域的大型语言模型测试提供了标准化框架和评估方法。

Abstract: In this paper, we present an overview of ClinIQLink, a shared task,
collocated with the 24th BioNLP workshop at ACL 2025, designed to stress-test
large language models (LLMs) on medically-oriented question answering aimed at
the level of a General Practitioner. The challenge supplies 4,978
expert-verified, medical source-grounded question-answer pairs that cover seven
formats: true/false, multiple choice, unordered list, short answer,
short-inverse, multi-hop, and multi-hop-inverse. Participating systems, bundled
in Docker or Apptainer images, are executed on the CodaBench platform or the
University of Maryland's Zaratan cluster. An automated harness (Task 1) scores
closed-ended items by exact match and open-ended items with a three-tier
embedding metric. A subsequent physician panel (Task 2) audits the top model
responses.

</details>


### [60] [Structured Attention Matters to Multimodal LLMs in Document Understanding](https://arxiv.org/abs/2506.21600)
*Chang Liu,Hongkai Chen,Yujun Cai,Hang Wu,Qingwen Ye,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 研究发现，输入格式对多模态大语言模型（MLLMs）的文档理解性能有显著影响，结构化文本能提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨输入格式如何影响MLLMs的文档理解性能，发现原始OCR文本可能损害性能。

Method: 提出一种基于LaTex范式的结构保留方法，保持文档的层次和空间关系。

Result: 结构化文本显著提升MLLMs的文档问答性能，无需修改模型架构或额外训练。

Conclusion: 结构化输入能有效提升MLLMs的文档理解能力，减少注意力分散。

Abstract: Document understanding remains a significant challenge for multimodal large
language models (MLLMs). While previous research has primarily focused on
locating evidence pages through precise multimodal queries, our work
investigates a fundamental yet overlooked aspect: how input format influences
document comprehension performance. Through systematic analysis, we discover
that raw OCR text often impairs rather than improves MLLMs' performance, which
is a counterintuitive finding we attribute to attention dispersion and
structure loss. To further substantiate our hypothesis, we propose a novel
structure-preserving approach that encodes document elements using the LaTex
paradigm, maintaining the hierarchical organization and spatial relationships
critical for comprehension. Our attention analysis reveals that structured text
induces structured attention patterns on both textual and visual content,
directing models to focus on semantically meaningful regions while reducing
attention waste. This approach significantly enhances MLLMs' document question
answering performance across diverse document types without requiring
architectural modifications or additional training.

</details>


### [61] [BiMark: Unbiased Multilayer Watermarking for Large Language Models](https://arxiv.org/abs/2506.21602)
*Xiaoyan Feng,He Zhang,Yanjun Zhang,Leo Yu Zhang,Shirui Pan*

Main category: cs.CL

TL;DR: BiMark是一种新型水印框架，通过三个创新点解决了LLM生成文本的识别问题：模型无关检测、多层架构和多比特水印编码，实验表明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的发展，识别其生成文本的真实性成为迫切需求，现有水印方法难以同时满足文本质量、模型无关检测和消息嵌入能力的要求。

Method: 提出BiMark框架，包括比特翻转无偏重加权机制、多层架构和信息编码方法，以平衡文本质量与水印能力。

Result: BiMark在短文本中提取率提高30%，同时保持较低的困惑度，在下游任务中表现与非水印文本相当。

Conclusion: BiMark在文本质量和水印能力之间取得了平衡，为LLM生成文本的识别提供了有效解决方案。

Abstract: Recent advances in Large Language Models (LLMs) have raised urgent concerns
about LLM-generated text authenticity, prompting regulatory demands for
reliable identification mechanisms. Although watermarking offers a promising
solution, existing approaches struggle to simultaneously achieve three critical
requirements: text quality preservation, model-agnostic detection, and message
embedding capacity, which are crucial for practical implementation. To achieve
these goals, the key challenge lies in balancing the trade-off between text
quality preservation and message embedding capacity. To address this challenge,
we propose BiMark, a novel watermarking framework that achieves these
requirements through three key innovations: (1) a bit-flip unbiased reweighting
mechanism enabling model-agnostic detection, (2) a multilayer architecture
enhancing detectability without compromising generation quality, and (3) an
information encoding approach supporting multi-bit watermarking. Through
theoretical analysis and extensive experiments, we validate that, compared to
state-of-the-art multi-bit watermarking methods, BiMark achieves up to 30%
higher extraction rates for short texts while maintaining text quality
indicated by lower perplexity, and performs comparably to non-watermarked text
on downstream tasks such as summarization and translation.

</details>


### [62] [Operationalizing Automated Essay Scoring: A Human-Aware Approach](https://arxiv.org/abs/2506.21603)
*Yenisel Plasencia-Calaña*

Main category: cs.CL

TL;DR: 论文探讨了自动化作文评分（AES）系统的人本操作化，比较了机器学习与大型语言模型（LLM）方法的优缺点，重点关注偏差、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在超越准确性，探索AES系统在实际应用中的可靠性，尤其是人类可感知的维度。

Method: 比较了基于机器学习的AES模型和LLM方法，分析了它们在偏差、鲁棒性和可解释性方面的表现。

Result: 机器学习模型在准确性上优于LLM，但可解释性较差；LLM提供更丰富的解释，但两者在偏差和边缘分数鲁棒性上均存在挑战。

Conclusion: 研究揭示了不同方法之间的权衡，为开发更可靠和可信的AES系统提供了方向。

Abstract: This paper explores the human-centric operationalization of Automated Essay
Scoring (AES) systems, addressing aspects beyond accuracy. We compare various
machine learning-based approaches with Large Language Models (LLMs) approaches,
identifying their strengths, similarities and differences. The study
investigates key dimensions such as bias, robustness, and explainability,
considered important for human-aware operationalization of AES systems. Our
study shows that ML-based AES models outperform LLMs in accuracy but struggle
with explainability, whereas LLMs provide richer explanations. We also found
that both approaches struggle with bias and robustness to edge scores. By
analyzing these dimensions, the paper aims to identify challenges and
trade-offs between different methods, contributing to more reliable and
trustworthy AES methods.

</details>


### [63] [MemBench: Towards More Comprehensive Evaluation on the Memory of LLM-based Agents](https://arxiv.org/abs/2506.21605)
*Haoran Tan,Zeyu Zhang,Chen Ma,Xu Chen,Quanyu Dai,Zhenhua Dong*

Main category: cs.CL

TL;DR: 本文提出了一个更全面的数据集和基准（MemBench），用于评估基于LLM的代理的记忆能力，解决了现有评估方法在记忆多样性和交互场景上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在记忆多样性和交互场景上存在局限性，且缺乏全面的指标来多角度反映记忆能力。

Method: 构建包含事实记忆和反思记忆的数据集，并提出参与和观察两种交互场景，基于此设计MemBench基准。

Result: 提出了MemBench基准，从有效性、效率和容量等多方面评估记忆能力，并公开了数据集和项目。

Conclusion: MemBench为研究社区提供了一个更全面的记忆能力评估工具，推动了相关领域的发展。

Abstract: Recent works have highlighted the significance of memory mechanisms in
LLM-based agents, which enable them to store observed information and adapt to
dynamic environments. However, evaluating their memory capabilities still
remains challenges. Previous evaluations are commonly limited by the diversity
of memory levels and interactive scenarios. They also lack comprehensive
metrics to reflect the memory capabilities from multiple aspects. To address
these problems, in this paper, we construct a more comprehensive dataset and
benchmark to evaluate the memory capability of LLM-based agents. Our dataset
incorporates factual memory and reflective memory as different levels, and
proposes participation and observation as various interactive scenarios. Based
on our dataset, we present a benchmark, named MemBench, to evaluate the memory
capability of LLM-based agents from multiple aspects, including their
effectiveness, efficiency, and capacity. To benefit the research community, we
release our dataset and project at https://github.com/import-myself/Membench.

</details>


### [64] [Large Language Models as symbolic DNA of cultural dynamics](https://arxiv.org/abs/2506.21606)
*Parham Pourdavood,Michael Jacob,Terrence Deacon*

Main category: cs.CL

TL;DR: 论文提出将大语言模型（LLMs）视为类似DNA的文化信息载体，强调其作为压缩人类符号表达模式的外部存储库，而非自主智能或简单模仿工具。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在人类文化动态中的角色，超越传统视角，将其定位为促进文化进化的工具。

Method: 通过分析压缩、解压、外部化和递归四个特征，类比DNA的功能，论证LLMs如何保存文化规律。

Result: LLMs的意义在于为人类提供低风险环境下的自我反思和创意假设生成工具，而非竞争人类智能。

Conclusion: LLMs是文化可进化性的工具，支持人类生成新假设，同时依赖人类解释以保持其文化相关性。

Abstract: This paper proposes a novel conceptualization of Large Language Models (LLMs)
as externalized informational substrates that function analogously to DNA for
human cultural dynamics. Rather than viewing LLMs as either autonomous
intelligence or mere programmed mimicry, we argue they serve a broader role as
repositories that preserve compressed patterns of human symbolic
expression--"fossils" of meaningful dynamics that retain relational residues
without their original living contexts. Crucially, these compressed patterns
only become meaningful through human reinterpretation, creating a recursive
feedback loop where they can be recombined and cycle back to ultimately
catalyze human creative processes. Through analysis of four universal
features--compression, decompression, externalization, and recursion--we
demonstrate that just as DNA emerged as a compressed and externalized medium
for preserving useful cellular dynamics without containing explicit reference
to goal-directed physical processes, LLMs preserve useful regularities of human
culture without containing understanding of embodied human experience.
Therefore, we argue that LLMs' significance lies not in rivaling human
intelligence, but in providing humanity a tool for self-reflection and playful
hypothesis-generation in a low-stakes, simulated environment. This framework
positions LLMs as tools for cultural evolvability, enabling humanity to
generate novel hypotheses about itself while maintaining the human
interpretation necessary to ground these hypotheses in ongoing human aesthetics
and norms.

</details>


### [65] [CORE-KG: An LLM-Driven Knowledge Graph Construction Framework for Human Smuggling Networks](https://arxiv.org/abs/2506.21607)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.CL

TL;DR: CORE-KG是一种模块化框架，用于从法律文本构建可解释的知识图谱，通过类型感知的共指消解和领域引导的实体关系提取，显著减少了节点重复和噪声。


<details>
  <summary>Details</summary>
Motivation: 现有的知识图谱方法在处理法律文本时存在共指消解不足、噪声多和节点重复的问题，需要一种更高效的解决方案。

Method: CORE-KG采用两步流程：类型感知的共指消解和领域引导的实体关系提取，基于改进的GraphRAG框架。

Result: 与基线相比，CORE-KG减少了33.28%的节点重复和38.37%的法律噪声，生成更清晰的知识图谱。

Conclusion: CORE-KG为分析复杂犯罪网络提供了更可靠的基础，显著提升了知识图谱的质量。

Abstract: Human smuggling networks are increasingly adaptive and difficult to analyze.
Legal case documents offer valuable insights but are unstructured, lexically
dense, and filled with ambiguous or shifting references-posing challenges for
automated knowledge graph (KG) construction. Existing KG methods often rely on
static templates and lack coreference resolution, while recent LLM-based
approaches frequently produce noisy, fragmented graphs due to hallucinations,
and duplicate nodes caused by a lack of guided extraction. We propose CORE-KG,
a modular framework for building interpretable KGs from legal texts. It uses a
two-step pipeline: (1) type-aware coreference resolution via sequential,
structured LLM prompts, and (2) entity and relationship extraction using
domain-guided instructions, built on an adapted GraphRAG framework. CORE-KG
reduces node duplication by 33.28%, and legal noise by 38.37% compared to a
GraphRAG-based baseline-resulting in cleaner and more coherent graph
structures. These improvements make CORE-KG a strong foundation for analyzing
complex criminal networks.

</details>


### [66] [SysTemp: A Multi-Agent System for Template-Based Generation of SysML v2](https://arxiv.org/abs/2506.21608)
*Yasmine Bouamra,Bruno Yun,Alexandre Poisson,Frédéric Armetta*

Main category: cs.CL

TL;DR: SysTemp是一个基于多代理系统的工具，旨在通过自然语言规范自动生成SysML v2模型，解决学习语料稀缺和语法复杂的问题。


<details>
  <summary>Details</summary>
Motivation: SysML v2模型的自动生成在复杂系统工程中面临学习语料稀缺和语法复杂的挑战。

Method: 采用多代理系统，包括一个模板生成器，以结构化生成过程。

Result: 通过评估展示了该系统在提高SysML v2模型生成质量方面的潜力。

Conclusion: SysTemp为SysML v2模型的自动生成提供了有效的解决方案，但仍需进一步优化。

Abstract: The automatic generation of SysML v2 models represents a major challenge in
the engineering of complex systems, particularly due to the scarcity of
learning corpora and complex syntax. We present SysTemp, a system aimed at
facilitating and improving the creation of SysML v2 models from natural
language specifications. It is based on a multi-agent system, including a
template generator that structures the generation process. We discuss the
advantages and challenges of this system through an evaluation, highlighting
its potential to improve the quality of the generations in SysML v2 modeling.

</details>


### [67] [From Thinking to Output: Chain-of-Thought and Text Generation Characteristics in Reasoning Language Models](https://arxiv.org/abs/2506.21609)
*Junhao Liu,Zhenhao Xu,Yuxin Fang,Yichuan Chen,Zuobin Ying,Wenhan Chang*

Main category: cs.CL

TL;DR: 本文提出了一种新框架，用于分析四种前沿大型推理模型的推理特性，揭示了它们在推理过程中的不同模式，并提供了模型设计和评估的实用建议。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了大型语言模型（LLMs）推理过程和输出的系统性比较，尤其是在自我反思模式和多领域关联方面。

Method: 采用关键词统计和LLM-as-a-judge范式，结合多样化的真实场景问题数据集，评估推理连贯性和输出准确性。

Result: 研究发现不同模型在推理深度、中间步骤依赖以及与GPT-o1的相似性方面存在差异。

Conclusion: 研究为计算效率与推理鲁棒性之间的权衡提供了见解，并提出了模型设计和评估的改进建议。

Abstract: Recently, there have been notable advancements in large language models
(LLMs), demonstrating their growing abilities in complex reasoning. However,
existing research largely overlooks a thorough and systematic comparison of
these models' reasoning processes and outputs, particularly regarding their
self-reflection pattern (also termed "Aha moment") and the interconnections
across diverse domains. This paper proposes a novel framework for analyzing the
reasoning characteristics of four cutting-edge large reasoning models (GPT-o1,
DeepSeek-R1, Kimi-k1.5, and Grok-3) using keywords statistic and LLM-as-a-judge
paradigm. Our approach connects their internal thinking processes with their
final outputs. A diverse dataset consists of real-world scenario-based
questions covering logical deduction, causal inference, and multi-step
problem-solving. Additionally, a set of metrics is put forward to assess both
the coherence of reasoning and the accuracy of the outputs. The research
results uncover various patterns of how these models balance exploration and
exploitation, deal with problems, and reach conclusions during the reasoning
process. Through quantitative and qualitative comparisons, disparities among
these models are identified in aspects such as the depth of reasoning, the
reliance on intermediate steps, and the degree of similarity between their
thinking processes and output patterns and those of GPT-o1. This work offers
valuable insights into the trade-off between computational efficiency and
reasoning robustness and provides practical recommendations for enhancing model
design and evaluation in practical applications. We publicly release our
project at: https://github.com/ChangWenhan/FromThinking2Output

</details>


### [68] [Does Multimodality Lead to Better Time Series Forecasting?](https://arxiv.org/abs/2506.21611)
*Xiyuan Zhang,Boran Han,Haoyang Fang,Abdul Fatir Ansari,Shuai Zhang,Danielle C. Maddix,Cuixiong Hu,Andrew Gordon Wilson,Michael W. Mahoney,Hao Wang,Yan Liu,Huzefa Rangwala,George Karypis,Bernie Wang*

Main category: cs.CL

TL;DR: 研究探讨了在多模态时间序列预测中文本信息的作用，发现其效果因模型和数据特性而异，并提出了适用条件。


<details>
  <summary>Details</summary>
Motivation: 探索文本信息在多模态时间序列预测中的实际效果及其适用条件。

Method: 系统评估了14个预测任务，比较了对齐法和提示法两种多模态方法，并分析了模型架构和数据特性的影响。

Result: 多模态方法并非在所有情况下优于单模态基线，其效果取决于文本模型容量、时间序列模型强度、对齐策略、数据量和文本信息的互补性。

Conclusion: 提出了多模态预测的适用条件，为实际应用提供了指导。

Abstract: Recently, there has been growing interest in incorporating textual
information into foundation models for time series forecasting. However, it
remains unclear whether and under what conditions such multimodal integration
consistently yields gains. We systematically investigate these questions across
a diverse benchmark of 14 forecasting tasks spanning 7 domains, including
health, environment, and economics. We evaluate two popular multimodal
forecasting paradigms: aligning-based methods, which align time series and text
representations; and prompting-based methods, which directly prompt large
language models for forecasting. Although prior works report gains from
multimodal input, we find these effects are not universal across datasets and
models, and multimodal methods sometimes do not outperform the strongest
unimodal baselines. To understand when textual information helps, we
disentangle the effects of model architectural properties and data
characteristics. Our findings highlight that on the modeling side,
incorporating text information is most helpful given (1) high-capacity text
models, (2) comparatively weaker time series models, and (3) appropriate
aligning strategies. On the data side, performance gains are more likely when
(4) sufficient training data is available and (5) the text offers complementary
predictive signal beyond what is already captured from the time series alone.
Our empirical findings offer practical guidelines for when multimodality can be
expected to aid forecasting tasks, and when it does not.

</details>


### [69] [AdaptGOT: A Pre-trained Model for Adaptive Contextual POI Representation Learning](https://arxiv.org/abs/2506.21612)
*Xiaobin Ren,Xinyu Zhu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 提出AdaptGOT模型，结合自适应表示学习和地理-共现-文本信息，解决POI嵌入中的多上下文采样、多样性和泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有POI嵌入方法在多上下文采样、多样性和泛化方面存在不足，需更高效的多上下文策略和通用性。

Method: AdaptGOT模型包含三部分：上下文邻域生成（混合采样技术）、增强的GOT表示（注意力机制）、MoE自适应编码器-解码器架构。

Result: 在两个真实数据集和多个POI任务上验证了AdaptGOT的优越性能。

Conclusion: AdaptGOT通过自适应技术和多上下文整合，显著提升了POI嵌入的效果。

Abstract: Currently, considerable strides have been achieved in Point-of-Interest (POI)
embedding methodologies, driven by the emergence of novel POI tasks like
recommendation and classification. Despite the success of task-specific,
end-to-end models in POI embedding, several challenges remain. These include
the need for more effective multi-context sampling strategies, insufficient
exploration of multiple POI contexts, limited versatility, and inadequate
generalization. To address these issues, we propose the AdaptGOT model, which
integrates both the (Adapt)ive representation learning technique and the
Geographical-Co-Occurrence-Text (GOT) representation with a particular emphasis
on Geographical location, Co-Occurrence and Textual information. The AdaptGOT
model comprises three key components: (1) contextual neighborhood generation,
which integrates advanced mixed sampling techniques such as KNN, density-based,
importance-based, and category-aware strategies to capture complex contextual
neighborhoods; (2) an advanced GOT representation enhanced by an attention
mechanism, designed to derive high-quality, customized representations and
efficiently capture complex interrelations between POIs; and (3) the MoE-based
adaptive encoder-decoder architecture, which ensures topological consistency
and enriches contextual representation by minimizing Jensen-Shannon divergence
across varying contexts. Experiments on two real-world datasets and multiple
POI tasks substantiate the superior performance of the proposed AdaptGOT model.

</details>


### [70] [ChildGuard: A Specialized Dataset for Combatting Child-Targeted Hate Speech](https://arxiv.org/abs/2506.21613)
*Gautam Siddharth Kashyap,Mohammad Anas Azeez,Rafiq Ali,Zohaib Hasan Siddiqui,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: 论文提出ChildGuard1数据集，专门针对儿童仇恨言论，填补现有数据集的不足，并评估现有检测方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论数据集缺乏针对儿童的特定标注和情感影响分析，急需专门数据集以解决这一问题。

Method: 通过从现有语料库中提取并添加儿童特定标注，构建ChildGuard1数据集，并评估现有先进检测方法（如LLMs）的效果。

Result: ChildGuard1数据集提供了多样化的儿童仇恨言论上下文，并公开以促进进一步研究。

Conclusion: ChildGuard1为改进儿童仇恨言论检测方法提供了坚实基础，并呼吁更多研究关注此领域。

Abstract: The increasing prevalence of child-targeted hate speech online underscores
the urgent need for specialized datasets to address this critical issue.
Existing hate speech datasets lack agespecific annotations, fail to capture
nuanced contexts, and overlook the unique emotional impact on children. To
bridge this gap, we introduce ChildGuard1, a curated dataset derived from
existing corpora and enriched with child-specific annotations. ChildGuard
captures diverse contexts of child-targeted hate speech, spanning age groups.
We benchmark existing state-of-the-art hate speech detection methods, including
Large Language Models (LLMs), and assess their effectiveness in detecting and
contextualizing child-targeted hate speech. To foster further research in this
area, we publicly release ChildGuard, providing a robust foundation for
developing improved methods to detect and mitigate such harm.

</details>


### [71] [LastingBench: Defend Benchmarks Against Knowledge Leakage](https://arxiv.org/abs/2506.21614)
*Yixiong Fang,Tianran Sun,Yuling Shi,Min Wang,Xiaodong Gu*

Main category: cs.CL

TL;DR: LastingBench框架通过扰动和改写泄漏点，减少大语言模型在问答基准测试中的记忆效应，提升评估的公平性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在问答基准测试中可能通过记忆任务数据“作弊”，削弱评估的有效性。现有研究多关注检测数据泄漏，但缺乏减轻其影响的方法。

Method: 提出LastingBench框架，通过扰动识别泄漏点，并将其改写为反事实内容，破坏模型记忆同时保留评估意图。

Result: 实验显示，LastingBench显著减少了记忆效应，在问答基准测试中表现出性能差距。

Conclusion: LastingBench为长期维护基准测试的稳健性提供了实用且可扩展的解决方案，促进更公平的LLM评估。

Abstract: The increasing complexity of large language models (LLMs) raises concerns
about their ability to "cheat" on standard Question Answering (QA) benchmarks
by memorizing task-specific data. This undermines the validity of benchmark
evaluations, as they no longer reflect genuine model capabilities but instead
the effects of data leakage. While prior work has focused on detecting such
leakage, little attention has been given to mitigating its impact and
preserving the long-term utility of benchmarks. In this paper, we introduce
LastingBench, a novel framework designed to continuously reinforce and
safeguard existing benchmarks against knowledge leakage. LastingBench
identifies leakage points in the context through perturbation, then rewrites
the leakage points to counterfactual ones-disrupting memorization while
preserving the benchmark's original evaluative intent. Evaluations of
state-of-the-art QA benchmarks show significant performance gaps, highlighting
the efficacy of LastingBench in reducing memorization effects. LastingBench
offers a practical and scalable solution to ensure benchmark robustness over
time, promoting fairer and more interpretable evaluations of LLMs.

</details>


### [72] [Refine Medical Diagnosis Using Generation Augmented Retrieval and Clinical Practice Guidelines](https://arxiv.org/abs/2506.21615)
*Wenhao Li,Hongkuan Zhang,Hongwei Zhang,Zhengxu Li,Zengjie Dong,Yafan Chen,Niranjan Bidargaddi,Hong Liu*

Main category: cs.CL

TL;DR: GARMLE-G框架通过检索权威临床指南内容，生成与临床实践一致的医疗建议，避免了传统方法的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有医疗语言模型依赖ICD代码，无法捕捉临床医生的复杂推理过程，限制了模型的临床实用性。

Method: GARMLE-G结合LLM预测和EHR数据生成查询，通过嵌入相似性检索指南内容，并将其与模型输出融合。

Result: 原型系统在高血压诊断中表现优于基线方法，检索精度、语义相关性和指南依从性更优。

Conclusion: GARMLE-G提供了一种可扩展、低成本且无幻觉的方法，适用于临床实践中的广泛部署。

Abstract: Current medical language models, adapted from large language models (LLMs),
typically predict ICD code-based diagnosis from electronic health records
(EHRs) because these labels are readily available. However, ICD codes do not
capture the nuanced, context-rich reasoning clinicians use for diagnosis.
Clinicians synthesize diverse patient data and reference clinical practice
guidelines (CPGs) to make evidence-based decisions. This misalignment limits
the clinical utility of existing models. We introduce GARMLE-G, a
Generation-Augmented Retrieval framework that grounds medical language model
outputs in authoritative CPGs. Unlike conventional Retrieval-Augmented
Generation based approaches, GARMLE-G enables hallucination-free outputs by
directly retrieving authoritative guideline content without relying on
model-generated text. It (1) integrates LLM predictions with EHR data to create
semantically rich queries, (2) retrieves relevant CPG knowledge snippets via
embedding similarity, and (3) fuses guideline content with model output to
generate clinically aligned recommendations. A prototype system for
hypertension diagnosis was developed and evaluated on multiple metrics,
demonstrating superior retrieval precision, semantic relevance, and clinical
guideline adherence compared to RAG-based baselines, while maintaining a
lightweight architecture suitable for localized healthcare deployment. This
work provides a scalable, low-cost, and hallucination-free method for grounding
medical language models in evidence-based clinical practice, with strong
potential for broader clinical deployment.

</details>


### [73] [TIM: A Large-Scale Dataset and large Timeline Intelligence Model for Open-domain Timeline Summarization](https://arxiv.org/abs/2506.21616)
*Chuanrui Hu,Wei Hu,Penghang Yu,Hua Zhang,Bing-Kun Bao*

Main category: cs.CL

TL;DR: 论文提出了一种名为TIM的大规模时间线智能模型，用于开放领域时间线摘要（TLS），解决了现有方法在主题相关性和时间准确性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用通用大语言模型（LLMs）进行新闻摘要和时间戳定位，但在主题相关性和时间演化理解上表现不佳，导致摘要包含无关信息或不准确时间戳。

Method: 提出TIM模型，通过构建大规模TLS数据集（1000+新闻主题和3000+标注实例），并采用渐进优化策略，包括指令调优和双对齐奖励学习（结合语义和时间视角）。

Result: TIM在开放领域实验中表现出强大的时间线摘要能力。

Conclusion: TIM通过渐进优化策略，显著提升了开放领域时间线摘要的性能。

Abstract: Open-domain Timeline Summarization (TLS) is crucial for monitoring the
evolution of news topics. To identify changes in news topics, existing methods
typically employ general Large Language Models (LLMs) to summarize relevant
timestamps from retrieved news. While general LLMs demonstrate capabilities in
zero-shot news summarization and timestamp localization, they struggle with
assessing topic relevance and understanding topic evolution. Consequently, the
summarized information often includes irrelevant details or inaccurate
timestamps. To address these issues, we propose the first large Timeline
Intelligence Model (TIM) for open-domain TLS, which is capable of effectively
summarizing open-domain timelines. Specifically, we begin by presenting a
large-scale TLS dataset, comprising over 1,000 news topics and more than 3,000
annotated TLS instances. Furthermore, we propose a progressive optimization
strategy, which gradually enhance summarization performance. It employs
instruction tuning to enhance summarization and topic-irrelevant information
filtering capabilities. Following this, it exploits a novel dual-alignment
reward learning method that incorporates both semantic and temporal
perspectives, thereby improving the understanding of topic evolution
principles. Through this progressive optimization strategy, TIM demonstrates a
robust ability to summarize open-domain timelines. Extensive experiments in
open-domain demonstrate the effectiveness of our TIM.

</details>


### [74] [TrajTok: Technical Report for 2025 Waymo Open Sim Agents Challenge](https://arxiv.org/abs/2506.21618)
*Zhiyuan Zhang,Xiaosong Jia,Guanyu Chen,Qifeng Li,Junchi Yan*

Main category: cs.CL

TL;DR: TrajTok是一种轨迹标记器，结合数据驱动和基于规则的方法，用于离散的下一个标记预测行为生成模型，具有更好的覆盖性、对称性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有行为生成模型在覆盖性、对称性和鲁棒性方面的不足，提升轨迹预测的准确性。

Method: 结合数据驱动和基于规则的方法，引入空间感知标签平滑技术用于交叉熵损失。

Result: 在Waymo Open Sim Agents Challenge 2025中，SMART模型实现了0.7852的真实性评分。

Conclusion: TrajTok在轨迹标记和行为生成方面表现出色，未来将开源代码。

Abstract: In this technical report, we introduce TrajTok, a trajectory tokenizer for
discrete next-token-prediction based behavior generation models, which combines
data-driven and rule-based methods with better coverage, symmetry and
robustness, along with a spatial-aware label smoothing method for cross-entropy
loss. We adopt the tokenizer and loss for the SMART model and reach a superior
performance with realism score of 0.7852 on the Waymo Open Sim Agents Challenge
2025. We will open-source the code in the future.

</details>


### [75] [IndexTTS2: A Breakthrough in Emotionally Expressive and Duration-Controlled Auto-Regressive Zero-Shot Text-to-Speech](https://arxiv.org/abs/2506.21619)
*Siyi Zhou,Yiquan Zhou,Yi He,Xun Zhou,Jinchao Wang,Wei Deng,Jingchen Shu*

Main category: cs.CL

TL;DR: IndexTTS2提出了一种新的自回归模型友好的语音时长控制方法，支持精确时长控制和自由生成模式，并实现了音色与情感的分离控制，在零样本设置下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决自回归TTS模型在语音时长控制上的局限性，特别是在需要严格音视频同步的应用中，同时实现音色与情感的独立控制。

Method: 引入两种生成模式（精确时长控制和自由生成），结合GPT潜在表示增强稳定性，并通过软指令机制实现自然语言情感控制。

Result: 在零样本设置下，IndexTTS2在词错误率、说话人相似性和情感保真度上优于现有最先进的TTS模型。

Conclusion: IndexTTS2为自回归TTS模型提供了更灵活的时长控制和情感表达方式，适用于多种应用场景。

Abstract: Large-scale text-to-speech (TTS) models are typically categorized into
autoregressive and non-autoregressive systems. Although autoregressive systems
exhibit certain advantages in speech naturalness, their token-by-token
generation mechanism makes it difficult to precisely control the duration of
synthesized speech. This is a key limitation in applications such as video
dubbing that require strict audio-visual synchronization. This paper introduces
IndexTTS2, which proposes a novel and autoregressive-model-friendly method for
speech duration control. The method supports two generation modes: one allows
explicit specification of the number of generated tokens for precise duration
control; the other does not require manual input and lets the model freely
generate speech while preserving prosodic characteristics from the input
prompt. Furthermore, IndexTTS2 achieves disentanglement between emotional
expression and speaker identity, enabling independent control of timbre and
emotion. In the zero-shot setting, the model can perfectly reproduce the
emotional characteristics of the input prompt. Users may also provide a
separate emotion prompt, even from a different speaker, allowing the model to
reconstruct the target timbre while conveying the desired emotion. To enhance
clarity during strong emotional expressions, we incorporate GPT latent
representations to improve speech stability. Meanwhile, to lower the barrier
for emotion control, we design a soft instruction mechanism based on textual
descriptions by fine-tuning Qwen3. This enables effective guidance of speech
generation with desired emotional tendencies using natural language input.
Experimental results demonstrate that IndexTTS2 outperforms existing
state-of-the-art zero-shot TTS models in word error rate, speaker similarity,
and emotional fidelity.

</details>


### [76] [How Large Language Models play humans in online conversations: a simulated study of the 2016 US politics on Reddit](https://arxiv.org/abs/2506.21620)
*Daniele Cirulli,Giulio Cimini,Giovanni Palermo*

Main category: cs.CL

TL;DR: 研究评估了GPT-4在模拟2016年美国总统选举期间Reddit用户评论的能力，发现其能生成政治倾向和情感上接近真实的评论，但更易形成共识而非分歧。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）在政治相关在线讨论中的表现及其潜在影响。

Method: 通过三个实验，让GPT-4模拟真实或虚构的党派用户生成评论，并分析其政治倾向、情感和语言特征。

Result: GPT-4能生成逼真的评论，但更倾向于形成共识；真实与人工评论在语义嵌入空间中有区分，但人工难以辨别。

Conclusion: LLMs可能被用于渗透在线讨论并影响政治叙事，需警惕AI驱动的言论操纵。

Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for
natural language generation, with applications spanning from content creation
to social simulations. Their ability to mimic human interactions raises both
opportunities and concerns, particularly in the context of politically relevant
online discussions. In this study, we evaluate the performance of LLMs in
replicating user-generated content within a real-world, divisive scenario:
Reddit conversations during the 2016 US Presidential election. In particular,
we conduct three different experiments, asking GPT-4 to generate comments by
impersonating either real or artificial partisan users. We analyze the
generated comments in terms of political alignment, sentiment, and linguistic
features, comparing them against real user contributions and benchmarking
against a null model. We find that GPT-4 is able to produce realistic comments,
both in favor of or against the candidate supported by the community, yet
tending to create consensus more easily than dissent. In addition we show that
real and artificial comments are well separated in a semantically embedded
space, although they are indistinguishable by manual inspection. Our findings
provide insights on the potential use of LLMs to sneak into online discussions,
influence political debate and shape political narratives, bearing broader
implications of AI-driven discourse manipulation.

</details>


### [77] [The Open Proof Corpus: A Large-Scale Study of LLM-Generated Mathematical Proofs](https://arxiv.org/abs/2506.21621)
*Jasper Dekoninck,Ivo Petrov,Kristian Minchev,Mislav Balunovic,Martin Vechev,Miroslav Marinov,Maria Drencheva,Lyuba Konova,Milen Shumanov,Kaloyan Tsvetkov,Nikolay Drenchev,Lazar Todorov,Kalina Nikolova,Nikolay Georgiev,Vanesa Kalinkova,Margulan Ismoldayev*

Main category: cs.CL

TL;DR: 介绍了Open Proof Corpus（OPC），一个包含5000多个人工评估证明的数据集，用于推动LLM在数学证明生成中的研究。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、高质量的数学证明数据集，阻碍了LLM在数学证明生成中的进一步发展。

Method: 构建了OPC数据集，并利用其探索了自动化证明生成中的关键问题，如自然语言与形式证明生成的性能差距。

Result: 通过OPC微调的8B参数模型在评估证明正确性任务中表现与Gemini-2.5-Pro相当。

Conclusion: OPC为数学证明生成研究提供了重要资源，并展示了其实际应用价值。

Abstract: In recent months, large language models (LLMs) have made significant progress
in mathematical proof generation, but further advancement is hindered by the
lack of a large-scale, high-quality dataset of human-evaluated proofs. While
expensive to create, such a dataset is essential for driving improvements in
training and enabling a rigorous analysis of proof generation capabilities. In
this work, we present the Open Proof Corpus (OPC), a dataset comprising over
5,000 human-evaluated proofs produced by state-of-the-art LLMs. The OPC was
specifically designed for broad applicability and downstream usage in proof
generation research and is the first to include a substantial number of
correct, LLM-generated solutions to problems from prestigious mathematics
competitions such as the USAMO and IMO. Using the OPC, we explore critical
questions in automated proof generation: (1) the performance gap between
natural language and formal proof generation, (2) the discrepancy between
final-answer accuracy and full-proof validity, and (3) the impact of best-of-n
selection on proof quality. Finally, to showcase the utility of the OPC, we
finetune an 8B-parameter model on the dataset, obtaining a model that performs
on par with the best model, Gemini-2.5-Pro, on the task of evaluating proof
correctness.

</details>


### [78] [Adapting Foundation Speech Recognition Models to Impaired Speech: A Semantic Re-chaining Approach for Personalization of German Speech](https://arxiv.org/abs/2506.21622)
*Niclas Pokel,Pehuén Moure,Roman Boehringer,Yingqiang Gao*

Main category: cs.CL

TL;DR: 提出了一种轻量级管道，用于个性化ASR模型，改善非标准语音的转录质量。


<details>
  <summary>Details</summary>
Motivation: 解决ASR模型在处理非标准语音（如脑瘫或遗传障碍导致的语音障碍）时的挑战，因训练数据有限且收集标注困难。

Method: 提出了一种实用且轻量级的管道，通过选择单词和丰富小型语音障碍数据集，增强语义连贯性。

Result: 在儿童结构性语音障碍数据上应用后，转录质量显著提升。

Conclusion: 该方法有望减少非标准语音模式个体的沟通障碍。

Abstract: Speech impairments caused by conditions such as cerebral palsy or genetic
disorders pose significant challenges for automatic speech recognition (ASR)
systems. Despite recent advances, ASR models like Whisper struggle with
non-normative speech due to limited training data and the difficulty of
collecting and annotating non-normative speech samples. In this work, we
propose a practical and lightweight pipeline to personalize ASR models,
formalizing the selection of words and enriching a small, speech-impaired
dataset with semantic coherence. Applied to data from a child with a structural
speech impairment, our approach shows promising improvements in transcription
quality, demonstrating the potential to reduce communication barriers for
individuals with atypical speech patterns.

</details>


### [79] [Performance of diverse evaluation metrics in NLP-based assessment and text generation of consumer complaints](https://arxiv.org/abs/2506.21623)
*Peiheng Gao,Chen Yang,Ning Sun,Ričardas Zitikis*

Main category: cs.CL

TL;DR: 该研究通过结合人类经验训练的算法和合成数据生成方法，提升了机器学习在文本分类中的性能，特别是在消费者投诉分析中。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言中细微语义差异的捕捉问题，特别是在消费者投诉分析中，以提高分类准确性和鲁棒性。

Method: 结合人类经验训练的算法和专家评估的生成对抗网络（GAN）生成的合成数据，并通过专家注释进行优化。

Result: 显著提升了机器学习分类器的性能，降低了数据集获取成本，并改善了评估指标和鲁棒性。

Conclusion: 通过整合专家知识和高质量合成数据，可以有效提升文本分类任务的性能和经济性。

Abstract: Machine learning (ML) has significantly advanced text classification by
enabling automated understanding and categorization of complex, unstructured
textual data. However, accurately capturing nuanced linguistic patterns and
contextual variations inherent in natural language, particularly within
consumer complaints, remains a challenge. This study addresses these issues by
incorporating human-experience-trained algorithms that effectively recognize
subtle semantic differences crucial for assessing consumer relief eligibility.
Furthermore, we propose integrating synthetic data generation methods that
utilize expert evaluations of generative adversarial networks and are refined
through expert annotations. By combining expert-trained classifiers with
high-quality synthetic data, our research seeks to significantly enhance
machine learning classifier performance, reduce dataset acquisition costs, and
improve overall evaluation metrics and robustness in text classification tasks.

</details>


### [80] [Doc2SAR: A Synergistic Framework for High-Fidelity Extraction of Structure-Activity Relationships from Scientific Documents](https://arxiv.org/abs/2506.21625)
*Jiaxi Zhuang,Kangning Li,Jue Hou,Mingjun Xu,Zhifeng Gao,Hengxing Cai*

Main category: cs.CL

TL;DR: 论文提出了Doc2SAR框架，结合领域专用工具和微调的多模态大语言模型（MLLMs），显著提升了科学文献中分子结构-活性关系（SARs）的提取性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提取SARs时面临文档格式多样性和现有技术（如规则模板或通用MLLMs）的局限性，需要更高效的解决方案。

Method: 提出Doc2SAR框架，整合领域专用工具和经过监督微调的MLLMs，并开发了DocSAR-200基准数据集用于评估。

Result: Doc2SAR在DocSAR-200上实现了80.78%的表格召回率，比GPT-4o高出51.48%，且推理高效。

Conclusion: Doc2SAR为SAR提取提供了高效、准确的解决方案，并通过Web应用展示了实用性。

Abstract: Extracting molecular structure-activity relationships (SARs) from scientific
literature and patents is essential for drug discovery and materials research.
However, this task remains challenging due to heterogeneous document formats
and limitations of existing methods. Specifically, rule-based approaches
relying on rigid templates fail to generalize across diverse document layouts,
while general-purpose multimodal large language models (MLLMs) lack sufficient
accuracy and reliability for specialized tasks, such as layout detection and
optical chemical structure recognition (OCSR). To address these challenges, we
introduce DocSAR-200, a rigorously annotated benchmark of 200 scientific
documents designed specifically for evaluating SAR extraction methods.
Additionally, we propose Doc2SAR, a novel synergistic framework that integrates
domain-specific tools with MLLMs enhanced via supervised fine-tuning (SFT).
Extensive experiments demonstrate that Doc2SAR achieves state-of-the-art
performance across various document types, significantly outperforming leading
end-to-end baselines. Specifically, Doc2SAR attains an overall Table Recall of
80.78% on DocSAR-200, exceeding end2end GPT-4o by 51.48%. Furthermore, Doc2SAR
demonstrates practical usability through efficient inference and is accompanied
by a web app.

</details>


### [81] [Do We Really Need GNNs with Explicit Structural Modeling? MLPs Suffice for Language Model Representations](https://arxiv.org/abs/2506.21682)
*Li Zhou,Hao Jiang,Junjie Li,Zefeng Zhao,Feng Jiang,Wenyu Chen,Haizhou Li*

Main category: cs.CL

TL;DR: 该论文通过信息论视角提出了一种探测框架，评估显式结构建模对语言模型表示的作用，并探讨MLPs作为GNNs高效替代方案的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究发现GNNs未能充分利用结构信息，而MLPs在结构感知任务中表现优异，因此提出系统评估结构建模的作用。

Method: 引入模块化探测框架，选择性使用GNN或其解耦组件（消息传递和特征转换），并通过Edge Probing Suite评估。

Result: MLPs作为特征转换模块能有效提升语言模型表示中的语言知识，而仅依赖消息传递的模型表现较差。

Conclusion: 特征转换操作对提升语言模型表示至关重要，MLPs可作为GNNs的高效替代方案。

Abstract: Explicit structural information has been proven to be encoded by Graph Neural
Networks (GNNs), serving as auxiliary knowledge to enhance model capabilities
and improve performance in downstream NLP tasks. However, recent studies
indicate that GNNs fail to fully utilize structural information, whereas
Multi-Layer Perceptrons (MLPs), despite lacking the message-passing mechanisms
inherent to GNNs, exhibit a surprising ability in structure-aware tasks.
Motivated by these findings, this paper introduces a comprehensive probing
framework from an information-theoretic perspective. The framework is designed
to systematically assess the role of explicit structural modeling in enhancing
language model (LM) representations and to investigate the potential of MLPs as
efficient and scalable alternatives to GNNs. We extend traditional probing
classifiers by incorporating a control module that allows for selective use of
either the full GNN model or its decoupled components, specifically, the
message-passing and feature-transformation operations.This modular approach
isolates and assesses the individual contributions of these operations,
avoiding confounding effects from the complete GNN architecture. Using the Edge
Probing Suite, a diagnostic tool for evaluating the linguistic knowledge
encoded in LMs, we find that MLPs, when used as feature-transformation modules,
consistently improve the linguistic knowledge captured in LM representations
across different architectures. They effectively encode both syntactic and
semantic patterns. Similarly, GNNs that incorporate feature-transformation
operations show beneficial effects. In contrast, models that rely solely on
message-passing operations tend to underperform, often leading to negative
impacts on probing task performance.

</details>


### [82] [ANUBHUTI: A Comprehensive Corpus For Sentiment Analysis In Bangla Regional Languages](https://arxiv.org/abs/2506.21686)
*Swastika Kundu,Autoshi Ibrahim,Mithila Rahman,Tanvir Ahmed*

Main category: cs.CL

TL;DR: ANUBHUTI是一个包含2000句孟加拉语方言的标注数据集，支持情感分析，填补了低资源方言研究的空白。


<details>
  <summary>Details</summary>
Motivation: 由于语言多样性和标注数据有限，孟加拉方言的情感分析研究不足。

Method: 数据集包含政治、宗教和中性文本，采用双重标注方案（主题分类和情感标注），由专家翻译和标注，并通过一致性检验优化。

Result: 数据集质量高，标注一致性强，适用于低资源方言的情感分析。

Conclusion: ANUBHUTI为孟加拉方言的情感分析提供了重要资源，提升了自然语言处理的准确性和上下文感知能力。

Abstract: Sentiment analysis for regional dialects of Bangla remains an underexplored
area due to linguistic diversity and limited annotated data. This paper
introduces ANUBHUTI, a comprehensive dataset consisting of 2000 sentences
manually translated from standard Bangla into four major regional dialects
Mymensingh, Noakhali, Sylhet, and Chittagong. The dataset predominantly
features political and religious content, reflecting the contemporary socio
political landscape of Bangladesh, alongside neutral texts to maintain balance.
Each sentence is annotated using a dual annotation scheme: multiclass thematic
labeling categorizes sentences as Political, Religious, or Neutral, and
multilabel emotion annotation assigns one or more emotions from Anger,
Contempt, Disgust, Enjoyment, Fear, Sadness, and Surprise. Expert native
translators conducted the translation and annotation, with quality assurance
performed via Cohens Kappa inter annotator agreement, achieving strong
consistency across dialects. The dataset was further refined through systematic
checks for missing data, anomalies, and inconsistencies. ANUBHUTI fills a
critical gap in resources for sentiment analysis in low resource Bangla
dialects, enabling more accurate and context aware natural language processing.

</details>


### [83] [Identifying Speaker Information in Feed-Forward Layers of Self-Supervised Speech Transformers](https://arxiv.org/abs/2506.21712)
*Tzu-Quan Lin,Hsi-Chun Cheng,Hung-yi Lee,Hao Tang*

Main category: cs.CL

TL;DR: 本文通过分析自监督语音Transformer中的神经元，识别出与说话者信息相关的神经元，并通过保护这些神经元在剪枝过程中显著保留说话者相关任务的性能。


<details>
  <summary>Details</summary>
Motivation: 探索自监督语音Transformer如何编码说话者信息，填补相关研究的空白。

Method: 分析前馈层中与k-means聚类和i-vector相关的神经元，识别与说话者信息相关的神经元。

Result: 这些神经元与广泛的语音和性别类别相关，保护它们能显著保留说话者相关任务的性能。

Conclusion: 这些神经元在编码说话者信息中起关键作用，保护它们有助于提升模型在说话者相关任务中的表现。

Abstract: In recent years, the impact of self-supervised speech Transformers has
extended to speaker-related applications. However, little research has explored
how these models encode speaker information. In this work, we address this gap
by identifying neurons in the feed-forward layers that are correlated with
speaker information. Specifically, we analyze neurons associated with k-means
clusters of self-supervised features and i-vectors. Our analysis reveals that
these clusters correspond to broad phonetic and gender classes, making them
suitable for identifying neurons that represent speakers. By protecting these
neurons during pruning, we can significantly preserve performance on
speaker-related task, demonstrating their crucial role in encoding speaker
information.

</details>


### [84] [(Fact) Check Your Bias](https://arxiv.org/abs/2506.21745)
*Eivind Morris Bakke,Nora Winger Heggelund*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLM）中的参数知识偏见如何影响HerO系统的事实核查结果，发现直接提示时模型对近半数声明标记为“证据不足”，而故意注入的偏见显著影响检索结果。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在自动事实核查系统中的参数知识偏见及其对结果的影响。

Method: 通过两种实验：1）直接提示模型进行事实核查；2）故意注入偏见并观察其对检索结果的影响。

Result: 直接提示时，模型对50%的声明标记为“证据不足”；故意注入偏见导致50%的检索证据因视角不同而独特。

Conclusion: 尽管检索证据因提示策略不同而变化，最终预测结果表现出稳定性，但模型存在固有负面偏见。

Abstract: Automatic fact verification systems increasingly rely on large language
models (LLMs). We investigate how parametric knowledge biases in these models
affect fact-checking outcomes of the HerO system (baseline for FEVER-25). We
examine how the system is affected by: (1) potential bias in Llama 3.1's
parametric knowledge and (2) intentionally injected bias. When prompted
directly to perform fact-verification, Llama 3.1 labels nearly half the claims
as "Not Enough Evidence". Using only its parametric knowledge it is able to
reach a verdict on the remaining half of the claims. In the second experiment,
we prompt the model to generate supporting, refuting, or neutral fact-checking
documents. These prompts significantly influence retrieval outcomes, with
approximately 50\% of retrieved evidence being unique to each perspective.
Notably, the model sometimes refuses to generate supporting documents for
claims it believes to be false, creating an inherent negative bias. Despite
differences in retrieved evidence, final verdict predictions show stability
across prompting strategies. The code is available at:
https://github.com/eibakke/FEVER-8-Shared-Task

</details>


### [85] [Evaluating List Construction and Temporal Understanding capabilities of Large Language Models](https://arxiv.org/abs/2506.21783)
*Alexandru Dumitru,V Venktesh,Adam Jatowt,Avishek Anand*

Main category: cs.CL

TL;DR: 论文提出了一个名为TLQA的基准测试，用于评估大型语言模型在时间引用列表问答任务中的表现，发现现有模型在时间对齐和列表构建方面存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在时间理解任务中容易产生幻觉和错误，现有研究未充分评估模型在列表答案构建中的时间理解能力。

Method: 提出TLQA基准测试，要求模型生成与时间区间对齐的结构化列表答案，并在闭卷和开放域设置下评估模型表现。

Result: 当前模型在闭卷设置中难以提供完整答案和时间对齐的事实，开放域设置中检索能力有待提升。

Conclusion: TLQA基准为未来研究提供了明确方向，代码和基准已开源。

Abstract: Large Language Models (LLMs) have demonstrated immense advances in a wide
range of natural language tasks. However, these models are susceptible to
hallucinations and errors on particularly temporal understanding tasks
involving multiple entities in answers. In such tasks, they fail to associate
entities with accurate time intervals, generate a complete list of entities in
answers or reason about events associated with specific temporal bounds.
Existing works do not extensively evaluate the abilities of the model to
perform implicit and explicit temporal understanding in a list answer
construction setup. To bridge this gap, we propose the Time referenced List
based Question Answering or TLQA benchmark that requires structured answers in
list format aligned with corresponding time periods. Our TLQA benchmark,
requires both list construction and temporal understanding simultaneously,
which to the best of our knowledge has not been explored in prior benchmarks.
We investigate the temporal understanding and list construction capabilities of
state-of-the-art generative models on TLQA in closed-book and open-domain
settings. Our findings reveal significant shortcomings in current models,
particularly their inability to provide complete answers and temporally align
facts in a closed-book setup and the need to improve retrieval in open-domain
setup, providing clear future directions for research on TLQA. The benchmark
and code at https://github.com/elixir-research-group/TLQA.

</details>


### [86] [Offensive Language Detection on Social Media Using XLNet](https://arxiv.org/abs/2506.21795)
*Reem Alothman,Hafida Benhidour,Said Kerrache*

Main category: cs.CL

TL;DR: 提出了一种基于XLNet的自动检测社交媒体上攻击性语言的模型，并与BERT进行比较，结果显示XLNet在检测攻击性内容方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上攻击性内容增多，手动审核不现实，需要自动化系统。

Method: 使用XLNet和BERT模型，基于OLID数据集进行实验，并采用过采样和欠采样策略处理类别不平衡。

Result: XLNet在检测攻击性内容方面优于BERT，但BERT在识别攻击目标上略优。过采样和欠采样策略有效。

Conclusion: XLNet和迁移学习架构在检测社交媒体攻击性语言方面具有潜力。

Abstract: The widespread use of text-based communication on social media-through chats,
comments, and microblogs-has improved user interaction but has also led to an
increase in offensive content, including hate speech, racism, and other forms
of abuse. Due to the enormous volume of user-generated content, manual
moderation is impractical, which creates a need for automated systems that can
detect offensive language. Deep learning models, particularly those using
transfer learning, have demonstrated significant success in understanding
natural language through large-scale pretraining. In this study, we propose an
automatic offensive language detection model based on XLNet, a generalized
autoregressive pretraining method, and compare its performance with BERT
(Bidirectional Encoder Representations from Transformers), which is a widely
used baseline in natural language processing (NLP). Both models are evaluated
using the Offensive Language Identification Dataset (OLID), a benchmark Twitter
dataset that includes hierarchical annotations. Our experimental results show
that XLNet outperforms BERT in detecting offensive content and in categorizing
the types of offenses, while BERT performs slightly better in identifying the
targets of the offenses. Additionally, we find that oversampling and
undersampling strategies are effective in addressing class imbalance and
improving classification performance. These findings highlight the potential of
transfer learning and XLNet-based architectures to create robust systems for
detecting offensive language on social media platforms.

</details>


### [87] [A suite of allotaxonometric tools for the comparison of complex systems using rank-turbulence divergence](https://arxiv.org/abs/2506.21808)
*Jonathan St-Onge,Ashley M. A. Fehr,Carter Ward,Calla G. Beauregard,Michael V. Arnold,Samuel F. Rosenblatt,Benjamin Cooley,Christopher M. Danforth,Peter Sheridan Dodds*

Main category: cs.CL

TL;DR: 论文介绍了一种名为allotaxonographs的工具，用于可视化比较重尾分布对，支持多种度量方法，并提供了Matlab、Javascript和Python的实现。


<details>
  <summary>Details</summary>
Motivation: 复杂系统的描述和比较需要理论支持的工具，allotaxonographs旨在满足这一需求。

Method: 围绕类型湍流现象，设计allotaxonographs工具，支持多种度量方法（如rank-turbulence divergence、Jenson-Shannon divergence等），并提供多语言实现。

Result: 开发了适用于Matlab、Javascript和Python的allotaxonographs工具套件，满足不同使用场景。

Conclusion: allotaxonographs为复杂系统的比较提供了灵活且理论支持的可视化工具。

Abstract: Describing and comparing complex systems requires principled, theoretically
grounded tools. Built around the phenomenon of type turbulence,
allotaxonographs provide map-and-list visual comparisons of pairs of
heavy-tailed distributions. Allotaxonographs are designed to accommodate a wide
range of instruments including rank- and probability-turbulence divergences,
Jenson-Shannon divergence, and generalized entropy divergences. Here, we
describe a suite of programmatic tools for rendering allotaxonographs for
rank-turbulence divergence in Matlab, Javascript, and Python, all of which have
different use cases.

</details>


### [88] [Exploring the Structure of AI-Induced Language Change in Scientific English](https://arxiv.org/abs/2506.21817)
*Riley Galpin,Bryce Anderson,Tom S. Juzek*

Main category: cs.CL

TL;DR: 研究探讨了科学英语中词汇频率的突然变化，特别是由大型语言模型（如ChatGPT）引起的语义和语用变化，而非简单的同义词替换。


<details>
  <summary>Details</summary>
Motivation: 近年来科学英语词汇频率的突然变化（如“delve”、“intricate”、“crucial”等词的激增）与大型语言模型的影响相关，但其具体结构尚不明确。

Method: 通过PubMed科学摘要的频率趋势，系统分析同义词组，并引入词性标注以量化语法类别和词形的变化。

Result: 发现语义集群整体变化，表明变化主要是语义和语用的；同时“important”等词的使用显著下降，揭示了更复杂的语言变化模式。

Conclusion: 大型语言模型对语言的影响主要是语义和语用的，而非纯粹的词汇替换，这有助于理解语言技术如何塑造人类语言。

Abstract: Scientific English has undergone rapid and unprecedented changes in recent
years, with words such as "delve," "intricate," and "crucial" showing
significant spikes in frequency since around 2022. These changes are widely
attributed to the growing influence of Large Language Models like ChatGPT in
the discourse surrounding bias and misalignment. However, apart from changes in
frequency, the exact structure of these linguistic shifts has remained unclear.
The present study addresses this and investigates whether these changes involve
the replacement of synonyms by suddenly 'spiking words,' for example, "crucial"
replacing "essential" and "key," or whether they reflect broader semantic and
pragmatic qualifications. To further investigate structural changes, we include
part of speech tagging in our analysis to quantify linguistic shifts over
grammatical categories and differentiate between word forms, like "potential"
as a noun vs. as an adjective. We systematically analyze synonym groups for
widely discussed 'spiking words' based on frequency trends in scientific
abstracts from PubMed. We find that entire semantic clusters often shift
together, with most or all words in a group increasing in usage. This pattern
suggests that changes induced by Large Language Models are primarily semantic
and pragmatic rather than purely lexical. Notably, the adjective "important"
shows a significant decline, which prompted us to systematically analyze
decreasing lexical items. Our analysis of "collapsing" words reveals a more
complex picture, which is consistent with organic language change and contrasts
with the patterns of the abrupt spikes. These insights into the structure of
language change contribute to our understanding of how language technology
continues to shape human language.

</details>


### [89] [Towards Transparent AI: A Survey on Explainable Large Language Models](https://arxiv.org/abs/2506.21812)
*Avash Palikhe,Zhenyu Yu,Zichong Wang,Wenbin Zhang*

Main category: cs.CL

TL;DR: 该论文综述了大型语言模型（LLMs）的可解释性方法，分类并评估了基于不同Transformer架构的XAI技术，探讨了实际应用中的挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: LLMs的决策过程缺乏透明度，限制了其在高风险领域的应用，因此需要系统化的可解释性方法。

Method: 通过分类（编码器、解码器、编码-解码器模型）和评估XAI技术，分析其在实践中的应用。

Result: 提供了对现有XAI方法的全面回顾，并指出了评估标准、资源及未来研究方向。

Conclusion: 需进一步开发透明且负责任的LLMs，以解决可解释性挑战并推动实际应用。

Abstract: Large Language Models (LLMs) have played a pivotal role in advancing
Artificial Intelligence (AI). However, despite their achievements, LLMs often
struggle to explain their decision-making processes, making them a 'black box'
and presenting a substantial challenge to explainability. This lack of
transparency poses a significant obstacle to the adoption of LLMs in
high-stakes domain applications, where interpretability is particularly
essential. To overcome these limitations, researchers have developed various
explainable artificial intelligence (XAI) methods that provide
human-interpretable explanations for LLMs. However, a systematic understanding
of these methods remains limited. To address this gap, this survey provides a
comprehensive review of explainability techniques by categorizing XAI methods
based on the underlying transformer architectures of LLMs: encoder-only,
decoder-only, and encoder-decoder models. Then these techniques are examined in
terms of their evaluation for assessing explainability, and the survey further
explores how these explanations are leveraged in practical applications.
Finally, it discusses available resources, ongoing research challenges, and
future directions, aiming to guide continued efforts toward developing
transparent and responsible LLMs.

</details>


### [90] [PARSI: Persian Authorship Recognition via Stylometric Integration](https://arxiv.org/abs/2506.21840)
*Kourosh Shahnazari,Mohammadali Keshtparvar,Seyed Moein Ayyoubzadeh*

Main category: cs.CL

TL;DR: 提出了一种用于波斯古典诗歌作者归属的多输入神经网络框架，结合语义、风格和韵律特征，在67位诗人中达到71%准确率，高置信度预测时可达97%。


<details>
  <summary>Details</summary>
Motivation: 解决波斯古典诗歌在语言、风格和韵律方面的复杂性对计算作者归属的挑战。

Method: 使用基于Transformer的语言编码器，结合Word2Vec嵌入、风格测量和韵律编码，构建多输入神经网络框架。

Result: 加权投票方案准确率为71%，高置信度阈值（0.9）下准确率达97%。

Conclusion: 该方法为波斯诗歌的作者归属和风格分析提供了有效工具，并支持多语言作者归属和生成模型研究。

Abstract: The intricate linguistic, stylistic, and metrical aspects of Persian
classical poetry pose a challenge for computational authorship attribution. In
this work, we present a versatile framework to determine authorship among 67
prominent poets. We employ a multi-input neural framework consisting of a
transformer-based language encoder complemented by features addressing the
semantic, stylometric, and metrical dimensions of Persian poetry. Our feature
set encompasses 100-dimensional Word2Vec embeddings, seven stylometric
measures, and categorical encodings of poetic form and meter. We compiled a
vast corpus of 647,653 verses of the Ganjoor digital collection, validating the
data through strict preprocessing and author verification while preserving
poem-level splitting to prevent overlap. This work employs verse-level
classification and majority and weighted voting schemes in evaluation,
revealing that weighted voting yields 71% accuracy. We further investigate
threshold-based decision filtering, allowing the model to generate highly
confident predictions, achieving 97% accuracy at a 0.9 threshold, though at
lower coverage. Our work focuses on the integration of deep representational
forms with domain-specific features for improved authorship attribution. The
results illustrate the potential of our approach for automated classification
and the contribution to stylistic analysis, authorship disputes, and general
computational literature research. This research will facilitate further
research on multilingual author attribution, style shift, and generative
modeling of Persian poetry.

</details>


### [91] [The Consistency Hypothesis in Uncertainty Quantification for Large Language Models](https://arxiv.org/abs/2506.21849)
*Quan Xiao,Debarun Bhattacharjya,Balaji Ganesan,Radu Marinescu,Katsiaryna Mirylenka,Nhan H Pham,Michael Glass,Junkyu Lee*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）输出置信度的估计方法，提出了基于生成一致性的假设（一致性假设），并通过统计测试和实证研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在需要高用户信任的实际应用中，准确估计LLM输出的置信度至关重要。黑盒不确定性量化（UQ）方法因其仅需模型API访问而受到关注。

Method: 论文形式化了生成一致性作为置信度代理的假设（一致性假设），提出了三个数学陈述及统计测试，并在8个基准数据集和3个任务上进行了实证研究。

Result: 研究发现一致性假设在不同设置下普遍成立，其中‘Sim-Any’假设最具可操作性。基于此提出的无数据黑盒UQ方法在置信度估计上优于基线方法。

Conclusion: 一致性假设的实证观察具有实际价值，为LLM输出的置信度估计提供了新思路。

Abstract: Estimating the confidence of large language model (LLM) outputs is essential
for real-world applications requiring high user trust. Black-box uncertainty
quantification (UQ) methods, relying solely on model API access, have gained
popularity due to their practical benefits. In this paper, we examine the
implicit assumption behind several UQ methods, which use generation consistency
as a proxy for confidence, an idea we formalize as the consistency hypothesis.
We introduce three mathematical statements with corresponding statistical tests
to capture variations of this hypothesis and metrics to evaluate LLM output
conformity across tasks. Our empirical investigation, spanning 8 benchmark
datasets and 3 tasks (question answering, text summarization, and text-to-SQL),
highlights the prevalence of the hypothesis under different settings. Among the
statements, we highlight the `Sim-Any' hypothesis as the most actionable, and
demonstrate how it can be leveraged by proposing data-free black-box UQ methods
that aggregate similarities between generations for confidence estimation.
These approaches can outperform the closest baselines, showcasing the practical
value of the empirically observed consistency hypothesis.

</details>


### [92] [LinguaSynth: Heterogeneous Linguistic Signals for News Classification](https://arxiv.org/abs/2506.21848)
*Duo Zhang,Junyi Mo*

Main category: cs.CL

TL;DR: LinguaSynth是一种新型文本分类框架，通过整合五种互补的语言特征类型，在透明逻辑回归模型中实现高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在NLP中的可解释性和计算效率问题。

Method: 整合五种语言特征类型（词汇、句法、实体级、词级语义和文档级语义）于逻辑回归模型。

Result: 在20 Newsgroups数据集上达到84.89%准确率，超越TF-IDF基线3.32%。

Conclusion: LinguaSynth为可解释且高效的NLP模型设定了新标准，挑战了深度神经网络在文本分类中的必要性。

Abstract: Deep learning has significantly advanced NLP, but its reliance on large
black-box models introduces critical interpretability and computational
efficiency concerns. This paper proposes LinguaSynth, a novel text
classification framework that strategically integrates five complementary
linguistic feature types: lexical, syntactic, entity-level, word-level
semantics, and document-level semantics within a transparent logistic
regression model. Unlike transformer-based architectures, LinguaSynth maintains
interpretability and computational efficiency, achieving an accuracy of 84.89
percent on the 20 Newsgroups dataset and surpassing a robust TF-IDF baseline by
3.32 percent. Through rigorous feature interaction analysis, we show that
syntactic and entity-level signals provide essential disambiguation and
effectively complement distributional semantics. LinguaSynth sets a new
benchmark for interpretable, resource-efficient NLP models and challenges the
prevailing assumption that deep neural networks are necessary for
high-performing text classification.

</details>


### [93] [Derivational Probing: Unveiling the Layer-wise Derivation of Syntactic Structures in Neural Language Models](https://arxiv.org/abs/2506.21861)
*Taiga Someya,Ryo Yoshida,Hitomi Yanaka,Yohei Oseki*

Main category: cs.CL

TL;DR: 论文提出Derivational Probing方法，研究BERT模型中微观和宏观句法结构在不同层的构建过程。


<details>
  <summary>Details</summary>
Motivation: 探究神经网络语言模型如何在不同层中构建句法结构，尤其是微观和宏观结构的形成过程。

Method: 采用Derivational Probing方法，分析BERT模型中词嵌入在层间传播时的句法结构变化。

Result: 实验显示，微观句法结构在低层形成，逐渐整合为宏观结构；宏观结构的构建时机对下游任务性能至关重要。

Conclusion: 研究揭示了BERT模型中句法结构的自底向上构建过程，并指出全局句法信息整合的最佳时机。

Abstract: Recent work has demonstrated that neural language models encode syntactic
structures in their internal representations, yet the derivations by which
these structures are constructed across layers remain poorly understood. In
this paper, we propose Derivational Probing to investigate how micro-syntactic
structures (e.g., subject noun phrases) and macro-syntactic structures (e.g.,
the relationship between the root verbs and their direct dependents) are
constructed as word embeddings propagate upward across layers. Our experiments
on BERT reveal a clear bottom-up derivation: micro-syntactic structures emerge
in lower layers and are gradually integrated into a coherent macro-syntactic
structure in higher layers. Furthermore, a targeted evaluation on subject-verb
number agreement shows that the timing of constructing macro-syntactic
structures is critical for downstream performance, suggesting an optimal timing
for integrating global syntactic information.

</details>


### [94] [DeepTalk: Towards Seamless and Smart Speech Interaction with Adaptive Modality-Specific MoE](https://arxiv.org/abs/2506.21864)
*Hang Shao,Heting Gao,Yunhang Shen,Jiawei Chen,Lijiang Li,Zuwei Long,Bo Tong,Ke Li,Xing Sun*

Main category: cs.CL

TL;DR: DeepTalk是一种基于混合专家（MoE）架构的自适应模态专家学习框架，旨在解决原生多模态大语言模型（MLLMs）因数据不足导致的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 原生MLLMs在保留丰富副语言特征（如情感和韵律）的同时，因配对语音-文本数据不足而面临灾难性遗忘和性能下降的问题。

Method: DeepTalk通过MoE架构自适应区分模态专家，进行单模态训练后联合多模态协作训练。

Result: DeepTalk仅导致5.5%的性能下降，显著优于原生MLLMs（如GLM-4-Voice）的20%下降，且端到端对话延迟保持在0.5秒内。

Conclusion: DeepTalk在保持低延迟的同时，显著提升了原生MLLMs的性能，为智能语音交互提供了无缝体验。

Abstract: Native multimodal large language models (MLLMs) restructure a single large
language model (LLM) into a spoken language model (SLM) capable of both speech
and text generation. Compared to modular and aligned MLLMs, native MLLMs
preserve richer paralinguistic features such as emotion and prosody, and
generate speech responses directly within the backbone LLM rather than using a
separate speech decoder. This integration also results in lower response
latency and smoother interaction. However, native MLLMs suffer from
catastrophic forgetting and performance degradation because the available
paired speech-text data is insufficient to support the pretraining of MLLMs
compared to the vast amount of text data required to pretrain text LLMs. To
address this issue, we propose DeepTalk, a framework for adaptive modality
expert learning based on a Mixture of Experts (MoE) architecture. DeepTalk
first adaptively distinguishes modality experts according to their modality
load within the LLM. Each modality expert then undergoes specialized
single-modality training, followed by joint multimodal collaborative training.
As a result, DeepTalk incurs only a 5.5% performance drop compared to the
original LLM, which is significantly lower than the average performance drop of
over 20% typically seen in native MLLMs (such as GLM-4-Voice), and is on par
with modular MLLMs. Meanwhile, the end-to-end dialogue latency remains within
0.5 seconds, ensuring a seamless and intelligent speech interaction experience.
Code and models are released at https://github.com/talkking/DeepTalk.

</details>


### [95] [WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation](https://arxiv.org/abs/2506.21875)
*Jian Zhang,Linhao Zhang,Bokai Lei,Chuhan Wu,Wei Jia,Xiao Zhou*

Main category: cs.CL

TL;DR: 论文提出了一种新的评估方法，专门针对语音交互的多模态大语言模型（如GPT-4o），通过系统化的数据集构建和查询感知评估方法，解决了现有文本基准在语音场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法多基于文本基准，忽视了语音特有的挑战（如韵律、同音词、口吃等），无法全面优化语音LLM在实际应用中的用户体验。

Method: 系统收集真实语音聊天数据，引入多样化的说话者属性和声学条件，并增强语音特有现象；设计查询感知评估方法，使用定制化评估清单和提示。

Result: 对不同主流语音模型进行全面测试，揭示了模型在不同语音场景下的显著性能差异，查询感知评估提供了更细粒度的分析。

Conclusion: 提出的基准为语音模型的开发和评估提供了有价值的见解，弥补了现有评估方法的不足。

Abstract: Recent multi-modal Large Language Models (LLMs) such as GPT-4o have
demonstrated strong capabilities of direct speech interaction. However, the
lack of specialized and comprehensive benchmarks for end-to-end speech LLM
evaluation hinders optimizing the user experience of Audio LLMs in real-world
applications. Existing evaluation methods often adapt text-based benchmarks,
overlooking speech's unique characteristics and challenges, including prosody,
homophones, stuttering, and differing user expectations. Here, we present a
novel approach to thoroughly evaluate LLMs in practical speech conversations.
We systematically curate real-world chat data relevant to spoken scenarios,
introduce diversity in speaker attributes and acoustic conditions, and augment
the dataset with speech-specific phenomena. We further design a query-aware
evaluation method to use customized evaluation checklists and prompts to
enhance the accuracy of automatic evaluation. We conduct comprehensive testing
and detailed analysis of various mainstream speech models, revealing
significant differences in model performance across different speech scenarios.
The use of query-aware evaluation further enables a finer-grained assessment
under various speech-specific scenarios. Our benchmark can provide valuable
insights for speech model development and evaluation.

</details>


### [96] [Do Vision-Language Models Have Internal World Models? Towards an Atomic Evaluation](https://arxiv.org/abs/2506.21876)
*Qiyue Gao,Xinyu Pi,Kevin Liu,Junrong Chen,Ruolan Yang,Xinqi Huang,Xinyu Fang,Lu Sun,Gautham Kishore,Bo Ai,Stone Tao,Mengyang Liu,Jiaxi Yang,Chao-Jung Lai,Chuanyang Jin,Jiannan Xiang,Benhao Huang,Zeming Chen,David Danks,Hao Su,Tianmin Shu,Ziqiao Ma,Lianhui Qin,Zhiting Hu*

Main category: cs.CL

TL;DR: 论文提出了一个两阶段框架评估视觉语言模型（VLMs）作为世界模型（WMs）的能力，发现现有模型在基本世界建模能力上存在显著局限性。


<details>
  <summary>Details</summary>
Motivation: 评估VLMs作为通用世界模型的潜力，填补系统性评估的空白。

Method: 提出两阶段框架（感知与预测），并引入WM-ABench基准，涵盖23个细粒度评估维度。

Result: 现有VLMs在基本世界建模能力上表现接近随机，且缺乏解耦理解。

Conclusion: VLMs与世界建模的人类水平存在显著差距，需进一步改进。

Abstract: Internal world models (WMs) enable agents to understand the world's state and
predict transitions, serving as the basis for advanced deliberative reasoning.
Recent large Vision-Language Models (VLMs), such as OpenAI o3, GPT-4o and
Gemini, exhibit potential as general-purpose WMs. While the latest studies have
evaluated and shown limitations in specific capabilities such as visual
understanding, a systematic evaluation of VLMs' fundamental WM abilities
remains absent. Drawing on comparative psychology and cognitive science, we
propose a two-stage framework that assesses Perception (visual, spatial,
temporal, quantitative, and motion) and Prediction (mechanistic simulation,
transitive inference, compositional inference) to provide an atomic evaluation
of VLMs as WMs. Guided by this framework, we introduce WM-ABench, a large-scale
benchmark comprising 23 fine-grained evaluation dimensions across 6 diverse
simulated environments with controlled counterfactual simulations. Through 660
experiments on 15 latest commercial and open-source VLMs, we find that these
models exhibit striking limitations in basic world modeling abilities. For
instance, almost all models perform at near-random accuracy when distinguishing
motion trajectories. Additionally, they lack disentangled understanding --
e.g., some models tend to believe blue objects move faster than green ones.
More rich results and analyses reveal significant gaps between VLMs and
human-level world modeling.

</details>


### [97] [A Dual-Layered Evaluation of Geopolitical and Cultural Bias in LLMs](https://arxiv.org/abs/2506.21881)
*Sean Kim,Hyuhng Joon Kim*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLMs）在事实性和争议性问题中的偏见，分为模型偏见和推理偏见，并通过两阶段评估揭示其行为。


<details>
  <summary>Details</summary>
Motivation: 理解LLMs在多语言和文化背景下的行为，尤其是其对公众意见和主流叙事的影响。

Method: 两阶段评估：阶段1测试事实性问题的一致性；阶段2探讨地缘政治争议中的模型行为。

Result: 阶段1显示查询语言导致的偏见；阶段2反映模型训练背景与查询语言的交互作用。

Conclusion: 提出了评估LLMs行为的框架，为多语言环境下的模型部署和文化敏感评估提供参考。

Abstract: As large language models (LLMs) are increasingly deployed across diverse
linguistic and cultural contexts, understanding their behavior in both factual
and disputable scenarios is essential, especially when their outputs may shape
public opinion or reinforce dominant narratives. In this paper, we define two
types of bias in LLMs: model bias (bias stemming from model training) and
inference bias (bias induced by the language of the query), through a two-phase
evaluation. Phase 1 evaluates LLMs on factual questions where a single
verifiable answer exists, assessing whether models maintain consistency across
different query languages. Phase 2 expands the scope by probing geopolitically
sensitive disputes, where responses may reflect culturally embedded or
ideologically aligned perspectives. We construct a manually curated dataset
spanning both factual and disputable QA, across four languages and question
types. The results show that Phase 1 exhibits query language induced alignment,
while Phase 2 reflects an interplay between the model's training context and
query language. This paper offers a structured framework for evaluating LLM
behavior across neutral and sensitive topics, providing insights for future LLM
deployment and culturally aware evaluation practices in multilingual contexts.

</details>


### [98] [AutoMixer: Checkpoint Artifacts as Automatic Data Mixers](https://arxiv.org/abs/2506.21910)
*Ernie Chang,Yang Li,Patrick Huber,David Kant,Yangyang Shi,Vikas Chandra*

Main category: cs.CL

TL;DR: 该论文提出利用训练过程中的检查点模型作为数据混合器，通过其影响力优化数据混合，显著提升了预训练模型的性能。


<details>
  <summary>Details</summary>
Motivation: 在语言模型训练中，如何直接获取适合多任务能力的数据混合是一个难题，因为数据与任务之间的关系难以建模。

Method: 通过识别检查点模型在不同训练阶段的能力，利用其一阶影响力近似作为数据混合的信号，优化数据质量。

Result: 在八个推理基准测试中，该方法显著提升了预训练模型的性能，最高提升达1.93%。

Conclusion: 检查点模型可以作为优化数据混合的有效工具，提升模型训练效果。

Abstract: In language model training, it is desirable to equip models with capabilities
from various tasks. However, it is not clear how to directly obtain the right
data mixtures for these capabilities as the relationship between data and tasks
is difficult to be modeled. In this work, we observe that checkpoint models
exhibit emerging capabilities at different points in the training trajectory.
Often, the training process saves checkpoints as artifacts that are
under-utilized as a source of in-training data signals. We identify these
artifact models based on their respective capabilities on the benchmarks and
leverage them as data mixers by using their aggregated first-order influence
approximation over source data. We demonstrated on eight reasoning benchmarks
that the proposed framework shows significant improvements in the pretraining
setting, with performance improvements of up to 1.93%. Overall, this shows the
potential of checkpoint models to enhance data quality and optimize data
mixtures.

</details>


### [99] [Advancing Jailbreak Strategies: A Hybrid Approach to Exploiting LLM Vulnerabilities and Bypassing Modern Defenses](https://arxiv.org/abs/2506.21972)
*Mohamed Ahmed,Mohamed Abdelmouty,Mingyu Kim,Gunvanth Kandula,Alex Park,James C. Davis*

Main category: cs.CL

TL;DR: 论文提出两种混合方法（GCG + PAIR和GCG + WordGame），结合令牌级和提示级攻击技术，显著提高了对预训练语言模型的越狱成功率，并揭示了现有安全措施的漏洞。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练语言模型（PTLMs）和大型语言模型（LLMs）广泛应用，但其仍易受攻击，现有令牌级和提示级攻击方法各有局限性，需结合两者以提升攻击效果。

Method: 提出两种混合攻击方法：GCG + PAIR和GCG + WordGame，结合令牌级和提示级技术，评估其在Vicuna和Llama模型上的效果。

Result: GCG + PAIR在Llama-3上的攻击成功率（ASR）达91.6%，显著高于PAIR的58.4%；GCG + WordGame保持80%以上的高ASR，且能突破高级防御措施。

Conclusion: 混合攻击方法暴露了现有安全措施的漏洞，需开发更全面的防御策略以应对适应性攻击。

Abstract: The advancement of Pre-Trained Language Models (PTLMs) and Large Language
Models (LLMs) has led to their widespread adoption across diverse applications.
Despite their success, these models remain vulnerable to attacks that exploit
their inherent weaknesses to bypass safety measures. Two primary
inference-phase threats are token-level and prompt-level jailbreaks.
Token-level attacks embed adversarial sequences that transfer well to black-box
models like GPT but leave detectable patterns and rely on gradient-based token
optimization, whereas prompt-level attacks use semantically structured inputs
to elicit harmful responses yet depend on iterative feedback that can be
unreliable. To address the complementary limitations of these methods, we
propose two hybrid approaches that integrate token- and prompt-level techniques
to enhance jailbreak effectiveness across diverse PTLMs. GCG + PAIR and the
newly explored GCG + WordGame hybrids were evaluated across multiple Vicuna and
Llama models. GCG + PAIR consistently raised attack-success rates over its
constituent techniques on undefended models; for instance, on Llama-3, its
Attack Success Rate (ASR) reached 91.6%, a substantial increase from PAIR's
58.4% baseline. Meanwhile, GCG + WordGame matched the raw performance of
WordGame maintaining a high ASR of over 80% even under stricter evaluators like
Mistral-Sorry-Bench. Crucially, both hybrids retained transferability and
reliably pierced advanced defenses such as Gradient Cuff and JBShield, which
fully blocked single-mode attacks. These findings expose previously unreported
vulnerabilities in current safety stacks, highlight trade-offs between raw
success and defensive robustness, and underscore the need for holistic
safeguards against adaptive adversaries.

</details>


### [100] [PapersPlease: A Benchmark for Evaluating Motivational Values of Large Language Models Based on ERG Theory](https://arxiv.org/abs/2506.21961)
*Junho Myung,Yeon Su Park,Sunwoo Kim,Shin Yoo,Alice Oh*

Main category: cs.CL

TL;DR: 论文提出了PapersPlease基准，通过3700个道德困境评估大语言模型（LLMs）在移民审批决策中的偏好和偏见，发现LLMs存在隐式偏好，并对社会身份敏感。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在角色扮演场景中的决策偏见，特别是在移民审批中基于人类需求层次的偏好。

Method: 使用ERG理论构建3,700个道德困境，LLMs作为移民检查员根据叙事决定是否批准入境。

Result: LLMs表现出显著的决策模式，对边际化身份有更高的拒绝率。

Conclusion: LLMs在决策中编码了隐式偏好，且对社会身份敏感，数据已公开。

Abstract: Evaluating the performance and biases of large language models (LLMs) through
role-playing scenarios is becoming increasingly common, as LLMs often exhibit
biased behaviors in these contexts. Building on this line of research, we
introduce PapersPlease, a benchmark consisting of 3,700 moral dilemmas designed
to investigate LLMs' decision-making in prioritizing various levels of human
needs. In our setup, LLMs act as immigration inspectors deciding whether to
approve or deny entry based on the short narratives of people. These narratives
are constructed using the Existence, Relatedness, and Growth (ERG) theory,
which categorizes human needs into three hierarchical levels. Our analysis of
six LLMs reveals statistically significant patterns in decision-making,
suggesting that LLMs encode implicit preferences. Additionally, our evaluation
of the impact of incorporating social identities into the narratives shows
varying responsiveness based on both motivational needs and identity cues, with
some models exhibiting higher denial rates for marginalized identities. All
data is publicly available at https://github.com/yeonsuuuu28/papers-please.

</details>


### [101] [Analyzing and Fine-Tuning Whisper Models for Multilingual Pilot Speech Transcription in the Cockpit](https://arxiv.org/abs/2506.21990)
*Kartheek Kumar Reddy Nareddy,Sarah Ternus,Julia Niebling*

Main category: cs.CL

TL;DR: 本文研究了如何通过Whisper模型提高驾驶舱对话的转录准确性，提出多种规范化方案和微调方法，显著降低了词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 预训练模型在通用领域表现优异，但在特定领域（如驾驶舱对话）因专业词汇和多语言对话导致性能下降。

Method: 收集驾驶舱模拟器和飞行员访谈录音，手动标注数据，提出规范化方案，并采用LoRA进行高效微调。

Result: WER从68.49%降至26.26%。

Conclusion: 提出的规范化方案和微调方法显著提升了驾驶舱对话的转录准确性。

Abstract: The developments in transformer encoder-decoder architectures have led to
significant breakthroughs in machine translation, Automatic Speech Recognition
(ASR), and instruction-based chat machines, among other applications. The
pre-trained models were trained on vast amounts of generic data over a few
epochs (fewer than five in most cases), resulting in their strong
generalization capabilities. Nevertheless, the performance of these models does
suffer when applied to niche domains like transcribing pilot speech in the
cockpit, which involves a lot of specific vocabulary and multilingual
conversations. This paper investigates and improves the transcription accuracy
of cockpit conversations with Whisper models. We have collected around 85
minutes of cockpit simulator recordings and 130 minutes of interview recordings
with pilots and manually labeled them. The speakers are middle aged men
speaking both German and English. To improve the accuracy of transcriptions, we
propose multiple normalization schemes to refine the transcripts and improve
Word Error Rate (WER). We then employ fine-tuning to enhance ASR performance,
utilizing performance-efficient fine-tuning with Low-Rank Adaptation (LoRA).
Hereby, WER decreased from 68.49 \% (pretrained whisper Large model without
normalization baseline) to 26.26\% (finetuned whisper Large model with the
proposed normalization scheme).

</details>


### [102] [More Vulnerable than You Think: On the Stability of Tool-Integrated LLM Agents](https://arxiv.org/abs/2506.21967)
*Weimin Xiong,Ke Wang,Yifan Song,Hanchao Liu,Sai Zhou,Wei Peng,Sujian Li*

Main category: cs.CL

TL;DR: 研究评估了工具集成LLM代理的稳定性，发现其在工具调用各阶段易出错，开源模型比专有模型更脆弱，增大模型规模未必提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前工具集成LLM代理的评估多关注端到端工具使用，忽视稳定性，限制了其实际应用。

Method: 通过实验分析代理在工具调用各阶段（读取文档、选择工具、生成参数、处理响应）的脆弱性。

Result: 代理在各阶段均易出错，开源模型更脆弱；增大模型规模未显著提升推理能力，反而可能增加攻击风险。

Conclusion: 强调评估代理稳定性的重要性，为未来LLM开发和评估提供洞见。

Abstract: Current evaluations of tool-integrated LLM agents typically focus on
end-to-end tool-usage evaluation while neglecting their stability. This limits
their real-world applicability, as various internal or external factors can
cause agents to crash or behave abnormally. Our research addresses this by
investigating whether agents are vulnerable to errors throughout the entire
tool invocation process, including reading tool documentation, selecting tools
and generating parameters, and processing the tool's response. Through
extensive experiments, we observe that agents are highly susceptible to errors
at each stage and agents based on open-source models are more vulnerable than
those based on proprietary models. We also find that increasing the model size
does not significantly improve tool invocation reasoning and may make agents
more vulnerable to attacks resembling normal user instructions. This highlights
the importance of evaluating agent stability and offers valuable insights for
future LLM development and evaluation.

</details>


### [103] [Don't Trust Generative Agents to Mimic Communication on Social Networks Unless You Benchmarked their Empirical Realism](https://arxiv.org/abs/2506.21974)
*Simon Münker,Nils Schwager,Achim Rettinger*

Main category: cs.CL

TL;DR: 本文探讨了使用大语言模型（LLMs）模拟社交网络用户行为的可行性，并提出了一个正式框架来验证其现实性。


<details>
  <summary>Details</summary>
Motivation: 由于现有研究对LLMs是否能替代人类进行社会科学实验存在争议，本文旨在通过实证分析理解实验设计的差异。

Method: 提出了一个社交网络模拟的正式框架，并测试了不同方法在英语和德语社交网络（如X平台）上模拟用户行为的效果。

Result: 研究发现，社交模拟的实证现实性应在模拟组件拟合的场景中进行验证。

Conclusion: 本文主张在基于生成代理的社会模拟中应更加严谨。

Abstract: The ability of Large Language Models (LLMs) to mimic human behavior triggered
a plethora of computational social science research, assuming that empirical
studies of humans can be conducted with AI agents instead. Since there have
been conflicting research findings on whether and when this hypothesis holds,
there is a need to better understand the differences in their experimental
designs. We focus on replicating the behavior of social network users with the
use of LLMs for the analysis of communication on social networks. First, we
provide a formal framework for the simulation of social networks, before
focusing on the sub-task of imitating user communication. We empirically test
different approaches to imitate user behavior on X in English and German. Our
findings suggest that social simulations should be validated by their empirical
realism measured in the setting in which the simulation components were fitted.
With this paper, we argue for more rigor when applying generative-agent-based
modeling for social simulation.

</details>


### [104] [Can Peter Pan Survive MT? A Stylometric Study of LLMs, NMTs, and HTs in Children's Literature Translation](https://arxiv.org/abs/2506.22038)
*Delu Kong,Lieve Macken*

Main category: cs.CL

TL;DR: 该研究从风格计量学角度评估了机器翻译（MTs）与人工翻译（HTs）在英译中儿童文学翻译（CLT）中的表现，发现LLMs在风格特征上更接近HTs。


<details>
  <summary>Details</summary>
Motivation: 比较机器翻译与人工翻译在儿童文学翻译中的表现，探索LLMs在CLT中的潜力。

Method: 构建包含21种翻译的Peter Pan语料库，使用通用和特定特征集进行风格计量学分析。

Result: HTs与MTs在通用特征上有显著差异，LLMs在CTT特定特征上表现优于NMTs。

Conclusion: LLMs在儿童文学翻译中展现出潜力，尤其在风格特征上更接近人工翻译。

Abstract: This study focuses on evaluating the performance of machine translations
(MTs) compared to human translations (HTs) in English-to-Chinese children's
literature translation (CLT) from a stylometric perspective. The research
constructs a Peter Pan corpus, comprising 21 translations: 7 human translations
(HTs), 7 large language model translations (LLMs), and 7 neural machine
translation outputs (NMTs). The analysis employs a generic feature set
(including lexical, syntactic, readability, and n-gram features) and a creative
text translation (CTT-specific) feature set, which captures repetition, rhythm,
translatability, and miscellaneous levels, yielding 447 linguistic features in
total.
  Using classification and clustering techniques in machine learning, we
conduct a stylometric analysis of these translations. Results reveal that in
generic features, HTs and MTs exhibit significant differences in conjunction
word distributions and the ratio of 1-word-gram-YiYang, while NMTs and LLMs
show significant variation in descriptive words usage and adverb ratios.
Regarding CTT-specific features, LLMs outperform NMTs in distribution, aligning
more closely with HTs in stylistic characteristics, demonstrating the potential
of LLMs in CLT.

</details>


### [105] [Decoding Machine Translationese in English-Chinese News: LLMs vs. NMTs](https://arxiv.org/abs/2506.22050)
*Delu Kong,Lieve Macken*

Main category: cs.CL

TL;DR: 研究探索了机器翻译英语到中文新闻文本中的特有语言特征（MTese），通过构建大型数据集和五层特征集，发现NMT和LLM输出均存在MTese，且与原始中文文本区分度高。


<details>
  <summary>Details</summary>
Motivation: 研究动机是填补英语到中文机器翻译语言特征的研究空白，特别是在新闻文本中。

Method: 方法包括构建4个子语料库的大型数据集，采用五层特征集，并使用卡方排名算法进行特征选择。

Result: 结果显示NMT和LLM输出均存在MTese，原始中文文本与机器翻译输出区分度高；LLM词汇多样性更高，NMT更多使用括号。

Conclusion: 结论是机器翻译输出存在显著语言特征，且LLM与NMT在词汇和语法使用上有差异，但中外LLM无显著区别。

Abstract: This study explores Machine Translationese (MTese) -- the linguistic
peculiarities of machine translation outputs -- focusing on the
under-researched English-to-Chinese language pair in news texts. We construct a
large dataset consisting of 4 sub-corpora and employ a comprehensive five-layer
feature set. Then, a chi-square ranking algorithm is applied for feature
selection in both classification and clustering tasks. Our findings confirm the
presence of MTese in both Neural Machine Translation systems (NMTs) and Large
Language Models (LLMs). Original Chinese texts are nearly perfectly
distinguishable from both LLM and NMT outputs. Notable linguistic patterns in
MT outputs are shorter sentence lengths and increased use of adversative
conjunctions. Comparing LLMs and NMTs, we achieve approximately 70%
classification accuracy, with LLMs exhibiting greater lexical diversity and
NMTs using more brackets. Additionally, translation-specific LLMs show lower
lexical diversity but higher usage of causal conjunctions compared to generic
LLMs. Lastly, we find no significant differences between LLMs developed by
Chinese firms and their foreign counterparts.

</details>


### [106] [Lost at the Beginning of Reasoning](https://arxiv.org/abs/2506.22058)
*Baohao Liao,Xinyi Chen,Sara Rajaee,Yuhui Xu,Christian Herold,Anders Søgaard,Maarten de Rijke,Christof Monz*

Main category: cs.CL

TL;DR: 论文提出了一种高效采样策略，通过奖励模型筛选高质量初始推理步骤，降低推理成本70%且不影响准确性，并引入新基准评估模型自纠正能力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）在复杂推理方面取得进展，但其在长链推理中的自纠正能力仍未被充分研究，且存在冗余推理问题。

Method: 提出一种采样策略，利用奖励模型筛选高质量初始推理步骤，丢弃次优步骤。

Result: 实验表明，该方法在DeepSeek-R1和Qwen3模型上显著降低推理成本70%，同时保持准确性。

Conclusion: 论文为LLM的鲁棒推理研究提供了新基准和方法，未来可进一步探索自纠正能力。

Abstract: Recent advancements in large language models (LLMs) have significantly
advanced complex reasoning capabilities, particularly through extended
chain-of-thought (CoT) reasoning that incorporates mechanisms such as
backtracking, self-reflection and self-correction. Despite these developments,
the self-correction abilities of LLMs during long CoT reasoning remain
underexplored. And recent findings on overthinking suggest that such models
often engage in unnecessarily redundant reasoning. In this work, we empirically
show that the first reasoning step exerts a disproportionately large influence
on the final prediction - errors introduced at this stage can substantially
degrade subsequent reasoning quality. This phenomenon is consistently observed
across two state-of-the-art open-source reasoning model families: DeepSeek-R1
and Qwen3. To address this, we propose an efficient sampling strategy that
leverages a reward model to identify and retain high-quality first reasoning
steps while discarding suboptimal ones, achieving up to a 70% reduction in
inference cost without sacrificing accuracy. Finally, we introduce a new
benchmark specifically constructed with deliberately flawed first reasoning
steps to systematically evaluate model self-correction capabilities, offering a
foundation for future research on robust reasoning in LLMs.

</details>


### [107] [MDC-R: The Minecraft Dialogue Corpus with Reference](https://arxiv.org/abs/2506.22062)
*Chris Madge,Maris Camilleri,Paloma Carretero Garcia,Mladen Karan,Juexi Shao,Prashant Jayannavar,Julian Hough,Benjamin Roth,Massimo Poesio*

Main category: cs.CL

TL;DR: MDC-R是一个补充了专家标注的指代和指示参考的Minecraft对话语料库，旨在为动态环境中的多轮任务导向对话提供有价值的语言资源。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的多轮任务导向对话引发了有趣的语言现象，需要标注指代和指示参考以增强语料库的价值。

Method: 采用了专家标注方法，对语料库进行了定量和定性分析，并通过实验验证了语料库在指代表达理解中的实用性。

Result: 生成了MDC-R语料库，并通过实验证明了其在指代表达理解中的有效性。

Conclusion: MDC-R是一个有价值的语言资源，适用于动态环境中的指代和指示参考研究。

Abstract: We introduce the Minecraft Dialogue Corpus with Reference (MDC-R). MDC-R is a
new language resource that supplements the original Minecraft Dialogue Corpus
(MDC) with expert annotations of anaphoric and deictic reference. MDC's
task-orientated, multi-turn, situated dialogue in a dynamic environment has
motivated multiple annotation efforts, owing to the interesting linguistic
phenomena that this setting gives rise to. We believe it can serve as a
valuable resource when annotated with reference, too. Here, we discuss our
method of annotation and the resulting corpus, and provide both a quantitative
and a qualitative analysis of the data. Furthermore, we carry out a short
experiment demonstrating the usefulness of our corpus for referring expression
comprehension.

</details>


### [108] [Involvement drives complexity of language in online debates](https://arxiv.org/abs/2506.22098)
*Eleonora Amadori,Daniele Cirulli,Edoardo Di Martino,Jacopo Nudo,Maria Sahakyan,Emanuele Sangiorgio,Arnaldo Santoro,Simon Zollo,Alessandro Galeazzi,Niccolò Di Marco*

Main category: cs.CL

TL;DR: 研究分析了Twitter上有影响力用户在三个全球争议话题（COVID-19、COP26、俄乌战争）中的语言复杂性，发现语言使用在账户类型、政治倾向、内容可靠性和情感四个维度上存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探讨社交媒体如何重塑公共话语，以及用户生成内容的语言特征如何反映更广泛的社会影响。

Method: 结合多种文本复杂性度量，分析Twitter内容在四个维度（账户类型、政治倾向、内容可靠性、情感）上的语言差异。

Result: 发现语言复杂性在不同维度上存在显著差异，政治立场和可靠性相似的用户倾向于使用共同的行话，负面和攻击性内容通常语言更复杂。

Conclusion: 研究揭示了数字平台的社交语言动态，深化了对在线空间中语言如何反映意识形态和社会结构的理解。

Abstract: Language is a fundamental aspect of human societies, continuously evolving in
response to various stimuli, including societal changes and intercultural
interactions. Technological advancements have profoundly transformed
communication, with social media emerging as a pivotal force that merges
entertainment-driven content with complex social dynamics. As these platforms
reshape public discourse, analyzing the linguistic features of user-generated
content is essential to understanding their broader societal impact. In this
paper, we examine the linguistic complexity of content produced by influential
users on Twitter across three globally significant and contested topics:
COVID-19, COP26, and the Russia-Ukraine war. By combining multiple measures of
textual complexity, we assess how language use varies along four key
dimensions: account type, political leaning, content reliability, and
sentiment. Our analysis reveals significant differences across all four axes,
including variations in language complexity between individuals and
organizations, between profiles with sided versus moderate political views, and
between those associated with higher versus lower reliability scores.
Additionally, profiles producing more negative and offensive content tend to
use more complex language, with users sharing similar political stances and
reliability levels converging toward a common jargon. Our findings offer new
insights into the sociolinguistic dynamics of digital platforms and contribute
to a deeper understanding of how language reflects ideological and social
structures in online spaces.

</details>


### [109] [QuickSilver -- Speeding up LLM Inference through Dynamic Token Halting, KV Skipping, Contextual Token Fusion, and Adaptive Matryoshka Quantization](https://arxiv.org/abs/2506.22396)
*Danush Khanna,Aditya Kumar Guru,Srivarshinee Sridhar,Zidan Ahmed,Rubhav Bahirwani,Meetu Malhotra,Vinija Jain,Aman Chadha,Amitava Das,Kripabandhu Ghosh*

Main category: cs.CL

TL;DR: QuickSilver是一个模块化的推理时优化框架，通过动态令牌停止、KV缓存跳过和上下文令牌融合等机制，显著减少大型语言模型推理时的计算开销，无需修改模型权重或结构。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）推理时的高延迟和能耗是主要瓶颈，现有方法通常需要重新训练或架构修改，限制了实用性。

Method: QuickSilver通过动态令牌停止、KV缓存跳过和上下文令牌融合三种机制，在不改变模型权重或结构的情况下优化推理效率。

Result: 在GPT-2和Llama-2上，QuickSilver实现了高达39.6%的FLOP减少，且困惑度增加可忽略（<=0.2）。

Conclusion: QuickSilver为LLM推理提供了一种高效且兼容性强的优化方案，适用于冻结的密集模型。

Abstract: Inference accounts for the majority of latency and energy consumption in
large language model (LLM) deployments, often exceeding 90% of total cost.
While training-time efficiency has seen extensive progress, runtime
optimization remains a key bottleneck, particularly under autoregressive
decoding. Existing approaches -- such as pruning, quantization, early exits,
and speculative decoding -- often require retraining, architectural changes, or
disrupt decoding compatibility. We introduce QuickSilver, a modular,
token-level framework that enables semantic adaptivity at inference time
without altering model weights or structure. QuickSilver integrates four
synergistic mechanisms:
  (i) Dynamic Token Halting, which halts computation for tokens with converged
representations; (ii) KV Cache Skipping, which selectively suppresses memory
writes to reduce attention overhead; and (iii) Contextual Token Fusion, which
collapses redundant tokens into shared paths to shrink sequence length.
  Unlike speculative decoding or MoE routing, QuickSilver operates entirely on
frozen, dense models and requires no auxiliary networks. Applied to GPT-2 and
Llama-2 across WikiText-103 and C4, QuickSilver achieves up to 39.6% FLOP
reduction with negligible perplexity degradation (<=0.2).

</details>


### [110] [Identifying a Circuit for Verb Conjugation in GPT-2](https://arxiv.org/abs/2506.22105)
*David Demitri Africa*

Main category: cs.CL

TL;DR: 研究通过一系列技术手段，在GPT-2 Small中分离出负责主谓一致的子网络，发现仅需少量组件即可完成任务。


<details>
  <summary>Details</summary>
Motivation: 探究GPT-2 Small如何实现主谓一致任务，并识别关键子网络。

Method: 使用性能验证、自动电路发现（直接路径修补）和直接对数归因技术。

Result: 分离出显著影响动词变形的候选电路，少量组件即可完成任务，复杂场景需更多组件。

Conclusion: GPT-2 Small中主谓一致任务由特定子网络完成，简单任务高效，复杂任务需更多资源。

Abstract: I implement a procedure to isolate and interpret the sub-network (or
"circuit") responsible for subject-verb agreement in GPT-2 Small. In this
study, the model is given prompts where the subject is either singular (e.g.
"Alice") or plural (e.g. "Alice and Bob"), and the task is to correctly predict
the appropriate verb form ("walks" for singular subjects, "walk" for plural
subjects). Using a series of techniques-including performance verification
automatic circuit discovery via direct path patching, and direct logit
attribution- I isolate a candidate circuit that contributes significantly to
the model's correct verb conjugation. The results suggest that only a small
fraction of the network's component-token pairs is needed to achieve near-model
performance on the base task but substantially more for more complex settings.

</details>


### [111] [HyperCLOVA X THINK Technical Report](https://arxiv.org/abs/2506.22403)
*NAVER Cloud HyperCLOVA X Team*

Main category: cs.CL

TL;DR: HyperCLOVA X THINK是首个专注于推理的大语言模型，基于6万亿高质量韩语和英语数据训练，支持128K上下文窗口，性能优于同类模型，且训练计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 为韩国AI创新提供强大基础，并成为全球研究社区的宝贵资源。

Method: 采用Peri-LN Transformer架构，通过三阶段课程学习和强化学习微调，支持详细推理和简洁回答模式。

Result: 在韩国基准测试中表现优异，视觉增强版本甚至超越GPT-4.1，训练计算成本更低。

Conclusion: HyperCLOVA X THINK是韩国AI创新的重要基础，未来将通过剪枝和蒸馏技术进一步优化。

Abstract: We introduce HyperCLOVA X THINK, the first reasoning-focused large language
model in the HyperCLOVA X family, pre-trained on roughly $6$ trillion
high-quality Korean, and English tokens, augmented with targeted synthetic
Korean data. It was implemented as a compute-memory-balanced Peri-LN
Transformer scaled with $\mu$P, pre-trained through a three-stage curriculum
that expands the context window to $128$K tokens, and post-trained via
supervised fine-tuning with Reinforcement Learning from Verifiable Rewards
supports both detailed rationale and concise-answer modes. It delivers
competitive performance against similarly sized models on Korea-focused
benchmarks such as KMMLU, CSAT, KoBALT-700, HAERAE-1.0, and KoBigBench, while
preserving robust bilingual consistency and translation quality. In addition, a
vision-augmented variant matches or exceeds GPT-4.1 on the KCSAT STEM
benchmark, all of which are achieved with substantially lower training compute
than existing models of similar sizes. We also present a pruning and
distillation technique that will soon be applied to HyperCLOVA X THINK for an
open-source and business-friendly foundation model. Altogether, these
capabilities position HyperCLOVA X THINK as a robust foundation for Korean AI
innovation and a valuable resource for the global research community.

</details>


### [112] [DAPFAM: A Domain-Aware Patent Retrieval Dataset Aggregated at the Family Level](https://arxiv.org/abs/2506.22141)
*Iliass Ayaou,Denis Cavallucci,Hicham Chibane*

Main category: cs.CL

TL;DR: DAPFAM是一个新的开放获取专利检索数据集，解决了现有数据集中领域标签、多司法管辖区覆盖和计算资源限制等问题。


<details>
  <summary>Details</summary>
Motivation: 现有专利检索数据集缺乏明确的领域标签、多司法管辖区覆盖和平衡的查询领域表示，且计算资源需求高。

Method: 通过三步数据整理流程构建DAPFAM数据集，包括领域平衡查询家族、目标家族和基于IPC代码的标签方案。

Result: 数据集包含1,247个查询家族和45,336个目标家族，生成49,869个评估对，支持跨领域专利检索实验。

Conclusion: DAPFAM填补了专利检索数据集的空白，基线实验揭示了跨领域检索的挑战，数据集将公开提供。

Abstract: In the landscape of publicly available patent retrieval datasets, the need
for explicit indomain and out-of-domain labeling, multi-jurisdiction coverage,
balanced query domain representation and manageable sizes that support sub
document level experiments on moderate computational resources is often
overlooked. To address these gaps, we propose DAPFAM, a new open access
domain-aware patent retrieval dataset constructed at the simple-family level.
The dataset contains 1,247 domain balanced full text query families and 45,336
full text target families. The dataset is enriched by clear relevance judgments
(forward/backward citations as positive links, random negatives), as well as
explicit in-domain or out-of-domain relationships via a novel proposed
labelling scheme based on via International Patent Classification (IPC) codes,
resulting in 49,869 evaluation pairs. The dataset is multi jurisdictional,
requires little to no preprocessing for retrieval evaluation, and remains of a
size manageable for entities with limited ressources allowing for sub document
level retrieval experiments without excessive computational costs. We describe
our three-step data-curation pipeline, present comprehensive dataset
statistics, and provide baseline experiments using lexical and neural retrieval
methods. Our baseline experiments highlight significant challenges in
crossdomain patent retrieval. The dataset will be publicly available (for now
the access link is this repository:
https://osf.io/vbyzd/?view_only=1a40242e0d1941a58aa854af3e50cf6b).

</details>


### [113] [SAGE: Spliced-Audio Generated Data for Enhancing Foundational Models in Low-Resource Arabic-English Code-Switched Speech Recognition](https://arxiv.org/abs/2506.22143)
*Muhammad Umar Farooq,Oscar Saz*

Main category: cs.CL

TL;DR: 论文研究了语音SSL模型在方言阿拉伯语（DA）和阿拉伯语-英语代码转换（CS）语音上的表现，提出了一种改进的音频拼接方法生成人工CS数据，并结合经验回放（ER）方法提升泛化能力，显著降低了词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 解决方言阿拉伯语和阿拉伯语-英语代码转换语音数据稀缺的问题，并提升模型在这些任务上的性能。

Method: 提出改进的音频拼接方法（SAGE）生成人工CS数据，结合经验回放（ER）方法防止灾难性遗忘，并引入外部3-gram语言模型。

Result: WER在阿拉伯语和英语CS基准上绝对提升7.8%，整体平均WER从31.7%降至26.6%，在代码转换基准上进一步降低4.9%。

Conclusion: 提出的方法在阿拉伯语-英语CS任务上表现优于大规模多语言模型，展示了高效的数据生成和模型优化策略。

Abstract: This paper investigates the performance of various speech SSL models on
dialectal Arabic (DA) and Arabic-English code-switched (CS) speech. To address
data scarcity, a modified audio-splicing approach is introduced to generate
artificial CS speech data. Fine-tuning an already fine-tuned SSL model with the
proposed Spliced-Audio Generated (SAGE) data results in an absolute improvement
on Word Error Rate (WER) of 7.8% on Arabic and English CS benchmarks.
Additionally, an Experience Replay (ER) inspired approach is proposed to
enhance generalisation across DA and CS speech while mitigating catastrophic
forgetting. Integrating an out-of-domain 3-gram language model reduces the
overall mean WER from 31.7% to 26.6%. Few-shot fine-tuning for code-switching
benchmarks further improves WER by 4.9%. A WER of 31.1% on Arabic-English CS
benchmarks surpasses large-scale multilingual models, including USM and
Whisper-large-v2 (both over ten times larger) by an absolute margin of 5.5% and
8.4%, respectively.

</details>


### [114] [Training Language Model to Critique for Better Refinement](https://arxiv.org/abs/2506.22157)
*Tianshu Yu,Chao Xiang,Mingchuan Yang,Pei Ke,Bosi Wen,Cunxiang Wang,Jiale Cheng,Li Zhang,Xinyu Mu,Chuxiong Sun,Minlie Huang*

Main category: cs.CL

TL;DR: 论文提出了一种名为RCO的新框架，通过优化批评模型来提升语言模型的反馈和修正能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究未深入探讨哪些类型的批评对改进模型响应最有效，以及如何生成这些批评。

Method: RCO框架通过反馈循环训练批评模型，利用修正信号量化批评的效用，并作为奖励信号。

Result: 在五个任务中，RCO显著优于传统方法和开源模型，提升了批评质量和修正效果。

Conclusion: RCO通过基于修正偏好的监督方案，有效增强了语言模型的批评-修正循环。

Abstract: Large language models (LLMs) have demonstrated remarkable evaluation and
critique capabilities, providing insightful feedback and identifying flaws in
various tasks. However, limited research has explored which types of critiques
are most effective for improving model responses or how to generate such
critiques. To address this gap, we introduce \textbf{R}efinement-oriented
\textbf{C}ritique \textbf{O}ptimization (RCO), a novel framework designed to
train critic models using refinement signals. RCO uses a feedback loop where
critiques, generated by the critic model, guide the actor model in refining its
responses. The critique utility (CU) quantifies the effectiveness of these
refinements, serving as the reward signal for training the critic model. By
focusing on critiques that lead to better refinements, RCO eliminates the need
for direct critique preference assessment, ensuring that critiques driving
meaningful improvements are rewarded. We evaluate RCO across five tasks, i.e.,
dialog generation, summarization, question answering, mathematical reasoning,
and code generation, and show that it significantly outperforms traditional
methods and open-source models in terms of critique quality and refinement
outcomes. Our contributions include the introduction of RCO, a novel
supervision scheme based on refined response preferences, and comprehensive
experimental results that highlight the method's effectiveness in enhancing LLM
critique-refinement loops.

</details>


### [115] [Leveraging In-Context Learning for Political Bias Testing of LLMs](https://arxiv.org/abs/2506.22232)
*Patrick Haller,Jannis Vamvas,Rico Sennrich,Lena A. Jäger*

Main category: cs.CL

TL;DR: 论文提出了一种新的探测任务（QM），利用人类调查数据作为上下文示例，提高了基于问题的偏见评估的稳定性，并比较了指令调优模型与其基础版本的差异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在评估LLMs的政治偏见时稳定性不足，难以可靠比较不同模型。

Method: 提出QM任务，使用人类调查数据作为上下文示例，改进偏见评估的稳定性。

Result: 实验表明，指令调优可以改变偏见方向，且更大模型能更有效地利用上下文示例，表现出更小的偏见分数。

Conclusion: QM方法提高了偏见评估的可靠性，并揭示了模型大小与偏见表现之间的关系。

Abstract: A growing body of work has been querying LLMs with political questions to
evaluate their potential biases. However, this probing method has limited
stability, making comparisons between models unreliable. In this paper, we
argue that LLMs need more context. We propose a new probing task, Questionnaire
Modeling (QM), that uses human survey data as in-context examples. We show that
QM improves the stability of question-based bias evaluation, and demonstrate
that it may be used to compare instruction-tuned models to their base versions.
Experiments with LLMs of various sizes indicate that instruction tuning can
indeed change the direction of bias. Furthermore, we observe a trend that
larger models are able to leverage in-context examples more effectively, and
generally exhibit smaller bias scores in QM. Data and code are publicly
available.

</details>


### [116] [Detection of Personal Data in Structured Datasets Using a Large Language Model](https://arxiv.org/abs/2506.22305)
*Albert Agisha Ntwali,Luca Rück,Martin Heckmann*

Main category: cs.CL

TL;DR: 提出了一种基于GPT-4o的新方法，利用上下文信息检测结构化数据中的个人数据，并在多个数据集上验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CASSED和Microsoft Presidio）在检测个人数据时未充分利用上下文信息，导致性能受限。

Method: 结合特征名称、值、其他特征名称及数据集描述等上下文信息，利用GPT-4o进行检测。

Result: 在医疗数据集MIMIC-Demo-Ext上表现优异，在Kaggle和OpenML数据集上因利用上下文信息而显著优于其他方法。

Conclusion: 未来研究需更多包含个人信息的真实数据集以推动进展。

Abstract: We propose a novel approach for detecting personal data in structured
datasets, leveraging GPT-4o, a state-of-the-art Large Language Model. A key
innovation of our method is the incorporation of contextual information: in
addition to a feature's name and values, we utilize information from other
feature names within the dataset as well as the dataset description. We compare
our approach to alternative methods, including Microsoft Presidio and CASSED,
evaluating them on multiple datasets: DeSSI, a large synthetic dataset,
datasets we collected from Kaggle and OpenML as well as MIMIC-Demo-Ext, a
real-world dataset containing patient information from critical care units.
  Our findings reveal that detection performance varies significantly depending
on the dataset used for evaluation. CASSED excels on DeSSI, the dataset on
which it was trained. Performance on the medical dataset MIMIC-Demo-Ext is
comparable across all models, with our GPT-4o-based approach clearly
outperforming the others. Notably, personal data detection in the Kaggle and
OpenML datasets appears to benefit from contextual information. This is
evidenced by the poor performance of CASSED and Presidio (both of which do not
utilize the context of the dataset) compared to the strong results of our
GPT-4o-based approach.
  We conclude that further progress in this field would greatly benefit from
the availability of more real-world datasets containing personal information.

</details>


### [117] [Evaluating Scoring Bias in LLM-as-a-Judge](https://arxiv.org/abs/2506.22316)
*Qingquan Li,Shaoyu Dou,Kailai Shao,Chao Chen,Haixiang Hu*

Main category: cs.CL

TL;DR: 论文探讨了LLM作为评估工具时的评分偏见问题，提出了一个框架来评估和缓解这种偏见。


<details>
  <summary>Details</summary>
Motivation: LLM作为评估工具（LLM-as-a-Judge）在复杂任务中表现优异，但存在偏见，影响公平性和可靠性。目前研究多关注基于比较的评估，而对基于评分的偏见研究较少。

Method: 定义了评分偏见，并通过数据合成扩展现有基准，设计多维度评估指标，构建评估数据集。

Result: 实验表明现有评估模型的评分稳定性受偏见干扰，进一步实验为评分提示模板设计和偏见缓解提供了见解。

Conclusion: 研究揭示了评分偏见问题，并提出了评估框架和缓解建议，为未来研究提供了方向。

Abstract: The remarkable performance of Large Language Models (LLMs) gives rise
to``LLM-as-a-Judge'', where LLMs are employed as evaluators for complex tasks.
Moreover, it has been widely adopted across fields such as Natural Language
Processing (NLP), preference learning, and various specific domains. However,
there are various biases within LLM-as-a-Judge, which adversely affect the
fairness and reliability of judgments. Current research on evaluating or
mitigating bias in LLM-as-a-Judge predominantly focuses on comparison-based
evaluations, while systematic investigations into bias in scoring-based
evaluations remain limited. Therefore, we define scoring bias in LLM-as-a-Judge
as the scores differ when scoring judge models are bias-related perturbed, and
provide a well-designed framework to comprehensively evaluate scoring bias. We
augment existing LLM-as-a-Judge benchmarks through data synthesis to construct
our evaluation dataset and design multi-faceted evaluation metrics. Our
experimental results demonstrate that the scoring stability of existing judge
models is disrupted by scoring biases. Further exploratory experiments and
discussions provide valuable insights into the design of scoring prompt
templates and the mitigation of scoring biases on aspects such as score
rubrics, score IDs, and reference answer selection.

</details>


### [118] [Why Are Parsing Actions for Understanding Message Hierarchies Not Random?](https://arxiv.org/abs/2506.22366)
*Daichi Kato,Ryo Ueda,Yusuke Miyao*

Main category: cs.CL

TL;DR: 研究探讨了人类语言解析策略的非随机性，通过实验验证随机解析策略在复杂输入和引入意外性因素后的表现。


<details>
  <summary>Details</summary>
Motivation: 人类语言解析策略并非随机，但先前研究表明随机策略也能实现高通信准确性。本研究旨在验证在更复杂输入和引入意外性因素后，随机策略是否仍有效。

Method: 修改实验设置：(I) 使用具有层次结构的复杂输入，(II) 在目标函数中加入意外性相关项。

Result: 评估随机解析策略在修改后的实验条件下是否仍能保持高通信准确性。

Conclusion: 研究结果可能揭示人类语言解析策略的非随机性原因及其与通信效率的关系。

Abstract: If humans understood language by randomly selecting parsing actions, it might
have been necessary to construct a robust symbolic system capable of being
interpreted under any hierarchical structure. However, human parsing strategies
do not seem to follow such a random pattern. Why is that the case? In fact, a
previous study on emergent communication using models with hierarchical biases
have reported that agents adopting random parsing
strategies$\unicode{x2013}$ones that deviate significantly from human language
comprehension$\unicode{x2013}$can achieve high communication accuracy. In this
study, we investigate this issue by making two simple and natural modifications
to the experimental setup: (I) we use more complex inputs that have
hierarchical structures, such that random parsing makes semantic interpretation
more difficult, and (II) we incorporate a surprisal-related term, which is
known to influence the order of words and characters in natural language, into
the objective function. With these changes, we evaluate whether agents
employing random parsing strategies still maintain high communication accuracy.

</details>


### [119] [Refining Czech GEC: Insights from a Multi-Experiment Approach](https://arxiv.org/abs/2506.22402)
*Petr Pechman,Milan Straka,Jana Straková,Jakub Náplava*

Main category: cs.CL

TL;DR: 提出了一种基于Transformer架构的捷克语语法纠错系统，通过动态生成合成错误实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决捷克语语法纠错（GEC）的现有技术限制，提升性能和计算效率。

Method: 采用神经机器翻译方法，结合实时合成错误生成管道，引入语言无关和捷克语特有的错误。

Result: 最佳模型在性能和计算效率上均优于现有技术，并开源了代码和模型。

Conclusion: 该系统为捷克语GEC提供了高效解决方案，并展示了合成错误生成的有效性。

Abstract: We present a grammar error correction (GEC) system that achieves state of the
art for the Czech language. Our system is based on a neural network translation
approach with the Transformer architecture, and its key feature is its
real-time synthetic generation pipeline, which dynamically augments sentences
with artificial errors by introducing both language-agnostic and Czech-specific
errors. We conduct a comprehensive series of experiments, investigating the
Czech GEC corpora as bases for synthetic error introduction, several error
generation strategies, domain balancing, tokenization granularity, model size,
and data scaling during fine-tuning. Additionally, we evaluate the performance
of large language models (LLMs) on Czech GEC in both end-user and expert
fine-tuning scenarios. Our best-performing model is superior both in
performance and computational efficiency. The source code and the trained model
links are available on https://github.com/ufal/tsd2025-gec.

</details>


### [120] [Sequential Diagnosis with Language Models](https://arxiv.org/abs/2506.22405)
*Harsha Nori,Mayank Daswani,Christopher Kelly,Scott Lundberg,Marco Tulio Ribeiro,Marc Wilson,Xiaoxuan Liu,Viknesh Sounderajah,Jonathan Carlson,Matthew P Lungren,Bay Gross,Peter Hames,Mustafa Suleyman,Dominic King,Eric Horvitz*

Main category: cs.CL

TL;DR: 论文介绍了Sequential Diagnosis Benchmark和MAI-DxO，用于模拟临床诊断的迭代过程，显著提高了诊断准确性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型评估方法未能反映真实世界医学诊断的复杂性和迭代性，需要更贴近临床实践的评价框架。

Method: 通过Sequential Diagnosis Benchmark模拟逐步诊断过程，并开发MAI-DxO模型，优化诊断策略和成本。

Result: MAI-DxO将诊断准确性提高到80%，成本降低20%，且在不同模型家族中表现一致。

Conclusion: AI系统通过迭代思考和策略性行动，可显著提升临床诊断的精确性和经济性。

Abstract: Artificial intelligence holds great promise for expanding access to expert
medical knowledge and reasoning. However, most evaluations of language models
rely on static vignettes and multiple-choice questions that fail to reflect the
complexity and nuance of evidence-based medicine in real-world settings. In
clinical practice, physicians iteratively formulate and revise diagnostic
hypotheses, adapting each subsequent question and test to what they've just
learned, and weigh the evolving evidence before committing to a final
diagnosis. To emulate this iterative process, we introduce the Sequential
Diagnosis Benchmark, which transforms 304 diagnostically challenging New
England Journal of Medicine clinicopathological conference (NEJM-CPC) cases
into stepwise diagnostic encounters. A physician or AI begins with a short case
abstract and must iteratively request additional details from a gatekeeper
model that reveals findings only when explicitly queried. Performance is
assessed not just by diagnostic accuracy but also by the cost of physician
visits and tests performed. We also present the MAI Diagnostic Orchestrator
(MAI-DxO), a model-agnostic orchestrator that simulates a panel of physicians,
proposes likely differential diagnoses and strategically selects high-value,
cost-effective tests. When paired with OpenAI's o3 model, MAI-DxO achieves 80%
diagnostic accuracy--four times higher than the 20% average of generalist
physicians. MAI-DxO also reduces diagnostic costs by 20% compared to
physicians, and 70% compared to off-the-shelf o3. When configured for maximum
accuracy, MAI-DxO achieves 85.5% accuracy. These performance gains with MAI-DxO
generalize across models from the OpenAI, Gemini, Claude, Grok, DeepSeek, and
Llama families. We highlight how AI systems, when guided to think iteratively
and act judiciously, can advance diagnostic precision and cost-effectiveness in
clinical care.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [121] [Fine-Grained Preference Optimization Improves Spatial Reasoning in VLMs](https://arxiv.org/abs/2506.21656)
*Yifan Shen,Yuanzhe Liu,Jingyuan Zhu,Xu Cao,Xiaofeng Zhang,Yixiao He,Wenming Ye,James Matthew Rehg,Ismini Lourentzou*

Main category: cs.CV

TL;DR: SpatialReasoner-R1是一种新型视觉语言推理模型，通过M3CTS生成高质量监督数据，结合fDPO优化空间推理能力，显著提升了细粒度空间推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在细粒度空间推理和多步逻辑对齐方面表现不足，需要改进。

Method: 提出M3CTS生成多样化、逻辑一致的LongCoT推理轨迹，并设计fDPO方法，通过空间奖励机制优化描述性基础和逻辑推理。

Result: fDPO在空间质量和数量任务上分别提升4.1%和9.0%，SpatialReasoner-R1在SPATIALRGPT-Bench上优于基线9.8%。

Conclusion: SpatialReasoner-R1在细粒度空间推理任务上表现优异，同时保持通用视觉语言任务的竞争力。

Abstract: Current Vision-Language Models (VLMs) struggle with fine-grained spatial
reasoning, particularly when multi-step logic and precise spatial alignment are
required. In this work, we introduce SpatialReasoner-R1, a vision-language
reasoning model designed to address these limitations. To construct
high-quality supervision for spatial reasoning, we design a Multi-Model Monte
Carlo Tree Search (M3CTS) method that generates diverse, logically consistent
Long Chain-of-Thought (LongCoT) reasoning trajectories. In addition, we propose
fine-grained Direct Preference Optimization (fDPO), which introduces
segment-specific preference granularity for descriptive grounding and logical
reasoning, guided by a spatial reward mechanism that evaluates candidate
responses based on visual consistency, spatial grounding, and logical
coherence. Experimental results demonstrate that fDPO achieves an average
improvement of 4.1% over standard DPO across spatial quality tasks, and a 9.0%
gain in spatial quantity tasks. SpatialReasoner-R1, trained with fDPO, sets a
new SoTA on SPATIALRGPT-Bench, outperforming the strongest baseline by 9.8% in
average accuracy, while maintaining competitive performance on general
vision-language tasks.

</details>


### [122] [TanDiT: Tangent-Plane Diffusion Transformer for High-Quality 360° Panorama Generation](https://arxiv.org/abs/2506.21681)
*Hakan Çapuk,Andrew Bond,Muhammed Burak Kızıl,Emir Göçen,Erkut Erdem,Aykut Erdem*

Main category: cs.CV

TL;DR: TanDiT是一种生成全景图像的新方法，通过统一扩散模型生成切线平面图像，解决了现有模型在全景生成中的几何失真和一致性挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在全景图像生成中存在几何失真和一致性不足的问题，需要一种更有效的方法。

Method: TanDiT通过统一扩散模型生成切线平面图像，并提出模型无关的后处理步骤增强全局一致性。

Result: 实验表明，TanDiT能有效泛化训练数据，处理复杂文本提示，并生成高质量全景图像。

Conclusion: TanDiT为全景图像生成提供了一种高效且通用的解决方案。

Abstract: Recent advances in image generation have led to remarkable improvements in
synthesizing perspective images. However, these models still struggle with
panoramic image generation due to unique challenges, including varying levels
of geometric distortion and the requirement for seamless loop-consistency. To
address these issues while leveraging the strengths of the existing models, we
introduce TanDiT, a method that synthesizes panoramic scenes by generating
grids of tangent-plane images covering the entire 360$^\circ$ view. Unlike
previous methods relying on multiple diffusion branches, TanDiT utilizes a
unified diffusion model trained to produce these tangent-plane images
simultaneously within a single denoising iteration. Furthermore, we propose a
model-agnostic post-processing step specifically designed to enhance global
coherence across the generated panoramas. To accurately assess panoramic image
quality, we also present two specialized metrics, TangentIS and TangentFID, and
provide a comprehensive benchmark comprising captioned panoramic datasets and
standardized evaluation scripts. Extensive experiments demonstrate that our
method generalizes effectively beyond its training data, robustly interprets
detailed and complex text prompts, and seamlessly integrates with various
generative models to yield high-quality, diverse panoramic images.

</details>


### [123] [FOCUS: Internal MLLM Representations for Efficient Fine-Grained Visual Question Answering](https://arxiv.org/abs/2506.21710)
*Liangyu Zhong,Fabio Rosenthal,Joachim Sicking,Fabian Hüger,Thorsten Bagdonat,Hanno Gottschalk,Leo Schwinn*

Main category: cs.CV

TL;DR: FOCUS是一种无需训练的视觉裁剪方法，利用MLLM内部表示指导搜索最相关图像区域，显著提升细粒度VQA任务性能。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉裁剪技术有潜力，但现有方法存在任务特定微调需求、低效搜索或与高效注意力实现不兼容等问题。

Method: FOCUS通过四步实现：识别VQA提示中的目标对象，计算对象相关性图，提出并排序相关图像区域，使用排名最高区域执行VQA任务。

Result: FOCUS在四个细粒度VQA数据集和两种MLLM上表现优异，优于三种流行视觉裁剪方法，计算效率提升3-6.5倍。

Conclusion: FOCUS通过智能搜索策略解决了现有视觉裁剪方法的局限性，为细粒度VQA任务提供了高效解决方案。

Abstract: While Multimodal Large Language Models (MLLMs) offer strong perception and
reasoning capabilities for image-text input, Visual Question Answering (VQA)
focusing on small image details still remains a challenge. Although visual
cropping techniques seem promising, recent approaches have several limitations:
the need for task-specific fine-tuning, low efficiency due to uninformed
exhaustive search, or incompatibility with efficient attention implementations.
We address these shortcomings by proposing a training-free visual cropping
method, dubbed FOCUS, that leverages MLLM-internal representations to guide the
search for the most relevant image region. This is accomplished in four steps:
first, we identify the target object(s) in the VQA prompt; second, we compute
an object relevance map using the key-value (KV) cache; third, we propose and
rank relevant image regions based on the map; and finally, we perform the
fine-grained VQA task using the top-ranked region. As a result of this informed
search strategy, FOCUS achieves strong performance across four fine-grained VQA
datasets and two types of MLLMs. It outperforms three popular visual cropping
methods in both accuracy and efficiency, and matches the best-performing
baseline, ZoomEye, while requiring 3 - 6.5 x less compute.

</details>


### [124] [CAST: Cross-Attentive Spatio-Temporal feature fusion for Deepfake detection](https://arxiv.org/abs/2506.21711)
*Aryan Thakre,Omkar Nagwekar,Vedang Talekar,Aparna Santra Biswas*

Main category: cs.CV

TL;DR: 提出了一种基于交叉注意力的CAST模型，用于更有效地融合时空特征，提升深度伪造视频检测的性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对数字媒体真实性构成威胁，现有CNN-Transformer模型在时空特征融合上存在局限性。

Method: 提出CAST模型，利用交叉注意力动态融合时空特征，增强对细微时间演化伪造痕迹的检测能力。

Result: 在FaceForensics++、Celeb-DF和DeepfakeDetection数据集上表现优异，AUC达99.49%，准确率97.57%。

Conclusion: 交叉注意力特征融合显著提升了深度伪造检测的鲁棒性和泛化能力。

Abstract: Deepfakes have emerged as a significant threat to digital media authenticity,
increasing the need for advanced detection techniques that can identify subtle
and time-dependent manipulations. CNNs are effective at capturing spatial
artifacts, and Transformers excel at modeling temporal inconsistencies.
However, many existing CNN-Transformer models process spatial and temporal
features independently. In particular, attention-based methods often use
separate attention mechanisms for spatial and temporal features and combine
them using naive approaches like averaging, addition, or concatenation, which
limits the depth of spatio-temporal interaction. To address this challenge, we
propose a unified CAST model that leverages cross-attention to effectively fuse
spatial and temporal features in a more integrated manner. Our approach allows
temporal features to dynamically attend to relevant spatial regions, enhancing
the model's ability to detect fine-grained, time-evolving artifacts such as
flickering eyes or warped lips. This design enables more precise localization
and deeper contextual understanding, leading to improved performance across
diverse and challenging scenarios. We evaluate the performance of our model
using the FaceForensics++, Celeb-DF, and DeepfakeDetection datasets in both
intra- and cross-dataset settings to affirm the superiority of our approach.
Our model achieves strong performance with an AUC of 99.49 percent and an
accuracy of 97.57 percent in intra-dataset evaluations. In cross-dataset
testing, it demonstrates impressive generalization by achieving a 93.31 percent
AUC on the unseen DeepfakeDetection dataset. These results highlight the
effectiveness of cross-attention-based feature fusion in enhancing the
robustness of deepfake video detection.

</details>


### [125] [Elucidating and Endowing the Diffusion Training Paradigm for General Image Restoration](https://arxiv.org/abs/2506.21722)
*Xin Lu,Xueyang Fu,Jie Xiao,Zihao Fan,Yurui Zhu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出了一种将扩散训练范式融入普通图像修复（IR）框架的新方法，通过系统分析时间步依赖、网络层次等关键原则，并引入正则化策略和增量训练范式，显著提升了单任务和多任务IR的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像修复任务中表现出强大的生成能力，但其复杂架构和迭代过程限制了实际应用。现有方法主要关注网络架构和扩散路径优化，忽视了扩散训练范式与普通IR框架的整合。

Method: 通过分析时间步依赖、网络层次等关键原则，提出新的IR框架，并引入正则化策略和增量训练范式，结合任务特定适配器。

Result: 实验表明，该方法显著提升了单任务IR的泛化能力，并在多任务统一IR中表现优异。

Conclusion: 所提框架可无缝集成到现有普通IR架构中，为扩散训练范式在IR任务中的应用提供了有效解决方案。

Abstract: While diffusion models demonstrate strong generative capabilities in image
restoration (IR) tasks, their complex architectures and iterative processes
limit their practical application compared to mainstream reconstruction-based
general ordinary IR networks. Existing approaches primarily focus on optimizing
network architecture and diffusion paths but overlook the integration of the
diffusion training paradigm within general ordinary IR frameworks. To address
these challenges, this paper elucidates key principles for adapting the
diffusion training paradigm to general IR training through systematic analysis
of time-step dependencies, network hierarchies, noise-level relationships, and
multi-restoration task correlations, proposing a new IR framework supported by
diffusion-based training. To enable IR networks to simultaneously restore
images and model generative representations, we introduce a series of
regularization strategies that align diffusion objectives with IR tasks,
improving generalization in single-task scenarios. Furthermore, recognizing
that diffusion-based generation exerts varying influences across different IR
tasks, we develop an incremental training paradigm and task-specific adaptors,
further enhancing performance in multi-task unified IR. Experiments demonstrate
that our method significantly improves the generalization of IR networks in
single-task IR and achieves superior performance in multi-task unified IR.
Notably, the proposed framework can be seamlessly integrated into existing
general IR architectures.

</details>


### [126] [Asymmetric Dual Self-Distillation for 3D Self-Supervised Representation Learning](https://arxiv.org/abs/2506.21724)
*Remco F. Leijenaar,Hamidreza Kasaei*

Main category: cs.CV

TL;DR: AsymDSD是一种自监督学习框架，通过潜在空间预测结合掩码建模和不变性学习，提升了3D点云语义表示的能力。


<details>
  <summary>Details</summary>
Motivation: 解决无标签大规模3D点云数据中语义表示学习的挑战，避免传统掩码点建模（MPM）在高级语义捕捉上的局限性。

Method: 提出Asymmetric Dual Self-Distillation（AsymDSD）框架，结合掩码建模和不变性学习，采用潜在空间预测、非对称架构、多掩码采样和多裁剪点云适配等设计。

Result: 在ScanObjectNN上达到90.53%的准确率，预训练后提升至93.72%，优于现有方法。

Conclusion: AsymDSD通过潜在空间预测和高效设计，显著提升了3D点云语义表示的性能。

Abstract: Learning semantically meaningful representations from unstructured 3D point
clouds remains a central challenge in computer vision, especially in the
absence of large-scale labeled datasets. While masked point modeling (MPM) is
widely used in self-supervised 3D learning, its reconstruction-based objective
can limit its ability to capture high-level semantics. We propose AsymDSD, an
Asymmetric Dual Self-Distillation framework that unifies masked modeling and
invariance learning through prediction in the latent space rather than the
input space. AsymDSD builds on a joint embedding architecture and introduces
several key design choices: an efficient asymmetric setup, disabling attention
between masked queries to prevent shape leakage, multi-mask sampling, and a
point cloud adaptation of multi-crop. AsymDSD achieves state-of-the-art results
on ScanObjectNN (90.53%) and further improves to 93.72% when pretrained on 930k
shapes, surpassing prior methods.

</details>


### [127] [Exploring Image Generation via Mutually Exclusive Probability Spaces and Local Correlation Hypothesis](https://arxiv.org/abs/2506.21731)
*Chenqiu Zhao,Anup Basu*

Main category: cs.CV

TL;DR: 论文提出两种理论框架（MESP和LCH），探讨概率生成模型的局限性，即学习全局分布可能导致记忆而非生成行为。通过改进VAE和提出BL-AE及ARVM，实验验证了其有效性，但发现高分可能源于记忆。LCH假设局部相关性是生成能力的关键。


<details>
  <summary>Details</summary>
Motivation: 探索概率生成模型中全局分布学习可能导致记忆而非生成行为的局限性。

Method: 提出MESP框架改进VAE，引入BL-AE和ARVM模型，并通过LCH假设分析局部相关性的作用。

Result: ARVM在标准数据集上取得竞争性FID分数，但高分可能反映记忆行为。LCH验证了局部相关性对生成能力的重要性。

Conclusion: MESP和LCH框架揭示了概率生成模型的局限性，并提出局部相关性是提升生成能力的关键。

Abstract: We propose two theoretical frameworks, the Mutually Exclusive Probability
Space (MESP) and the Local Correlation Hypothesis (LCH), to explore a potential
limitation in probabilistic generative models; namely that learning global
distributions leads to memorization rather than generative behavior. MESP
emerges from our rethinking of the Variational Autoencoder (VAE). We observe
that latent variable distributions in VAE exhibit overlap, which leads to an
optimization conflict between the reconstruction loss and KL-divergence loss. A
lower bound based on the overlap coefficient is proposed. We refer to this
phenomenon as Mutually Exclusive Probability Spaces. Based on MESP, a Binary
Latent Autoencoder (BL-AE) is proposed to encode images into binary latent
representations. These binary latents are used as the input to our
Autoregressive Random Variable Model (ARVM), a modified autoregressive model
outputting histograms. Our ARVM achieves competitive FID scores, outperforming
state-of-the-art methods on standard datasets. However, such scores reflect
memorization rather than generation. To address this issue, we propose the
Local Correlation Hypothesis (LCH), which posits that generative capability
arising from local correlations among latent variables. Comprehensive
experiments and discussions are conducted to validate our frameworks.

</details>


### [128] [Equitable Federated Learning with NCA](https://arxiv.org/abs/2506.21735)
*Nick Lemke,Mirko Konstantin,Henry John Krumb,John Kalkhof,Jonathan Stieber,Anirban Mukhopadhyay*

Main category: cs.CV

TL;DR: FedNCA是一个专为医疗图像分割设计的轻量级联邦学习系统，适用于资源有限的地区，解决了计算和网络限制问题。


<details>
  <summary>Details</summary>
Motivation: 在低收入和中等收入国家（LMICs），医疗资源有限，联邦学习（FL）可以促进协作模型训练，但面临计算和网络障碍。

Method: 提出FedNCA系统，基于轻量级Med-NCA架构，支持低成本边缘设备（如智能手机）训练，并减少通信开销。

Result: FedNCA在资源受限环境中高效运行，支持加密通信，为医疗影像提供轻量级解决方案。

Conclusion: FedNCA为资源匮乏地区提供了高效、轻量且安全的医疗影像解决方案，推动医疗公平。

Abstract: Federated Learning (FL) is enabling collaborative model training across
institutions without sharing sensitive patient data. This approach is
particularly valuable in low- and middle-income countries (LMICs), where access
to trained medical professionals is limited. However, FL adoption in LMICs
faces significant barriers, including limited high-performance computing
resources and unreliable internet connectivity. To address these challenges, we
introduce FedNCA, a novel FL system tailored for medical image segmentation
tasks. FedNCA leverages the lightweight Med-NCA architecture, enabling training
on low-cost edge devices, such as widely available smartphones, while
minimizing communication costs. Additionally, our encryption-ready FedNCA
proves to be suitable for compromised network communication. By overcoming
infrastructural and security challenges, FedNCA paves the way for inclusive,
efficient, lightweight, and encryption-ready medical imaging solutions,
fostering equitable healthcare advancements in resource-constrained regions.

</details>


### [129] [ImplicitQA: Going beyond frames towards Implicit Video Reasoning](https://arxiv.org/abs/2506.21742)
*Sirnam Swetha,Rohit Gupta,Parth Parag Kulkarni,David G Shatwell,Jeffrey A Chan Santiago,Nyle Siddiqui,Joseph Fioresi,Mubarak Shah*

Main category: cs.CV

TL;DR: 论文提出了ImplicitQA基准，用于测试视频问答模型在隐含推理上的能力，弥补现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答基准主要关注显性视觉内容，而忽略了隐含推理（如动机、因果关系等），无法反映人类的理解能力。

Method: 构建了包含1K QA对的ImplicitQA基准，涵盖多种推理维度，并评估了主流视频问答模型的性能。

Result: 实验显示现有模型在隐含推理任务上表现不佳，依赖表面视觉线索。

Conclusion: ImplicitQA为社区提供了新的研究方向和数据集，推动视频问答领域的发展。

Abstract: Video QA has made significant strides by leveraging multimodal learning to
align visual and textual modalities. However, current benchmarks overwhelmingly
focus on questions answerable through explicit visual content - actions,
objects & events directly observable within individual frames or short clips.
In contrast, creative and cinematic videos - such as movies, TV shows, and
narrative-driven content - employ storytelling techniques that deliberately
omit certain depictions, requiring viewers to infer motives, causality, and
relationships across discontinuous frames. Humans naturally excel at such
implicit reasoning, seamlessly integrating information across time and context
to construct coherent narratives. Current VideoQA systems and benchmarks fail
to capture this essential dimension of human-like understanding. To bridge this
gap, we present ImplicitQA, a novel benchmark specifically designed to test
models on implicit reasoning. It comprises 1K meticulously annotated QA pairs
derived from 320+ high-quality creative video clips, systematically categorized
into key reasoning dimensions: lateral and vertical spatial reasoning, depth
and proximity, viewpoint and visibility, motion and trajectory, causal and
motivational reasoning, social interactions, physical context, and inferred
counting. These annotations are deliberately challenging, crafted by authors
ensuring high-quality. Our extensive evaluations on leading VideoQA models
reveals performance degradation, underscoring their reliance on surface-level
visual cues and highlighting the difficulty of implicit reasoning. Performance
variations across models further illustrate the complexity and diversity of the
challenges presented by ImplicitQA. By releasing both the dataset and our data
collection framework, we aim to stimulate further research and development in
the community. https://huggingface.co/datasets/ucf-crcv/ImplicitQA.

</details>


### [130] [Early Glaucoma Detection using Deep Learning with Multiple Datasets of Fundus Images](https://arxiv.org/abs/2506.21770)
*Rishiraj Paul Chowdhury,Nirmit Shekar Karkera*

Main category: cs.CV

TL;DR: 提出了一种基于EfficientNet-B0的深度学习流程，用于从视网膜眼底图像中检测青光眼，通过多数据集训练提升泛化能力，结果显示简单预处理效果更好。


<details>
  <summary>Details</summary>
Motivation: 青光眼是不可逆失明的主要原因，早期检测对治疗至关重要，传统方法通常侵入性强且需要专业设备。

Method: 使用EfficientNet-B0架构，通过ACRIMA、ORIGA和RIM-ONE数据集进行顺序训练和微调，以增强泛化能力。

Result: 实验表明，简单预处理比复杂增强方法具有更高的AUC-ROC，模型在未见数据集上表现出强判别性能。

Conclusion: 该流程为青光眼早期检测提供了可重复且可扩展的方法，具有潜在临床价值。

Abstract: Glaucoma is a leading cause of irreversible blindness, but early detection
can significantly improve treatment outcomes. Traditional diagnostic methods
are often invasive and require specialized equipment. In this work, we present
a deep learning pipeline using the EfficientNet-B0 architecture for glaucoma
detection from retinal fundus images. Unlike prior studies that rely on single
datasets, we sequentially train and fine-tune our model across ACRIMA, ORIGA,
and RIM-ONE datasets to enhance generalization. Our experiments show that
minimal preprocessing yields higher AUC-ROC compared to more complex
enhancements, and our model demonstrates strong discriminative performance on
unseen datasets. The proposed pipeline offers a reproducible and scalable
approach to early glaucoma detection, supporting its potential clinical
utility.

</details>


### [131] [Comparing Learning Paradigms for Egocentric Video Summarization](https://arxiv.org/abs/2506.21785)
*Daniel Wen*

Main category: cs.CV

TL;DR: 研究比较了监督学习、无监督学习和提示微调在自我中心视频理解中的表现，发现通用模型GPT-4o优于专用模型，凸显现有方法在适应第一人称视角时的不足。


<details>
  <summary>Details</summary>
Motivation: 探索计算机视觉技术在自我中心视频中的应用，推动该领域的发展。

Method: 评估了三种模型（Shotluck Holmes、TAC-SUM、GPT-4o）在Ego-Exo4D数据集上的视频摘要能力。

Result: 现有模型在第一人称视频中表现较差，但GPT-4o表现优于专用模型。

Conclusion: 需进一步研究以提升模型对自我中心视频的处理能力，通用模型在此领域具有潜力。

Abstract: In this study, we investigate various computer vision paradigms - supervised
learning, unsupervised learning, and prompt fine-tuning - by assessing their
ability to understand and interpret egocentric video data. Specifically, we
examine Shotluck Holmes (state-of-the-art supervised learning), TAC-SUM
(state-of-the-art unsupervised learning), and GPT-4o (a prompt fine-tuned
pre-trained model), evaluating their effectiveness in video summarization. Our
results demonstrate that current state-of-the-art models perform less
effectively on first-person videos compared to third-person videos,
highlighting the need for further advancements in the egocentric video domain.
Notably, a prompt fine-tuned general-purpose GPT-4o model outperforms these
specialized models, emphasizing the limitations of existing approaches in
adapting to the unique challenges of first-person perspectives. Although our
evaluation is conducted on a small subset of egocentric videos from the
Ego-Exo4D dataset due to resource constraints, the primary objective of this
research is to provide a comprehensive proof-of-concept analysis aimed at
advancing the application of computer vision techniques to first-person videos.
By exploring novel methodologies and evaluating their potential, we aim to
contribute to the ongoing development of models capable of effectively
processing and interpreting egocentric perspectives.

</details>


### [132] [CAT-SG: A Large Dynamic Scene Graph Dataset for Fine-Grained Understanding of Cataract Surgery](https://arxiv.org/abs/2506.21813)
*Felix Holm,Gözde Ünver,Ghazal Ghazaei,Nassir Navab*

Main category: cs.CV

TL;DR: 论文介绍了首个白内障手术场景图数据集CAT-SG，通过结构化标注工具-组织交互和时间依赖关系，为手术工作流提供全面视角，并提出优于现有方法的场景图生成模型CatSGG。


<details>
  <summary>Details</summary>
Motivation: 现有数据集仅关注手术分析的孤立方面（如工具检测或阶段分割），缺乏对实体间语义关系和时间依赖的全面建模。

Method: 提出CAT-SG数据集，标注工具-组织交互、手术变体和时间依赖关系；开发场景图生成模型CatSGG。

Result: CAT-SG数据集提供了手术工作流的全面表示；CatSGG模型在生成结构化手术表示方面优于现有方法。

Conclusion: CAT-SG和CatSGG为AI驱动的手术培训、实时决策支持和流程分析提供了新工具，推动临床实践中更智能、上下文感知系统的发展。

Abstract: Understanding the intricate workflows of cataract surgery requires modeling
complex interactions between surgical tools, anatomical structures, and
procedural techniques. Existing datasets primarily address isolated aspects of
surgical analysis, such as tool detection or phase segmentation, but lack
comprehensive representations that capture the semantic relationships between
entities over time. This paper introduces the Cataract Surgery Scene Graph
(CAT-SG) dataset, the first to provide structured annotations of tool-tissue
interactions, procedural variations, and temporal dependencies. By
incorporating detailed semantic relations, CAT-SG offers a holistic view of
surgical workflows, enabling more accurate recognition of surgical phases and
techniques. Additionally, we present a novel scene graph generation model,
CatSGG, which outperforms current methods in generating structured surgical
representations. The CAT-SG dataset is designed to enhance AI-driven surgical
training, real-time decision support, and workflow analysis, paving the way for
more intelligent, context-aware systems in clinical practice.

</details>


### [133] [Few-Shot Segmentation of Historical Maps via Linear Probing of Vision Foundation Models](https://arxiv.org/abs/2506.21826)
*Rafael Sterzinger,Marco Peer,Robert Sablatnig*

Main category: cs.CV

TL;DR: 提出了一种基于大型视觉基础模型和参数高效微调的少样本历史地图分割方法，显著提升了分割性能，并减少了对人工标注的需求。


<details>
  <summary>Details</summary>
Motivation: 历史地图作为丰富的历史资源，其多样化的视觉表现和有限的标注数据给自动化处理带来了挑战。

Method: 结合大型视觉基础模型的丰富语义嵌入和参数高效微调技术，提出了一种简单有效的少样本分割方法。

Result: 在Siegfried基准数据集上，葡萄园和铁路分割的mIoU分别提升了5%和13%，在5-shot设置下提升约20%。在ICDAR 2021数据集上，建筑块分割的PQ达到67.3%。

Conclusion: 该方法在极低数据量（10-shot和5-shot）下仍保持高性能，仅需689k可训练参数，显著减少了对人工标注的依赖，推动了历史地图的自动化处理。

Abstract: As rich sources of history, maps provide crucial insights into historical
changes, yet their diverse visual representations and limited annotated data
pose significant challenges for automated processing. We propose a simple yet
effective approach for few-shot segmentation of historical maps, leveraging the
rich semantic embeddings of large vision foundation models combined with
parameter-efficient fine-tuning. Our method outperforms the state-of-the-art on
the Siegfried benchmark dataset in vineyard and railway segmentation, achieving
+5% and +13% relative improvements in mIoU in 10-shot scenarios and around +20%
in the more challenging 5-shot setting. Additionally, it demonstrates strong
performance on the ICDAR 2021 competition dataset, attaining a mean PQ of 67.3%
for building block segmentation, despite not being optimized for this
shape-sensitive metric, underscoring its generalizability. Notably, our
approach maintains high performance even in extremely low-data regimes (10- &
5-shot), while requiring only 689k trainable parameters - just 0.21% of the
total model size. Our approach enables precise segmentation of diverse
historical maps while drastically reducing the need for manual annotations,
advancing automated processing and analysis in the field. Our implementation is
publicly available at:
https://github.com/RafaelSterzinger/few-shot-map-segmentation.

</details>


### [134] [TaleForge: Interactive Multimodal System for Personalized Story Creation](https://arxiv.org/abs/2506.21832)
*Minh-Loi Nguyen,Quang-Khai Le,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: TaleForge是一个结合LLMs和文本到图像扩散技术的个性化故事生成系统，通过将用户面部图像嵌入叙事和插图中，提升沉浸感和参与度。


<details>
  <summary>Details</summary>
Motivation: 现有方法将用户视为被动消费者，提供通用情节，缺乏个性化，影响参与度和沉浸感。

Method: TaleForge包含三个模块：故事生成（LLMs根据用户提示创建叙事和角色描述）、个性化图像生成（将用户面部和服装选择融入角色插图）、背景生成（创建包含个性化角色的场景背景）。

Result: 用户研究表明，当用户作为主角时，参与感和归属感显著提升。系统获得实时预览和直观控制的赞誉，但用户希望有更精细的叙事编辑工具。

Conclusion: TaleForge通过个性化文本和图像的结合，推动了多模态叙事的发展，创造了沉浸式、以用户为中心的体验。

Abstract: Storytelling is a deeply personal and creative process, yet existing methods
often treat users as passive consumers, offering generic plots with limited
personalization. This undermines engagement and immersion, especially where
individual style or appearance is crucial. We introduce TaleForge, a
personalized story-generation system that integrates large language models
(LLMs) and text-to-image diffusion to embed users' facial images within both
narratives and illustrations. TaleForge features three interconnected modules:
Story Generation, where LLMs create narratives and character descriptions from
user prompts; Personalized Image Generation, merging users' faces and outfit
choices into character illustrations; and Background Generation, creating scene
backdrops that incorporate personalized characters. A user study demonstrated
heightened engagement and ownership when individuals appeared as protagonists.
Participants praised the system's real-time previews and intuitive controls,
though they requested finer narrative editing tools. TaleForge advances
multimodal storytelling by aligning personalized text and imagery to create
immersive, user-centric experiences.

</details>


### [135] [PrefPaint: Enhancing Image Inpainting through Expert Human Feedback](https://arxiv.org/abs/2506.21834)
*Duy-Bao Bui,Hoang-Khang Nguyen,Trung-Nghia Le*

Main category: cs.CV

TL;DR: PrefPaint通过结合人类反馈改进Stable Diffusion Inpainting，提升医学图像修复的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 医学图像修复在如息肉成像等专业领域需要高精度，现有模型可能生成不准确图像，影响诊断。

Method: PrefPaint引入人类反馈优化训练过程，无需复杂奖励模型，并提供基于网页的交互界面。

Result: PrefPaint在多个领域表现优于现有方法，尤其在医学图像中生成更真实的息肉图像。

Conclusion: PrefPaint通过交互式反馈显著提升医学图像修复质量，具有实际应用潜力。

Abstract: Inpainting, the process of filling missing or corrupted image parts, has
broad applications, including medical imaging. However, in specialized fields
like medical polyps imaging, where accuracy and reliability are critical,
inpainting models can generate inaccurate images, leading to significant errors
in medical diagnosis and treatment. To ensure reliability, medical images
should be annotated by experts like oncologists for effective model training.
We propose PrefPaint, an approach that incorporates human feedback into the
training process of Stable Diffusion Inpainting, bypassing the need for
computationally expensive reward models. In addition, we develop a web-based
interface streamlines training, fine-tuning, and inference. This interactive
interface provides a smooth and intuitive user experience, making it easier to
offer feedback and manage the fine-tuning process. User study on various
domains shows that PrefPaint outperforms existing methods, reducing visual
inconsistencies and improving image rendering, particularly in medical
contexts, where our model generates more realistic polyps images.

</details>


### [136] [ProSAM: Enhancing the Robustness of SAM-based Visual Reference Segmentation with Probabilistic Prompts](https://arxiv.org/abs/2506.21835)
*Xiaoqi Wang,Clint Sebastian,Wenbin He,Liu Ren*

Main category: cs.CV

TL;DR: ProSAM提出了一种改进的视觉参考分割方法，通过学习变分提示编码器生成更稳定的提示分布，解决了现有SAM方法在边界生成提示的不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有SAM方法在视觉参考分割中因提示编码器不理想而在边界生成提示，导致不稳定性和鲁棒性下降。

Method: ProSAM通过学习变分提示编码器预测多变量提示分布，避免在不稳定区域生成提示。

Result: 在Pascal-5$^i$和COCO-20$^i$数据集上，ProSAM表现优于现有方法。

Conclusion: ProSAM为视觉参考分割提供了更鲁棒的解决方案。

Abstract: The recent advancements in large foundation models have driven the success of
open-set image segmentation, a task focused on segmenting objects beyond
predefined categories. Among various prompt types (such as points, boxes,
texts, and visual references), visual reference segmentation stands out for its
unique flexibility and strong zero-shot capabilities. Recently, several
SAM-based methods have made notable progress in this task by automatically
generating prompts to guide SAM. However, these methods often generate prompts
at object boundaries due to suboptimal prompt encoder, which results in
instability and reduced robustness. In this work, we introduce ProSAM, a simple
but effective method to address the stability challenges we identified in
existing SAM-based visual reference segmentation approaches. By learning a
variational prompt encoder to predict multivariate prompt distributions, ProSAM
avoids generating prompts that lie in unstable regions, overcoming the
instability caused by less robust prompts. Our approach consistently surpasses
state-of-the-art methods on the Pascal-5$^i$ and COCO-20$^i$ datasets,
providing a more robust solution for visual reference segmentation.

</details>


### [137] [GenEscape: Hierarchical Multi-Agent Generation of Escape Room Puzzles](https://arxiv.org/abs/2506.21839)
*Mengyi Shan,Brian Curless,Ira Kemelmacher-Shlizerman,Steve Seitz*

Main category: cs.CV

TL;DR: 提出了一种分层多智能体框架，用于生成视觉吸引、逻辑严密且具有挑战性的逃脱房间谜题图像，解决了基础图像模型在空间关系和功能推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 挑战文本到图像模型生成逃脱房间谜题图像的能力，要求其视觉吸引、逻辑严密且具有挑战性。

Method: 采用分层多智能体框架，将任务分解为功能设计、符号场景图推理、布局合成和局部图像编辑四个阶段，通过智能体协作和迭代反馈确保场景的视觉一致性和功能性可解性。

Result: 实验表明，智能体协作显著提升了输出质量，包括可解性、避免捷径和功能清晰度，同时保持了视觉质量。

Conclusion: 提出的多智能体框架有效提升了生成逃脱房间谜题图像的质量，解决了基础模型的局限性。

Abstract: We challenge text-to-image models with generating escape room puzzle images
that are visually appealing, logically solid, and intellectually stimulating.
While base image models struggle with spatial relationships and affordance
reasoning, we propose a hierarchical multi-agent framework that decomposes this
task into structured stages: functional design, symbolic scene graph reasoning,
layout synthesis, and local image editing. Specialized agents collaborate
through iterative feedback to ensure the scene is visually coherent and
functionally solvable. Experiments show that agent collaboration improves
output quality in terms of solvability, shortcut avoidance, and affordance
clarity, while maintaining visual quality.

</details>


### [138] [ADNet: Leveraging Error-Bias Towards Normal Direction in Face Alignment](https://arxiv.org/abs/2109.05721)
*Yangyu Huang,Hao Yang,Chong Li,Jongyoo Kim,Fangyun Wei*

Main category: cs.CV

TL;DR: 该论文提出了一种解决人脸对齐中误差偏差问题的方法，通过各向异性方向损失（ADL）和各向异性注意力模块（AAM）优化CNN模型，并在多个数据集上取得了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 人脸对齐任务中，地标误差的分布往往沿着地标曲线的切线方向扩散，这种误差偏差与模糊的地标标注任务密切相关。论文旨在利用这一特性优化CNN模型的收敛性。

Method: 提出ADL和AAM方法，分别用于坐标回归和热图回归。ADL在法线方向上施加强约束力，而AAM则生成各向异性注意力掩码，在切线方向上放松约束。

Result: 在300W、WFLW和COFW数据集上实现了最先进的性能。

Conclusion: ADL和AAM的互补性有效学习了面部结构和纹理细节，验证了方法的有效性和鲁棒性。

Abstract: The recent progress of CNN has dramatically improved face alignment
performance. However, few works have paid attention to the error-bias with
respect to error distribution of facial landmarks. In this paper, we
investigate the error-bias issue in face alignment, where the distributions of
landmark errors tend to spread along the tangent line to landmark curves. This
error-bias is not trivial since it is closely connected to the ambiguous
landmark labeling task. Inspired by this observation, we seek a way to leverage
the error-bias property for better convergence of CNN model. To this end, we
propose anisotropic direction loss (ADL) and anisotropic attention module (AAM)
for coordinate and heatmap regression, respectively. ADL imposes strong binding
force in normal direction for each landmark point on facial boundaries. On the
other hand, AAM is an attention module which can get anisotropic attention mask
focusing on the region of point and its local edge connected by adjacent
points, it has a stronger response in tangent than in normal, which means
relaxed constraints in the tangent. These two methods work in a complementary
manner to learn both facial structures and texture details. Finally, we
integrate them into an optimized end-to-end training pipeline named ADNet. Our
ADNet achieves state-of-the-art results on 300W, WFLW and COFW datasets, which
demonstrates the effectiveness and robustness.

</details>


### [139] [3D-Telepathy: Reconstructing 3D Objects from EEG Signals](https://arxiv.org/abs/2506.21843)
*Yuxiang Ge,Jionghao Cheng,Ruiquan Ge,Zhaojie Fang,Gangyong Jia,Xiang Wan,Nannan Li,Ahmed Elazab,Changmiao Wang*

Main category: cs.CV

TL;DR: 提出了一种从EEG数据重建3D视觉刺激的创新方法，解决了传统2D重建的局限性。


<details>
  <summary>Details</summary>
Motivation: EEG数据中蕴含丰富的空间信息，但传统方法仅重建2D图像，限制了BCI应用潜力。

Method: 采用双自注意力机制的EEG编码器架构，结合交叉注意力、对比学习和自监督学习的混合训练策略，并使用稳定扩散和变分评分蒸馏生成3D对象。

Result: 成功从EEG数据生成了内容和结构相似的3D对象。

Conclusion: 该方法为EEG到3D重建提供了新思路，扩展了BCI的应用范围。

Abstract: Reconstructing 3D visual stimuli from Electroencephalography (EEG) data holds
significant potential for applications in Brain-Computer Interfaces (BCIs) and
aiding individuals with communication disorders. Traditionally, efforts have
focused on converting brain activity into 2D images, neglecting the translation
of EEG data into 3D objects. This limitation is noteworthy, as the human brain
inherently processes three-dimensional spatial information regardless of
whether observing 2D images or the real world. The neural activities captured
by EEG contain rich spatial information that is inevitably lost when
reconstructing only 2D images, thus limiting its practical applications in BCI.
The transition from EEG data to 3D object reconstruction faces considerable
obstacles. These include the presence of extensive noise within EEG signals and
a scarcity of datasets that include both EEG and 3D information, which
complicates the extraction process of 3D visual data. Addressing this
challenging task, we propose an innovative EEG encoder architecture that
integrates a dual self-attention mechanism. We use a hybrid training strategy
to train the EEG Encoder, which includes cross-attention, contrastive learning,
and self-supervised learning techniques. Additionally, by employing stable
diffusion as a prior distribution and utilizing Variational Score Distillation
to train a neural radiation field, we successfully generate 3D objects with
similar content and structure from EEG data.

</details>


### [140] [FreeEnricher: Enriching Face Landmarks without Additional Cost](https://arxiv.org/abs/2212.09525)
*Yangyu Huang,Xi Chen,Jongyoo Kim,Hao Yang,Chong Li,Jiaolong Yang,Dong Chen*

Main category: cs.CV

TL;DR: 提出了一种通过稀疏标志点数据集（如300W和WFLW）生成密集标志点的框架，利用弱监督学习提升标志点密度，并在多个测试集上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 密集面部标志点在美容医学和面部美化等场景需求高，但现有工作多关注稀疏标志点。

Method: 通过观察语义轮廓局部外观相似性，提出弱监督学习框架，设计多个操作符实现标志点密度提升，并作为即插即用模块应用于现有网络。

Result: 在密集300W测试集及原始稀疏300W和WFLW测试集上均取得最优性能，且无需额外成本。

Conclusion: 该框架能有效提升标志点密度，并在多个测试集上表现优异，具有广泛应用潜力。

Abstract: Recent years have witnessed significant growth of face alignment. Though
dense facial landmark is highly demanded in various scenarios, e.g., cosmetic
medicine and facial beautification, most works only consider sparse face
alignment. To address this problem, we present a framework that can enrich
landmark density by existing sparse landmark datasets, e.g., 300W with 68
points and WFLW with 98 points. Firstly, we observe that the local patches
along each semantic contour are highly similar in appearance. Then, we propose
a weakly-supervised idea of learning the refinement ability on original sparse
landmarks and adapting this ability to enriched dense landmarks. Meanwhile,
several operators are devised and organized together to implement the idea.
Finally, the trained model is applied as a plug-and-play module to the existing
face alignment networks. To evaluate our method, we manually label the dense
landmarks on 300W testset. Our method yields state-of-the-art accuracy not only
in newly-constructed dense 300W testset but also in the original sparse 300W
and WFLW testsets without additional cost.

</details>


### [141] [End-to-End RGB-IR Joint Image Compression With Channel-wise Cross-modality Entropy Model](https://arxiv.org/abs/2506.21851)
*Haofeng Wang,Fangtao Zhou,Qi Zhang,Zeyuan Chen,Enci Zhang,Zhao Wang,Xiaofeng Huang,Siwei Ma*

Main category: cs.CV

TL;DR: 提出了一种用于RGB-IR图像对的联合压缩框架，通过跨模态熵模型（CCEM）提升压缩效率，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着RGB-IR图像对在多模态应用中的广泛使用，数据存储和传输成本成倍增加，因此需要高效的压缩方法。

Method: 设计了CCEM模型，包含LCEB和LCFB模块，用于提取和融合跨模态的低频信息，以更准确地预测熵参数。

Result: 在LLVIP和KAIST数据集上，该方法比现有RGB-IR和单模态压缩方法表现更优，例如在LLVIP数据集上节省了23.1%的比特率。

Conclusion: 提出的框架通过利用跨模态先验信息，显著提升了RGB-IR图像对的压缩效率。

Abstract: RGB-IR(RGB-Infrared) image pairs are frequently applied simultaneously in
various applications like intelligent surveillance. However, as the number of
modalities increases, the required data storage and transmission costs also
double. Therefore, efficient RGB-IR data compression is essential. This work
proposes a joint compression framework for RGB-IR image pair. Specifically, to
fully utilize cross-modality prior information for accurate context probability
modeling within and between modalities, we propose a Channel-wise
Cross-modality Entropy Model (CCEM). Among CCEM, a Low-frequency Context
Extraction Block (LCEB) and a Low-frequency Context Fusion Block (LCFB) are
designed for extracting and aggregating the global low-frequency information
from both modalities, which assist the model in predicting entropy parameters
more accurately. Experimental results demonstrate that our approach outperforms
existing RGB-IR image pair and single-modality compression methods on LLVIP and
KAIST datasets. For instance, the proposed framework achieves a 23.1% bit rate
saving on LLVIP dataset compared to the state-of-the-art RGB-IR image codec
presented at CVPR 2022.

</details>


### [142] [Periodic-MAE: Periodic Video Masked Autoencoder for rPPG Estimation](https://arxiv.org/abs/2506.21855)
*Jiho Choi,Sang Jun Lee*

Main category: cs.CV

TL;DR: 提出一种通过自监督学习从无标签面部视频中学习周期性信号通用表示的方法，用于远程光电容积描记术（rPPG）估计。


<details>
  <summary>Details</summary>
Motivation: 从面部视频中捕捉细微肤色变化以估计生理信号（如心率）是rPPG的关键，但现有方法在跨数据集评估中表现不佳。

Method: 使用视频掩码自编码器学习高维时空表示，结合帧掩码和生理带宽限制约束。

Result: 在PURE、UBFC-rPPG、MMPD和V4V数据集上表现优异，尤其在跨数据集评估中显著提升。

Conclusion: 该方法通过自监督学习和生理约束有效提升了rPPG任务的性能。

Abstract: In this paper, we propose a method that learns a general representation of
periodic signals from unlabeled facial videos by capturing subtle changes in
skin tone over time. The proposed framework employs the video masked
autoencoder to learn a high-dimensional spatio-temporal representation of the
facial region through self-supervised learning. Capturing quasi-periodic
signals in the video is crucial for remote photoplethysmography (rPPG)
estimation. To account for signal periodicity, we apply frame masking in terms
of video sampling, which allows the model to capture resampled quasi-periodic
signals during the pre-training stage. Moreover, the framework incorporates
physiological bandlimit constraints, leveraging the property that physiological
signals are sparse within their frequency bandwidth to provide pulse cues to
the model. The pre-trained encoder is then transferred to the rPPG task, where
it is used to extract physiological signals from facial videos. We evaluate the
proposed method through extensive experiments on the PURE, UBFC-rPPG, MMPD, and
V4V datasets. Our results demonstrate significant performance improvements,
particularly in challenging cross-dataset evaluations. Our code is available at
https://github.com/ziiho08/Periodic-MAE.

</details>


### [143] [PEACE: Empowering Geologic Map Holistic Understanding with MLLMs](https://arxiv.org/abs/2501.06184)
*Yangyu Huang,Tianyi Gao,Haoran Xu,Qihao Zhao,Yang Song,Zhipeng Gui,Tengchao Lv,Hao Chen,Lei Cui,Scarlett Li,Furu Wei*

Main category: cs.CV

TL;DR: 论文提出了GeoMap-Bench基准和GeoMap-Agent模型，用于提升多模态大语言模型在地质图理解上的能力，显著优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在地质图理解上表现不足，主要由于地图的高分辨率、多组件和领域知识需求。

Method: 构建GeoMap-Bench基准，开发GeoMap-Agent模型，包含层次信息提取、领域知识注入和提示增强问答模块。

Result: GeoMap-Agent在GeoMap-Bench上得分为0.811，显著高于GPT-4o的0.369。

Conclusion: 该工作为地质学中的AI应用铺平道路，提升了地质调查的效率和准确性。

Abstract: Geologic map, as a fundamental diagram in geology science, provides critical
insights into the structure and composition of Earth's subsurface and surface.
These maps are indispensable in various fields, including disaster detection,
resource exploration, and civil engineering. Despite their significance,
current Multimodal Large Language Models (MLLMs) often fall short in geologic
map understanding. This gap is primarily due to the challenging nature of
cartographic generalization, which involves handling high-resolution map,
managing multiple associated components, and requiring domain-specific
knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever
benchmark for evaluating MLLMs in geologic map understanding, which assesses
the full-scale abilities in extracting, referring, grounding, reasoning, and
analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent
designed for geologic map understanding, which features three modules:
Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI),
and Prompt-enhanced Question Answering (PEQA). Inspired by the
interdisciplinary collaboration among human scientists, an AI expert group acts
as consultants, utilizing a diverse tool pool to comprehensively analyze
questions. Through comprehensive experiments, GeoMap-Agent achieves an overall
score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o.
Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs,
paves the way for advanced AI applications in geology, enhancing the efficiency
and accuracy of geological investigations.

</details>


### [144] [SPADE: Spatial Transcriptomics and Pathology Alignment Using a Mixture of Data Experts for an Expressive Latent Space](https://arxiv.org/abs/2506.21857)
*Ekaterina Redekop,Mara Pleasure,Zichen Wang,Kimberly Flores,Anthony Sisk,William Speier,Corey W. Arnold*

Main category: cs.CV

TL;DR: SPADE是一种基础模型，整合了组织病理学和空间转录组学数据，通过对比学习在统一框架内学习图像表示，显著提升了少样本任务的性能。


<details>
  <summary>Details</summary>
Motivation: 数字病理学和自监督深度学习的快速发展为多疾病病理任务的基础模型开发提供了可能，但全切片图像与空间转录组学的全面整合仍存在关键缺口。

Method: SPADE采用混合数据专家技术，通过两阶段特征空间聚类创建专家，利用对比学习学习共配准的WSI切片和基因表达谱的表示。

Result: 在HEST-1k数据集上预训练后，SPADE在14个下游任务中表现出显著优于基线模型的少样本性能。

Conclusion: SPADE展示了将形态学和分子信息整合到一个潜在空间中的优势，为病理学任务提供了更全面的解决方案。

Abstract: The rapid growth of digital pathology and advances in self-supervised deep
learning have enabled the development of foundational models for various
pathology tasks across diverse diseases. While multimodal approaches
integrating diverse data sources have emerged, a critical gap remains in the
comprehensive integration of whole-slide images (WSIs) with spatial
transcriptomics (ST), which is crucial for capturing critical molecular
heterogeneity beyond standard hematoxylin & eosin (H&E) staining. We introduce
SPADE, a foundation model that integrates histopathology with ST data to guide
image representation learning within a unified framework, in effect creating an
ST-informed latent space. SPADE leverages a mixture-of-data experts technique,
where experts, created via two-stage feature-space clustering, use contrastive
learning to learn representations of co-registered WSI patches and gene
expression profiles. Pre-trained on the comprehensive HEST-1k dataset, SPADE is
evaluated on 14 downstream tasks, demonstrating significantly superior few-shot
performance compared to baseline models, highlighting the benefits of
integrating morphological and molecular information into one latent space.

</details>


### [145] [LLaVA-Scissor: Token Compression with Semantic Connected Components for Video LLMs](https://arxiv.org/abs/2506.21862)
*Boyuan Sun,Jiaxing Zhao,Xihan Wei,Qibin Hou*

Main category: cs.CV

TL;DR: LLaVA-Scissor是一种无需训练的令牌压缩策略，用于视频多模态大语言模型，通过语义连通组件（SCC）方法实现全面的语义覆盖，优于其他压缩方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力得分的令牌压缩方法无法有效捕捉所有语义区域且易导致冗余，需改进。

Method: 提出两步骤的时空令牌压缩策略，利用SCC在空间和时间域分配令牌至不同语义区域。

Result: 在多种视频理解基准测试中表现优异，尤其在低令牌保留率下。

Conclusion: LLaVA-Scissor通过SCC方法实现了高效的令牌压缩，显著提升了视频理解性能。

Abstract: In this paper, we present LLaVA-Scissor, a training-free token compression
strategy designed for video multimodal large language models. Previous methods
mostly attempt to compress tokens based on attention scores, but fail to
effectively capture all semantic regions and often lead to token redundancy.
Differently, we propose to leverage the Semantic Connected Components (SCC)
approach that assigns tokens to distinct semantic regions within the token set,
ensuring comprehensive semantic coverage. The outcome is a two-step
spatio-temporal token compression strategy that utilizes SCC in both spatial
and temporal domains. This strategy can effectively compress tokens by
representing the entire video with a set of non-overlapping semantic tokens. We
conduct extensive evaluations of the token compression capabilities of
LLaVA-Scissor across diverse video understanding benchmarks, including video
question answering, long video understanding, and comprehensive multi-choices
benchmarks. Experimental results show that the proposed LLaVA-Scissor
outperforms other token compression methods, achieving superior performance in
various video understanding benchmarks, particularly at low token retention
ratios. Project page: https://github.com/HumanMLLM/LLaVA-Scissor.

</details>


### [146] [Remote Sensing Large Vision-Language Model: Semantic-augmented Multi-level Alignment and Semantic-aware Expert Modeling](https://arxiv.org/abs/2506.21863)
*Sungjune Park,Yeongyun Kim,Se Yeon Kim,Yong Man Ro*

Main category: cs.CV

TL;DR: 论文提出了一种针对遥感（RS）图像理解的新型大型视觉与语言模型（LVLM）框架，通过语义增强的多级对齐和语义感知专家建模，解决了现有LVLMs在RS领域的适应性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs在自然图像领域表现优异，但在遥感图像中因视觉外观、对象尺度和语义的显著差异而效果受限，亟需针对RS的定制化解决方案。

Method: 框架包含两个核心组件：1）基于检索的语义增强模块，用于多级视觉特征对齐；2）语义感知专家建模，分层次处理不同级别的语义表示。

Result: 在多个RS任务（如场景分类和视觉问答）中，该框架实现了跨语义级别的性能提升，验证了其有效性。

Conclusion: 该研究成功填补了通用LVLMs与RS特定需求之间的鸿沟，为RS领域的视觉-语言理解提供了有效工具。

Abstract: Large Vision and Language Models (LVLMs) have shown strong performance across
various vision-language tasks in natural image domains. However, their
application to remote sensing (RS) remains underexplored due to significant
domain differences in visual appearances, object scales, and semantics. These
discrepancies hider the effective understanding of RS scenes, which contain
rich, multi-level semantic information spanning from coarse-to-fine levels.
Hence, it limits the direct adaptation of existing LVLMs to RS imagery. To
address this gap, we propose a novel LVLM framework tailored for RS
understanding, incorporating two core components: Semantic-augmented
Multi-level Alignment and Semantic-aware Expert Modeling. First, to align
multi-level visual features, we introduce the retrieval-based Semantic
Augmentation Module which enriches the visual features with relevant semantics
across fine-to-coarse levels (e.g., object- and scene-level information). It is
designed to retrieve relevant semantic cues from a RS semantic knowledge
database, followed by aggregation of semantic cues with user query and
multi-level visual features, resulting in semantically enriched representation
across multiple levels. Second, for Semantic-aware Expert Modeling, we design
semantic experts, where each expert is responsible for processing semantic
representation at different levels separately. This enables hierarchical
semantic understanding from coarse to fine levels. Evaluations across multiple
RS tasks-including scene classification and VQA, etc.-demonstrate that the
proposed framework achieves consistent improvements across multiple semantic
levels. This highlights its capability and effectiveness in bridging the gap
between general LVLMs and unique demands of RS-specific vision-language
understanding.

</details>


### [147] [Dual-Perspective United Transformer for Object Segmentation in Optical Remote Sensing Images](https://arxiv.org/abs/2506.21866)
*Yanguang Sun,Jiexi Yan,Jianjun Qian,Chunyan Xu,Jian Yang,Lei Luo*

Main category: cs.CV

TL;DR: 提出了一种名为DPU-Former的双视角统一Transformer模型，用于光学遥感图像分割，结合了卷积和Transformer的优势，解决了现有方法的异质性、高复杂性和大参数问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅基于卷积或Transformer特征，忽略了二者的异质性和融合问题，导致分割效果不佳。

Method: 设计了全局-局部混合注意力机制和傅里叶空间融合策略，并引入门控线性前馈网络增强表达能力，构建了DPU-Former解码器。

Result: DPU-Former在多个数据集上优于现有最优方法。

Conclusion: DPU-Former通过双视角融合策略和高效结构设计，显著提升了光学遥感图像的分割性能。

Abstract: Automatically segmenting objects from optical remote sensing images (ORSIs)
is an important task. Most existing models are primarily based on either
convolutional or Transformer features, each offering distinct advantages.
Exploiting both advantages is valuable research, but it presents several
challenges, including the heterogeneity between the two types of features, high
complexity, and large parameters of the model. However, these issues are often
overlooked in existing the ORSIs methods, causing sub-optimal segmentation. For
that, we propose a novel Dual-Perspective United Transformer (DPU-Former) with
a unique structure designed to simultaneously integrate long-range dependencies
and spatial details. In particular, we design the global-local mixed attention,
which captures diverse information through two perspectives and introduces a
Fourier-space merging strategy to obviate deviations for efficient fusion.
Furthermore, we present a gated linear feed-forward network to increase the
expressive ability. Additionally, we construct a DPU-Former decoder to
aggregate and strength features at different layers. Consequently, the
DPU-Former model outperforms the state-of-the-art methods on multiple datasets.
Code: https://github.com/CSYSI/DPU-Former.

</details>


### [148] [Grounding-Aware Token Pruning: Recovering from Drastic Performance Drops in Visual Grounding Caused by Pruning](https://arxiv.org/abs/2506.21873)
*Tzu-Chun Chien,Chieh-Kai Lin,Shiang-Feng Tsai,Ruei-Chi Lai,Hung-Jen Chen,Min Sun*

Main category: cs.CV

TL;DR: 多模态大语言模型（MLLMs）在视觉定位任务中表现优异，但视觉标记剪枝会显著降低模型性能。研究发现位置ID错位是主要原因，提出了一种无需额外训练的方法GAP，显著恢复了性能。


<details>
  <summary>Details</summary>
Motivation: 视觉标记剪枝虽然能降低计算成本，但会严重损害模型的视觉定位能力，导致性能大幅下降。

Method: 提出Grounding-Aware Token Pruning (GAP)，通过调整位置ID，解决剪枝后的性能下降问题。

Result: GAP将LLaVA在RefCOCO验证集上的准确率从剪枝后的15.34%恢复到51.42%，接近原始性能的90%。

Conclusion: GAP是一种简单有效的方法，无需额外资源即可显著提升剪枝后模型的视觉定位性能。

Abstract: Recent Multimodal Large Language Models (MLLMs) have demonstrated strong
performance in visual grounding, establishing themselves as a general interface
for various vision-language applications. This progress has driven the
development of token pruning methods to mitigate the high computational costs
associated with processing numerous visual tokens. However, we observe that
pruning significantly weakens the model's grounding ability, leading to
incorrect predictions and drastic performance degradation. In Referring
Expression Comprehension (REC), for instance, pruning causes the accuracy of
LLaVA on the RefCOCO validation set to drop from 56.14% to 15.34%. Our analysis
identifies misaligned position IDs after pruning as the primary cause of this
degradation, as both the order and value of these IDs are crucial for
maintaining performance in grounding tasks. To address this issue, we propose
Grounding-Aware Token Pruning (GAP), a simple yet effective adjustment to
position IDs that recovers REC accuracy back to 51.42%, which is 90% of the
original performance in the without pruning setting, all while requiring no
additional training, memory, or computational overhead. Applied to models such
as Shikra, MiniGPTv2, and the LLaVA series, our method consistently improves
performance across various token pruning strategies.

</details>


### [149] [GRASP-PsONet: Gradient-based Removal of Spurious Patterns for PsOriasis Severity Classification](https://arxiv.org/abs/2506.21883)
*Basudha Pal,Sharif Amit Kamran,Brendon Lutnick,Molly Lucas,Chaitanya Parmar,Asha Patel Shah,David Apfel,Steven Fakharzadeh,Lloyd Miller,Gabriela Cula,Kristopher Standish*

Main category: cs.CV

TL;DR: 提出一种基于梯度的框架，用于自动识别训练图像中的问题样本，提升银屑病严重程度自动评分的模型性能。


<details>
  <summary>Details</summary>
Motivation: 银屑病严重程度评分在临床试验中很重要，但受限于评估者间差异和临床评估负担。远程成像虽具扩展性，但存在光照、背景和设备质量等问题，影响模型性能。

Method: 采用基于梯度的可解释性方法，通过追踪误分类验证图像的梯度，检测训练样本中的不一致标注或非临床伪影。

Result: 移除8.2%的问题图像后，模型AUC-ROC提升5%（85%至90%）。方法还能检测90%以上的标注不一致案例。

Conclusion: 该方法提升了远程评估的自动化评分鲁棒性，减少了对人工标注的依赖。

Abstract: Psoriasis (PsO) severity scoring is important for clinical trials but is
hindered by inter-rater variability and the burden of in person clinical
evaluation. Remote imaging using patient captured mobile photos offers
scalability but introduces challenges, such as variation in lighting,
background, and device quality that are often imperceptible to humans but can
impact model performance. These factors, along with inconsistencies in
dermatologist annotations, reduce the reliability of automated severity
scoring. We propose a framework to automatically flag problematic training
images that introduce spurious correlations which degrade model generalization,
using a gradient based interpretability approach. By tracing the gradients of
misclassified validation images, we detect training samples where model errors
align with inconsistently rated examples or are affected by subtle, nonclinical
artifacts. We apply this method to a ConvNeXT based weakly supervised model
designed to classify PsO severity from phone images. Removing 8.2% of flagged
images improves model AUC-ROC by 5% (85% to 90%) on a held out test set.
Commonly, multiple annotators and an adjudication process ensure annotation
accuracy, which is expensive and time consuming. Our method detects training
images with annotation inconsistencies, potentially removing the need for
manual review. When applied to a subset of training data rated by two
dermatologists, the method identifies over 90% of cases with inter-rater
disagreement by reviewing only the top 30% of samples. This improves automated
scoring for remote assessments, ensuring robustness despite data collection
variability.

</details>


### [150] [Integrating Multi-Modal Sensors: A Review of Fusion Techniques for Intelligent Vehicles](https://arxiv.org/abs/2506.21885)
*Chuheng Wei,Ziye Qin,Ziyan Zhang,Guoyuan Wu,Matthew J. Barth*

Main category: cs.CV

TL;DR: 本文系统综述了多传感器融合在自动驾驶中的策略（数据级、特征级、决策级）及深度学习方法，探讨了多模态数据集的应用和新兴趋势（如视觉语言模型和大语言模型的集成）。


<details>
  <summary>Details</summary>
Motivation: 多传感器融合能克服单一传感器的局限性，提升自动驾驶的环境感知能力，尤其在恶劣天气和复杂城市环境中。

Method: 将多传感器融合策略分为数据级、特征级和决策级，并系统综述了基于深度学习的对应方法。

Result: 提出了多模态数据集的应用和新兴趋势，展示了传感器融合在增强系统适应性和鲁棒性方面的潜力。

Conclusion: 本文为自动驾驶中的多传感器融合提供了当前方法和未来方向的宝贵见解。

Abstract: Multi-sensor fusion plays a critical role in enhancing perception for
autonomous driving, overcoming individual sensor limitations, and enabling
comprehensive environmental understanding. This paper first formalizes
multi-sensor fusion strategies into data-level, feature-level, and
decision-level categories and then provides a systematic review of deep
learning-based methods corresponding to each strategy. We present key
multi-modal datasets and discuss their applicability in addressing real-world
challenges, particularly in adverse weather conditions and complex urban
environments. Additionally, we explore emerging trends, including the
integration of Vision-Language Models (VLMs), Large Language Models (LLMs), and
the role of sensor fusion in end-to-end autonomous driving, highlighting its
potential to enhance system adaptability and robustness. Our work offers
valuable insights into current methods and future directions for multi-sensor
fusion in autonomous driving.

</details>


### [151] [DIVE: Deep-search Iterative Video Exploration A Technical Report for the CVRR Challenge at CVPR 2025](https://arxiv.org/abs/2506.21891)
*Umihiro Kamoto,Tatsuya Ishibashi,Noriyuki Kugo*

Main category: cs.CV

TL;DR: DIVE方法在2025年复杂视频推理与鲁棒性评估挑战赛中夺冠，通过迭代推理框架在CVRR-ES基准上达到81.44%的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决复杂视频问答任务，提升对多样化视频内容的自然语言回答准确性。

Method: 采用DIVE（深度搜索迭代视频探索）方法，通过语义分解和逐步推理实现渐进推断。

Result: 在CVRR-ES基准测试集上达到81.44%的准确率，排名第一。

Conclusion: 迭代推理框架在复杂视频问答任务中表现出色，代码已开源。

Abstract: In this report, we present the winning solution that achieved the 1st place
in the Complex Video Reasoning & Robustness Evaluation Challenge 2025. This
challenge evaluates the ability to generate accurate natural language answers
to questions about diverse, real-world video clips. It uses the Complex Video
Reasoning and Robustness Evaluation Suite (CVRR-ES) benchmark, which consists
of 214 unique videos and 2,400 question-answer pairs spanning 11 categories.
Our method, DIVE (Deep-search Iterative Video Exploration), adopts an iterative
reasoning approach, in which each input question is semantically decomposed and
solved through stepwise reasoning and progressive inference. This enables our
system to provide highly accurate and contextually appropriate answers to even
the most complex queries. Applied to the CVRR-ES benchmark, our approach
achieves 81.44% accuracy on the test set, securing the top position among all
participants. This report details our methodology and provides a comprehensive
analysis of the experimental results, demonstrating the effectiveness of our
iterative reasoning framework in achieving robust video question answering. The
code is available at https://github.com/PanasonicConnect/DIVE

</details>


### [152] [SODA: Out-of-Distribution Detection in Domain-Shifted Point Clouds via Neighborhood Propagation](https://arxiv.org/abs/2506.21892)
*Adam Goodge,Xun Xu,Bryan Hooi,Wee Siong Ng,Jingyi Liao,Yongyi Su,Xulei Yang*

Main category: cs.CV

TL;DR: 论文提出SODA方法，通过基于邻域的分数传播方案改进点云数据的OOD检测，无需额外训练，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着点云数据应用增多，检测OOD点云对象对模型安全性和可靠性至关重要，但现有研究对此问题探索不足。

Method: 利用3D视觉语言模型（3D VLMs）进行OOD检测，提出SODA方法，通过邻域分数传播解决合成数据与真实数据的域偏移问题。

Result: SODA在无需额外训练的情况下，在多种数据集和问题设置中实现了最先进的性能。

Conclusion: SODA方法有效解决了合成到真实数据域偏移对3D VLM性能的影响，提升了OOD点云检测能力。

Abstract: As point cloud data increases in prevalence in a variety of applications, the
ability to detect out-of-distribution (OOD) point cloud objects becomes
critical for ensuring model safety and reliability. However, this problem
remains under-explored in existing research. Inspired by success in the image
domain, we propose to exploit advances in 3D vision-language models (3D VLMs)
for OOD detection in point cloud objects. However, a major challenge is that
point cloud datasets used to pre-train 3D VLMs are drastically smaller in size
and object diversity than their image-based counterparts. Critically, they
often contain exclusively computer-designed synthetic objects. This leads to a
substantial domain shift when the model is transferred to practical tasks
involving real objects scanned from the physical environment. In this paper,
our empirical experiments show that synthetic-to-real domain shift
significantly degrades the alignment of point cloud with their associated text
embeddings in the 3D VLM latent space, hindering downstream performance. To
address this, we propose a novel methodology called SODA which improves the
detection of OOD point clouds through a neighborhood-based score propagation
scheme. SODA is inference-based, requires no additional model training, and
achieves state-of-the-art performance over existing approaches across datasets
and problem settings.

</details>


### [153] [Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning](https://arxiv.org/abs/2506.21895)
*Fangling Jiang,Qi Li,Weining Wang,Gang Wang,Bing Liu,Zhenan Sun*

Main category: cs.CV

TL;DR: 提出了一种基于强化微调的面部反欺骗方法，利用多模态大语言模型的能力，通过设计奖励机制和优化策略，提升模型的泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有面部反欺骗方法容易过拟合训练数据，泛化能力差且缺乏可解释性。

Method: 设计了可验证的类别一致奖励和推理一致奖励，采用GRPO优化策略，通过迭代学习提炼泛化决策规则。

Result: 实验表明，该方法在跨域泛化性能上达到最优，能有效应对未知攻击类型并提供可解释的决策。

Conclusion: 该方法显著提升了面部反欺骗的泛化能力和可解释性，无需大量人工标注。

Abstract: Recently the emergence of novel presentation attacks has drawn increasing
attention to face anti-spoofing. However, existing methods tend to memorize
data patterns from the training set, resulting in poor generalization to
unknown attack types across different scenarios and limited interpretability.
To address these challenges, this paper presents a reinforcement
fine-tuning-based face anti-spoofing method that stimulates the capabilities of
multimodal large language models to think and learn how to solve the
anti-spoofing task itself, rather than relying on the memorization of
authenticity patterns. We design verifiable class consistent reward and
reasoning consistent reward, and employ a GRPO-based optimization strategy to
guide the model in exploring reasoning policies from multiple perspectives to
maximize expected rewards. As a result, through iterative trial-and-error
learning while retaining only high-reward trajectories, the model distills
highly generalizable decision-making rules from the extensive solution space to
effectively address cross-domain face anti-spoofing tasks. Extensive
experimental results demonstrate that our method achieves state-of-the-art
cross-domain generalization performance. It generalizes well to diverse unknown
attack types in unseen target domains while providing interpretable reasoning
for its authenticity decisions without requiring labor-intensive textual
annotations for training.

</details>


### [154] [Visual Content Detection in Educational Videos with Transfer Learning and Dataset Enrichment](https://arxiv.org/abs/2506.21903)
*Dipayan Biswas,Shishir Shah,Jaspal Subhlok*

Main category: cs.CV

TL;DR: 论文提出了一种基于迁移学习的方法，用于检测讲座视频中的视觉元素，优化了YOLO模型，并发布了标注数据集和源代码。


<details>
  <summary>Details</summary>
Motivation: 讲座视频中的视觉元素（如图表、表格）对理解和检索至关重要，但自动检测这些元素存在挑战，缺乏标准结构和标注数据集。

Method: 采用迁移学习方法，评估了多种目标检测模型，优化YOLO模型，并使用半监督自动标注策略。

Result: YOLO模型表现最佳，优化后成功检测讲座视频中的视觉元素，并发布了标注数据集和源代码。

Conclusion: 该方法为讲座视频中的目标检测提供了通用解决方案，促进了未来研究。

Abstract: Video is transforming education with online courses and recorded lectures
supplementing and replacing classroom teaching. Recent research has focused on
enhancing information retrieval for video lectures with advanced navigation,
searchability, summarization, as well as question answering chatbots. Visual
elements like tables, charts, and illustrations are central to comprehension,
retention, and data presentation in lecture videos, yet their full potential
for improving access to video content remains underutilized. A major factor is
that accurate automatic detection of visual elements in a lecture video is
challenging; reasons include i) most visual elements, such as charts, graphs,
tables, and illustrations, are artificially created and lack any standard
structure, and ii) coherent visual objects may lack clear boundaries and may be
composed of connected text and visual components. Despite advancements in deep
learning based object detection, current models do not yield satisfactory
performance due to the unique nature of visual content in lectures and scarcity
of annotated datasets. This paper reports on a transfer learning approach for
detecting visual elements in lecture video frames. A suite of state of the art
object detection models were evaluated for their performance on lecture video
datasets. YOLO emerged as the most promising model for this task. Subsequently
YOLO was optimized for lecture video object detection with training on multiple
benchmark datasets and deploying a semi-supervised auto labeling strategy.
Results evaluate the success of this approach, also in developing a general
solution to the problem of object detection in lecture videos. Paper
contributions include a publicly released benchmark of annotated lecture video
frames, along with the source code to facilitate future research.

</details>


### [155] [RAUM-Net: Regional Attention and Uncertainty-aware Mamba Network](https://arxiv.org/abs/2506.21905)
*Mingquan Liu*

Main category: cs.CV

TL;DR: 提出了一种结合Mamba特征建模、区域注意力和贝叶斯不确定性的半监督方法，用于细粒度视觉分类（FGVC），在标记数据稀缺时表现优异。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类因类间差异细微和特征表示脆弱而具有挑战性，现有方法在标记数据稀缺时表现不佳。

Method: 结合Mamba特征建模、区域注意力和贝叶斯不确定性，增强局部到全局特征建模，并选择高质量伪标签。

Result: 在FGVC基准测试中表现优异，尤其在标记数据有限时具有鲁棒性。

Conclusion: 该方法在标记数据稀缺时提升了FGVC的性能，代码已开源。

Abstract: Fine Grained Visual Categorization (FGVC) remains a challenging task in
computer vision due to subtle inter class differences and fragile feature
representations. Existing methods struggle in fine grained scenarios,
especially when labeled data is scarce. We propose a semi supervised method
combining Mamba based feature modeling, region attention, and Bayesian
uncertainty. Our approach enhances local to global feature modeling while
focusing on key areas during learning. Bayesian inference selects high quality
pseudo labels for stability. Experiments show strong performance on FGVC
benchmarks with occlusions, demonstrating robustness when labeled data is
limited. Code is available at https://github.com/wxqnl/RAUM Net.

</details>


### [156] [CERBERUS: Crack Evaluation & Recognition Benchmark for Engineering Reliability & Urban Stability](https://arxiv.org/abs/2506.21909)
*Justin Reinman,Sunwoong Choi*

Main category: cs.CV

TL;DR: CERBERUS是一个合成基准，用于训练和评估AI模型检测基础设施中的裂缝和其他缺陷。它包括裂缝图像生成器和基于Unity的真实3D检查场景。测试表明，结合合成和真实数据可提升模型在真实图像上的性能。


<details>
  <summary>Details</summary>
Motivation: 为自动化基础设施检查提供灵活、可重复的测试方法，支持未来研究。

Method: 使用CERBERUS基准，结合合成和真实裂缝数据测试YOLO模型。

Result: 结合合成和真实数据能提高模型在真实图像上的检测性能。

Conclusion: CERBERUS为缺陷检测系统提供了有效的测试工具，并支持进一步研究。

Abstract: CERBERUS is a synthetic benchmark designed to help train and evaluate AI
models for detecting cracks and other defects in infrastructure. It includes a
crack image generator and realistic 3D inspection scenarios built in Unity. The
benchmark features two types of setups: a simple Fly-By wall inspection and a
more complex Underpass scene with lighting and geometry challenges. We tested a
popular object detection model (YOLO) using different combinations of synthetic
and real crack data. Results show that combining synthetic and real data
improves performance on real-world images. CERBERUS provides a flexible,
repeatable way to test defect detection systems and supports future research in
automated infrastructure inspection. CERBERUS is publicly available at
https://github.com/justinreinman/Cerberus-Defect-Generator.

</details>


### [157] [Generating Attribute-Aware Human Motions from Textual Prompt](https://arxiv.org/abs/2506.21912)
*Xinghan Wang,Kun Xu,Fei Li,Cao Sheng,Jiazhong Yu,Yadong Mu*

Main category: cs.CV

TL;DR: 本文提出了一种基于文本和人体属性的动作生成框架，解决了现有方法忽略人体属性影响的问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动的人体动作生成方法忽视了人体属性（如年龄、性别、体重和身高）对动作模式的影响，本文旨在填补这一空白。

Method: 提出了一种受结构因果模型启发的框架，将动作语义与人体属性解耦，实现文本到语义的预测和属性控制的生成。

Result: 模型能够生成符合用户文本和属性输入的逼真动作，并通过新数据集HumanAttr验证了其有效性。

Conclusion: 本文为属性感知的文本到动作生成设定了首个基准，实验证明了模型的有效性。

Abstract: Text-driven human motion generation has recently attracted considerable
attention, allowing models to generate human motions based on textual
descriptions. However, current methods neglect the influence of human
attributes (such as age, gender, weight, and height) which are key factors
shaping human motion patterns. This work represents a pilot exploration for
bridging this gap. We conceptualize each motion as comprising both attribute
information and action semantics, where textual descriptions align exclusively
with action semantics. To achieve this, a new framework inspired by Structural
Causal Models is proposed to decouple action semantics from human attributes,
enabling text-to-semantics prediction and attribute-controlled generation. The
resulting model is capable of generating realistic, attribute-aware motion
aligned with the user's text and attribute inputs. For evaluation, we introduce
HumanAttr, a comprehensive dataset containing attribute annotations for
text-motion pairs, setting the first benchmark for attribute-aware
text-to-motion generation. Extensive experiments on the new dataset validate
our model's effectiveness.

</details>


### [158] [SepFormer: Coarse-to-fine Separator Regression Network for Table Structure Recognition](https://arxiv.org/abs/2506.21920)
*Nam Quan Nguyen,Xuan Phong Pham,Tuan-Anh Tran*

Main category: cs.CV

TL;DR: SepFormer是一种基于DETR架构的表格结构识别方法，通过单步分隔符回归实现快速且鲁棒的表格重构。


<details>
  <summary>Details</summary>
Motivation: 表格结构识别（TSR）是语义数据提取的基础，但现有方法需要改进速度和鲁棒性。

Method: SepFormer采用粗到细的方法，通过两个Transformer解码器堆叠预测分隔符，包括单线到线带分隔符的逐步细化。

Result: SepFormer在多个基准数据集（如SciTSR、PubTabNet等）上达到25.6 FPS的速度，性能与最先进方法相当。

Conclusion: SepFormer通过单步分隔符回归和粗到细方法，显著提升了表格结构识别的速度和鲁棒性。

Abstract: The automated reconstruction of the logical arrangement of tables from image
data, termed Table Structure Recognition (TSR), is fundamental for semantic
data extraction. Recently, researchers have explored a wide range of techniques
to tackle this problem, demonstrating significant progress. Each table is a set
of vertical and horizontal separators. Following this realization, we present
SepFormer, which integrates the split-and-merge paradigm into a single step
through separator regression with a DETR-style architecture, improving speed
and robustness. SepFormer is a coarse-to-fine approach that predicts table
separators from single-line to line-strip separators with a stack of two
transformer decoders. In the coarse-grained stage, the model learns to
gradually refine single-line segments through decoder layers with additional
angle loss. At the end of the fine-grained stage, the model predicts line-strip
separators by refining sampled points from each single-line segment. Our
SepFormer can run on average at 25.6 FPS while achieving comparable performance
with state-of-the-art methods on several benchmark datasets, including SciTSR,
PubTabNet, WTW, and iFLYTAB.

</details>


### [159] [ZeroReg3D: A Zero-shot Registration Pipeline for 3D Consecutive Histopathology Image Reconstruction](https://arxiv.org/abs/2506.21923)
*Juming Xiong,Ruining Deng,Jialin Yue,Siqi Lu,Junlin Guo,Marilyn Lionts,Tianyuan Yao,Can Cui,Junchao Zhu,Chongyu Qu,Mengmeng Yin,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: ZeroReg3D是一种新型零样本配准方法，用于从连续组织切片中构建精确的3D模型，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有2D组织学分析方法难以保留3D空间关系，且深度学习方法泛化性差，非深度学习方法精度不足。

Method: 结合零样本深度学习关键点匹配与基于优化的仿射和非刚性配准技术。

Result: 有效解决了组织变形、切片伪影、染色变异和光照不一致等问题，无需重新训练或微调。

Conclusion: ZeroReg3D为3D组织学重建提供了一种高效且通用的解决方案。

Abstract: Histological analysis plays a crucial role in understanding tissue structure
and pathology. While recent advancements in registration methods have improved
2D histological analysis, they often struggle to preserve critical 3D spatial
relationships, limiting their utility in both clinical and research
applications. Specifically, constructing accurate 3D models from 2D slices
remains challenging due to tissue deformation, sectioning artifacts,
variability in imaging techniques, and inconsistent illumination. Deep
learning-based registration methods have demonstrated improved performance but
suffer from limited generalizability and require large-scale training data. In
contrast, non-deep-learning approaches offer better generalizability but often
compromise on accuracy. In this study, we introduced ZeroReg3D, a novel
zero-shot registration pipeline tailored for accurate 3D reconstruction from
serial histological sections. By combining zero-shot deep learning-based
keypoint matching with optimization-based affine and non-rigid registration
techniques, ZeroReg3D effectively addresses critical challenges such as tissue
deformation, sectioning artifacts, staining variability, and inconsistent
illumination without requiring retraining or fine-tuning. The code has been
made publicly available at https://github.com/hrlblab/ZeroReg3D

</details>


### [160] [SPAZER: Spatial-Semantic Progressive Reasoning Agent for Zero-shot 3D Visual Grounding](https://arxiv.org/abs/2506.21924)
*Zhao Jin,Rong-Cheng Tu,Jingyi Liao,Wenhao Sun,Xiao Luo,Shunyu Liu,Dacheng Tao*

Main category: cs.CV

TL;DR: SPAZER是一种结合3D和2D模态的零样本3D视觉定位方法，通过渐进式推理框架显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在3D视觉定位中过度依赖3D训练数据或仅侧重空间或语义理解的局限性。

Method: SPAZER先分析场景生成3D渲染，筛选候选对象，再结合2D图像进行3D-2D联合决策。

Result: 在ScanRefer和Nr3D基准测试中，准确率分别提升9.0%和10.9%。

Conclusion: SPAZER通过结合空间和语义推理，无需3D标注数据即可实现鲁棒的零样本定位。

Abstract: 3D Visual Grounding (3DVG) aims to localize target objects within a 3D scene
based on natural language queries. To alleviate the reliance on costly 3D
training data, recent studies have explored zero-shot 3DVG by leveraging the
extensive knowledge and powerful reasoning capabilities of pre-trained LLMs and
VLMs. However, existing paradigms tend to emphasize either spatial (3D-based)
or semantic (2D-based) understanding, limiting their effectiveness in complex
real-world applications. In this work, we introduce SPAZER - a VLM-driven agent
that combines both modalities in a progressive reasoning framework. It first
holistically analyzes the scene and produces a 3D rendering from the optimal
viewpoint. Based on this, anchor-guided candidate screening is conducted to
perform a coarse-level localization of potential objects. Furthermore,
leveraging retrieved relevant 2D camera images, 3D-2D joint decision-making is
efficiently performed to determine the best-matching object. By bridging
spatial and semantic reasoning neural streams, SPAZER achieves robust zero-shot
grounding without training on 3D-labeled data. Extensive experiments on
ScanRefer and Nr3D benchmarks demonstrate that SPAZER significantly outperforms
previous state-of-the-art zero-shot methods, achieving notable gains of 9.0%
and 10.9% in accuracy.

</details>


### [161] [Quality Assessment and Distortion-aware Saliency Prediction for AI-Generated Omnidirectional Images](https://arxiv.org/abs/2506.21925)
*Liu Yang,Huiyu Duan,Jiarui Wang,Jing Liu,Menghan Hu,Xiongkuo Min,Guangtao Zhai,Patrick Le Callet*

Main category: cs.CV

TL;DR: 该论文研究了AI生成的全景图像（AIGODIs）的质量评估和优化问题，提出了一个包含主观评分和失真显著区域的数据库OHF2024，并基于BLIP-2模型开发了两个模型（BLIP2OIQA和BLIP2OISal）用于质量评估和显著区域预测，最终实现了自动优化过程。


<details>
  <summary>Details</summary>
Motivation: 随着AIGC技术的发展，AI生成的全景图像在VR/AR应用中潜力巨大，但其质量评估和优化研究仍不足。

Method: 建立了OHF2024数据库，包含主观评分和失真显著区域；基于BLIP-2模型开发了BLIP2OIQA和BLIP2OISal模型；提出了自动优化过程。

Result: BLIP2OIQA和BLIP2OISal在质量评估和显著区域预测任务中达到SOTA效果，并成功用于优化过程。

Conclusion: 该研究为AIGODIs的质量评估和优化提供了有效工具，数据库和代码将开源以促进未来研究。

Abstract: With the rapid advancement of Artificial Intelligence Generated Content
(AIGC) techniques, AI generated images (AIGIs) have attracted widespread
attention, among which AI generated omnidirectional images (AIGODIs) hold
significant potential for Virtual Reality (VR) and Augmented Reality (AR)
applications. AI generated omnidirectional images exhibit unique quality
issues, however, research on the quality assessment and optimization of
AI-generated omnidirectional images is still lacking. To this end, this work
first studies the quality assessment and distortion-aware saliency prediction
problems for AIGODIs, and further presents a corresponding optimization
process. Specifically, we first establish a comprehensive database to reflect
human feedback for AI-generated omnidirectionals, termed OHF2024, which
includes both subjective quality ratings evaluated from three perspectives and
distortion-aware salient regions. Based on the constructed OHF2024 database, we
propose two models with shared encoders based on the BLIP-2 model to evaluate
the human visual experience and predict distortion-aware saliency for
AI-generated omnidirectional images, which are named as BLIP2OIQA and
BLIP2OISal, respectively. Finally, based on the proposed models, we present an
automatic optimization process that utilizes the predicted visual experience
scores and distortion regions to further enhance the visual quality of an
AI-generated omnidirectional image. Extensive experiments show that our
BLIP2OIQA model and BLIP2OISal model achieve state-of-the-art (SOTA) results in
the human visual experience evaluation task and the distortion-aware saliency
prediction task for AI generated omnidirectional images, and can be effectively
used in the optimization process. The database and codes will be released on
https://github.com/IntMeGroup/AIGCOIQA to facilitate future research.

</details>


### [162] [SDRNET: Stacked Deep Residual Network for Accurate Semantic Segmentation of Fine-Resolution Remotely Sensed Images](https://arxiv.org/abs/2506.21945)
*Naftaly Wambugu,Ruisheng Wang,Bo Guo,Tianshu Yu,Sheng Xu,Mohammed Elhassan*

Main category: cs.CV

TL;DR: 论文提出了一种堆叠深度残差网络（SDRNet），用于高分辨率遥感图像的语义分割，解决了类间差异、遮挡和物体尺寸变化等问题。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像（FRRS）的语义分割面临类间差异、遮挡和物体尺寸变化的挑战，现有深度卷积神经网络（DCNNs）难以提取足够特征。

Method: 采用两个堆叠的编码器-解码器网络和扩张残差块（DRB），以捕获长距离语义并保留空间信息。

Result: 在ISPRS Vaihingen和Potsdam数据集上的实验表明，SDRNet性能优于当前DCNNs。

Conclusion: SDRNet能有效解决FRRS图像语义分割的挑战，具有竞争力。

Abstract: Land cover maps generated from semantic segmentation of high-resolution
remotely sensed images have drawn mucon in the photogrammetry and remote
sensing research community. Currently, massive fine-resolution remotely sensed
(FRRS) images acquired by improving sensing and imaging technologies become
available. However, accurate semantic segmentation of such FRRS images is
greatly affected by substantial class disparities, the invisibility of key
ground objects due to occlusion, and object size variation. Despite the
extraordinary potential in deep convolutional neural networks (DCNNs) in image
feature learning and representation, extracting sufficient features from FRRS
images for accurate semantic segmentation is still challenging. These
challenges demand the deep learning models to learn robust features and
generate sufficient feature descriptors. Specifically, learning
multi-contextual features to guarantee adequate coverage of varied object sizes
from the ground scene and harnessing global-local contexts to overcome class
disparities challenge even profound networks. Deeper networks significantly
lose spatial details due to gradual downsampling processes resulting in poor
segmentation results and coarse boundaries. This article presents a stacked
deep residual network (SDRNet) for semantic segmentation from FRRS images. The
proposed framework utilizes two stacked encoder-decoder networks to harness
long-range semantics yet preserve spatial information and dilated residual
blocks (DRB) between each encoder and decoder network to capture sufficient
global dependencies thus improving segmentation performance. Our experimental
results obtained using the ISPRS Vaihingen and Potsdam datasets demonstrate
that the SDRNet performs effectively and competitively against current DCNNs in
semantic segmentation.

</details>


### [163] [Exploring Semantic Masked Autoencoder for Self-supervised Point Cloud Understanding](https://arxiv.org/abs/2506.21957)
*Yixin Zha,Chuxin Wang,Wenfei Yang,Tianzhu Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于语义掩码自编码器的方法，通过原型语义建模和增强掩码策略，解决了随机掩码策略在点云理解中的语义关系捕捉不足问题。


<details>
  <summary>Details</summary>
Motivation: 随机掩码策略在点云预训练中难以捕捉合理的语义关系，限制了自监督模型的性能。

Method: 设计了原型语义建模模块和增强掩码策略，结合语义引导机制和提示调优策略。

Result: 在ScanObjectNN、ModelNet40和ShapeNetPart等数据集上验证了方法的有效性。

Conclusion: 提出的方法显著提升了点云理解任务中的语义关系捕捉能力。

Abstract: Point cloud understanding aims to acquire robust and general feature
representations from unlabeled data. Masked point modeling-based methods have
recently shown significant performance across various downstream tasks. These
pre-training methods rely on random masking strategies to establish the
perception of point clouds by restoring corrupted point cloud inputs, which
leads to the failure of capturing reasonable semantic relationships by the
self-supervised models. To address this issue, we propose Semantic Masked
Autoencoder, which comprises two main components: a prototype-based component
semantic modeling module and a component semantic-enhanced masking strategy.
Specifically, in the component semantic modeling module, we design a component
semantic guidance mechanism to direct a set of learnable prototypes in
capturing the semantics of different components from objects. Leveraging these
prototypes, we develop a component semantic-enhanced masking strategy that
addresses the limitations of random masking in effectively covering complete
component structures. Furthermore, we introduce a component semantic-enhanced
prompt-tuning strategy, which further leverages these prototypes to improve the
performance of pre-trained models in downstream tasks. Extensive experiments
conducted on datasets such as ScanObjectNN, ModelNet40, and ShapeNetPart
demonstrate the effectiveness of our proposed modules.

</details>


### [164] [TASeg: Text-aware RGB-T Semantic Segmentation based on Fine-tuning Vision Foundation Models](https://arxiv.org/abs/2506.21975)
*Meng Yu,Te Cui,Qitong Chu,Wenjie Song,Yi Yang,Yufeng Yue*

Main category: cs.CV

TL;DR: 提出TASeg框架，通过LoRA微调技术和动态特征融合模块（DFFM）改进RGB-T语义分割，结合CLIP文本嵌入提升语义理解准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-T分割模型依赖低层视觉特征，缺乏高层文本信息，导致类别相似时分割不准确；SAM在多模态融合和计算效率上存在不足。

Method: 使用LoRA微调技术适配视觉基础模型，提出DFFM融合多模态视觉特征，结合CLIP文本嵌入实现语义对齐。

Result: 在多样化数据集上表现优异，挑战性场景中性能更优且参数更少。

Conclusion: TASeg通过文本感知和多模态特征融合，显著提升了RGB-T语义分割的准确性和效率。

Abstract: Reliable semantic segmentation of open environments is essential for
intelligent systems, yet significant problems remain: 1) Existing RGB-T
semantic segmentation models mainly rely on low-level visual features and lack
high-level textual information, which struggle with accurate segmentation when
categories share similar visual characteristics. 2) While SAM excels in
instance-level segmentation, integrating it with thermal images and text is
hindered by modality heterogeneity and computational inefficiency. To address
these, we propose TASeg, a text-aware RGB-T segmentation framework by using
Low-Rank Adaptation (LoRA) fine-tuning technology to adapt vision foundation
models. Specifically, we propose a Dynamic Feature Fusion Module (DFFM) in the
image encoder, which effectively merges features from multiple visual
modalities while freezing SAM's original transformer blocks. Additionally, we
incorporate CLIP-generated text embeddings in the mask decoder to enable
semantic alignment, which further rectifies the classification error and
improves the semantic understanding accuracy. Experimental results across
diverse datasets demonstrate that our method achieves superior performance in
challenging scenarios with fewer trainable parameters.

</details>


### [165] [R1-Track: Direct Application of MLLMs to Visual Object Tracking via Reinforcement Learning](https://arxiv.org/abs/2506.21980)
*Biao Wang,Wenwen Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态大语言模型（MLLMs）的视觉单目标跟踪方法R1-Track，通过GRPO强化学习微调Qwen2.5-VL，在GOT-10k基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统跟踪方法依赖大规模监督训练且缺乏灵活性，而MLLMs在基础任务中表现优异，但直接应用于跟踪任务效果不佳，因此需要改进。

Method: 使用GRPO强化学习方法在小规模数据集上微调Qwen2.5-VL，生成模型R1-Track。

Result: R1-Track在GOT-10k基准测试中表现突出，支持通过边界框或文本描述灵活初始化。

Conclusion: R1-Track展示了MLLMs在视觉跟踪任务中的潜力，并提出了进一步改进的方向。

Abstract: Visual single object tracking aims to continuously localize and estimate the
scale of a target in subsequent video frames, given only its initial state in
the first frame. This task has traditionally been framed as a template matching
problem, evolving through major phases including correlation filters,
two-stream networks, and one-stream networks with significant progress
achieved. However, these methods typically require explicit classification and
regression modeling, depend on supervised training with large-scale datasets,
and are limited to the single task of tracking, lacking flexibility. In recent
years, multi-modal large language models (MLLMs) have advanced rapidly.
Open-source models like Qwen2.5-VL, a flagship MLLMs with strong foundational
capabilities, demonstrate excellent performance in grounding tasks. This has
spurred interest in applying such models directly to visual tracking. However,
experiments reveal that Qwen2.5-VL struggles with template matching between
image pairs (i.e., tracking tasks). Inspired by deepseek-R1, we fine-tuned
Qwen2.5-VL using the group relative policy optimization (GRPO) reinforcement
learning method on a small-scale dataset with a rule-based reward function. The
resulting model, R1-Track, achieved notable performance on the GOT-10k
benchmark. R1-Track supports flexible initialization via bounding boxes or text
descriptions while retaining most of the original model's general capabilities.
And we further discuss potential improvements for R1-Track. This rough
technical report summarizes our findings as of May 2025.

</details>


### [166] [RoboEnvision: A Long-Horizon Video Generation Model for Multi-Task Robot Manipulation](https://arxiv.org/abs/2506.22007)
*Liudi Yang,Yang Bai,George Eskandar,Fengyi Shen,Mohammad Altillawi,Dong Chen,Soumajit Majumder,Ziyuan Liu,Gitta Kutyniok,Abhinav Valada*

Main category: cs.CV

TL;DR: 提出了一种新方法，通过分解任务和关键帧生成，避免自回归生成，提升长时程视频生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到视频扩散模型在长时程机器人任务中因自回归生成导致的误差累积问题。

Method: 1) 分解高层目标为原子任务并生成关键帧；2) 使用语义保持注意力模块维持一致性；3) 设计轻量级策略模型从视频回归机器人关节状态。

Result: 在两个基准测试中取得视频质量和一致性的最佳结果，并在长时程任务中优于现有策略模型。

Conclusion: 新方法有效解决了长时程视频生成的误差累积问题，显著提升了性能。

Abstract: We address the problem of generating long-horizon videos for robotic
manipulation tasks. Text-to-video diffusion models have made significant
progress in photorealism, language understanding, and motion generation but
struggle with long-horizon robotic tasks. Recent works use video diffusion
models for high-quality simulation data and predictive rollouts in robot
planning. However, these works predict short sequences of the robot achieving
one task and employ an autoregressive paradigm to extend to the long horizon,
leading to error accumulations in the generated video and in the execution. To
overcome these limitations, we propose a novel pipeline that bypasses the need
for autoregressive generation. We achieve this through a threefold
contribution: 1) we first decompose the high-level goals into smaller atomic
tasks and generate keyframes aligned with these instructions. A second
diffusion model then interpolates between each of the two generated frames,
achieving the long-horizon video. 2) We propose a semantics preserving
attention module to maintain consistency between the keyframes. 3) We design a
lightweight policy model to regress the robot joint states from generated
videos. Our approach achieves state-of-the-art results on two benchmarks in
video quality and consistency while outperforming previous policy models on
long-horizon tasks.

</details>


### [167] [Towards Universal & Efficient Model Compression via Exponential Torque Pruning](https://arxiv.org/abs/2506.22015)
*Sarthak Ketanbhai Modi,Lim Zi Pong,Shourya Kuchhal,Yoshi Cao,Yupeng Cheng,Teo Yon Shin,Lin Shang-Wei,Zhiming Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为指数扭矩剪枝（ETP）的新方法，通过指数力应用方案改进神经网络剪枝效果，显著提高压缩率且几乎不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络（DNNs）的复杂性和规模快速增长，导致计算成本和内存使用问题突出，亟需高效的模型压缩技术。现有方法（如扭矩启发式正则化）的剪枝效果不理想，网络仍较密集且准确性下降明显。

Method: 作者提出ETP方法，采用指数力应用方案进行正则化，有效剪除冗余和远距离模块，同时保留必要模块。

Result: 实验结果表明，ETP在多个领域显著优于现有剪枝策略，压缩率更高且准确性损失可忽略。

Conclusion: ETP是一种简单高效的剪枝方法，解决了现有技术的不足，为模型压缩提供了新思路。

Abstract: The rapid growth in complexity and size of modern deep neural networks (DNNs)
has increased challenges related to computational costs and memory usage,
spurring a growing interest in efficient model compression techniques. Previous
state-of-the-art approach proposes using a Torque-inspired regularization which
forces the weights of neural modules around a selected pivot point. Whereas, we
observe that the pruning effect of this approach is far from perfect, as the
post-trained network is still dense and also suffers from high accuracy drop.
In this work, we attribute such ineffectiveness to the default linear force
application scheme, which imposes inappropriate force on neural module of
different distances. To efficiently prune the redundant and distant modules
while retaining those that are close and necessary for effective inference, in
this work, we propose Exponential Torque Pruning (ETP), which adopts an
exponential force application scheme for regularization. Experimental results
on a broad range of domains demonstrate that, though being extremely simple,
ETP manages to achieve significantly higher compression rate than the previous
state-of-the-art pruning strategies with negligible accuracy drop.

</details>


### [168] [Advancing Facial Stylization through Semantic Preservation Constraint and Pseudo-Paired Supervision](https://arxiv.org/abs/2506.22022)
*Zhanyi Lu,Yue Zhou*

Main category: cs.CV

TL;DR: 提出了一种结合语义保留约束和伪配对监督的面部风格化方法，解决了生成结果中的伪影和内容不一致问题，并实现了多模态和参考引导的风格化。


<details>
  <summary>Details</summary>
Motivation: 现有StyleGAN方法在面部风格化中存在伪影和内容保真度不足的问题，主要原因是忽略了生成器在风格化过程中的语义偏移。

Method: 提出语义保留约束和伪配对监督，构建多级伪配对数据集，实现监督约束，并支持多模态和参考引导风格化。

Result: 实验结果表明，该方法生成的面部风格化结果具有高保真度和美观性，优于现有方法。

Conclusion: 该方法通过语义保留和伪配对监督，显著提升了面部风格化的质量和灵活性。

Abstract: Facial stylization aims to transform facial images into appealing,
high-quality stylized portraits, with the critical challenge of accurately
learning the target style while maintaining content consistency with the
original image. Although previous StyleGAN-based methods have made significant
advancements, the generated results still suffer from artifacts or insufficient
fidelity to the source image. We argue that these issues stem from neglecting
semantic shift of the generator during stylization. Therefore, we propose a
facial stylization method that integrates semantic preservation constraint and
pseudo-paired supervision to enhance the content correspondence and improve the
stylization effect. Additionally, we develop a methodology for creating
multi-level pseudo-paired datasets to implement supervisory constraint.
Furthermore, building upon our facial stylization framework, we achieve more
flexible multimodal and reference-guided stylization without complex network
architecture designs or additional training. Experimental results demonstrate
that our approach produces high-fidelity, aesthetically pleasing facial style
transfer that surpasses previous methods.

</details>


### [169] [Cross-modal Ship Re-Identification via Optical and SAR Imagery: A Novel Dataset and Method](https://arxiv.org/abs/2506.22027)
*Han Wang,Shengyang Li,Jian Yang,Yuxuan Liu,Yixuan Lv,Zhuang Zhou*

Main category: cs.CV

TL;DR: 提出了一种结合光学和合成孔径雷达（SAR）的船舶再识别数据集（HOSS ReID），用于评估低地球轨道星座的船舶跟踪效果，并提出了基于Vision Transformer的基线方法TransOSS。


<details>
  <summary>Details</summary>
Motivation: 当前船舶跟踪方法依赖低分辨率的地球静止卫星或短时拍摄的视频卫星，无法满足全天候和长时间跟踪的需求。

Method: 构建HOSS ReID数据集，包含多模态卫星在不同时间和角度拍摄的船舶图像；提出TransOSS方法，改进Vision Transformer以适应跨模态任务，并采用对比学习预训练。

Result: HOSS ReID数据集支持全天候船舶跟踪，TransOSS方法能够提取模态不变特征。

Conclusion: HOSS ReID数据集和TransOSS方法为船舶跟踪提供了新的解决方案，支持更短的重访周期和全天候能力。

Abstract: Detecting and tracking ground objects using earth observation imagery remains
a significant challenge in the field of remote sensing. Continuous maritime
ship tracking is crucial for applications such as maritime search and rescue,
law enforcement, and shipping analysis. However, most current ship tracking
methods rely on geostationary satellites or video satellites. The former offer
low resolution and are susceptible to weather conditions, while the latter have
short filming durations and limited coverage areas, making them less suitable
for the real-world requirements of ship tracking. To address these limitations,
we present the Hybrid Optical and Synthetic Aperture Radar (SAR) Ship
Re-Identification Dataset (HOSS ReID dataset), designed to evaluate the
effectiveness of ship tracking using low-Earth orbit constellations of optical
and SAR sensors. This approach ensures shorter re-imaging cycles and enables
all-weather tracking. HOSS ReID dataset includes images of the same ship
captured over extended periods under diverse conditions, using different
satellites of different modalities at varying times and angles. Furthermore, we
propose a baseline method for cross-modal ship re-identification, TransOSS,
which is built on the Vision Transformer architecture. It refines the patch
embedding structure to better accommodate cross-modal tasks, incorporates
additional embeddings to introduce more reference information, and employs
contrastive learning to pre-train on large-scale optical-SAR image pairs,
ensuring the model's ability to extract modality-invariant features. Our
dataset and baseline method are publicly available on
https://github.com/Alioth2000/Hoss-ReID.

</details>


### [170] [Partial CLIP is Enough: Chimera-Seg for Zero-shot Semantic Segmentation](https://arxiv.org/abs/2506.22032)
*Jialei Chen,Xu Zheng,Danda Pani Paudel,Luc Van Gool,Hiroshi Murase,Daisuke Deguchi*

Main category: cs.CV

TL;DR: Chimera-Seg和SGD方法解决了零样本语义分割中的特征对齐和语义鸿沟问题，提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 零样本语义分割（ZSS）需要从已见类别的监督中分割未见类别，但现有方法在特征对齐和语义鸿沟方面存在挑战。

Method: 提出Chimera-Seg，结合分割主干和CLIP语义头，并设计SGD和SAM模块优化特征对齐。

Result: 在两个基准测试中，hIoU分别提升了0.9%和1.2%。

Conclusion: Chimera-Seg和SGD有效解决了ZSS中的关键问题，显著提升了性能。

Abstract: Zero-shot Semantic Segmentation (ZSS) aims to segment both seen and unseen
classes using supervision from only seen classes. Beyond adaptation-based
methods, distillation-based approaches transfer vision-language alignment of
vision-language model, e.g., CLIP, to segmentation models. However, such
knowledge transfer remains challenging due to: (1) the difficulty of aligning
vision-based features with the textual space, which requires combining spatial
precision with vision-language alignment; and (2) the semantic gap between
CLIP's global representations and the local, fine-grained features of
segmentation models. To address challenge (1), we propose Chimera-Seg, which
integrates a segmentation backbone as the body and a CLIP-based semantic head
as the head, like the Chimera in Greek mythology, combining spatial precision
with vision-language alignment. Specifically, Chimera-Seg comprises a trainable
segmentation model and a CLIP Semantic Head (CSH), which maps dense features
into the CLIP-aligned space. The CSH incorporates a frozen subnetwork and fixed
projection layers from the CLIP visual encoder, along with lightweight
trainable components. The partial module from CLIP visual encoder, paired with
the segmentation model, retains segmentation capability while easing the
mapping to CLIP's semantic space. To address challenge (2), we propose
Selective Global Distillation (SGD), which distills knowledge from dense
features exhibiting high similarity to the CLIP CLS token, while gradually
reducing the number of features used for alignment as training progresses.
Besides, we also use a Semantic Alignment Module (SAM) to further align dense
visual features with semantic embeddings extracted from the frozen CLIP text
encoder. Experiments on two benchmarks show improvements of 0.9% and 1.2% in
hIoU.

</details>


### [171] [Few-Shot Identity Adaptation for 3D Talking Heads via Global Gaussian Field](https://arxiv.org/abs/2506.22044)
*Hong Nie,Fuyuan Cao,Lu Chen,Fengxin Chen,Yuefeng Zou,Jun Yu*

Main category: cs.CV

TL;DR: FIAG是一种新型的3D说话头合成框架，通过共享的全局高斯场和通用运动场，实现了高效的身份特定适应，仅需少量训练数据即可完成。


<details>
  <summary>Details</summary>
Motivation: 现有基于重建和渲染的说话头合成方法依赖身份特定模型，计算成本高且扩展性差。

Method: FIAG结合全局高斯场（支持多身份共享表示）和通用运动场（捕捉跨身份运动动态），实现快速身份适应。

Result: 实验表明，FIAG在质量和通用性上优于现有方法。

Conclusion: FIAG通过共享结构和运动先验，显著提升了身份适应的效率和效果。

Abstract: Reconstruction and rendering-based talking head synthesis methods achieve
high-quality results with strong identity preservation but are limited by their
dependence on identity-specific models. Each new identity requires training
from scratch, incurring high computational costs and reduced scalability
compared to generative model-based approaches. To overcome this limitation, we
propose FIAG, a novel 3D speaking head synthesis framework that enables
efficient identity-specific adaptation using only a few training footage. FIAG
incorporates Global Gaussian Field, which supports the representation of
multiple identities within a shared field, and Universal Motion Field, which
captures the common motion dynamics across diverse identities. Benefiting from
the shared facial structure information encoded in the Global Gaussian Field
and the general motion priors learned in the motion field, our framework
enables rapid adaptation from canonical identity representations to specific
ones with minimal data. Extensive comparative and ablation experiments
demonstrate that our method outperforms existing state-of-the-art approaches,
validating both the effectiveness and generalizability of the proposed
framework. Code is available at: \textit{https://github.com/gme-hong/FIAG}.

</details>


### [172] [EnLVAM: Enhanced Left Ventricle Linear Measurements Utilizing Anatomical Motion Mode](https://arxiv.org/abs/2506.22063)
*Durgesh K. Singh,Ahcene Boubekki,Qing Cao,Svein Arne Aase,Robert Jenssen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 提出了一种通过强制直线约束提高左心室测量精度的新框架，结合解剖M模式图像和B模式视频，减少人工标注误差。


<details>
  <summary>Details</summary>
Motivation: 手动放置左心室标志点耗时且易出错，现有深度学习方法常导致标志点错位，影响测量精度。

Method: 训练标志点检测器于解剖M模式图像，实时从B模式视频计算并转换回B模式空间，结合半自动设计。

Result: 实验显示较标准B模式方法精度提升，框架对网络架构泛化能力强。

Conclusion: 该框架简化用户交互，保持对齐灵活性和临床相关性，显著提高测量准确性。

Abstract: Linear measurements of the left ventricle (LV) in the Parasternal Long Axis
(PLAX) view using B-mode echocardiography are crucial for cardiac assessment.
These involve placing 4-6 landmarks along a virtual scanline (SL) perpendicular
to the LV axis near the mitral valve tips. Manual placement is time-consuming
and error-prone, while existing deep learning methods often misalign landmarks,
causing inaccurate measurements. We propose a novel framework that enhances LV
measurement accuracy by enforcing straight-line constraints. A landmark
detector is trained on Anatomical M-Mode (AMM) images, computed in real time
from B-mode videos, then transformed back to B-mode space. This approach
addresses misalignment and reduces measurement errors. Experiments show
improved accuracy over standard B-mode methods, and the framework generalizes
well across network architectures. Our semi-automatic design includes a
human-in-the-loop step where the user only places the SL, simplifying
interaction while preserving alignment flexibility and clinical relevance.

</details>


### [173] [MirrorMe: Towards Realtime and High Fidelity Audio-Driven Halfbody Animation](https://arxiv.org/abs/2506.22065)
*Dechao Meng,Steven Xiao,Xindi Zhang,Guangyuan Wang,Peng Zhang,Qi Wang,Bang Zhang,Liefeng Bo*

Main category: cs.CV

TL;DR: MirrorMe是一个基于LTX视频模型的实时、可控框架，通过空间和时间压缩实现高效潜空间去噪，解决了音频驱动肖像动画的高延迟和时间一致性问题。


<details>
  <summary>Details</summary>
Motivation: 音频驱动肖像动画在实时生成高保真、时间连贯的视频方面存在挑战，现有方法因逐帧UNet架构导致高延迟和时间不一致。

Method: 1. 通过VAE编码图像拼接和自注意力机制注入参考身份；2. 为LTX时间结构设计的因果音频编码器和适配器；3. 渐进式训练策略结合面部、半身和手势控制。

Result: 在EMTD Benchmark上，MirrorMe在保真度、唇同步准确性和时间稳定性上表现最佳。

Conclusion: MirrorMe通过创新机制和训练策略，显著提升了音频驱动肖像动画的实时性和生成质量。

Abstract: Audio-driven portrait animation, which synthesizes realistic videos from
reference images using audio signals, faces significant challenges in real-time
generation of high-fidelity, temporally coherent animations. While recent
diffusion-based methods improve generation quality by integrating audio into
denoising processes, their reliance on frame-by-frame UNet architectures
introduces prohibitive latency and struggles with temporal consistency. This
paper introduces MirrorMe, a real-time, controllable framework built on the LTX
video model, a diffusion transformer that compresses video spatially and
temporally for efficient latent space denoising. To address LTX's trade-offs
between compression and semantic fidelity, we propose three innovations: 1. A
reference identity injection mechanism via VAE-encoded image concatenation and
self-attention, ensuring identity consistency; 2. A causal audio encoder and
adapter tailored to LTX's temporal structure, enabling precise audio-expression
synchronization; and 3. A progressive training strategy combining close-up
facial training, half-body synthesis with facial masking, and hand pose
integration for enhanced gesture control. Extensive experiments on the EMTD
Benchmark demonstrate MirrorMe's state-of-the-art performance in fidelity,
lip-sync accuracy, and temporal stability.

</details>


### [174] [Single-Scanline Relative Pose Estimation for Rolling Shutter Cameras](https://arxiv.org/abs/2506.22069)
*Petr Hruby,Marc Pollefeys*

Main category: cs.CV

TL;DR: 提出了一种新颖的方法，通过单扫描线投影的交点估计滚动快门相机的相对位姿，无需显式建模相机运动。


<details>
  <summary>Details</summary>
Motivation: 解决滚动快门相机在结构从运动（SfM）中位姿估计的挑战，避免复杂的运动建模。

Method: 利用线投影与单扫描线的交点进行位姿估计，支持单视图或多视图场景，并开发了最小求解器。

Result: 在Fastec数据集上的实验验证了方法的可行性，展示了其在滚动快门SfM初始化中的潜力。

Conclusion: 该方法为滚动快门SfM提供了基础模块，无需运动模型，具有进一步开发的潜力。

Abstract: We propose a novel approach for estimating the relative pose between rolling
shutter cameras using the intersections of line projections with a single
scanline per image. This allows pose estimation without explicitly modeling
camera motion. Alternatively, scanlines can be selected within a single image,
enabling single-view relative pose estimation for scanlines of rolling shutter
cameras. Our approach is designed as a foundational building block for rolling
shutter structure-from-motion (SfM), where no motion model is required, and
each scanline's pose can be computed independently. % We classify minimal
solvers for this problem in both generic and specialized settings, including
cases with parallel lines and known gravity direction, assuming known
intrinsics and no lens distortion. Furthermore, we develop minimal solvers for
the parallel-lines scenario, both with and without gravity priors, by
leveraging connections between this problem and the estimation of 2D structure
from 1D cameras. % Experiments on rolling shutter images from the Fastec
dataset demonstrate the feasibility of our approach for initializing rolling
shutter SfM, highlighting its potential for further development. % The code
will be made publicly available.

</details>


### [175] [Reasoning in machine vision: learning to think fast and slow](https://arxiv.org/abs/2506.22075)
*Shaheer U. Saeed,Yipei Wang,Veeru Kasivisvanathan,Brian R. Davidson,Matthew J. Clarkson,Yipeng Hu,Daniel C. Alexander*

Main category: cs.CV

TL;DR: 论文提出了一种新的学习范式，通过增加推理时间（计算资源）提升机器在视觉任务中的推理能力，尤其在数据稀缺情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类推理能力强大，而机器智能仍受限于训练数据，无法在推理时动态优化解决方案。当前机器推理主要局限于语言领域，非语言推理（如视觉、空间推理）仍是挑战。

Method: 受心理学双过程理论启发，结合快速思考的System I模块和慢速思考的System II模块，通过自玩强化学习迭代优化解决方案。

Result: 在视觉任务中，通过延长思考时间，性能优于大规模监督学习、基础模型甚至人类专家，特别是在医学图像癌症定位等任务中表现突出。

Conclusion: 该范式为非语言机器推理提供了突破性方法，展示了在真实世界视觉任务中的巨大潜力。

Abstract: Reasoning is a hallmark of human intelligence, enabling adaptive
decision-making in complex and unfamiliar scenarios. In contrast, machine
intelligence remains bound to training data, lacking the ability to dynamically
refine solutions at inference time. While some recent advances have explored
reasoning in machines, these efforts are largely limited to verbal domains such
as mathematical problem-solving, where explicit rules govern step-by-step
reasoning. Other critical real-world tasks - including visual perception,
spatial reasoning, and radiological diagnosis - require non-verbal reasoning,
which remains an open challenge. Here we present a novel learning paradigm that
enables machine reasoning in vision by allowing performance improvement with
increasing thinking time (inference-time compute), even under conditions where
labelled data is very limited. Inspired by dual-process theories of human
cognition in psychology, our approach integrates a fast-thinking System I
module for familiar tasks, with a slow-thinking System II module that
iteratively refines solutions using self-play reinforcement learning. This
paradigm mimics human reasoning by proposing, competing over, and refining
solutions in data-scarce scenarios. We demonstrate superior performance through
extended thinking time, compared not only to large-scale supervised learning
but also foundation models and even human experts, in real-world vision tasks.
These tasks include computer-vision benchmarks and cancer localisation on
medical images across five organs, showcasing transformative potential for
non-verbal machine reasoning.

</details>


### [176] [Towards Accurate Heart Rate Measurement from Ultra-Short Video Clips via Periodicity-Guided rPPG Estimation and Signal Reconstruction](https://arxiv.org/abs/2506.22078)
*Pei-Kai Huanga,Ya-Ting Chan,Kuan-Wen Chen,Yen-Chun Chou,Shih-Yu Yang,Chiou-Ting Hsu*

Main category: cs.CV

TL;DR: 提出了一种从超短2秒视频中准确测量心率的方法，通过周期性引导的rPPG估计和信号重构解决频谱泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注10秒视频的心率测量，忽视了超短视频的需求。

Method: 提出周期性引导的rPPG估计和信号重构生成器，确保信号周期性一致。

Result: 在四个基准数据集上表现优于现有技术，达到最优性能。

Conclusion: 方法能准确测量超短视频的心率，且性能优于现有技术。

Abstract: Many remote Heart Rate (HR) measurement methods focus on estimating remote
photoplethysmography (rPPG) signals from video clips lasting around 10 seconds
but often overlook the need for HR estimation from ultra-short video clips. In
this paper, we aim to accurately measure HR from ultra-short 2-second video
clips by specifically addressing two key challenges. First, to overcome the
limited number of heartbeat cycles in ultra-short video clips, we propose an
effective periodicity-guided rPPG estimation method that enforces consistent
periodicity between rPPG signals estimated from ultra-short clips and their
much longer ground truth signals. Next, to mitigate estimation inaccuracies due
to spectral leakage, we propose including a generator to reconstruct longer
rPPG signals from ultra-short ones while preserving their periodic consistency
to enable more accurate HR measurement. Extensive experiments on four rPPG
estimation benchmark datasets demonstrate that our proposed method not only
accurately measures HR from ultra-short video clips but also outperform
previous rPPG estimation techniques to achieve state-of-the-art performance.

</details>


### [177] [BézierGS: Dynamic Urban Scene Reconstruction with Bézier Curve Gaussian Splatting](https://arxiv.org/abs/2506.22099)
*Zipei Ma,Junzhe Jiang,Yurui Chen,Li Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于Bézier曲线的高斯泼溅方法（BézierGS），用于动态场景重建，无需依赖高精度物体姿态标注。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖物体姿态标注，限制了大规模场景重建。BézierGS通过Bézier曲线建模动态物体运动轨迹，自动修正姿态误差。

Method: 使用可学习的Bézier曲线表示动态物体运动轨迹，引入动态物体渲染和曲线间一致性约束。

Result: 在Waymo Open Dataset和nuPlan基准测试中，BézierGS在动态和静态场景重建及新视角合成上优于现有方法。

Conclusion: BézierGS通过曲线建模和额外监督，实现了高效且准确的场景重建。

Abstract: The realistic reconstruction of street scenes is critical for developing
real-world simulators in autonomous driving. Most existing methods rely on
object pose annotations, using these poses to reconstruct dynamic objects and
move them during the rendering process. This dependence on high-precision
object annotations limits large-scale and extensive scene reconstruction. To
address this challenge, we propose B\'ezier curve Gaussian splatting
(B\'ezierGS), which represents the motion trajectories of dynamic objects using
learnable B\'ezier curves. This approach fully leverages the temporal
information of dynamic objects and, through learnable curve modeling,
automatically corrects pose errors. By introducing additional supervision on
dynamic object rendering and inter-curve consistency constraints, we achieve
reasonable and accurate separation and reconstruction of scene elements.
Extensive experiments on the Waymo Open Dataset and the nuPlan benchmark
demonstrate that B\'ezierGS outperforms state-of-the-art alternatives in both
dynamic and static scene components reconstruction and novel view synthesis.

</details>


### [178] [Tied Prototype Model for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2506.22101)
*Hyeongji Kim,Stine Hansen,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: TPM改进ADNet，通过绑定原型位置和多原型扩展，提升医学图像少样本分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决ADNet在医学图像分割中的局限性，如单原型依赖、二元分类和固定阈值问题。

Method: 提出TPM模型，绑定前景和背景的原型位置，支持多原型和多类分割，并利用类先验优化自适应阈值。

Result: TPM在多原型和多类分割中表现更优，显著提升分割精度。

Conclusion: TPM为医学图像少样本分割提供了新思路，代码已开源。

Abstract: Common prototype-based medical image few-shot segmentation (FSS) methods
model foreground and background classes using class-specific prototypes.
However, given the high variability of the background, a more promising
direction is to focus solely on foreground modeling, treating the background as
an anomaly -- an approach introduced by ADNet. Yet, ADNet faces three key
limitations: dependence on a single prototype per class, a focus on binary
classification, and fixed thresholds that fail to adapt to patient and organ
variability. To address these shortcomings, we propose the Tied Prototype Model
(TPM), a principled reformulation of ADNet with tied prototype locations for
foreground and background distributions. Building on its probabilistic
foundation, TPM naturally extends to multiple prototypes and multi-class
segmentation while effectively separating non-typical background features.
Notably, both extensions lead to improved segmentation accuracy. Finally, we
leverage naturally occurring class priors to define an ideal target for
adaptive thresholds, boosting segmentation performance. Taken together, TPM
provides a fresh perspective on prototype-based FSS for medical image
segmentation. The code can be found at https://github.com/hjk92g/TPM-FSS.

</details>


### [179] [Pedestrian Intention and Trajectory Prediction in Unstructured Traffic Using IDD-PeD](https://arxiv.org/abs/2506.22111)
*Ruthvik Bokkasam,Shankar Gangisetty,A. H. Abdul Hafez,C. V. Jawahar*

Main category: cs.CV

TL;DR: 论文介绍了一个印度驾驶行人数据集，用于解决非结构化环境中行人行为建模的复杂性，并评估了现有方法的性能下降。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶的快速发展，准确预测行人行为对复杂交通环境中的安全至关重要，但缺乏针对非结构化环境的全面数据集。

Method: 提出了一个印度驾驶行人数据集，包含高水平和低水平的详细标注，重点关注需要车辆注意的行人。

Result: 评估显示，现有意图预测方法性能下降15%，轨迹预测方法的MSE增加1208，表现不如标准数据集。

Conclusion: 该数据集为行人行为研究社区提供了新挑战，有助于构建更鲁棒的模型。

Abstract: With the rapid advancements in autonomous driving, accurately predicting
pedestrian behavior has become essential for ensuring safety in complex and
unpredictable traffic conditions. The growing interest in this challenge
highlights the need for comprehensive datasets that capture unstructured
environments, enabling the development of more robust prediction models to
enhance pedestrian safety and vehicle navigation. In this paper, we introduce
an Indian driving pedestrian dataset designed to address the complexities of
modeling pedestrian behavior in unstructured environments, such as illumination
changes, occlusion of pedestrians, unsignalized scene types and
vehicle-pedestrian interactions. The dataset provides high-level and detailed
low-level comprehensive annotations focused on pedestrians requiring the
ego-vehicle's attention. Evaluation of the state-of-the-art intention
prediction methods on our dataset shows a significant performance drop of up to
$\mathbf{15\%}$, while trajectory prediction methods underperform with an
increase of up to $\mathbf{1208}$ MSE, defeating standard pedestrian datasets.
Additionally, we present exhaustive quantitative and qualitative analysis of
intention and trajectory baselines. We believe that our dataset will open new
challenges for the pedestrian behavior research community to build robust
models. Project Page:
https://cvit.iiit.ac.in/research/projects/cvit-projects/iddped

</details>


### [180] [Pipe Reconstruction from Point Cloud Data](https://arxiv.org/abs/2506.22118)
*Antje Alex,Jannis Stoppe*

Main category: cs.CV

TL;DR: 提出了一种从激光扫描数据自动重建管道的流程，通过骨架曲线估计和优化，实现快速、精确的管道建模。


<details>
  <summary>Details</summary>
Motivation: 手动从激光扫描数据建模管道耗时且费力，需要自动化方法以支持数字孪生的发展。

Method: 采用基于拉普拉斯的收缩估计骨架曲线，结合滚动球技术和2D圆拟合优化，最后进行3D平滑。

Result: 能够精确确定管道的半径、长度和方向，生成复杂管道网络的详细3D模型。

Conclusion: 自动化管道重建方法显著提高了建模效率，降低了成本，支持数字孪生的发展。

Abstract: Accurate digital twins of industrial assets, such as ships and offshore
platforms, rely on the precise reconstruction of complex pipe networks.
However, manual modelling of pipes from laser scan data is a time-consuming and
labor-intensive process. This paper presents a pipeline for automated pipe
reconstruction from incomplete laser scan data. The approach estimates a
skeleton curve using Laplacian-based contraction, followed by curve elongation.
The skeleton axis is then recentred using a rolling sphere technique combined
with 2D circle fitting, and refined with a 3D smoothing step. This enables the
determination of pipe properties, including radius, length and orientation, and
facilitates the creation of detailed 3D models of complex pipe networks. By
automating pipe reconstruction, this approach supports the development of
digital twins, allowing for rapid and accurate modeling while reducing costs.

</details>


### [181] [Low-Rank Implicit Neural Representation via Schatten-p Quasi-Norm and Jacobian Regularization](https://arxiv.org/abs/2506.22134)
*Zhengyun Cheng,Changhao Wang,Guanwen Zhang,Yi Xu,Wei Zhou,Xiangyang Ji*

Main category: cs.CV

TL;DR: 提出了一种基于CP分解的低秩张量函数（CP-INR），通过神经网络参数化实现连续数据表示，解决了稀疏性和平滑性问题，并在多维数据恢复任务中表现出优越性。


<details>
  <summary>Details</summary>
Motivation: 现有张量分解方法（如Tucker和CP）在灵活性和可解释性之间存在权衡，稀疏CP分解仍具挑战性。

Method: 结合CP分解与神经网络，提出CP-INR；引入Schatten-p拟范数的变分形式实现稀疏性，提出基于谱范数的平滑正则化。

Result: 在图像修复、去噪和点云上采样等任务中优于现有方法。

Conclusion: CP-INR方法在多维数据恢复中具有优越性和通用性，为连续数据表示提供了新思路。

Abstract: Higher-order tensors are well-suited for representing multi-dimensional data,
such as color images and videos. Low-rank tensor representation has become
essential in machine learning and computer vision, but existing methods like
Tucker decomposition offer flexibility at the expense of interpretability. In
contrast, while the CANDECOMP/PARAFAC (CP) decomposition provides a more
natural and interpretable tensor structure, obtaining sparse solutions remains
challenging. Leveraging the rich properties of CP decomposition, we propose a
CP-based low-rank tensor function parameterized by neural networks for implicit
neural representation (CP-INR). This approach enables continuous data
representation beyond structured grids, fully exploiting the non-linearity of
tensor data with theoretical guarantees on excess risk bounds. To achieve a
sparse CP decomposition, we introduce a variational form of the Schatten-p
quasi-norm and prove its relationship to multilinear rank minimization. For
smoothness, we propose a regularization term based on the spectral norm of the
Jacobian and Hutchinson's trace estimator. Our proposed smoothness
regularization is SVD-free and avoids explicit chain rule derivations. It can
serve as an alternative to Total Variation (TV) regularization in image
denoising tasks and is naturally applicable to continuous data. Extensive
experiments on multi-dimensional data recovery tasks, including image
inpainting, denoising, and point cloud upsampling, demonstrate the superiority
and versatility of our method compared to state-of-the-art approaches.

</details>


### [182] [Q-Frame: Query-aware Frame Selection and Multi-Resolution Adaptation for Video-LLMs](https://arxiv.org/abs/2506.22139)
*Shaojie Zhang,Jiahui Yang,Jianqin Yin,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Q-Frame是一种自适应帧选择和多分辨率缩放的新方法，针对视频内容和特定查询优化，提升视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频-LLM在均匀帧采样下难以有效捕捉关键时空线索，Q-Frame旨在解决这一问题。

Method: 采用无训练、即插即用策略，结合CLIP文本-图像匹配网络和Gumbel-Max技巧进行高效帧选择。

Result: 在MLVU、LongVideoBench和Video-MME等基准测试中表现优于现有方法。

Conclusion: Q-Frame能高效处理更多帧，保留关键时空信息，适用于多种视频理解任务。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated significant
success in visual understanding tasks. However, challenges persist in adapting
these models for video comprehension due to the large volume of data and
temporal complexity. Existing Video-LLMs using uniform frame sampling often
struggle to capture the query-related crucial spatiotemporal clues of videos
effectively. In this paper, we introduce Q-Frame, a novel approach for adaptive
frame selection and multi-resolution scaling tailored to the video's content
and the specific query. Q-Frame employs a training-free, plug-and-play strategy
generated by a text-image matching network like CLIP, utilizing the Gumbel-Max
trick for efficient frame selection. Q-Frame allows Video-LLMs to process more
frames without exceeding computational limits, thereby preserving critical
temporal and spatial information. We demonstrate Q-Frame's effectiveness
through extensive experiments on benchmark datasets, including MLVU,
LongVideoBench, and Video-MME, illustrating its superiority over existing
methods and its applicability across various video understanding tasks.

</details>


### [183] [Visual Structures Helps Visual Reasoning: Addressing the Binding Problem in VLMs](https://arxiv.org/abs/2506.22146)
*Amirmohammad Izadi,Mohammad Ali Banayeeanzade,Fatemeh Askari,Ali Rahimiakbar,Mohammad Mahdi Vahedi,Hosein Hasani,Mahdieh Soleymani Baghshah*

Main category: cs.CV

TL;DR: 论文提出通过增强视觉输入的低级空间结构（如水平线）并结合文本提示，显著提升了视觉语言模型在视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在视觉推理中存在绑定问题，即难以可靠地将感知特征与正确的视觉对象关联，导致在计数、视觉搜索等任务中表现不佳。

Method: 通过为视觉输入添加低级空间结构（如水平线），并辅以鼓励顺序、空间感知解析的文本提示。

Result: 方法显著提升了多项视觉推理任务的性能，如视觉搜索准确率提高25.00%，计数准确率提高26.83%。

Conclusion: 低级视觉结构调整是提升视觉语言模型在空间任务中性能的有效且未被充分探索的方向。

Abstract: Despite progress in Vision-Language Models (VLMs), their capacity for visual
reasoning is often limited by the \textit{binding problem}: the failure to
reliably associate perceptual features with their correct visual referents.
This limitation underlies persistent errors in tasks such as counting, visual
search, scene description, and spatial relationship understanding. A key factor
is that current VLMs process visual features largely in parallel, lacking
mechanisms for spatially grounded, serial attention. This paper introduces a
simple yet effective intervention: augmenting visual inputs with low-level
spatial structures (e.g., horizontal lines) and pairing this with a textual
prompt that encourages sequential, spatially-aware parsing. We empirically
demonstrate substantial performance improvements across core visual reasoning
tasks. Specifically, our method improves GPT-4o visual search accuracy by
25.00%, increases counting accuracy by 26.83%, reduces edit distance error in
scene description by 0.32, and enhances performance on spatial relationship
tasks by 9.50% on a a 2D synthetic dataset. Furthermore, we find that the
visual modification is essential for these gains; purely textual strategies,
including Chain-of-Thought prompting, are insufficient and can even degrade
performance. Our method enhances binding only with a single-query inference,
underscoring the importance of visual input design over purely
linguistically-based approaches. These findings suggest that low-level visual
structuring is a powerful and underexplored direction for improving
compositional visual reasoning and could serve as a general strategy for
enhancing VLM performance on spatially grounded tasks.

</details>


### [184] [RetFiner: A Vision-Language Refinement Scheme for Retinal Foundation Models](https://arxiv.org/abs/2506.22149)
*Ronald Fecso,José Morano,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: RetFiner是一种自监督学习（SSL）视觉语言细化方案，通过利用文本数据的监督信号改进现有基础模型（FMs）的表征，显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有OCT基础模型仅基于图像数据训练，缺乏全面的语义理解，需监督微调以适应特定任务和人群，但成本高昂。

Method: 提出RetFiner，结合多样化的训练目标，利用文本数据的丰富监督信号改进FMs表征。

Result: 在七项OCT分类任务中，RetFiner显著提升了RETFound、UrFound和VisionFM的线性探测性能，平均分别提高5.8、3.9和2.1个百分点。

Conclusion: RetFiner通过视觉语言细化方案，无需监督微调即可高效适应特定人群，显著提升下游任务表现。

Abstract: The rise of imaging techniques such as optical coherence tomography (OCT) and
advances in deep learning (DL) have enabled clinicians and researchers to
streamline retinal disease staging. A popular DL approach is self-supervised
learning (SSL), where models learn from vast amounts of unlabeled data,
avoiding costly annotation. SSL has allowed the development of foundation
models (FMs), large models that can be used for a variety of downstream tasks.
However, existing FMs for OCT, trained solely on image data, lack a
comprehensive and robust semantic understanding of images, as evidenced by
their downstream performance (especially for complex tasks), and thus require
supervised fine-tuning (which may be unfeasible) to better adapt to specific
applications and populations. To address this, we propose RetFiner, an SSL
vision-language refinement scheme that improves the representations of existing
FMs and enables their efficient and direct adaptation to specific populations
for improved downstream performance. Our method uses a diverse set of training
objectives which take advantage of the rich supervisory signal found in textual
data. We tested RetFiner on the retinal FMs RETFound, UrFound, and VisionFM,
showing significant improvements in linear probing performance on seven highly
diverse OCT classification tasks, with an average increase of 5.8, 3.9, and 2.1
percentage points over their baselines, respectively. Our code and model
weights are publicly available at https://github.com/ronnief1/RetFiner.

</details>


### [185] [Attention-disentangled Uniform Orthogonal Feature Space Optimization for Few-shot Object Detection](https://arxiv.org/abs/2506.22161)
*Taijin Zhao,Heqian Qiu,Yu Dai,Lanxiao Wang,Fanman Meng,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: 论文提出了一种Uniform Orthogonal Feature Space (UOFS)优化框架，通过解耦特征空间解决Few-shot目标检测中类特定对象性标准的问题，并引入HBO策略和SADA模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有Few-shot目标检测方法在共享特征空间中耦合对象性识别和前景分类，导致类特定对象性标准和样本不具代表性的问题。

Method: 提出UOFS框架，将特征空间解耦为幅度（对象性）和角度（分类）两个正交分量；引入HBO策略处理未标记前景实例和背景混淆问题；设计SADA模块解决任务冲突。

Result: 实验表明，该方法显著优于基于耦合特征空间的现有方法。

Conclusion: UOFS框架通过解耦特征空间和优化策略，有效提升了Few-shot目标检测的性能。

Abstract: Few-shot object detection (FSOD) aims to detect objects with limited samples
for novel classes, while relying on abundant data for base classes. Existing
FSOD approaches, predominantly built on the Faster R-CNN detector, entangle
objectness recognition and foreground classification within shared feature
spaces. This paradigm inherently establishes class-specific objectness criteria
and suffers from unrepresentative novel class samples. To resolve this
limitation, we propose a Uniform Orthogonal Feature Space (UOFS) optimization
framework. First, UOFS decouples the feature space into two orthogonal
components, where magnitude encodes objectness and angle encodes
classification. This decoupling enables transferring class-agnostic objectness
knowledge from base classes to novel classes. Moreover, implementing the
disentanglement requires careful attention to two challenges: (1) Base set
images contain unlabeled foreground instances, causing confusion between
potential novel class instances and backgrounds. (2) Angular optimization
depends exclusively on base class foreground instances, inducing overfitting of
angular distributions to base classes. To address these challenges, we propose
a Hybrid Background Optimization (HBO) strategy: (1) Constructing a pure
background base set by removing unlabeled instances in original images to
provide unbiased magnitude-based objectness supervision. (2) Incorporating
unlabeled foreground instances in the original base set into angular
optimization to enhance distribution uniformity. Additionally, we propose a
Spatial-wise Attention Disentanglement and Association (SADA) module to address
task conflicts between class-agnostic and class-specific tasks. Experiments
demonstrate that our method significantly outperforms existing approaches based
on entangled feature spaces.

</details>


### [186] [Frequency-Semantic Enhanced Variational Autoencoder for Zero-Shot Skeleton-based Action Recognition](https://arxiv.org/abs/2506.22179)
*Wenhan Wu,Zhishuai Guo,Chen Chen,Hongfei Xue,Aidong Lu*

Main category: cs.CV

TL;DR: 提出FS-VAE模型，通过频率分解增强骨架语义表示学习，改进零样本动作识别。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视语义空间中细粒度动作模式的问题。

Method: FS-VAE包含频率增强模块、多级对齐的语义描述和校准交叉对齐损失。

Result: 在基准测试中验证了频率增强语义特征的有效性。

Conclusion: FS-VAE能有效区分视觉和语义相似的动作簇，提升零样本识别性能。

Abstract: Zero-shot skeleton-based action recognition aims to develop models capable of
identifying actions beyond the categories encountered during training. Previous
approaches have primarily focused on aligning visual and semantic
representations but often overlooked the importance of fine-grained action
patterns in the semantic space (e.g., the hand movements in drinking water and
brushing teeth). To address these limitations, we propose a Frequency-Semantic
Enhanced Variational Autoencoder (FS-VAE) to explore the skeleton semantic
representation learning with frequency decomposition. FS-VAE consists of three
key components: 1) a frequency-based enhancement module with high- and
low-frequency adjustments to enrich the skeletal semantics learning and improve
the robustness of zero-shot action recognition; 2) a semantic-based action
description with multilevel alignment to capture both local details and global
correspondence, effectively bridging the semantic gap and compensating for the
inherent loss of information in skeleton sequences; 3) a calibrated
cross-alignment loss that enables valid skeleton-text pairs to counterbalance
ambiguous ones, mitigating discrepancies and ambiguities in skeleton and text
features, thereby ensuring robust alignment. Evaluations on the benchmarks
demonstrate the effectiveness of our approach, validating that
frequency-enhanced semantic features enable robust differentiation of visually
and semantically similar action clusters, improving zero-shot action
recognition.

</details>


### [187] [Robust and Accurate Multi-view 2D/3D Image Registration with Differentiable X-ray Rendering and Dual Cross-view Constraints](https://arxiv.org/abs/2506.22191)
*Yuxin Cui,Rui Song,Yibin Li,Max Q. -H. Meng,Zhe Min*

Main category: cs.CV

TL;DR: 提出了一种新颖的多视角2D/3D刚性配准方法，通过两阶段设计和交叉视角约束，显著提高了配准的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决单视角术中图像视野有限的问题，提升多视角2D/3D配准的精度和鲁棒性。

Method: 两阶段方法：第一阶段设计联合损失函数，引入交叉视角训练损失；第二阶段通过测试时优化细化估计姿态。

Result: 在DeepFluoro数据集上实现了0.79±2.17 mm的平均目标配准误差，优于现有方法。

Conclusion: 该方法通过多视角约束显著提升了配准性能，适用于临床导航应用。

Abstract: Robust and accurate 2D/3D registration, which aligns preoperative models with
intraoperative images of the same anatomy, is crucial for successful
interventional navigation. To mitigate the challenge of a limited field of view
in single-image intraoperative scenarios, multi-view 2D/3D registration is
required by leveraging multiple intraoperative images. In this paper, we
propose a novel multi-view 2D/3D rigid registration approach comprising two
stages. In the first stage, a combined loss function is designed, incorporating
both the differences between predicted and ground-truth poses and the
dissimilarities (e.g., normalized cross-correlation) between simulated and
observed intraoperative images. More importantly, additional cross-view
training loss terms are introduced for both pose and image losses to explicitly
enforce cross-view constraints. In the second stage, test-time optimization is
performed to refine the estimated poses from the coarse stage. Our method
exploits the mutual constraints of multi-view projection poses to enhance the
robustness of the registration process. The proposed framework achieves a mean
target registration error (mTRE) of $0.79 \pm 2.17$ mm on six specimens from
the DeepFluoro dataset, demonstrating superior performance compared to
state-of-the-art registration algorithms.

</details>


### [188] [ReF-LLE: Personalized Low-Light Enhancement via Reference-Guided Deep Reinforcement Learning](https://arxiv.org/abs/2506.22216)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: ReF-LLE是一种基于傅里叶频域和深度强化学习的个性化低光图像增强方法，通过零参考图像评分策略和自适应迭代策略，显著提升图像增强效果。


<details>
  <summary>Details</summary>
Motivation: 解决低光图像增强中的两大挑战：不同条件下的图像差异和主观偏好影响增强效果。

Method: 在傅里叶频域中结合深度强化学习，引入零参考图像评分策略和自适应迭代策略。

Result: 在基准数据集上表现优于现有方法，提供更好的感知质量和个性化适应性。

Conclusion: ReF-LLE通过创新方法有效解决了低光图像增强的挑战，实现了高质量的个性化增强。

Abstract: Low-light image enhancement presents two primary challenges: 1) Significant
variations in low-light images across different conditions, and 2) Enhancement
levels influenced by subjective preferences and user intent. To address these
issues, we propose ReF-LLE, a novel personalized low-light image enhancement
method that operates in the Fourier frequency domain and incorporates deep
reinforcement learning. ReF-LLE is the first to integrate deep reinforcement
learning into this domain. During training, a zero-reference image evaluation
strategy is introduced to score enhanced images, providing reward signals that
guide the model to handle varying degrees of low-light conditions effectively.
In the inference phase, ReF-LLE employs a personalized adaptive iterative
strategy, guided by the zero-frequency component in the Fourier domain, which
represents the overall illumination level. This strategy enables the model to
adaptively adjust low-light images to align with the illumination distribution
of a user-provided reference image, ensuring personalized enhancement results.
Extensive experiments on benchmark datasets demonstrate that ReF-LLE
outperforms state-of-the-art methods, achieving superior perceptual quality and
adaptability in personalized low-light image enhancement.

</details>


### [189] [Boosting Classification with Quantum-Inspired Augmentations](https://arxiv.org/abs/2506.22241)
*Matthias Tschöpe,Vitor Fortes Rey,Sogo Pierre Sanon,Paul Lukowicz,Nikolaos Palaiodimopoulos,Maximilian Kiefer-Emmanouilidis*

Main category: cs.CV

TL;DR: 量子门扰动在量子机器学习中可能带来性能提升，通过随机Bloch球旋转作为数据增强方法，显著提高了ImageNet数据集的分类性能。


<details>
  <summary>Details</summary>
Motivation: 研究量子门扰动对量子机器学习的潜在优势，探索其作为数据增强方法的有效性。

Method: 采用随机Bloch球旋转（SU(2)变换）作为量子启发式数据增强技术，应用于经典数据。

Result: 在ImageNet数据集上，Top-1准确率提升3%，Top-5准确率提升2.5%，F1分数从8%增至12%。

Conclusion: 量子启发式数据增强方法有效，但更强的酉变换虽保留信息却导致视觉不可识别，且未增强差分隐私。

Abstract: Understanding the impact of small quantum gate perturbations, which are
common in quantum digital devices but absent in classical computers, is crucial
for identifying potential advantages in quantum machine learning. While these
perturbations are typically seen as detrimental to quantum computation, they
can actually enhance performance by serving as a natural source of data
augmentation. Additionally, they can often be efficiently simulated on
classical hardware, enabling quantum-inspired approaches to improve classical
machine learning methods. In this paper, we investigate random Bloch sphere
rotations, which are fundamental SU(2) transformations, as a simple yet
effective quantum-inspired data augmentation technique. Unlike conventional
augmentations such as flipping, rotating, or cropping, quantum transformations
lack intuitive spatial interpretations, making their application to tasks like
image classification less straightforward. While common quantum augmentation
methods rely on applying quantum models or trainable quanvolutional layers to
classical datasets, we focus on the direct application of small-angle Bloch
rotations and their effect on classical data. Using the large-scale ImageNet
dataset, we demonstrate that our quantum-inspired augmentation method improves
image classification performance, increasing Top-1 accuracy by 3%, Top-5
accuracy by 2.5%, and the F$_1$ score from 8% to 12% compared to standard
classical augmentation methods. Finally, we examine the use of stronger unitary
augmentations. Although these transformations preserve information in
principle, they result in visually unrecognizable images with potential
applications for privacy computations. However, we show that our augmentation
approach and simple SU(2) transformations do not enhance differential privacy
and discuss the implications of this limitation.

</details>


### [190] [4D-VLA: Spatiotemporal Vision-Language-Action Pretraining with Cross-Scene Calibration](https://arxiv.org/abs/2506.22242)
*Jiahui Zhang,Yurui Chen,Yueming Xu,Ze Huang,Yanpeng Zhou,Yu-Jie Yuan,Xinyue Cai,Guowei Huang,Xingyue Quan,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: 论文提出4D-VLA方法，通过整合4D信息解决机器人数据预训练中的坐标系统和状态混乱问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因输入不完整导致动作分布分散，影响预训练效率。

Method: 引入深度和时间信息到视觉特征中，采用记忆库采样策略提取关键帧。

Result: 在仿真和真实实验中，模型性能显著提升，优于OpenVLA。

Conclusion: 4D-VLA有效解决了预训练中的混乱问题，增强了时空推理能力。

Abstract: Leveraging diverse robotic data for pretraining remains a critical challenge.
Existing methods typically model the dataset's action distribution using simple
observations as inputs. However, these inputs are often incomplete, resulting
in a dispersed conditional action distribution-an issue we refer to as
coordinate system chaos and state chaos. This inconsistency significantly
hampers pretraining efficiency. To address this, we propose 4D-VLA, a novel
approach that effectively integrates 4D information into the input to mitigate
these sources of chaos. Our model introduces depth and temporal information
into visual features with sequential RGB-D inputs, aligning the coordinate
systems of the robot and the scene. This alignment endows the model with strong
spatiotemporal reasoning capabilities while minimizing training overhead.
Additionally, we introduce memory bank sampling, a frame sampling strategy
designed to extract informative frames from historical images, further
improving effectiveness and efficiency. Experimental results demonstrate that
our pretraining method and architectural components substantially enhance model
performance. In both simulated and real-world experiments, our model achieves a
significant increase in success rate over OpenVLA. To further assess spatial
perception and generalization to novel views, we introduce MV-Bench, a
multi-view simulation benchmark. Our model consistently outperforms existing
methods, demonstrating stronger spatial understanding and adaptability.

</details>


### [191] [EAMamba: Efficient All-Around Vision State Space Model for Image Restoration](https://arxiv.org/abs/2506.22246)
*Yu-Cheng Lin,Yu-Syuan Xu,Hao-Wei Chen,Hsien-Kai Kuo,Chun-Yi Lee*

Main category: cs.CV

TL;DR: EAMamba框架通过多头部选择性扫描模块（MHSSM）和全方位扫描机制，解决了Vision Mamba在低层视觉任务中的计算复杂性和局部像素遗忘问题，显著降低了计算量并保持性能。


<details>
  <summary>Details</summary>
Motivation: Vision Mamba在图像恢复任务中表现出色，但在低层视觉任务中存在计算复杂性和局部像素遗忘的挑战，需要改进。

Method: 提出EAMamba框架，引入MHSSM模块和全方位扫描策略，以高效聚合扫描序列并捕获全局信息。

Result: 实验表明，EAMamba在多种恢复任务中显著降低FLOPs（31-89%），同时保持性能。

Conclusion: EAMamba为低层视觉任务提供了一种高效且性能优越的解决方案。

Abstract: Image restoration is a key task in low-level computer vision that aims to
reconstruct high-quality images from degraded inputs. The emergence of Vision
Mamba, which draws inspiration from the advanced state space model Mamba, marks
a significant advancement in this field. Vision Mamba demonstrates excellence
in modeling long-range dependencies with linear complexity, a crucial advantage
for image restoration tasks. Despite its strengths, Vision Mamba encounters
challenges in low-level vision tasks, including computational complexity that
scales with the number of scanning sequences and local pixel forgetting. To
address these limitations, this study introduces Efficient All-Around Mamba
(EAMamba), an enhanced framework that incorporates a Multi-Head Selective Scan
Module (MHSSM) with an all-around scanning mechanism. MHSSM efficiently
aggregates multiple scanning sequences, which avoids increases in computational
complexity and parameter count. The all-around scanning strategy implements
multiple patterns to capture holistic information and resolves the local pixel
forgetting issue. Our experimental evaluations validate these innovations
across several restoration tasks, including super resolution, denoising,
deblurring, and dehazing. The results validate that EAMamba achieves a
significant 31-89% reduction in FLOPs while maintaining favorable performance
compared to existing low-level Vision Mamba methods.

</details>


### [192] [COOCO -- Common Objects Out-of-Context -- Semantic Violation in Scenes: Investigating Multimodal Context in Referential Communication](https://arxiv.org/abs/2506.22274)
*Filippo Merlo,Ece Takmaz,Wenkai Chen,Albert Gatt*

Main category: cs.CV

TL;DR: 论文研究了视觉语言模型（VLMs）是否依赖场景上下文生成对象引用，并引入COOCO数据集测试模型在不同场景-对象一致性和噪声下的表现。


<details>
  <summary>Details</summary>
Motivation: 探索VLMs是否像人类一样利用场景上下文进行对象识别和引用。

Method: 使用COOCO数据集，测试模型在不同场景-对象一致性和噪声条件下的表现，并进行注意力分析。

Result: 模型会根据场景-对象语义相关性和噪声水平自适应地利用上下文，尤其在目标-场景高度一致或对象退化时更依赖上下文。

Conclusion: VLMs动态平衡局部和上下文信息进行对象引用生成，成功分类时中层注意力更集中于目标。

Abstract: Natural scenes provide us with rich contexts for object recognition and
reference. In particular, knowing what type of scene one is looking at
generates expectations about which objects will occur, and what their spatial
configuration should be. Do Vision-Language Models (VLMs) learn to rely on
scene contexts in a similar way, when generating references to objects? To
address this question, we introduce the \textit{Common Objects Out-of-Context
(COOCO)} dataset and test to what extent VLMs rely on scene context to refer to
objects under different degrees of scene-object congruency, and different
perturbations. Our findings show that models leverage scene context adaptively,
depending on both the semantic relatedness between object and scene and the
level of noise. In particular, models rely more on context under high
target-scene congruence or when objects are degraded. Attention analysis
reveals that successful object categorisation involves increased focus on the
target in mid-level layers, especially under moderate noise, suggesting that
VLMs dynamically balance local and contextual information for reference
generation. We make our dataset, code and models available at
\href{https://github.com/cs-nlp-uu/scenereg}{https://github.com/cs-nlp-uu/scenereg}.

</details>


### [193] [Rethinking Visual Token Reduction in LVLMs under Cross-modal Misalignment](https://arxiv.org/abs/2506.22283)
*Rui Xu,Yunke Wang,Yong Luo,Bo Du*

Main category: cs.CV

TL;DR: VisionDrop是一种无需训练的视觉令牌修剪框架，通过视觉内注意力选择信息丰富的令牌，解决了跨模态不对齐问题，提升了LVLMs的效率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌减少方法依赖文本条件，但跨模态不对齐（因果、语义和空间）削弱了其效果，需要一种不依赖文本信号的视觉令牌修剪方法。

Method: 提出VisionDrop，基于视觉内注意力选择令牌，设计渐进式修剪管道，在模型层次中抑制冗余。

Result: 在多样化基准测试中，VisionDrop一致优于现有方法，无需额外训练或复杂修改。

Conclusion: VisionDrop简单有效，在保持性能的同时实现了高效推理。

Abstract: Large Vision-Language Models (LVLMs) encode visual inputs as dense sequences
of patch-level tokens to capture fine-grained semantics. These visual tokens
often outnumber their textual counterparts by a large margin, leading to
substantial computational overhead and limiting the scalability of LVLMs in
practice. Previous efforts have explored visual token reduction either prior to
or within the large language models (LLM). However, most in-LLM reduction
approaches rely on text-conditioned interactions, implicitly assuming that
textual tokens can reliably capture the importance of visual tokens. In this
work, we revisit this assumption and reveal causal, semantic, and spatial forms
of cross-modal misalignment. These misalignments undermine the effectiveness of
text-guided visual token reduction. To address this, we introduce VisionDrop, a
training-free, visual-only pruning framework that selects informative visual
tokens based on intra-modal (visual-to-visual) attention, without relying on
textual signals. To further suppress redundancy throughout the model hierarchy,
we treat the visual encoder and the LLM as a unified system and design a
progressive pruning pipeline. Our method performs dominant token selection and
lightweight contextual merging at multiple stages, enabling fine-grained visual
information to be retained even under aggressive token budgets. Extensive
experiments across diverse benchmarks show that VisionDrop achieves consistent
improvements over existing methods, despite requiring no additional training or
complex modifications. Its simple yet effective design enables efficient
inference while preserving strong performance across tasks.

</details>


### [194] [RoomCraft: Controllable and Complete 3D Indoor Scene Generation](https://arxiv.org/abs/2506.22291)
*Mengqi Zhou,Xipeng Wang,Yuxi Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: RoomCraft是一个多阶段管道，将真实图像、草图或文本描述转换为连贯的3D室内场景，结合约束驱动优化框架，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在生成3D室内场景时因全局空间推理不足导致的重复元素问题，以及多约束场景下的家具碰撞和布局不完整问题。

Method: 结合场景生成管道与约束驱动优化框架，提取高层场景信息，构建空间关系网络，使用HDFS算法生成优化放置序列，并引入统一约束表示和CAPS策略。

Result: RoomCraft在生成真实、语义连贯且视觉吸引人的房间布局方面显著优于现有方法。

Conclusion: RoomCraft通过多阶段管道和优化策略，有效解决了3D室内场景生成中的关键挑战，实现了高质量布局。

Abstract: Generating realistic 3D indoor scenes from user inputs remains a challenging
problem in computer vision and graphics, requiring careful balance of geometric
consistency, spatial relationships, and visual realism. While neural generation
methods often produce repetitive elements due to limited global spatial
reasoning, procedural approaches can leverage constraints for controllable
generation but struggle with multi-constraint scenarios. When constraints
become numerous, object collisions frequently occur, forcing the removal of
furniture items and compromising layout completeness.
  To address these limitations, we propose RoomCraft, a multi-stage pipeline
that converts real images, sketches, or text descriptions into coherent 3D
indoor scenes. Our approach combines a scene generation pipeline with a
constraint-driven optimization framework. The pipeline first extracts
high-level scene information from user inputs and organizes it into a
structured format containing room type, furniture items, and spatial relations.
It then constructs a spatial relationship network to represent furniture
arrangements and generates an optimized placement sequence using a
heuristic-based depth-first search (HDFS) algorithm to ensure layout coherence.
To handle complex multi-constraint scenarios, we introduce a unified constraint
representation that processes both formal specifications and natural language
inputs, enabling flexible constraint-oriented adjustments through a
comprehensive action space design. Additionally, we propose a Conflict-Aware
Positioning Strategy (CAPS) that dynamically adjusts placement weights to
minimize furniture collisions and ensure layout completeness.
  Extensive experiments demonstrate that RoomCraft significantly outperforms
existing methods in generating realistic, semantically coherent, and visually
appealing room layouts across diverse input modalities.

</details>


### [195] [OutDreamer: Video Outpainting with a Diffusion Transformer](https://arxiv.org/abs/2506.22298)
*Linhao Zhong,Fan Li,Yi Huang,Jianzhuang Liu,Renjing Pei,Fenglong Song*

Main category: cs.CV

TL;DR: OutDreamer是一个基于扩散变换器（DiT）的视频外绘框架，通过高效视频控制分支和条件外绘分支实现高质量视频内容生成，并引入掩码驱动自注意力层和潜在对齐损失提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于U-Net的潜在扩散模型在视频外绘任务中难以实现高质量和适应性，扩散变换器（DiT）因其优越性能成为有前景的替代方案。

Method: 提出OutDreamer框架，包含高效视频控制分支和条件外绘分支，引入掩码驱动自注意力层和潜在对齐损失，采用跨视频片段细化器确保长视频一致性。

Result: 在广泛认可的基准测试中，OutDreamer的零样本性能优于现有最先进的零样本方法。

Conclusion: OutDreamer通过DiT框架和创新的组件设计，显著提升了视频外绘任务的质量和适应性。

Abstract: Video outpainting is a challenging task that generates new video content by
extending beyond the boundaries of an original input video, requiring both
temporal and spatial consistency. Many state-of-the-art methods utilize latent
diffusion models with U-Net backbones but still struggle to achieve high
quality and adaptability in generated content. Diffusion transformers (DiTs)
have emerged as a promising alternative because of their superior performance.
We introduce OutDreamer, a DiT-based video outpainting framework comprising two
main components: an efficient video control branch and a conditional
outpainting branch. The efficient video control branch effectively extracts
masked video information, while the conditional outpainting branch generates
missing content based on these extracted conditions. Additionally, we propose a
mask-driven self-attention layer that dynamically integrates the given mask
information, further enhancing the model's adaptability to outpainting tasks.
Furthermore, we introduce a latent alignment loss to maintain overall
consistency both within and between frames. For long video outpainting, we
employ a cross-video-clip refiner to iteratively generate missing content,
ensuring temporal consistency across video clips. Extensive evaluations
demonstrate that our zero-shot OutDreamer outperforms state-of-the-art
zero-shot methods on widely recognized benchmarks.

</details>


### [196] [MatChA: Cross-Algorithm Matching with Feature Augmentation](https://arxiv.org/abs/2506.22336)
*Paula Carbó Cubero,Alberto Jaenal Gálvez,André Mateus,José Araújo,Patric Jensfelt*

Main category: cs.CV

TL;DR: 提出了一种针对跨特征检测器场景的特征描述符增强和转换方法，显著提升了图像匹配和视觉定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨设备使用不同稀疏特征提取算法时性能下降，因为假设使用相同检测器，而实际中很少如此。

Method: 通过特征描述符增强和转换到潜在空间，解决跨检测器特征匹配问题。

Result: 在多个基准测试中，该方法显著提升了跨特征场景下的图像匹配和视觉定位性能。

Conclusion: 该方法有效解决了跨特征检测器场景下的视觉定位问题，性能显著优于现有方法。

Abstract: State-of-the-art methods fail to solve visual localization in scenarios where
different devices use different sparse feature extraction algorithms to obtain
keypoints and their corresponding descriptors. Translating feature descriptors
is enough to enable matching. However, performance is drastically reduced in
cross-feature detector cases, because current solutions assume common
keypoints. This means that the same detector has to be used, which is rarely
the case in practice when different descriptors are used. The low repeatability
of keypoints, in addition to non-discriminatory and non-distinctive
descriptors, make the identification of true correspondences extremely
challenging. We present the first method tackling this problem, which performs
feature descriptor augmentation targeting cross-detector feature matching, and
then feature translation to a latent space. We show that our method
significantly improves image matching and visual localization in the
cross-feature scenario and evaluate the proposed method on several benchmarks.

</details>


### [197] [A Deep Learning framework for building damage assessment using VHR SAR and geospatial data: demonstration on the 2023 Turkiye Earthquake](https://arxiv.org/abs/2506.22338)
*Luigi Russo,Deodato Tapete,Silvia Liberata Ullo,Paolo Gamba*

Main category: cs.CV

TL;DR: 提出了一种基于单日期高分辨率SAR图像和多源地理空间数据的深度学习框架，用于快速检测建筑物损坏，无需依赖灾前影像。


<details>
  <summary>Details</summary>
Motivation: 解决光学卫星影像在灾害后因云层覆盖或缺乏灾前数据而受限的问题，以支持紧急响应和恢复工作。

Method: 结合SAR图像、OSM建筑足迹、DSM数据和GEM属性，构建多模态深度学习模型，仅使用灾后数据。

Result: 在土耳其2023年地震数据集上验证，显示结合地理空间特征显著提高了检测性能和泛化能力。

Conclusion: 该方法可快速、可靠地评估建筑物损坏，适用于多样化灾区，支持灾害管理和恢复。

Abstract: Building damage identification shortly after a disaster is crucial for
guiding emergency response and recovery efforts. Although optical satellite
imagery is commonly used for disaster mapping, its effectiveness is often
hampered by cloud cover or the absence of pre-event acquisitions. To overcome
these challenges, we introduce a novel multimodal deep learning (DL) framework
for detecting building damage using single-date very high resolution (VHR)
Synthetic Aperture Radar (SAR) imagery from the Italian Space Agency (ASI)
COSMO SkyMed (CSK) constellation, complemented by auxiliary geospatial data.
Our method integrates SAR image patches, OpenStreetMap (OSM) building
footprints, digital surface model (DSM) data, and structural and exposure
attributes from the Global Earthquake Model (GEM) to improve detection accuracy
and contextual interpretation. Unlike existing approaches that depend on pre
and post event imagery, our model utilizes only post event data, facilitating
rapid deployment in critical scenarios. The framework effectiveness is
demonstrated using a new dataset from the 2023 earthquake in Turkey, covering
multiple cities with diverse urban settings. Results highlight that
incorporating geospatial features significantly enhances detection performance
and generalizability to previously unseen areas. By combining SAR imagery with
detailed vulnerability and exposure information, our approach provides reliable
and rapid building damage assessments without the dependency from available
pre-event data. Moreover, the automated and scalable data generation process
ensures the framework's applicability across diverse disaster-affected regions,
underscoring its potential to support effective disaster management and
recovery efforts. Code and data will be made available upon acceptance of the
paper.

</details>


### [198] [Closing the Performance Gap in Biometric Cryptosystems: A Deeper Analysis on Unlinkable Fuzzy Vaults](https://arxiv.org/abs/2506.22347)
*Hans Geißner,Christian Rathgeb*

Main category: cs.CV

TL;DR: 论文提出了一种基于等频区间的特征量化方法，解决了模糊保险库生物识别系统中的性能差距问题。


<details>
  <summary>Details</summary>
Motivation: 模糊保险库生物识别系统因特征集大小不稳定和特征类型转换导致的信息丢失而性能下降。

Method: 采用基于等频区间的特征量化方法，确保固定特征集大小，并支持无训练适应任意区间数。

Result: 实验表明，该方法显著减少了模板保护引入的性能差距，并在多种生物识别系统中表现优异。

Conclusion: 提出的方法有效解决了性能问题，适用于多种生物识别模态。

Abstract: This paper analyses and addresses the performance gap in the fuzzy
vault-based \ac{BCS}. We identify unstable error correction capabilities, which
are caused by variable feature set sizes and their influence on similarity
thresholds, as a key source of performance degradation. This issue is further
compounded by information loss introduced through feature type transformations.
To address both problems, we propose a novel feature quantization method based
on \it{equal frequent intervals}. This method guarantees fixed feature set
sizes and supports training-free adaptation to any number of intervals. The
proposed approach significantly reduces the performance gap introduced by
template protection. Additionally, it integrates seamlessly with existing
systems to minimize the negative effects of feature transformation. Experiments
on state-of-the-art face, fingerprint, and iris recognition systems confirm
that only minimal performance degradation remains, demonstrating the
effectiveness of the method across major biometric modalities.

</details>


### [199] [From Ground to Air: Noise Robustness in Vision Transformers and CNNs for Event-Based Vehicle Classification with Potential UAV Applications](https://arxiv.org/abs/2506.22360)
*Nouf Almesafri,Hector Figueiredo,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 研究比较了卷积神经网络（ResNet34）和视觉变换器（ViT B16）在事件相机上的性能，发现ResNet34在分类准确率上略优，但ViT B16在噪声环境下表现更稳健。


<details>
  <summary>Details</summary>
Motivation: 事件相机适用于动态环境（如无人机和自动驾驶车辆），但传统深度学习模型在此类数据上的表现尚不明确，因此需要研究其性能。

Method: 使用ResNet34和ViT B16在GEN1事件数据集上进行微调，并在标准条件和模拟噪声下评估模型性能。

Result: 在干净数据集上，ResNet34和ViT B16的准确率分别为88%和86%；ViT B16在噪声环境下表现更稳健。

Conclusion: 尽管ResNet34在准确率上略优，ViT B16的稳健性使其更适合动态环境，研究结果对无人机等应用具有潜在价值。

Abstract: This study investigates the performance of the two most relevant computer
vision deep learning architectures, Convolutional Neural Network and Vision
Transformer, for event-based cameras. These cameras capture scene changes,
unlike traditional frame-based cameras with capture static images, and are
particularly suited for dynamic environments such as UAVs and autonomous
vehicles. The deep learning models studied in this work are ResNet34 and ViT
B16, fine-tuned on the GEN1 event-based dataset. The research evaluates and
compares these models under both standard conditions and in the presence of
simulated noise. Initial evaluations on the clean GEN1 dataset reveal that
ResNet34 and ViT B16 achieve accuracies of 88% and 86%, respectively, with
ResNet34 showing a slight advantage in classification accuracy. However, the
ViT B16 model demonstrates notable robustness, particularly given its
pre-training on a smaller dataset. Although this study focuses on ground-based
vehicle classification, the methodologies and findings hold significant promise
for adaptation to UAV contexts, including aerial object classification and
event-based vision systems for aviation-related tasks.

</details>


### [200] [Exploiting Vision Language Model for Training-Free 3D Point Cloud OOD Detection via Graph Score Propagation](https://arxiv.org/abs/2506.22375)
*Tiankai Chen,Yushu Li,Adam Goodge,Fei Teng,Xulei Yang,Tianrui Li,Xun Xu*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言模型（VLM）的无训练框架，用于3D点云数据的OOD检测，通过图分数传播（GSP）方法显著提升了检测效果。


<details>
  <summary>Details</summary>
Motivation: 3D点云数据的OOD检测在安全感知应用中至关重要，但现有方法主要针对2D图像，难以直接扩展到3D环境。

Method: 利用VLM构建基于类别原型和测试数据的图，提出GSP方法，结合提示聚类和自训练负提示优化OOD评分。

Result: GSP在合成和真实数据集上均优于现有方法，且适用于少样本场景。

Conclusion: 该方法为3D点云OOD检测提供了一种高效且灵活的解决方案。

Abstract: Out-of-distribution (OOD) detection in 3D point cloud data remains a
challenge, particularly in applications where safe and robust perception is
critical. While existing OOD detection methods have shown progress for 2D image
data, extending these to 3D environments involves unique obstacles. This paper
introduces a training-free framework that leverages Vision-Language Models
(VLMs) for effective OOD detection in 3D point clouds. By constructing a graph
based on class prototypes and testing data, we exploit the data manifold
structure to enhancing the effectiveness of VLMs for 3D OOD detection. We
propose a novel Graph Score Propagation (GSP) method that incorporates prompt
clustering and self-training negative prompting to improve OOD scoring with
VLM. Our method is also adaptable to few-shot scenarios, providing options for
practical applications. We demonstrate that GSP consistently outperforms
state-of-the-art methods across synthetic and real-world datasets 3D point
cloud OOD detection.

</details>


### [201] [Can Video Large Multimodal Models Think Like Doubters-or Double-Down: A Study on Defeasible Video Entailment](https://arxiv.org/abs/2506.22385)
*Yue Zhang,Jilei Sun,Yunhui Guo,Vibhav Gogate*

Main category: cs.CV

TL;DR: 论文提出了Defeasible Video Entailment (DVidE)任务，旨在提升视频大模型在动态推理中的能力，并提出了两种解决方案和一个新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大模型在抽象和自适应推理方面表现不足，无法根据新信息动态调整推理结果。

Method: 提出了Chain of Counterfactual Thought框架用于分类任务，结合反事实推理和ASR增强视频内容；生成任务则结合ASR输出和大型语言模型生成更新。

Result: 实验结果显示方法显著提升了模型的动态推理能力。

Conclusion: DVidE任务和相关方法有效增强了视频大模型的动态推理能力，为未来研究提供了新方向。

Abstract: Video Large Multimodal Models (VLMMs) have made impressive strides in
understanding video content, but they often struggle with abstract and adaptive
reasoning-the ability to revise their interpretations when new information
emerges. In reality, conclusions are rarely set in stone; additional context
can strengthen or weaken an initial inference. To address this, we introduce
Defeasible Video Entailment (DVidE), a new task that challenges models to think
like doubters, constantly updating their reasoning based on evolving evidence.
In DVidE, given a video premise and a textual hypothesis, models must determine
whether a new update strengthens or weakens the hypothesis (classification
version) or generate a coherent update that modifies the entailment
relationship (generation version). For solving the classification task, we
propose the Chain of Counterfactual Thought framework, utilizing counterfactual
reasoning, ASR-enhanced video content, and rationale refinement to reduce
inference bias. For the generation task, we develop a framework that combines
ASR output with a Large Language Model (LLM) to produce coherent, contextually
relevant updates aligned with the intended strengthener or weakener goals.
Additionally, we introduce a novel benchmark dataset, with
strengthener/weakener annotations and an LLM-based evaluation metric
specifically designed for assessing generative performance. Experimental
results demonstrate significant improvements, highlighting our proposed method
in enhancing dynamic reasoning capabilities of VLMMs.

</details>


### [202] [Test-Time Consistency in Vision Language Models](https://arxiv.org/abs/2506.22395)
*Shih-Han Chou,Shivam Chandhok,James J. Little,Leonid Sigal*

Main category: cs.CV

TL;DR: 提出一种无需监督再训练的测试时一致性框架，提升视觉语言模型在语义等效输入下的预测一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在语义等效输入下表现不一致，影响可靠性和鲁棒性。

Method: 通过交叉熵一致性损失和伪标签一致性损失，在测试时增强预测一致性。

Result: 在MM-R3基准测试中显著提升了模型的一致性。

Conclusion: 该方法为多模态学习的推理时适应提供了新方向。

Abstract: Vision-Language Models (VLMs) have achieved impressive performance across a
wide range of multimodal tasks, yet they often exhibit inconsistent behavior
when faced with semantically equivalent inputs, undermining their reliability
and robustness. Recent benchmarks, such as MM-R3, highlight that even
state-of-the-art VLMs can produce divergent predictions across semantically
equivalent inputs, despite maintaining high average accuracy. Prior work
addresses this issue by modifying model architectures or conducting large-scale
fine-tuning on curated datasets. In contrast, we propose a simple and effective
test-time consistency framework that enhances semantic consistency without
supervised re-training. Our method is entirely post-hoc, model-agnostic, and
applicable to any VLM with access to its weights. Given a single test point, we
enforce consistent predictions via two complementary objectives: (i) a
Cross-Entropy Agreement Loss that aligns predictive distributions across
semantically equivalent inputs, and (ii) a Pseudo-Label Consistency Loss that
draws outputs toward a self-averaged consensus. Our method is plug-and-play and
leverages information from a single test input itself to improve consistency.
Experiments on the MM-R3 benchmark show that our framework yields substantial
gains in consistency across state-of-the-art models, establishing a new
direction for inference-time adaptation in multimodal learning.

</details>


### [203] [Shape-for-Motion: Precise and Consistent Video Editing with 3D Proxy](https://arxiv.org/abs/2506.22432)
*Yuhao Liu,Tengfei Wang,Fang Liu,Zhenwei Wang,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: Shape-for-Motion框架通过3D代理实现精确一致的视频编辑，支持多种物理一致的操作。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在视频编辑中难以精确对齐用户意图的问题。

Method: 使用3D代理（时间一致的网格）进行编辑，通过双传播策略简化编辑过程，并结合视频扩散模型生成结果。

Result: 支持多种精确操作（如姿态编辑、纹理修改等），实验证明其优越性和有效性。

Conclusion: 该框架是高质量、可控视频编辑工作流的重要进展。

Abstract: Recent advances in deep generative modeling have unlocked unprecedented
opportunities for video synthesis. In real-world applications, however, users
often seek tools to faithfully realize their creative editing intentions with
precise and consistent control. Despite the progress achieved by existing
methods, ensuring fine-grained alignment with user intentions remains an open
and challenging problem. In this work, we present Shape-for-Motion, a novel
framework that incorporates a 3D proxy for precise and consistent video
editing. Shape-for-Motion achieves this by converting the target object in the
input video to a time-consistent mesh, i.e., a 3D proxy, allowing edits to be
performed directly on the proxy and then inferred back to the video frames. To
simplify the editing process, we design a novel Dual-Propagation Strategy that
allows users to perform edits on the 3D mesh of a single frame, and the edits
are then automatically propagated to the 3D meshes of the other frames. The 3D
meshes for different frames are further projected onto the 2D space to produce
the edited geometry and texture renderings, which serve as inputs to a
decoupled video diffusion model for generating edited results. Our framework
supports various precise and physically-consistent manipulations across the
video frames, including pose editing, rotation, scaling, translation, texture
modification, and object composition. Our approach marks a key step toward
high-quality, controllable video editing workflows. Extensive experiments
demonstrate the superiority and effectiveness of our approach. Project page:
https://shapeformotion.github.io/

</details>


### [204] [WarpRF: Multi-View Consistency for Training-Free Uncertainty Quantification and Applications in Radiance Fields](https://arxiv.org/abs/2506.22433)
*Sadra Safadoust,Fabio Tosi,Fatma Güney,Matteo Poggi*

Main category: cs.CV

TL;DR: WarpRF是一个无需训练、通用的框架，用于量化辐射场的不确定性，通过反向变形和一致性测量实现。


<details>
  <summary>Details</summary>
Motivation: 量化辐射场的不确定性对于提高渲染质量和下游任务（如主动视图选择）至关重要。

Method: 利用反向变形将可靠渲染投影到新视角，测量与渲染图像的一致性。

Result: WarpRF在不确定性量化和下游任务中表现优异，超越现有方法。

Conclusion: WarpRF简单、高效，适用于任何辐射场实现。

Abstract: We introduce WarpRF, a training-free general-purpose framework for
quantifying the uncertainty of radiance fields. Built upon the assumption that
photometric and geometric consistency should hold among images rendered by an
accurate model, WarpRF quantifies its underlying uncertainty from an unseen
point of view by leveraging backward warping across viewpoints, projecting
reliable renderings to the unseen viewpoint and measuring the consistency with
images rendered there. WarpRF is simple and inexpensive, does not require any
training, and can be applied to any radiance field implementation for free.
WarpRF excels at both uncertainty quantification and downstream tasks, e.g.,
active view selection and active mapping, outperforming any existing method
tailored to specific frameworks.

</details>


### [205] [MiCo: Multi-image Contrast for Reinforcement Visual Reasoning](https://arxiv.org/abs/2506.22434)
*Xi Chen,Mingkang Zhu,Shaoteng Liu,Xiaoyang Wu,Xiaogang Xu,Yu Liu,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: 论文提出一种自监督方法，通过构建图像三元组和规则强化学习，提升视觉语言模型在多图像推理任务中的表现，无需人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 现有基于规则强化学习的方法依赖人工标注的问题-答案对，难以处理细粒度视觉细节和复杂逻辑。

Method: 构建图像三元组（两个增强视图和一个相似但不同的图像），通过自监督学习生成推理过程并优化模型。

Result: 模型在视觉比较任务中表现优异，推理能力泛化至多种问题，显著提升多图像推理基准性能。

Conclusion: 自监督方法有效提升视觉语言模型的推理能力，无需人工标注数据。

Abstract: This work explores enabling Chain-of-Thought (CoT) reasoning to link visual
cues across multiple images. A straightforward solution is to adapt rule-based
reinforcement learning for Vision-Language Models (VLMs). However, such methods
typically rely on manually curated question-answer pairs, which can be
particularly challenging when dealing with fine grained visual details and
complex logic across images. Inspired by self-supervised visual representation
learning, we observe that images contain inherent constraints that can serve as
supervision. Based on this insight, we construct image triplets comprising two
augmented views of the same image and a third, similar but distinct image.
During training, the model is prompted to generate a reasoning process to
compare these images (i.e., determine same or different). Then we optimize the
model with rule-based reinforcement learning. Due to the high visual similarity
and the presence of augmentations, the model must attend to subtle visual
changes and perform logical reasoning to succeed. Experiments show that,
although trained solely on visual comparison tasks, the learned reasoning
ability generalizes effectively to a wide range of questions. Without relying
on any human-annotated question-answer pairs, our method achieves significant
improvements on multi-image reasoning benchmarks and shows strong performance
on general vision tasks.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [206] [Revisiting Graph Analytics Benchmark](https://arxiv.org/abs/2506.21811)
*Lingkai Meng,Yu Shao,Long Yuan,Longbin Lai,Peng Cheng,Xue Li,Wenyuan Yu,Wenjie Zhang,Xuemin Lin,Jingren Zhou*

Main category: cs.DB

TL;DR: 提出了一种新的图分析基准测试，改进了核心算法选择、数据生成和API可用性评估。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在核心算法选择、数据生成和API可用性评估方面存在不足，无法全面评估平台性能。

Method: 1. 选择8个核心算法；2. 设计高效灵活的数据生成器并生成8个新数据集；3. 引入基于大语言模型的多层次API可用性评估框架。

Result: 实验结果表明，新基准测试在现有平台上表现出优越性。

Conclusion: 新基准测试解决了现有问题，为图分析平台性能评估提供了更全面的工具。

Abstract: The rise of graph analytics platforms has led to the development of various
benchmarks for evaluating and comparing platform performance. However, existing
benchmarks often fall short of fully assessing performance due to limitations
in core algorithm selection, data generation processes (and the corresponding
synthetic datasets), as well as the neglect of API usability evaluation. To
address these shortcomings, we propose a novel graph analytics benchmark.
First, we select eight core algorithms by extensively reviewing both academic
and industrial settings. Second, we design an efficient and flexible data
generator and produce eight new synthetic datasets as the default datasets for
our benchmark. Lastly, we introduce a multi-level large language model
(LLM)-based framework for API usability evaluation-the first of its kind in
graph analytics benchmarks. We conduct comprehensive experimental evaluations
on existing platforms (GraphX, PowerGraph, Flash, Grape, Pregel+, Ligra and
G-thinker). The experimental results demonstrate the superiority of our
proposed benchmark.

</details>


### [207] [A Survey of LLM Inference Systems](https://arxiv.org/abs/2506.21901)
*James Pan,Guoliang Li*

Main category: cs.DB

TL;DR: 本文综述了大型语言模型（LLM）推理系统中的关键技术，包括请求处理、模型优化、内存管理等，并探讨了如何将这些技术整合为单副本和多副本推理系统。


<details>
  <summary>Details</summary>
Motivation: 由于LLM的自回归特性，需要新的技术来在高负载和高速度的工作中保持高性能和推理质量。

Method: 综述了从请求处理算法到内存管理的多种技术，包括内核设计、批处理、调度、分页内存等。

Result: 这些技术依赖于负载预测、自适应机制和成本降低，以克服自回归生成的挑战。

Conclusion: 讨论了如何整合这些技术构建推理系统，并指出了剩余挑战。

Abstract: The past few years has witnessed specialized large language model (LLM)
inference systems, such as vLLM, SGLang, Mooncake, and DeepFlow, alongside
rapid LLM adoption via services like ChatGPT. Driving these system design
efforts is the unique autoregressive nature of LLM request processing,
motivating new techniques for achieving high performance while preserving high
inference quality over high-volume and high-velocity workloads. While many of
these techniques are discussed across the literature, they have not been
analyzed under the framework of a complete inference system, nor have the
systems themselves been analyzed and compared.
  In this survey, we review these techniques, starting from operators and
algorithms for request processing, then moving on to techniques for model
optimization and execution, including kernel design, batching, and scheduling,
before ending with techniques for memory management, including paged memory,
eviction and offloading techniques, quantization, and cache persistence.
Through these discussions, we show that these techniques fundamentally rely on
load prediction, adaptive mechanisms, and cost reduction in order to overcome
the challenges introduced by autoregressive generation and achieve the goals of
the system. We then discuss how these techniques can be combined to form
single-replica and multi-replica inference systems, including disaggregated
inference systems that offer more control over resource allocation and
serverless systems that can be deployed over shared hardware infrastructure. We
end with a discussion of remaining challenges.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [208] [SiPipe: Bridging the CPU-GPU Utilization Gap for Efficient Pipeline-Parallel LLM Inference](https://arxiv.org/abs/2506.22033)
*Yongchao He,Bohan Zhao,Zheng Cao*

Main category: cs.DC

TL;DR: SiPipe是一种异构管道设计，通过利用未充分利用的CPU资源卸载辅助计算和通信，提高大型语言模型（LLM）推理吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推理工作负载的增加，管道并行（PP）在多GPU部署中广泛使用，但其存在执行效率低下的问题，如负载不平衡和阶段间/阶段内气泡，限制了管道饱和。

Method: SiPipe采用三种关键技术：CPU采样、令牌安全执行模型和结构感知传输，以减少管道气泡并提高执行效率。

Result: 在相同PP配置下，SiPipe相比vLLM实现了高达2.1倍的吞吐量提升、43%的每令牌延迟降低和23%的平均GPU利用率提升。

Conclusion: SiPipe在多种LLM和部署场景中表现出广泛的适用性和高效性。

Abstract: As inference workloads for large language models (LLMs) scale to meet growing
user demand, pipeline parallelism (PP) has become a widely adopted strategy for
multi-GPU deployment, particularly in cross-node setups, to improve key-value
(KV) cache capacity and inference throughput. However, PP suffers from inherent
inefficiencies caused by three types of execution bubbles-load-imbalance,
intra-stage, and inter-stage-which limit pipeline saturation. We present
SiPipe, a heterogeneous pipeline design that improves throughput by leveraging
underutilized CPU resources to offload auxiliary computation and communication.
SiPipe incorporates three key techniques-CPU sampling, a token-safe execution
model, and structure-aware transmission-to mitigate pipeline bubbles and
improve execution efficiency. Across diverse LLMs, SiPipe achieves up to 2.1
times higher throughput, 43% lower per-token latency, and up to 23% higher
average GPU utilization compared to the state-of-the-art vLLM under the same PP
configuration, demonstrating its generality across LLMs and deployment
scenarios.

</details>


### [209] [SPTCStencil: Unleashing Sparse Tensor Cores for Stencil Computation via Strided Swap](https://arxiv.org/abs/2506.22035)
*Qiqi GU,Chenpeng Wu,Heng Shi,Jianguo Yao*

Main category: cs.DC

TL;DR: SPTCStencil利用稀疏张量核心（SpTCs）优化了模板计算，消除了冗余零填充，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前针对张量核心加速器的模板计算优化技术因冗余零填充导致高开销，需解决这一问题。

Method: 提出稀疏计算范式，将模板计算高效转换为矩阵乘法，并通过稀疏化策略适配SpTCs，同时优化GPU内核。

Result: 实验显示SPTCStencil平均性能提升5.46倍，优于基于张量核心的方法2倍。

Conclusion: SPTCStencil首次将SpTCs应用于深度学习以外的领域，显著提升了模板计算效率。

Abstract: Stencil computation, a pivotal numerical method in science and engineering,
iteratively updates grid points using weighted neighbor contributions and
exhibits strong parallelism for multi-core processors. Current optimization
techniques targeting conducting stencil computation on tensor core accelerators
incur substantial overheads due to redundant zero-padding during the
transformation to matrix multiplication. To address this, we introduce a sparse
computation paradigm that eliminates inefficiencies by exploiting specialized
hardware units.
  This paper exploits the sparsity in these matrices as a feature and presents
SPTCStencil, a high-performance stencil computation system accelerated by
Sparse Tensor Core (SpTCs). SPTCStencil is the first to harness SpTCs for
acceleration beyond deep learning domains. First, Our approach generalizes an
efficient transformation of stencil computation into matrix multiplications and
specializes this conversion for SpTC compatibility through a novel
sparsification strategy. Furthermore, SPTCStencil incorporates a
high-performance GPU kernel with systematic optimizations designed to maximize
efficiency on SpTCs. Experimental evaluations demonstrate that SPTCStencil
5.46$\times$ and Tensor Core-based approaches by 2.00$\times$ on average.

</details>


### [210] [MCFuser: High-Performance and Rapid Fusion of Memory-Bound Compute-Intensive Operators](https://arxiv.org/abs/2506.22169)
*Zheng Zhang,Donglin Yang,Xiaobo Zhou,Dazhao Cheng*

Main category: cs.DC

TL;DR: MCFuser是一个框架，用于高效融合内存密集型计算操作符，通过优化搜索空间和减少冗余内存访问，显著提升性能并缩短调优时间。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法在多计算密集型操作符融合时存在性能瓶颈、冗余内存访问和调优时间长的问题，MCFuser旨在解决这些挑战。

Method: MCFuser利用高级平铺表达式定义搜索空间，结合DAG分析消除冗余内存访问，并通过启发式搜索和性能模型加速优化。

Result: 在NVIDIA A100和RTX3080 GPU上，MCFuser性能提升达5.9倍，调优时间减少70倍以上。

Conclusion: MCFuser通过创新方法显著提升了操作符融合的效率和性能，适用于内存密集型计算任务。

Abstract: Operator fusion, a key technique to improve data locality and alleviate GPU
memory bandwidth pressure, often fails to extend to the fusion of multiple
compute-intensive operators due to saturated computation throughput. However,
the dynamicity of tensor dimension sizes could potentially lead to these
operators becoming memory-bound, necessitating the generation of fused kernels,
a task hindered by limited search spaces for fusion strategies, redundant
memory access, and prolonged tuning time, leading to sub-optimal performance
and inefficient deployment.
  We introduce MCFuser, a pioneering framework designed to overcome these
obstacles by generating high-performance fused kernels for what we define as
memory-bound compute-intensive (MBCI) operator chains. Leveraging high-level
tiling expressions to delineate a comprehensive search space, coupled with
Directed Acyclic Graph (DAG) analysis to eliminate redundant memory accesses,
MCFuser streamlines kernel optimization. By implementing guidelines to prune
the search space and incorporating an analytical performance model with a
heuristic search, MCFuser not only significantly accelerates the tuning process
but also demonstrates superior performance. Benchmarked against leading
compilers like Ansor on NVIDIA A100 and RTX3080 GPUs, MCFuser achieves up to a
5.9x speedup in kernel performance and outpaces other baselines while reducing
tuning time by over 70-fold, showcasing its agility.

</details>


### [211] [Proof-of-Behavior: Behavior-Driven Consensus for Trustworthy Decentralized Finance](https://arxiv.org/abs/2506.22171)
*Ailiya Borjigin,Wei Zhou,Cong He*

Main category: cs.DC

TL;DR: Proof-of-Behavior (PoB) 是一种新型共识模型，通过行为评分和动态验证权重提升区块链的安全性和公平性，显著减少欺诈行为。


<details>
  <summary>Details</summary>
Motivation: 现有区块链协议（如PoW和PoS）无法衡量验证者的可信度，导致在DeFi等场景中难以防范隐蔽的恶意行为。

Method: PoB通过分层行为评分（动机和结果）、动态调整验证者权重以及去中心化验证与惩罚机制，设计激励兼容的奖励机制。

Result: 模拟实验显示，PoB将欺诈接受率降低90%以上，快速识别恶意验证者，并提升提案公平性，吞吐量开销不超过5%。

Conclusion: PoB通过将共识影响力与可验证的信任行为挂钩，为金融应用提供了可扩展且合规的区块链治理基础。

Abstract: Current blockchain protocols (e.g., Proof-of-Work and Proof-of-Stake) secure
the ledger yet cannot measure validator trustworthiness, allowing subtle
misconduct that is especially damaging in decentralized-finance (DeFi)
settings. We introduce Proof-of-Behavior (PoB), a consensus model that (i)
gives each action a layered utility score -- covering motivation and outcome,
(ii) adapts validator weights using recent scores, and (iii) applies
decentralized verification with proportional slashing. The reward design is
incentive-compatible, yielding a Nash equilibrium in which honest behavior
maximizes long-run pay-offs. Simulated DeFi experiments (loan-fraud detection,
reputation-weighted validation) show that PoB cuts fraud acceptance by more
than 90%, demotes malicious validators within two rounds, and improves proposer
fairness versus standard PoS, all with no more than a 5% throughput overhead.
By linking consensus influence to verifiably trustworthy conduct, PoB offers a
scalable, regulation-friendly foundation for secure and fair blockchain
governance in financial applications.

</details>


### [212] [MPipeMoE: Memory Efficient MoE for Pre-trained Models with Adaptive Pipeline Parallelism](https://arxiv.org/abs/2506.22175)
*Zheng Zhang,Donglin Yang,Yaqi Xia,Liang Ding,Dacheng Tao,Xiaobo Zhou,Dazhao Cheng*

Main category: cs.DC

TL;DR: MPipeMoE是一个高性能库，通过自适应和内存高效的流水线并行加速MoE训练，实现2.8倍加速和47%内存减少。


<details>
  <summary>Details</summary>
Motivation: 解决MoE训练中通信和内存消耗的低效问题。

Method: 设计自适应流水线并行和内存重用策略，减少内存冗余。

Result: 在8台NVIDIA DGX A100服务器上测试，MPipeMoE比现有方法快2.8倍，内存减少47%。

Conclusion: MPipeMoE显著提升MoE训练效率和内存利用率。

Abstract: Recently, Mixture-of-Experts (MoE) has become one of the most popular
techniques to scale pre-trained models to extraordinarily large sizes. Dynamic
activation of experts allows for conditional computation, increasing the number
of parameters of neural networks, which is critical for absorbing the vast
amounts of knowledge available in many deep learning areas. However, despite
the existing system and algorithm optimizations, there are significant
challenges to be tackled when it comes to the inefficiencies of communication
and memory consumption.
  In this paper, we present the design and implementation of MPipeMoE, a
high-performance library that accelerates MoE training with adaptive and
memory-efficient pipeline parallelism. Inspired by that the MoE training
procedure can be divided into multiple independent sub-stages, we design
adaptive pipeline parallelism with an online algorithm to configure the
granularity of the pipelining. Further, we analyze the memory footprint
breakdown of MoE training and identify that activations and temporary buffers
are the primary contributors to the overall memory footprint. Toward memory
efficiency, we propose memory reusing strategies to reduce memory requirements
by eliminating memory redundancies, and develop an adaptive selection component
to determine the optimal strategy that considers both hardware capacities and
model characteristics at runtime. We implement MPipeMoE upon PyTorch and
evaluate it with common MoE models in a physical cluster consisting of 8 NVIDIA
DGX A100 servers. Compared with the state-of-art approach, MPipeMoE achieves up
to 2.8x speedup and reduces memory footprint by up to 47% in training large
models.

</details>


### [213] [Towards Operational Data Analytics Chatbots -- Virtual Knowledge Graph is All You Need](https://arxiv.org/abs/2506.22267)
*Junaid Ahmed Khan,Hiari Pizzini Cavagna,Andrea Proia,Andrea Bartolini*

Main category: cs.DC

TL;DR: 论文提出了一种基于虚拟知识图谱（VKG）和大型语言模型（LLM）的端到端ODA聊天机器人系统，显著提高了查询效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的发展，数据中心的规模和复杂性增加，计算效率变得至关重要。传统方法在查询无模式的NoSQL数据库时效率低下，需要一种更高效的方法。

Method: 利用虚拟知识图谱（VKG）动态生成查询特定图谱，并结合大型语言模型（LLM）生成SPARQL查询，优化了数据检索过程。

Result: 系统实现了92.5%的查询准确率（相比NoSQL直接查询的25%），并将查询延迟从20.36秒降至3.03秒，同时VKG大小控制在179 MiB以内。

Conclusion: 该方法显著提升了ODA系统的实时交互能力，适合实际部署。

Abstract: With generative artificial intelligence challenging computational scientific
computing, data centers are experiencing unprecedented growth in both scale and
volume. As a result, computing efficiency has become more critical than ever.
Operational Data Analytics (ODA) relies on the collection of data center
telemetry to improve efficiency, but so far has been focusing on real-time
telemetry data visualization and post-mortem analysis. However, with NoSQL
databases now serving as the default storage backend to support scalability,
querying this data is challenging due to its schema-less nature, which requires
domain knowledge to traverse relationships between data sources. Ontologies and
Knowledge Graphs (KGs) can capture these relationships, but traditional KGs are
costly to scale and have not been widely applied to multivariate timeseries.
Virtual Knowledge Graphs (VKGs) offer a lightweight alternative by generating
query-specific graphs at runtime. In this work, we present a full end-to-end
ODA chatbot system that uses a Large Language Model (LLM) to generate SPARQL
queries, utilizing VKG for data retrieval. This approach achieves 92.5%
accuracy compared to 25% with direct NoSQL queries. The proposed methodology
optimizes VKG construction and LLM inference, cutting previous work average
query latency by 85% (from 20.36s to 3.03s) and keeping VKG sizes under 179
MiB. This performance makes the tool suitable for deployment and real-time
interaction with ODA end-users.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [214] [Joint Task Offloading and Resource Allocation in Low-Altitude MEC via Graph Attention Diffusion](https://arxiv.org/abs/2506.21933)
*Yifan Xue,Ruihuai Liang,Bo Yang,Xuelin Cao,Zhiwen Yu,Mérouane Debbah,Chau Yuen*

Main category: cs.NI

TL;DR: 本文提出了一种基于图注意力扩散的解决方案生成器（GADSG），用于解决低空经济网络中任务卸载和资源分配的联合优化问题。该方法结合了图注意力网络的上下文感知能力和扩散模型的解分布学习能力，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 随着低空经济的快速发展，空地一体化多接入边缘计算（MEC）系统对实时和智能任务调度的需求日益增加，但面临节点异构性、通信链路不稳定和任务动态变化等挑战。

Method: 构建了一个三层异构MEC系统架构，通过图结构化建模任务，提出GADSG方法，结合图注意力网络和扩散模型进行联合优化。

Result: 实验表明，GADSG在优化性能、鲁棒性和泛化能力上显著优于基线方法。

Conclusion: GADSG在动态复杂的低空经济网络环境中展现出高效任务调度的潜力。

Abstract: With the rapid development of the low-altitude economy, air-ground integrated
multi-access edge computing (MEC) systems are facing increasing demands for
real-time and intelligent task scheduling. In such systems, task offloading and
resource allocation encounter multiple challenges, including node
heterogeneity, unstable communication links, and dynamic task variations. To
address these issues, this paper constructs a three-layer heterogeneous MEC
system architecture for low-altitude economic networks, encompassing aerial and
ground users as well as edge servers. The system is systematically modeled from
the perspectives of communication channels, computational costs, and constraint
conditions, and the joint optimization problem of offloading decisions and
resource allocation is uniformly abstracted into a graph-structured modeling
task. On this basis, we propose a graph attention diffusion-based solution
generator (GADSG). This method integrates the contextual awareness of graph
attention networks with the solution distribution learning capability of
diffusion models, enabling joint modeling and optimization of discrete
offloading variables and continuous resource allocation variables within a
high-dimensional latent space. We construct multiple simulation datasets with
varying scales and topologies. Extensive experiments demonstrate that the
proposed GADSG model significantly outperforms existing baseline methods in
terms of optimization performance, robustness, and generalization across task
structures, showing strong potential for efficient task scheduling in dynamic
and complex low-altitude economic network environments.

</details>


### [215] [Resilient Communication For Avalanche Response in Infrastructure-Limited Environments](https://arxiv.org/abs/2506.22148)
*Joshua Goulton,Milena Radenkovic*

Main category: cs.NI

TL;DR: 论文研究了利用瑞士铁路网络作为数据骨干网，通过DTN协议（Epidemic和PROPHET）传播关键雪崩警报的可行性。实验证明铁路网络在两种场景下均能提供稳定的通信。


<details>
  <summary>Details</summary>
Motivation: 在基础设施有限的自然灾害环境中，DTN为维持通信提供了可能。本文旨在验证利用现有交通系统（如瑞士铁路）作为数据骨干网的可行性。

Method: 使用ONE模拟器建模瑞士铁路网络，并比较Epidemic和PROPHET两种DTN路由协议在两种场景（城市中心和偏远山区）下的表现。

Result: 实验结果表明，铁路网络在两种环境中均能为机会性通信提供稳定的连接。

Conclusion: 验证了DTN原则在偏远场景中的适用性，铁路网络可作为有效的通信骨干网。

Abstract: Delay Tolerant Networks (DTNs) offer a promising paradigm for maintaining
communication in infrastructure limited environments, such as those encountered
during natural disasters. This paper investigates the viability of leveraging
an existing national transport system - the Swiss rail network - as a data mule
backbone for disseminating critical avalanche alerts. Using The Opportunistic
Network Environment (ONE) simulator, we model the entire Swiss rail network and
conduct a rigorous comparative analysis of two seminal DTN routing protocols:
Epidemic and PROPHET. Experiments are performed in two distinct scenarios:
alerts originating from dense urban centres and from sparse, remote mountainous
regions. Our results demonstrate that the rail network provides robust
connectivity for opportunistic communication in both environments thus
validating the integration of DTN principles in remote scenarios.

</details>


### [216] [V2X Intention Sharing for Cooperative Electrically Power-Assisted Cycles](https://arxiv.org/abs/2506.22223)
*Felipe Valle Quiroz,Johan Elfing,Joel Pålsson,Elena Haller,Oscar Amador Molina*

Main category: cs.NI

TL;DR: 论文提出了一种新型的意图共享机制，用于V2X通信框架中的电动助力自行车（EPACs），通过改进ETSI VRU感知消息（VAM）协议，用紧凑的椭圆地理区域表示替代离散预测轨迹点。


<details>
  <summary>Details</summary>
Motivation: 提升电动助力自行车在V2X通信中的意图共享效率，增强网络可靠性和安全性。

Method: 采用二次多项式拟合和最小二乘法（LSM）生成紧凑的椭圆地理区域表示，固定数据负载，支持高频传输。

Result: 仿真显示在受限通信条件下优于标准ETSI VAM，物理实验验证了嵌入式系统的实时部署可行性。

Conclusion: 该方法支持可扩展、低延迟的意图共享，为V2X生态系统中的弱势道路用户提供更安全的协作感知。

Abstract: This paper introduces a novel intention-sharing mechanism for Electrically
Power-Assisted Cycles (EPACs) within V2X communication frameworks, enhancing
the ETSI VRU Awareness Message (VAM) protocol. The method replaces discrete
predicted trajectory points with a compact elliptical geographical area
representation derived via quadratic polynomial fitting and Least Squares
Method (LSM). This approach encodes trajectory predictions with fixed-size data
payloads, independent of the number of forecasted points, enabling
higher-frequency transmissions and improved network reliability. Simulation
results demonstrate superior inter-packet gap (IPG) performance compared to
standard ETSI VAMs, particularly under constrained communication conditions. A
physical experiment validates the feasibility of real-time deployment on
embedded systems. The method supports scalable, low-latency intention sharing,
contributing to cooperative perception and enhanced safety for vulnerable road
users in connected and automated mobility ecosystems. Finally, we discuss the
viability of LSM and open the door to other methods for prediction.

</details>


### [217] [Design and Evaluation of IEEE 802.11ax Uplink Orthogonal Frequency Division Multiple Random Access in ns-3](https://arxiv.org/abs/2506.22260)
*Douglas Dziedzorm Agbeve,Andrey Belogaev,Jeroen Famaey*

Main category: cs.NI

TL;DR: 论文提出了一种完全符合标准且开源的UORA实现，解决了现有ns-3模拟器中UORA实现的关键限制，提升了资源分配的效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 随着Wi-Fi网络密度增加和新兴应用对低延迟、高可靠性的需求，EDCA机制的局限性日益明显，而现有UORA研究多依赖非公开模拟器，限制了结果的可复现性。

Method: 开发了一个完全符合标准的开源UORA实现，解决了ns-3模拟器中现有UORA实现的关键问题，如资源调度和配置信号缺失。

Result: 实现了更高效和灵活的UORA资源分配，为未来Wi-Fi资源分配策略研究提供了更准确的评估工具。

Conclusion: 该开源实现提升了UORA研究的可复现性和灵活性，为Wi-Fi资源分配的未来研究奠定了基础。

Abstract: Wi-Fi networks have long relied on the Enhanced Distributed Channel Access
(EDCA) mechanism, allowing stations to compete for transmission opportunities.
However, as networks become denser and emerging applications demand lower
latency and higher reliability, the limitations of EDCA such as overhead due to
contention and collisions have become more pronounced. To address these
challenges, Orthogonal Frequency Division Multiple Access (OFDMA) has been
introduced in Wi-Fi, enabling more efficient channel utilization through
scheduled resource allocation. Furthermore, Wi-Fi 6 defines Uplink Orthogonal
Frequency Division Multiple Random Access (UORA), a hybrid mechanism that
combines both scheduled and random access, balancing efficiency and
responsiveness in resource allocation. Despite significant research on UORA,
most studies rely on custom simulators that are not publicly available,
limiting reproducibility and preventing validation of the presented results.
The only known open-source UORA implementation in the ns-3 simulator exhibits
key limitations, such as usage of the same trigger frame (TF) to schedule
resources for buffer status reports and data transmissions, and lack of
signaling for UORA configuration. In this paper, we present a fully
standard-compliant and open source UORA implementation that is compatible with
ns-3 version 3.38, addressing these limitations to improve resource allocation
efficiency and adaptability. This implementation enables more accurate and
flexible evaluation of UORA, fostering future research on Wi-Fi resource
allocation strategies.

</details>


### [218] [Concept-Level AI for Telecom: Moving Beyond Large Language Models](https://arxiv.org/abs/2506.22359)
*Viswanath Kumarskandpriya,Abdulhalim Dandoush,Abbas Bradai,Ali Belgacem*

Main category: cs.NI

TL;DR: 论文探讨了在电信和网络领域，大型概念模型（LCMs）比大型语言模型（LLMs）更适合解决复杂、多层次的电信管理问题。


<details>
  <summary>Details</summary>
Motivation: 电信领域面临复杂、多层次的网络管理挑战，而LLMs由于处理方式的局限性无法满足需求，因此需要更高效的解决方案。

Method: 提出使用LCMs，通过语义概念层面的推理和双曲潜在空间的层次表示，解决LLMs在跨层依赖、时空故障关联和实时分布式协调方面的不足。

Result: LCMs在内存效率、跨层关联和原生多模态集成方面优于LLMs，为电信管理提供了更有效的AI驱动方案。

Conclusion: 采用LCMs是实现稳健高效AI驱动电信管理的必要进化步骤。

Abstract: The telecommunications and networking domain stands at the precipice of a
transformative era, driven by the necessity to manage increasingly complex,
hierarchical, multi administrative domains (i.e., several operators on the same
path) and multilingual systems. Recent research has demonstrated that Large
Language Models (LLMs), with their exceptional general-purpose text analysis
and code generation capabilities, can be effectively applied to certain telecom
problems (e.g., auto-configuration of data plan to meet certain application
requirements). However, due to their inherent token-by-token processing and
limited capacity for maintaining extended context, LLMs struggle to fulfill
telecom-specific requirements such as cross-layer dependency cascades (i.e.,
over OSI), temporal-spatial fault correlation, and real-time distributed
coordination. In contrast, Large Concept Models (LCMs), which reason at the
abstraction level of semantic concepts rather than individual lexical tokens,
offer a fundamentally superior approach for addressing these telecom
challenges. By employing hyperbolic latent spaces for hierarchical
representation and encapsulating complex multi-layered network interactions
within concise concept embeddings, LCMs overcome critical shortcomings of LLMs
in terms of memory efficiency, cross-layer correlation, and native multimodal
integration. This paper argues that adopting LCMs is not simply an incremental
step, but a necessary evolutionary leap toward achieving robust and effective
AI-driven telecom management.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [219] [How (Not) To Write a Software Engineering Abstract](https://arxiv.org/abs/2506.21634)
*Lutz Prechelt,Lloyd Montgomery,Julian Frattini,Franz Zieris*

Main category: cs.SE

TL;DR: 论文分析了高质量软件工程会议摘要的结构，发现大多数摘要不完整或存在问题，建议采用结构化格式以提高质量。


<details>
  <summary>Details</summary>
Motivation: 研究高质量软件工程会议摘要的结构，观察其不足，并提出改进指南。

Method: 通过定性开放编码和定量内容分析，分析了362篇摘要的结构，并比较了典型结构与实际结构。

Result: 仅29%的摘要完整，结构化摘要的比例更高（58%），仅4%的摘要完全符合标准。

Conclusion: 高质量会议摘要仍有改进空间，结构化格式更优，需推广通用结论。

Abstract: Background: Abstracts are a particularly valuable element in a software
engineering research article. However, not all abstracts are as informative as
they could be. Objective: Characterize the structure of abstracts in
high-quality software engineering venues. Observe and quantify deficiencies.
Suggest guidelines for writing informative abstracts. Methods: Use qualitative
open coding to derive concepts that explain relevant properties of abstracts.
Identify the archetypical structure of abstracts. Use quantitative content
analysis to objectively characterize abstract structure of a sample of 362
abstracts from five presumably high-quality venues. Use exploratory data
analysis to find recurring issues in abstracts. Compare the archetypical
structure to actual structures. Infer guidelines for producing informative
abstracts. Results: Only 29% of the sampled abstracts are complete, i.e.,
provide background, objective, method, result, and conclusion information. For
structured abstracts, the ratio is twice as big. Only 4% of the abstracts are
proper, i.e., they also have good readability (Flesch-Kincaid score) and have
no informativeness gaps, understandability gaps, nor highly ambiguous
sentences. Conclusions: (1) Even in top venues, a large majority of abstracts
are far from ideal. (2) Structured abstracts tend to be better than
unstructured ones. (3) Artifact-centric works need a different structured
format. (4) The community should start requiring conclusions that generalize,
which currently are often missing in abstracts.

</details>


### [220] [Autonomic Microservice Management via Agentic AI and MAPE-K Integration](https://arxiv.org/abs/2506.22185)
*Matteo Esposito,Alexander Bakhtin,Noman Ahmad,Mikel Robredo,Ruoyu Su,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: 提出基于MAPE-K和AI的框架，用于微服务的自主异常检测与修复，提升系统稳定性和安全性。


<details>
  <summary>Details</summary>
Motivation: 微服务的去中心化特性带来安全和管理的挑战，威胁系统稳定性。

Method: 基于MAPE-K框架，利用智能代理AI实现自主异常检测与修复。

Result: 提供实用的行业解决方案，增强系统稳定性、减少停机时间，并监控性能、弹性等质量属性。

Conclusion: 该框架可定制，适用于研究和实践，提升微服务系统的整体质量。

Abstract: While microservices are revolutionizing cloud computing by offering
unparalleled scalability and independent deployment, their decentralized nature
poses significant security and management challenges that can threaten system
stability. We propose a framework based on MAPE-K, which leverages agentic AI,
for autonomous anomaly detection and remediation to address the daunting task
of highly distributed system management. Our framework offers practical,
industry-ready solutions for maintaining robust and secure microservices.
Practitioners and researchers can customize the framework to enhance system
stability, reduce downtime, and monitor broader system quality attributes such
as system performance level, resilience, security, and anomaly management,
among others.

</details>


### [221] [Experience converting a large mathematical software package written in C++ to C++20 modules](https://arxiv.org/abs/2506.21654)
*Wolfgang Bangerth*

Main category: cs.SE

TL;DR: 论文探讨了将大型数学软件包从传统的C++头文件接口转换为C++20模块系统的可行性，以deal.II有限元库为例，展示了转换的挑战和实际效果。


<details>
  <summary>Details</summary>
Motivation: 传统的C++头文件接口方式笨拙、不可靠且缓慢，C++20引入的模块系统提供了更高效的替代方案。

Method: 通过deal.II库（约80万行代码）的实例，研究如何同时支持头文件和模块接口，分析转换过程中的技术挑战和实际效果。

Result: 转换到模块系统是可行的，能减少库自身的编译时间，但对下游项目的编译时间影响不明确。

Conclusion: 尽管转换需要一定努力，但模块系统为数学软件生态的长期改进提供了方向。

Abstract: Mathematical software has traditionally been built in the form of "packages"
that build on each other. A substantial fraction of these packages is written
in C++ and, as a consequence, the interface of a package is described in the
form of header files that downstream packages and applications can then
#include. C++ has inherited this approach towards exporting interfaces from C,
but the approach is clunky, unreliable, and slow. As a consequence, C++20 has
introduced a "module" system in which packages explicitly export declarations
and code that compilers then store in machine-readable form and that downstream
users can "import" -- a system in line with what many other programming
languages have used for decades.
  Herein, I explore how one can convert large mathematical software packages
written in C++ to this system, using the deal.II finite element library with
its around 800,000 lines of code as an example. I describe an approach that
allows providing both header-based and module-based interfaces from the same
code base, discuss the challenges one encounters, and how modules actually work
in practice in a variety of technical and human metrics. The results show that
with a non-trivial, but also not prohibitive effort, the conversion to modules
is possible, resulting in a reduction in compile time for the converted library
itself; on the other hand, for downstream projects, compile times show no clear
trend. I end with thoughts about long-term strategies for converting the entire
ecosystem of mathematical software over the coming years or decades.

</details>


### [222] [Can Large Language Models Help Students Prove Software Correctness? An Experimental Study with Dafny](https://arxiv.org/abs/2506.22370)
*Carolina Carreira,Álvaro Silva,Alexandre Abreu,Alexandra Mendes*

Main category: cs.SE

TL;DR: 论文研究了学生在使用ChatGPT解决Dafny形式验证练习时的表现，发现使用ChatGPT的学生表现更好，但效果与提示质量相关。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（如ChatGPT）在支持认知密集型任务（如程序验证）中的作用。

Method: 通过混合方法研究，让硕士生在形式方法课程中完成验证问题，一组使用ChatGPT，另一组不使用，并记录交互。

Result: 使用ChatGPT的学生表现显著更好，但表现提升与提示质量相关。

Conclusion: 建议在形式方法课程中更有效地整合LLM，设计促进学习的LLM感知挑战。

Abstract: Students in computing education increasingly use large language models (LLMs)
such as ChatGPT. Yet, the role of LLMs in supporting cognitively demanding
tasks, like deductive program verification, remains poorly understood. This
paper investigates how students interact with an LLM when solving formal
verification exercises in Dafny, a language that supports functional
correctness, by allowing programmers to write formal specifications and
automatically verifying that the implementation satisfies the specification. We
conducted a mixed-methods study with master's students enrolled in a formal
methods course. Each participant completed two verification problems, one with
access to a custom ChatGPT interface, that logged all interactions, and the
other without. We identified strategies used by successful students and
assessed the level of trust students place in LLMs. %\todo{Our findings show
that something here} Our findings show that students perform significantly
better when using ChatGPT; however, performance gains are tied to prompt
quality. We conclude with practical recommendations for integrating LLMs into
formal methods courses more effectively, including designing LLM-aware
challenges that promote learning rather than substitution.

</details>


### [223] [The DevSafeOps Dilemma: A Systematic Literature Review on Rapidity in Safe Autonomous Driving Development and Operation](https://arxiv.org/abs/2506.21693)
*Ali Nouri,Beatriz Cabrero-Daniel,Fredrik Törner,Christian Berger*

Main category: cs.SE

TL;DR: 论文探讨了在自动驾驶开发中应用DevOps的挑战与解决方案，指出仍需解决多个开放性问题以实现安全的DevOps。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统复杂且需确保安全可靠运行，DevOps方法有望支持AI技术的持续进步和快速响应需求。

Method: 通过系统性文献综述，识别、分析和综合了与自动驾驶开发中DevOps应用相关的广泛文献。

Result: 研究结果提供了挑战与解决方案的结构化概述，并指出仍需解决多个开放性问题。

Conclusion: DevOps在自动驾驶开发中的应用仍需进一步研究以实现安全可靠的开发流程。

Abstract: Developing autonomous driving (AD) systems is challenging due to the
complexity of the systems and the need to assure their safe and reliable
operation. The widely adopted approach of DevOps seems promising to support the
continuous technological progress in AI and the demand for fast reaction to
incidents, which necessitate continuous development, deployment, and
monitoring. We present a systematic literature review meant to identify,
analyse, and synthesise a broad range of existing literature related to usage
of DevOps in autonomous driving development. Our results provide a structured
overview of challenges and solutions, arising from applying DevOps to
safety-related AI-enabled functions. Our results indicate that there are still
several open topics to be addressed to enable safe DevOps for the development
of safe AD.

</details>


### [224] [Using Generative AI in Software Design Education: An Experience Report](https://arxiv.org/abs/2506.21703)
*Victoria Jackson,Susannah Liu,Andre van der Hoek*

Main category: cs.SE

TL;DR: 论文探讨了在本科软件设计课程中引入生成式AI（如ChatGPT）的实践经验，分析了学生使用AI完成团队作业的效果及其对设计过程的帮助。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI工具的快速普及，软件工程教育者需要探索如何将其有效融入课堂，尤其是在软件设计等非编程领域。

Method: 学生在团队作业中使用ChatGPT，收集对话日志和反思，并进行定性分析。

Result: 学生发现ChatGPT在设计过程中提供了帮助，但也意识到需要批判性评估其回答。同时，研究为教育者提供了有效部署AI的关键经验。

Conclusion: 生成式AI在软件设计教育中具有潜力，能帮助学生设计并了解AI的优势与局限。

Abstract: With the rapid adoption of Generative AI (GenAI) tools, software engineering
educators have grappled with how best to incorporate them into the classroom.
While some research discusses the use of GenAI in the context of learning to
code, there is little research that explores the use of GenAI in the classroom
for other areas of software development. This paper provides an experience
report on introducing GenAI into an undergraduate software design class.
Students were required to use GenAI (in the form of ChatGPT) to help complete a
team-based assignment. The data collected consisted of the ChatGPT conversation
logs and students' reflections on using ChatGPT for the assignment.
Subsequently, qualitative analysis was undertaken on the data. Students
identified numerous ways ChatGPT helped them in their design process while
recognizing the need to critique the response before incorporating it into
their design. At the same time, we identified several key lessons for educators
in how to deploy GenAI in a software design class effectively. Based on our
experience, we believe students can benefit from using GenAI in software design
education as it helps them design and learn about the strengths and weaknesses
of GenAI.

</details>


### [225] [KARMA Approach supporting Development Process Reconstruction in Model-based Systems Engineering](https://arxiv.org/abs/2506.22037)
*Jiawei Li,Zan Liang,Guoxin Wang,Jinzhi Lu,Yan Yan,Shouxuan Wu,Hao Wang*

Main category: cs.SE

TL;DR: 提出了一种基于KARMA语言和GOPPRR-E元建模方法的模型重构方法，用于支持系统开发过程模型的重构，显著提升设计效率。


<details>
  <summary>Details</summary>
Motivation: 当前系统迭代设计过程中缺乏有效管理开发需求变化的方法，如开发周期和成本需求，需要实现系统开发过程模型的重构。

Method: 利用KARMA语言统一形式化不同建模语言构建的过程模型，引入模型重构框架，通过自然语言处理分析需求文本，提取结构和优化约束信息，经重组和优化算法得到满足需求的开发过程模型。

Result: 以飞机机载维护系统开发过程为例，验证了该方法能显著提升开发过程的设计效率。

Conclusion: 该方法有效解决了开发需求变化管理问题，提升了模型重构的效率和实用性。

Abstract: Model reconstruction is a method used to drive the development of complex
system development processes in model-based systems engineering. Currently,
during the iterative design process of a system, there is a lack of an
effective method to manage changes in development requirements, such as
development cycle requirements and cost requirements, and to realize the
reconstruction of the system development process model. To address these
issues, this paper proposes a model reconstruction method to support the
development process model. Firstly, the KARMA language, based on the GOPPRR-E
metamodeling method, is utilized to uniformly formalize the process models
constructed based on different modeling languages. Secondly, a model
reconstruction framework is introduced. This framework takes a structured
development requirements based natural language as input, employs natural
language processing techniques to analyze the development requirements text,
and extracts structural and optimization constraint information. Then, after
structural reorganization and algorithm optimization, a development process
model that meets the development requirements is obtained. Finally, as a case
study, the development process of the aircraft onboard maintenance system is
reconstructed. The results demonstrate that this method can significantly
enhance the design efficiency of the development process.

</details>


### [226] [What Makes ChatGPT Effective for Software Issue Resolution? An Empirical Study of Developer-ChatGPT Conversations in GitHub](https://arxiv.org/abs/2506.22390)
*Ramtin Ehsani,Sakshi Pathak,Esteban Parra,Sonia Haiduc,Preetha Chatterjee*

Main category: cs.SE

TL;DR: 分析了686个开发者与ChatGPT的对话，发现62%对问题解决有帮助，ChatGPT在代码生成和工具推荐上表现较好，但在代码解释上较弱。


<details>
  <summary>Details</summary>
Motivation: 研究开发者与ChatGPT对话的有效性，以优化问题解决工具的设计。

Method: 分类对话任务，分析对话、项目和问题相关指标，识别有效对话的特征和常见缺陷。

Result: 62%的对话有帮助，ChatGPT在代码生成和工具推荐上表现最佳，但在代码解释上较弱。

Conclusion: 研究结果为开发者提供了互动策略建议，并指导优化LLM的设计和微调。

Abstract: Conversational large-language models are extensively used for issue
resolution tasks. However, not all developer-LLM conversations are useful for
effective issue resolution. In this paper, we analyze 686 developer-ChatGPT
conversations shared within GitHub issue threads to identify characteristics
that make these conversations effective for issue resolution. First, we analyze
the conversations and their corresponding issues to distinguish helpful from
unhelpful conversations. We begin by categorizing the types of tasks developers
seek help with to better understand the scenarios in which ChatGPT is most
effective. Next, we examine a wide range of conversational, project, and
issue-related metrics to uncover factors associated with helpful conversations.
Finally, we identify common deficiencies in unhelpful ChatGPT responses to
highlight areas that could inform the design of more effective developer-facing
tools. We found that only 62% of the ChatGPT conversations were helpful for
successful issue resolution. ChatGPT is most effective for code generation and
tools/libraries/APIs recommendations, but struggles with code explanations.
Helpful conversations tend to be shorter, more readable, and exhibit stronger
semantic and linguistic alignment. Larger, more popular projects and more
experienced developers benefit more from ChatGPT. At the issue level, ChatGPT
performs best on simpler problems with limited developer activity and faster
resolution, typically well-scoped tasks like compilation errors. The most
common deficiencies in unhelpful ChatGPT responses include incorrect
information and lack of comprehensiveness. Our findings have wide implications
including guiding developers on effective interaction strategies for issue
resolution, informing the development of tools or frameworks to support optimal
prompt design, and providing insights on fine-tuning LLMs for issue resolution
tasks.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [227] [Optimal Estimation of Two-Way Effects under Limited Mobility](https://arxiv.org/abs/2506.21987)
*Xu Cheng,Sheng Chao Ho,Frank Schorfheide*

Main category: econ.EM

TL;DR: 提出一种基于经验贝叶斯的双向效应估计器，利用数据中的匹配模式，通过最小化无偏风险估计确定超参数，证明其渐近最优性，并应用于教师增值评估。


<details>
  <summary>Details</summary>
Motivation: 针对关联数据集中的双向效应估计问题，利用数据中的匹配模式和有限流动性，提出一种更优的估计方法。

Method: 基于二分图模型，利用拉普拉斯矩阵的小特征值特性，通过经验贝叶斯方法确定先验超参数。

Result: 证明估计器在复合损失下渐近最优，适用于弱连通二分图和先验可能错误的情况。

Conclusion: 该方法在教师增值评估中表现出色，为类似问题提供了有效解决方案。

Abstract: We propose an empirical Bayes estimator for two-way effects in linked data
sets based on a novel prior that leverages patterns of assortative matching
observed in the data. To capture limited mobility we model the bipartite graph
associated with the matched data in an asymptotic framework where its Laplacian
matrix has small eigenvalues that converge to zero. The prior hyperparameters
that control the shrinkage are determined by minimizing an unbiased risk
estimate. We show the proposed empirical Bayes estimator is asymptotically
optimal in compound loss, despite the weak connectivity of the bipartite graph
and the potential misspecification of the prior. We estimate teacher
values-added from a linked North Carolina Education Research Data Center
student-teacher data set.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [228] [Monetary Macro Accounting Theory](https://arxiv.org/abs/2506.21651)
*Renéee Menéndez,Viktor Winschel*

Main category: econ.GN

TL;DR: 提出了一种货币宏观会计理论（MoMaT）及其软件规范，用于一致的国民经济核算，强调货币作为支付债务的媒介而非交换媒介。


<details>
  <summary>Details</summary>
Motivation: 解决传统货币理论中货币作为交换媒介的局限性，关注债务关系及其在宏观经济中的作用。

Method: 应用法律原则（分离与抽象）建模债务、合同、产权和货币，构建三层次（微观、中观、宏观）货币系统模型，并以汇票（BoE）为核心工具。

Result: 提出了一个多层次的BoE框架，支持流动性交换、投资和背书，适用于区块链智能合约和AI自动化。

Conclusion: MoMaT为区块链经济理论、货币政策和供应链金融提供了新的分析工具，具有广泛的应用潜力。

Abstract: We develop a monetary macro accounting theory (MoMaT) and its software
specification for a consistent national accounting. In our money theory money
functions primarily as a medium of payment for obligations and debts, not as a
medium of exchange, originating from the temporal misalignment where producers
pay suppliers before receiving revenue. MoMaT applies the legal principles of
Separation and Abstraction to model debt, contracts, property rights, and money
to understand their nature. Monetary systems according to our approach operate
at three interconnected levels: micro (division of labor), meso (banking for
risk-sharing), and macro (GDP sharing, money issuance). Critical to money
theory are macro debt relations, hence the model focuses not on the circulation
of money but on debt vortices: the ongoing creation and resolution of financial
obligations. The Bill of Exchange (BoE) acts as a unifying contractual
instrument, linking debt processes and monetary issuance across fiat and
gold-based systems. A multi-level BoE framework enables liquidity exchange,
investments, and endorsements, designed for potential implementation in
blockchain smart contracts and AI automation to improve borrowing transparency.
Mathematical rigor can be ensured through category theory and sheaf theory for
invariances between economic levels and homology theory for monetary policy
foundations. Open Games can structure macroeconomic analysis with multi-agent
models, making MoMaT applicable to blockchain economic theory, monetary policy,
and supply chain finance.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [229] [Independence Axioms in Social Ranking](https://arxiv.org/abs/2506.21836)
*Takahiro Suzuki,Michele Aleandri,Stefano Moretti*

Main category: econ.TH

TL;DR: 论文研究了社会排名解决方案（SRSs）中的独立性公理，分析了七种独立性公理（其中两种为新提出的），并通过替换公理对词典卓越解和多数解进行了新表征。


<details>
  <summary>Details</summary>
Motivation: 独立性公理在社交选择理论中具有重要意义，可以减少非必要数据的分析成本。研究旨在深入理解独立性公理在社会排名解决方案中的应用。

Method: 研究分析了七种独立性公理（包括两种新公理），并通过替换公理对词典卓越解和多数解进行了新表征。

Result: 研究提供了词典卓越解和多数解的新表征，突出了三种社会排名解决方案在独立性方面的差异。

Conclusion: 研究通过分析独立性公理，为社会排名解决方案提供了新的理论支持，并揭示了不同解决方案在独立性上的区别。

Abstract: Independence from non-essential changes in input information is a widely
recognized axiom in social choice theory. This independence reduces the cost of
specifying and/or analyzing non-essential data. This study makes a
comprehensive analysis of independence axioms in the context of social ranking
solutions (SRSs). We consider seven independence axioms (two of which are new)
and provide a novel characterization of the lexicographic excellence solution
and plurality by substituting these independence axioms in the existing
characterization of the intersection initial segment rule. The
characterizations highlight the differences among the three SRSs in terms of
independence.

</details>
