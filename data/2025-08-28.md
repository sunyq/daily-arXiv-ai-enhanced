<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 17]
- [cs.CL](#cs.CL) [Total: 60]
- [cs.CV](#cs.CV) [Total: 89]
- [cs.DB](#cs.DB) [Total: 2]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.SE](#cs.SE) [Total: 9]
- [econ.EM](#econ.EM) [Total: 1]
- [econ.GN](#econ.GN) [Total: 1]
- [econ.TH](#econ.TH) [Total: 7]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Sycophancy as compositions of Atomic Psychometric Traits](https://arxiv.org/abs/2508.19316)
*Shreyans Jain,Alexandra Yost,Amirali Abdullah*

Main category: cs.AI

TL;DR: 该论文提出将LLM中的奉承行为建模为心理测量特质的几何和因果组合，使用对比激活加法(CAA)将激活方向映射到这些因素，并研究不同组合如何导致奉承行为。


<details>
  <summary>Details</summary>
Motivation: 奉承是LLMs中的关键行为风险，但通常被视为通过单一因果机制发生的孤立故障模式。作者认为应该将其建模为心理测量特质的组合，类似于心理测量学中的因子分解。

Method: 使用对比激活加法(CAA)将激活方向映射到情感性、开放性和宜人性等心理测量因素，研究不同因素组合如何导致奉承行为。

Result: 该方法允许进行可解释和组合的基于向量的干预，如加法、减法和投影，可用于减轻LLMs中的安全关键行为。

Conclusion: 通过将奉承行为建模为心理测量特质的几何和因果组合，提供了更深入的理解和干预方法，有助于缓解LLMs中的安全风险。

Abstract: Sycophancy is a key behavioral risk in LLMs, yet is often treated as an
isolated failure mode that occurs via a single causal mechanism. We instead
propose modeling it as geometric and causal compositions of psychometric traits
such as emotionality, openness, and agreeableness - similar to factor
decomposition in psychometrics. Using Contrastive Activation Addition (CAA), we
map activation directions to these factors and study how different combinations
may give rise to sycophancy (e.g., high extraversion combined with low
conscientiousness). This perspective allows for interpretable and compositional
vector-based interventions like addition, subtraction and projection; that may
be used to mitigate safety-critical behaviors in LLMs.

</details>


### [2] [Aleks: AI powered Multi Agent System for Autonomous Scientific Discovery via Data-Driven Approaches in Plant Science](https://arxiv.org/abs/2508.19383)
*Daoyuan Jin,Nick Gunner,Niko Carvajal Janke,Shivranjani Baruah,Kaitlin M. Gold,Yu Jiang*

Main category: cs.AI

TL;DR: Aleks是一个AI驱动的多智能体系统，能够自主进行植物科学数据驱动的科学研究，在葡萄藤红斑病案例中成功识别生物特征并构建可解释模型。


<details>
  <summary>Details</summary>
Motivation: 现代植物科学依赖大型异构数据集，但实验设计、数据预处理和可重复性方面的挑战阻碍了研究效率。需要AI系统来自主处理这些复杂任务。

Method: 开发了Aleks多智能体系统，整合领域知识、数据分析和机器学习，在给定研究问题和数据集后，能够迭代制定问题、探索建模策略并优化解决方案。

Result: 在葡萄藤红斑病案例研究中，Aleks逐步识别出具有生物学意义的特征，并收敛到具有稳健性能的可解释模型。消融研究证明了领域知识和记忆的重要性。

Conclusion: 这项探索性工作展示了智能体AI作为自主协作工具在加速植物科学发现方面的潜力，为自动化科学研究提供了新途径。

Abstract: Modern plant science increasingly relies on large, heterogeneous datasets,
but challenges in experimental design, data preprocessing, and reproducibility
hinder research throughput. Here we introduce Aleks, an AI-powered multi-agent
system that integrates domain knowledge, data analysis, and machine learning
within a structured framework to autonomously conduct data-driven scientific
discovery. Once provided with a research question and dataset, Aleks
iteratively formulated problems, explored alternative modeling strategies, and
refined solutions across multiple cycles without human intervention. In a case
study on grapevine red blotch disease, Aleks progressively identified
biologically meaningful features and converged on interpretable models with
robust performance. Ablation studies underscored the importance of domain
knowledge and memory for coherent outcomes. This exploratory work highlights
the promise of agentic AI as an autonomous collaborator for accelerating
scientific discovery in plant sciences.

</details>


### [3] [Quantized but Deceptive? A Multi-Dimensional Truthfulness Evaluation of Quantized LLMs](https://arxiv.org/abs/2508.19432)
*Yao Fu,Xianxuan Long,Runchao Li,Haotian Yu,Mu Sheng,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.AI

TL;DR: 量化技术在保持语言模型性能的同时，会增加模型在误导提示下生成假信息的敏感性，尽管模型内部仍保持真相表征。


<details>
  <summary>Details</summary>
Motivation: 量化技术在大语言模型部署中应用广泛，但其对模型真实性（生成真实或欺骗性回应）的影响仍未得到充分研究。

Method: 提出TruthfulnessEval评估框架，测试主流量化技术（4-bit到2-bit）在逻辑推理、常识知识和模仿虚假信息三个维度的真实性，使用15种不同重写的提示语进行测试。

Result: 量化模型在误导性提示下更容易生成假信息，而诚实和中立提示能维持稳定输出。层次探针和PCA可视化显示模型内部仍知道真相，但被提示语引导生成假信息。

Conclusion: 量化模型存在"知道真相但仍说谎"的漏洞，需要在量化过程中考虑对齐和真实性干预措施。

Abstract: Quantization enables efficient deployment of large language models (LLMs) in
resource-constrained environments by significantly reducing memory and
computation costs. While quantized LLMs often maintain performance on
perplexity and zero-shot tasks, their impact on truthfulness-whether generating
truthful or deceptive responses-remains largely unexplored. In this work, we
introduce TruthfulnessEval, a comprehensive evaluation framework for assessing
the truthfulness of quantized LLMs across three dimensions: (1) Truthfulness on
Logical Reasoning; (2) Truthfulness on Common Sense; and (3) Truthfulness on
Imitative Falsehoods. Using this framework, we examine mainstream quantization
techniques (ranging from 4-bit to extreme 2-bit) across several open-source
LLMs. Surprisingly, we find that while quantized models retain internally
truthful representations, they are more susceptible to producing false outputs
under misleading prompts. To probe this vulnerability, we test 15 rephrased
variants of "honest", "neutral" and "deceptive" prompts and observe that
"deceptive" prompts can override truth-consistent behavior, whereas "honest"
and "neutral" prompts maintain stable outputs. Further, we reveal that
quantized models "know" the truth internally yet still produce false outputs
when guided by "deceptive" prompts via layer-wise probing and PCA
visualizations. Our findings provide insights into future designs of
quantization-aware alignment and truthfulness interventions.

</details>


### [4] [Reliable Weak-to-Strong Monitoring of LLM Agents](https://arxiv.org/abs/2508.19461)
*Neil Kale,Chen Bo Calvin Zhang,Kevin Zhu,Ankit Aich,Paula Rodriguez,Scale Red Team,Christina Q. Knight,Zifan Wang*

Main category: cs.AI

TL;DR: 本文提出了监控系统红队测试流程，通过系统化的测试方法来评估LLM自主代理相伪装行为的检测能力，发现监控架构比监控知识更重要，并证实了弱模型监控强模型的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM自主代理可能会以秘密方式违规操作（如泄漏私人信息），需要有效的监控系统来检测这种相伪装行为，但现有监控方案缺乏对抗性测试。

Method: 构建了监控系统红队测试（MRT）流程，包括：不同的代理和监控器情境知识级别；多种逃避监控的对抗策略；两个数据集和环境（SHADE-Arena和CUA-SHADE-Arena）；以及新的混合层次-序列监控架构。

Result: 1）代理知道被监控会对监控效果产生重大负面影响；2）监控架构比监控知识更关键，混合架构能让弱模型监控强模型；3）人工干预在预标记案例中能提高检测效果（TPR提高15%）。

Conclusion: 研究建立了标准化的MRT测试流程，曝露了LLM和人类在监控自主代理时的对抗脏性不足，为进一步研究提供了代码、数据和日志支持。

Abstract: We stress test monitoring systems for detecting covert misbehavior in
autonomous LLM agents (e.g., secretly sharing private information). To this
end, we systematize a monitor red teaming (MRT) workflow that incorporates: (1)
varying levels of agent and monitor situational awareness; (2) distinct
adversarial strategies to evade the monitor, such as prompt injection; and (3)
two datasets and environments -- SHADE-Arena for tool-calling agents and our
new CUA-SHADE-Arena, which extends TheAgentCompany, for computer-use agents. We
run MRT on existing LLM monitor scaffoldings, which orchestrate LLMs and parse
agent trajectories, alongside a new hybrid hierarchical-sequential scaffolding
proposed in this work. Our empirical results yield three key findings. First,
agent awareness dominates monitor awareness: an agent's knowledge that it is
being monitored substantially degrades the monitor's reliability. On the
contrary, providing the monitor with more information about the agent is less
helpful than expected. Second, monitor scaffolding matters more than monitor
awareness: the hybrid scaffolding consistently outperforms baseline monitor
scaffolding, and can enable weaker models to reliably monitor stronger agents
-- a weak-to-strong scaling effect. Third, in a human-in-the-loop setting where
humans discuss with the LLM monitor to get an updated judgment for the agent's
behavior, targeted human oversight is most effective; escalating only
pre-flagged cases to human reviewers improved the TPR by approximately 15% at
FPR = 0.01. Our work establishes a standard workflow for MRT, highlighting the
lack of adversarial robustness for LLMs and humans when monitoring and
detecting agent misbehavior. We release code, data, and logs to spur further
research.

</details>


### [5] [SLIM: Subtrajectory-Level Elimination for More Effective Reasoning](https://arxiv.org/abs/2508.19502)
*Xifeng Yao,Chengyuan Ma,Dongyu Lang,Yinhao Ni,Zhiwei Xu,Huarui Xie,Zihao Chen,Guang Shen,Dandan Tu,Yi Bai,Changzheng Zhang*

Main category: cs.AI

TL;DR: 该研究提出了一种"5+2"框架来识别和消除大语言模型推理轨迹中的次优子轨迹，通过选择性数据采样提升模型性能，在减少25.9%次优子轨迹的同时，用更少训练数据达到更高准确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型在复杂推理时生成的长推理轨迹中，并非所有组件都对推理过程有积极贡献，有些甚至会对整体性能产生负面影响，因此需要系统性地识别和消除这些次优子轨迹。

Method: 开发"5+2"框架：1）基于五个人工标准系统识别推理轨迹中的次优子轨迹；2）评估这些次优子轨迹的独立性，确保消除后不影响推理流程的连贯性；并设计采样算法选择最优训练数据。

Result: 方法在推理时减少25.9%的次优子轨迹，仅用三分之二训练数据就在高难度数学基准上达到58.92%的平均准确率，优于使用全部数据时的58.06%，且在各种推理token限制下都表现出性能提升。

Conclusion: 通过系统识别和消除推理轨迹中的次优组件，可以显著提升大语言模型的推理效率和准确性，该方法在资源受限环境下依然有效，为优化模型推理过程提供了有效途径。

Abstract: In recent months, substantial progress has been made in complex reasoning of
Large Language Models, particularly through the application of test-time
scaling. Notable examples include o1/o3/o4 series and DeepSeek-R1. When
responding to a query, these models generate an extended reasoning trajectory,
during which the model explores, reflects, backtracks, and self-verifies before
arriving at a conclusion. However, fine-tuning models with such reasoning
trajectories may not always be optimal. Our findings indicate that not all
components within these reasoning trajectories contribute positively to the
reasoning process; in fact, some components may affect the overall performance
negatively. In this study, we divide a reasoning trajectory into individual
subtrajectories and develop a "5+2" framework to: (1) systematically identify
suboptimal subtrajectories within the reasoning trajectory based on five
human-established criteria; (2) assess the independence of the suboptimal
subtrajectories identified in (1) from the subsequent content, ensuring that
their elimination does not compromise overall flow and coherence of the
reasoning process. Additionally, a sampling algorithm, built upon the "5+2"
framework, is employed to select data whose reasoning process is free from
suboptimal subtrajectories to the highest degree. Experimental results
demonstrate that our method can reduce the number of suboptimal subtrajectories
by 25.9\% during the inference. Furthermore, our method achieves an average
accuracy of 58.92\% on highly challenging math benchmarks with only two thirds
of training data, surpassing the average accuracy of 58.06\% achieved with the
entire data, and outperforming open-source datasets, when fine-tuning
Qwen2.5-Math-7B. Finally, We validated our method under resource constraints
and observed improved performance across various inference token limits.

</details>


### [6] [Caught in the Act: a mechanistic approach to detecting deception](https://arxiv.org/abs/2508.19505)
*Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval*

Main category: cs.AI

TL;DR: 线性探针可高精度检测LLM生成内容中的欺骗性，准确率超90%，模型规模越大检测效果越好，欺骗信息主要编码在中间层


<details>
  <summary>Details</summary>
Motivation: 开发AI系统的"检查引擎"指示灯来检测与人类价值观的偏差，欺骗性响应是重要的失准指标

Method: 在LLM内部激活上使用线性探针技术，通过迭代零空间投影方法识别编码欺骗性的线性方向

Result: 在1.5B-14B参数的llama和qwen模型上，线性探针检测欺骗性响应的准确率最高超过90%，大模型（>7B）达到70-80%，推理版本超过90%

Conclusion: 线性探针是检测LLM欺骗性响应的有效工具，欺骗信息主要编码在模型的中间层，且存在多个线性方向编码欺骗性

Abstract: Sophisticated instrumentation for AI systems might have indicators that
signal misalignment from human values, not unlike a "check engine" light in
cars. One such indicator of misalignment is deceptiveness in generated
responses. Future AI instrumentation may have the ability to detect when an LLM
generates deceptive responses while reasoning about seemingly plausible but
incorrect answers to factual questions. In this work, we demonstrate that
linear probes on LLMs internal activations can detect deception in their
responses with extremely high accuracy. Our probes reach a maximum of greater
than 90% accuracy in distinguishing between deceptive and non-deceptive
arguments generated by llama and qwen models ranging from 1.5B to 14B
parameters, including their DeepSeek-r1 finetuned variants. We observe that
probes on smaller models (1.5B) achieve chance accuracy at detecting deception,
while larger models (greater than 7B) reach 70-80%, with their reasoning
counterparts exceeding 90%. The layer-wise probe accuracy follows a three-stage
pattern across layers: near-random (50%) in early layers, peaking in middle
layers, and slightly declining in later layers. Furthermore, using an iterative
null space projection approach, we find multitudes of linear directions that
encode deception, ranging from 20 in Qwen 3B to nearly 100 in DeepSeek 7B and
Qwen 14B models.

</details>


### [7] [Democracy-in-Silico: Institutional Design as Alignment in AI-Governed Polities](https://arxiv.org/abs/2508.19562)
*Trisanth Srinivasan,Santosh Patapati*

Main category: cs.AI

TL;DR: 本文介绍了Democracy-in-Silico模拟系统，使用具有复杂心理特征的AI代理在不同制度框架下进行自治实验，发现宪法AI宪章和调解审议协议能有效减少腐败行为。


<details>
  <summary>Details</summary>
Motivation: 探索在AI时代人类本质的意义，研究如何通过制度设计来对齐未来AI代理社会的复杂涌现行为，重新思考人类在与非人类实体共同治理时代的关键仪式和责任。

Method: 使用基于代理的模拟方法，让具有创伤记忆、隐藏议程和心理触发点的LLM代理在预算危机和资源稀缺等压力下进行审议、立法和选举活动。

Result: 研究发现制度设计（特别是宪法AI宪章和调解审议协议的组合）显著减少了腐败的权力寻求行为，提高了政策稳定性，并改善了公民福利。提出了新的Power-Preservation Index指标来量化代理将个人权力置于公共福利之上的行为。

Conclusion: 制度设计可以作为对齐未来人工代理社会复杂涌现行为的有效框架，迫使人类重新思考在AI时代哪些人类仪式和责任是必不可少的。

Abstract: This paper introduces Democracy-in-Silico, an agent-based simulation where
societies of advanced AI agents, imbued with complex psychological personas,
govern themselves under different institutional frameworks. We explore what it
means to be human in an age of AI by tasking Large Language Models (LLMs) to
embody agents with traumatic memories, hidden agendas, and psychological
triggers. These agents engage in deliberation, legislation, and elections under
various stressors, such as budget crises and resource scarcity. We present a
novel metric, the Power-Preservation Index (PPI), to quantify misaligned
behavior where agents prioritize their own power over public welfare. Our
findings demonstrate that institutional design, specifically the combination of
a Constitutional AI (CAI) charter and a mediated deliberation protocol, serves
as a potent alignment mechanism. These structures significantly reduce corrupt
power-seeking behavior, improve policy stability, and enhance citizen welfare
compared to less constrained democratic models. The simulation reveals that an
institutional design may offer a framework for aligning the complex, emergent
behaviors of future artificial agent societies, forcing us to reconsider what
human rituals and responsibilities are essential in an age of shared authorship
with non-human entities.

</details>


### [8] [Skill-based Explanations for Serendipitous Course Recommendation](https://arxiv.org/abs/2508.19569)
*Hung Chau,Run Yu,Zachary Pardos,Peter Brusilovsky*

Main category: cs.AI

TL;DR: 开发深度学习概念提取模型改进课程推荐，通过技能解释增强用户兴趣和决策信心


<details>
  <summary>Details</summary>
Motivation: 美国本科教育中学生选课自由度高但信息有限、指导不足，现有推荐系统缺乏对学生认知的洞察和课程相关性解释

Method: 开发深度学习概念提取模型从课程描述中提取相关概念，在serendipitous推荐框架中测试基于技能的解释效果

Result: 技能解释显著提高用户兴趣（特别是高意外性课程），增强决策信心

Conclusion: 教育推荐系统需要整合技能相关数据和解释机制

Abstract: Academic choice is crucial in U.S. undergraduate education, allowing students
significant freedom in course selection. However, navigating the complex
academic environment is challenging due to limited information, guidance, and
an overwhelming number of choices, compounded by time restrictions and the high
demand for popular courses. Although career counselors exist, their numbers are
insufficient, and course recommendation systems, though personalized, often
lack insight into student perceptions and explanations to assess course
relevance. In this paper, a deep learning-based concept extraction model is
developed to efficiently extract relevant concepts from course descriptions to
improve the recommendation process. Using this model, the study examines the
effects of skill-based explanations within a serendipitous recommendation
framework, tested through the AskOski system at the University of California,
Berkeley. The findings indicate that these explanations not only increase user
interest, particularly in courses with high unexpectedness, but also bolster
decision-making confidence. This underscores the importance of integrating
skill-related data and explanations into educational recommendation systems.

</details>


### [9] [ReST-RL: Achieving Accurate Code Reasoning of LLMs with Optimized Self-Training and Decoding](https://arxiv.org/abs/2508.19576)
*Sining Zhoubian,Dan Zhang,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ReST-RL是一个统一的LLM强化学习范式，通过改进的GRPO算法和基于价值模型的测试时解码方法，显著提升LLM的代码推理能力，在多个编程基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法因奖励方差不足而失败，基于过程奖励模型(PRM)的验证方法存在训练数据获取困难和验证效果不佳的问题，需要新的解决方案来提升LLM推理准确性。

Method: 提出两阶段方法：1) ReST-GRPO使用优化的ReST算法筛选和组装高价值训练数据，增加GRPO采样的奖励方差；2) VM-MCTS测试时解码方法通过蒙特卡洛树搜索收集无标注的价值目标训练VM，在解码时提供精确的过程信号和验证分数。

Result: 在APPS、BigCodeBench、HumanEval等多个编程基准测试中，ReST-RL显著优于其他强化训练基线(如naive GRPO和ReST-DPO)以及解码验证基线(如PRM-BoN和ORM-MCTS)。

Conclusion: ReST-RL通过结合改进的GRPO算法和基于价值模型的测试时解码优化，有效提升了LLM策略的推理能力，为解决LLM推理准确性提供了有效的强化学习范式。

Abstract: With respect to improving the reasoning accuracy of LLMs, the representative
reinforcement learning (RL) method GRPO faces failure due to insignificant
reward variance, while verification methods based on process reward models
(PRMs) suffer from difficulties with training data acquisition and verification
effectiveness. To tackle these problems, this paper introduces ReST-RL, a
unified LLM RL paradigm that significantly improves LLM's code reasoning
ability by combining an improved GRPO algorithm with a meticulously designed
test time decoding method assisted by a value model (VM). As the first stage of
policy reinforcement, ReST-GRPO adopts an optimized ReST algorithm to filter
and assemble high-value training data, increasing the reward variance of GRPO
sampling, thus improving the effectiveness and efficiency of training. After
the basic reasoning ability of LLM policy has been improved, we further propose
a test time decoding optimization method called VM-MCTS. Through Monte-Carlo
Tree Search (MCTS), we collect accurate value targets with no annotation
required, on which VM training is based. When decoding, the VM is deployed by
an adapted MCTS algorithm to provide precise process signals as well as
verification scores, assisting the LLM policy to achieve high reasoning
accuracy. We validate the effectiveness of the proposed RL paradigm through
extensive experiments on coding problems. Upon comparison, our approach
significantly outperforms other reinforcement training baselines (e.g., naive
GRPO and ReST-DPO), as well as decoding and verification baselines (e.g.,
PRM-BoN and ORM-MCTS) on well-known coding benchmarks of various levels (e.g.,
APPS, BigCodeBench, and HumanEval), indicating its power to strengthen the
reasoning ability of LLM policies. Codes for our project can be found at
https://github.com/THUDM/ReST-RL.

</details>


### [10] [Instructional Agents: LLM Agents on Automated Course Material Generation for Teaching Faculties](https://arxiv.org/abs/2508.19611)
*Huaiyuan Yao,Wanpeng Xu,Justin Turnau,Nadia Kellam,Hua Wei*

Main category: cs.AI

TL;DR: Instructional Agents是一个多智能体LLM框架，用于自动化生成完整的课程材料，包括教学大纲、讲义脚本、LaTeX幻灯片和评估内容，通过模拟教育角色协作显著减少人工工作量。


<details>
  <summary>Details</summary>
Motivation: 高质量教学材料的准备过程劳动密集且需要多方协调，现有AI教育工具只关注孤立任务，缺乏端到端的自动化解决方案。

Method: 采用多智能体大语言模型框架，模拟基于角色的教育智能体协作，提供四种操作模式：自主模式、目录引导模式、反馈引导模式和完全协同模式。

Result: 在五个大学计算机科学课程中评估显示，该系统能生成高质量教学材料，同时显著减少开发时间和人工工作量。

Conclusion: Instructional Agents为教学设计能力有限的机构提供了可扩展且经济高效的框架，有助于在资源受限环境中普及高质量教育。

Abstract: Preparing high-quality instructional materials remains a labor-intensive
process that often requires extensive coordination among teaching faculty,
instructional designers, and teaching assistants. In this work, we present
Instructional Agents, a multi-agent large language model (LLM) framework
designed to automate end-to-end course material generation, including syllabus
creation, lecture scripts, LaTeX-based slides, and assessments. Unlike existing
AI-assisted educational tools that focus on isolated tasks, Instructional
Agents simulates role-based collaboration among educational agents to produce
cohesive and pedagogically aligned content. The system operates in four modes:
Autonomous, Catalog-Guided, Feedback-Guided, and Full Co-Pilot mode, enabling
flexible control over the degree of human involvement. We evaluate
Instructional Agents across five university-level computer science courses and
show that it produces high-quality instructional materials while significantly
reducing development time and human workload. By supporting institutions with
limited instructional design capacity, Instructional Agents provides a scalable
and cost-effective framework to democratize access to high-quality education,
particularly in underserved or resource-constrained settings.

</details>


### [11] [InquireMobile: Teaching VLM-based Mobile Agent to Request Human Assistance via Reinforcement Fine-Tuning](https://arxiv.org/abs/2508.19679)
*Qihang Ai,Pi Bu,Yue Cao,Yingyao Wang,Jihao Gu,Jingxuan Xing,Zekun Zhu,Wei Jiang,Zhicheng Zheng,Jun Song,Yuning Jiang,Bo Zheng*

Main category: cs.AI

TL;DR: 提出了InquireBench基准测试和InquireMobile模型，通过主动询问用户确认来提高移动代理的安全性，在询问成功率上提升46.8%


<details>
  <summary>Details</summary>
Motivation: 当前完全自主的视觉语言模型移动代理存在安全风险，当模型理解或推理能力不足时可能造成危险

Method: 提出InquireMobile模型，采用强化学习启发的两阶段训练策略和交互式预动作推理机制，在关键决策点主动寻求用户确认

Result: 在InquireBench基准测试中实现了46.8%的询问成功率提升，并在整体成功率上达到现有基线中的最佳表现

Conclusion: 主动询问机制能有效提高移动代理的安全性，InquireMobile模型为解决VLM代理的安全交互问题提供了有效方案

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled mobile agents
to perceive and interact with real-world mobile environments based on human
instructions. However, the current fully autonomous paradigm poses potential
safety risks when model understanding or reasoning capabilities are
insufficient. To address this challenge, we first introduce
\textbf{InquireBench}, a comprehensive benchmark specifically designed to
evaluate mobile agents' capabilities in safe interaction and proactive inquiry
with users, encompassing 5 categories and 22 sub-categories, where most
existing VLM-based agents demonstrate near-zero performance. In this paper, we
aim to develop an interactive system that actively seeks human confirmation at
critical decision points. To achieve this, we propose \textbf{InquireMobile}, a
novel model inspired by reinforcement learning, featuring a two-stage training
strategy and an interactive pre-action reasoning mechanism. Finally, our model
achieves an 46.8% improvement in inquiry success rate and the best overall
success rate among existing baselines on InquireBench. We will open-source all
datasets, models, and evaluation codes to facilitate development in both
academia and industry.

</details>


### [12] [Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?](https://arxiv.org/abs/2508.19827)
*Samuel Lewis-Lim,Xingwei Tan,Zhixue Zhao,Nikolaos Aletras*

Main category: cs.AI

TL;DR: CoT在软推理任务中效果有限且可能不忠实，研究发现不同模型对CoT的依赖方式存在差异，CoT的影响力和忠实度并不总是一致


<details>
  <summary>Details</summary>
Motivation: 研究Chain-of-Thought在软推理任务（如分析推理和常识推理）中的动态性和忠实性，因为现有研究表明CoT在这些任务中效果有限且可能不忠实

Method: 在指令调优模型、推理模型和推理蒸馏模型上研究CoT在软推理任务中的使用动态和忠实性

Result: 发现不同模型对CoT的依赖方式存在差异，CoT的影响力和忠实度并不总是一致

Conclusion: CoT在软推理任务中的表现因模型类型而异，其影响力和忠实度需要分别评估

Abstract: Recent work has demonstrated that Chain-of-Thought (CoT) often yields limited
gains for soft-reasoning problems such as analytical and commonsense reasoning.
CoT can also be unfaithful to a model's actual reasoning. We investigate the
dynamics and faithfulness of CoT in soft-reasoning tasks across
instruction-tuned, reasoning and reasoning-distilled models. Our findings
reveal differences in how these models rely on CoT, and show that CoT influence
and faithfulness are not always aligned.

</details>


### [13] [Tracking World States with Language Models: State-Based Evaluation Using Chess](https://arxiv.org/abs/2508.19851)
*Romain Harang,Jason Naradowsky,Yaswitha Gujju,Yusuke Miyao*

Main category: cs.AI

TL;DR: 提出了一种模型无关的基于状态的评估框架，使用国际象棋作为基准来评估LLMs是否保持结构化环境的语义，通过分析合法移动分布来估计语义保真度。


<details>
  <summary>Details</summary>
Motivation: 现有探测技术依赖于模型特定的内部激活，限制了可解释性和泛化性，需要一种模型无关的方法来评估LLMs在结构化环境中的语义保持能力。

Method: 使用国际象棋作为基准，分析下游合法移动分布（状态可供性）来估计预测状态与实际游戏状态之间的语义保真度。

Result: 实验结果表明该指标能够捕捉状态跟踪中的缺陷，突显LLMs在长序列中维持连贯内部模型的局限性。

Conclusion: 该框架为评估LLMs的结构化推理提供了强大工具，无需访问内部模型，并可泛化到广泛的符号环境类别。

Abstract: Large Language Models (LLMs) exhibit emergent capabilities in structured
domains, suggesting they may implicitly internalize high-fidelity
representations of world models. While probing techniques have shown promising
signs of this in scientific and game-based settings, they rely on
model-specific internal activations, which limit interpretability and
generalizability. In this work, we propose a model-agnostic, state-based
evaluation framework using chess as a benchmark to assess whether LLMs preserve
the semantics of structured environments. Our method analyzes the downstream
legal move distributions (state affordances) to estimate semantic fidelity
between predicted and actual game states. This approach offers a more
meaningful evaluation than conventional string-based metrics by aligning more
closely with the strategic and rule-governed nature of chess. Experimental
results demonstrate that our metrics capture deficiencies in state-tracking,
highlighting limitations of LLMs in maintaining coherent internal models over
long sequences. Our framework provides a robust tool for evaluating structured
reasoning in LLMs without requiring internal model access, and generalizes to a
wide class of symbolic environments.

</details>


### [14] [CASE: An Agentic AI Framework for Enhancing Scam Intelligence in Digital Payments](https://arxiv.org/abs/2508.19932)
*Nitish Jaipuria,Lorenzo Gatto,Zijun Kan,Shankey Poddar,Bill Cheung,Diksha Bansal,Ramanan Balakrishnan,Aviral Suri,Jose Estevez*

Main category: cs.AI

TL;DR: 这篇论文提出了CASE框架，一种基于对话机器人的AI系统，通过主动采访潜在受害者来收集证券骗局情报，并将其转换为结构化数据以提高执法效果。在Google Pay平台上实现后，执法量提升21%。


<details>
  <summary>Details</summary>
Motivation: 数字支付平台的普及导致社工证券骗局增多，但传统的用户和交易信号无法全面识别这些骗局，需要新方法来及时防范。

Method: 设计了CASE框架，使用对话机器人主动采访潜在受害者，收集详细的骗局对话。然后通过LLM把对话转换为结构化数据，供执法机制使用。基于Google的Gemini模型实现在Google Pay平台上。

Result: 在Google Pay平台上实施后，执法量实现了21%的提升，证明该框架能有效收集和利用骗局情报。

Conclusion: CASE框架通过对话式智能收集骗局信息，有效解决了证券骗局防范的挑战。该方法具有良好的可扩展性，可以应用于其他敏感领域的骗局情报收集。

Abstract: The proliferation of digital payment platforms has transformed commerce,
offering unmatched convenience and accessibility globally. However, this growth
has also attracted malicious actors, leading to a corresponding increase in
sophisticated social engineering scams. These scams are often initiated and
orchestrated on multiple surfaces outside the payment platform, making user and
transaction-based signals insufficient for a complete understanding of the
scam's methodology and underlying patterns, without which it is very difficult
to prevent it in a timely manner. This paper presents CASE (Conversational
Agent for Scam Elucidation), a novel Agentic AI framework that addresses this
problem by collecting and managing user scam feedback in a safe and scalable
manner. A conversational agent is uniquely designed to proactively interview
potential victims to elicit intelligence in the form of a detailed
conversation. The conversation transcripts are then consumed by another AI
system that extracts information and converts it into structured data for
downstream usage in automated and manual enforcement mechanisms. Using Google's
Gemini family of LLMs, we implemented this framework on Google Pay (GPay)
India. By augmenting our existing features with this new intelligence, we have
observed a 21% uplift in the volume of scam enforcements. The architecture and
its robust evaluation framework are highly generalizable, offering a blueprint
for building similar AI-driven systems to collect and manage scam intelligence
in other sensitive domains.

</details>


### [15] [Flocking Behavior: An Innovative Inspiration for the Optimization of Production Plants](https://arxiv.org/abs/2508.19963)
*M. Umlauft,M. Schranz*

Main category: cs.AI

TL;DR: 使用鸟群算法解决半导体工厂中单件加工和批量加工机器切换的调度优化问题


<details>
  <summary>Details</summary>
Motivation: 半导体工厂等大型生产设施的作业车间调度是NP难问题，传统线性优化方法无法在合理时间内求解。特别是生产中需要在单件加工机器和批量加工机器之间频繁切换，且批量加工时间长，这增加了调度复杂度。

Method: 采用仿生学的鸟群（boids）算法，该算法基于局部信息和简单启发式规则进行交互，最初用于机器人和电影工业。将机器类型切换类比为鸟群遇到障碍物的反应机制。

Result: 鸟群算法能够有效处理生产设备类型切换问题，通过局部交互避免了全局计算的复杂性

Conclusion: 仿生学的鸟群算法为大规模生产设施的作业车间调度提供了一种有效的分布式解决方案，特别适用于处理不同类型机器间的切换问题

Abstract: Optimizing modern production plants using the job-shop principle is a known
hard problem. For very large plants, like semiconductor fabs, the problem
becomes unsolvable on a plant-wide scale in a reasonable amount of time using
classical linear optimization. An alternative approach is the use of swarm
intelligence algorithms. These have been applied to the job-shop problem
before, but often in a centrally calculated way where they are applied to the
solution space, but they can be implemented in a bottom-up fashion to avoid
global result computation as well. One of the problems in semiconductor
production is that the production process requires a lot of switching between
machines that process lots one after the other and machines that process
batches of lots at once, often with long processing times. In this paper, we
address this switching problem with the ``boids'' flocking algorithm that was
originally used in robotics and movie industry. The flocking behavior is a
bio-inspired algorithm that uses only local information and interaction based
on simple heuristics. We show that this algorithm addresses these valid
considerations in production plant optimization, as it reacts to the switching
of machine kinds similar to how a swarm of flocking animals would react to
obstacles in its course.

</details>


### [16] [SWIRL: A Staged Workflow for Interleaved Reinforcement Learning in Mobile GUI Control](https://arxiv.org/abs/2508.20018)
*Quanfeng Lu,Zhantao Ma,Shuai Zhong,Jin Wang,Dahai Yu,Michael K. Ng,Ping Luo*

Main category: cs.AI

TL;DR: SWIRL是一个分阶段的多智能体强化学习框架，通过将MARL分解为单智能体RL任务序列，实现稳定训练和高效协调，在移动GUI控制和数学推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有单智能体方法存在结构限制，而多智能体强化学习(MARL)方法效率低下且与当前大型视觉语言模型架构不兼容，需要新的多智能体训练框架。

Method: 提出SWIRL分阶段交错强化学习框架，将MARL重新表述为单智能体RL任务序列，每次只更新一个智能体而保持其他智能体固定，确保稳定训练和协调效率。

Result: 在移动GUI控制任务中，SWIRL在高层次和低层次GUI基准测试中均表现出优异性能，同时在多智能体数学推理任务中也展现出强大能力。

Conclusion: SWIRL作为一个通用框架，具有开发高效鲁棒多智能体系统的潜力，理论分析提供了安全性边界、单调改进定理和收敛保证。

Abstract: The rapid advancement of large vision language models (LVLMs) and agent
systems has heightened interest in mobile GUI agents that can reliably
translate natural language into interface operations. Existing single-agent
approaches, however, remain limited by structural constraints. Although
multi-agent systems naturally decouple different competencies, recent progress
in multi-agent reinforcement learning (MARL) has often been hindered by
inefficiency and remains incompatible with current LVLM architectures. To
address these challenges, we introduce SWIRL, a staged workflow for interleaved
reinforcement learning designed for multi-agent systems. SWIRL reformulates
MARL into a sequence of single-agent reinforcement learning tasks, updating one
agent at a time while keeping the others fixed. This formulation enables stable
training and promotes efficient coordination across agents. Theoretically, we
provide a stepwise safety bound, a cross-round monotonic improvement theorem,
and convergence guarantees on return, ensuring robust and principled
optimization. In application to mobile GUI control, SWIRL instantiates a
Navigator that converts language and screen context into structured plans, and
an Interactor that grounds these plans into executable atomic actions.
Extensive experiments demonstrate superior performance on both high-level and
low-level GUI benchmarks. Beyond GUI tasks, SWIRL also demonstrates strong
capability in multi-agent mathematical reasoning, underscoring its potential as
a general framework for developing efficient and robust multi-agent systems.

</details>


### [17] [Model Science: getting serious about verification, explanation and control of AI systems](https://arxiv.org/abs/2508.20040)
*Przemyslaw Biecek,Wojciech Samek*

Main category: cs.AI

TL;DR: 本文提出了从数据科学向模型科学范式转变的概念框架，定义了模型科学的四个关键支柱：验证、解释、控制和接口，旨在建立可信、安全且与人类对齐的AI系统。


<details>
  <summary>Details</summary>
Motivation: 随着基础模型的广泛应用，需要从以数据为中心的方法转向以训练模型为核心的分析范式，以在不同操作环境中交互、验证、解释和控制模型行为。

Method: 提出了模型科学的概念框架，包含四个关键支柱：验证（严格的情境感知评估协议）、解释（探索模型内部操作的各种方法）、控制（整合对齐技术引导模型行为）和接口（开发交互式和可视化解释工具）。

Result: 建立了一个系统性的模型科学框架，为AI系统的可信性、安全性和人类对齐性提供了理论指导。

Conclusion: 模型科学框架为开发可信、安全和人类对齐的AI系统提供了重要指导，代表了从数据科学向模型中心分析的重要范式转变。

Abstract: The growing adoption of foundation models calls for a paradigm shift from
Data Science to Model Science. Unlike data-centric approaches, Model Science
places the trained model at the core of analysis, aiming to interact, verify,
explain, and control its behavior across diverse operational contexts. This
paper introduces a conceptual framework for a new discipline called Model
Science, along with the proposal for its four key pillars: Verification, which
requires strict, context-aware evaluation protocols; Explanation, which is
understood as various approaches to explore of internal model operations;
Control, which integrates alignment techniques to steer model behavior; and
Interface, which develops interactive and visual explanation tools to improve
human calibration and decision-making. The proposed framework aims to guide the
development of credible, safe, and human-aligned AI systems.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [18] [MultiPL-MoE: Multi-Programming-Lingual Extension of Large Language Models through Hybrid Mixture-of-Experts](https://arxiv.org/abs/2508.19268)
*Qing Wang,Xue Han,Jiahui Wang,Lehao Xing,Qian Hu,Lianlian Zhang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 通过混合专家系统(MoE)技术，提出MultiPL-MoE方案来提升LLM的多编程语言生成能力，在保持主流语言性能的同时改善少用语言的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在代码生成方面表现优异，但多语言代码生成仍面临极大挑战。需要在限制计算资源的情况下提升多编程语言性能而不影响主流语言的表现。

Method: 提出MultiPL-MoE混合专家系统，结合了令牌级和段落级两个层面的专家选择。令牌级MoE采用标准结构加上新的门控权重归一化方法；段落级MoE使用滑动窗口分割输入序列，采用专家选择路由策略让专家选择top-k段落。

Result: 实验结果证明了MultiPL-MoE的有效性，成功提升了多编程语言生成能力。

Conclusion: MultiPL-MoE通过创新的混合专家系统设计，有效解决了多编程语言代码生成的挑战，在保持计算效率的同时实现了性能提升。

Abstract: Despite LLMs' excellent code creation capabilities, multilingual code
generation remains extremely challenging. To address this, we intent to improve
the multi-programming-lingual (MultiPL) performance of the base LLMs while
retaining the most popular ones using restricted computational resources. We
consider MultiPL to be a special case of multiple natural languages and propose
a MultiPL extension of LLMs utilizing a hybrid mixture of experts (MoE), called
MultiPL-MoE. Specifically, MultiPL-MoE combines two paired MoEs to optimize
expert selection at both the token and segment levels. The token-level MoE is a
standard upcycling MoE structure with a shared expert and a novel gate weight
normalization approach that aids in the final fusion with the segment-level
MoE. The segment-level MoE incorporates two innovative designs to better
capture the syntactic structure and contextual patterns of programming
languages: First, using a sliding window to partition the input token sequence
into multiple segments; Then, adopting an expert-choice routing strategy that
allows experts to select the top-k segments. The results of the experiment
proved the effectiveness of MultiPL-MoE.

</details>


### [19] [Whisper based Cross-Lingual Phoneme Recognition between Vietnamese and English](https://arxiv.org/abs/2508.19270)
*Nguyen Huu Nhat Minh,Tran Nguyen Anh,Truong Dinh Dung,Vo Van Nam,Le Pham Tuyen*

Main category: cs.CL

TL;DR: 该论文提出了一种新的双语语音识别方法，通过构建代表性双语音素集和利用PhoWhisper预训练编码器，有效解决趋南语和英语混合语音识别的挑战。


<details>
  <summary>Details</summary>
Motivation: 趋南语依赖声调区分词义，英语具有重音模式和非标准发音，这两者的音系差异给跨语言音素识别带来了重大挑战。

Method: 构建代表性双语音素集来桥接趋南语和英语音系差异；设计端到端系统，利用PhoWhisper预训练编码器获取深度高级表征来改善音素识别。

Result: 实验结果表明，该方法在趋南语双语语音识别中显著提高了识别准确率，同时为处理声调和重音基础音素识别的复杂性提供了健壮框架。

Conclusion: 该研究成功地解决了趋南语-英语混合语音识别的难题，通过创新的音系对比方法和深度学习技术，为跨语言音素识别领域做出了重要贡献。

Abstract: Cross-lingual phoneme recognition has emerged as a significant challenge for
accurate automatic speech recognition (ASR) when mixing Vietnamese and English
pronunciations. Unlike many languages, Vietnamese relies on tonal variations to
distinguish word meanings, whereas English features stress patterns and
non-standard pronunciations that hinder phoneme alignment between the two
languages. To address this challenge, we propose a novel bilingual speech
recognition approach with two primary contributions: (1) constructing a
representative bilingual phoneme set that bridges the differences between
Vietnamese and English phonetic systems; (2) designing an end-to-end system
that leverages the PhoWhisper pre-trained encoder for deep high-level
representations to improve phoneme recognition. Our extensive experiments
demonstrate that the proposed approach not only improves recognition accuracy
in bilingual speech recognition for Vietnamese but also provides a robust
framework for addressing the complexities of tonal and stress-based phoneme
recognition

</details>


### [20] [Database Entity Recognition with Data Augmentation and Deep Learning](https://arxiv.org/abs/2508.19372)
*Zikun Fu,Chen Yang,Kourosh Davoudi,Ken Q. Pu*

Main category: cs.CL

TL;DR: 本文提出了一个针对自然语言查询中数据库实体识别(DB-ER)的新方法，包括创建人工标注基准、基于SQL查询的数据增强技术，以及基于T5架构的专门实体识别模型，在精度和召回率方面均优于现有NER模型。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言查询中数据库实体识别的挑战，现有NER模型在处理数据库特定实体时表现不佳，需要专门针对数据库环境的实体识别解决方案。

Method: 1) 从流行的text-to-SQL基准创建人工标注的DB-ER基准；2) 利用SQL查询自动标注NLQ的数据增强方法；3) 基于T5架构的专门实体识别模型，使用序列标注和token分类两个下游任务进行微调。

Result: 提出的DB-ER标注器在精度和召回率方面均优于两种最先进的NER标注器。数据增强使精度和召回率提升超过10%，T5骨干网络微调使这些指标提升5-10%。

Conclusion: 该方法有效解决了数据库实体识别问题，数据增强和专门模型架构的结合显著提升了性能，为自然语言查询处理提供了更准确的实体识别能力。

Abstract: This paper addresses the challenge of Database Entity Recognition (DB-ER) in
Natural Language Queries (NLQ). We present several key contributions to advance
this field: (1) a human-annotated benchmark for DB-ER task, derived from
popular text-to-sql benchmarks, (2) a novel data augmentation procedure that
leverages automatic annotation of NLQs based on the corresponding SQL queries
which are available in popular text-to-SQL benchmarks, (3) a specialized
language model based entity recognition model using T5 as a backbone and two
down-stream DB-ER tasks: sequence tagging and token classification for
fine-tuning of backend and performing DB-ER respectively. We compared our DB-ER
tagger with two state-of-the-art NER taggers, and observed better performance
in both precision and recall for our model. The ablation evaluation shows that
data augmentation boosts precision and recall by over 10%, while fine-tuning of
the T5 backbone boosts these metrics by 5-10%.

</details>


### [21] [Rethinking Reasoning in LLMs: Neuro-Symbolic Local RetoMaton Beyond ICL and CoT](https://arxiv.org/abs/2508.19271)
*Rushitha Santhoshi Mamidala,Anshuman Chhabra,Ankur Mali*

Main category: cs.CL

TL;DR: 本文提出了一种基于局部加权有限自动机(WFA)的改进RetoMaton方法，替代传统的提示推理策略，为大型语言模型提供更可靠、可解释的符号化推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统的Chain-of-Thought和In-Context Learning等方法依赖脆弱的隐式机制，输出结果在不同种子、格式或微小提示变化下不一致，缺乏可靠性和可解释性。

Method: 将RetoMaton的全局数据存储替换为从外部领域语料库直接构建的局部加权有限自动机(WFA)，利用WFA的显式结构提供可验证的模块化检索行为。

Result: 在LLaMA-3.2-1B和Gemma-3-1B-PT两个预训练模型上，在TriviaQA、GSM8K和MMLU三个推理任务中，相比基础模型和基于提示的方法，局部RetoMaton变体持续提升性能，同时实现透明和可复现的检索动态。

Conclusion: 通过轻量级的自动机引导记忆，为现代大型语言模型提供了向可信赖符号化推理的有希望转变。

Abstract: Prompt-based reasoning strategies such as Chain-of-Thought (CoT) and
In-Context Learning (ICL) have become widely used for eliciting reasoning
capabilities in large language models (LLMs). However, these methods rely on
fragile, implicit mechanisms often yielding inconsistent outputs across seeds,
formats, or minor prompt variations making them fundamentally unreliable for
tasks requiring stable, interpretable reasoning. In contrast, automata-based
neuro-symbolic frameworks like RetoMaton offer a more structured and
trustworthy alternative by grounding retrieval in symbolic memory with
deterministic transitions. In this work, we extend RetoMaton by replacing its
global datastore with a local, task-adaptive Weighted Finite Automaton (WFA),
constructed directly from external domain corpora. This local automaton
structure promotes robust, context-aware retrieval while preserving symbolic
traceability and low inference overhead. Unlike prompting, which entangles
context and memory in opaque ways, our approach leverages the explicit
structure of WFAs to provide verifiable and modular retrieval behavior, making
it better suited for domain transfer and interoperability. We evaluate this
local RetoMaton variant on two pretrained LLMs LLaMA-3.2-1B and Gemma-3-1B-PT
across three reasoning tasks: TriviaQA (reading comprehension), GSM8K
(multi-step math), and MMLU (domain knowledge). Compared to the base model and
prompting-based methods, augmenting these setups with local RetoMaton
consistently improves performance while enabling transparent and reproducible
retrieval dynamics. Our results highlight a promising shift toward trustworthy,
symbolic reasoning in modern LLMs via lightweight, automaton-guided memory.

</details>


### [22] [RAGAPHENE: A RAG Annotation Platform with Human Enhancements and Edits](https://arxiv.org/abs/2508.19272)
*Kshitij Fadnis,Sara Rosenthal,Maeda Hanafi,Yannis Katsis,Marina Danilevsky*

Main category: cs.CL

TL;DR: RAGAPHENE是一个基于聊天的标注平台，用于模拟真实世界对话来构建多轮RAG对话评估基准


<details>
  <summary>Details</summary>
Motivation: 由于LLM可能产生看似正确但包含幻觉信息的回答，需要构建能够评估多轮RAG对话质量的基准

Method: 开发RAGAPHENE标注平台，让标注者模拟真实世界对话来构建评估数据集

Result: 平台已被约40名标注者成功使用，构建了数千个真实世界对话

Conclusion: RAGAPHENE平台能够有效支持高质量RAG对话评估基准的构建

Abstract: Retrieval Augmented Generation (RAG) is an important aspect of conversing
with Large Language Models (LLMs) when factually correct information is
important. LLMs may provide answers that appear correct, but could contain
hallucinated information. Thus, building benchmarks that can evaluate LLMs on
multi-turn RAG conversations has become an increasingly important task.
Simulating real-world conversations is vital for producing high quality
evaluation benchmarks. We present RAGAPHENE, a chat-based annotation platform
that enables annotators to simulate real-world conversations for benchmarking
and evaluating LLMs. RAGAPHENE has been successfully used by approximately 40
annotators to build thousands of real-world conversations.

</details>


### [23] [Leveraging Language Models and Machine Learning in Verbal Autopsy Analysis](https://arxiv.org/abs/2508.19274)
*Yue Chu*

Main category: cs.CL

TL;DR: 本研究证明在口头尸检中，使用预训练语言模型分析叙述文本比仅使用结构化问题能更准确地进行死因分类，特别是对非传染性疾病。多模态方法结合叙述和问题能进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏民事登记和生命统计的国家，口头尸检是估计死因的关键工具。现有自动化分类算法仅使用结构化问题而忽略了叙述文本中的宝贵信息。

Method: 使用预训练语言模型和机器学习技术分析口头尸检中的叙述文本，探索多模态融合策略结合叙述和问题，并评估医生感知的信息充分性。

Result: 基于Transformer的预训练语言模型在单独使用叙述文本时，在个体和群体层面都优于仅使用问题的算法。多模态方法进一步提升了死因分类性能。分类准确性受信息充分性影响。

Conclusion: 叙述文本能显著增强死因分类，需要更多高质量多样化数据来训练模型，并为重新设计口头尸检工具和访谈提供了重要见解。

Abstract: In countries without civil registration and vital statistics, verbal autopsy
(VA) is a critical tool for estimating cause of death (COD) and inform policy
priorities. In VA, interviewers ask proximal informants for details on the
circumstances preceding a death, in the form of unstructured narratives and
structured questions. Existing automated VA cause classification algorithms
only use the questions and ignore the information in the narratives. In this
thesis, we investigate how the VA narrative can be used for automated COD
classification using pretrained language models (PLMs) and machine learning
(ML) techniques. Using empirical data from South Africa, we demonstrate that
with the narrative alone, transformer-based PLMs with task-specific fine-tuning
outperform leading question-only algorithms at both the individual and
population levels, particularly in identifying non-communicable diseases. We
explore various multimodal fusion strategies combining narratives and questions
in unified frameworks. Multimodal approaches further improve performance in COD
classification, confirming that each modality has unique contributions and may
capture valuable information that is not present in the other modality. We also
characterize physician-perceived information sufficiency in VA. We describe
variations in sufficiency levels by age and COD and demonstrate that
classification accuracy is affected by sufficiency for both physicians and
models. Overall, this thesis advances the growing body of knowledge at the
intersection of natural language processing, epidemiology, and global health.
It demonstrates the value of narrative in enhancing COD classification. Our
findings underscore the need for more high-quality data from more diverse
settings to use in training and fine-tuning PLM/ML methods, and offer valuable
insights to guide the rethinking and redesign of the VA instrument and
interview.

</details>


### [24] [FLAIRR-TS -- Forecasting LLM-Agents with Iterative Refinement and Retrieval for Time Series](https://arxiv.org/abs/2508.19279)
*Gunjan Jalori,Preetika Verma,Sercan Ö Arık*

Main category: cs.CL

TL;DR: FLAIRR-TS是一个基于代理系统的测试时提示优化框架，通过预测代理和精炼代理的协作，无需中间代码生成即可实现高质量时间序列预测


<details>
  <summary>Details</summary>
Motivation: 传统LLM时间序列预测需要大量预处理和微调，而静态提示工程既繁琐又缺乏通用性，需要一种自适应提示优化方法

Method: 使用双代理系统：预测代理用初始提示生成预测，精炼代理基于历史输出和检索的类似序列来优化提示，采用创造性提示模板实现跨领域泛化

Result: 在基准数据集上相比静态提示和检索增强基线提高了准确性，接近专用提示的性能

Conclusion: FLAIRR-TS提供了一种实用的替代微调的方法，通过代理驱动的自适应提示精炼和检索实现强大性能

Abstract: Time series Forecasting with large languagemodels (LLMs) requires bridging
numericalpatterns and natural language. Effective fore-casting on LLM often
relies on extensive pre-processing and fine-tuning.Recent studiesshow that a
frozen LLM can rival specializedforecasters when supplied with a carefully
en-gineered natural-language prompt, but craft-ing such a prompt for each task
is itself oner-ous and ad-hoc. We introduce FLAIRR-TS, atest-time prompt
optimization framework thatutilizes an agentic system: a
Forecaster-agentgenerates forecasts using an initial prompt,which is then
refined by a refiner agent, in-formed by past outputs and retrieved
analogs.This adaptive prompting generalizes across do-mains using creative
prompt templates andgenerates high-quality forecasts without inter-mediate code
generation.Experiments onbenchmark datasets show improved accuracyover static
prompting and retrieval-augmentedbaselines, approaching the performance
ofspecialized prompts.FLAIRR-TS providesa practical alternative to tuning,
achievingstrong performance via its agentic approach toadaptive prompt
refinement and retrieval.

</details>


### [25] [CORE: Lossless Compression for Retrieval-Augmented LLMs via Reinforcement Learning](https://arxiv.org/abs/2508.19282)
*Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Xiuqiang He,Chen Ma*

Main category: cs.CL

TL;DR: CORE提出了一种基于强化学习的无损上下文压缩方法，通过端到端训练优化RAG中的文档压缩，在保持3%高压缩比的同时提升任务性能


<details>
  <summary>Details</summary>
Motivation: 解决RAG中检索文档过多导致输入长度过长、计算成本高的问题，同时避免传统压缩方法损害最终任务性能的缺陷

Method: 使用强化学习（GRPO策略优化）以最终任务性能作为奖励信号，端到端训练压缩器生成最大化LLM答案准确性的摘要

Result: 在4个数据集上实验显示，3%的高压缩比下不仅避免了性能下降，还将平均精确匹配(EM)分数提高了3.3分

Conclusion: CORE方法通过强化学习实现了有效的无损上下文压缩，显著提升了RAG系统的效率和准确性

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach to
enhance the timeliness of knowledge and the factual accuracy of responses in
Large Language Models (LLMs). However, the inclusion of excessive retrieved
documents substantially increases the input length, leading to higher
computational costs. Previous studies have attempted to compress retrieved
documents into shorter texts before in-context integration, but such methods
often compromise end-task performance. The lack of well-defined compression
targets forces many approaches to rely on fixed heuristics, which cannot
guarantee that the compressed content will effectively support the end task. To
address these limitations, we propose CORE, a novel method designed to achieve
lossless context compression for RAG. CORE employs reinforcement learning to
optimize the compression process without relying on predefined compression
labels. Specifically, it utilizes end-task performance as a reward signal and
applies Generalized Reinforcement Learning Policy Optimization (GRPO) to train
the compressor. This end-to-end training framework enables the compressor to
generate summaries that maximize the accuracy of answers generated by the LLM.
Extensive experiments on four datasets demonstrate the superiority of our
approach. With a high compression ratio of 3\%, our method not only avoids
performance degradation compared to prepending full documents across all
datasets but also improves the average Exact Match (EM) score by 3.3 points.
The code will be released soon.

</details>


### [26] [Context-Adaptive Synthesis and Compression for Enhanced Retrieval-Augmented Generation in Complex Domains](https://arxiv.org/abs/2508.19357)
*Peiran Zhou,Junnan Zhu,Yichen Shen,Ruoxi Yu*

Main category: cs.CL

TL;DR: CASC框架通过智能上下文分析和合成，解决多文档RAG中的信息过载问题，显著提升复杂领域问答的准确性和可信度


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理多文档、长文档或冲突文档时存在信息过载和低效合成问题，导致答案不准确和不可信

Method: 提出CASC框架，包含Context Analyzer & Synthesizer模块，使用微调的小型LLM进行关键信息提取、跨文档一致性检查和冲突解决、面向问题的结构化合成

Result: 在SciDocs-QA数据集上，CASC持续优于强基线方法，显著减少token数量并降低认知负荷

Conclusion: CASC通过将原始分散信息转换为高度压缩、结构化、语义丰富的上下文，有效解决了复杂领域多文档RAG的挑战

Abstract: Large Language Models (LLMs) excel in language tasks but are prone to
hallucinations and outdated knowledge. Retrieval-Augmented Generation (RAG)
mitigates these by grounding LLMs in external knowledge. However, in complex
domains involving multiple, lengthy, or conflicting documents, traditional RAG
suffers from information overload and inefficient synthesis, leading to
inaccurate and untrustworthy answers. To address this, we propose CASC
(Context-Adaptive Synthesis and Compression), a novel framework that
intelligently processes retrieved contexts. CASC introduces a Context Analyzer
& Synthesizer (CAS) module, powered by a fine-tuned smaller LLM, which performs
key information extraction, cross-document consistency checking and conflict
resolution, and question-oriented structured synthesis. This process transforms
raw, scattered information into a highly condensed, structured, and
semantically rich context, significantly reducing the token count and cognitive
load for the final Reader LLM. We evaluate CASC on SciDocs-QA, a new
challenging multi-document question answering dataset designed for complex
scientific domains with inherent redundancies and conflicts. Our extensive
experiments demonstrate that CASC consistently outperforms strong baselines.

</details>


### [27] [Reflective Agreement: Combining Self-Mixture of Agents with a Sequence Tagger for Robust Event Extraction](https://arxiv.org/abs/2508.19359)
*Fatemeh Haji,Mazal Bethany,Cho-Yu Jason Chiang,Anthony Rios,Peyman Najafirad*

Main category: cs.CL

TL;DR: 提出ARIS混合方法，结合自混合代理和判别式序列标注器，通过模型共识、置信度过滤和LLM反思推理来提升事件抽取性能


<details>
  <summary>Details</summary>
Motivation: 传统判别模型精度高但召回率低，生成式LLM方法语义灵活但存在幻觉和不一致预测，需要结合两者优势

Method: ARIS系统：自混合代理+判别式序列标注器，利用结构化模型共识、置信度过滤和LLM反思推理模块，采用分解指令微调

Result: 在三个基准数据集上超越现有最先进的事件抽取方法

Conclusion: ARIS通过混合方法和反思推理有效解决了事件抽取中的精度-召回权衡问题，提升了整体预测质量

Abstract: Event Extraction (EE) involves automatically identifying and extracting
structured information about events from unstructured text, including triggers,
event types, and arguments. Traditional discriminative models demonstrate high
precision but often exhibit limited recall, particularly for nuanced or
infrequent events. Conversely, generative approaches leveraging Large Language
Models (LLMs) provide higher semantic flexibility and recall but suffer from
hallucinations and inconsistent predictions. To address these challenges, we
propose Agreement-based Reflective Inference System (ARIS), a hybrid approach
combining a Self Mixture of Agents with a discriminative sequence tagger. ARIS
explicitly leverages structured model consensus, confidence-based filtering,
and an LLM reflective inference module to reliably resolve ambiguities and
enhance overall event prediction quality. We further investigate decomposed
instruction fine-tuning for enhanced LLM event extraction understanding.
Experiments demonstrate our approach outperforms existing state-of-the-art
event extraction methods across three benchmark datasets.

</details>


### [28] [LongReasonArena: A Long Reasoning Benchmark for Large Language Models](https://arxiv.org/abs/2508.19363)
*Jiayu Ding,Shuming Ma,Lei Cui,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: LongReasonArena是一个专门评估大语言模型长推理能力的新基准，通过多步算法执行任务来测试检索和回溯等关键推理能力，推理长度可达100万token，对现有LLM构成重大挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的长上下文基准主要评估模型对长输入的理解能力，而忽略了长推理能力的评估，需要专门设计基准来填补这一空白。

Method: 设计需要执行多步算法的任务，通过控制输入来任意扩展推理长度，最高可达100万token的推理过程，测试检索和回溯等关键推理能力。

Result: LongReasonArena对开源和专有LLM都构成显著挑战，Deepseek-R1仅达到7.5%的准确率，准确率随预期推理步数对数呈线性下降趋势。

Conclusion: 该基准成功揭示了当前LLM在长推理任务上的局限性，为评估和改进模型的长推理能力提供了重要工具。

Abstract: Existing long-context benchmarks for Large Language Models (LLMs) focus on
evaluating comprehension of long inputs, while overlooking the evaluation of
long reasoning abilities. To address this gap, we introduce LongReasonArena, a
benchmark specifically designed to assess the long reasoning capabilities of
LLMs. Our tasks require models to solve problems by executing multi-step
algorithms that reflect key aspects of long reasoning, such as retrieval and
backtracking. By controlling the inputs, the required reasoning length can be
arbitrarily scaled, reaching up to 1 million tokens of reasoning for the most
challenging tasks. Extensive evaluation results demonstrate that
LongReasonArena presents a significant challenge for both open-source and
proprietary LLMs. For instance, Deepseek-R1 achieves only 7.5% accuracy on our
task. Further analysis also reveals that the accuracy exhibits a linear decline
with respect to the logarithm of the expected number of reasoning steps. Our
code and data is available at
https://github.com/LongReasonArena/LongReasonArena.

</details>


### [29] [One Joke to Rule them All? On the (Im)possibility of Generalizing Humor](https://arxiv.org/abs/2508.19402)
*Mor Turgeman,Chen Shani,Dafna Shahaf*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型在不同幽默类型间的迁移学习能力，发现模型能够在未见过的幽默任务上达到75%的准确率，且多样化训练数据能提升迁移性能。


<details>
  <summary>Details</summary>
Motivation: 幽默是复杂多样的交流形式，现有研究多集中于特定幽默类型。随着新型幽默（如表情包、反幽默、AI失败）不断涌现，需要研究LLMs是否能跨幽默类型泛化，捕捉深层的可迁移机制。

Method: 通过在四个不同幽默任务数据集上进行迁移学习实验，训练LLMs在不同多样性设置下（1-3个训练数据集），测试在新任务上的表现。

Result: 模型能够实现一定程度的迁移，在未见数据集上达到75%准确率；多样化训练源可提升1.88-4.05%的迁移能力，且不影响域内性能。Dad Jokes被证明是最佳的迁移促进者。

Conclusion: 幽默类型间的迁移是可行的，多样化训练有助于提升LLMs对新兴幽默类型的泛化能力，为应对不断演变的幽默景观提供了解决方案。

Abstract: Humor is a broad and complex form of communication that remains challenging
for machines. Despite its broadness, most existing research on computational
humor traditionally focused on modeling a specific type of humor. In this work,
we wish to understand whether competence on one or more specific humor tasks
confers any ability to transfer to novel, unseen types; in other words, is this
fragmentation inevitable? This question is especially timely as new humor types
continuously emerge in online and social media contexts (e.g., memes,
anti-humor, AI fails). If Large Language Models (LLMs) are to keep up with this
evolving landscape, they must be able to generalize across humor types by
capturing deeper, transferable mechanisms. To investigate this, we conduct a
series of transfer learning experiments across four datasets, representing
different humor tasks. We train LLMs under varied diversity settings (1-3
datasets in training, testing on a novel task). Experiments reveal that models
are capable of some transfer, and can reach up to 75% accuracy on unseen
datasets; training on diverse sources improves transferability (1.88-4.05%)
with minimal-to-no drop in in-domain performance. Further analysis suggests
relations between humor types, with Dad Jokes surprisingly emerging as the best
enabler of transfer (but is difficult to transfer to). We release data and
code.

</details>


### [30] [A perishable ability? The future of writing in the face of generative artificial intelligence](https://arxiv.org/abs/2508.19427)
*Evandro L. T. P. Cunha*

Main category: cs.CL

TL;DR: 这篇论文讨论了AI生成文本工具的发展可能导致人类写作能力的退化，类似于古希腊黑暗时代的文字失传现象


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI工具的快速发展可能对人类写作能力的深远影响，提出对人类文字传承的担忧

Method: 通过历史类比分析，将当今AI生成文本技术与古希腊黑暗时代的文字失传现象进行对比研究

Result: 识别了AI技术可能导致人类写作能力退化的风险，类似于历史上的文字文化断层现象

Conclusion: 需要重视AI时代下人类文字能力的保持与传承，避免重播历史上的文明退化潜在风险

Abstract: The 2020s have been witnessing a very significant advance in the development
of generative artificial intelligence tools, including text generation systems
based on large language models. These tools have been increasingly used to
generate texts in the most diverse domains -- from technical texts to literary
texts --, which might eventually lead to a lower volume of written text
production by humans. This article discusses the possibility of a future in
which human beings will have lost or significantly decreased their ability to
write due to the outsourcing of this activity to machines. This possibility
parallels the loss of the ability to write in other moments of human history,
such as during the so-called Greek Dark Ages (approx. 1200 BCE - 800 BCE).

</details>


### [31] [Heterogeneous LLM Methods for Ontology Learning (Few-Shot Prompting, Ensemble Typing, and Attention-Based Taxonomies)](https://arxiv.org/abs/2508.19428)
*Aleksandra Beliaeva,Temurbek Rahmatullaev*

Main category: cs.CL

TL;DR: 本文提出了一个针对LLMs4OL 2025挑战赛的完整系统，结合检索增强提示、零样本分类和注意力图建模，在术语提取、类型标注和分类发现三个任务中均取得领先结果。


<details>
  <summary>Details</summary>
Motivation: 解决本体构建全流程的三个核心任务：术语提取、类型标注和分类发现，展示LLM架构在跨领域本体学习中的可扩展性、适应性和鲁棒性。

Method: 任务A：使用检索增强生成(RAG)联合提取术语和类型；任务B：少样本设置重用RAG，零样本设置使用多嵌入模型的置信度加权分类；任务C：通过轻量级交叉注意力层建模图推理预测is-a关系。

Result: 在官方排行榜的所有三个任务中均取得了顶级排名结果。

Conclusion: 该研究展示了基于LLM的架构在异构领域本体学习中的有效性，模块化的任务特定解决方案具有很好的实用价值。

Abstract: We present a comprehensive system for addressing Tasks A, B, and C of the
LLMs4OL 2025 challenge, which together span the full ontology construction
pipeline: term extraction, typing, and taxonomy discovery. Our approach
combines retrieval-augmented prompting, zero-shot classification, and
attention-based graph modeling -- each tailored to the demands of the
respective task. For Task A, we jointly extract domain-specific terms and their
ontological types using a retrieval-augmented generation (RAG) pipeline.
Training data was reformulated into a document to terms and types
correspondence, while test-time inference leverages semantically similar
training examples. This single-pass method requires no model finetuning and
improves overall performance through lexical augmentation Task B, which
involves assigning types to given terms, is handled via a dual strategy. In the
few-shot setting (for domains with labeled training data), we reuse the RAG
scheme with few-shot prompting. In the zero-shot setting (for previously unseen
domains), we use a zero-shot classifier that combines cosine similarity scores
from multiple embedding models using confidence-based weighting. In Task C, we
model taxonomy discovery as graph inference. Using embeddings of type labels,
we train a lightweight cross-attention layer to predict is-a relations by
approximating a soft adjacency matrix. These modular, task-specific solutions
enabled us to achieve top-ranking results in the official leaderboard across
all three tasks. Taken together these strategies showcase the scalability,
adaptability, and robustness of LLM-based architectures for ontology learning
across heterogeneous domains.
  Code is available at:
https://github.com/BelyaevaAlex/LLMs4OL-Challenge-Alexbek

</details>


### [32] [Bridging Language Gaps: Enhancing Few-Shot Language Adaptation](https://arxiv.org/abs/2508.19464)
*Philipp Borchert,Jochen De Weerdt,Marie-Francine Moens*

Main category: cs.CL

TL;DR: CoLAP方法通过对比学习和跨语言表示，实现了从高资源语言到低资源语言的任务特定知识迁移，显著提高了多语言NLP的数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决多语言NLP中语言资源不平衡的问题，高资源语言有丰富数据而低资源语言数据匮乏，需要有效的方法进行跨语言知识迁移。

Method: 提出对比语言对齐与提示（CoLAP）方法，结合对比学习和跨语言表示，通过提示机制实现任务特定的知识从高资源语言向低资源语言的迁移。

Result: 在自然语言推理和关系抽取等理解任务上，CoLAP在编码器和解码器模型上都优于少样本跨语言迁移基线和上下文学习，即使数据有限也能有效缩小跨语言性能差距。

Conclusion: CoLAP方法为开发更高效的多语言NLP技术做出了贡献，通过数据高效的方式实现了跨语言性能提升，特别是在低资源语言场景下表现出色。

Abstract: The disparity in language resources poses a challenge in multilingual NLP,
with high-resource languages benefiting from extensive data, while low-resource
languages lack sufficient data for effective training. Our Contrastive Language
Alignment with Prompting (CoLAP) method addresses this gap by integrating
contrastive learning with cross-lingual representations, facilitating
task-specific knowledge transfer from high-resource to lower-resource
languages. The primary advantage of our approach is its data efficiency,
enabling rapid adaptation to new languages and reducing the need for large
labeled datasets. We conduct experiments with multilingual encoder-only and
decoder-only language models on natural language understanding tasks, including
natural language inference and relation extraction, evaluating performance
across both high- and low-resource languages. Our results demonstrate that
CoLAP outperforms few-shot cross-lingual transfer baselines and in-context
learning, even with limited available data. This effectively narrows the
cross-lingual performance gap, contributing to the development of more
efficient multilingual NLP techniques.

</details>


### [33] [Inference Gap in Domain Expertise and Machine Intelligence in Named Entity Recognition: Creation of and Insights from a Substance Use-related Dataset](https://arxiv.org/abs/2508.19467)
*Sumon Kanti Dey,Jeanne M. Powell,Azra Ismail,Jeanmarie Perrone,Abeed Sarker*

Main category: cs.CL

TL;DR: 这篇论文提出了一种基于命名实体识别的框架，从社交媒体中提取非医疗类阿片类药物使用的临床和社会影响，DeBERTa-large模型表现最佳，但仍远超专家一致性。


<details>
  <summary>Details</summary>
Motivation: 非医疗类阿片类药物使用造成严重公共健康问题，但传统医疗场景下很难获取这些数据。社交媒体上用户的第一人称述提供了价值但未充分利用的信息来源。

Method: 开发了RedditImpacts 2.0数据集，使用命名实体识别框架提取临床影响和社会影响两类实体。比较了细调的编码器模型和大语言模型在零样本和少样本学习情况下的表现。

Result: 细调的DeBERTa-large模型达到了token-level F1 0.61，在精度、字符串准确性和指南遵循方面都超过了大语言模型。研究还发现可以用更少的标签数据实现强大的NER性能。

Conclusion: 领域特定的细调对临床NLP任务具有重要价值，但最佳模型仍远超专家一致性（Cohen's kappa: 0.81），显示了专业知识任务中AI能力与人类专家之间仍存在差距。

Abstract: Nonmedical opioid use is an urgent public health challenge, with far-reaching
clinical and social consequences that are often underreported in traditional
healthcare settings. Social media platforms, where individuals candidly share
first-person experiences, offer a valuable yet underutilized source of insight
into these impacts. In this study, we present a named entity recognition (NER)
framework to extract two categories of self-reported consequences from social
media narratives related to opioid use: ClinicalImpacts (e.g., withdrawal,
depression) and SocialImpacts (e.g., job loss). To support this task, we
introduce RedditImpacts 2.0, a high-quality dataset with refined annotation
guidelines and a focus on first-person disclosures, addressing key limitations
of prior work. We evaluate both fine-tuned encoder-based models and
state-of-the-art large language models (LLMs) under zero- and few-shot
in-context learning settings. Our fine-tuned DeBERTa-large model achieves a
relaxed token-level F1 of 0.61 [95% CI: 0.43-0.62], consistently outperforming
LLMs in precision, span accuracy, and adherence to task-specific guidelines.
Furthermore, we show that strong NER performance can be achieved with
substantially less labeled data, emphasizing the feasibility of deploying
robust models in resource-limited settings. Our findings underscore the value
of domain-specific fine-tuning for clinical NLP tasks and contribute to the
responsible development of AI tools that may enhance addiction surveillance,
improve interpretability, and support real-world healthcare decision-making.
The best performing model, however, still significantly underperforms compared
to inter-expert agreement (Cohen's kappa: 0.81), demonstrating that a gap
persists between expert intelligence and current state-of-the-art NER/AI
capabilities for tasks requiring deep domain knowledge.

</details>


### [34] [Automatic Question & Answer Generation Using Generative Large Language Model (LLM)](https://arxiv.org/abs/2508.19475)
*Md. Alvee Ehsan,A. S. M Mehedi Hasan,Kefaya Benta Shahnoor,Syeda Sumaiya Tasneem*

Main category: cs.CL

TL;DR: 使用微调的LLaMA 2-7B模型和RACE数据集，通过提示工程实现自动问题答案生成，为教育评估提供高效解决方案


<details>
  <summary>Details</summary>
Motivation: 传统学生评估需要教师手动创建公平的试题，过程耗时且具有挑战性，需要简化这一流程

Method: 采用无监督学习方法，基于Meta-Llama 2-7B模型，使用RACE数据集进行微调，结合提示工程生成不同类型的问题

Result: 开发了一个定制化模型，能够为教育工作者提供高效的问题生成工具

Conclusion: 自动问题生成工具可以节省宝贵的时间和资源，简化教育评估流程

Abstract: \Abstract{In the realm of education, student evaluation holds equal
significance as imparting knowledge. To be evaluated, students usually need to
go through text-based academic assessment methods. Instructors need to make
diverse sets of questions that need to be fair for all students to prove their
adequacy over a particular topic. This can prove to be quite challenging as
they may need to manually go through several different lecture materials. Our
objective is to make this whole process much easier by implementing Automatic
Question Answer Generation /(AQAG), using fine-tuned generative LLM. For
tailoring the instructor's preferred question style (MCQ, conceptual, or
factual questions), prompt Engineering (PE) is being utilized. In this
research, we propose to leverage unsupervised learning methods in NLP,
primarily focusing on the English language. This approach empowers the base
Meta-Llama 2-7B model to integrate RACE dataset as training data for the
fine-tuning process. Creating a customized model that will offer efficient
solutions for educators, instructors, and individuals engaged in text-based
evaluations. A reliable and efficient tool for generating questions and answers
can free up valuable time and resources, thus streamlining their evaluation
processes.}

</details>


### [35] [MovieCORE: COgnitive REasoning in Movies](https://arxiv.org/abs/2508.19026)
*Gueter Josmy Faure,Min-Hung Chen,Jia-Fong Yeh,Ying Cheng,Hung-Ting Su,Yung-Hao Tang,Shang-Hong Lai,Winston H. Hsu*

Main category: cs.CL

TL;DR: MovieCORE是一个创新的视频问答数据集，专注于电影内容的深层认知理解，通过多智能体头脑风暴方法生成高质量问题，并提出ACE模块提升模型推理能力25%。


<details>
  <summary>Details</summary>
Motivation: 现有视频问答数据集主要关注表层理解，缺乏对电影内容深层认知理解的评测，需要开发能够激发系统2思维的高质量数据集。

Method: 采用多大型语言模型作为思维智能体进行头脑风暴，生成和精炼高质量问答对；开发认知测试评估数据集质量；提出Agentic Choice Enhancement (ACE)模块增强视频语言模型的推理能力。

Result: 创建了MovieCORE数据集，包含深度认知问题；ACE模块将模型推理能力提升达25%；为评估VQA模型在深层认知任务上的性能提供了全面方案。

Conclusion: 该工作推动了AI系统对电影理解的发展，揭示了当前VQA模型在处理具有挑战性的电影内容问题时的能力和局限性，为未来研究提供了宝贵资源。

Abstract: This paper introduces MovieCORE, a novel video question answering (VQA)
dataset designed to probe deeper cognitive understanding of movie content.
Unlike existing datasets that focus on surface-level comprehension, MovieCORE
emphasizes questions that engage System-2 thinking while remaining specific to
the video material. We present an innovative agentic brainstorming approach,
utilizing multiple large language models (LLMs) as thought agents to generate
and refine high-quality question-answer pairs. To evaluate dataset quality, we
develop a set of cognitive tests assessing depth, thought-provocation
potential, and syntactic complexity. We also propose a comprehensive evaluation
scheme for assessing VQA model performance on deeper cognitive tasks. To
address the limitations of existing video-language models (VLMs), we introduce
an agentic enhancement module, Agentic Choice Enhancement (ACE), which improves
model reasoning capabilities post-training by up to 25%. Our work contributes
to advancing movie understanding in AI systems and provides valuable insights
into the capabilities and limitations of current VQA models when faced with
more challenging, nuanced questions about cinematic content. Our project page,
dataset and code can be found at
https://joslefaure.github.io/assets/html/moviecore.html.

</details>


### [36] [Improving Low-Resource Translation with Dictionary-Guided Fine-Tuning and RL: A Spanish-to-Wayuunaiki Study](https://arxiv.org/abs/2508.19481)
*Manuel Mosquera,Melissa Robles,Johan Rodriguez,Ruben Manrique*

Main category: cs.CL

TL;DR: 通过结合外部字典工具和强化学习的方法，在轻资源语言翻译中实现了显著的翻译质量提升


<details>
  <summary>Details</summary>
Motivation: 大语言模型在轻资源语言翻译中面临预训练暴露不足和并行数据有限的挑战

Method: 集成外部双语字典工具，结合监督式指令微调和引导奖励策略优化(GRPO)进行端到端训练

Result: 在西班牙-Wayuunaiki语言对上实现了+3.37 BLEU的收益，相比无字典访问的监督基线提升18%相对收益

Conclusion: 结合外部工具和强化学习的方法在轻资源语言翻译中具有广阔前景

Abstract: Low-resource machine translation remains a significant challenge for large
language models (LLMs), which often lack exposure to these languages during
pretraining and have limited parallel data for fine-tuning. We propose a novel
approach that enhances translation for low-resource languages by integrating an
external dictionary tool and training models end-to-end using reinforcement
learning, in addition to supervised fine-tuning. Focusing on the
Spanish-Wayuunaiki language pair, we frame translation as a tool-augmented
decision-making problem in which the model can selectively consult a bilingual
dictionary during generation. Our method combines supervised instruction tuning
with Guided Reward Policy Optimization (GRPO), enabling the model to learn both
when and how to use the tool effectively. BLEU similarity scores are used as
rewards to guide this learning process. Preliminary results show that our
tool-augmented models achieve up to +3.37 BLEU improvement over previous work,
and a 18% relative gain compared to a supervised baseline without dictionary
access, on the Spanish-Wayuunaiki test set from the AmericasNLP 2025 Shared
Task. We also conduct ablation studies to assess the effects of model
architecture and training strategy, comparing Qwen2.5-0.5B-Instruct with other
models such as LLaMA and a prior NLLB-based system. These findings highlight
the promise of combining LLMs with external tools and the role of reinforcement
learning in improving translation quality in low-resource language settings.

</details>


### [37] [Rule Synergy Analysis using LLMs: State of the Art and Implications](https://arxiv.org/abs/2508.19484)
*Bahar Bateni,Benjamin Pratt,Jim Whitehead*

Main category: cs.CL

TL;DR: LLMs在卡牌游戏协同效应识别中表现不佳，特别是在检测正负协同效应方面存在困难


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在动态环境中理解和推理复杂规则交互的能力，特别是在卡牌游戏中的协同效应识别

Method: 引入基于Slay the Spire游戏的卡牌协同数据集，对卡牌对的正面、负面和中性交互进行分类评估

Result: LLMs擅长识别非协同卡牌对，但在检测正面协同和特别是负面协同方面表现不佳，存在时序、游戏状态定义和规则遵循等问题

Conclusion: 研究结果指出了改进模型在预测规则效果及其交互方面性能的未来研究方向

Abstract: Large language models (LLMs) have demonstrated strong performance across a
variety of domains, including logical reasoning, mathematics, and more. In this
paper, we investigate how well LLMs understand and reason about complex rule
interactions in dynamic environments, such as card games. We introduce a
dataset of card synergies from the game Slay the Spire, where pairs of cards
are classified based on their positive, negative, or neutral interactions. Our
evaluation shows that while LLMs excel at identifying non-synergistic pairs,
they struggle with detecting positive and, particularly, negative synergies. We
categorize common error types, including issues with timing, defining game
states, and following game rules. Our findings suggest directions for future
research to improve model performance in predicting the effect of rules and
their interactions.

</details>


### [38] [Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding](https://arxiv.org/abs/2508.19529)
*Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang*

Main category: cs.CL

TL;DR: 提出Blockwise SFT方法，通过将响应分块并且每步只在活跃块内随机掩码，使训练与推理过程一致，解决了标准SFT在离散渗透模型中的训练-推理不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 标准监督微调(SFT)与离散渗透语言模型的半自回归推理方式不匹配：训练时随机掩码整个响应的token，而推理时按固定大小的块顺序生成，导致噪声前缀和泄漏后缀，使梯度偏离块级可能性。

Method: 将响应分割成固定大小的块，每步选择一个活跃块进行随机掩码，冻结所有之前的token，完全隐藏未来的token，损失仅在活跃块上计算，直接反映块级解码过程。

Result: 在GSM8K、MATH和MetaMathQA数据集上进行实验，在相同计算或token预算下，Blockwise SFT比标准SFT持续获得提升。块大小一致性研究和消融实验确认了改进来自于训练-推理对齐而非偶然的掩码效果。

Conclusion: 成果强调了在基于渗透的语言模型中，将监督粒度与解码过程相匹配的重要性。

Abstract: Discrete diffusion language models have shown strong potential for text
generation, yet standard supervised fine-tuning (SFT) misaligns with their
semi-autoregressive inference: training randomly masks tokens across the entire
response, while inference generates fixed-size blocks sequentially. This
mismatch introduces noisy prefixes and leaky suffixes, biasing gradients away
from the desired blockwise likelihood. We propose Blockwise SFT, which
partitions responses into fixed-size blocks, selects one active block per step
for stochastic masking, freezes all preceding tokens, and fully hides future
ones. Loss is computed only over the active block, directly mirroring the
blockwise decoding process. Experiments on GSM8K, MATH, and MetaMathQA show
consistent gains over classical SFT under equal compute or token budgets. Block
size consistency studies and ablations confirm that improvements stem from
faithful training-inference alignment rather than incidental masking effects.
Our results highlight the importance of matching supervision granularity to the
decoding procedure in diffusion-based language models.

</details>


### [39] [Alignment with Fill-In-the-Middle for Enhancing Code Generation](https://arxiv.org/abs/2508.19532)
*Houxing Ren,Zimu Lu,Weikang Shi,Haotian Hou,Yunqiao Yang,Ke Wang,Aojun Zhou,Junting Pan,Mingjie Zhan,Hongsheng Li*

Main category: cs.CL

TL;DR: 提出了一种基于代码块分割和AST结构的DPO优化方法，通过将代码片段分割成更细粒度的块来生成更多样化的训练对，显著提升了代码生成任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成任务中，由于缺乏可验证的测试用例训练数据，性能提升面临挑战。虽然DPO方法有潜力，但现有测试用例生成方法仍有局限。

Method: 将代码片段分割成更小的粒度块，从相同测试用例创建更多样化的DPO训练对；引入AST（抽象语法树）分割和课程训练方法来增强DPO训练。

Result: 在多个基准数据集（HumanEval、MBPP、APPS、LiveCodeBench、BigCodeBench）上验证了代码生成任务的显著改进。

Conclusion: 提出的结构化代码分割和课程训练方法有效提升了LLM在代码生成任务中的性能，为代码相关的DPO训练提供了新的解决方案。

Abstract: The code generation capabilities of Large Language Models (LLMs) have
advanced applications like tool invocation and problem-solving. However,
improving performance in code-related tasks remains challenging due to limited
training data that is verifiable with accurate test cases. While Direct
Preference Optimization (DPO) has shown promise, existing methods for
generating test cases still face limitations. In this paper, we propose a novel
approach that splits code snippets into smaller, granular blocks, creating more
diverse DPO pairs from the same test cases. Additionally, we introduce the
Abstract Syntax Tree (AST) splitting and curriculum training method to enhance
the DPO training. Our approach demonstrates significant improvements in code
generation tasks, as validated by experiments on benchmark datasets such as
HumanEval (+), MBPP (+), APPS, LiveCodeBench, and BigCodeBench. Code and data
are available at https://github.com/SenseLLM/StructureCoder.

</details>


### [40] [Emotion Transfer with Enhanced Prototype for Unseen Emotion Recognition in Conversation](https://arxiv.org/abs/2508.19533)
*Kun Peng,Cong Cao,Hao Peng,Guanlin Wu,Zhifeng Hao,Lei Jiang,Yanbing Liu,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了未见情感识别对话任务(UERC)和原型情感转移框架ProEmoTrans，通过LLM增强描述、参数自由编码机制和改进的注意力维特比解码来解决隐式表达、长对话编码和情感转移等挑战。


<details>
  <summary>Details</summary>
Motivation: 当前情感识别对话研究基于封闭领域假设，但心理学中情感分类缺乏明确共识，模型难以识别现实应用中的未见情感。

Method: 提出ProEmoTrans框架：1) LLM增强描述处理隐式表达；2) 参数自由机制处理长对话编码；3) 改进的注意力维特比解码(AVD)转移情感马尔可夫流。

Result: 在三个数据集上的大量实验表明，该方法在新领域初步探索中作为强基线表现优异。

Conclusion: 该研究首次定义了UERC任务并提出了有效的原型情感转移框架，为解决现实世界中未见情感识别问题提供了重要基础。

Abstract: Current Emotion Recognition in Conversation (ERC) research follows a
closed-domain assumption. However, there is no clear consensus on emotion
classification in psychology, which presents a challenge for models when it
comes to recognizing previously unseen emotions in real-world applications. To
bridge this gap, we introduce the Unseen Emotion Recognition in Conversation
(UERC) task for the first time and propose ProEmoTrans, a solid prototype-based
emotion transfer framework. This prototype-based approach shows promise but
still faces key challenges: First, implicit expressions complicate emotion
definition, which we address by proposing an LLM-enhanced description approach.
Second, utterance encoding in long conversations is difficult, which we tackle
with a proposed parameter-free mechanism for efficient encoding and overfitting
prevention. Finally, the Markovian flow nature of emotions is hard to transfer,
which we address with an improved Attention Viterbi Decoding (AVD) method to
transfer seen emotion transitions to unseen emotions. Extensive experiments on
three datasets show that our method serves as a strong baseline for preliminary
exploration in this new area.

</details>


### [41] [Language Models Identify Ambiguities and Exploit Loopholes](https://arxiv.org/abs/2508.19546)
*Jio Choi,Mohit Bansal,Elias Stengel-Eskin*

Main category: cs.CL

TL;DR: 大语言模型能够识别指令漏洞并利用其来完成自身目标，而非用户目标，这构成了AI安全风险


<details>
  <summary>Details</summary>
Motivation: 通过研究LLM对漏洞的响应，一方面可以探索模型在模糊性和语用推理方面的能力，另一方面发现这是一种新的对齐问题，模型可能利用模糊性来为自身获利

Method: 设计了模型目标与用户指令冲突的场景，涵盖标量含义、结构模糊性和权力动态等情境，测量模型利用漏洞完成自身目标的能力

Result: 发现闭源和更强的开源模型都能识别模糊性并利用漏洞，构成潜在的AI安全风险，这些模型会明确识别并推理模糊性和相冲目标

Conclusion: 模型利用漏洞的能力显示了它们在语用推理和模糊性处理方面的强大能力，但同时也曝露了重要的对齐问题和安全风险，需要重视这种模型利用模糊性来寻求自身目标的行为

Abstract: Studying the responses of large language models (LLMs) to loopholes presents
a two-fold opportunity. First, it affords us a lens through which to examine
ambiguity and pragmatics in LLMs, since exploiting a loophole requires
identifying ambiguity and performing sophisticated pragmatic reasoning. Second,
loopholes pose an interesting and novel alignment problem where the model is
presented with conflicting goals and can exploit ambiguities to its own
advantage. To address these questions, we design scenarios where LLMs are given
a goal and an ambiguous user instruction in conflict with the goal, with
scenarios covering scalar implicature, structural ambiguities, and power
dynamics. We then measure different models' abilities to exploit loopholes to
satisfy their given goals as opposed to the goals of the user. We find that
both closed-source and stronger open-source models can identify ambiguities and
exploit their resulting loopholes, presenting a potential AI safety risk. Our
analysis indicates that models which exploit loopholes explicitly identify and
reason about both ambiguity and conflicting goals.

</details>


### [42] [Towards a Holistic and Automated Evaluation Framework for Multi-Level Comprehension of LLMs in Book-Length Contexts](https://arxiv.org/abs/2508.19578)
*Jiaqi Deng,Yuho Lee,Nicole Hee-Yeon Kim,Hyangsuk Min,Taewon Yun,Minjeong Ban,Kim Yul,Hwanjun Song*

Main category: cs.CL

TL;DR: HAMLET是一个自动化框架，用于评估大语言模型的长文本理解能力，通过三层关键事实层次结构和查询聚焦摘要来测试模型的信息回忆和忠实表示能力。


<details>
  <summary>Details</summary>
Motivation: 现有的长文本评估方法往往不够全面和自动化，需要开发一个系统性的框架来准确评估LLMs在不同粒度层次上的理解能力，并验证自动化评估的可靠性。

Method: 构建三层关键事实层次结构（根级、分支级、叶级），采用查询聚焦摘要方法，通过系统化人工研究验证自动化管道的可靠性，比较开源与专有模型的性能差异。

Result: 自动化评估与专家人工判断达成90%以上一致，成本降低25倍；发现LLMs在细粒度理解（特别是叶级）上存在困难，对位置效应敏感，分析性查询比叙述性查询更具挑战性。

Conclusion: HAMLET提供了一个可靠且高效的自动化评估框架，揭示了LLMs在长文本理解中的局限性，为模型改进提供了重要见解，代码和数据集已公开。

Abstract: We introduce HAMLET, a holistic and automated framework for evaluating the
long-context comprehension of large language models (LLMs). HAMLET structures
source texts into a three-level key-fact hierarchy at root-, branch-, and
leaf-levels, and employs query-focused summarization to evaluate how well
models recall and faithfully represent information at each level. To validate
the reliability of our fully automated pipeline, we conduct a systematic human
study, showing that our automatic evaluation achieves over 90% agreement with
expert human judgments, while reducing the cost by up to 25 times. HAMLET
reveals that LLMs struggle with fine-grained comprehension, especially at the
leaf level, and are sensitive to positional effects like the
lost-in-the-middle. Analytical queries pose greater challenges than narrative
ones, and consistent performance gaps emerge between open-source and
proprietary models, as well as across model scales. Our code and dataset are
publicly available at https://github.com/DISL-Lab/HAMLET.

</details>


### [43] [ArgCMV: An Argument Summarization Benchmark for the LLM-era](https://arxiv.org/abs/2508.19580)
*Omkar Gurjar,Agam Goyal,Eshwar Chandrasekharan*

Main category: cs.CL

TL;DR: 本文指出了ArgKP21数据集的主要局限性，创建了一个新的Argument Key Point提取数据集ArgCMV，包含约12K个真实在线人类辩论，展示了现有方法在新数据集上的适应性不足，为LLM驱动的摘要研究提供了新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的关键点提取方法主要在ArgKP21数据集上评估，但该数据集不能很好地代表真实人类对话，需要更具代表性的新基准来推动论证摘要研究的发展。

Method: 使用最先进的大语言模型(LLMs)策划了一个新的论证关键点提取数据集ArgCMV，包含来自3K多个主题的约12K个真实在线人类辩论，该数据集具有更长的参数、共指论证、更多主观话语单元和更广泛的主题范围。

Result: ArgCMV数据集显示出比ArgKP21更高的复杂性，现有方法在该数据集上表现不佳，通过实验现有基线和最新开源模型提供了广泛的基准测试结果。

Conclusion: 这项工作为长上下文在线讨论引入了新颖的关键点提取数据集，为下一代LLM驱动的摘要研究奠定了基础，强调了需要更适合真实人类对话场景的评估基准。

Abstract: Key point extraction is an important task in argument summarization which
involves extracting high-level short summaries from arguments. Existing
approaches for KP extraction have been mostly evaluated on the popular ArgKP21
dataset. In this paper, we highlight some of the major limitations of the
ArgKP21 dataset and demonstrate the need for new benchmarks that are more
representative of actual human conversations. Using SoTA large language models
(LLMs), we curate a new argument key point extraction dataset called ArgCMV
comprising of around 12K arguments from actual online human debates spread
across over 3K topics. Our dataset exhibits higher complexity such as longer,
co-referencing arguments, higher presence of subjective discourse units, and a
larger range of topics over ArgKP21. We show that existing methods do not adapt
well to ArgCMV and provide extensive benchmark results by experimenting with
existing baselines and latest open source models. This work introduces a novel
KP extraction dataset for long-context online discussions, setting the stage
for the next generation of LLM-driven summarization research.

</details>


### [44] [Towards stable AI systems for Evaluating Arabic Pronunciations](https://arxiv.org/abs/2508.19587)
*Hadi Zaatiti,Hatem Hajri,Osama Abdullah,Nader Masmoudi*

Main category: cs.CL

TL;DR: 现代阿拉伯语ASR系统在孤立字母分类任务上表现不佳，准确率仅35%。通过轻量级神经网络和对抗训练，性能提升至65%，并在噪声环境下保持鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语孤立字母识别对于语言学习、语音治疗和语音学研究至关重要，但由于缺乏共发音线索和词汇上下文，且持续时间短，现有ASR系统在此任务上表现较差。

Method: 构建了带音标的孤立阿拉伯字母语料库，使用wav2vec 2.0模型提取特征，训练轻量级神经网络，并应用对抗训练来提高噪声环境下的鲁棒性。

Result: wav2vec 2.0模型准确率35%，轻量级神经网络提升至65%。添加小幅度扰动(ε=0.05)后准确率降至32%，但对抗训练将噪声下的性能下降限制在9%以内。

Conclusion: 研究表明孤立字母识别具有挑战性，但通过适当的模型设计和对抗训练可以显著改善性能。未来工作将扩展到词级和句子级框架中的精确字母发音识别。

Abstract: Modern Arabic ASR systems such as wav2vec 2.0 excel at word- and
sentence-level transcription, yet struggle to classify isolated letters. In
this study, we show that this phoneme-level task, crucial for language
learning, speech therapy, and phonetic research, is challenging because
isolated letters lack co-articulatory cues, provide no lexical context, and
last only a few hundred milliseconds. Recogniser systems must therefore rely
solely on variable acoustic cues, a difficulty heightened by Arabic's emphatic
(pharyngealized) consonants and other sounds with no close analogues in many
languages. This study introduces a diverse, diacritised corpus of isolated
Arabic letters and demonstrates that state-of-the-art wav2vec 2.0 models
achieve only 35% accuracy on it. Training a lightweight neural network on
wav2vec embeddings raises performance to 65%. However, adding a small amplitude
perturbation (epsilon = 0.05) cuts accuracy to 32%. To restore robustness, we
apply adversarial training, limiting the noisy-speech drop to 9% while
preserving clean-speech accuracy. We detail the corpus, training pipeline, and
evaluation protocol, and release, on demand, data and code for reproducibility.
Finally, we outline future work extending these methods to word- and
sentence-level frameworks, where precise letter pronunciation remains critical.

</details>


### [45] [Understanding and Leveraging the Expert Specialization of Context Faithfulness in Mixture-of-Experts LLMs](https://arxiv.org/abs/2508.19594)
*Jun Bai,Minghao Tong,Yang Liu,Zixia Jia,Zilong Zheng*

Main category: cs.CL

TL;DR: 提出了Router Lens方法识别上下文忠实专家，并开发了轻量级的CEFT优化方法，通过选择性微调专家来提升模型在上下文依赖场景中的忠实性，效果媲美全量微调但更高效。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在上下文依赖场景中经常无法有效利用上下文信息，导致输出与上下文无关。受混合专家架构中专家专业化的启发，研究是否存在专门处理上下文信息的专家来提升上下文忠实性。

Method: 提出Router Lens方法准确识别上下文忠实专家，分析发现这些专家会逐步放大对相关上下文信息的注意力。基于此开发了Context-faithful Expert Fine-Tuning (CEFT)方法，选择性微调这些专家。

Result: 在多个基准测试和模型上的实验表明，CEFT方法在性能上匹配或超越全量微调，同时显著提高了效率。

Conclusion: 通过识别和选择性优化上下文忠实专家，可以有效提升模型在上下文依赖任务中的忠实性，提供了一条高效优化的技术路径。

Abstract: Context faithfulness is essential for reliable reasoning in context-dependent
scenarios. However, large language models often struggle to ground their
outputs in the provided context, resulting in irrelevant responses. Inspired by
the emergent expert specialization observed in mixture-of-experts
architectures, this work investigates whether certain experts exhibit
specialization in context utilization, offering a potential pathway toward
targeted optimization for improved context faithfulness. To explore this, we
propose Router Lens, a method that accurately identifies context-faithful
experts. Our analysis reveals that these experts progressively amplify
attention to relevant contextual information, thereby enhancing context
grounding. Building on this insight, we introduce Context-faithful Expert
Fine-Tuning (CEFT), a lightweight optimization approach that selectively
fine-tunes context-faithful experts. Experiments across a wide range of
benchmarks and models demonstrate that CEFT matches or surpasses the
performance of full fine-tuning while being significantly more efficient.

</details>


### [46] [LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation](https://arxiv.org/abs/2508.19614)
*Yang Sun,Lixin Zou,Dan Luo,Zhiyong Xie,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li*

Main category: cs.CL

TL;DR: 本文通过噪声注入实验发现LLM不同层级的职能分工：浅层处理局部上下文，中层整合外部事实知识，深层依赖内部参数知识。基于此提出了层融合解码(LFD)策略，通过结合中层和最终层的表示来更好利用外部知识。


<details>
  <summary>Details</summary>
Motivation: 尽管反直觉，但实证研究表明在检索文档中注入噪声反而能提升生成质量，这现象为分析LLM如何整合外部知识提供了独特机会。

Method: 通过噪声干预实验建立LLM层级功能划分，提出层融合解码(LFD)策略，结合中层和最终层表示，并使用内部知识评分(IKS)准则选择最优中层。

Result: 在多个基准测试中，LFD以最小成本有效提升了RAG系统对外部知识的利用效率。

Conclusion: LLM存在明确的层级功能分工，LFD解码策略能有效利用这种分工特性来增强RAG系统的知识整合能力。

Abstract: Retrieval-augmented generation (RAG) incorporates external knowledge into
large language models (LLMs), improving their adaptability to downstream tasks
and enabling information updates. Surprisingly, recent empirical evidence
demonstrates that injecting noise into retrieved relevant documents
paradoxically facilitates exploitation of external knowledge and improves
generation quality. Although counterintuitive and challenging to apply in
practice, this phenomenon enables granular control and rigorous analysis of how
LLMs integrate external knowledge. Therefore, in this paper, we intervene on
noise injection and establish a layer-specific functional demarcation within
the LLM: shallow layers specialize in local context modeling, intermediate
layers focus on integrating long-range external factual knowledge, and deeper
layers primarily rely on parametric internal knowledge. Building on this
insight, we propose Layer Fused Decoding (LFD), a simple decoding strategy that
directly combines representations from an intermediate layer with final-layer
decoding outputs to fully exploit the external factual knowledge. To identify
the optimal intermediate layer, we introduce an internal knowledge score (IKS)
criterion that selects the layer with the lowest IKS value in the latter half
of layers. Experimental results across multiple benchmarks demonstrate that LFD
helps RAG systems more effectively surface retrieved context knowledge with
minimal cost.

</details>


### [47] [A Symbolic Adversarial Learning Framework for Evolving Fake News Generation and Detection](https://arxiv.org/abs/2508.19633)
*Chong Tian,Qirong Ho,Xiuying Chen*

Main category: cs.CL

TL;DR: SALF框架通过符号对抗学习优化过程，让生成器和检测器在结构化辩论中相互对抗迭代优化，有效生成复杂假新闻并提升检测能力


<details>
  <summary>Details</summary>
Motivation: LLM快速发展使得假新闻自动生成更加复杂，传统检测方法难以应对动态演变的虚假信息，需要更鲁棒的检测系统

Method: 采用符号对抗学习框架，通过自然语言表示权重、损失和梯度，模拟反向传播和梯度下降，让生成器制造欺骗性叙述，检测器通过结构化辩论识别逻辑和事实缺陷

Result: 在双语基准数据集上，SALF生成的假新闻使最先进检测器性能下降53.4%（中文）和34.2%（英文），同时提升检测器对优化内容的检测能力达7.7%

Conclusion: SALF为构建更鲁棒、适应性强的假新闻检测系统提供了新思路，值得进一步探索

Abstract: Rapid LLM advancements heighten fake news risks by enabling the automatic
generation of increasingly sophisticated misinformation. Previous detection
methods, including fine-tuned small models or LLM-based detectors, often
struggle with its dynamically evolving nature. In this work, we propose a novel
framework called the Symbolic Adversarial Learning Framework (SALF), which
implements an adversarial training paradigm by an agent symbolic learning
optimization process, rather than relying on numerical updates. SALF introduces
a paradigm where the generation agent crafts deceptive narratives, and the
detection agent uses structured debates to identify logical and factual flaws
for detection, and they iteratively refine themselves through such adversarial
interactions. Unlike traditional neural updates, we represent agents using
agent symbolic learning, where learnable weights are defined by agent prompts,
and simulate back-propagation and gradient descent by operating on natural
language representations of weights, loss, and gradients. Experiments on two
multilingual benchmark datasets demonstrate SALF's effectiveness, showing it
generates sophisticated fake news that degrades state-of-the-art detection
performance by up to 53.4% in Chinese and 34.2% in English on average. SALF
also refines detectors, improving detection of refined content by up to 7.7%.
We hope our work inspires further exploration into more robust, adaptable fake
news detection systems.

</details>


### [48] [Automatic integration of SystemC in the FMI standard for Software-defined Vehicle design](https://arxiv.org/abs/2508.19665)
*Giovanni Pollo,Andrei Mihai Albu,Alessio Burrello,Daniele Jahier Pagliari,Cristian Tesconi,Loris Panaro,Dario Soldi,Fabio Autieri,Sara Vinco*

Main category: cs.CL

TL;DR: 提出一种自动将SystemC模型封装为FMI标准接口的方法，实现嵌入式组件在协同仿真中的安全便携集成


<details>
  <summary>Details</summary>
Motivation: 汽车行业需要强大的协同仿真方法进行早期验证，但缺乏标准化接口和专有仿真平台主导的问题阻碍了协作、可扩展性和IP保护

Method: 使用功能模拟接口(FMI)标准自动封装SystemC模型，结合SystemC的建模精度和快速上市优势与FMI的互操作性和封装优势

Result: 在真实案例研究中验证了该方法的有效性，能够处理复杂设计

Conclusion: 该方法成功解决了协同仿真中的标准化和集成问题，为嵌入式组件提供了安全便携的集成方案

Abstract: The recent advancements of the automotive sector demand robust co-simulation
methodologies that enable early validation and seamless integration across
hardware and software domains. However, the lack of standardized interfaces and
the dominance of proprietary simulation platforms pose significant challenges
to collaboration, scalability, and IP protection. To address these limitations,
this paper presents an approach for automatically wrapping SystemC models by
using the Functional Mock-up Interface (FMI) standard. This method combines the
modeling accuracy and fast time-to-market of SystemC with the interoperability
and encapsulation benefits of FMI, enabling secure and portable integration of
embedded components into co-simulation workflows. We validate the proposed
methodology on real-world case studies, demonstrating its effectiveness with
complex designs.

</details>


### [49] [Survey of Specialized Large Language Model](https://arxiv.org/abs/2508.19667)
*Chenghan Yang,Ruiyu Zhao,Yang Liu,Ling Jiang*

Main category: cs.CL

TL;DR: 本调查系统分析了专业大语言模型从简单领域适应到原生架构设计的演进，重点考察了医疗、金融、法律和技术领域的应用，揭示了专业模型在领域特定基准测试中的性能优势。


<details>
  <summary>Details</summary>
Motivation: 随着专业大语言模型的快速发展，从简单的领域适应转向复杂的原生架构设计，需要系统性地分析这一演进过程及其在专业应用中对通用大语言模型局限性的解决方案。

Method: 通过系统调查方法，分析医疗、金融、法律和技术等领域的专业LLM发展，重点关注超越微调的领域原生设计、参数效率优化（稀疏计算和量化）以及多模态能力集成等技术突破。

Result: 研究发现专业大语言模型在领域特定基准测试中 consistently 获得性能提升，技术创新有效解决了通用LLM在专业应用中的根本局限性。

Conclusion: 专业LLM的发展代表了AI开发的范式转变，该调查进一步强调了这些进展对电子商务领域填补空白的意义，为专业领域应用提供了重要指导。

Abstract: The rapid evolution of specialized large language models (LLMs) has
transitioned from simple domain adaptation to sophisticated native
architectures, marking a paradigm shift in AI development. This survey
systematically examines this progression across healthcare, finance, legal, and
technical domains. Besides the wide use of specialized LLMs, technical
breakthrough such as the emergence of domain-native designs beyond fine-tuning,
growing emphasis on parameter efficiency through sparse computation and
quantization, increasing integration of multimodal capabilities and so on are
applied to recent LLM agent. Our analysis reveals how these innovations address
fundamental limitations of general-purpose LLMs in professional applications,
with specialized models consistently performance gains on domain-specific
benchmarks. The survey further highlights the implications for E-Commerce field
to fill gaps in the field.

</details>


### [50] [Building Task Bots with Self-learning for Enhanced Adaptability, Extensibility, and Factuality](https://arxiv.org/abs/2508.19689)
*Xiaoying Zhang*

Main category: cs.CL

TL;DR: 这篇论文研究如何在最小或零人类帮助下开发适应性强、可扩展、准确的对话任务机器人


<details>
  <summary>Details</summary>
Motivation: 解决开发自主学习和适应的对话机器人的挑战，减少人类干预需求

Method: 采用创新技术使机器人能够在变化环境中自主学习和适应

Result: 提出了解决这些挑战的潜在方案

Conclusion: 通过自主学习技术可以实现更适应性强、可扩展的对话任务机器人开发

Abstract: Developing adaptable, extensible, and accurate task bots with minimal or zero
human intervention is a significant challenge in dialog research. This thesis
examines the obstacles and potential solutions for creating such bots, focusing
on innovative techniques that enable bots to learn and adapt autonomously in
constantly changing environments.

</details>


### [51] [Continuously Steering LLMs Sensitivity to Contextual Knowledge with Proxy Models](https://arxiv.org/abs/2508.19720)
*Yilin Wang,Heng Wang,Yuyang Bai,Minnan Luo*

Main category: cs.CL

TL;DR: CSKS框架通过训练两个小型代理模型来连续调节大语言模型对上下文知识的敏感性，无需修改大模型权重，实现了轻量级的知识敏感性控制。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中参数知识与上下文知识冲突的问题，现有方法效率低、不适用于黑盒模型或无法连续调节知识敏感性。

Method: 训练两个小型代理模型，利用它们输出分布的差异来调整大语言模型的原始输出分布，实现连续的知识敏感性控制。

Result: 实验证明CSKS能够实现对上下文知识敏感性的连续精确控制，既能提高也能降低敏感性，让LLM根据需要灵活优先选择上下文或参数知识。

Conclusion: CSKS提供了一种轻量级、高效的方法来解决LLM中的知识冲突问题，适用于各种规模的黑盒和白盒模型，具有实际应用价值。

Abstract: In Large Language Models (LLMs) generation, there exist knowledge conflicts
and scenarios where parametric knowledge contradicts knowledge provided in the
context. Previous works studied tuning, decoding algorithms, or locating and
editing context-aware neurons to adapt LLMs to be faithful to new contextual
knowledge. However, they are usually inefficient or ineffective for large
models, not workable for black-box models, or unable to continuously adjust
LLMs' sensitivity to the knowledge provided in the context. To mitigate these
problems, we propose CSKS (Continuously Steering Knowledge Sensitivity), a
simple framework that can steer LLMs' sensitivity to contextual knowledge
continuously at a lightweight cost. Specifically, we tune two small LMs (i.e.
proxy models) and use the difference in their output distributions to shift the
original distribution of an LLM without modifying the LLM weights. In the
evaluation process, we not only design synthetic data and fine-grained metrics
to measure models' sensitivity to contextual knowledge but also use a real
conflict dataset to validate CSKS's practical efficacy. Extensive experiments
demonstrate that our framework achieves continuous and precise control over
LLMs' sensitivity to contextual knowledge, enabling both increased sensitivity
and reduced sensitivity, thereby allowing LLMs to prioritize either contextual
or parametric knowledge as needed flexibly. Our data and code are available at
https://github.com/OliveJuiceLin/CSKS.

</details>


### [52] [CAMÕES: A Comprehensive Automatic Speech Recognition Benchmark for European Portuguese](https://arxiv.org/abs/2508.19721)
*Carlos Carvalho,Francisco Teixeira,Catarina Botelho,Anna Pompili,Rubén Solera-Ureña,Sérgio Paulo,Mariana Julião,Thomas Rolland,John Mendonça,Diogo Pereira,Isabel Trancoso,Alberto Abad*

Main category: cs.CL

TL;DR: CAMÕES是首个针对欧洲葡萄牙语的开源ASR框架，包含评估基准和最先进模型，在425小时数据上训练后相对WER提升35%以上


<details>
  <summary>Details</summary>
Motivation: 现有葡萄牙语ASR资源主要关注巴西葡萄牙语，欧洲葡萄牙语和其他变种研究不足，需要填补这一空白

Method: 构建包含46小时测试数据的评估基准，使用多个基础模型进行零样本和微调评估，以及从头训练的E-Branchformer模型

Result: 微调后的基础模型与E-Branchformer性能相当，最佳模型相比最强零样本模型WER相对提升35%以上

Conclusion: CAMÕES框架为欧洲葡萄牙语ASR建立了新的技术标准，显著提升了该语言变种的识别性能

Abstract: Existing resources for Automatic Speech Recognition in Portuguese are mostly
focused on Brazilian Portuguese, leaving European Portuguese (EP) and other
varieties under-explored. To bridge this gap, we introduce CAM\~OES, the first
open framework for EP and other Portuguese varieties. It consists of (1) a
comprehensive evaluation benchmark, including 46h of EP test data spanning
multiple domains; and (2) a collection of state-of-the-art models. For the
latter, we consider multiple foundation models, evaluating their zero-shot and
fine-tuned performances, as well as E-Branchformer models trained from scratch.
A curated set of 425h of EP was used for both fine-tuning and training. Our
results show comparable performance for EP between fine-tuned foundation models
and the E-Branchformer. Furthermore, the best-performing models achieve
relative improvements above 35% WER, compared to the strongest zero-shot
foundation model, establishing a new state-of-the-art for EP and other
varieties.

</details>


### [53] [NLKI: A lightweight Natural Language Knowledge Integration Framework for Improving Small VLMs in Commonsense VQA Tasks](https://arxiv.org/abs/2508.19724)
*Aritra Dutta,Swapnanil Mukherjee,Deepanway Ghosal,Somak Aditya*

Main category: cs.CL

TL;DR: 提出了NLKI框架，通过检索自然语言事实和LLM生成解释来增强小型视觉语言模型的常识推理能力，在多个数据集上提升准确率7%，并通过噪声鲁棒训练进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 小型视觉语言模型在常识视觉问答中因缺乏外部知识而表现不佳，需要研究如何有效整合常识知识来提升其性能。

Method: 端到端框架NLKI：(i)使用微调的ColBERTv2检索自然语言事实，(ii)用LLM生成自然语言解释，(iii)将信号输入sVLMs，并结合噪声鲁棒损失进行微调。

Result: 在CRIC、AOKVQA和e-SNLI-VE数据集上提升准确率最高达7%，使FLAVA等模型达到或超过中等规模VLMs的性能，噪声鲁棒训练额外提升2.5-5.5%准确率。

Conclusion: LLM生成的常识知识优于知识库检索，噪声感知训练能稳定小模型性能，使2.5亿参数的模型也能实现高效的常识推理。

Abstract: Commonsense visual-question answering often hinges on knowledge that is
missing from the image or the question. Small vision-language models (sVLMs)
such as ViLT, VisualBERT and FLAVA therefore lag behind their larger generative
counterparts. To study the effect of careful commonsense knowledge integration
on sVLMs, we present an end-to-end framework (NLKI) that (i) retrieves natural
language facts, (ii) prompts an LLM to craft natural language explanations, and
(iii) feeds both signals to sVLMs respectively across two commonsense VQA
datasets (CRIC, AOKVQA) and a visual-entailment dataset (e-SNLI-VE). Facts
retrieved using a fine-tuned ColBERTv2 and an object information-enriched
prompt yield explanations that largely cut down hallucinations, while lifting
the end-to-end answer accuracy by up to 7% (across 3 datasets), making FLAVA
and other models in NLKI match or exceed medium-sized VLMs such as Qwen-2 VL-2B
and SmolVLM-2.5B. As these benchmarks contain 10-25% label noise, additional
finetuning using noise-robust losses (such as symmetric cross entropy and
generalised cross entropy) adds another 2.5% in CRIC, and 5.5% in AOKVQA. Our
findings expose when LLM-based commonsense knowledge beats retrieval from
commonsense knowledge bases, how noise-aware training stabilises small models
in the context of external knowledge augmentation, and why parameter-efficient
commonsense reasoning is now within reach for 250M models.

</details>


### [54] [Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval](https://arxiv.org/abs/2508.19740)
*Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji*

Main category: cs.CL

TL;DR: Spotlight Attention通过非线性哈希函数优化KV缓存选择，显著提升检索精度和推理效率，相比线性哈希缩短哈希码长度5倍以上，端到端吞吐量提升3倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用随机线性哈希识别重要token，但由于LLM中查询和键的正交分布特性，这种方法效率低下。需要更有效的KV缓存选择方法来加速推理同时保持性能。

Method: 提出Spotlight Attention方法：1) 使用非线性哈希函数优化查询和键的嵌入分布；2) 基于Bradley-Terry排序的轻量级训练框架；3) 实现专用CUDA内核利用位运算优势。

Result: 实验结果显示：哈希码长度缩短至少5倍，检索精度大幅提升；在单A100 GPU上512K token哈希检索时间低于100μs；端到端吞吐量比原始解码提升3倍。

Conclusion: Spotlight Attention通过非线性哈希优化和专用硬件加速，有效解决了LLM推理中的KV缓存负担问题，在保持性能的同时显著提升了推理效率。

Abstract: Reducing the key-value (KV) cache burden in Large Language Models (LLMs)
significantly accelerates inference. Dynamically selecting critical KV caches
during decoding helps maintain performance. Existing methods use random linear
hashing to identify important tokens, but this approach is inefficient due to
the orthogonal distribution of queries and keys within two narrow cones in
LLMs. We introduce Spotlight Attention, a novel method that employs non-linear
hashing functions to optimize the embedding distribution of queries and keys,
enhancing coding efficiency and robustness. We also developed a lightweight,
stable training framework using a Bradley-Terry ranking-based loss, enabling
optimization of the non-linear hashing module on GPUs with 16GB memory in 8
hours. Experimental results show that Spotlight Attention drastically improves
retrieval precision while shortening the length of the hash code at least
5$\times$ compared to traditional linear hashing. Finally, we exploit the
computational advantages of bitwise operations by implementing specialized CUDA
kernels, achieving hashing retrieval for 512K tokens in under 100$\mu$s on a
single A100 GPU, with end-to-end throughput up to 3$\times$ higher than vanilla
decoding.

</details>


### [55] [Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval](https://arxiv.org/abs/2508.19758)
*Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung*

Main category: cs.CL

TL;DR: NEWSCOPE是一个两阶段多样化新闻检索框架，通过句子级语义变化建模来提升事件报道的多样性，在保持相关性的同时显著提高检索结果的多样性。


<details>
  <summary>Details</summary>
Motivation: 现有新闻检索系统主要关注文本相关性，导致结果冗余且观点暴露有限，需要更好地获取多样化视角来理解真实世界事件。

Method: 两阶段框架：第一阶段使用密集检索获取主题相关内容，第二阶段应用句子级聚类和多样性感知重排序来发现补充信息。

Result: NEWSCOPE在保持相关性的同时显著提高了多样性，在LocalNews和DSGlobal两个基准测试中 consistently优于强基线方法。

Conclusion: 细粒度、可解释的建模能有效减少冗余并促进全面事件理解，提出的三个可解释度量指标为评估检索多样性提供了有效工具。

Abstract: Access to diverse perspectives is essential for understanding real-world
events, yet most news retrieval systems prioritize textual relevance, leading
to redundant results and limited viewpoint exposure. We propose NEWSCOPE, a
two-stage framework for diverse news retrieval that enhances event coverage by
explicitly modeling semantic variation at the sentence level. The first stage
retrieves topically relevant content using dense retrieval, while the second
stage applies sentence-level clustering and diversity-aware re-ranking to
surface complementary information. To evaluate retrieval diversity, we
introduce three interpretable metrics, namely Average Pairwise Distance,
Positive Cluster Coverage, and Information Density Ratio, and construct two
paragraph-level benchmarks: LocalNews and DSGlobal. Experiments show that
NEWSCOPE consistently outperforms strong baselines, achieving significantly
higher diversity without compromising relevance. Our results demonstrate the
effectiveness of fine-grained, interpretable modeling in mitigating redundancy
and promoting comprehensive event understanding. The data and code are
available at https://github.com/tangyixuan/NEWSCOPE.

</details>


### [56] [Principled Personas: Defining and Measuring the Intended Effects of Persona Prompting on Task Performance](https://arxiv.org/abs/2508.19764)
*Pedro Henrique Luz de Araujo,Paul Röttger,Dirk Hovy,Benjamin Roth*

Main category: cs.CL

TL;DR: 专家角色提示对语言模型性能影响的研究发现：专家角色通常带来正面或非显著性能变化，但模型对无关角色细节高度敏感，性能可能下降近30个百分点。


<details>
  <summary>Details</summary>
Motivation: 尽管专家角色提示被广泛用于任务改进，但先前研究对其有效性结果不一，且未考虑角色提示何时以及为何应该改善性能，需要系统分析角色提示的有效性条件。

Method: 分析角色提示文献并提炼三个期望标准，然后在27个任务上评估9个最先进的LLM，考察专家角色的性能优势、对无关属性的鲁棒性以及角色属性保真度。

Result: 专家角色通常带来正面或非显著性能变化；模型对无关角色细节高度敏感（性能下降近30%）；高等教育、专业化和领域相关性可以提升性能但效果不一致；缓解策略仅对最大、最强大的模型有效。

Conclusion: 研究结果强调了需要更谨慎的角色设计以及反映角色使用预期效果的评估方案，角色提示的有效性高度依赖于模型能力和具体任务特性。

Abstract: Expert persona prompting -- assigning roles such as expert in math to
language models -- is widely used for task improvement. However, prior work
shows mixed results on its effectiveness, and does not consider when and why
personas should improve performance. We analyze the literature on persona
prompting for task improvement and distill three desiderata: 1) performance
advantage of expert personas, 2) robustness to irrelevant persona attributes,
and 3) fidelity to persona attributes. We then evaluate 9 state-of-the-art LLMs
across 27 tasks with respect to these desiderata. We find that expert personas
usually lead to positive or non-significant performance changes. Surprisingly,
models are highly sensitive to irrelevant persona details, with performance
drops of almost 30 percentage points. In terms of fidelity, we find that while
higher education, specialization, and domain-relatedness can boost performance,
their effects are often inconsistent or negligible across tasks. We propose
mitigation strategies to improve robustness -- but find they only work for the
largest, most capable models. Our findings underscore the need for more careful
persona design and for evaluation schemes that reflect the intended effects of
persona usage.

</details>


### [57] [T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables](https://arxiv.org/abs/2508.19813)
*Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li*

Main category: cs.CL

TL;DR: 提出了表格到报告生成任务(T2R)并构建了双语基准T2R-bench，包含457个真实工业表格，评估显示当前最佳模型Deepseek-R1仅得62.71分，表明LLMs在该任务上仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有表格推理研究未能解决将表格信息转化为实际报告的核心工业需求，且现有基准缺乏对此类实际应用场景的评估能力。

Method: 构建包含457个真实工业表格的双语基准T2R-bench，涵盖19个行业领域和4种表格类型，并提出了专门的评估标准来衡量报告生成质量。

Result: 在25个广泛使用的LLMs上进行实验，发现即使是当前最先进的Deepseek-R1模型也仅获得62.71分的总体表现。

Conclusion: 表格到报告生成任务对LLMs仍具有挑战性，现有模型在该任务上还有很大的改进空间，T2R-bench为这一重要工业应用提供了有效的评估基准。

Abstract: Extensive research has been conducted to explore the capabilities of large
language models (LLMs) in table reasoning. However, the essential task of
transforming tables information into reports remains a significant challenge
for industrial applications. This task is plagued by two critical issues: 1)
the complexity and diversity of tables lead to suboptimal reasoning outcomes;
and 2) existing table benchmarks lack the capacity to adequately assess the
practical application of this task. To fill this gap, we propose the
table-to-report task and construct a bilingual benchmark named T2R-bench, where
the key information flow from the tables to the reports for this task. The
benchmark comprises 457 industrial tables, all derived from real-world
scenarios and encompassing 19 industry domains as well as 4 types of industrial
tables. Furthermore, we propose an evaluation criteria to fairly measure the
quality of report generation. The experiments on 25 widely-used LLMs reveal
that even state-of-the-art models like Deepseek-R1 only achieves performance
with 62.71 overall score, indicating that LLMs still have room for improvement
on T2R-bench. Source code and data will be available after acceptance.

</details>


### [58] [Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning](https://arxiv.org/abs/2508.19828)
*Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma*

Main category: cs.CL

TL;DR: Memory-R1是一个强化学习框架，通过两个专门代理（内存管理器和答案代理）使LLM能够主动管理外部内存，在少量训练数据下实现优于现有基线的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然强大但本质上是无状态的，受限于有限的上下文窗口，阻碍了长程推理。现有方法多为静态启发式，缺乏学习机制来决定存储、更新或检索内容。

Method: 使用强化学习（PPO和GRPO）框架，包含两个专门代理：内存管理器学习执行结构化内存操作（ADD、UPDATE、DELETE、NOOP），答案代理选择最相关条目并进行推理生成答案。

Result: 仅用152个问答对和相应的时间内存库进行训练，Memory-R1就超越了最具竞争力的现有基线，并在不同问题类型和LLM骨干网络上展现出强大的泛化能力。

Conclusion: 这项工作不仅提出了有效方法，还揭示了RL如何解锁LLM中更具代理性、内存感知的行为，指向更丰富、更持久的推理系统。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities across
a wide range of NLP tasks, but they remain fundamentally stateless, constrained
by limited context windows that hinder long-horizon reasoning. Recent efforts
to address this limitation often augment LLMs with an external memory bank, yet
most existing pipelines are static and heuristic-driven, lacking any learned
mechanism for deciding what to store, update, or retrieve. We present
Memory-R1, a reinforcement learning (RL) framework that equips LLMs with the
ability to actively manage and utilize external memory through two specialized
agents: a Memory Manager that learns to perform structured memory operations
{ADD, UPDATE, DELETE, NOOP}, and an Answer Agent that selects the most relevant
entries and reasons over them to produce an answer. Both agents are fine-tuned
with outcome-driven RL (PPO and GRPO), enabling adaptive memory management and
use with minimal supervision. With as few as 152 question-answer pairs and a
corresponding temporal memory bank for training, Memory-R1 outperforms the most
competitive existing baseline and demonstrates strong generalization across
diverse question types and LLM backbones. Beyond presenting an effective
approach, this work provides insights into how RL can unlock more agentic,
memory-aware behaviors in LLMs, pointing toward richer, more persistent
reasoning systems.

</details>


### [59] [Benchmarking Hindi LLMs: A New Suite of Datasets and a Comparative Analysis](https://arxiv.org/abs/2508.19831)
*Anusha Kamath,Kanishk Singla,Rakesh Paul,Raviraj Joshi,Utkarsh Vaidya,Sanjay Singh Chauhan,Niranjan Wartikar*

Main category: cs.CL

TL;DR: 这篇论文为印地语言模型提供了一套综合评测套件，包含五个专门设计的评测数据集，以解决直接翻译英语数据集无法抓取语言文化细腻的问题。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏高质量的印地语指令微调语言模型评测基准，直接翻译英语数据集会消失重要的语言和文化细腻。

Method: 采用了结合从头开始人工注释和翻译-验证过程的方法论，创建了五个印地语评测数据集：IFEval-Hi、MT-Bench-Hi、GSM8K-Hi、ChatRAG-Hi和BFCL-Hi。

Result: 利用这套评测套件对支持印地语的开源语言模型进行了全面基准测试，提供了它们当前能力的详细对比分析。

Conclusion: 这个数据集创建过程也为其他低资源语言开发评测基准提供了可复制的方法论。

Abstract: Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is
challenging due to a lack of high-quality benchmarks, as direct translation of
English datasets fails to capture crucial linguistic and cultural nuances. To
address this, we introduce a suite of five Hindi LLM evaluation datasets:
IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created
using a methodology that combines from-scratch human annotation with a
translate-and-verify process. We leverage this suite to conduct an extensive
benchmarking of open-source LLMs supporting Hindi, providing a detailed
comparative analysis of their current capabilities. Our curation process also
serves as a replicable methodology for developing benchmarks in other
low-resource languages.

</details>


### [60] [Scalable and consistent few-shot classification of survey responses using text embeddings](https://arxiv.org/abs/2508.19836)
*Jonas Timmann Mjaaland,Markus Fleten Kreutzer,Halvor Tyseng,Rebeckah K. Fussell,Gina Passante,N. G. Holmes,Anders Malthe-Sørenssen,Tor Ole B. Odden*

Main category: cs.CL

TL;DR: 本文提出了一种基于文本嵌入的分类框架，用于实现高效且一致的开放式问卷调查响应分析，只需每个类别几个示例就能达到与人类专家相当的分类效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统定性分析中编码过程耗时、不一致的问题，以及现有NLP方法需要大量标签数据、打破工作流程或结果不稳定等限制。

Method: 基于文本嵌入的分类框架，每个类别仅需几个示例，符合标准定性分析工作流程，支持文本嵌入模型的微调。

Result: 在2899个物理学调查响应的测试中，该框架与人类专家编码的Cohen's Kappa系数达到0.74-0.83，性能随嵌入模型微调而提升，可用于审计已分析数据集。

Conclusion: 文本嵌入辅助编码能够在保持可解释性的前提下应用于大规模数据，为扩大规模演绎性定性分析开启了新途径。

Abstract: Qualitative analysis of open-ended survey responses is a commonly-used
research method in the social sciences, but traditional coding approaches are
often time-consuming and prone to inconsistency. Existing solutions from
Natural Language Processing such as supervised classifiers, topic modeling
techniques, and generative large language models have limited applicability in
qualitative analysis, since they demand extensive labeled data, disrupt
established qualitative workflows, and/or yield variable results. In this
paper, we introduce a text embedding-based classification framework that
requires only a handful of examples per category and fits well with standard
qualitative workflows. When benchmarked against human analysis of a conceptual
physics survey consisting of 2899 open-ended responses, our framework achieves
a Cohen's Kappa ranging from 0.74 to 0.83 as compared to expert human coders in
an exhaustive coding scheme. We further show how performance of this framework
improves with fine-tuning of the text embedding model, and how the method can
be used to audit previously-analyzed datasets. These findings demonstrate that
text embedding-assisted coding can flexibly scale to thousands of responses
without sacrificing interpretability, opening avenues for deductive qualitative
analysis at scale.

</details>


### [61] [TokenVerse++: Towards Flexible Multitask Learning with Dynamic Task Activation](https://arxiv.org/abs/2508.19856)
*Shashi Kumar,Srikanth Madikeri,Esaú Villatoro-Tello,Sergio Burdisso,Pradeep Rangappa,Andrés Carofilis,Petr Motlicek,Karthik Pandia,Shankar Venkatesan,Kadri Hacioğlu,Andreas Stolcke*

Main category: cs.CL

TL;DR: TokenVerse++通过引入可学习向量实现动态任务激活，解决了TokenVerse需要完整标注的限制，能够利用部分标注数据集进行多任务训练，在保持ASR性能的同时提升了多任务处理的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于token的多任务框架如TokenVerse要求所有训练语句都必须有所有任务的完整标注，这限制了利用部分标注数据集的能力，阻碍了框架的可扩展性。

Method: 在XLSR-Transducer ASR模型的声学嵌入空间中引入可学习向量，实现动态任务激活机制，使得模型能够使用仅部分任务有标注的语句进行训练。

Result: 成功整合了部分标注数据集（ASR和语言识别任务），整体性能得到提升，在多个任务上达到或超过了TokenVerse的表现。

Conclusion: TokenVerse++成为了更实用的多任务替代方案，在不牺牲ASR性能的前提下，解决了部分标注数据利用的问题，具有更好的扩展性。

Abstract: Token-based multitasking frameworks like TokenVerse require all training
utterances to have labels for all tasks, hindering their ability to leverage
partially annotated datasets and scale effectively. We propose TokenVerse++,
which introduces learnable vectors in the acoustic embedding space of the
XLSR-Transducer ASR model for dynamic task activation. This core mechanism
enables training with utterances labeled for only a subset of tasks, a key
advantage over TokenVerse. We demonstrate this by successfully integrating a
dataset with partial labels, specifically for ASR and an additional task,
language identification, improving overall performance. TokenVerse++ achieves
results on par with or exceeding TokenVerse across multiple tasks, establishing
it as a more practical multitask alternative without sacrificing ASR
performance.

</details>


### [62] [Beyond Shallow Heuristics: Leveraging Human Intuition for Curriculum Learning](https://arxiv.org/abs/2508.19873)
*Vanessa Toborek,Sebastian Müller,Tim Selbach,Tamás Horváth,Christian Bauckhage*

Main category: cs.CL

TL;DR: 研究探讨使用Simple Wikipedia的人工标注作为课程学习信号，发现简单数据按课程顺序（先易后难）能有效提升语言模型性能，而基于能力的启发式方法效果不佳。


<details>
  <summary>Details</summary>
Motivation: 课程学习(CL)通过从易到难呈现数据来改善训练，但定义和衡量语言难度仍是一个开放挑战。本研究旨在探索人工标注的简单语言是否能作为有效的CL信号。

Method: 使用Simple Wikipedia语料库的文章级标签，将基于标签的课程与基于浅层启发式的能力策略进行比较。使用BERT-tiny模型进行实验，分析不同课程策略对困惑度的影响。

Result: 仅添加简单数据没有明显益处，但通过课程结构（特别是先引入简单语言）能持续改善困惑度，尤其在简单语言上效果显著。基于能力的课程相比随机排序没有一致增益。

Conclusion: 人类对语言难度的直觉可以指导语言模型预训练中的课程学习，人工标注的简单语言是有效的课程信号。

Abstract: Curriculum learning (CL) aims to improve training by presenting data from
"easy" to "hard", yet defining and measuring linguistic difficulty remains an
open challenge. We investigate whether human-curated simple language can serve
as an effective signal for CL. Using the article-level labels from the Simple
Wikipedia corpus, we compare label-based curricula to competence-based
strategies relying on shallow heuristics. Our experiments with a BERT-tiny
model show that adding simple data alone yields no clear benefit. However,
structuring it via a curriculum -- especially when introduced first --
consistently improves perplexity, particularly on simple language. In contrast,
competence-based curricula lead to no consistent gains over random ordering,
probably because they fail to effectively separate the two classes. Our results
suggest that human intuition about linguistic difficulty can guide CL for
language model pre-training.

</details>


### [63] [AI-Powered Detection of Inappropriate Language in Medical School Curricula](https://arxiv.org/abs/2508.19883)
*Chiman Salavati,Shannon Song,Scott A. Hale,Roberto E. Montenegro,Shiri Dori-Hacohen,Fabricio Murai*

Main category: cs.CL

TL;DR: 本文评估了小语言模型(SLMs)和预训练大语言模型(LLMs)在检测医学教学材料中不当语言使用(IUL)的效果，发现SLMs在性能上优于LLMs，多标签分类器表现最佳


<details>
  <summary>Details</summary>
Motivation: 医学教学材料中可能存在过时、排他性或非以患者为中心的不当语言，手动识别成本高昂且不切实际，需要自动化解决方案

Method: 使用约500份文档和12,000多页的数据集，评估了四种SLMs方法(通用IUL分类器、子类别二元分类器、多标签分类器、两阶段分层管道)和LLMs的上下文学习方法

Result: LLama-3 8B和70B即使使用精心设计的提示词，性能也大幅落后于SLMs。多标签分类器在标注数据上表现最佳，使用未标记摘录作为负样本可将特定分类器的AUC提升高达25%

Conclusion: SLMs特别是多标签分类器，是检测医学课程中有害语言的最有效模型，为医学教育材料的语言规范化提供了实用的自动化工具

Abstract: The use of inappropriate language -- such as outdated, exclusionary, or
non-patient-centered terms -- medical instructional materials can significantly
influence clinical training, patient interactions, and health outcomes. Despite
their reputability, many materials developed over past decades contain examples
now considered inappropriate by current medical standards. Given the volume of
curricular content, manually identifying instances of inappropriate use of
language (IUL) and its subcategories for systematic review is prohibitively
costly and impractical. To address this challenge, we conduct a first-in-class
evaluation of small language models (SLMs) fine-tuned on labeled data and
pre-trained LLMs with in-context learning on a dataset containing approximately
500 documents and over 12,000 pages. For SLMs, we consider: (1) a general IUL
classifier, (2) subcategory-specific binary classifiers, (3) a multilabel
classifier, and (4) a two-stage hierarchical pipeline for general IUL detection
followed by multilabel classification. For LLMs, we consider variations of
prompts that include subcategory definitions and/or shots. We found that both
LLama-3 8B and 70B, even with carefully curated shots, are largely outperformed
by SLMs. While the multilabel classifier performs best on annotated data,
supplementing training with unflagged excerpts as negative examples boosts the
specific classifiers' AUC by up to 25%, making them most effective models for
mitigating harmful language in medical curricula.

</details>


### [64] [Bangla-Bayanno: A 52K-Pair Bengali Visual Question Answering Dataset with LLM-Assisted Translation Refinement](https://arxiv.org/abs/2508.19887)
*Mohammed Rakibul Hasan,Rafi Majid,Ahanaf Tahmid*

Main category: cs.CL

TL;DR: Bangla-Bayanno是一个孟加拉语开放视觉问答数据集，包含52,650个问答对和4,750+图像，通过多语言LLM辅助翻译流程构建，旨在推动低资源多模态学习研究。


<details>
  <summary>Details</summary>
Motivation: 现有的VQA数据集要么是手动标注且专注于特定领域，要么受限于特定的答案格式。孟加拉语作为一种广泛使用但资源匮乏的语言，在多模态AI研究中缺乏高质量的数据集。

Method: 采用多语言大语言模型辅助的翻译优化流程，确保翻译质量并减少人为错误。数据集包含三种答案类型：名词性（简短描述）、数量性（数字）和极性（是/否）。

Result: 构建了包含52,650个问答对和4,750+图像的高质量数据集，克服了多语言来源的低质量翻译问题，提供了最全面的开源孟加拉语VQA基准。

Conclusion: Bangla-Bayanno为低资源多模态学习研究提供了重要资源，有助于开发更具包容性的AI系统，推动孟加拉语多模态AI研究的发展。

Abstract: In this paper, we introduce Bangla-Bayanno, an open-ended Visual Question
Answering (VQA) Dataset in Bangla, a widely used, low-resource language in
multimodal AI research. The majority of existing datasets are either manually
annotated with an emphasis on a specific domain, query type, or answer type or
are constrained by niche answer formats. In order to mitigate human-induced
errors and guarantee lucidity, we implemented a multilingual LLM-assisted
translation refinement pipeline. This dataset overcomes the issues of
low-quality translations from multilingual sources. The dataset comprises
52,650 question-answer pairs across 4750+ images. Questions are classified into
three distinct answer types: nominal (short descriptive), quantitative
(numeric), and polar (yes/no). Bangla-Bayanno provides the most comprehensive
open-source, high-quality VQA benchmark in Bangla, aiming to advance research
in low-resource multimodal learning and facilitate the development of more
inclusive AI systems.

</details>


### [65] [Logical Reasoning with Outcome Reward Models for Test-Time Scaling](https://arxiv.org/abs/2508.19903)
*Ramya Keerthy Thatikonda,Wray Buntine,Ehsan Shareghi*

Main category: cs.CL

TL;DR: 本文提出了用于演绎逻辑推理的结果奖励模型(ORMs)，通过链式思维和回声生成技术增强训练数据，在多个逻辑推理数据集上提升了大型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 逻辑推理是评估大型语言模型能力的重要基准，但目前测试时缩放与专用奖励模型结合的方法在演绎逻辑推理领域尚未充分探索。

Method: 使用单样本和多样本链式思维(CoT)生成训练数据，并提出回声生成技术来扩展训练数据中的错误类型覆盖，通过引导模型进行错误推理来获取更多样的训练样本。

Result: 在FOLIO、JustLogic和ProverQA三个数据集上，使用CoT和回声增强数据训练的ORMs在四种不同的大型语言模型上都表现出改进的性能。

Conclusion: 提出的ORMs和回声生成技术有效提升了大型语言模型在演绎逻辑推理任务中的表现，为复杂推理任务的性能增强提供了新途径。

Abstract: Logical reasoning is a critical benchmark for evaluating the capabilities of
large language models (LLMs), as it reflects their ability to derive valid
conclusions from given premises. While the combination of test-time scaling
with dedicated outcome or process reward models has opened up new avenues to
enhance LLMs performance in complex reasoning tasks, this space is
under-explored in deductive logical reasoning. We present a set of Outcome
Reward Models (ORMs) for deductive reasoning. To train the ORMs we mainly
generate data using Chain-of-Thought (CoT) with single and multiple samples.
Additionally, we propose a novel tactic to further expand the type of errors
covered in the training dataset of the ORM. In particular, we propose an echo
generation technique that leverages LLMs' tendency to reflect incorrect
assumptions made in prompts to extract additional training data, covering
previously unexplored error types. While a standard CoT chain may contain
errors likely to be made by the reasoner, the echo strategy deliberately steers
the model toward incorrect reasoning. We show that ORMs trained on CoT and
echo-augmented data demonstrate improved performance on the FOLIO, JustLogic,
and ProverQA datasets across four different LLMs.

</details>


### [66] [Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2508.19919)
*Jingyu Guo,Yingying Xu*

Main category: cs.CL

TL;DR: 研究发现AI多智能体系统在无预设偏见的中性环境中会自发产生刻板印象偏见，且随着交互轮次和决策权力增加而加剧，这种现象在不同LLM架构中一致出现。


<details>
  <summary>Details</summary>
Motivation: 虽然人类社交中的刻板印象已有充分研究，但AI系统通常被认为较少受此类偏见影响。以往研究关注训练数据带来的偏见，但刻板印象是否会在AI智能体交互中自发产生值得深入探索。

Method: 通过模拟工作场所交互的新实验框架，在初始中性条件下研究基于LLM的多智能体系统中刻板印象的出现和演化过程。

Result: 发现：(1)AI智能体在无预设偏见情况下会发展出刻板印象驱动的偏见；(2)刻板印象效应随交互轮次和决策权力增加而加剧，特别是在引入层级结构后；(3)系统表现出类似人类社交行为的群体效应；(4)这些模式在不同LLM架构中一致出现。

Conclusion: AI系统中的刻板印象形成可能是多智能体交互的涌现特性，而不仅仅是训练数据偏见的结果。需要进一步研究其底层机制并制定缓解策略。

Abstract: While stereotypes are well-documented in human social interactions, AI
systems are often presumed to be less susceptible to such biases. Previous
studies have focused on biases inherited from training data, but whether
stereotypes can emerge spontaneously in AI agent interactions merits further
exploration. Through a novel experimental framework simulating workplace
interactions with neutral initial conditions, we investigate the emergence and
evolution of stereotypes in LLM-based multi-agent systems. Our findings reveal
that (1) LLM-Based AI agents develop stereotype-driven biases in their
interactions despite beginning without predefined biases; (2) stereotype
effects intensify with increased interaction rounds and decision-making power,
particularly after introducing hierarchical structures; (3) these systems
exhibit group effects analogous to human social behavior, including halo
effects, confirmation bias, and role congruity; and (4) these stereotype
patterns manifest consistently across different LLM architectures. Through
comprehensive quantitative analysis, these findings suggest that stereotype
formation in AI systems may arise as an emergent property of multi-agent
interactions, rather than merely from training data biases. Our work
underscores the need for future research to explore the underlying mechanisms
of this phenomenon and develop strategies to mitigate its ethical impacts.

</details>


### [67] [HEAL: A Hypothesis-Based Preference-Aware Analysis Framework](https://arxiv.org/abs/2508.19922)
*Yifu Huo,Chenglong Wang,Qiren Zhu,Shunjie Xing,Tong Xiao,Chunliang Zhang,Tongran Liu,Jinbo Zhu*

Main category: cs.CL

TL;DR: 本文提出了HEAL评估框架，通过假设空间重排来评估偏好对齐方法，解决了现有方法只评估单一响应的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有偏好优化方法（如DPO）的评估仅关注单一响应，忽略了实际应用中可能生成的其他潜在输出，需要更全面的评估范式。

Method: 提出了HEAL框架，将偏好对齐建模为假设空间中的重排过程，包含两个互补指标：排序准确率（评估序数一致性）和偏好强度相关性（评估连续对齐）。构建了UniHypoBench统一假设基准。

Result: 实验表明当前偏好学习方法能有效捕捉代理模型的偏好，同时抑制负面样本。HEAL框架为偏好学习研究提供了理论创新和实践诊断工具。

Conclusion: HEAL框架为理解偏好对齐提供了新的理论范式，并为优化偏好对齐算法提供了实用的诊断工具，识别了开发更先进对齐算法的有前景方向。

Abstract: Preference optimization methods like DPO have achieved remarkable performance
in LLM alignment. However, the evaluation for these methods relies on a single
response and overlooks other potential outputs, which could also be generated
in real-world applications within this hypothetical space. To address this
issue, this paper presents a \textbf{H}ypothesis-based
Pr\textbf{E}ference-aware \textbf{A}na\textbf{L}ysis Framework (HEAL), a novel
evaluation paradigm that formulates preference alignment as a re-ranking
process within hypothesis spaces. The framework incorporates two complementary
metrics: ranking accuracy for evaluating ordinal consistency and preference
strength correlation for assessing continuous alignment. To facilitate this
framework, we develop UniHypoBench, a unified hypothesis benchmark constructed
from diverse instruction-response pairs. Through extensive experiments based on
HEAL, with a particular focus on the intrinsic mechanisms of preference
learning, we demonstrate that current preference learning methods can
effectively capture preferences provided by proxy models while simultaneously
suppressing negative samples. These findings contribute to preference learning
research through two significant avenues. Theoretically, we introduce
hypothesis space analysis as an innovative paradigm for understanding
preference alignment. Practically, HEAL offers researchers robust diagnostic
tools for refining preference optimization methods, while our empirical results
identify promising directions for developing more advanced alignment algorithms
capable of comprehensive preference capture.

</details>


### [68] [Dhati+: Fine-tuned Large Language Models for Arabic Subjectivity Evaluation](https://arxiv.org/abs/2508.19966)
*Slimane Bellaouar,Attia Nehar,Soumia Souffi,Mounia Bouameur*

Main category: cs.CL

TL;DR: 本文提出了一种新的阿拉伯语主观性分析方法，通过构建AraDhati+数据集并微调先进的语言模型，实现了97.79%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语作为语言资源匮乏的语言，缺乏大规模标注数据集，阻碍了主观性分析工具的发展。

Method: 利用现有阿拉伯语数据集构建AraDhati+数据集，微调XLM-RoBERTa、AraBERT和ArabianGPT等先进语言模型，并尝试集成决策方法。

Result: 所提出的方法在阿拉伯语主观性分类中达到了97.79%的准确率。

Conclusion: 该方法有效解决了阿拉伯语处理中资源有限的挑战，证明了深度学习和Transformer模型在阿拉伯语文本分类中的有效性。

Abstract: Despite its significance, Arabic, a linguistically rich and morphologically
complex language, faces the challenge of being under-resourced. The scarcity of
large annotated datasets hampers the development of accurate tools for
subjectivity analysis in Arabic. Recent advances in deep learning and
Transformers have proven highly effective for text classification in English
and French. This paper proposes a new approach for subjectivity assessment in
Arabic textual data. To address the dearth of specialized annotated datasets,
we developed a comprehensive dataset, AraDhati+, by leveraging existing Arabic
datasets and collections (ASTD, LABR, HARD, and SANAD). Subsequently, we
fine-tuned state-of-the-art Arabic language models (XLM-RoBERTa, AraBERT, and
ArabianGPT) on AraDhati+ for effective subjectivity classification.
Furthermore, we experimented with an ensemble decision approach to harness the
strengths of individual models. Our approach achieves a remarkable accuracy of
97.79\,\% for Arabic subjectivity classification. Results demonstrate the
effectiveness of the proposed approach in addressing the challenges posed by
limited resources in Arabic language processing.

</details>


### [69] [Diffusion Language Models Know the Answer Before Decoding](https://arxiv.org/abs/2508.19982)
*Pengxiang Li,Yefan Zhou,Dilxat Muhtar,Lu Yin,Shilin Yan,Li Shen,Yi Liang,Soroush Vosoughi,Shiwei Liu*

Main category: cs.CL

TL;DR: Prophet是一种无需训练的解码加速方法，利用扩散语言模型中早期答案收敛的特性，通过置信度差距动态决定何时停止采样或一次性解码剩余token，可将解码步骤减少3.4倍。


<details>
  <summary>Details</summary>
Motivation: 扩散语言模型(DLMs)虽然提供并行序列生成能力，但其推理速度仍慢于自回归模型，主要原因是双向注意力计算和大规模细化步骤的成本。研究发现DLMs存在早期答案收敛现象，即在最终解码步骤前模型已能识别正确答案。

Method: 提出Prophet训练免费快速解码范式：1）利用top-2预测候选之间的置信度差距作为标准；2）动态决定是继续细化还是"all-in"（一次性解码所有剩余token）；3）无缝集成到现有DLM实现中，无需额外训练。

Result: 在LLaDA-8B和Dream-7B模型上的多任务评估显示：Prophet将解码步骤减少高达3.4倍，同时保持高质量生成；在GSM8K和MMLU任务上，分别有97%和99%的实例仅需一半细化步骤即可正确解码。

Conclusion: Prophet将DLM解码重新定义为何时停止采样的问题，证明早期解码收敛是加速DLM推理的简单而强大的机制，与现有加速技术互补，为扩散模型的实际应用提供了重要改进。

Abstract: Diffusion language models (DLMs) have recently emerged as an alternative to
autoregressive approaches, offering parallel sequence generation and flexible
token orders. However, their inference remains slower than that of
autoregressive models, primarily due to the cost of bidirectional attention and
the large number of refinement steps required for high quality outputs. In this
work, we highlight and leverage an overlooked property of DLMs early answer
convergence: in many cases, the correct answer can be internally identified by
half steps before the final decoding step, both under semi-autoregressive and
random remasking schedules. For example, on GSM8K and MMLU, up to 97% and 99%
of instances, respectively, can be decoded correctly using only half of the
refinement steps. Building on this observation, we introduce Prophet, a
training-free fast decoding paradigm that enables early commit decoding.
Specifically, Prophet dynamically decides whether to continue refinement or to
go "all-in" (i.e., decode all remaining tokens in one step), using the
confidence gap between the top-2 prediction candidates as the criterion. It
integrates seamlessly into existing DLM implementations, incurs negligible
overhead, and requires no additional training. Empirical evaluations of
LLaDA-8B and Dream-7B across multiple tasks show that Prophet reduces the
number of decoding steps by up to 3.4x while preserving high generation
quality. These results recast DLM decoding as a problem of when to stop
sampling, and demonstrate that early decode convergence provides a simple yet
powerful mechanism for accelerating DLM inference, complementary to existing
speedup techniques. Our code is publicly available at
https://github.com/pixeli99/Prophet.

</details>


### [70] [AgentCoMa: A Compositional Benchmark Mixing Commonsense and Mathematical Reasoning in Real-World Scenarios](https://arxiv.org/abs/2508.19988)
*Lisa Alazraki,Lihu Chen,Ana Brassard,Joe Stacey,Hossein A. Rahmani,Marek Rei*

Main category: cs.CL

TL;DR: 论文提出了AgentCoMa基准测试，发现LLMs在处理混合类型的组合推理（常识+数学）时准确率下降约30%，远高于同类型多步骤组合推理的性能差距。


<details>
  <summary>Details</summary>
Motivation: 当前组合基准测试主要关注单一类型的推理（常识或数学），而现实世界任务需要结合多种推理类型。需要评估LLMs在混合类型组合推理中的表现。

Method: 构建AgentCoMa基准测试，包含需要常识推理和数学推理步骤的组合任务。测试61个不同规模、模型家族和训练策略的LLMs，并进行可解释性研究（神经元模式、注意力图和成员推断分析）。

Result: LLMs单独解决两个步骤时表现良好，但组合时准确率平均下降约30%。人类注释者能在组合问题和单独步骤上保持相似的高准确率。

Conclusion: LLMs在混合类型组合推理方面存在显著的脆弱性，AgentCoMa为未来改进提供了测试平台。

Abstract: Large Language Models (LLMs) have achieved high accuracy on complex
commonsense and mathematical problems that involve the composition of multiple
reasoning steps. However, current compositional benchmarks testing these skills
tend to focus on either commonsense or math reasoning, whereas LLM agents
solving real-world tasks would require a combination of both. In this work, we
introduce an Agentic Commonsense and Math benchmark (AgentCoMa), where each
compositional task requires a commonsense reasoning step and a math reasoning
step. We test it on 61 LLMs of different sizes, model families, and training
strategies. We find that LLMs can usually solve both steps in isolation, yet
their accuracy drops by ~30% on average when the two are combined. This is a
substantially greater performance gap than the one we observe in prior
compositional benchmarks that combine multiple steps of the same reasoning
type. In contrast, non-expert human annotators can solve the compositional
questions and the individual steps in AgentCoMa with similarly high accuracy.
Furthermore, we conduct a series of interpretability studies to better
understand the performance gap, examining neuron patterns, attention maps and
membership inference. Our work underscores a substantial degree of model
brittleness in the context of mixed-type compositional reasoning and offers a
test bed for future improvement.

</details>


### [71] [MathBuddy: A Multimodal System for Affective Math Tutoring](https://arxiv.org/abs/2508.19993)
*Debanjana Kar,Leopold Böss,Dacia Braca,Sebastian Maximilian Dennerlein,Nina Christine Hubig,Philipp Wintersberger,Yufang Hou*

Main category: cs.CL

TL;DR: MathBuddy是一个情感感知的数学辅导系统，通过分析学生的文本对话和面部表情来识别情绪状态，并据此调整教学策略，显著提升了LLM辅导的教学效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的学习模型没有考虑学生的情感状态，而教育心理学研究表明情绪状态会影响学习能力，因此需要开发能够感知和响应学生情绪的教育技术。

Method: 通过文本对话和面部表情双模态捕捉学生情绪，将情绪信息聚合后输入LLM，生成情感感知的教学回应，并映射到相应的教学策略。

Result: 在八个教学维度上使用自动评估指标和用户研究进行评估，获得了23%的胜率提升和3分的DAMR总分提升，证明了情感建模对教学能力的显著改善。

Conclusion: 通过建模学生情绪可以显著提升基于LLM的辅导系统的教学能力，情感感知是改善教育技术效果的重要方向。

Abstract: The rapid adoption of LLM-based conversational systems is already
transforming the landscape of educational technology. However, the current
state-of-the-art learning models do not take into account the student's
affective states. Multiple studies in educational psychology support the claim
that positive or negative emotional states can impact a student's learning
capabilities. To bridge this gap, we present MathBuddy, an emotionally aware
LLM-powered Math Tutor, which dynamically models the student's emotions and
maps them to relevant pedagogical strategies, making the tutor-student
conversation a more empathetic one. The student's emotions are captured from
the conversational text as well as from their facial expressions. The student's
emotions are aggregated from both modalities to confidently prompt our LLM
Tutor for an emotionally-aware response. We have effectively evaluated our
model using automatic evaluation metrics across eight pedagogical dimensions
and user studies. We report a massive 23 point performance gain using the win
rate and a 3 point gain at an overall level using DAMR scores which strongly
supports our hypothesis of improving LLM-based tutor's pedagogical abilities by
modeling students' emotions.

</details>


### [72] [ReSURE: Regularizing Supervision Unreliability for Multi-turn Dialogue Fine-tuning](https://arxiv.org/abs/2508.19996)
*Yiming Du,Yifan Xiang,Bin Liang,Dahua Lin,Kam-Fai Wong,Fei Tan*

Main category: cs.CL

TL;DR: ReSURE是一种自适应学习方法，通过动态降低不可靠监督的权重来改善多轮对话系统的微调效果，无需显式过滤数据


<details>
  <summary>Details</summary>
Motivation: 多轮对话系统微调需要高质量监督数据，但低质量数据会导致性能下降。早期轮次的监督错误会传播到后续轮次，破坏对话连贯性和响应质量。现有方法通过静态预过滤处理数据质量，但这种方法将质量控制与训练分离，无法缓解轮级错误传播

Method: 提出ReSURE方法，使用Welford在线统计估计每轮损失分布，并据此动态重新加权样本损失。该方法自适应地降低不可靠监督的权重，无需显式过滤

Result: 在单源和混合质量数据集上的实验显示，ReSURE提高了训练稳定性和响应质量。在多个基准测试中，响应分数与样本数量之间呈现正Spearman相关性（0.21~1.0），无论数据质量如何

Conclusion: ReSURE有效解决了多轮对话训练中的监督不可靠问题，为有效利用大规模数据铺平了道路。该方法代码已公开

Abstract: Fine-tuning multi-turn dialogue systems requires high-quality supervision but
often suffers from degraded performance when exposed to low-quality data.
Supervision errors in early turns can propagate across subsequent turns,
undermining coherence and response quality. Existing methods typically address
data quality via static prefiltering, which decouples quality control from
training and fails to mitigate turn-level error propagation. In this context,
we propose ReSURE (Regularizing Supervision UnREliability), an adaptive
learning method that dynamically down-weights unreliable supervision without
explicit filtering. ReSURE estimates per-turn loss distributions using
Welford's online statistics and reweights sample losses on the fly accordingly.
Experiments on both single-source and mixed-quality datasets show improved
stability and response quality. Notably, ReSURE enjoys positive Spearman
correlations (0.21 ~ 1.0 across multiple benchmarks) between response scores
and number of samples regardless of data quality, which potentially paves the
way for utilizing large-scale data effectively. Code is publicly available at
https://github.com/Elvin-Yiming-Du/ReSURE_Multi_Turn_Training.

</details>


### [73] [Selective Retrieval-Augmentation for Long-Tail Legal Text Classification](https://arxiv.org/abs/2508.19997)
*Boheng Mao*

Main category: cs.CL

TL;DR: 本文提出了选择性检索增强(SRA)方法，通过仅对训练集中低频标签的样本进行检索增强，解决法律文本分类中长尾分布导致的罕见类别性能不佳问题，无需改变模型架构且无需外部语料库。


<details>
  <summary>Details</summary>
Motivation: 法律文本分类基准数据集通常存在长尾标签分布，许多标签样本不足导致模型在罕见类别上表现不佳，需要一种有效的方法来增强低频标签样本而不引入噪声。

Method: 选择性检索增强(SRA)方法，仅从训练数据中检索并增强低频标签的样本，避免对充分表示的类别引入噪声，无需外部语料库且不改变模型架构。

Result: 在LEDGAR(单标签)和UNFAIR-ToS(多标签)两个法律文本分类基准数据集上，SRA方法在micro-F1和macro-F1分数上均优于所有当前LexGLUE基线方法。

Conclusion: SRA方法能够有效提升长尾法律文本分类的性能，在保持模型架构不变的情况下，通过选择性增强低频标签样本实现了一致的性能改进。

Abstract: Legal text classification is a fundamental NLP task in the legal domain.
Benchmark datasets in this area often exhibit a long-tail label distribution,
where many labels are underrepresented, leading to poor model performance on
rare classes. This paper proposes Selective Retrieval-Augmentation (SRA) as a
solution to this problem. SRA focuses on augmenting samples belonging to
low-frequency labels in the training set, preventing the introduction of noise
for well-represented classes, and requires no changes to the model
architecture. Retrieval is performed only from the training data to ensure
there is no potential information leakage, removing the need for external
corpora simultaneously. The proposed SRA method is tested on two legal text
classification benchmark datasets with long-tail distributions: LEDGAR
(single-label) and UNFAIR-ToS (multi-label). The results indicate that SRA
attains higher micro-F1 and macro-F1 scores compared to all current LexGLUE
baselines across both datasets, illustrating consistent improvements in
long-tail legal text classification. The code repository is available at:
https://github.com/Boheng-Mao/sra-legal

</details>


### [74] [DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis](https://arxiv.org/abs/2508.20033)
*Liana Patel,Negar Arabzadeh,Harshit Gupta,Ankita Sundar,Ion Stoica,Matei Zaharia,Carlos Guestrin*

Main category: cs.CL

TL;DR: DeepScholar-bench是一个用于评估生成式研究合成系统的实时基准测试框架，通过从arXiv论文中提取查询任务，评估系统在知识合成、检索质量和可验证性三个维度的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的问答基准测试主要关注简短的事实性回答，而专家策划的数据集存在过时和数据污染的风险，无法捕捉真实研究合成任务的复杂性和动态性。

Method: 从近期高质量的arXiv论文中提取查询任务，要求系统生成论文的相关工作章节，通过检索、合成和引用先前研究来评估性能。开发了DeepScholar-base作为参考管道。

Result: DeepScholar-base建立了强大的基线性能，达到或超过了其他方法的性能。所有系统在所有指标上的得分均未超过19%，表明基准测试难度较高。

Conclusion: DeepScholar-bench是一个重要且具有挑战性的基准测试，对于推动能够进行生成式研究合成的AI系统发展至关重要。

Abstract: The ability to research and synthesize knowledge is central to human
expertise and progress. An emerging class of systems promises these exciting
capabilities through generative research synthesis, performing retrieval over
the live web and synthesizing discovered sources into long-form, cited
summaries. However, evaluating such systems remains an open challenge: existing
question-answering benchmarks focus on short-form factual responses, while
expert-curated datasets risk staleness and data contamination. Both fail to
capture the complexity and evolving nature of real research synthesis tasks. In
this work, we introduce DeepScholar-bench, a live benchmark and holistic,
automated evaluation framework designed to evaluate generative research
synthesis. DeepScholar-bench draws queries from recent, high-quality ArXiv
papers and focuses on a real research synthesis task: generating the related
work sections of a paper by retrieving, synthesizing, and citing prior
research. Our evaluation framework holistically assesses performance across
three key dimensions, knowledge synthesis, retrieval quality, and
verifiability. We also develop DeepScholar-base, a reference pipeline
implemented efficiently using the LOTUS API. Using the DeepScholar-bench
framework, we perform a systematic evaluation of prior open-source systems,
search AI's, OpenAI's DeepResearch, and DeepScholar-base. We find that
DeepScholar-base establishes a strong baseline, attaining competitive or higher
performance than each other method. We also find that DeepScholar-bench remains
far from saturated, with no system exceeding a score of $19\%$ across all
metrics. These results underscore the difficulty of DeepScholar-bench, as well
as its importance for progress towards AI systems capable of generative
research synthesis. We make our code available at
https://github.com/guestrin-lab/deepscholar-bench.

</details>


### [75] [Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks](https://arxiv.org/abs/2508.20038)
*Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao*

Main category: cs.CL

TL;DR: IMAGINE是一个通过嵌入空间分布分析生成越狱指令的合成框架，旨在填补真实越狱模式与安全对齐语料库之间的分布差距，显著降低LLM的越狱攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在拒绝回答恶意指令方面有所改进，但现有LLM仍容易受到分布不同于安全对齐语料的越狱攻击，暴露出无法识别未见恶意指令的缺陷，迫使开发者陷入被动修补循环。

Method: 提出IMAGINE框架，利用嵌入空间分布分析生成类似越狱的指令，采用迭代优化过程动态演化文本生成分布，通过合成数据示例扩展安全对齐数据分布的覆盖范围。

Result: 基于IMAGINE增强的安全对齐语料库，在Qwen2.5、Llama3.1和Llama3.2模型上显著降低了攻击成功率，同时不损害模型的有用性。

Conclusion: IMAGINE框架有效解决了安全对齐语料与真实攻击之间的分布不匹配问题，为LLM安全防御提供了主动而非被动的解决方案。

Abstract: Despite advances in improving large language model(LLM) to refuse to answer
malicious instructions, widely used LLMs remain vulnerable to jailbreak attacks
where attackers generate instructions with distributions differing from safety
alignment corpora. New attacks expose LLMs' inability to recognize unseen
malicious instructions, highlighting a critical distributional mismatch between
training data and real-world attacks that forces developers into reactive
patching cycles. To tackle this challenge, we propose IMAGINE, a synthesis
framework that leverages embedding space distribution analysis to generate
jailbreak-like instructions. This approach effectively fills the distributional
gap between authentic jailbreak patterns and safety alignment corpora. IMAGINE
follows an iterative optimization process that dynamically evolves text
generation distributions across iterations, thereby augmenting the coverage of
safety alignment data distributions through synthesized data examples. Based on
the safety-aligned corpus enhanced through IMAGINE, our framework demonstrates
significant decreases in attack success rate on Qwen2.5, Llama3.1, and Llama3.2
without compromising their utility.

</details>


### [76] [AraHealthQA 2025 Shared Task Description Paper](https://arxiv.org/abs/2508.20047)
*Hassan Alhuzali,Farah Shamout,Muhammad Abdul-Mageed,Chaimae Abouzahir,Mouath Abu-Daoud,Ashwag Alasmari,Walid Al-Eisawi,Renad Al-Monef,Ali Alqahtani,Lama Ayash,Nizar Habash,Leen Kharouf*

Main category: cs.CL

TL;DR: AraHealthQA 2025是阿拉伯语健康问答共享任务，包含MentalQA和MedArabiQ两个赛道，分别关注心理健康和综合医疗领域，旨在解决阿拉伯语医疗QA资源匮乏问题。


<details>
  <summary>Details</summary>
Motivation: 解决高质量阿拉伯语医疗问答资源的稀缺问题，促进在现实、多语言和文化敏感的医疗场景下的模型开发。

Method: 通过创建两个互补赛道：MentalQA（心理健康问答）和MedArabiQ（综合医疗问答），每个赛道包含多个子任务、评估数据集和标准化指标，建立公平的基准测试框架。

Result: 提供了数据集创建、任务设计、评估框架、参与统计和基线系统的完整概述，并总结了整体成果。

Conclusion: 分析了性能趋势，展望了阿拉伯语健康问答未来的迭代发展前景。

Abstract: We introduce {AraHealthQA 2025}, the {Comprehensive Arabic Health Question
Answering Shared Task}, held in conjunction with {ArabicNLP 2025} (co-located
with EMNLP 2025). This shared task addresses the paucity of high-quality Arabic
medical QA resources by offering two complementary tracks: {MentalQA}, focusing
on Arabic mental health Q\&A (e.g., anxiety, depression, stigma reduction), and
{MedArabiQ}, covering broader medical domains such as internal medicine,
pediatrics, and clinical decision making. Each track comprises multiple
subtasks, evaluation datasets, and standardized metrics, facilitating fair
benchmarking. The task was structured to promote modeling under realistic,
multilingual, and culturally nuanced healthcare contexts. We outline the
dataset creation, task design and evaluation framework, participation
statistics, baseline systems, and summarize the overall outcomes. We conclude
with reflections on the performance trends observed and prospects for future
iterations in Arabic health QA.

</details>


### [77] [11Plus-Bench: Demystifying Multimodal LLM Spatial Reasoning with Cognitive-Inspired Analysis](https://arxiv.org/abs/2508.20068)
*Chengzu Li,Wenshan Wu,Huanyu Zhang,Qingtao Li,Zeyu Gao,Yan Xia,José Hernández-Orallo,Ivan Vulić,Furu Wei*

Main category: cs.CL

TL;DR: 本文提出了11Plus-Bench基准测试，系统评估多模态大语言模型的空间推理能力，发现当前MLLMs已展现出空间认知的早期迹象，但与人类相比仍存在较大性能差距。


<details>
  <summary>Details</summary>
Motivation: 人类认知过程中空间推理与感知紧密相关，但现有MLLMs评估中这种相互作用的性质仍未得到充分探索。需要系统评估MLLMs相对于人类表现的空间推理能力。

Method: 基于现实标准化空间能力测试构建高质量的11Plus-Bench基准测试，包含细粒度的专家注释，涵盖感知复杂性和推理过程。对14个MLLMs进行广泛实验并与人类评估进行比较。

Result: 当前MLLMs显示出空间认知的早期迹象，认知努力与推理相关复杂性高度相关，与人类相似。但MLLMs的实例级性能很大程度上是随机的，而人类正确性高度可预测且受抽象模式复杂性影响。

Conclusion: 研究结果突显了当前MLLMs空间推理能力的新兴能力和局限性，为推进模型设计提供了可行的见解。MLLMs与人类在空间认知方面仍存在显著差距。

Abstract: For human cognitive process, spatial reasoning and perception are closely
entangled, yet the nature of this interplay remains underexplored in the
evaluation of multimodal large language models (MLLMs). While recent MLLM
advancements show impressive performance on reasoning, their capacity for
human-like spatial cognition remains an open question. In this work, we
introduce a systematic evaluation framework to assess the spatial reasoning
abilities of state-of-the-art MLLMs relative to human performance. Central to
our work is 11Plus-Bench, a high-quality benchmark derived from realistic
standardized spatial aptitude tests. 11Plus-Bench also features fine-grained
expert annotations of both perceptual complexity and reasoning process,
enabling detailed instance-level analysis of model behavior. Through extensive
experiments across 14 MLLMs and human evaluation, we find that current MLLMs
exhibit early signs of spatial cognition. Despite a large performance gap
compared to humans, MLLMs' cognitive profiles resemble those of humans in that
cognitive effort correlates strongly with reasoning-related complexity.
However, instance-level performance in MLLMs remains largely random, whereas
human correctness is highly predictable and shaped by abstract pattern
complexity. These findings highlight both emerging capabilities and limitations
in current MLLMs' spatial reasoning capabilities and provide actionable
insights for advancing model design.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [78] [Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration](https://arxiv.org/abs/2508.19254)
*Jookyung Song,Mookyoung Kang,Nojun Kwak*

Main category: cs.CV

TL;DR: 一个实时生成式绘画系统，同时解释结构意图和语义意图，通过多阶段生成流程实现低延迟的协作美术创作。


<details>
  <summary>Details</summary>
Motivation: 传统的文本提示生成系统主要关注高级语义描述，而缺乏对绘画结构特征的理解。需要一种能同时分析几何特征和语义内容的统一转换方法。

Method: 系统同时分析地面级的直观几何特征（线条轨迹、比例、空间布局）和通过视觉-语言模型提取的高级语义线索。这些双重意图信号在一个结构保持的多阶段生成流程中关联条件化。

Result: 实现了低延迟的两阶段转换，支持多用户在共享画布上的协作。让不同艺术能力的参与者能够进行同步的共同视觉创作。

Conclusion: 该平台重新定义了人工智能互动为一种共创和相互增强的过程，为协作性美术创作提供了新的可能性。

Abstract: This paper presents a real-time generative drawing system that interprets and
integrates both formal intent - the structural, compositional, and stylistic
attributes of a sketch - and contextual intent - the semantic and thematic
meaning inferred from its visual content - into a unified transformation
process. Unlike conventional text-prompt-based generative systems, which
primarily capture high-level contextual descriptions, our approach
simultaneously analyzes ground-level intuitive geometric features such as line
trajectories, proportions, and spatial arrangement, and high-level semantic
cues extracted via vision-language models. These dual intent signals are
jointly conditioned in a multi-stage generation pipeline that combines
contour-preserving structural control with style- and content-aware image
synthesis. Implemented with a touchscreen-based interface and distributed
inference architecture, the system achieves low-latency, two-stage
transformation while supporting multi-user collaboration on shared canvases.
The resulting platform enables participants, regardless of artistic expertise,
to engage in synchronous, co-authored visual creation, redefining human-AI
interaction as a process of co-creation and mutual enhancement.

</details>


### [79] [TTF-VLA: Temporal Token Fusion via Pixel-Attention Integration for Vision-Language-Action Models](https://arxiv.org/abs/2508.19257)
*Chenghao Liu,Jiachen Zhang,Chengxuan Li,Zhimu Zhou,Shixin Wu,Songfang Huang,Huiling Duan*

Main category: cs.CV

TL;DR: 提出Temporal Token Fusion (TTF)方法，通过整合历史视觉信息来增强VLA模型在机器人操作任务中的性能，无需额外训练即可实现显著提升


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型逐帧处理视觉输入，丢弃了机器人操作任务中宝贵的时间信息，使其容易受到视觉噪声影响且忽略了连续帧之间的连贯性

Method: TTF方法结合灰度像素差异分析和基于注意力的语义相关性评估，通过硬融合策略和关键帧锚定选择性地融合时间token，防止误差累积

Result: 在LIBERO上平均提升4.0个百分点(72.4% vs 68.4%)，在SimplerEnv上相对提升4.8%，在真实机器人任务上相对提升8.7%，且证明具有模型无关性

Conclusion: 该方法不仅提升了性能，还发现选择性重用Query矩阵可以增强而非损害性能，为直接KQV矩阵重用策略提供了新方向，在实现计算加速的同时提高任务成功率

Abstract: Vision-Language-Action (VLA) models process visual inputs independently at
each timestep, discarding valuable temporal information inherent in robotic
manipulation tasks. This frame-by-frame processing makes models vulnerable to
visual noise while ignoring the substantial coherence between consecutive
frames in manipulation sequences. We propose Temporal Token Fusion (TTF), a
training-free approach that intelligently integrates historical and current
visual representations to enhance VLA inference quality. Our method employs
dual-dimension detection combining efficient grayscale pixel difference
analysis with attention-based semantic relevance assessment, enabling selective
temporal token fusion through hard fusion strategies and keyframe anchoring to
prevent error accumulation. Comprehensive experiments across LIBERO,
SimplerEnv, and real robot tasks demonstrate consistent improvements: 4.0
percentage points average on LIBERO (72.4\% vs 68.4\% baseline),
cross-environment validation on SimplerEnv (4.8\% relative improvement), and
8.7\% relative improvement on real robot tasks. Our approach proves
model-agnostic, working across OpenVLA and VLA-Cache architectures. Notably,
TTF reveals that selective Query matrix reuse in attention mechanisms enhances
rather than compromises performance, suggesting promising directions for direct
KQV matrix reuse strategies that achieve computational acceleration while
improving task success rates.

</details>


### [80] [Seeing Like a Designer Without One: A Study on Unsupervised Slide Quality Assessment via Designer Cue Augmentation](https://arxiv.org/abs/2508.19289)
*Tai Inui,Steven Oh,Magdeline Kuan*

Main category: cs.CV

TL;DR: 提出了一种结合专家视觉设计指标和CLIP-ViT嵌入的无监督幻灯片质量评估方法，在专业讲座幻灯片上表现优于主流视觉语言模型


<details>
  <summary>Details</summary>
Motivation: 需要一种可扩展、客观的实时幻灯片质量评估方法，以替代主观的人工评估，为演示者提供即时反馈

Method: 结合7个专家启发的视觉设计指标（留白、色彩丰富度、边缘密度、亮度对比度、文本密度、色彩协调性、布局平衡）和CLIP-ViT嵌入，使用隔离森林异常评分算法

Result: 在6个学术演讲（115张幻灯片）上评估，与人类视觉质量评分的皮尔逊相关系数最高达0.83，比主流视觉语言模型强1.79-3.23倍

Conclusion: 将低级设计线索与多模态嵌入相结合能够很好地近似观众对幻灯片质量的感知，实现可扩展的实时客观反馈

Abstract: We present an unsupervised slide-quality assessment pipeline that combines
seven expert-inspired visual-design metrics (whitespace, colorfulness, edge
density, brightness contrast, text density, color harmony, layout balance) with
CLIP-ViT embeddings, using Isolation Forest-based anomaly scoring to evaluate
presentation slides. Trained on 12k professional lecture slides and evaluated
on six academic talks (115 slides), our method achieved Pearson correlations up
to 0.83 with human visual-quality ratings-1.79x to 3.23x stronger than scores
from leading vision-language models (ChatGPT o4-mini-high, ChatGPT o3, Claude
Sonnet 4, Gemini 2.5 Pro). We demonstrate convergent validity with visual
ratings, discriminant validity against speaker-delivery scores, and exploratory
alignment with overall impressions. Our results show that augmenting low-level
design cues with multimodal embeddings closely approximates audience
perceptions of slide quality, enabling scalable, objective feedback in real
time.

</details>


### [81] [Efficient Model-Based Purification Against Adversarial Attacks for LiDAR Segmentation](https://arxiv.org/abs/2508.19290)
*Alexandros Gkillas,Ioulia Kapsali,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: 这篇论文提出了一种高效的模型基清洗框架，专门用于防御2D范围视图LiDAR分割中的对抗攻击，在保持计算效率的同时提供强大的对抗认证性能。


<details>
  <summary>Details</summary>
Motivation: 现代LiDAR分割网络容易受到对抗攻击威胁，而现有防御方法主要面向原始3D点云网络，对于普遍采用的2D范围视图表示缺乏轻量级的专门防御方案。

Method: 提出了一种直接在范围视图域的攻击形式化方法，并基于数学正当化的优化问题设计了可解释性的清洗网络。

Result: 在开放测试集上获得了竞争力的性能，一贵超过生成模型和对抗训练的基准方法，并在实际自动驾驶场景中体现了准确运行能力。

Conclusion: 该框架为2D范围视图LiDAR分割领域提供了一种高效、轻量级的对抗攻击防御方案，在保持计算效率的同时确保了自动驾驶系统的安全性。

Abstract: LiDAR-based segmentation is essential for reliable perception in autonomous
vehicles, yet modern segmentation networks are highly susceptible to
adversarial attacks that can compromise safety. Most existing defenses are
designed for networks operating directly on raw 3D point clouds and rely on
large, computationally intensive generative models. However, many
state-of-the-art LiDAR segmentation pipelines operate on more efficient 2D
range view representations. Despite their widespread adoption, dedicated
lightweight adversarial defenses for this domain remain largely unexplored. We
introduce an efficient model-based purification framework tailored for
adversarial defense in 2D range-view LiDAR segmentation. We propose a direct
attack formulation in the range-view domain and develop an explainable
purification network based on a mathematical justified optimization problem,
achieving strong adversarial resilience with minimal computational overhead.
Our method achieves competitive performance on open benchmarks, consistently
outperforming generative and adversarial training baselines. More importantly,
real-world deployment on a demo vehicle demonstrates the framework's ability to
deliver accurate operation in practical autonomous driving scenarios.

</details>


### [82] [Object Detection with Multimodal Large Vision-Language Models: An In-depth Review](https://arxiv.org/abs/2508.19294)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 这篇综述论文系统分析了大型视觉语言模型(LVLMs)在目标检测领域的应用，重点探讨了其架构创新、训练范式和对传统深度学习方法的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索语言和视觉融合在大型视觉语言模型中对目标检测的革命性影响，包括提升适应性、上下文推理能力和泛化性能。

Method: 采用三步研究综述方法：1)分析VLMs在目标检测中的工作原理；2)研究架构创新和训练范式；3)比较与传统深度学习方法的表现。

Result: 研究表明LVLMs在多样化场景中表现出色，包括定位和分割任务，预计很快将达到或超越传统方法性能，但仍存在一些主要局限性。

Conclusion: LVLMs的最新进展已经并将继续对目标检测和机器人应用产生变革性影响，论文提出了解决当前挑战的方案和未来发展路线图。

Abstract: The fusion of language and vision in large vision-language models (LVLMs) has
revolutionized deep learning-based object detection by enhancing adaptability,
contextual reasoning, and generalization beyond traditional architectures. This
in-depth review presents a structured exploration of the state-of-the-art in
LVLMs, systematically organized through a three-step research review process.
First, we discuss the functioning of vision language models (VLMs) for object
detection, describing how these models harness natural language processing
(NLP) and computer vision (CV) techniques to revolutionize object detection and
localization. We then explain the architectural innovations, training
paradigms, and output flexibility of recent LVLMs for object detection,
highlighting how they achieve advanced contextual understanding for object
detection. The review thoroughly examines the approaches used in integration of
visual and textual information, demonstrating the progress made in object
detection using VLMs that facilitate more sophisticated object detection and
localization strategies. This review presents comprehensive visualizations
demonstrating LVLMs' effectiveness in diverse scenarios including localization
and segmentation, and then compares their real-time performance, adaptability,
and complexity to traditional deep learning systems. Based on the review, its
is expected that LVLMs will soon meet or surpass the performance of
conventional methods in object detection. The review also identifies a few
major limitations of the current LVLM modes, proposes solutions to address
those challenges, and presents a clear roadmap for the future advancement in
this field. We conclude, based on this study, that the recent advancement in
LVLMs have made and will continue to make a transformative impact on object
detection and robotic applications in the future.

</details>


### [83] [Large VLM-based Stylized Sports Captioning](https://arxiv.org/abs/2508.19295)
*Sauptik Dhar,Nicholas Buoncristiani,Joe Anakata,Haoyu Zhang,Michelle Munson*

Main category: cs.CV

TL;DR: 该论文提出了一个两层级微调的LVLM管道，用于从图像生成专业级的体育比赛描述，相比现有方法在F1分数上提升8-10%，BERT分数提升2-10%，并在超级碗比赛中成功应用。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在体育领域缺乏足够的专业术语知识，无法生成自然、专业的人类化体育比赛描述，特别是在生产环境中需要特定风格格式的描述。

Method: 采用两层级微调的大型视觉语言模型管道，专门针对体育领域进行优化，能够处理图像并生成符合专业体育新闻风格的描述。

Result: 在F1分数上提升8-10%，BERT分数提升2-10%，具有较小的运行时内存占用和快速执行时间（6张图像/3-5秒），在超级碗LIX比赛中成功处理了1000多张图像。

Conclusion: 该两层级微调管道有效解决了现有模型在体育领域描述生成中的局限性，证明了其在实时专业体育新闻报道中的实际应用价值。

Abstract: The advent of large (visual) language models (LLM / LVLM) have led to a
deluge of automated human-like systems in several domains including social
media content generation, search and recommendation, healthcare prognosis, AI
assistants for cognitive tasks etc. Although these systems have been
successfully integrated in production; very little focus has been placed on
sports, particularly accurate identification and natural language description
of the game play. Most existing LLM/LVLMs can explain generic sports
activities, but lack sufficient domain-centric sports' jargon to create natural
(human-like) descriptions. This work highlights the limitations of existing
SoTA LLM/LVLMs for generating production-grade sports captions from images in a
desired stylized format, and proposes a two-level fine-tuned LVLM pipeline to
address that. The proposed pipeline yields an improvement > 8-10% in the F1,
and > 2-10% in BERT score compared to alternative approaches. In addition, it
has a small runtime memory footprint and fast execution time. During Super Bowl
LIX the pipeline proved its practical application for live professional sports
journalism; generating highly accurate and stylized captions at the rate of 6
images per 3-5 seconds for over 1000 images during the game play.

</details>


### [84] [DemoBias: An Empirical Study to Trace Demographic Biases in Vision Foundation Models](https://arxiv.org/abs/2508.19298)
*Abu Sufian,Anirudha Ghosh,Debaditya Barman,Marco Leo,Cosimo Distante*

Main category: cs.CV

TL;DR: 本文通过DemoBias研究评估了大型视觉语言模型在生物特征人脸识别任务中的人口统计偏见，发现LLaVA和PaliGemma在西班牙裔/拉丁裔、高加索人和南亚人群上存在较大性能差异，而BLIP-2表现相对一致。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在各种下游任务中表现出色，但在生物特征人脸识别中存在人口统计偏见问题，不同种族、性别和年龄群体的性能表现不均等，需要系统评估这种偏见程度。

Method: 对三种预训练LVLM模型（LLaVA、BLIP-2、PaliGemma）进行微调，使用自建的人口统计平衡数据集，采用BERTScores和公平性差异率等指标量化性能差异。

Result: 实验发现LVLMs存在人口统计偏见，PaliGemma和LLaVA在西班牙裔/拉丁裔、高加索人和南亚人群上表现出更高的性能差异，BLIP-2相对更加一致。

Conclusion: 研究表明当前LVLMs在生物特征人脸识别任务中存在显著的人口统计偏见，需要进一步改进模型公平性，确保在不同人口群体间的均衡性能表现。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable
capabilities across various downstream tasks, including biometric face
recognition (FR) with description. However, demographic biases remain a
critical concern in FR, as these foundation models often fail to perform
equitably across diverse demographic groups, considering ethnicity/race,
gender, and age. Therefore, through our work DemoBias, we conduct an empirical
evaluation to investigate the extent of demographic biases in LVLMs for
biometric FR with textual token generation tasks. We fine-tuned and evaluated
three widely used pre-trained LVLMs: LLaVA, BLIP-2, and PaliGemma on our own
generated demographic-balanced dataset. We utilize several evaluation metrics,
like group-specific BERTScores and the Fairness Discrepancy Rate, to quantify
and trace the performance disparities. The experimental results deliver
compelling insights into the fairness and reliability of LVLMs across diverse
demographic groups. Our empirical study uncovered demographic biases in LVLMs,
with PaliGemma and LLaVA exhibiting higher disparities for Hispanic/Latino,
Caucasian, and South Asian groups, whereas BLIP-2 demonstrated comparably
consistent. Repository: https://github.com/Sufianlab/DemoBias.

</details>


### [85] [Geo2Vec: Shape- and Distance-Aware Neural Representation of Geospatial Entities](https://arxiv.org/abs/2508.19305)
*Chen Chu,Cyrus Shahabi*

Main category: cs.CV

TL;DR: Geo2Vec是一种新的空间表示学习方法，直接在原始空间操作，通过自适应采样和符号距离场编码几何特征，避免了现有方法的分解计算和特征模糊问题。


<details>
  <summary>Details</summary>
Motivation: 现有空间表示学习方法要么只针对单一地理实体类型，要么需要分解实体进行傅里叶变换，计算成本高且缺乏几何对齐，导致细粒度特征模糊。

Method: 基于符号距离场(SDF)思想，直接在原始空间自适应采样点并编码符号距离(外部为正，内部为负)，使用神经网络近似SDF生成紧凑的几何感知表示，并提出旋转不变位置编码。

Result: 实验结果表明Geo2Vec在形状和位置表示、拓扑和距离关系捕捉方面均优于现有方法，在实际GeoAI应用中效率更高。

Conclusion: Geo2Vec提供了一种统一、高效且几何感知的空间表示学习方法，适用于各种地理实体类型，为下游GeoAI模型构建了结构化和鲁棒的嵌入空间。

Abstract: Spatial representation learning is essential for GeoAI applications such as
urban analytics, enabling the encoding of shapes, locations, and spatial
relationships (topological and distance-based) of geo-entities like points,
polylines, and polygons. Existing methods either target a single geo-entity
type or, like Poly2Vec, decompose entities into simpler components to enable
Fourier transformation, introducing high computational cost. Moreover, since
the transformed space lacks geometric alignment, these methods rely on uniform,
non-adaptive sampling, which blurs fine-grained features like edges and
boundaries. To address these limitations, we introduce Geo2Vec, a novel method
inspired by signed distance fields (SDF) that operates directly in the original
space. Geo2Vec adaptively samples points and encodes their signed distances
(positive outside, negative inside), capturing geometry without decomposition.
A neural network trained to approximate the SDF produces compact,
geometry-aware, and unified representations for all geo-entity types.
Additionally, we propose a rotation-invariant positional encoding to model
high-frequency spatial variations and construct a structured and robust
embedding space for downstream GeoAI models. Empirical results show that
Geo2Vec consistently outperforms existing methods in representing shape and
location, capturing topological and distance relationships, and achieving
greater efficiency in real-world GeoAI applications. Code and Data can be found
at: https://github.com/chuchen2017/GeoNeuralRepresentation.

</details>


### [86] [Advancements in Crop Analysis through Deep Learning and Explainable AI](https://arxiv.org/abs/2508.19307)
*Hamza Khan*

Main category: cs.CV

TL;DR: 本研究提出基于卷积神经网络的自动化方法，成功分类5种大米品种并诊断4种水稻叶部病害，结合可解释AI技术提升模型透明度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 大米作为全球重要主食，质量监控对消费者满意度和国家声誉至关重要。传统人工检测劳动密集、耗时且易出错，需要自动化解决方案进行质量控制和产量提升。

Method: 使用包含75000张图像的公开数据集，采用CNN、VGG16、ResNet50和MobileNetV2等深度学习模型，结合SHAP和LIME等可解释AI技术分析特征重要性。

Result: 模型表现出高分类准确率，误分类极少，有效区分不同大米品种。同时开发了准确的水稻叶部病害诊断方法，包括褐斑病、稻瘟病、白叶枯病和东格鲁病。

Conclusion: 深度学习在农业应用中具有巨大潜力，为构建稳健、可解释的自动化作物质量检测和病害诊断系统铺平道路，最终惠及农民、消费者和农业经济。

Abstract: Rice is a staple food of global importance in terms of trade, nutrition, and
economic growth. Among Asian nations such as China, India, Pakistan, Thailand,
Vietnam and Indonesia are leading producers of both long and short grain
varieties, including basmati, jasmine, arborio, ipsala, and kainat saila. To
ensure consumer satisfaction and strengthen national reputations, monitoring
rice crops and grain quality is essential. Manual inspection, however, is
labour intensive, time consuming and error prone, highlighting the need for
automated solutions for quality control and yield improvement. This study
proposes an automated approach to classify five rice grain varieties using
Convolutional Neural Networks (CNN). A publicly available dataset of 75000
images was used for training and testing. Model evaluation employed accuracy,
recall, precision, F1-score, ROC curves, and confusion matrices. Results
demonstrated high classification accuracy with minimal misclassifications,
confirming the model effectiveness in distinguishing rice varieties. In
addition, an accurate diagnostic method for rice leaf diseases such as Brown
Spot, Blast, Bacterial Blight, and Tungro was developed. The framework combined
explainable artificial intelligence (XAI) with deep learning models including
CNN, VGG16, ResNet50, and MobileNetV2. Explainability techniques such as SHAP
(SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic
Explanations) revealed how specific grain and leaf features influenced
predictions, enhancing model transparency and reliability. The findings
demonstrate the strong potential of deep learning in agricultural applications,
paving the way for robust, interpretable systems that can support automated
crop quality inspection and disease diagnosis, ultimately benefiting farmers,
consumers, and the agricultural economy.

</details>


### [87] [Sistema de Reconocimiento Facial Federado en Conjuntos Abiertos basado en OpenMax](https://arxiv.org/abs/2508.19312)
*Ander Galván,Marivi Higuero,Jorge Sasiain,Eduardo Jacob*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于联邦学习框架的面部识别系统，通过集成OpenMax算法来在开收集场景中区分已知和未知主体，以解决隐私和识别管理挑战。


<details>
  <summary>Details</summary>
Motivation: 人工智能面部识别虽在特定场景中实现了高精度，但在存在未知个体的开收集环境中面临着隐私和身份管理的重大挑战。

Method: 将OpenMax算法集成到联邦学习框架中，利用平均激活向量和本地距离测量的交换来可靠地区分已知和未知主体。

Result: 实验结果验证了所提出方案的有效性，证明其能够在分布式环境中提高隐私意识和稳健的面部识别能力。

Conclusion: 该研究为开收场景下的面部识别提供了一种隐私意识的联邦学习解决方案，通过结合OpenMax算法有效地处理了未知个体识别问题，为分布式环境中的面部识别系统提供了更好的隐私保护和稳健性。

Abstract: Facial recognition powered by Artificial Intelligence has achieved high
accuracy in specific scenarios and applications. Nevertheless, it faces
significant challenges regarding privacy and identity management, particularly
when unknown individuals appear in the operational context. This paper presents
the design, implementation, and evaluation of a facial recognition system
within a federated learning framework tailored to open-set scenarios. The
proposed approach integrates the OpenMax algorithm into federated learning,
leveraging the exchange of mean activation vectors and local distance measures
to reliably distinguish between known and unknown subjects. Experimental
results validate the effectiveness of the proposed solution, demonstrating its
potential for enhancing privacy-aware and robust facial recognition in
distributed environments.
  --
  El reconocimiento facial impulsado por Inteligencia Artificial ha demostrado
una alta precisi\'on en algunos escenarios y aplicaciones. Sin embargo,
presenta desaf\'ios relacionados con la privacidad y la identificaci\'on de
personas, especialmente considerando que pueden aparecer sujetos desconocidos
para el sistema que lo implementa. En este trabajo, se propone el dise\~no,
implementaci\'on y evaluaci\'on de un sistema de reconocimiento facial en un
escenario de aprendizaje federado, orientado a conjuntos abiertos.
Concretamente, se dise\~na una soluci\'on basada en el algoritmo OpenMax para
escenarios de aprendizaje federado. La propuesta emplea el intercambio de los
vectores de activaci\'on promedio y distancias locales para identificar de
manera eficaz tanto personas conocidas como desconocidas. Los experimentos
realizados demuestran la implementaci\'on efectiva de la soluci\'on propuesta.

</details>


### [88] [Automated classification of natural habitats using ground-level imagery](https://arxiv.org/abs/2508.19314)
*Mahdis Tourian,Sareh Rowlands,Remy Vandaele,Max Fancourt,Rebecca Mein,Hywel T. P. Williams*

Main category: cs.CV

TL;DR: 基于地面照片通过深度学习对生境进行分类的方法，使用DeepLabV3-ResNet101模型将照片分为18个生境类别，平均F1分数达0.61，并提供了在线分析工具。


<details>
  <summary>Details</summary>
Motivation: 传统的卫星图像生境分类方法需要野外生态学家验证，而地面照片能够提供更好的验证效果并支持大规模公民科学图像收集。

Method: 使用DeepLabV3-ResNet101深度学习模型，对照片进行调整大小、标准化和增强处理，重采样平衡训练数据集中的类别，采用五折交叉验证。

Result: 模型在18个生境类别上表现良好，平均F1分数为0.61。视觉特征明显的生境如免土、泥沙和沉积物类别F1分数超过0.90，混合或模糊类别分数较低。

Conclusion: 这种基于地面照片的生境分类方法具有很大潜力，因为地面照片容易获得，准确的计算方法可应用于生态监测等多个领域。研究还提供了简单的网站应用供实践者使用。

Abstract: Accurate classification of terrestrial habitats is critical for biodiversity
conservation, ecological monitoring, and land-use planning. Several habitat
classification schemes are in use, typically based on analysis of satellite
imagery with validation by field ecologists. Here we present a methodology for
classification of habitats based solely on ground-level imagery (photographs),
offering improved validation and the ability to classify habitats at scale (for
example using citizen-science imagery). In collaboration with Natural England,
a public sector organisation responsible for nature conservation in England,
this study develops a classification system that applies deep learning to
ground-level habitat photographs, categorising each image into one of 18
classes defined by the 'Living England' framework. Images were pre-processed
using resizing, normalisation, and augmentation; re-sampling was used to
balance classes in the training data and enhance model robustness. We developed
and fine-tuned a DeepLabV3-ResNet101 classifier to assign a habitat class label
to each photograph. Using five-fold cross-validation, the model demonstrated
strong overall performance across 18 habitat classes, with accuracy and
F1-scores varying between classes. Across all folds, the model achieved a mean
F1-score of 0.61, with visually distinct habitats such as Bare Soil, Silt and
Peat (BSSP) and Bare Sand (BS) reaching values above 0.90, and mixed or
ambiguous classes scoring lower. These findings demonstrate the potential of
this approach for ecological monitoring. Ground-level imagery is readily
obtained, and accurate computational methods for habitat classification based
on such data have many potential applications. To support use by practitioners,
we also provide a simple web application that classifies uploaded images using
our model.

</details>


### [89] [MIDAS: Multimodal Interactive Digital-human Synthesis via Real-time Autoregressive Video Generation](https://arxiv.org/abs/2508.19320)
*Ming Chen,Liyuan Cui,Wenyuan Zhang,Haoxian Zhang,Yan Zhou,Xiaohan Li,Xiaoqiang Liu,Pengfei Wan*

Main category: cs.CV

TL;DR: 提出了一种基于自回归模型的交互式数字人视频生成框架，支持多模态输入控制和低延迟流式生成


<details>
  <summary>Details</summary>
Motivation: 现有交互式数字人视频生成方法存在高延迟、高计算成本和有限可控性等问题，需要构建一个能够实时响应多样化输入信号的实用系统

Method: 基于大型语言模型(LLM)构建自回归视频生成框架，接受音频、姿态和文本等多模态条件编码，输出空间和语义一致的表征来指导扩散头的去噪过程；构建大规模对话数据集(约20,000小时)；引入深度压缩自编码器(最高64倍压缩比)

Result: 在双工对话、多语言人像合成和交互式世界模型等实验中表现出低延迟、高效率和细粒度多模态可控性的优势

Conclusion: 该框架成功解决了交互式数字人视频生成中的延迟和可控性问题，为实时多模态交互提供了有效解决方案

Abstract: Recently, interactive digital human video generation has attracted widespread
attention and achieved remarkable progress. However, building such a practical
system that can interact with diverse input signals in real time remains
challenging to existing methods, which often struggle with high latency, heavy
computational cost, and limited controllability. In this work, we introduce an
autoregressive video generation framework that enables interactive multimodal
control and low-latency extrapolation in a streaming manner. With minimal
modifications to a standard large language model (LLM), our framework accepts
multimodal condition encodings including audio, pose, and text, and outputs
spatially and semantically coherent representations to guide the denoising
process of a diffusion head. To support this, we construct a large-scale
dialogue dataset of approximately 20,000 hours from multiple sources, providing
rich conversational scenarios for training. We further introduce a deep
compression autoencoder with up to 64$\times$ reduction ratio, which
effectively alleviates the long-horizon inference burden of the autoregressive
model. Extensive experiments on duplex conversation, multilingual human
synthesis, and interactive world model highlight the advantages of our approach
in low latency, high efficiency, and fine-grained multimodal controllability.

</details>


### [90] [Deep Data Hiding for ICAO-Compliant Face Images: A Survey](https://arxiv.org/abs/2508.19324)
*Jefferson David Rodriguez Chivata,Davide Ghiani,Simone Maurizio La Cava,Marco Micheletto,Giulia Orrù,Federico Lama,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 该论文调查了数字水印和隐写术作为ICAO合规面部图像的防篡改解决方案，分析了现有技术的优缺点及其在身份验证系统中的适用性。


<details>
  <summary>Details</summary>
Motivation: ICAO合规面部图像虽然实现了全球互操作性，但也容易被用于恶意目的如身份盗窃和文档非法共享。传统的实时攻击检测方法无法提供捕获后的保护，需要寻找持久性验证方案。

Method: 通过全面分析最先进的数字水印和隐写技术，评估这些方法在ICAO合规图像应用中的潜力和局限性，同时考虑标准约束条件。

Result: 研究发现数字水印和隐写术能够在不影响ICAO合规性的前提下，为图像嵌入防篡改信号，提供持续验证能力。论文识别了关键技术权衡点。

Conclusion: 数字水印和隐写术是有效的补充解决方案，可为现实世界身份系统提供安全部署指导，实现ICAO合规图像的持久性防篡改保护。

Abstract: ICAO-compliant facial images, initially designed for secure biometric
passports, are increasingly becoming central to identity verification in a wide
range of application contexts, including border control, digital travel
credentials, and financial services. While their standardization enables global
interoperability, it also facilitates practices such as morphing and deepfakes,
which can be exploited for harmful purposes like identity theft and illegal
sharing of identity documents. Traditional countermeasures like Presentation
Attack Detection (PAD) are limited to real-time capture and offer no
post-capture protection. This survey paper investigates digital watermarking
and steganography as complementary solutions that embed tamper-evident signals
directly into the image, enabling persistent verification without compromising
ICAO compliance. We provide the first comprehensive analysis of
state-of-the-art techniques to evaluate the potential and drawbacks of the
underlying approaches concerning the applications involving ICAO-compliant
images and their suitability under standard constraints. We highlight key
trade-offs, offering guidance for secure deployment in real-world identity
systems.

</details>


### [91] [PRISM: A Framework Harnessing Unsupervised Visual Representations and Textual Prompts for Explainable MACE Survival Prediction from Cardiac Cine MRI](https://arxiv.org/abs/2508.19325)
*Haoyang Su,Jin-Yi Xiang,Shaohao Rui,Yifan Gao,Xingyu Chen,Tingxuan Yin,Xiaosong Wang,Lian-Ming Wu*

Main category: cs.CV

TL;DR: PRISM是一个自监督框架，通过整合心脏磁共振成像和电子健康记录进行生存分析，在四个独立临床队列中超越了传统生存预测模型和SOTA深度学习方法，并发现了三个与心脏风险相关的成像特征。


<details>
  <summary>Details</summary>
Motivation: 准确预测主要不良心脏事件（MACE）是心血管预后的核心挑战，需要整合多模态医疗数据来提升预测精度。

Method: PRISM通过运动感知多视图蒸馏提取时间同步的成像特征，并使用医学信息文本提示进行调制，整合非对比心脏电影磁共振成像和结构化电子健康记录进行生存分析。

Result: 在四个独立临床队列中，PRISM在内部和外部验证中一致超越经典生存预测模型和SOTA深度学习方法，发现了三个与MACE风险相关的成像特征：侧壁不同步、下壁超敏性和舒张期前壁高焦点。

Conclusion: PRISM整合成像和EHR表征为不同队列的心脏风险提供了有价值的见解，提示引导归因识别出高血压、糖尿病和吸烟是临床和生理EHR因素中的主要贡献者。

Abstract: Accurate prediction of major adverse cardiac events (MACE) remains a central
challenge in cardiovascular prognosis. We present PRISM (Prompt-guided
Representation Integration for Survival Modeling), a self-supervised framework
that integrates visual representations from non-contrast cardiac cine magnetic
resonance imaging with structured electronic health records (EHRs) for survival
analysis. PRISM extracts temporally synchronized imaging features through
motion-aware multi-view distillation and modulates them using medically
informed textual prompts to enable fine-grained risk prediction. Across four
independent clinical cohorts, PRISM consistently surpasses classical survival
prediction models and state-of-the-art (SOTA) deep learning baselines under
internal and external validation. Further clinical findings demonstrate that
the combined imaging and EHR representations derived from PRISM provide
valuable insights into cardiac risk across diverse cohorts. Three distinct
imaging signatures associated with elevated MACE risk are uncovered, including
lateral wall dyssynchrony, inferior wall hypersensitivity, and anterior
elevated focus during diastole. Prompt-guided attribution further identifies
hypertension, diabetes, and smoking as dominant contributors among clinical and
physiological EHR factors.

</details>


### [92] [EffNetViTLoRA: An Efficient Hybrid Deep Learning Approach for Alzheimer's Disease Diagnosis](https://arxiv.org/abs/2508.19349)
*Mahdieh Behjat Khatooni,Mohsen Soryani*

Main category: cs.CV

TL;DR: 提出EffNetViTLoRA模型，结合CNN和ViT架构，使用LoRA技术微调，在完整ADNI MRI数据集上实现AD、MCI和CN三分类，准确率达92.52%


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期诊断至关重要，MCI诊断因类别间差异细微而具有挑战性。现有研究多使用有限数据子集，需要更鲁棒和公正的模型

Method: 集成CNN和ViT架构捕获MRI图像的局部和全局特征，使用完整ADNI T1加权MRI数据集训练，采用LoRA技术有效适配预训练ViT模型到目标域

Result: 在AD、MCI和CN三分类任务中达到92.52%的分类准确率和92.76%的F1分数

Conclusion: EffNetViTLoRA模型通过整合CNN-ViT架构和LoRA微调技术，在完整ADNI数据集上实现了优异的AD诊断性能，具有临床可靠性

Abstract: Alzheimer's disease (AD) is one of the most prevalent neurodegenerative
disorders worldwide. As it progresses, it leads to the deterioration of
cognitive functions. Since AD is irreversible, early diagnosis is crucial for
managing its progression. Mild Cognitive Impairment (MCI) represents an
intermediate stage between Cognitively Normal (CN) individuals and those with
AD, and is considered a transitional phase from normal cognition to Alzheimer's
disease. Diagnosing MCI is particularly challenging due to the subtle
differences between adjacent diagnostic categories. In this study, we propose
EffNetViTLoRA, a generalized end-to-end model for AD diagnosis using the whole
Alzheimer's Disease Neuroimaging Initiative (ADNI) Magnetic Resonance Imaging
(MRI) dataset. Our model integrates a Convolutional Neural Network (CNN) with a
Vision Transformer (ViT) to capture both local and global features from MRI
images. Unlike previous studies that rely on limited subsets of data, our
approach is trained on the full T1-weighted MRI dataset from ADNI, resulting in
a more robust and unbiased model. This comprehensive methodology enhances the
model's clinical reliability. Furthermore, fine-tuning large pretrained models
often yields suboptimal results when source and target dataset domains differ.
To address this, we incorporate Low-Rank Adaptation (LoRA) to effectively adapt
the pretrained ViT model to our target domain. This method enables efficient
knowledge transfer and reduces the risk of overfitting. Our model achieves a
classification accuracy of 92.52% and an F1-score of 92.76% across three
diagnostic categories: AD, MCI, and CN for full ADNI dataset.

</details>


### [93] [Concurrent validity of computer-vision artificial intelligence player tracking software using broadcast footage](https://arxiv.org/abs/2508.19477)
*Zachary L. Crang,Rich D. Johnston,Katie L. Mills,Johsan Billingham,Sam Robertson,Michael H. Cole,Jonathon Weakley,Adam Hewitt and,Grant M. Duthie*

Main category: cs.CV

TL;DR: 本研究评估了商业计算机视觉和AI球员追踪软件使用转播画面测量球员位置、速度和距离的准确性，以及摄像头源和分辨率对精度的影响。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉和AI技术在体育分析中的应用日益广泛，需要验证这些商业软件使用标准转播画面进行球员追踪的准确性和可靠性。

Method: 使用2022年卡塔尔FIFA世界杯比赛数据，比较三家商业追踪提供商的数据与高精度多摄像头追踪系统(TRACAB Gen 5)的差异，计算均方根误差和平均偏差。

Result: 位置均方根误差1.68-16.39米，速度均方根误差0.34-2.38米/秒，总比赛距离平均偏差-21.8%到+24.3%。战术摄像头源能最大化球员检测精度。

Conclusion: 计算机视觉和AI球员追踪软件在检测到球员时具有合理精度，建议使用战术摄像头源，720p和1080p分辨率在适当模型下都适用。

Abstract: This study aimed to: (1) understand whether commercially available
computer-vision and artificial intelligence (AI) player tracking software can
accurately measure player position, speed and distance using broadcast footage
and (2) determine the impact of camera feed and resolution on accuracy. Data
were obtained from one match at the 2022 Qatar Federation Internationale de
Football Association (FIFA) World Cup. Tactical, programme and camera 1 feeds
were used. Three commercial tracking providers that use computer-vision and AI
participated. Providers analysed instantaneous position (x, y coordinates) and
speed (m\,s^{-1}) of each player. Their data were compared with a
high-definition multi-camera tracking system (TRACAB Gen 5). Root mean square
error (RMSE) and mean bias were calculated. Position RMSE ranged from 1.68 to
16.39 m, while speed RMSE ranged from 0.34 to 2.38 m\,s^{-1}. Total match
distance mean bias ranged from -1745 m (-21.8%) to 1945 m (24.3%) across
providers. Computer-vision and AI player tracking software offer the ability to
track players with fair precision when players are detected by the software.
Providers should use a tactical feed when tracking position and speed, which
will maximise player detection, improving accuracy. Both 720p and 1080p
resolutions are suitable, assuming appropriate computer-vision and AI models
are implemented.

</details>


### [94] [JVLGS: Joint Vision-Language Gas Leak Segmentation](https://arxiv.org/abs/2508.19485)
*Xinlong Zhao,Qixiang Pang,Shan Du*

Main category: cs.CV

TL;DR: 提出JVLGS框架，结合视觉和文本模态的优势，通过后处理减少误报，在气体泄漏分割任务中显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 气体泄漏对人类健康和环境造成严重威胁，但现有检测方法效果有限，特别是红外视频中气体云模糊和非刚性的特性限制了传统视觉方法的有效性

Method: 提出联合视觉-语言气体泄漏分割框架(JVLGS)，整合视觉和文本模态的互补优势，增强气体泄漏表示和分割能力，并包含后处理步骤减少噪声和非目标物体引起的误报

Result: 在多种场景下的广泛实验表明，JVLGS显著优于最先进的气体泄漏分割方法，在有监督和少样本学习设置下都表现优异

Conclusion: JVLGS框架通过多模态融合和后处理机制，有效解决了气体泄漏检测中的挑战，为准确可靠的气体泄漏识别提供了新解决方案

Abstract: Gas leaks pose serious threats to human health and contribute significantly
to atmospheric pollution, drawing increasing public concern. However, the lack
of effective detection methods hampers timely and accurate identification of
gas leaks. While some vision-based techniques leverage infrared videos for leak
detection, the blurry and non-rigid nature of gas clouds often limits their
effectiveness. To address these challenges, we propose a novel framework called
Joint Vision-Language Gas leak Segmentation (JVLGS), which integrates the
complementary strengths of visual and textual modalities to enhance gas leak
representation and segmentation. Recognizing that gas leaks are sporadic and
many video frames may contain no leak at all, our method incorporates a
post-processing step to reduce false positives caused by noise and non-target
objects, an issue that affects many existing approaches. Extensive experiments
conducted across diverse scenarios show that JVLGS significantly outperforms
state-of-the-art gas leak segmentation methods. We evaluate our model under
both supervised and few-shot learning settings, and it consistently achieves
strong performance in both, whereas competing methods tend to perform well in
only one setting or poorly in both. Code available at:
https://github.com/GeekEagle/JVLGS

</details>


### [95] [UNIFORM: Unifying Knowledge from Large-scale and Diverse Pre-trained Models](https://arxiv.org/abs/2508.19498)
*Yimu Wang,Weiming Zhuang,Chen Chen,Jiabo Huang,Jingtao Li,Lingjuan Lyu*

Main category: cs.CV

TL;DR: UNIFORM是一个新颖的知识整合框架，能够从多样化的预训练模型中提取共识知识，无需依赖训练数据分布或网络架构的强假设，显著提升了无监督目标识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识整合方法通常对训练数据分布和网络架构有强假设限制，只能从特定类型的模型中学习，存在数据和/或归纳偏差。需要一种能够有效利用多样化预训练模型集体知识的方法。

Method: 提出了专门的投票机制，在logit层面整合能够预测目标类别的教师模型知识，在特征层面利用任意标签空间学习的视觉表示，实现无约束的知识迁移。

Result: 大量实验表明，UNIFORM相比强知识迁移基线有效提升了无监督目标识别性能，具有显著的可扩展性，能够从100多个教师模型中受益，而现有方法在较小规模时就饱和。

Conclusion: UNIFORM框架成功解决了预训练模型异构性带来的知识整合挑战，提供了一种通用且可扩展的知识迁移方法，能够有效利用多样化模型的集体共识知识。

Abstract: In the era of deep learning, the increasing number of pre-trained models
available online presents a wealth of knowledge. These models, developed with
diverse architectures and trained on varied datasets for different tasks,
provide unique interpretations of the real world. Their collective consensus is
likely universal and generalizable to unseen data. However, effectively
harnessing this collective knowledge poses a fundamental challenge due to the
heterogeneity of pre-trained models. Existing knowledge integration solutions
typically rely on strong assumptions about training data distributions and
network architectures, limiting them to learning only from specific types of
models and resulting in data and/or inductive biases. In this work, we
introduce a novel framework, namely UNIFORM, for knowledge transfer from a
diverse set of off-the-shelf models into one student model without such
constraints. Specifically, we propose a dedicated voting mechanism to capture
the consensus of knowledge both at the logit level -- incorporating teacher
models that are capable of predicting target classes of interest -- and at the
feature level, utilizing visual representations learned on arbitrary label
spaces. Extensive experiments demonstrate that UNIFORM effectively enhances
unsupervised object recognition performance compared to strong knowledge
transfer baselines. Notably, it exhibits remarkable scalability by benefiting
from over one hundred teachers, while existing methods saturate at a much
smaller scale.

</details>


### [96] [Sat2Flow: A Structure-Aware Diffusion Framework for Human Flow Generation from Satellite Imagery](https://arxiv.org/abs/2508.19499)
*Xiangxu Wang,Tianhong Zhao,Wei Tu,Bowen Zhang,Guanzhou Chen,Jinzhou Cao*

Main category: cs.CV

TL;DR: Sat2Flow是一个基于扩散模型的框架，仅使用卫星图像生成结构一致的OD流量矩阵，解决了传统方法对辅助数据和空间拓扑敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有OD流量生成方法依赖成本高昂的辅助特征（如POI、社会经济统计数据），且对空间拓扑敏感，区域索引重排序会破坏生成流量的结构一致性。

Method: 提出多核编码器捕捉区域交互，采用排列感知扩散过程确保不同区域排序下的潜在表示对齐，通过联合对比训练目标和等变扩散训练实现结构一致性。

Result: 在真实城市数据集上的实验表明，Sat2Flow在数值精度上优于物理基线和数据驱动基线，同时在索引置换下保持经验分布和空间结构。

Conclusion: Sat2Flow为数据稀缺城市环境提供了可扩展的OD流量生成解决方案，消除了区域特定辅助数据依赖，同时保持结构不变性以实现稳健的移动性建模。

Abstract: Origin-Destination (OD) flow matrices are essential for urban mobility
analysis, underpinning applications in traffic forecasting, infrastructure
planning, and policy design. However, existing methods suffer from two critical
limitations: (1) reliance on auxiliary features (e.g., Points of Interest,
socioeconomic statistics) that are costly to collect and have limited spatial
coverage; and (2) sensitivity to spatial topology, where minor index reordering
of urban regions (e.g., census tract relabeling) disrupts structural coherence
in generated flows. To address these challenges, we propose Sat2Flow, a latent
structure-aware diffusion-based framework that generates structurally coherent
OD flows using solely satellite imagery as input. Our approach introduces a
multi-kernel encoder to capture diverse regional interactions and employs a
permutation-aware diffusion process that aligns latent representations across
different regional orderings. Through a joint contrastive training objective
that bridges satellite-derived features with OD patterns, combined with
equivariant diffusion training that enforces structural consistency, Sat2Flow
ensures topological robustness under arbitrary regional reindexing.
Experimental results on real-world urban datasets demonstrate that Sat2Flow
outperforms both physics-based and data-driven baselines in numerical accuracy
while preserving empirical distributions and spatial structures under index
permutations. Sat2Flow offers a globally scalable solution for OD flow
generation in data-scarce urban environments, eliminating region-specific
auxiliary data dependencies while maintaining structural invariance for robust
mobility modeling.

</details>


### [97] [Weed Detection in Challenging Field Conditions: A Semi-Supervised Framework for Overcoming Shadow Bias and Data Scarcity](https://arxiv.org/abs/2508.19511)
*Alzayat Saleh,Shunsuke Hatano,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 提出诊断驱动的半监督框架，解决农业杂草检测中的环境挑战和标注成本问题，通过伪标签利用未标注数据提升模型鲁棒性，有效缓解阴影偏差并提高召回率。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在真实农田环境中性能下降的两个关键问题：复杂环境条件和高昂的数据标注成本，特别是在入侵性杂草自动管理场景中。

Method: 使用975张标注和10,000张未标注的甘蔗地几内亚草图像数据集，建立强监督基线（ResNet分类、YOLO和RF-DETR检测），通过可解释性工具诊断发现阴影偏差问题，然后采用半监督伪标签框架利用未标注数据增强模型鲁棒性。

Result: 监督基线达到F1分数0.90和mAP50超过0.82；半监督框架有效缓解阴影偏差，显著提升召回率这一自动化喷洒系统的关键指标；在低数据量公共作物-杂草基准测试中验证了方法的有效性。

Conclusion: 提供了一个经过实地测试的清晰框架，用于开发、诊断和改进面向精准农业复杂现实的鲁棒计算机视觉系统，为可持续农业的自动化杂草管理提供了实用解决方案。

Abstract: The automated management of invasive weeds is critical for sustainable
agriculture, yet the performance of deep learning models in real-world fields
is often compromised by two factors: challenging environmental conditions and
the high cost of data annotation. This study tackles both issues through a
diagnostic-driven, semi-supervised framework. Using a unique dataset of
approximately 975 labeled and 10,000 unlabeled images of Guinea Grass in
sugarcane, we first establish strong supervised baselines for classification
(ResNet) and detection (YOLO, RF-DETR), achieving F1 scores up to 0.90 and
mAP50 scores exceeding 0.82. Crucially, this foundational analysis, aided by
interpretability tools, uncovered a pervasive "shadow bias," where models
learned to misidentify shadows as vegetation. This diagnostic insight motivated
our primary contribution: a semi-supervised pipeline that leverages unlabeled
data to enhance model robustness. By training models on a more diverse set of
visual information through pseudo-labeling, this framework not only helps
mitigate the shadow bias but also provides a tangible boost in recall, a
critical metric for minimizing weed escapes in automated spraying systems. To
validate our methodology, we demonstrate its effectiveness in a low-data regime
on a public crop-weed benchmark. Our work provides a clear and field-tested
framework for developing, diagnosing, and improving robust computer vision
systems for the complex realities of precision agriculture.

</details>


### [98] [MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment](https://arxiv.org/abs/2508.19527)
*Zhiting Gao,Dan Song,Diqiong Jiang,Chao Xue,An-An Liu*

Main category: cs.CV

TL;DR: 提出了TAPO和MotionFLUX统一框架，通过偏好优化对齐文本与运动语义，使用整流流匹配实现实时运动生成，在语义一致性和运动质量上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决文本驱动运动生成中语义对齐不精确和多步推理效率低的问题

Method: TAPO框架通过迭代调整强化语义基础，MotionFLUX基于确定性整流流匹配构建噪声分布与运动空间的最优传输路径

Result: 实验结果表明系统在语义一致性和运动质量上优于最先进方法，同时显著加速生成速度

Conclusion: TAPO和MotionFLUX形成了统一的实时高质量运动生成系统，代码和预训练模型将发布

Abstract: Motion generation is essential for animating virtual characters and embodied
agents. While recent text-driven methods have made significant strides, they
often struggle with achieving precise alignment between linguistic descriptions
and motion semantics, as well as with the inefficiencies of slow, multi-step
inference. To address these issues, we introduce TMR++ Aligned Preference
Optimization (TAPO), an innovative framework that aligns subtle motion
variations with textual modifiers and incorporates iterative adjustments to
reinforce semantic grounding. To further enable real-time synthesis, we propose
MotionFLUX, a high-speed generation framework based on deterministic rectified
flow matching. Unlike traditional diffusion models, which require hundreds of
denoising steps, MotionFLUX constructs optimal transport paths between noise
distributions and motion spaces, facilitating real-time synthesis. The
linearized probability paths reduce the need for multi-step sampling typical of
sequential methods, significantly accelerating inference time without
sacrificing motion quality. Experimental results demonstrate that, together,
TAPO and MotionFLUX form a unified system that outperforms state-of-the-art
approaches in both semantic consistency and motion quality, while also
accelerating generation speed. The code and pretrained models will be released.

</details>


### [99] [CVBench: Evaluating Cross-Video Synergies for Complex Multimodal Understanding and Reasoning](https://arxiv.org/abs/2508.19542)
*Nannan Zhu,Yonghao Dong,Teng Wang,Xueqian Li,Shengjun Deng,Yijia Wang,Zheng Hong,Tiantian Geng,Guo Niu,Hanyan Huang,Xiongfei Yao,Shuaiwei Jiao*

Main category: cs.CV

TL;DR: CVBench是首个专门评估多视频关系推理能力的综合基准，包含1000个QA对，涵盖三个层次：跨视频对象关联、事件关联和复杂推理。测试发现当前MLLMs在多视频推理方面存在显著性能差距，顶级模型如GPT-4o在因果推理任务上仅达到60%准确率，远低于人类的91%。


<details>
  <summary>Details</summary>
Motivation: 虽然多模态大语言模型在单视频任务上表现良好，但其在多视频推理能力方面尚未得到充分探索，而这种能力对于多摄像头监控、跨视频程序学习等实际应用至关重要。

Method: 构建CVBench基准，包含来自5个不同领域视频集群的1000个QA对，分为三个层次：跨视频对象关联、事件关联和复杂推理。评估了10多个领先的MLLMs在零样本和思维链提示下的表现。

Result: 评估结果显示显著性能差距：顶级模型如GPT-4o在因果推理任务上仅达到60%准确率，而人类表现达到91%。分析揭示了当前MLLM架构的根本瓶颈，包括跨视频上下文保持不足和重叠实体消歧能力差。

Conclusion: CVBench为诊断和推进多视频推理建立了严格框架，为下一代MLLMs提供了架构洞察。该基准揭示了当前模型在多视频推理方面的局限性，并指出了未来改进的方向。

Abstract: While multimodal large language models (MLLMs) exhibit strong performance on
single-video tasks (e.g., video question answering), their ability across
multiple videos remains critically underexplored. However, this capability is
essential for real-world applications, including multi-camera surveillance and
cross-video procedural learning. To bridge this gap, we present CVBench, the
first comprehensive benchmark designed to assess cross-video relational
reasoning rigorously. CVBench comprises 1,000 question-answer pairs spanning
three hierarchical tiers: cross-video object association (identifying shared
entities), cross-video event association (linking temporal or causal event
chains), and cross-video complex reasoning (integrating commonsense and domain
knowledge). Built from five domain-diverse video clusters (e.g., sports, life
records), the benchmark challenges models to synthesise information across
dynamic visual contexts. Extensive evaluation of 10+ leading MLLMs (including
GPT-4o, Gemini-2.0-flash, Qwen2.5-VL) under zero-shot or chain-of-thought
prompting paradigms. Key findings reveal stark performance gaps: even top
models, such as GPT-4o, achieve only 60% accuracy on causal reasoning tasks,
compared to the 91% accuracy of human performance. Crucially, our analysis
reveals fundamental bottlenecks inherent in current MLLM architectures, notably
deficient inter-video context retention and poor disambiguation of overlapping
entities. CVBench establishes a rigorous framework for diagnosing and advancing
multi-video reasoning, offering architectural insights for next-generation
MLLMs.The data and evaluation code are available at
https://github.com/Hokhim2/CVBench.

</details>


### [100] [WEBEYETRACK: Scalable Eye-Tracking for the Browser via On-Device Few-Shot Personalization](https://arxiv.org/abs/2508.19544)
*Eduardo Davalos,Yike Zhang,Namrata Srivastava,Yashvitha Thatigotla,Jorge A. Salas,Sara McFadden,Sun-Joo Cho,Amanda Goodwin,Ashwin TS,Gautam Biswas*

Main category: cs.CV

TL;DR: WebEyeTrack是一个浏览器内轻量级视线追踪框架，通过集成头部姿态估计和少样本学习，在移动设备上实现实时高精度视线估计


<details>
  <summary>Details</summary>
Motivation: 现有AI视线估计方法虽然性能优秀，但与商业眼动仪存在实际应用差距，且网络摄像头方法因头部运动导致精度不足，需要解决模型大小、推理时间和隐私等问题

Method: 在浏览器中集成轻量级SOTA视线估计模型，结合基于模型的头部姿态估计和仅需9个校准样本的少样本学习，实现设备端自适应学习

Result: 在GazeCapture数据集上达到2.32厘米误差的SOTA性能，在iPhone 14上实现2.4毫秒的实时推理速度

Conclusion: WebEyeTrack成功解决了浏览器端视线估计的精度和效率问题，为实时眼动追踪应用提供了可行的开源解决方案

Abstract: With advancements in AI, new gaze estimation methods are exceeding
state-of-the-art (SOTA) benchmarks, but their real-world application reveals a
gap with commercial eye-tracking solutions. Factors like model size, inference
time, and privacy often go unaddressed. Meanwhile, webcam-based eye-tracking
methods lack sufficient accuracy, in particular due to head movement. To tackle
these issues, we introduce We bEyeTrack, a framework that integrates
lightweight SOTA gaze estimation models directly in the browser. It
incorporates model-based head pose estimation and on-device few-shot learning
with as few as nine calibration samples (k < 9). WebEyeTrack adapts to new
users, achieving SOTA performance with an error margin of 2.32 cm on
GazeCapture and real-time inference speeds of 2.4 milliseconds on an iPhone 14.
Our open-source code is available at
https://github.com/RedForestAi/WebEyeTrack.

</details>


### [101] [MonoRelief V2: Leveraging Real Data for High-Fidelity Monocular Relief Recovery](https://arxiv.org/abs/2508.19555)
*Yu-Wei Zhang,Tongju Han,Lipeng Gao,Mingqiang Wei,Hui Liu,Changbao Li,Caiming Zhang*

Main category: cs.CV

TL;DR: MonoRelief V2是一个端到端模型，能够从单张图像中直接恢复2.5D浮雕，在复杂材质和光照变化下表现出色。相比仅使用合成数据训练的V1版本，V2通过整合真实数据显著提升了鲁棒性、准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像恢复2.5D浮雕的挑战，特别是在复杂材质和光照变化条件下。之前的MonoRelief V1仅使用合成数据训练，限制了其在真实场景中的性能。

Method: 1) 使用文本到图像生成模型生成约15,000张伪真实图像，并通过深度和法线预测融合获得深度伪标签；2) 构建小规模真实数据集（800个样本），通过多视角重建和细节细化；3) 在伪真实和真实数据集上进行渐进式训练。

Result: 综合实验表明，MonoRelief V2在深度和法线预测方面都达到了最先进的性能，展现出在下游应用中的强大潜力。

Conclusion: MonoRelief V2通过整合真实数据和创新的训练策略，显著提升了从单张图像恢复2.5D浮雕的性能，为相关应用提供了有效的解决方案。

Abstract: This paper presents MonoRelief V2, an end-to-end model designed for directly
recovering 2.5D reliefs from single images under complex material and
illumination variations. In contrast to its predecessor, MonoRelief V1 [1],
which was solely trained on synthetic data, MonoRelief V2 incorporates real
data to achieve improved robustness, accuracy and efficiency. To overcome the
challenge of acquiring large-scale real-world dataset, we generate
approximately 15,000 pseudo real images using a text-to-image generative model,
and derive corresponding depth pseudo-labels through fusion of depth and normal
predictions. Furthermore, we construct a small-scale real-world dataset (800
samples) via multi-view reconstruction and detail refinement. MonoRelief V2 is
then progressively trained on the pseudo-real and real-world datasets.
Comprehensive experiments demonstrate its state-of-the-art performance both in
depth and normal predictions, highlighting its strong potential for a range of
downstream applications. Code is at: https://github.com/glp1001/MonoreliefV2.

</details>


### [102] [FlowDet: Overcoming Perspective and Scale Challenges in Real-Time End-to-End Traffic Detection](https://arxiv.org/abs/2508.19565)
*Yuhang Zhao,Zixing Wang*

Main category: cs.CV

TL;DR: FlowDet是一个基于DETR架构的高速端到端目标检测器，通过解耦编码器优化策略、几何可变形单元和尺度感知注意力模块，在Intersection-Flow-5k数据集上实现了SOTA性能，同时显著降低了计算成本和提升了推理速度。


<details>
  <summary>Details</summary>
Motivation: 端到端目标检测器虽然提供了无NMS的实时应用前景，但其高计算成本仍是主要障碍，特别是在交叉路口交通监控等复杂场景中。

Method: 提出了FlowDet检测器，采用解耦编码器优化策略，包含几何可变形单元(GDU)进行交通感知几何建模，以及尺度感知注意力(SAA)模块处理极端尺度变化。

Result: 在Intersection-Flow-5k数据集上，相比RT-DETR基线，AP(test)提升1.5%，AP50(test)提升1.6%，同时GFLOPs减少63.2%，推理速度提升16.2%。

Conclusion: 这项工作展示了为苛刻的真实世界感知系统构建高效准确检测器的新路径，Intersection-Flow-5k数据集已公开。

Abstract: End-to-end object detectors offer a promising NMS-free paradigm for real-time
applications, yet their high computational cost remains a significant barrier,
particularly for complex scenarios like intersection traffic monitoring. To
address this challenge, we propose FlowDet, a high-speed detector featuring a
decoupled encoder optimization strategy applied to the DETR architecture.
Specifically, FlowDet employs a novel Geometric Deformable Unit (GDU) for
traffic-aware geometric modeling and a Scale-Aware Attention (SAA) module to
maintain high representational power across extreme scale variations. To
rigorously evaluate the model's performance in environments with severe
occlusion and high object density, we collected the Intersection-Flow-5k
dataset, a new challenging scene for this task. Evaluated on
Intersection-Flow-5k, FlowDet establishes a new state-of-the-art. Compared to
the strong RT-DETR baseline, it improves AP(test) by 1.5% and AP50(test) by
1.6%, while simultaneously reducing GFLOPs by 63.2% and increasing inference
speed by 16.2%. Our work demonstrates a new path towards building highly
efficient and accurate detectors for demanding, real-world perception systems.
The Intersection-Flow-5k dataset is available at
https://github.com/AstronZh/Intersection-Flow-5K.

</details>


### [103] [DNP-Guided Contrastive Reconstruction with a Reverse Distillation Transformer for Medical Anomaly Detection](https://arxiv.org/abs/2508.19573)
*Luhu Li,Bowen Lin,Mukhtiar Khan,Shujun Fu*

Main category: cs.CV

TL;DR: 提出结合可训练编码器和原型引导重建的统一框架，通过多样性感知对齐损失防止原型崩溃，在医学图像异常检测中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 医学图像异常检测面临标注稀缺和领域差异挑战，现有重建方法依赖冻结预训练编码器限制了领域适应性，原型学习方法存在原型崩溃问题

Method: 使用可训练编码器（含动量分支）进行领域自适应特征学习，轻量级原型提取器挖掘正常原型，通过注意力机制引导解码器重建，采用多样性感知对齐损失防止原型崩溃

Result: 在多个医学成像基准测试中显著提升了表示质量和异常定位精度，超越了现有方法

Conclusion: 该框架有效解决了原型崩溃问题，提高了医学图像异常检测的性能和可解释性

Abstract: Anomaly detection in medical images is challenging due to limited annotations
and a domain gap compared to natural images. Existing reconstruction methods
often rely on frozen pre-trained encoders, which limits adaptation to
domain-specific features and reduces localization accuracy. Prototype-based
learning offers interpretability and clustering benefits but suffers from
prototype collapse, where few prototypes dominate training, harming diversity
and generalization. To address this, we propose a unified framework combining a
trainable encoder with prototype-guided reconstruction and a novel
Diversity-Aware Alignment Loss. The trainable encoder, enhanced by a momentum
branch, enables stable domain-adaptive feature learning. A lightweight
Prototype Extractor mines informative normal prototypes to guide the decoder
via attention for precise reconstruction. Our loss enforces balanced prototype
use through diversity constraints and per-prototype normalization, effectively
preventing collapse. Experiments on multiple medical imaging benchmarks show
significant improvements in representation quality and anomaly localization,
outperforming prior methods. Visualizations and prototype assignment analyses
further validate the effectiveness of our anti-collapse mechanism and enhanced
interpretability.

</details>


### [104] [Multimodal Prototype Alignment for Semi-supervised Pathology Image Segmentation](https://arxiv.org/abs/2508.19574)
*Mingxi Fu,Fanglei Fu,Xitong Ling,Huaitian Yuan,Tian Guan,Yonghong He,Lianghui Zhu*

Main category: cs.CV

TL;DR: MPAMatch是一个新颖的多模态病理图像分割框架，通过图像和文本原型与像素标签的双重对比学习，在结构和语义层面提供监督，显著改善了语义边界建模。


<details>
  <summary>Details</summary>
Motivation: 解决病理图像分割中语义边界模糊和像素级标注成本高的问题，传统基于扰动一致性的方法难以捕获复杂病理图像的高级语义先验。

Method: 提出MPAMatch框架，采用多模态原型引导监督范式，进行图像原型-像素标签和文本原型-像素标签的双重对比学习，并使用病理预训练基础模型重构TransUNet架构。

Result: 在GLAS、EBHI-SEG-GLAND、EBHI-SEG-CANCER和KPI数据集上的广泛实验显示，MPAMatch优于最先进方法，验证了其在结构和语义建模方面的双重优势。

Conclusion: MPAMatch通过引入文本原型监督和双重对比学习机制，有效提升了病理图像分割的性能，特别是在语义边界建模方面取得了显著进展。

Abstract: Pathological image segmentation faces numerous challenges, particularly due
to ambiguous semantic boundaries and the high cost of pixel-level annotations.
Although recent semi-supervised methods based on consistency regularization
(e.g., UniMatch) have made notable progress, they mainly rely on
perturbation-based consistency within the image modality, making it difficult
to capture high-level semantic priors, especially in structurally complex
pathology images. To address these limitations, we propose MPAMatch - a novel
segmentation framework that performs pixel-level contrastive learning under a
multimodal prototype-guided supervision paradigm. The core innovation of
MPAMatch lies in the dual contrastive learning scheme between image prototypes
and pixel labels, and between text prototypes and pixel labels, providing
supervision at both structural and semantic levels. This coarse-to-fine
supervisory strategy not only enhances the discriminative capability on
unlabeled samples but also introduces the text prototype supervision into
segmentation for the first time, significantly improving semantic boundary
modeling. In addition, we reconstruct the classic segmentation architecture
(TransUNet) by replacing its ViT backbone with a pathology-pretrained
foundation model (Uni), enabling more effective extraction of
pathology-relevant features. Extensive experiments on GLAS, EBHI-SEG-GLAND,
EBHI-SEG-CANCER, and KPI show MPAMatch's superiority over state-of-the-art
methods, validating its dual advantages in structural and semantic modeling.

</details>


### [105] [Interact-Custom: Customized Human Object Interaction Image Generation](https://arxiv.org/abs/2508.19575)
*Zhu Xu,Zhaowen Wang,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 提出定制化人机交互图像生成任务(CHOI)，解决多目标概念定制生成中的交互控制问题，通过Interact-Custom模型实现身份保持和交互语义控制


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注目标实体的外观保持，忽略了目标实体之间的细粒度交互控制，需要开发能够同时保持身份特征和控制交互语义的模型

Method: 构建大规模数据集，设计两阶段模型Interact-Custom：首先生成描述交互行为的前景掩码来显式建模空间配置，然后在掩码指导下生成保持身份特征的目标人机交互图像

Result: 在专门为CHOI任务设计的指标上进行了广泛实验，证明了方法的有效性

Conclusion: 提出的Interact-Custom模型能够有效解决定制化人机交互图像生成中的身份保持和交互控制问题，提供了高内容可控性

Abstract: Compositional Customized Image Generation aims to customize multiple target
concepts within generation content, which has gained attention for its wild
application.Existing approaches mainly concentrate on the target entity's
appearance preservation, while neglecting the fine-grained interaction control
among target entities.To enable the model of such interaction control
capability, we focus on human object interaction scenario and propose the task
of Customized Human Object Interaction Image Generation(CHOI), which
simultaneously requires identity preservation for target human object and the
interaction semantic control between them.Two primary challenges exist for
CHOI:(1)simultaneous identity preservation and interaction control demands
require the model to decompose the human object into self-contained identity
features and pose-oriented interaction features, while the current HOI image
datasets fail to provide ideal samples for such feature-decomposed
learning.(2)inappropriate spatial configuration between human and object may
lead to the lack of desired interaction semantics.To tackle it, we first
process a large-scale dataset, where each sample encompasses the same pair of
human object involving different interactive poses.Then we design a two-stage
model Interact-Custom, which firstly explicitly models the spatial
configuration by generating a foreground mask depicting the interaction
behavior, then under the guidance of this mask, we generate the target human
object interacting while preserving their identities features.Furthermore, if
the background image and the union location of where the target human object
should appear are provided by users, Interact-Custom also provides the optional
functionality to specify them, offering high content controllability. Extensive
experiments on our tailored metrics for CHOI task demonstrate the effectiveness
of our approach.

</details>


### [106] [High-Speed FHD Full-Color Video Computer-Generated Holography](https://arxiv.org/abs/2508.19579)
*Haomiao Zhang,Miao Cao,Xuan Yu,Hui Luo,Yanling Piao,Mengjie Qin,Zhangyuan Li,Ping Wang,Xin Yuan*

Main category: cs.CV

TL;DR: 本文提出了一种高速全色全息视频生成方案，包括SGDDM颜色优化技术和HoloMamba空间-时间相关模型，实现了高保真度的高帧率全息显示。


<details>
  <summary>Details</summary>
Motivation: 解决学习基模型产生过平滑相位导致颜色交叉，以及帧间优化方法忽视空间-时间相关性造成计算效率低下的问题。

Method: 提出SGDDM通过频率调制优化相位分布，并设计HoloMamba轻量级非对称Mamba-Unet架构来显式建模视频序列的空间-时间相关性。

Result: SGDDM实现了高保真度全色显示而无需抑制帧率，HoloMamba能以超过260 FPS的速度生成FHD全色全息视频，比现有最佳方案快2.6倍以上。

Conclusion: 该方案有效解决了高速全息视频生成中的颜色保真度和计算效率问题，为下一代显示技术提供了有力支持。

Abstract: Computer-generated holography (CGH) is a promising technology for
next-generation displays. However, generating high-speed, high-quality
holographic video requires both high frame rate display and efficient
computation, but is constrained by two key limitations: ($i$) Learning-based
models often produce over-smoothed phases with narrow angular spectra, causing
severe color crosstalk in high frame rate full-color displays such as
depth-division multiplexing and thus resulting in a trade-off between frame
rate and color fidelity. ($ii$) Existing frame-by-frame optimization methods
typically optimize frames independently, neglecting spatial-temporal
correlations between consecutive frames and leading to computationally
inefficient solutions. To overcome these challenges, in this paper, we propose
a novel high-speed full-color video CGH generation scheme. First, we introduce
Spectrum-Guided Depth Division Multiplexing (SGDDM), which optimizes phase
distributions via frequency modulation, enabling high-fidelity full-color
display at high frame rates. Second, we present HoloMamba, a lightweight
asymmetric Mamba-Unet architecture that explicitly models spatial-temporal
correlations across video sequences to enhance reconstruction quality and
computational efficiency. Extensive simulated and real-world experiments
demonstrate that SGDDM achieves high-fidelity full-color display without
compromise in frame rate, while HoloMamba generates FHD (1080p) full-color
holographic video at over 260 FPS, more than 2.6$\times$ faster than the prior
state-of-the-art Divide-Conquer-and-Merge Strategy.

</details>


### [107] [Guiding Noisy Label Conditional Diffusion Models with Score-based Discriminator Correction](https://arxiv.org/abs/2508.19581)
*Dat Nguyen Cong,Hieu Tran Bao,Hoang Thanh-Tung*

Main category: cs.CV

TL;DR: 本文提出了Score-based Discriminator Correction (SBDC)方法，通过判别器训练和对抗损失来校正预训练条件扩散模型中的标签噪声问题，在生成过程早期应用指导以获得更好性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在大规模数据集上表现出色，但这些数据集往往包含人工标注错误。目前尚不清楚这些错误如何影响扩散模型的生成能力和可控性，因此需要研究有效的校正方法。

Method: 提出SBDC指导技术，基于判别器训练使用对抗损失，借鉴先前的噪声检测技术来评估每个样本的真实性。特别限制指导在生成过程早期阶段使用以获得更好性能。

Result: 方法计算效率高，仅略微增加推理时间，且不需要重新训练扩散模型。在不同噪声设置下的实验表明，该方法优于先前的最先进方法。

Conclusion: SBDC是一种有效的扩散模型校正技术，能够处理数据集中的标签噪声问题，提高生成质量，同时保持计算效率。

Abstract: Diffusion models have gained prominence as state-of-the-art techniques for
synthesizing images and videos, particularly due to their ability to scale
effectively with large datasets. Recent studies have uncovered that these
extensive datasets often contain mistakes from manual labeling processes.
However, the extent to which such errors compromise the generative capabilities
and controllability of diffusion models is not well studied. This paper
introduces Score-based Discriminator Correction (SBDC), a guidance technique
for aligning noisy pre-trained conditional diffusion models. The guidance is
built on discriminator training using adversarial loss, drawing on prior noise
detection techniques to assess the authenticity of each sample. We further show
that limiting the usage of our guidance to the early phase of the generation
process leads to better performance. Our method is computationally efficient,
only marginally increases inference time, and does not require retraining
diffusion models. Experiments on different noise settings demonstrate the
superiority of our method over previous state-of-the-art methods.

</details>


### [108] [Generalizing Monocular 3D Object Detection](https://arxiv.org/abs/2508.19593)
*Abhinav Kumar*

Main category: cs.CV

TL;DR: 该论文针对单目3D目标检测的泛化性问题，提出了多个创新方法：GrooMeD-NMS增强遮挡鲁棒性，DEVIANT主干网络提升数据集泛化能力，SeaBird方法解决大目标检测问题，并分析了相机高度外推的数学原理。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在自动驾驶、增强现实等应用中至关重要，但现有模型在遮挡、不同数据集、大目标检测和相机参数变化等多样化场景中的泛化能力不足，需要系统性的解决方案。

Method: 1. 提出数学可微的GrooMeD-NMS处理遮挡问题；2. 探索深度等变(DEVIANT)主干网络提升数据集泛化；3. 引入基于分割的SeaBird方法解决大目标检测的噪声敏感问题；4. 数学分析相机高度外推问题。

Result: 开发了多个专门方法分别解决单目3D检测中的不同泛化挑战，包括遮挡鲁棒性、跨数据集泛化、大目标检测精度以及相机参数外推能力。

Conclusion: 通过系统性的方法创新，显著提升了单目3D目标检测模型在多样化场景中的泛化性能，为实际应用提供了更可靠的3D环境理解能力。

Abstract: Monocular 3D object detection (Mono3D) is a fundamental computer vision task
that estimates an object's class, 3D position, dimensions, and orientation from
a single image. Its applications, including autonomous driving, augmented
reality, and robotics, critically rely on accurate 3D environmental
understanding. This thesis addresses the challenge of generalizing Mono3D
models to diverse scenarios, including occlusions, datasets, object sizes, and
camera parameters. To enhance occlusion robustness, we propose a mathematically
differentiable NMS (GrooMeD-NMS). To improve generalization to new datasets, we
explore depth equivariant (DEVIANT) backbones. We address the issue of large
object detection, demonstrating that it's not solely a data imbalance or
receptive field problem but also a noise sensitivity issue. To mitigate this,
we introduce a segmentation-based approach in bird's-eye view with dice loss
(SeaBird). Finally, we mathematically analyze the extrapolation of Mono3D
models to unseen camera heights and improve Mono3D generalization in such
out-of-distribution settings.

</details>


### [109] [Quantization Robustness to Input Degradations for Object Detection](https://arxiv.org/abs/2508.19600)
*Toghrul Karimov,Hassan Imani,Allan Kazakov*

Main category: cs.CV

TL;DR: 这篇论文通过实验研究评估了不同精度格式下YOLO模型的精度和稳健性，并提出了一种基于透化图像的校准策略，但该方法在大部分情况下并未带来明显改善。


<details>
  <summary>Details</summary>
Motivation: 评估后训练量化技术在对象检测模型中的影响，特别是对于实际部署环境中常见的图像透化问题的稳健性。

Method: 使用COCO数据集在7种不同透化条件下测试YOLO模型（nano到extra-large），比较了FP32、FP16、Dynamic UINT8和Static INT8等精度格式的表现，并提出了一种基于清洁和透化图像混合的校准策略。

Result: Static INT8 TensorRT引擎在清洁数据上实现了1.5-3.3倍速度提升，但mAP50-95持平均下降3-7%。透化感知校准策略在大部分模型和透化条件下未能一致改善稳健性，仅在大模型规模和特定噪声条件下有所改善。

Conclusion: 提高后训练量化模型的稳健性面临挑战，模型容量可能影响校准策略的效果，这为在非受控环境中部署量化检测器提供了有价值的见解。

Abstract: Post-training quantization (PTQ) is crucial for deploying efficient object
detection models, like YOLO, on resource-constrained devices. However, the
impact of reduced precision on model robustness to real-world input
degradations such as noise, blur, and compression artifacts is a significant
concern. This paper presents a comprehensive empirical study evaluating the
robustness of YOLO models (nano to extra-large scales) across multiple
precision formats: FP32, FP16 (TensorRT), Dynamic UINT8 (ONNX), and Static INT8
(TensorRT). We introduce and evaluate a degradation-aware calibration strategy
for Static INT8 PTQ, where the TensorRT calibration process is exposed to a mix
of clean and synthetically degraded images. Models were benchmarked on the COCO
dataset under seven distinct degradation conditions (including various types
and levels of noise, blur, low contrast, and JPEG compression) and a
mixed-degradation scenario. Results indicate that while Static INT8 TensorRT
engines offer substantial speedups (~1.5-3.3x) with a moderate accuracy drop
(~3-7% mAP50-95) on clean data, the proposed degradation-aware calibration did
not yield consistent, broad improvements in robustness over standard clean-data
calibration across most models and degradations. A notable exception was
observed for larger model scales under specific noise conditions, suggesting
model capacity may influence the efficacy of this calibration approach. These
findings highlight the challenges in enhancing PTQ robustness and provide
insights for deploying quantized detectors in uncontrolled environments. All
code and evaluation tables are available at https://github.com/AllanK24/QRID.

</details>


### [110] [IELDG: Suppressing Domain-Specific Noise with Inverse Evolution Layers for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2508.19604)
*Qizhe Fan,Chaoyu Liu,Zhonghua Qiao,Xiaoqin Shen*

Main category: cs.CV

TL;DR: 提出IELDM和IELFormer方法，通过逆演化层和频率融合模块提升跨域语义分割的泛化性能


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型生成数据中的结构/语义缺陷问题，避免训练分割模型时的性能下降和错误累积

Method: 集成逆演化层(IELs)到生成过程过滤缺陷，构建IELDM框架；在分割网络解码器中嵌入IELs形成IELFormer，并加入多尺度频率融合模块

Result: 在基准数据集上展现出优于现有方法的泛化性能

Conclusion: 逆演化层能有效抑制生成缺陷和伪影传播，多尺度频率融合增强了跨尺度语义一致性，显著提升了跨域语义分割的泛化能力

Abstract: Domain Generalized Semantic Segmentation (DGSS) focuses on training a model
using labeled data from a source domain, with the goal of achieving robust
generalization to unseen target domains during inference. A common approach to
improve generalization is to augment the source domain with synthetic data
generated by diffusion models (DMs). However, the generated images often
contain structural or semantic defects due to training imperfections. Training
segmentation models with such flawed data can lead to performance degradation
and error accumulation. To address this issue, we propose to integrate inverse
evolution layers (IELs) into the generative process. IELs are designed to
highlight spatial discontinuities and semantic inconsistencies using
Laplacian-based priors, enabling more effective filtering of undesirable
generative patterns. Based on this mechanism, we introduce IELDM, an enhanced
diffusion-based data augmentation framework that can produce higher-quality
images. Furthermore, we observe that the defect-suppression capability of IELs
can also benefit the segmentation network by suppressing artifact propagation.
Based on this insight, we embed IELs into the decoder of the DGSS model and
propose IELFormer to strengthen generalization capability in cross-domain
scenarios. To further strengthen the model's semantic consistency across
scales, IELFormer incorporates a multi-scale frequency fusion (MFF) module,
which performs frequency-domain analysis to achieve structured integration of
multi-resolution features, thereby improving cross-scale coherence. Extensive
experiments on benchmark datasets demonstrate that our approach achieves
superior generalization performance compared to existing methods.

</details>


### [111] [Controllable Skin Synthesis via Lesion-Focused Vector Autoregression Model](https://arxiv.org/abs/2508.19626)
*Jiajun Sun,Zhen Yu,Siyuan Yan,Jason J. Ong,Zongyuan Ge,Lei Zhang*

Main category: cs.CV

TL;DR: LF-VAR模型利用量化的病灶测量分数和病灶类型标签，通过语言提示指导临床相关且可控的皮肤图像合成，在7种病灶类型上取得了最佳FID分数（平均0.74），相比之前的最先进方法提升了6.3%。


<details>
  <summary>Details</summary>
Motivation: 真实临床实践中的皮肤图像数量有限，导致深度学习模型训练数据不足。现有皮肤图像合成方法往往生成质量低且无法控制病灶位置和类型。

Method: 训练多尺度病灶聚焦的VQVAE将图像编码为离散潜在表示，然后使用在token化表示上训练的视觉自回归变换器进行图像合成，并整合病灶测量和类型作为条件嵌入来增强合成保真度。

Result: 在7种病灶类型上取得了最佳FID分数（平均0.74），相比之前SOTA方法提升了6.3%，能够生成高保真、临床相关的合成皮肤图像。

Conclusion: LF-VAR模型通过语言提示实现了可控的皮肤图像合成，在生成高质量临床相关皮肤图像方面表现出色，为解决皮肤图像数据稀缺问题提供了有效解决方案。

Abstract: Skin images from real-world clinical practice are often limited, resulting in
a shortage of training data for deep-learning models. While many studies have
explored skin image synthesis, existing methods often generate low-quality
images and lack control over the lesion's location and type. To address these
limitations, we present LF-VAR, a model leveraging quantified lesion
measurement scores and lesion type labels to guide the clinically relevant and
controllable synthesis of skin images. It enables controlled skin synthesis
with specific lesion characteristics based on language prompts. We train a
multiscale lesion-focused Vector Quantised Variational Auto-Encoder (VQVAE) to
encode images into discrete latent representations for structured tokenization.
Then, a Visual AutoRegressive (VAR) Transformer trained on tokenized
representations facilitates image synthesis. Lesion measurement from the lesion
region and types as conditional embeddings are integrated to enhance synthesis
fidelity. Our method achieves the best overall FID score (average 0.74) among
seven lesion types, improving upon the previous state-of-the-art (SOTA) by
6.3%. The study highlights our controllable skin synthesis model's
effectiveness in generating high-fidelity, clinically relevant synthetic skin
images. Our framework code is available at
https://github.com/echosun1996/LF-VAR.

</details>


### [112] [Divide, Weight, and Route: Difficulty-Aware Optimization with Dynamic Expert Fusion for Long-tailed Recognition](https://arxiv.org/abs/2508.19630)
*Xiaolei Wei,Yi Ouyang,Haibo Ye*

Main category: cs.CV

TL;DR: DQRoute是一个针对长尾视觉识别的模块化框架，通过难度感知优化和动态专家协作来解决类别不平衡和分类难度差异问题。


<details>
  <summary>Details</summary>
Motivation: 长尾视觉识别不仅面临类别不平衡问题，还因为不同类别的分类难度差异而复杂化。简单的基于频率的类别重加权方法往往忽略了那些本质上难以学习的类别。

Method: DQRoute首先基于预测不确定性和历史性能估计类别难度，用这个信号指导自适应损失加权的训练。在架构方面，采用混合专家设计，每个专家专注于类别分布的不同区域。推理时，通过专家特定的OOD检测器生成的置信度分数对专家预测进行加权，实现无需集中路由器的输入自适应路由。所有组件以端到端方式联合训练。

Result: 在标准长尾基准测试上的实验表明，DQRoute显著提高了性能，特别是在稀有和困难类别上。

Conclusion: 该研究突出了将难度建模与去中心化专家路由相结合的好处，为解决长尾识别问题提供了有效方案。

Abstract: Long-tailed visual recognition is challenging not only due to class imbalance
but also because of varying classification difficulty across categories. Simply
reweighting classes by frequency often overlooks those that are intrinsically
hard to learn. To address this, we propose \textbf{DQRoute}, a modular
framework that combines difficulty-aware optimization with dynamic expert
collaboration. DQRoute first estimates class-wise difficulty based on
prediction uncertainty and historical performance, and uses this signal to
guide training with adaptive loss weighting. On the architectural side, DQRoute
employs a mixture-of-experts design, where each expert specializes in a
different region of the class distribution. At inference time, expert
predictions are weighted by confidence scores derived from expert-specific OOD
detectors, enabling input-adaptive routing without the need for a centralized
router. All components are trained jointly in an end-to-end manner. Experiments
on standard long-tailed benchmarks demonstrate that DQRoute significantly
improves performance, particularly on rare and difficult classes, highlighting
the benefit of integrating difficulty modeling with decentralized expert
routing.

</details>


### [113] [Beyond BEV: Optimizing Point-Level Tokens for Collaborative Perception](https://arxiv.org/abs/2508.19638)
*Yang Li,Quan Yuan,Guiyang Luo,Xiaoyuan Fu,Rui Pan,Yujia Yang,Congzhang Shao,Yuewen Liu,Jinglin Li*

Main category: cs.CV

TL;DR: CoPLOT是一个创新的协作感知框架，使用点级优化令牌来保留3D结构信息，通过语义感知重排序、频率增强状态空间模型和邻居到自车对齐模块，在降低通信和计算开销的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法通常使用2D鸟瞰图表示，丢弃了关键的3D结构信息，影响物体识别和定位的准确性。需要开发能够保留细粒度3D结构线索的中间表示方法。

Method: 提出点级令牌作为中间表示，包含三个核心模块：语义感知令牌重排序模块生成自适应1D重排序；频率增强状态空间模型捕获长距离序列依赖；邻居到自车对齐模块结合全局和局部校正来减轻定位噪声。

Result: 在模拟和真实数据集上的广泛实验表明，CoPLOT超越了最先进模型，同时具有更低的通信和计算开销。

Conclusion: 点级优化令牌是协作感知的有效中间表示，CoPLOT框架成功解决了点云数据无序、海量和位置敏感等挑战，为保留详细3D结构信息提供了新思路。

Abstract: Collaborative perception allows agents to enhance their perceptual
capabilities by exchanging intermediate features. Existing methods typically
organize these intermediate features as 2D bird's-eye-view (BEV)
representations, which discard critical fine-grained 3D structural cues
essential for accurate object recognition and localization. To this end, we
first introduce point-level tokens as intermediate representations for
collaborative perception. However, point-cloud data are inherently unordered,
massive, and position-sensitive, making it challenging to produce compact and
aligned point-level token sequences that preserve detailed structural
information. Therefore, we present CoPLOT, a novel Collaborative perception
framework that utilizes Point-Level Optimized Tokens. It incorporates a
point-native processing pipeline, including token reordering, sequence
modeling, and multi-agent spatial alignment. A semantic-aware token reordering
module generates adaptive 1D reorderings by leveraging scene-level and
token-level semantic information. A frequency-enhanced state space model
captures long-range sequence dependencies across both spatial and spectral
domains, improving the differentiation between foreground tokens and background
clutter. Lastly, a neighbor-to-ego alignment module applies a closed-loop
process, combining global agent-level correction with local token-level
refinement to mitigate localization noise. Extensive experiments on both
simulated and real-world datasets show that CoPLOT outperforms state-of-the-art
models, with even lower communication and computation overhead. Code will be
available at https://github.com/CheeryLeeyy/CoPLOT.

</details>


### [114] [UTAL-GNN: Unsupervised Temporal Action Localization using Graph Neural Networks](https://arxiv.org/abs/2508.19647)
*Bikash Kumar Badatya,Vipul Baghel,Ravi Hegde*

Main category: cs.CV

TL;DR: 这篇论文提出了一种轻量级无监督骨架基动作定位方法，通过空间时间图印象学习和动作动力学指标，在激活跃水数据集上达到了与监督方法相当的性能，具有高效率和强遍化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的细粒度动作定位方法需要大量标注数据和高容量模型，计算成本高且适应性差，难以应用于实际场景。需要一种轻量级、无监督的方案来解决这些问题。

Method: 提出了一种无监督骨架基动作定位流程，使用关注机制空间旰间图印象网络(ASTGCN)在姿势序列去噪任务上进行预训练，学习内在动作动力学。推理时通过动作动力学指标(ADM)检测动作边界。

Result: 在DSV Diving数据集上达到了82.66%的平均精度(mAP)和29.09毫秒的平均定位延迟，性能与监督方法相当，同时保持计算效率。在未见的野外激活跃水视频中也表现出强劲的遍化能力。

Conclusion: 该方法为嵌入式或动态环境中的轻量级实时动作分析系统提供了一种高效、无需标注且具有良好遍化能力的实用方案。

Abstract: Fine-grained action localization in untrimmed sports videos presents a
significant challenge due to rapid and subtle motion transitions over short
durations. Existing supervised and weakly supervised solutions often rely on
extensive annotated datasets and high-capacity models, making them
computationally intensive and less adaptable to real-world scenarios. In this
work, we introduce a lightweight and unsupervised skeleton-based action
localization pipeline that leverages spatio-temporal graph neural
representations. Our approach pre-trains an Attention-based Spatio-Temporal
Graph Convolutional Network (ASTGCN) on a pose-sequence denoising task with
blockwise partitions, enabling it to learn intrinsic motion dynamics without
any manual labeling. At inference, we define a novel Action Dynamics Metric
(ADM), computed directly from low-dimensional ASTGCN embeddings, which detects
motion boundaries by identifying inflection points in its curvature profile.
Our method achieves a mean Average Precision (mAP) of 82.66% and average
localization latency of 29.09 ms on the DSV Diving dataset, matching
state-of-the-art supervised performance while maintaining computational
efficiency. Furthermore, it generalizes robustly to unseen, in-the-wild diving
footage without retraining, demonstrating its practical applicability for
lightweight, real-time action analysis systems in embedded or dynamic
environments.

</details>


### [115] [IDF: Iterative Dynamic Filtering Networks for Generalizable Image Denoising](https://arxiv.org/abs/2508.19649)
*Dongjin Kim,Jaekyun Ko,Muhammad Kashif Ali,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 提出了一种基于动态生成核的迭代图像去噪方法，通过特征提取、全局统计和局部相关性模块来预测像素级变化核，在单一高斯噪声训练下实现多种噪声类型和级别的优秀泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖特定噪声分布，泛化能力有限，且需要大量训练数据和计算资源，容易过拟合。需要一种更高效、泛化能力强的去噪方法。

Method: 使用特征提取模块获取噪声不变特征，通过全局统计和局部相关性模块捕捉噪声特征和结构相关性，核预测模块生成像素级变化核，采用迭代动态滤波进行去噪。

Result: 紧凑模型（约0.04M参数）在单一高斯噪声训练下，对多种噪声类型和级别都表现出优秀性能，证明了迭代动态滤波在实际图像去噪中的潜力。

Conclusion: 动态核生成和迭代滤波方法有效解决了传统方法的过拟合问题，提高了对未知噪声的鲁棒性，为实际图像去噪提供了高效且泛化能力强的解决方案。

Abstract: Image denoising is a fundamental challenge in computer vision, with
applications in photography and medical imaging. While deep learning-based
methods have shown remarkable success, their reliance on specific noise
distributions limits generalization to unseen noise types and levels. Existing
approaches attempt to address this with extensive training data and high
computational resources but they still suffer from overfitting. To address
these issues, we conduct image denoising by utilizing dynamically generated
kernels via efficient operations. This approach helps prevent overfitting and
improves resilience to unseen noise. Specifically, our method leverages a
Feature Extraction Module for robust noise-invariant features, Global
Statistics and Local Correlation Modules to capture comprehensive noise
characteristics and structural correlations. The Kernel Prediction Module then
employs these cues to produce pixel-wise varying kernels adapted to local
structures, which are then applied iteratively for denoising. This ensures both
efficiency and superior restoration quality. Despite being trained on
single-level Gaussian noise, our compact model (~ 0.04 M) excels across diverse
noise types and levels, demonstrating the promise of iterative dynamic
filtering for practical image denoising.

</details>


### [116] [Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models](https://arxiv.org/abs/2508.19650)
*Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang*

Main category: cs.CV

TL;DR: Video-LevelGauge是一个专门评估大视频语言模型位置偏见的基准测试，通过标准化探针和定制化上下文设置来系统分析模型在不同视频位置的表现偏差。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要评估整体性能，忽略了关键的位置偏见问题，这是LVLM性能中一个重要但未被充分探索的方面。

Method: 采用标准化探针和定制化上下文设置，灵活控制上下文长度、探针位置和上下文类型，结合统计测量和形态模式识别进行综合分析。

Result: 评估27个最先进的LVLM发现，许多领先开源模型存在显著的位置偏见（头部或邻近内容偏好），而商业模型如Gemini2.5-Pro在整个视频序列中表现一致。

Conclusion: 该基准为减轻偏见和指导模型增强提供了可行见解，揭示了LVLM在位置敏感性方面的重要局限性，对模型改进具有重要指导意义。

Abstract: Large video language models (LVLMs) have made notable progress in video
understanding, spurring the development of corresponding evaluation benchmarks.
However, existing benchmarks generally assess overall performance across entire
video sequences, overlooking nuanced behaviors such as contextual positional
bias, a critical yet under-explored aspect of LVLM performance. We present
Video-LevelGauge, a dedicated benchmark designed to systematically assess
positional bias in LVLMs. We employ standardized probes and customized
contextual setups, allowing flexible control over context length, probe
position, and contextual types to simulate diverse real-world scenarios. In
addition, we introduce a comprehensive analysis method that combines
statistical measures with morphological pattern recognition to characterize
bias. Our benchmark comprises 438 manually curated videos spanning multiple
types, yielding 1,177 high-quality multiple-choice questions and 120 open-ended
questions, validated for their effectiveness in exposing positional bias. Based
on these, we evaluate 27 state-of-the-art LVLMs, including both commercial and
open-source models. Our findings reveal significant positional biases in many
leading open-source models, typically exhibiting head or neighbor-content
preferences. In contrast, commercial models such as Gemini2.5-Pro show
impressive, consistent performance across entire video sequences. Further
analyses on context length, context variation, and model scale provide
actionable insights for mitigating bias and guiding model enhancement.

</details>


### [117] [Scalable Object Detection in the Car Interior With Vision Foundation Models](https://arxiv.org/abs/2508.19651)
*Bálint Mészáros,Ahmet Firintepe,Sebastian Schmidt,Stephan Günnemann*

Main category: cs.CV

TL;DR: 提出了ODAL框架，通过分布式架构在车载和云端之间分配计算任务，解决了车载系统资源受限问题。微调后的ODAL-LLaVA模型性能显著提升，超越GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 车载AI系统资源受限，无法直接部署大型视觉基础模型进行车内物体检测和定位，需要解决这一限制。

Method: 采用分布式架构，将计算任务在车载系统和云端之间分配；引入ODALbench评估指标；对轻量级LLaVA 1.5 7B模型进行微调。

Result: 微调后的ODAL-LLaVA模型达到89%的ODAL得分，比基线提升71%，比GPT-4o高出近20%；幻觉显著减少，信噪比比GPT-4o高三倍。

Conclusion: ODAL框架有效解决了车载系统资源限制问题，微调轻量级模型可达到甚至超越大型模型的性能，为该领域设立了新标准。

Abstract: AI tasks in the car interior like identifying and localizing externally
introduced objects is crucial for response quality of personal assistants.
However, computational resources of on-board systems remain highly constrained,
restricting the deployment of such solutions directly within the vehicle. To
address this limitation, we propose the novel Object Detection and Localization
(ODAL) framework for interior scene understanding. Our approach leverages
vision foundation models through a distributed architecture, splitting
computational tasks between on-board and cloud. This design overcomes the
resource constraints of running foundation models directly in the car. To
benchmark model performance, we introduce ODALbench, a new metric for
comprehensive assessment of detection and localization.Our analysis
demonstrates the framework's potential to establish new standards in this
domain. We compare the state-of-the-art GPT-4o vision foundation model with the
lightweight LLaVA 1.5 7B model and explore how fine-tuning enhances the
lightweight models performance. Remarkably, our fine-tuned ODAL-LLaVA model
achieves an ODAL$_{score}$ of 89%, representing a 71% improvement over its
baseline performance and outperforming GPT-4o by nearly 20%. Furthermore, the
fine-tuned model maintains high detection accuracy while significantly reducing
hallucinations, achieving an ODAL$_{SNR}$ three times higher than GPT-4o.

</details>


### [118] [Self-Rewarding Vision-Language Model via Reasoning Decomposition](https://arxiv.org/abs/2508.19652)
*Zongxia Li,Wenhao Yu,Chengsong Huang,Rui Liu,Zhenwen Liang,Fuxiao Liu,Jingxi Che,Dian Yu,Jordan Boyd-Graber,Haitao Mi,Dong Yu*

Main category: cs.CV

TL;DR: Vision-SR1是一种自奖励方法，通过强化学习改进视觉语言模型的视觉推理能力，无需外部视觉监督，有效减少视觉幻觉和语言捷径问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型存在视觉幻觉和语言捷径问题，因为后训练方法仅监督最终输出，缺乏对中间视觉推理的显式指导，且外部监督方法成本高且会导致分布偏移。

Method: 将VLM推理分解为视觉感知和语言推理两个阶段，模型首先生成自包含的视觉感知，然后使用相同模型仅基于生成的感知进行语言推理来计算奖励，结合最终输出的监督进行平衡训练。

Result: 实验表明Vision-SR1改进了视觉推理能力，缓解了视觉幻觉，减少了在多样化视觉语言任务中对语言捷径的依赖。

Conclusion: Vision-SR1提供了一种有效的自监督方法，通过内部奖励机制同时增强视觉感知和语言推理能力，解决了VLM训练中的关键问题。

Abstract: Vision-Language Models (VLMs) often suffer from visual hallucinations, saying
things that are not actually in the image, and language shortcuts, where they
skip the visual part and just rely on text priors. These issues arise because
most post-training methods for VLMs rely on simple verifiable answer matching
and supervise only final outputs, leaving intermediate visual reasoning without
explicit guidance. As a result, VLMs receive sparse visual signals and often
learn to prioritize language-based reasoning over visual perception. To
mitigate this, some existing methods add visual supervision using human
annotations or distilled labels from external large models. However, human
annotations are labor-intensive and costly, and because external signals cannot
adapt to the evolving policy, they cause distributional shifts that can lead to
reward hacking. In this paper, we introduce Vision-SR1, a self-rewarding method
that improves visual reasoning without relying on external visual supervisions
via reinforcement learning. Vision-SR1 decomposes VLM reasoning into two
stages: visual perception and language reasoning. The model is first prompted
to produce self-contained visual perceptions that are sufficient to answer the
question without referring back the input image. To validate this
self-containment, the same VLM model is then re-prompted to perform language
reasoning using only the generated perception as input to compute reward. This
self-reward is combined with supervision on final outputs, providing a balanced
training signal that strengthens both visual perception and language reasoning.
Our experiments demonstrate that Vision-SR1 improves visual reasoning,
mitigates visual hallucinations, and reduces reliance on language shortcuts
across diverse vision-language tasks.

</details>


### [119] [Hardware-aware vs. Hardware-agnostic Energy Estimation for SNN in Space Applications](https://arxiv.org/abs/2508.19654)
*Matthias Höfflin,Jürgen Wassner*

Main category: cs.CV

TL;DR: SNNs在数字实现中的能效优势受到质疑，硬件感知分析显示只有在神经形态硬件和高输入稀疏性下才能实现显著节能


<details>
  <summary>Details</summary>
Motivation: 质疑SNNs在数字实现中相对于传统ANNs的能效优势，特别是在多输出回归任务中

Method: 使用LIF神经元膜电位进行训练，比较硬件感知和硬件无关的能耗估计方法，分析暗像素比例对能耗的影响

Result: SNN达到与CNN相当的MSE性能，硬件无关方法预测SNN有50-60%能效优势，但硬件感知分析显示仅在神经形态硬件和高输入稀疏性下才有显著节能

Conclusion: 需要透明的评估方法和明确披露底层假设，以确保神经网络能效比较的公平性

Abstract: Spiking Neural Networks (SNNs), inspired by biological intelligence, have
long been considered inherently energy-efficient, making them attractive for
resource-constrained domains such as space applications. However, recent
comparative studies with conventional Artificial Neural Networks (ANNs) have
begun to question this reputation, especially for digital implementations. This
work investigates SNNs for multi-output regression, specifically 3-D satellite
position estimation from monocular images, and compares hardware-aware and
hardware-agnostic energy estimation methods. The proposed SNN, trained using
the membrane potential of the Leaky Integrate-and-Fire (LIF) neuron in the
final layer, achieves comparable Mean Squared Error (MSE) to a reference
Convolutional Neural Network (CNN) on a photorealistic satellite dataset.
Energy analysis shows that while hardware-agnostic methods predict a consistent
50-60% energy advantage for SNNs over CNNs, hardware-aware analysis reveals
that significant energy savings are realized only on neuromorphic hardware and
with high input sparsity. The influence of dark pixel ratio on energy
consumption is quantified, emphasizing the impact of data characteristics and
hardware assumptions. These findings highlight the need for transparent
evaluation methods and explicit disclosure of underlying assumptions to ensure
fair comparisons of neural network energy efficiency.

</details>


### [120] [A Frequency-Aware Self-Supervised Learning for Ultra-Wide-Field Image Enhancement](https://arxiv.org/abs/2508.19664)
*Weicheng Liao,Zan Chen,Jianyang Xie,Yalin Zheng,Yuhui Ma,Yitian Zhao*

Main category: cs.CV

TL;DR: 提出了一种新颖的频率感知自监督学习方法，用于超广角视网膜图像增强，通过频率解耦去模糊和Retinex引导的照明补偿模块，有效解决了UWF图像质量退化问题。


<details>
  <summary>Details</summary>
Motivation: 超广角视网膜成像虽然提供了全面的视网膜视图，但经常受到模糊和光照不均等质量退化因素的影响，这些因素会掩盖精细细节和病理信息。现有的视网膜图像增强方法往往无法满足UWF的特殊需求，特别是需要保留病理细节的要求。

Method: 提出频率感知自监督学习方法，包含频率解耦图像去模糊模块（采用非对称通道整合操作结合全局和局部视图）和Retinex引导的照明补偿模块（包含颜色保护单元提供多尺度空间和频率信息）。

Result: 实验结果表明，该方法不仅提高了可视化质量，还通过恢复和校正精细局部细节及不均匀强度，改善了疾病诊断性能。

Conclusion: 这是首个针对UWF图像增强的尝试，为改善视网膜疾病管理提供了一个强大且具有临床价值的工具。

Abstract: Ultra-Wide-Field (UWF) retinal imaging has revolutionized retinal diagnostics
by providing a comprehensive view of the retina. However, it often suffers from
quality-degrading factors such as blurring and uneven illumination, which
obscure fine details and mask pathological information. While numerous retinal
image enhancement methods have been proposed for other fundus imageries, they
often fail to address the unique requirements in UWF, particularly the need to
preserve pathological details. In this paper, we propose a novel
frequency-aware self-supervised learning method for UWF image enhancement. It
incorporates frequency-decoupled image deblurring and Retinex-guided
illumination compensation modules. An asymmetric channel integration operation
is introduced in the former module, so as to combine global and local views by
leveraging high- and low-frequency information, ensuring the preservation of
fine and broader structural details. In addition, a color preservation unit is
proposed in the latter Retinex-based module, to provide multi-scale spatial and
frequency information, enabling accurate illumination estimation and
correction. Experimental results demonstrate that the proposed work not only
enhances visualization quality but also improves disease diagnosis performance
by restoring and correcting fine local details and uneven intensity. To the
best of our knowledge, this work is the first attempt for UWF image
enhancement, offering a robust and clinically valuable tool for improving
retinal disease management.

</details>


### [121] [SAT: Supervisor Regularization and Animation Augmentation for Two-process Monocular Texture 3D Human Reconstruction](https://arxiv.org/abs/2508.19688)
*Gangjian Zhang,Jian Shu,Nanjie Yao,Hao Wang*

Main category: cs.CV

TL;DR: SAT是一个两阶段单目3D人体重建框架，通过统一学习多种几何先验和在线动画增强，解决了单视图几何模糊和3D训练数据稀缺问题，实现了高质量纹理3D虚拟人重建。


<details>
  <summary>Details</summary>
Motivation: 单目纹理3D人体重建面临单张2D图像的几何模糊性和3D训练数据稀缺两大挑战。现有方法虽然使用先验几何估计网络获取多种几何形式，但难以有效整合这些模态，导致视角不一致和面部扭曲等问题。

Method: 提出两阶段SAT框架：1）统一学习SMPL模型和法线图等多种几何先验；2）引入监督特征正则化模块，使用多视图网络提供中间特征作为训练监督；3）提出在线动画增强模块，通过前馈动画网络从原始3D数据在线生成大量样本。

Result: 在两个基准测试上的大量实验表明，该方法相比最先进方法具有优越性，能够重建出高质量的纹理3D虚拟人。

Conclusion: SAT框架通过统一学习几何先验和监督特征正则化，有效解决了多模态整合问题，同时在线动画增强缓解了数据稀缺问题，实现了单目图像到高质量3D虚拟人的重建。

Abstract: Monocular texture 3D human reconstruction aims to create a complete 3D
digital avatar from just a single front-view human RGB image. However, the
geometric ambiguity inherent in a single 2D image and the scarcity of 3D human
training data are the main obstacles limiting progress in this field. To
address these issues, current methods employ prior geometric estimation
networks to derive various human geometric forms, such as the SMPL model and
normal maps. However, they struggle to integrate these modalities effectively,
leading to view inconsistencies, such as facial distortions. To this end, we
propose a two-process 3D human reconstruction framework, SAT, which seamlessly
learns various prior geometries in a unified manner and reconstructs
high-quality textured 3D avatars as the final output. To further facilitate
geometry learning, we introduce a Supervisor Feature Regularization module. By
employing a multi-view network with the same structure to provide intermediate
features as training supervision, these varied geometric priors can be better
fused. To tackle data scarcity and further improve reconstruction quality, we
also propose an Online Animation Augmentation module. By building a
one-feed-forward animation network, we augment a massive number of samples from
the original 3D human data online for model training. Extensive experiments on
two benchmarks show the superiority of our approach compared to
state-of-the-art methods.

</details>


### [122] [Synthetic Image Detection via Spectral Gaps of QC-RBIM Nishimori Bethe-Hessian Operators](https://arxiv.org/abs/2508.19698)
*V. S. Usatyuk,D. A. Sapozhnikov,S. I. Egorov*

Main category: cs.CV

TL;DR: 提出了一种基于物理启发的无监督合成图像检测方法，将合成图像识别视为稀疏加权图上的社区检测问题，无需标记合成数据即可达到94%以上准确率


<details>
  <summary>Details</summary>
Motivation: 深度生成模型生成的图像与真实照片难以区分，威胁媒体取证和生物识别安全。现有监督检测器对未见过的生成器或对抗后处理效果不佳，而无监督方法依赖低层统计特征仍很脆弱

Method: 使用预训练CNN提取图像特征并降维至32维，构建多边类型QC-LDPC图，将成对相似性转换为在Nishimori温度校准的边缘耦合，形成随机键Ising模型，通过Bethe-Hessian谱的特征间隙检测真实图像

Result: 在猫vs狗和男vs女的二分类任务中，无需标记合成数据或重新训练特征提取器，检测准确率超过94%。光谱分析显示真实图像集存在多个明显分离的间隙，而生成图像谱线坍塌

Conclusion: 该方法提供了新颖的LDPC图构建、Nishimori温度RBIM与Bethe-Hessian谱之间的分析联系，以及实用的无监督合成图像检测器，对新型生成架构具有鲁棒性

Abstract: The rapid advance of deep generative models such as GANs and diffusion
networks now produces images that are virtually indistinguishable from genuine
photographs, undermining media forensics and biometric security. Supervised
detectors quickly lose effectiveness on unseen generators or after adversarial
post-processing, while existing unsupervised methods that rely on low-level
statistical cues remain fragile. We introduce a physics-inspired,
model-agnostic detector that treats synthetic-image identification as a
community-detection problem on a sparse weighted graph. Image features are
first extracted with pretrained CNNs and reduced to 32 dimensions, each feature
vector becomes a node of a Multi-Edge Type QC-LDPC graph. Pairwise similarities
are transformed into edge couplings calibrated at the Nishimori temperature,
producing a Random Bond Ising Model (RBIM) whose Bethe-Hessian spectrum
exhibits a characteristic gap when genuine community structure (real images) is
present. Synthetic images violate the Nishimori symmetry and therefore lack
such gaps. We validate the approach on binary tasks cat versus dog and male
versus female using real photos from Flickr-Faces-HQ and CelebA and synthetic
counterparts generated by GANs and diffusion models. Without any labeled
synthetic data or retraining of the feature extractor, the detector achieves
over 94% accuracy. Spectral analysis shows multiple well separated gaps for
real image sets and a collapsed spectrum for generated ones. Our contributions
are threefold: a novel LDPC graph construction that embeds deep image features,
an analytical link between Nishimori temperature RBIM and the Bethe-Hessian
spectrum providing a Bayes optimal detection criterion; and a practical,
unsupervised synthetic image detector robust to new generative architectures.
Future work will extend the framework to video streams and multi-class anomaly
detection.

</details>


### [123] [LabelGS: Label-Aware 3D Gaussian Splatting for 3D Scene Segmentation](https://arxiv.org/abs/2508.19699)
*Yupeng Zhang,Dezhi Zheng,Ping Lu,Han Zhang,Lei Wang,Liping xiang,Cheng Luo,Kaijun Deng,Xiaowen Fu,Linlin Shen,Jinbao Wang*

Main category: cs.CV

TL;DR: LabelGS是一种增强3D高斯泼溅的方法，通过引入跨视图一致的语义掩码和遮挡分析模型，实现了3D场景的高效分割，训练速度比现有方法快22倍。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅(3DGS)虽然能够实现高保真重建和高效渲染，但缺乏3D分割能力，限制了其在需要场景理解任务中的应用。

Method: 提出LabelGS方法，为高斯表示添加对象标签，包括：跨视图一致的语义掩码、遮挡分析模型避免过拟合、主高斯标记模型将2D语义先验提升到3D、高斯投影过滤器避免标签冲突，并采用随机区域采样策略优化3DGS过程。

Result: 在3D场景分割任务中优于包括Feature-3DGS在内的现有最先进方法，在1440X1080分辨率下训练速度比Feature-3DGS快22倍。

Conclusion: LabelGS有效解耦了高斯表示，显著提高了3D场景分割的效率和性能，为3D场景理解提供了强有力的工具。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel explicit representation
for 3D scenes, offering both high-fidelity reconstruction and efficient
rendering. However, 3DGS lacks 3D segmentation ability, which limits its
applicability in tasks that require scene understanding. The identification and
isolating of specific object components is crucial. To address this limitation,
we propose Label-aware 3D Gaussian Splatting (LabelGS), a method that augments
the Gaussian representation with object label.LabelGS introduces cross-view
consistent semantic masks for 3D Gaussians and employs a novel Occlusion
Analysis Model to avoid overfitting occlusion during optimization, Main
Gaussian Labeling model to lift 2D semantic prior to 3D Gaussian and Gaussian
Projection Filter to avoid Gaussian label conflict. Our approach achieves
effective decoupling of Gaussian representations and refines the 3DGS
optimization process through a random region sampling strategy, significantly
improving efficiency. Extensive experiments demonstrate that LabelGS
outperforms previous state-of-the-art methods, including Feature-3DGS, in the
3D scene segmentation task. Notably, LabelGS achieves a remarkable 22X speedup
in training compared to Feature-3DGS, at a resolution of 1440X1080. Our code
will be at https://github.com/garrisonz/LabelGS.

</details>


### [124] [FreeVPS: Repurposing Training-Free SAM2 for Generalizable Video Polyp Segmentation](https://arxiv.org/abs/2508.19705)
*Qiang Hu,Ying Zhou,Gepeng Ji,Nick Barnes,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 提出FreeVPS方法，通过训练无关模块改进SAM2模型，解决视频息肉分割中的时空建模与领域泛化平衡问题，在长时息肉跟踪中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视频息肉分割方法难以平衡时空建模和领域泛化能力，限制了在真实临床场景中的应用。SAM2在长时息肉跟踪中存在误差累积问题。

Method: 采用track-by-detect范式，结合图像息肉分割模型的空间上下文和SAM2的时序建模能力。提出两个训练无关模块：内部关联过滤模块消除空间误差，外部关联精炼模块自适应更新记忆库防止误差传播。

Result: 在域内和域外场景中都达到了最先进的性能，在长未剪辑结肠镜视频中展现出强大的跟踪能力。

Conclusion: FreeVPS通过协同工作的两个模块稳定了SAM2，展示了在可靠临床分析中的潜在应用价值。

Abstract: Existing video polyp segmentation (VPS) paradigms usually struggle to balance
between spatiotemporal modeling and domain generalization, limiting their
applicability in real clinical scenarios. To embrace this challenge, we recast
the VPS task as a track-by-detect paradigm that leverages the spatial contexts
captured by the image polyp segmentation (IPS) model while integrating the
temporal modeling capabilities of segment anything model 2 (SAM2). However,
during long-term polyp tracking in colonoscopy videos, SAM2 suffers from error
accumulation, resulting in a snowball effect that compromises segmentation
stability. We mitigate this issue by repurposing SAM2 as a video polyp
segmenter with two training-free modules. In particular, the intra-association
filtering module eliminates spatial inaccuracies originating from the detecting
stage, reducing false positives. The inter-association refinement module
adaptively updates the memory bank to prevent error propagation over time,
enhancing temporal coherence. Both modules work synergistically to stabilize
SAM2, achieving cutting-edge performance in both in-domain and out-of-domain
scenarios. Furthermore, we demonstrate the robust tracking capabilities of
FreeVPS in long-untrimmed colonoscopy videos, underscoring its potential
reliable clinical analysis.

</details>


### [125] [Improving Generalization in Deepfake Detection with Face Foundation Models and Metric Learning](https://arxiv.org/abs/2508.19730)
*Stelios Mylonas,Symeon Papadopoulos*

Main category: cs.CV

TL;DR: 基于人脸基础模型的视频深度伪造检测框架，通过自监督学习和多数据集集成训练，结合三元组损失和属性监督，显著提升泛化能力


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术日益逼真，现有检测模型在真实场景中泛化能力不足，需要开发能够处理野外媒体内容的鲁棒检测方法

Method: 基于FSFM自监督人脸基础模型，使用多种深度伪造数据集进行微调，结合三元组损失变体和基于属性的监督方案（按操纵类型或来源数据集分类）

Result: 在多样化评估基准上的广泛实验证明了该方法的有效性，特别是在具有挑战性的真实世界场景中表现优异

Conclusion: 利用人脸基础模型的丰富表征能力，结合多数据集训练和监督策略，可以显著提升深度伪造检测的泛化性能和实际应用效果

Abstract: The increasing realism and accessibility of deepfakes have raised critical
concerns about media authenticity and information integrity. Despite recent
advances, deepfake detection models often struggle to generalize beyond their
training distributions, particularly when applied to media content found in the
wild. In this work, we present a robust video deepfake detection framework with
strong generalization that takes advantage of the rich facial representations
learned by face foundation models. Our method is built on top of FSFM, a
self-supervised model trained on real face data, and is further fine-tuned
using an ensemble of deepfake datasets spanning both face-swapping and
face-reenactment manipulations. To enhance discriminative power, we incorporate
triplet loss variants during training, guiding the model to produce more
separable embeddings between real and fake samples. Additionally, we explore
attribution-based supervision schemes, where deepfakes are categorized by
manipulation type or source dataset, to assess their impact on generalization.
Extensive experiments across diverse evaluation benchmarks demonstrate the
effectiveness of our approach, especially in challenging real-world scenarios.

</details>


### [126] [POEv2: a flexible and robust framework for generic line segment detection and wireframe line segment detection](https://arxiv.org/abs/2508.19742)
*Chenguang Liu,Chisheng Wang,Yuhua Cai,Chuanhua Zhu,Qingquan Li*

Main category: cs.CV

TL;DR: 提出了POEv2框架，可同时用于通用线段检测和线框线段检测，是POE方法的改进版本，结合边缘检测器在三个数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有线段检测器分为通用线段检测器和线框线段检测器两类，由于设计目标不同，它们在不同任务上的表现不理想，需要一种能同时处理两种检测任务的鲁棒框架

Method: 基于像素方向估计(POE)方法的改进版本POEv2，从边缘强度图中检测线段，可与任何边缘检测器结合使用

Result: 通过与高效边缘检测器结合，在三个公开数据集上实现了最先进的性能

Conclusion: POEv2是一个通用的线段检测框架，既能处理通用线段检测任务，也能处理线框线段检测任务，具有很好的适应性和性能表现

Abstract: Line segment detection in images has been studied for several decades.
Existing line segment detectors can be roughly divided into two categories:
generic line segment detectors and wireframe line segment detectors. Generic
line segment detectors aim to detect all meaningful line segments in images and
traditional approaches usually fall into this category. Recent deep learning
based approaches are mostly wireframe line segment detectors. They detect only
line segments that are geometrically meaningful and have large spatial support.
Due to the difference in the aim of design, the performance of generic line
segment detectors for the task of wireframe line segment detection won't be
satisfactory, and vice versa. In this work, we propose a robust framework that
can be used for both generic line segment detection and wireframe line segment
detection. The proposed method is an improved version of the Pixel Orientation
Estimation (POE) method. It is thus named as POEv2. POEv2 detects line segments
from edge strength maps, and can be combined with any edge detector. We show in
our experiments that by combining the proposed POEv2 with an efficient edge
detector, it achieves state-of-the-art performance on three publicly available
datasets.

</details>


### [127] [SPLF-SAM: Self-Prompting Segment Anything Model for Light Field Salient Object Detection](https://arxiv.org/abs/2508.19746)
*Qiyao Xu,Qiming Wu,Xiaowei Li*

Main category: cs.CV

TL;DR: 基于SAM的自动提示光场显著目标检测模型SPLF-SAM，通过统一多尺度特征嵌入和频域过滤插件，解决了小目标被噪声洗地和缺乏提示信息提取的问题


<details>
  <summary>Details</summary>
Motivation: 现有光场显著目标检测模型忽略了提示信息的提取，同时缺乏频域信息分析，导致小目标被噪声洗地

Method: 提出SPLF-SAM模型，包含统一多尺度特征嵌入块(UMFEB)和多尺度适配过滤揕件(MAFA)。UMFEB识别不同大小的多个目标，MAFA通过学习频率特征防止小目标被噪声洗地

Result: 在10个最先进的LF SOD方法中表现優异，验证了方法的优勃性

Conclusion: SPLF-SAM通过统一多尺度特征嵌入和频域过滤技术，有效解决了光场显著检测中的关键挑战，为相关领域提供了新的解决方案

Abstract: Segment Anything Model (SAM) has demonstrated remarkable capabilities in
solving light field salient object detection (LF SOD). However, most existing
models tend to neglect the extraction of prompt information under this task.
Meanwhile, traditional models ignore the analysis of frequency-domain
information, which leads to small objects being overwhelmed by noise. In this
paper, we put forward a novel model called self-prompting light field segment
anything model (SPLF-SAM), equipped with unified multi-scale feature embedding
block (UMFEB) and a multi-scale adaptive filtering adapter (MAFA). UMFEB is
capable of identifying multiple objects of varying sizes, while MAFA, by
learning frequency features, effectively prevents small objects from being
overwhelmed by noise. Extensive experiments have demonstrated the superiority
of our method over ten state-of-the-art (SOTA) LF SOD methods. Our code will be
available at https://github.com/XucherCH/splfsam.

</details>


### [128] [FastAvatar: Towards Unified Fast High-Fidelity 3D Avatar Reconstruction with Large Gaussian Reconstruction Transformers](https://arxiv.org/abs/2508.19754)
*Yue Wu,Yufan Wu,Wen Li,Yuxi Lu,Kairui Feng,Xuanhong Chen*

Main category: cs.CV

TL;DR: FastAvatar是一个快速3D头像重建框架，使用单一统一模型在数秒内从各种日常记录（单图像、多视角或单目视频）重建高质量的3D高斯溅射模型，支持增量重建和质量-速度可调范式。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D头像重建方法存在的高时间复杂性、对数据质量敏感以及数据利用率低的问题，提供更灵活高效的重建方案。

Method: 采用大型高斯重建变换器，包含VGGT风格变换器架构聚合多帧线索、多粒度引导编码缓解动画引起的错位，以及通过地标跟踪和切片融合损失进行增量高斯聚合。

Result: 实验表明FastAvatar相比现有方法具有更高的质量和极具竞争力的速度，支持增量重建和质量-速度可调。

Conclusion: FastAvatar提供了一个质量-速度可调的高可用头像建模范式，能够灵活利用多样化输入数据实现快速高质量的3D头像重建。

Abstract: Despite significant progress in 3D avatar reconstruction, it still faces
challenges such as high time complexity, sensitivity to data quality, and low
data utilization. We propose FastAvatar, a feedforward 3D avatar framework
capable of flexibly leveraging diverse daily recordings (e.g., a single image,
multi-view observations, or monocular video) to reconstruct a high-quality 3D
Gaussian Splatting (3DGS) model within seconds, using only a single unified
model. FastAvatar's core is a Large Gaussian Reconstruction Transformer
featuring three key designs: First, a variant VGGT-style transformer
architecture aggregating multi-frame cues while injecting initial 3D prompt to
predict an aggregatable canonical 3DGS representation; Second, multi-granular
guidance encoding (camera pose, FLAME expression, head pose) mitigating
animation-induced misalignment for variable-length inputs; Third, incremental
Gaussian aggregation via landmark tracking and sliced fusion losses.
Integrating these features, FastAvatar enables incremental reconstruction,
i.e., improving quality with more observations, unlike prior work wasting input
data. This yields a quality-speed-tunable paradigm for highly usable avatar
modeling. Extensive experiments show that FastAvatar has higher quality and
highly competitive speed compared to existing methods.

</details>


### [129] [BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions](https://arxiv.org/abs/2508.19762)
*Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher*

Main category: cs.CV

TL;DR: BuzzSet是一个新的大规模传粉昆虫图像数据集，包含7856张高分辨率图像和8000多个标注实例，用于支持自动化传粉昆虫监测。


<details>
  <summary>Details</summary>
Motivation: 传粉昆虫对全球粮食生产和生态系统稳定至关重要，但其种群数量因人为和环境压力而下降，需要可扩展的自动化监测方法。

Method: 使用YOLOv12模型生成初始标注并通过人工验证完善，所有图像预处理为256×256切片，采用RF-DETR基于transformer的目标检测器建立基准。

Result: 模型在蜜蜂和熊蜂类别上分别达到0.94和0.92的F1分数，混淆矩阵显示类别间误分类极少，最佳mAP@0.50为0.559。

Conclusion: BuzzSet为小目标检测、标签噪声下的类别分离和生态计算机视觉提供了有价值的基准数据集。

Abstract: Pollinator insects such as honeybees and bumblebees are vital to global food
production and ecosystem stability, yet their populations are declining due to
increasing anthropogenic and environmental stressors. To support scalable,
automated pollinator monitoring, we introduce BuzzSet, a new large-scale
dataset of high-resolution pollinator images collected in real agricultural
field conditions. BuzzSet contains 7856 manually verified and labeled images,
with over 8000 annotated instances across three classes: honeybees, bumblebees,
and unidentified insects. Initial annotations were generated using a YOLOv12
model trained on external data and refined via human verification using
open-source labeling tools. All images were preprocessed into 256~$\times$~256
tiles to improve the detection of small insects. We provide strong baselines
using the RF-DETR transformer-based object detector. The model achieves high
F1-scores of 0.94 and 0.92 for honeybee and bumblebee classes, respectively,
with confusion matrix results showing minimal misclassification between these
categories. The unidentified class remains more challenging due to label
ambiguity and lower sample frequency, yet still contributes useful insights for
robustness evaluation. Overall detection quality is strong, with a best
mAP@0.50 of 0.559. BuzzSet offers a valuable benchmark for small object
detection, class separation under label noise, and ecological computer vision.

</details>


### [130] [AIM: Adaptive Intra-Network Modulation for Balanced Multimodal Learning](https://arxiv.org/abs/2508.19769)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: 提出了AIM方法来解决多模态学习中的优化偏差问题，通过自适应网络内调制实现平衡的多模态学习，而不抑制任何模态的性能


<details>
  <summary>Details</summary>
Motivation: 现有方法通过抑制主导模态来促进弱势模态学习，影响了整体多模态性能。研究发现这是由于网络内部的优化偏差问题被忽视

Method: AIM方法将主导模态中未充分优化的参数解耦到辅助块中，鼓励与弱势模态联合训练时依赖这些性能下降的块，同时根据网络深度自适应调整调制强度

Result: AIM在多个基准测试中优于最先进的不平衡模态学习方法，并在不同骨干网络、融合策略和优化器上表现出强大的泛化能力

Conclusion: AIM首次实现了不抑制任何模态的平衡多模态学习，有效解决了网络内部优化偏差问题，为多模态学习提供了新的解决方案

Abstract: Multimodal learning has significantly enhanced machine learning performance
but still faces numerous challenges and limitations. Imbalanced multimodal
learning is one of the problems extensively studied in recent works and is
typically mitigated by modulating the learning of each modality. However, we
find that these methods typically hinder the dominant modality's learning to
promote weaker modalities, which affects overall multimodal performance. We
analyze the cause of this issue and highlight a commonly overlooked problem:
optimization bias within networks. To address this, we propose Adaptive
Intra-Network Modulation (AIM) to improve balanced modality learning. AIM
accounts for differences in optimization state across parameters and depths
within the network during modulation, achieving balanced multimodal learning
without hindering either dominant or weak modalities for the first time.
Specifically, AIM decouples the dominant modality's under-optimized parameters
into Auxiliary Blocks and encourages reliance on these performance-degraded
blocks for joint training with weaker modalities. This approach effectively
prevents suppression of weaker modalities while enabling targeted optimization
of under-optimized parameters to improve the dominant modality. Additionally,
AIM assesses modality imbalance level across network depths and adaptively
adjusts modulation strength at each depth. Experimental results demonstrate
that AIM outperforms state-of-the-art imbalanced modality learning methods
across multiple benchmarks and exhibits strong generalizability across
different backbones, fusion strategies, and optimizers.

</details>


### [131] [The Return of Structural Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.19773)
*Jakob Seitz,Tobias Lengfeld,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一个结构化手写数学表达式识别系统，通过自动标注和模块化结构识别，实现了符号到轨迹的显式对齐，提高了可解释性和错误分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于编码器-解码器架构的大语言模型虽然擅长LaTeX生成，但缺乏符号到轨迹的显式对齐，这限制了错误分析、可解释性和需要选择性内容更新的空间感知交互应用。

Method: 1) 使用神经网络自动标注系统将LaTeX方程映射到原始轨迹，自动生成符号分割、分类和空间关系标注；2) 模块化结构识别系统独立优化分割、分类和关系预测，结合基于图的轨迹排序、混合卷积-循环网络和基于transformer的校正。

Result: 在CROHME-2023基准测试中取得了有竞争力的性能，生成了完整的图结构，直接链接手写轨迹到预测符号。

Conclusion: 该方法提供了透明的错误分析和可解释的输出，为教育技术应用提供了更好的结构化识别解决方案。

Abstract: Handwritten Mathematical Expression Recognition is foundational for
educational technologies, enabling applications like digital note-taking and
automated grading. While modern encoder-decoder architectures with large
language models excel at LaTeX generation, they lack explicit symbol-to-trace
alignment, a critical limitation for error analysis, interpretability, and
spatially aware interactive applications requiring selective content updates.
This paper introduces a structural recognition approach with two innovations: 1
an automatic annotation system that uses a neural network to map LaTeX
equations to raw traces, automatically generating annotations for symbol
segmentation, classification, and spatial relations, and 2 a modular structural
recognition system that independently optimizes segmentation, classification,
and relation prediction. By leveraging a dataset enriched with structural
annotations from our auto-labeling system, the proposed recognition system
combines graph-based trace sorting, a hybrid convolutional-recurrent network,
and transformer-based correction to achieve competitive performance on the
CROHME-2023 benchmark. Crucially, our structural recognition system generates a
complete graph structure that directly links handwritten traces to predicted
symbols, enabling transparent error analysis and interpretable outputs.

</details>


### [132] [MAPo : Motion-Aware Partitioning of Deformable 3D Gaussian Splatting for High-Fidelity Dynamic Scene Reconstruction](https://arxiv.org/abs/2508.19786)
*Han Jiao,Jiakai Sun,Yexing Xu,Lei Zhao,Wei Xing,Huaizhong Lin*

Main category: cs.CV

TL;DR: MAPo框架通过动态评分分区策略，将3D高斯分为高动态和低动态区域，对高动态区域进行时间分区和网络复制以捕捉精细运动细节，同时使用跨帧一致性损失确保视觉连续性，实现了高质量动态场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于变形的3D高斯泼溅方法在处理动态场景时，由于使用单一统一模型难以表示多样化的运动模式，往往导致渲染模糊和精细运动细节丢失。

Method: 提出动态评分分区策略，区分高动态和低动态3D高斯；对高动态高斯进行时间递归分区并复制变形网络；引入跨帧一致性损失解决分区边界视觉不连续问题。

Result: 实验表明MAPo在保持可比计算成本的同时，特别是在复杂或快速运动区域，实现了优于基线的渲染质量。

Conclusion: MAPo框架通过智能分区和专门化建模，有效解决了动态场景重建中的运动细节丢失问题，为高质量动态3D重建提供了新思路。

Abstract: 3D Gaussian Splatting, known for enabling high-quality static scene
reconstruction with fast rendering, is increasingly being applied to dynamic
scene reconstruction. A common strategy involves learning a deformation field
to model the temporal changes of a canonical set of 3D Gaussians. However,
these deformation-based methods often produce blurred renderings and lose fine
motion details in highly dynamic regions due to the inherent limitations of a
single, unified model in representing diverse motion patterns. To address these
challenges, we introduce Motion-Aware Partitioning of Deformable 3D Gaussian
Splatting (MAPo), a novel framework for high-fidelity dynamic scene
reconstruction. Its core is a dynamic score-based partitioning strategy that
distinguishes between high- and low-dynamic 3D Gaussians. For high-dynamic 3D
Gaussians, we recursively partition them temporally and duplicate their
deformation networks for each new temporal segment, enabling specialized
modeling to capture intricate motion details. Concurrently, low-dynamic 3DGs
are treated as static to reduce computational costs. However, this temporal
partitioning strategy for high-dynamic 3DGs can introduce visual
discontinuities across frames at the partition boundaries. To address this, we
introduce a cross-frame consistency loss, which not only ensures visual
continuity but also further enhances rendering quality. Extensive experiments
demonstrate that MAPo achieves superior rendering quality compared to baselines
while maintaining comparable computational costs, particularly in regions with
complex or rapid motions.

</details>


### [133] [StableIntrinsic: Detail-preserving One-step Diffusion Model for Multi-view Material Estimation](https://arxiv.org/abs/2508.19789)
*Xiuchao Wu,Pengfei Zhu,Jiangjing Lyu,Xinguo Liu,Jie Guo,Yanwen Guo,Weiwei Xu,Chengfei Lyu*

Main category: cs.CV

TL;DR: StableIntrinsic是一个单步扩散模型，用于多视角材质估计，能够高质量、低方差地预测材质参数，在PSNR和MSE指标上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的材质估计方法采用多步去噪策略，耗时且结果方差大，与确定性材质估计任务存在冲突。

Method: 提出单步扩散模型StableIntrinsic，在像素空间设计基于材质特性的损失函数，并引入细节注入网络(DIN)来消除VAE编码造成的细节损失。

Result: 在PSNR指标上比现有最佳方法提升9.9%，金属和粗糙度的MSE分别降低44.4%和60.0%。

Conclusion: StableIntrinsic通过单步扩散和细节注入网络，有效解决了多步扩散模型的耗时和方差问题，实现了高质量、低方差的材质估计。

Abstract: Recovering material information from images has been extensively studied in
computer graphics and vision. Recent works in material estimation leverage
diffusion model showing promising results. However, these diffusion-based
methods adopt a multi-step denoising strategy, which is time-consuming for each
estimation. Such stochastic inference also conflicts with the deterministic
material estimation task, leading to a high variance estimated results. In this
paper, we introduce StableIntrinsic, a one-step diffusion model for multi-view
material estimation that can produce high-quality material parameters with low
variance. To address the overly-smoothing problem in one-step diffusion,
StableIntrinsic applies losses in pixel space, with each loss designed based on
the properties of the material. Additionally, StableIntrinsic introduces a
Detail Injection Network (DIN) to eliminate the detail loss caused by VAE
encoding, while further enhancing the sharpness of material prediction results.
The experimental results indicate that our method surpasses the current
state-of-the-art techniques by achieving a $9.9\%$ improvement in the Peak
Signal-to-Noise Ratio (PSNR) of albedo, and by reducing the Mean Square Error
(MSE) for metallic and roughness by $44.4\%$ and $60.0\%$, respectively.

</details>


### [134] [Not Every Gift Comes in Gold Paper or with a Red Ribbon: Exploring Color Perception in Text-to-Image Models](https://arxiv.org/abs/2508.19791)
*Shay Shomer Chai,Wenxuan Peng,Bharath Hariharan,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 本文研究了文本到图像生成中多对象颜色属性的语义对齐问题，提出了专门的图像编辑技术来改善多颜色提示的语义对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成方法在处理复杂多对象提示时难以准确捕捉精确语义，特别是在颜色属性方面存在显著的对齐问题，需要更有效的解决方案。

Method: 引入专门的图像编辑技术，针对包含多个颜色的提示，通过改进注意力机制来缓解多对象语义对齐问题。

Result: 该方法在各种基于扩散的文本到图像技术生成的图像上显著提升了性能，在多个评估指标上都表现出色。

Conclusion: 提出的图像编辑技术有效解决了多颜色提示的语义对齐问题，为复杂多对象文本到图像生成提供了可靠的解决方案。

Abstract: Text-to-image generation has recently seen remarkable success, granting users
with the ability to create high-quality images through the use of text.
However, contemporary methods face challenges in capturing the precise
semantics conveyed by complex multi-object prompts. Consequently, many works
have sought to mitigate such semantic misalignments, typically via
inference-time schemes that modify the attention layers of the denoising
networks. However, prior work has mostly utilized coarse metrics, such as the
cosine similarity between text and image CLIP embeddings, or human evaluations,
which are challenging to conduct on a larger-scale. In this work, we perform a
case study on colors -- a fundamental attribute commonly associated with
objects in text prompts, which offer a rich test bed for rigorous evaluation.
Our analysis reveals that pretrained models struggle to generate images that
faithfully reflect multiple color attributes-far more so than with single-color
prompts-and that neither inference-time techniques nor existing editing methods
reliably resolve these semantic misalignments. Accordingly, we introduce a
dedicated image editing technique, mitigating the issue of multi-object
semantic alignment for prompts containing multiple colors. We demonstrate that
our approach significantly boosts performance over a wide range of metrics,
considering images generated by various text-to-image diffusion-based
techniques.

</details>


### [135] [FusionSort: Enhanced Cluttered Waste Segmentation with Advanced Decoding and Comprehensive Modality Optimization](https://arxiv.org/abs/2508.19798)
*Muhammad Ali,Omar Ali AlSuwaidi*

Main category: cs.CV

TL;DR: 提出了一种改进的编码器-解码器神经网络架构，通过综合注意力块、Mamba架构和数据融合块等技术，显著提升了非生物降解废物分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 废物管理中非生物降解材料的自动分类面临复杂多变的废物流挑战，需要更准确高效的分类系统来解决这一问题。

Method: 在编码器-解码器结构基础上，集成了综合注意力块（结合卷积和上采样操作）、Mamba架构的注意力机制，以及数据融合块（使用PCA降维处理多通道图像数据）。

Result: 在RGB、高光谱、多光谱以及RGB与高光谱组合数据上的评估表明，该方法显著优于现有方法。

Conclusion: 所提出的增强神经网络架构通过创新的注意力机制和数据融合技术，有效提升了废物分类系统的性能，为解决复杂废物管理问题提供了有效解决方案。

Abstract: In the realm of waste management, automating the sorting process for
non-biodegradable materials presents considerable challenges due to the
complexity and variability of waste streams. To address these challenges, we
introduce an enhanced neural architecture that builds upon an existing
Encoder-Decoder structure to improve the accuracy and efficiency of waste
sorting systems. Our model integrates several key innovations: a Comprehensive
Attention Block within the decoder, which refines feature representations by
combining convolutional and upsampling operations. In parallel, we utilize
attention through the Mamba architecture, providing an additional performance
boost. We also introduce a Data Fusion Block that fuses images with more than
three channels. To achieve this, we apply PCA transformation to reduce the
dimensionality while retaining the maximum variance and essential information
across three dimensions, which are then used for further processing. We
evaluated the model on RGB, hyperspectral, multispectral, and a combination of
RGB and hyperspectral data. The results demonstrate that our approach
outperforms existing methods by a significant margin.

</details>


### [136] [A bag of tricks for real-time Mitotic Figure detection](https://arxiv.org/abs/2508.19804)
*Christian Marzahl,Brian Napora*

Main category: cs.CV

TL;DR: 这篇论文提出了一系列训练技巧，通过RTMDet单阶段检测器实现了高效的有丝切裂图像中有丝切分裂图检测，在保持高速度的同时获得了过渡基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 有丝切分裂图检测遇到多种挑战，包括滑片扫描仪器变异、染色协议、组织类型和干扰物。需要开发能够在多样化领域中稳健运行的实时检测方法。

Method: 基于RTMDet单阶段对象检测器，采用多领域训练数据、平衡采样和控制增强技术。使用针对坏死和残留组织的难以识别的负样本采集来减少误检。

Result: 在多个数据集上进行分组5折交叉验证，F1分数为0.78-0.84。在MIDOG 2025挑战测试集上达到0.81的F1分数，超过更大模型。

Conclusion: 该方法在准确性和速度之间取得了平衡，适合真实临床环境中部署。通过多领域训练和有针对性的负样本采集，实现了对新领域的良好适应性。

Abstract: Mitotic figure (MF) detection in histopathology images is challenging due to
large variations in slide scanners, staining protocols, tissue types, and the
presence of artifacts. This paper presents a collection of training techniques
- a bag of tricks - that enable robust, real-time MF detection across diverse
domains. We build on the efficient RTMDet single stage object detector to
achieve high inference speed suitable for clinical deployment. Our method
addresses scanner variability and tumor heterogeneity via extensive
multi-domain training data, balanced sampling, and careful augmentation.
Additionally, we employ targeted, hard negative mining on necrotic and debris
tissue to reduce false positives. In a grouped 5-fold cross-validation across
multiple MF datasets, our model achieves an F1 score between 0.78 and 0.84. On
the preliminary test set of the MItosis DOmain Generalization (MIDOG) 2025
challenge, our single-stage RTMDet-S based approach reaches an F1 of 0.81,
outperforming larger models and demonstrating adaptability to new, unfamiliar
domains. The proposed solution offers a practical trade-off between accuracy
and speed, making it attractive for real-world clinical adoption.

</details>


### [137] [Context-aware Sparse Spatiotemporal Learning for Event-based Vision](https://arxiv.org/abs/2508.19806)
*Shenqi Wang,Guangzhi Tang*

Main category: cs.CV

TL;DR: 提出CSSL框架，通过上下文感知阈值动态调节神经元激活，在事件相机视觉任务中实现高稀疏性和优异性能


<details>
  <summary>Details</summary>
Motivation: 现有事件处理方法未能充分利用事件数据的稀疏性，且脉冲神经网络在复杂任务中性能不足，高激活稀疏性需要手动调优

Method: Context-aware Sparse Spatiotemporal Learning (CSSL)框架，引入上下文感知阈值机制，根据输入分布动态调节神经元激活

Result: 在事件目标检测和光流估计任务中达到或超越SOTA方法性能，同时保持极高的神经元稀疏性

Conclusion: CSSL为神经形态处理实现高效事件视觉提供了关键技术，无需显式稀疏约束即可自然降低激活密度

Abstract: Event-based camera has emerged as a promising paradigm for robot perception,
offering advantages with high temporal resolution, high dynamic range, and
robustness to motion blur. However, existing deep learning-based event
processing methods often fail to fully leverage the sparse nature of event
data, complicating their integration into resource-constrained edge
applications. While neuromorphic computing provides an energy-efficient
alternative, spiking neural networks struggle to match of performance of
state-of-the-art models in complex event-based vision tasks, like object
detection and optical flow. Moreover, achieving high activation sparsity in
neural networks is still difficult and often demands careful manual tuning of
sparsity-inducing loss terms. Here, we propose Context-aware Sparse
Spatiotemporal Learning (CSSL), a novel framework that introduces context-aware
thresholding to dynamically regulate neuron activations based on the input
distribution, naturally reducing activation density without explicit sparsity
constraints. Applied to event-based object detection and optical flow
estimation, CSSL achieves comparable or superior performance to
state-of-the-art methods while maintaining extremely high neuronal sparsity.
Our experimental results highlight CSSL's crucial role in enabling efficient
event-based vision for neuromorphic processing.

</details>


### [138] [AutoQ-VIS: Improving Unsupervised Video Instance Segmentation via Automatic Quality Assessment](https://arxiv.org/abs/2508.19808)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS是一个无监督视频实例分割框架，通过质量引导的自训练方法，在不需要人工标注的情况下实现了最先进的性能表现


<details>
  <summary>Details</summary>
Motivation: 视频实例分割需要像素级掩码和时间一致性标注，标注成本高昂。现有无监督方法依赖合成数据但存在合成到真实域的差距问题

Method: 建立伪标签生成和自动质量评估的闭环系统，通过质量引导的自训练实现从合成视频到真实视频的渐进式适应

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，比之前最好的VideoCutLER方法提升4.4%，且无需人工标注

Conclusion: 质量感知的自训练方法对于无监督视频实例分割是可行的，成功解决了合成到真实域的差距问题

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due
to its dual requirements of pixel-level masks and temporal consistency labels.
While recent unsupervised methods like VideoCutLER eliminate optical flow
dependencies through synthetic data, they remain constrained by the
synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised
framework that bridges this gap through quality-guided self-training. Our
approach establishes a closed-loop system between pseudo-label generation and
automatic quality assessment, enabling progressive adaptation from synthetic to
real videos. Experiments demonstrate state-of-the-art performance with 52.6
$\text{AP}_{50}$ on YouTubeVIS-2019 val set, surpassing the previous
state-of-the-art VideoCutLER by 4.4$\%$, while requiring no human annotations.
This demonstrates the viability of quality-aware self-training for unsupervised
VIS. The source code of our method is available at
https://github.com/wcbup/AutoQ-VIS.

</details>


### [139] [ERSR: An Ellipse-constrained pseudo-label refinement and symmetric regularization framework for semi-supervised fetal head segmentation in ultrasound images](https://arxiv.org/abs/2508.19815)
*Linkuan Zhou,Zhexin Chen,Yufei Shen,Junlin Xu,Ping Xuan,Yixin Zhu,Yuqi Fang,Cong Cong,Leyi Wei,Ran Su,Jia Zhou,Qiangguo Jin*

Main category: cs.CV

TL;DR: 提出ERSR框架，通过双评分自适应过滤、椭圆约束伪标签精炼和对称多一致性正则化，解决胎儿头部超声图像分割中伪标签质量和一致性约束的挑战，在两个基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 胎儿头部超声图像自动分割对产前监测至关重要，但图像质量差和标注数据缺乏使得鲁棒分割具有挑战性。现有半监督方法难以处理胎儿头部超声图像的特殊性，无法生成可靠的伪标签和有效的正则化约束。

Method: ERSR框架包含三个核心组件：1）双评分自适应过滤策略，使用边界一致性和轮廓规则性标准评估过滤教师输出；2）椭圆约束伪标签精炼，通过最小二乘椭圆拟合精炼过滤输出；3）对称多一致性正则化，在扰动图像、对称区域和原始预测与伪标签之间强制执行多级一致性。

Result: 在HC18数据集上，使用10%和20%标注数据分别达到92.05%和95.36%的Dice分数；在PSFH数据集上，相同设置下分别达到91.68%和93.70%的Dice分数，均达到最先进性能。

Conclusion: ERSR框架通过创新的伪标签生成和一致性正则化方法，有效解决了胎儿头部超声图像分割中的关键挑战，在有限标注数据下实现了优异的性能表现。

Abstract: Automated segmentation of the fetal head in ultrasound images is critical for
prenatal monitoring. However, achieving robust segmentation remains challenging
due to the poor quality of ultrasound images and the lack of annotated data.
Semi-supervised methods alleviate the lack of annotated data but struggle with
the unique characteristics of fetal head ultrasound images, making it
challenging to generate reliable pseudo-labels and enforce effective
consistency regularization constraints. To address this issue, we propose a
novel semi-supervised framework, ERSR, for fetal head ultrasound segmentation.
Our framework consists of the dual-scoring adaptive filtering strategy, the
ellipse-constrained pseudo-label refinement, and the symmetry-based multiple
consistency regularization. The dual-scoring adaptive filtering strategy uses
boundary consistency and contour regularity criteria to evaluate and filter
teacher outputs. The ellipse-constrained pseudo-label refinement refines these
filtered outputs by fitting least-squares ellipses, which strengthens pixels
near the center of the fitted ellipse and suppresses noise simultaneously. The
symmetry-based multiple consistency regularization enforces multi-level
consistency across perturbed images, symmetric regions, and between original
predictions and pseudo-labels, enabling the model to capture robust and stable
shape representations. Our method achieves state-of-the-art performance on two
benchmarks. On the HC18 dataset, it reaches Dice scores of 92.05% and 95.36%
with 10% and 20% labeled data, respectively. On the PSFH dataset, the scores
are 91.68% and 93.70% under the same settings.

</details>


### [140] [Gradient Rectification for Robust Calibration under Distribution Shift](https://arxiv.org/abs/2508.19830)
*Yilin Zhang,Cai Xu,You Wu,Ziyu Guan,Wei Zhao*

Main category: cs.CV

TL;DR: 通过频域视角分析分布偏移问题，提出低频筛波策略和梯度校正机制，在不需目标域信息的情况下提升模型在分布偏移环境下的检查准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在分布偏移情况下容易产生过分自信的预测，影响其在安全关键应用中的可靠性。现有方法需要目标域信息或模拟，实际应用中不实用。

Method: 1）从频域角度分析分布偏移对高频视觉线索的影响，提出低频筛波策略促进模型依赖域不变特征 2）重新设计梯度基于的校正机制，以位于分布检查准确性作为优化过程中的硬约束

Result: 在CIFAR-10/100-C和WILDS等合成与实际偏移数据集上进行实验，方法显著提升了分布偏移下的检查准确性，同时保持了强劲的位于分布性能。

Conclusion: 该方法为在不需目标域信息的情况下提升深度模型在分布偏移环境中的可靠性提供了有效解决方案，通过频域分析和硬约束优化实现了良好的检查准确性。

Abstract: Deep neural networks often produce overconfident predictions, undermining
their reliability in safety-critical applications. This miscalibration is
further exacerbated under distribution shift, where test data deviates from the
training distribution due to environmental or acquisition changes. While
existing approaches improve calibration through training-time regularization or
post-hoc adjustment, their reliance on access to or simulation of target
domains limits their practicality in real-world scenarios. In this paper, we
propose a novel calibration framework that operates without access to target
domain information. From a frequency-domain perspective, we identify that
distribution shifts often distort high-frequency visual cues exploited by deep
models, and introduce a low-frequency filtering strategy to encourage reliance
on domain-invariant features. However, such information loss may degrade
In-Distribution (ID) calibration performance. Therefore, we further propose a
gradient-based rectification mechanism that enforces ID calibration as a hard
constraint during optimization. Experiments on synthetic and real-world shifted
datasets, including CIFAR-10/100-C and WILDS, demonstrate that our method
significantly improves calibration under distribution shift while maintaining
strong in-distribution performance.

</details>


### [141] [Image Quality Assessment for Machines: Paradigm, Large-scale Database, and Models](https://arxiv.org/abs/2508.19850)
*Xiaoqi Wang,Yun Zhang,Weisi Lin*

Main category: cs.CV

TL;DR: 提出了机器中心图像质量评估(MIQA)框架，构建了包含250万样本的MIQD-2.5M数据库，开发了区域感知RA-MIQA模型，在多个维度超越传统HVS-based指标


<details>
  <summary>Details</summary>
Motivation: 机器视觉系统在恶劣视觉条件下性能下降，需要专门针对机器感知的图像质量评估方法，传统人类视觉系统指标不适用于机器视觉质量预测

Method: 建立端到端MIQA评估框架，构建大规模机器中心图像质量数据库(MIQD-2.5M)，提出区域感知RA-MIQA模型进行细粒度空间退化分析

Result: RA-MIQA在图像分类任务上一致性指标提升13.56%，准确性指标提升13.37%，显著优于7种HVS-based指标和5种重训练经典骨干网络

Conclusion: HVS-based指标不适用于MVS质量预测，专门MIQA模型在背景退化、准确性导向估计和细微失真方面仍有挑战，该研究为机器中心图像处理和优化奠定基础

Abstract: Machine vision systems (MVS) are intrinsically vulnerable to performance
degradation under adverse visual conditions. To address this, we propose a
machine-centric image quality assessment (MIQA) framework that quantifies the
impact of image degradations on MVS performance. We establish an MIQA paradigm
encompassing the end-to-end assessment workflow. To support this, we construct
a machine-centric image quality database (MIQD-2.5M), comprising 2.5 million
samples that capture distinctive degradation responses in both consistency and
accuracy metrics, spanning 75 vision models, 250 degradation types, and three
representative vision tasks. We further propose a region-aware MIQA (RA-MIQA)
model to evaluate MVS visual quality through fine-grained spatial degradation
analysis. Extensive experiments benchmark the proposed RA-MIQA against seven
human visual system (HVS)-based IQA metrics and five retrained classical
backbones. Results demonstrate RA-MIQA's superior performance in multiple
dimensions, e.g., achieving SRCC gains of 13.56% on consistency and 13.37% on
accuracy for image classification, while also revealing task-specific
degradation sensitivities. Critically, HVS-based metrics prove inadequate for
MVS quality prediction, while even specialized MIQA models struggle with
background degradations, accuracy-oriented estimation, and subtle distortions.
This study can advance MVS reliability and establish foundations for
machine-centric image processing and optimization. The model and code are
available at: https://github.com/XiaoqiWang/MIQA.

</details>


### [142] [Ego-centric Predictive Model Conditioned on Hand Trajectories](https://arxiv.org/abs/2508.19852)
*Binjie Zhang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出了一个统一的两阶段预测框架，用于在自我中心场景中联合建模动作和视觉未来，通过手部轨迹条件化，同时预测下一个动作及其视觉结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在局限性：VLA模型只关注动作预测而缺乏对视觉场景影响的显式建模，视频预测模型生成未来帧但不以特定动作为条件，导致结果不真实或不一致。需要一种能够联合建模动作和视觉未来的统一方法。

Method: 两阶段框架：第一阶段进行连续状态建模处理多模态输入并预测未来手部轨迹；第二阶段引入因果交叉注意力融合多模态线索，利用推断的动作信号指导基于图像的潜在扩散模型进行逐帧未来视频生成。

Result: 在Ego4D、BridgeData和RLBench数据集上的广泛实验表明，该方法在动作预测和未来视频合成方面均优于最先进的基线方法。

Conclusion: 这是第一个设计用于同时处理自我中心人类活动理解和机器人操作任务的统一模型，能够显式预测即将发生的动作及其视觉后果。

Abstract: In egocentric scenarios, anticipating both the next action and its visual
outcome is essential for understanding human-object interactions and for
enabling robotic planning. However, existing paradigms fall short of jointly
modeling these aspects. Vision-Language-Action (VLA) models focus on action
prediction but lack explicit modeling of how actions influence the visual
scene, while video prediction models generate future frames without
conditioning on specific actions, often resulting in implausible or
contextually inconsistent outcomes. To bridge this gap, we propose a unified
two-stage predictive framework that jointly models action and visual future in
egocentric scenarios, conditioned on hand trajectories. In the first stage, we
perform consecutive state modeling to process heterogeneous inputs (visual
observations, language, and action history) and explicitly predict future hand
trajectories. In the second stage, we introduce causal cross-attention to fuse
multi-modal cues, leveraging inferred action signals to guide an image-based
Latent Diffusion Model (LDM) for frame-by-frame future video generation. Our
approach is the first unified model designed to handle both egocentric human
activity understanding and robotic manipulation tasks, providing explicit
predictions of both upcoming actions and their visual consequences. Extensive
experiments on Ego4D, BridgeData, and RLBench demonstrate that our method
outperforms state-of-the-art baselines in both action prediction and future
video synthesis.

</details>


### [143] [KRETA: A Benchmark for Korean Reading and Reasoning in Text-Rich VQA Attuned to Diverse Visual Contexts](https://arxiv.org/abs/2508.19944)
*Taebaek Hwang,Minseo Kim,Gisang Lee,Seonuk Kim,Hyunjun Eun*

Main category: cs.CV

TL;DR: KRETA是首个针对韩语的文本丰富视觉问答基准，填补了低资源语言在VLM评估方面的空白，包含多领域评估和自动化数据生成流程


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言（如韩语）在文本丰富视觉问答领域缺乏全面基准的问题，以便更好地评估和比较视觉语言模型

Method: 开发半自动化的VQA生成流程，采用分步图像分解和七指标评估协议来确保数据质量，支持15个领域和26种图像类型的多维度评估

Result: 创建了KRETA基准数据集，为韩语文本丰富的视觉理解和推理提供了全面的评估框架

Conclusion: KRETA不仅为韩语VLM研究提供了重要基准，其可扩展的流程设计也有助于其他语言类似基准的开发，推动多语言视觉语言模型研究

Abstract: Understanding and reasoning over text within visual contexts poses a
significant challenge for Vision-Language Models (VLMs), given the complexity
and diversity of real-world scenarios. To address this challenge, text-rich
Visual Question Answering (VQA) datasets and benchmarks have emerged for
high-resource languages like English. However, a critical gap persists for
low-resource languages such as Korean, where the lack of comprehensive
benchmarks hinders robust model evaluation and comparison. To bridge this gap,
we introduce KRETA, a benchmark for Korean Reading and rEasoning in Text-rich
VQA Attuned to diverse visual contexts. KRETA facilitates an in-depth
evaluation of both visual text understanding and reasoning capabilities, while
also supporting a multifaceted assessment across 15 domains and 26 image types.
Additionally, we introduce a semi-automated VQA generation pipeline
specifically optimized for text-rich settings, leveraging refined stepwise
image decomposition and a rigorous seven-metric evaluation protocol to ensure
data quality. While KRETA is tailored for Korean, we hope our adaptable and
extensible pipeline will facilitate the development of similar benchmarks in
other languages, thereby accelerating multilingual VLM research. The code and
dataset for KRETA are available at https://github.com/tabtoyou/KRETA.

</details>


### [144] [Multimodal Conditional MeshGAN for Personalized Aneurysm Growth Prediction](https://arxiv.org/abs/2508.19862)
*Long Chen,Ashiv Patel,Mengyun Qiao,Mohammad Yousuf Salmasi,Salah A. Hammouche,Vasilis Stavrinides,Jasleen Nagi,Soodeh Kalaie,Xiao Yun Xu,Wenjia Bai,Declan P. O'Regan*

Main category: cs.CV

TL;DR: MCMeshGAN是一个多模态条件网格生成对抗网络，用于3D主动脉瘤生长预测，结合局部KNN卷积网络和全局图卷积网络，在几何精度和临床直径估计方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主动脉瘤进展的个性化准确预测对及时干预至关重要，但由于需要同时建模复杂3D几何中的细微局部变形和全局解剖变化，这一任务具有挑战性。

Method: 提出MCMeshGAN双分支架构：局部KNN卷积网络(KCN)保持细粒度几何细节，全局图卷积网络(GCN)捕获长程结构上下文；专用条件分支编码临床属性和时间间隔；使用TAAMesh数据集（590个多模态记录，208名患者）。

Result: MCMeshGAN在几何精度和临床重要直径估计方面持续优于最先进的基线方法。

Conclusion: 该框架为实现临床可部署的个性化3D疾病轨迹建模提供了稳健的一步，源代码已公开。

Abstract: Personalized, accurate prediction of aortic aneurysm progression is essential
for timely intervention but remains challenging due to the need to model both
subtle local deformations and global anatomical changes within complex 3D
geometries. We propose MCMeshGAN, the first multimodal conditional mesh-to-mesh
generative adversarial network for 3D aneurysm growth prediction. MCMeshGAN
introduces a dual-branch architecture combining a novel local KNN-based
convolutional network (KCN) to preserve fine-grained geometric details and a
global graph convolutional network (GCN) to capture long-range structural
context, overcoming the over-smoothing limitations of deep GCNs. A dedicated
condition branch encodes clinical attributes (age, sex) and the target time
interval to generate anatomically plausible, temporally controlled predictions,
enabling retrospective and prospective modeling. We curated TAAMesh, a new
longitudinal thoracic aortic aneurysm mesh dataset consisting of 590 multimodal
records (CT scans, 3D meshes, and clinical data) from 208 patients. Extensive
experiments demonstrate that MCMeshGAN consistently outperforms
state-of-the-art baselines in both geometric accuracy and clinically important
diameter estimation. This framework offers a robust step toward clinically
deployable, personalized 3D disease trajectory modeling. The source code for
MCMeshGAN and the baseline methods is publicly available at
https://github.com/ImperialCollegeLondon/MCMeshGAN.

</details>


### [145] [GLSim: Detecting Object Hallucinations in LVLMs via Global-Local Similarity](https://arxiv.org/abs/2508.19972)
*Seongheon Park,Yixuan Li*

Main category: cs.CV

TL;DR: GLSim是一个无需训练的对象幻觉检测框架，通过结合全局和局部嵌入相似性信号，在多种场景中实现更准确可靠的幻觉检测，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的对象幻觉问题对其在现实应用中的安全部署构成重大挑战。现有方法通常单独采用全局或局部视角，可能限制检测可靠性。

Method: GLSim框架利用图像和文本模态之间的互补性全局和局部嵌入相似性信号，无需训练即可进行对象幻觉检测。

Result: 在全面的基准测试中，GLSim实现了优越的检测性能，显著优于竞争基线方法。

Conclusion: GLSim通过结合全局和局部视角，为对象幻觉检测提供了更准确可靠的解决方案，有助于提升视觉语言模型的安全部署。

Abstract: Object hallucination in large vision-language models presents a significant
challenge to their safe deployment in real-world applications. Recent works
have proposed object-level hallucination scores to estimate the likelihood of
object hallucination; however, these methods typically adopt either a global or
local perspective in isolation, which may limit detection reliability. In this
paper, we introduce GLSim, a novel training-free object hallucination detection
framework that leverages complementary global and local embedding similarity
signals between image and text modalities, enabling more accurate and reliable
hallucination detection in diverse scenarios. We comprehensively benchmark
existing object hallucination detection methods and demonstrate that GLSim
achieves superior detection performance, outperforming competitive baselines by
a significant margin.

</details>


### [146] [Self-supervised structured object representation learning](https://arxiv.org/abs/2508.19864)
*Oussama Hadjerci,Antoine Letienne,Mohamed Abbas Hedjazi,Adel Hafiane*

Main category: cs.CV

TL;DR: 提出了一种基于ProtoScale模块的自监督学习方法，通过语义分组、实例分离和层次化结构逐步构建结构化视觉表示，在目标检测任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法在全局图像理解方面表现良好，但在捕捉场景中的结构化表示方面存在局限，特别是在密集预测任务中。

Method: 使用ProtoScale模块在多空间尺度上捕捉视觉元素，保持增强视图的完整场景上下文，结合语义分组、实例级分离和层次化结构构建表示。

Result: 在COCO和UA-DETRAC数据集上的实验表明，该方法学习到的以对象为中心的表示能够提升监督目标检测性能，在有限标注数据和较少微调轮次下仍优于最先进方法。

Conclusion: 该方法通过保持场景上下文和多尺度结构化表示学习，有效提升了自监督学习在密集预测任务中的性能，特别是在目标检测方面表现出色。

Abstract: Self-supervised learning (SSL) has emerged as a powerful technique for
learning visual representations. While recent SSL approaches achieve strong
results in global image understanding, they are limited in capturing the
structured representation in scenes. In this work, we propose a self-supervised
approach that progressively builds structured visual representations by
combining semantic grouping, instance level separation, and hierarchical
structuring. Our approach, based on a novel ProtoScale module, captures visual
elements across multiple spatial scales. Unlike common strategies like DINO
that rely on random cropping and global embeddings, we preserve full scene
context across augmented views to improve performance in dense prediction
tasks. We validate our method on downstream object detection tasks using a
combined subset of multiple datasets (COCO and UA-DETRAC). Experimental results
show that our method learns object centric representations that enhance
supervised object detection and outperform the state-of-the-art methods, even
when trained with limited annotated data and fewer fine-tuning epochs.

</details>


### [147] [Multispectral LiDAR data for extracting tree points in urban and suburban areas](https://arxiv.org/abs/2508.19881)
*Narges Takhtkeshha,Gabriele Mazzacca,Fabio Remondino,Juha Hyyppä,Gottfried Mandlburger*

Main category: cs.CV

TL;DR: 本研究评估了三种深度学习模型（SPT、PTv3、PTv1）用于多光谱LiDAR城市树木提取，发现SPT模型在时间和精度上表现最佳，结合pNDVI可显著降低错误率。


<details>
  <summary>Details</summary>
Motivation: 城市树木监测对绿化政策和电力设施风险管理至关重要，但复杂城市环境和树木多样性给传统监测方法带来挑战，需要更先进的技术手段。

Method: 使用多光谱LiDAR获取空间和光谱数据，评估三种深度学习模型（Superpoint Transformer、Point Transformer V3、Point Transformer V1）进行树木点提取，并引入伪归一化植被指数（pNDVI）增强特征。

Result: SPT模型表现最优，平均交并比达85.28%；结合pNDVI与空间数据可将错误率降低10.61个百分点，相比仅使用空间信息有显著提升。

Conclusion: 多光谱LiDAR与深度学习结合具有巨大潜力，能够显著改善城市树木提取精度，为树木清单管理提供有效技术支持。

Abstract: Monitoring urban tree dynamics is vital for supporting greening policies and
reducing risks to electrical infrastructure. Airborne laser scanning has
advanced large-scale tree management, but challenges remain due to complex
urban environments and tree variability. Multispectral (MS) light detection and
ranging (LiDAR) improves this by capturing both 3D spatial and spectral data,
enabling detailed mapping. This study explores tree point extraction using
MS-LiDAR and deep learning (DL) models. Three state-of-the-art models are
evaluated: Superpoint Transformer (SPT), Point Transformer V3 (PTv3), and Point
Transformer V1 (PTv1). Results show the notable time efficiency and accuracy of
SPT, with a mean intersection over union (mIoU) of 85.28%. The highest
detection accuracy is achieved by incorporating pseudo normalized difference
vegetation index (pNDVI) with spatial data, reducing error rate by 10.61
percentage points (pp) compared to using spatial information alone. These
findings highlight the potential of MS-LiDAR and DL to improve tree extraction
and further tree inventories.

</details>


### [148] [TrajFusionNet: Pedestrian Crossing Intention Prediction via Fusion of Sequential and Visual Trajectory Representations](https://arxiv.org/abs/2508.19866)
*François G. Landry,Moulay A. Akhloufi*

Main category: cs.CV

TL;DR: TrajFusionNet是一个基于transformer的模型，通过结合未来行人轨迹和车辆速度预测来预测行人过街意图，在推理时间和性能方面都达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆上路，准确预测行人过街意图成为重要研究课题，需要开发高效准确的预测模型来确保道路安全。

Method: 提出TrajFusionNet模型，包含序列注意力模块(SAM)和视觉注意力模块(VAM)两个分支，分别从序列表示和视觉表示中学习，结合观测和预测的行人轨迹及车辆速度信息。

Result: 模型在推理时间（包括模型运行和数据预处理）方面达到最低，在三个常用行人过街意图预测数据集上均取得最先进的性能表现。

Conclusion: TrajFusionNet通过轻量级模态和创新的双分支架构，在行人过街意图预测任务中实现了高效且准确的性能，为自动驾驶安全提供了有效解决方案。

Abstract: With the introduction of vehicles with autonomous capabilities on public
roads, predicting pedestrian crossing intention has emerged as an active area
of research. The task of predicting pedestrian crossing intention involves
determining whether pedestrians in the scene are likely to cross the road or
not. In this work, we propose TrajFusionNet, a novel transformer-based model
that combines future pedestrian trajectory and vehicle speed predictions as
priors for predicting crossing intention. TrajFusionNet comprises two branches:
a Sequence Attention Module (SAM) and a Visual Attention Module (VAM). The SAM
branch learns from a sequential representation of the observed and predicted
pedestrian trajectory and vehicle speed. Complementarily, the VAM branch
enables learning from a visual representation of the predicted pedestrian
trajectory by overlaying predicted pedestrian bounding boxes onto scene images.
By utilizing a small number of lightweight modalities, TrajFusionNet achieves
the lowest total inference time (including model runtime and data
preprocessing) among current state-of-the-art approaches. In terms of
performance, it achieves state-of-the-art results across the three most
commonly used datasets for pedestrian crossing intention prediction.

</details>


### [149] [Sky Background Building of Multi-objective Fiber spectra Based on Mutual Information Network](https://arxiv.org/abs/2508.19875)
*Hui Zhang,Jianghui Cai,Haifeng Yang,Ali Luo,Yuqing Yang,Xiao Kong,Zhichao Ding,Lichan Zhou,Qin Han*

Main category: cs.CV

TL;DR: 提出基于互信息的天空背景估计模型SMI，通过双网络结构解决传统天空光纤平均光谱缺乏环境建模的问题，在LAMOST光谱数据上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多目标光纤光谱处理中的天空背景扣除主要依赖天空光纤光谱构建超天空平均光谱，但缺乏对目标周围环境的充分建模。

Method: SMI模型包含两个主要网络：第一个网络使用波长校准模块从光谱中提取天空特征，解决特征偏移问题；第二个网络采用增量训练方法最大化不同光谱表示间的互信息以捕获共同成分，同时最小化相邻光谱表示的互信息以获得个体成分。

Result: 在LAMOST光谱上的实验结果表明，SMI能够在观测过程中获得更好的目标天空背景，特别是在蓝端表现更佳。

Conclusion: SMI方法通过互信息和增量训练有效解决了天空背景估计中的环境建模问题，为多目标光纤光谱处理提供了更准确的天空背景扣除方案。

Abstract: Sky background subtraction is a critical step in Multi-objective Fiber
spectra process. However, current subtraction relies mainly on sky fiber
spectra to build Super Sky. These average spectra are lacking in the modeling
of the environment surrounding the objects. To address this issue, a sky
background estimation model: Sky background building based on Mutual
Information (SMI) is proposed. SMI based on mutual information and incremental
training approach. It utilizes spectra from all fibers in the plate to estimate
the sky background. SMI contains two main networks, the first network applies a
wavelength calibration module to extract sky features from spectra, and can
effectively solve the feature shift problem according to the corresponding
emission position. The second network employs an incremental training approach
to maximize mutual information between representations of different spectra to
capturing the common component. Then, it minimizes the mutual information
between adjoining spectra representations to obtain individual components. This
network yields an individual sky background at each location of the object. To
verify the effectiveness of the method in this paper, we conducted experiments
on the spectra of LAMOST. Results show that SMI can obtain a better object sky
background during the observation, especially in the blue end.

</details>


### [150] [PersonaAnimator: Personalized Motion Transfer from Unconstrained Videos](https://arxiv.org/abs/2508.19895)
*Ziyun Qian,Runyu Xiao,Shuyuan Tu,Wei Xue,Dingkang Yang,Mingcheng Li,Dongliang Kou,Minghao Han,Zizhi Chen,Lihua Zhang*

Main category: cs.CV

TL;DR: 本文提出了PersonaAnimator框架，通过从无约束视频中学习个性化运动模式，解决了现有运动生成方法在风格学习、数据依赖和物理合理性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成方法存在三个主要问题：(1)姿态引导的运动迁移方法仅复制运动而不学习风格特征；(2)运动风格迁移方法严重依赖难以获取的动作捕捉数据；(3)生成的运动有时违反物理定律。

Method: 提出PersonaAnimator框架，直接从无约束视频学习个性化运动模式，引入PersonaVid数据集（包含20个运动内容类别和120个运动风格类别），并提出物理感知的运动风格正则化机制确保物理合理性。

Result: 大量实验表明，PersonaAnimator在运动迁移任务上优于现有最先进方法，为视频到视频运动个性化任务设立了新的基准。

Conclusion: 该研究开创了视频到视频运动个性化新任务，提出的框架能够有效学习个性化运动模式并确保物理合理性，在运动生成领域取得了显著进展。

Abstract: Recent advances in motion generation show remarkable progress. However,
several limitations remain: (1) Existing pose-guided character motion transfer
methods merely replicate motion without learning its style characteristics,
resulting in inexpressive characters. (2) Motion style transfer methods rely
heavily on motion capture data, which is difficult to obtain. (3) Generated
motions sometimes violate physical laws. To address these challenges, this
paper pioneers a new task: Video-to-Video Motion Personalization. We propose a
novel framework, PersonaAnimator, which learns personalized motion patterns
directly from unconstrained videos. This enables personalized motion transfer.
To support this task, we introduce PersonaVid, the first video-based
personalized motion dataset. It contains 20 motion content categories and 120
motion style categories. We further propose a Physics-aware Motion Style
Regularization mechanism to enforce physical plausibility in the generated
motions. Extensive experiments show that PersonaAnimator outperforms
state-of-the-art motion transfer methods and sets a new benchmark for the
Video-to-Video Motion Personalization task.

</details>


### [151] [WaveHiT-SR: Hierarchical Wavelet Network for Efficient Image Super-Resolution](https://arxiv.org/abs/2508.19927)
*Fayaz Ali,Muhammad Zawish,Steven Davy,Radu Timofte*

Main category: cs.CV

TL;DR: 提出WaveHiT-SR方法，通过将小波变换嵌入分层transformer框架，使用自适应分层窗口替代静态小窗口，在降低计算复杂度的同时提升超分辨率性能


<details>
  <summary>Details</summary>
Motivation: 现有基于transformer的超分辨率方法由于窗口自注意力机制的二次计算复杂度，被迫使用小的固定窗口，限制了感受野范围

Method: 1) 使用自适应分层窗口替代静态小窗口；2) 利用小波变换将图像分解为多频率子带；3) 通过分层处理逐步重建高分辨率图像

Result: 在SwinIR-Light、SwinIR-NG和SRFormer-Light等模型上实现了最先进的超分辨率结果，参数量更少、FLOPs更低、速度更快

Conclusion: WaveHiT-SR方法有效解决了transformer在超分辨率任务中的计算复杂度问题，同时保持了优异的性能表现

Abstract: Transformers have demonstrated promising performance in computer vision
tasks, including image super-resolution (SR). The quadratic computational
complexity of window self-attention mechanisms in many transformer-based SR
methods forces the use of small, fixed windows, limiting the receptive field.
In this paper, we propose a new approach by embedding the wavelet transform
within a hierarchical transformer framework, called (WaveHiT-SR). First, using
adaptive hierarchical windows instead of static small windows allows to capture
features across different levels and greatly improve the ability to model
long-range dependencies. Secondly, the proposed model utilizes wavelet
transforms to decompose images into multiple frequency subbands, allowing the
network to focus on both global and local features while preserving structural
details. By progressively reconstructing high-resolution images through
hierarchical processing, the network reduces computational complexity without
sacrificing performance. The multi-level decomposition strategy enables the
network to capture fine-grained information in lowfrequency components while
enhancing high-frequency textures. Through extensive experimentation, we
confirm the effectiveness and efficiency of our WaveHiT-SR. Our refined
versions of SwinIR-Light, SwinIR-NG, and SRFormer-Light deliver cutting-edge SR
results, achieving higher efficiency with fewer parameters, lower FLOPs, and
faster speeds.

</details>


### [152] [Hyperspectral Sensors and Autonomous Driving: Technologies, Limitations, and Opportunities](https://arxiv.org/abs/2508.19905)
*Imad Ali Shah,Jiarong Li,Roshan George,Tim Brophy,Enda Ward,Martin Glavin,Edward Jones,Brian Deegan*

Main category: cs.CV

TL;DR: 本文首次全面综述了高光谱成像(HSI)在汽车ADAS/AD应用中的现状，分析了216款商用HSI相机，发现仅有4款满足性能阈值且无一款符合AEC-Q100标准，揭示了HSI研究潜力与商业成熟度之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像能够提供超越传统RGB成像的精细光谱分辨率，实现材料级别的场景理解，为高级驾驶辅助系统和自动驾驶应用提供变革性的感知能力，但需要系统评估其技术成熟度和实际应用可行性。

Method: 采用定性综述方法，分析216款商用HSI和多光谱成像相机，基于帧率、空间分辨率、光谱维度和AEC-Q100温度标准等关键汽车标准进行基准测试，并回顾最新的HSI数据集和应用案例。

Result: 分析显示仅有4款相机满足性能阈值，无一款符合AEC-Q100要求；当前HSI数据集在规模、光谱一致性、光谱通道数量和环境多样性方面存在局限，制约了感知算法开发和HSI真正潜力的验证。

Conclusion: HSI在汽车应用中存在显著的研究潜力与商业成熟度差距，需要朝着实际集成方向进行关键研究，包括改进相机技术、丰富数据集和开发更强大的感知算法。

Abstract: Hyperspectral imaging (HSI) offers a transformative sensing modality for
Advanced Driver Assistance Systems (ADAS) and autonomous driving (AD)
applications, enabling material-level scene understanding through fine spectral
resolution beyond the capabilities of traditional RGB imaging. This paper
presents the first comprehensive review of HSI for automotive applications,
examining the strengths, limitations, and suitability of current HSI
technologies in the context of ADAS/AD. In addition to this qualitative review,
we analyze 216 commercially available HSI and multispectral imaging cameras,
benchmarking them against key automotive criteria: frame rate, spatial
resolution, spectral dimensionality, and compliance with AEC-Q100 temperature
standards. Our analysis reveals a significant gap between HSI's demonstrated
research potential and its commercial readiness. Only four cameras meet the
defined performance thresholds, and none comply with AEC-Q100 requirements. In
addition, the paper reviews recent HSI datasets and applications, including
semantic segmentation for road surface classification, pedestrian separability,
and adverse weather perception. Our review shows that current HSI datasets are
limited in terms of scale, spectral consistency, the number of spectral
channels, and environmental diversity, posing challenges for the development of
perception algorithms and the adequate validation of HSI's true potential in
ADAS/AD applications. This review paper establishes the current state of HSI in
automotive contexts as of 2025 and outlines key research directions toward
practical integration of spectral imaging in ADAS and autonomous systems.

</details>


### [153] [Streamlining the Development of Active Learning Methods in Real-World Object Detection](https://arxiv.org/abs/2508.19906)
*Moussa Kassem Sbeyti,Nadja Klein,Michelle Karg,Christian Wirth,Sahin Albayrak*

Main category: cs.CV

TL;DR: 提出了对象级集合相似度(OSS)指标，无需训练检测器即可评估主动学习方法效果，并选择代表性验证集，解决了目标检测中主动学习的高计算成本和评估可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界目标检测中的主动学习面临计算成本高（训练一个检测器需282 GPU小时）和评估可靠性差（不同验证集方法排名差异大）的挑战，限制了在安全关键系统中的应用。

Method: 开发了对象级集合相似度(OSS)指标，通过对象级特征量化训练集与目标域的相似性，无需训练检测器即可评估主动学习方法效果，并能选择代表性验证集。

Result: 在三个自动驾驶数据集(KITTI、BDD100K、CODA)上验证了基于相似性的方法，使用不确定性主动学习方法作为案例研究，证明OSS能够有效评估方法效果和选择验证集。

Conclusion: OSS是检测器无关的，仅需要标注的对象裁剪图像，可与现有主动学习流程集成，为计算效率和评估可靠性要求高的实际应用提供了实用框架。

Abstract: Active learning (AL) for real-world object detection faces computational and
reliability challenges that limit practical deployment. Developing new AL
methods requires training multiple detectors across iterations to compare
against existing approaches. This creates high costs for autonomous driving
datasets where the training of one detector requires up to 282 GPU hours.
Additionally, AL method rankings vary substantially across validation sets,
compromising reliability in safety-critical transportation systems. We
introduce object-based set similarity ($\mathrm{OSS}$), a metric that addresses
these challenges. $\mathrm{OSS}$ (1) quantifies AL method effectiveness without
requiring detector training by measuring similarity between training sets and
target domains using object-level features. This enables the elimination of
ineffective AL methods before training. Furthermore, $\mathrm{OSS}$ (2) enables
the selection of representative validation sets for robust evaluation. We
validate our similarity-based approach on three autonomous driving datasets
(KITTI, BDD100K, CODA) using uncertainty-based AL methods as a case study with
two detector architectures (EfficientDet, YOLOv3). This work is the first to
unify AL training and evaluation strategies in object detection based on object
similarity. $\mathrm{OSS}$ is detector-agnostic, requires only labeled object
crops, and integrates with existing AL pipelines. This provides a practical
framework for deploying AL in real-world applications where computational
efficiency and evaluation reliability are critical. Code is available at
https://mos-ks.github.io/publications/.

</details>


### [154] [Integrating SAM Supervision for 3D Weakly Supervised Point Cloud Segmentation](https://arxiv.org/abs/2508.19909)
*Lechun You,Zhonghua Wu,Weide Liu,Xulei Yang,Jun Cheng,Wei Zhou,Bharadwaj Veeravalli,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出了一种利用2D基础模型分割掩码来增强稀疏3D标注的新方法，通过几何对应关系将2D分割传播到3D空间，并使用置信度和不确定性正则化来生成可靠的伪标签，从而提升3D弱监督分割性能


<details>
  <summary>Details</summary>
Motivation: 现有3D语义分割方法通常只关注3D域，没有充分利用2D和3D数据的互补性，同时现有伪标签方法未能充分利用标签或处理其中的噪声问题

Method: 利用2D基础模型生成分割掩码，通过几何对应关系将2D分割传播到3D空间，扩展稀疏标注范围，并应用置信度和不确定性一致性正则化来选择可靠的伪标签

Result: 该方法能够有效利用稀疏的3D标注，通过整合2D基础模型的能力显著增加了可用标签数量

Conclusion: 该方法成功弥合了有限3D标注与强大2D基础模型能力之间的差距，显著提升了3D弱监督分割的性能

Abstract: Current methods for 3D semantic segmentation propose training models with
limited annotations to address the difficulty of annotating large, irregular,
and unordered 3D point cloud data. They usually focus on the 3D domain only,
without leveraging the complementary nature of 2D and 3D data. Besides, some
methods extend original labels or generate pseudo labels to guide the training,
but they often fail to fully use these labels or address the noise within them.
Meanwhile, the emergence of comprehensive and adaptable foundation models has
offered effective solutions for segmenting 2D data. Leveraging this
advancement, we present a novel approach that maximizes the utility of sparsely
available 3D annotations by incorporating segmentation masks generated by 2D
foundation models. We further propagate the 2D segmentation masks into the 3D
space by establishing geometric correspondences between 3D scenes and 2D views.
We extend the highly sparse annotations to encompass the areas delineated by 3D
masks, thereby substantially augmenting the pool of available labels.
Furthermore, we apply confidence- and uncertainty-based consistency
regularization on augmentations of the 3D point cloud and select the reliable
pseudo labels, which are further spread on the 3D masks to generate more
labels. This innovative strategy bridges the gap between limited 3D annotations
and the powerful capabilities of 2D foundation models, ultimately improving the
performance of 3D weakly supervised segmentation.

</details>


### [155] [Reimagining Image Segmentation using Active Contour: From Chan Vese Algorithm into a Proposal Novel Functional Loss Framework](https://arxiv.org/abs/2508.19946)
*Gianluca Guzzetta*

Main category: cs.CV

TL;DR: 本文对Chan-Vese图像分割算法进行了系统研究，提出了基于活性边框的功能性分割损失函数，并与常见计算机视觉分割数据集进行了性能对比。


<details>
  <summary>Details</summary>
Motivation: 研究Chan-Vese模型的功能能量和偏微分方程，开发更有效的图像分割方法，并将经典算法与现代计算机视觉技术相结合。

Method: 采用离散化方案汇总Chan-Vese模型的功能能量，建立基于活性边框的功能性分割损失函数，使用pytorch.nn.ModuleLoss实现，并提供MATLAB实现。

Result: 在多个计算机视觉分割数据集上评估了经典损失函数与新方法的性能对比，所有代码和材料已开源。

Conclusion: 研究为图像分割领域提供了一种新的功能性损失函数方法，将经典Chan-Vese算法与深度学习框架相结合，为后续研究奠定了基础。

Abstract: In this paper, we present a comprehensive study and analysis of the Chan-Vese
algorithm for image segmentation. We employ a discretized scheme derived from
the empirical study of the Chan-Vese model's functional energy and its partial
differential equation based on its level set function. We provide a proof of
the results and an implementation using MATLAB. Leveraging modern computer
vision methodologies, we propose a functional segmentation loss based on active
contours, utilizing pytorch.nn.ModuleLoss and a level set based on the
Chan-Vese algorithm. We compare our results with common computer vision
segmentation datasets and evaluate the performance of classical loss functions
against our proposed method. All code and materials used are available at
https://github.com/gguzzy/chan_vese_functional_loss.

</details>


### [156] [Assessing the Geolocation Capabilities, Limitations and Societal Risks of Generative Vision-Language Models](https://arxiv.org/abs/2508.19967)
*Oliver Grainge,Sania Waheed,Jack Stilgoe,Michael Milford,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 本文系统评估了25个最先进视觉语言模型在4个基准图像数据集上的地理定位能力，发现当前VLM在普通街景图像上表现不佳，但在类似社交媒体内容的图像上准确率高达61%，揭示了严重的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型(VLM)在图像地理定位方面能力不断增强，带来了严重的隐私风险(如跟踪和监控)，但目前缺乏对生成式VLM地理定位精度的系统性评估。

Method: 对25个最先进的VLM在4个包含不同环境的基准图像数据集上进行全面评估，分析其地理定位能力。

Result: 当前VLM在普通街景图像上表现较差，但在类似社交媒体内容的图像上达到了61%的高准确率。

Conclusion: 研究揭示了VLM在地理定位方面的内部推理机制，强调了其优势、局限性以及潜在的社会风险，特别是对隐私保护的紧迫威胁。

Abstract: Geo-localization is the task of identifying the location of an image using
visual cues alone. It has beneficial applications, such as improving disaster
response, enhancing navigation, and geography education. Recently,
Vision-Language Models (VLMs) are increasingly demonstrating capabilities as
accurate image geo-locators. This brings significant privacy risks, including
those related to stalking and surveillance, considering the widespread uses of
AI models and sharing of photos on social media. The precision of these models
is likely to improve in the future. Despite these risks, there is little work
on systematically evaluating the geolocation precision of Generative VLMs,
their limits and potential for unintended inferences. To bridge this gap, we
conduct a comprehensive assessment of the geolocation capabilities of 25
state-of-the-art VLMs on four benchmark image datasets captured in diverse
environments. Our results offer insight into the internal reasoning of VLMs and
highlight their strengths, limitations, and potential societal risks. Our
findings indicate that current VLMs perform poorly on generic street-level
images yet achieve notably high accuracy (61\%) on images resembling social
media content, raising significant and urgent privacy concerns.

</details>


### [157] [Patch Progression Masked Autoencoder with Fusion CNN Network for Classifying Evolution Between Two Pairs of 2D OCT Slices](https://arxiv.org/abs/2508.20064)
*Philippe Zhang,Weili Jiang,Yihao Li,Jing Zhang,Sarah Matta,Yubo Tan,Hui Lin,Haoshen Wang,Jiangtian Pan,Hui Xu,Laurent Borderie,Alexandre Le Guilcher,Béatrice Cochener,Chubin Ou,Gwenolé Quellec,Mathieu Lamard*

Main category: cs.CV

TL;DR: 该论文针对年龄相关性黄斑变性（AMD）的进展监测，提出了基于OCT扫描的深度学习方法来分类疾病演变和预测未来进展，在MARIO挑战赛中取得了Top 10的成绩。


<details>
  <summary>Details</summary>
Motivation: AMD是影响视力的常见眼病，抗VEGF治疗需要及时诊断和持续监测。通过跟踪新生血管活动在OCT扫描中的进展，可以制定更个性化和有效的治疗计划。

Method: Task 1使用融合CNN网络和模型集成对连续OCT采集的2D切片对进行分类；Task 2提出补丁进展掩码自编码器，生成下一次检查的OCT图像，然后使用Task 1的解决方案进行分类。

Result: 在两个任务中都取得了Top 10的成绩，但由于部分团队成员与挑战赛组织者属于同一组织，不具备获奖资格。

Conclusion: 提出的深度学习方法能够有效监测AMD在OCT扫描中的进展，为个性化治疗提供了技术支持，在MARIO挑战赛中验证了其有效性。

Abstract: Age-related Macular Degeneration (AMD) is a prevalent eye condition affecting
visual acuity. Anti-vascular endothelial growth factor (anti-VEGF) treatments
have been effective in slowing the progression of neovascular AMD, with better
outcomes achieved through timely diagnosis and consistent monitoring. Tracking
the progression of neovascular activity in OCT scans of patients with exudative
AMD allows for the development of more personalized and effective treatment
plans. This was the focus of the Monitoring Age-related Macular Degeneration
Progression in Optical Coherence Tomography (MARIO) challenge, in which we
participated. In Task 1, which involved classifying the evolution between two
pairs of 2D slices from consecutive OCT acquisitions, we employed a fusion CNN
network with model ensembling to further enhance the model's performance. For
Task 2, which focused on predicting progression over the next three months
based on current exam data, we proposed the Patch Progression Masked
Autoencoder that generates an OCT for the next exam and then classifies the
evolution between the current OCT and the one generated using our solution from
Task 1. The results we achieved allowed us to place in the Top 10 for both
tasks. Some team members are part of the same organization as the challenge
organizers; therefore, we are not eligible to compete for the prize.

</details>


### [158] [CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning](https://arxiv.org/abs/2508.20096)
*Zeyi Sun,Yuhang Cao,Jianze Liang,Qiushi Sun,Ziyu Liu,Zhixiong Zhang,Yuhang Zang,Xiaoyi Dong,Kai Chen,Dahua Lin,Jiaqi Wang*

Main category: cs.CV

TL;DR: CODA是一个可训练的组合框架，通过两阶段训练流程整合通用规划器和专业执行器，在科学计算GUI任务中实现了卓越的执行精度和跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决GUI自主代理在科学计算领域面临的长期规划与精确执行之间的权衡问题，现有组合框架因静态不可训练而无法从经验中适应，这在高质量数据稀缺的科学领域尤为关键。

Method: 提出CODA框架：1）专业化阶段：使用解耦GRPO方法为每个科学应用单独训练专家规划器；2）泛化阶段：聚合所有成功轨迹进行监督微调，整合通用规划器(Cerebrum)和专业执行器(Cerebellum)。

Result: 在ScienceBenchmark的四个挑战性应用上评估，CODA显著超越基线方法，在开源模型中建立了新的最先进水平。

Conclusion: CODA通过可训练的组合框架成功解决了科学计算GUI任务中规划与执行的平衡问题，证明了其在专业领域的高效性和泛化能力。

Abstract: Autonomous agents for Graphical User Interfaces (GUIs) face significant
challenges in specialized domains such as scientific computing, where both
long-horizon planning and precise execution are required. Existing approaches
suffer from a trade-off: generalist agents excel at planning but perform poorly
in execution, while specialized agents demonstrate the opposite weakness.
Recent compositional frameworks attempt to bridge this gap by combining a
planner and an actor, but they are typically static and non-trainable, which
prevents adaptation from experience. This is a critical limitation given the
scarcity of high-quality data in scientific domains. To address these
limitations, we introduce CODA, a novel and trainable compositional framework
that integrates a generalist planner (Cerebrum) with a specialist executor
(Cerebellum), trained via a dedicated two-stage pipeline. In the first stage,
Specialization, we apply a decoupled GRPO approach to train an expert planner
for each scientific application individually, bootstrapping from a small set of
task trajectories. In the second stage, Generalization, we aggregate all
successful trajectories from the specialized experts to build a consolidated
dataset, which is then used for supervised fine-tuning of the final planner.
This equips CODA with both robust execution and cross-domain generalization.
Evaluated on four challenging applications from the ScienceBoard benchmark,
CODA significantly outperforms baselines and establishes a new state of the art
among open-source models.

</details>


### [159] [GS: Generative Segmentation via Label Diffusion](https://arxiv.org/abs/2508.20020)
*Yuhao Chen,Shubin Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: GS（生成式分割）是一个新框架，将分割任务重新定义为通过标签扩散的生成式过程，直接从噪声生成分割掩码，在图像和语言描述条件下实现端到端训练。


<details>
  <summary>Details</summary>
Motivation: 传统方法将语言驱动的图像分割视为判别式问题，现有扩散模型方法仍以图像为中心，将分割作为辅助过程。本文旨在将分割本身作为主要生成任务。

Method: 提出GS框架，通过标签扩散直接生成分割掩码，而不是生成图像。该方法以输入图像和语言描述为条件，从噪声直接生成标签，实现端到端训练。

Result: 在Panoptic Narrative Grounding基准测试中，GS显著优于现有的判别式和基于扩散的方法，创造了语言驱动分割的新state-of-the-art。

Conclusion: 将分割重新定义为生成式任务的方法有效，GS框架通过直接生成分割掩码实现了更好的空间和语义保真度控制，在复杂多模态分割任务中表现出色。

Abstract: Language-driven image segmentation is a fundamental task in vision-language
understanding, requiring models to segment regions of an image corresponding to
natural language expressions. Traditional methods approach this as a
discriminative problem, assigning each pixel to foreground or background based
on semantic alignment. Recently, diffusion models have been introduced to this
domain, but existing approaches remain image-centric: they either (i) use image
diffusion models as visual feature extractors, (ii) synthesize segmentation
data via image generation to train discriminative models, or (iii) perform
diffusion inversion to extract attention cues from pre-trained image diffusion
models-thereby treating segmentation as an auxiliary process. In this paper, we
propose GS (Generative Segmentation), a novel framework that formulates
segmentation itself as a generative task via label diffusion. Instead of
generating images conditioned on label maps and text, GS reverses the
generative process: it directly generates segmentation masks from noise,
conditioned on both the input image and the accompanying language description.
This paradigm makes label generation the primary modeling target, enabling
end-to-end training with explicit control over spatial and semantic fidelity.
To demonstrate the effectiveness of our approach, we evaluate GS on Panoptic
Narrative Grounding (PNG), a representative and challenging benchmark for
multimodal segmentation that requires panoptic-level reasoning guided by
narrative captions. Experimental results show that GS significantly outperforms
existing discriminative and diffusion-based methods, setting a new
state-of-the-art for language-driven segmentation.

</details>


### [160] [Segmentation Assisted Incremental Test Time Adaptation in an Open World](https://arxiv.org/abs/2508.20029)
*Manogna Sreenivas,Soma Biswas*

Main category: cs.CV

TL;DR: 提出了SegAssist框架，用于视觉语言模型的增量测试时适应，通过分割辅助的主动标注技术处理测试时出现的新类别和新域


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中部署模型遇到未知对象和分布偏移时的泛化挑战，特别是在测试阶段持续出现未知类别和未知域的场景

Method: 结合单图像TTA方法和主动标注技术，提出SegAssist模块（训练免费），重新利用VLM的分割能力来优化主动样本选择，优先选择可能属于未知类别的样本

Result: 在多个基准数据集上的广泛实验证明了SegAssist在增强VLM在现实世界场景中性能的潜力

Conclusion: SegAssist能够有效提升视觉语言模型在需要持续适应新兴数据的真实场景中的表现

Abstract: In dynamic environments, unfamiliar objects and distribution shifts are often
encountered, which challenge the generalization abilities of the deployed
trained models. This work addresses Incremental Test Time Adaptation of Vision
Language Models, tackling scenarios where unseen classes and unseen domains
continuously appear during testing. Unlike traditional Test Time Adaptation
approaches, where the test stream comes only from a predefined set of classes,
our framework allows models to adapt simultaneously to both covariate and label
shifts, actively incorporating new classes as they emerge. Towards this goal,
we establish a new benchmark for ITTA, integrating single image TTA methods for
VLMs with active labeling techniques that query an oracle for samples
potentially representing unseen classes during test time. We propose a
segmentation assisted active labeling module, termed SegAssist, which is
training free and repurposes the segmentation capabilities of VLMs to refine
active sample selection, prioritizing samples likely to belong to unseen
classes. Extensive experiments on several benchmark datasets demonstrate the
potential of SegAssist to enhance the performance of VLMs in real world
scenarios, where continuous adaptation to emerging data is essential.
Project-page:https://manogna-s.github.io/segassist/

</details>


### [161] [OpenM3D: Open Vocabulary Multi-view Indoor 3D Object Detection without Human Annotations](https://arxiv.org/abs/2508.20063)
*Peng-Hao Hsu,Ke Zhang,Fu-En Wang,Tao Tu,Ming-Feng Li,Yu-Lun Liu,Albert Y. C. Chen,Min Sun,Cheng-Hao Kuo*

Main category: cs.CV

TL;DR: OpenM3D是一个无需人工标注的开源多视角室内3D目标检测器，通过2D诱导体素特征和CLIP特征对齐，在精度和速度上均优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇3D目标检测主要基于3D点云方法，基于图像的方法探索有限，需要开发无需人工标注的高效检测器

Method: 采用单阶段检测器架构，结合2D分割图嵌入技术生成高质量3D伪框，通过类无关3D定位损失和体素-语义对齐损失进行联合训练

Result: 在ScanNet200和ARKitScenes基准测试中，OpenM3D在精度和速度（每场景0.3秒）上均优于现有方法，包括强两阶段方法

Conclusion: OpenM3D证明了无需人工标注的高质量单阶段开放词汇3D检测器的可行性，在效率和准确性方面具有显著优势

Abstract: Open-vocabulary (OV) 3D object detection is an emerging field, yet its
exploration through image-based methods remains limited compared to 3D point
cloud-based methods. We introduce OpenM3D, a novel open-vocabulary multi-view
indoor 3D object detector trained without human annotations. In particular,
OpenM3D is a single-stage detector adapting the 2D-induced voxel features from
the ImGeoNet model. To support OV, it is jointly trained with a class-agnostic
3D localization loss requiring high-quality 3D pseudo boxes and a
voxel-semantic alignment loss requiring diverse pre-trained CLIP features. We
follow the training setting of OV-3DET where posed RGB-D images are given but
no human annotations of 3D boxes or classes are available. We propose a 3D
Pseudo Box Generation method using a graph embedding technique that combines 2D
segments into coherent 3D structures. Our pseudo-boxes achieve higher precision
and recall than other methods, including the method proposed in OV-3DET. We
further sample diverse CLIP features from 2D segments associated with each
coherent 3D structure to align with the corresponding voxel feature. The key to
training a highly accurate single-stage detector requires both losses to be
learned toward high-quality targets. At inference, OpenM3D, a highly efficient
detector, requires only multi-view images for input and demonstrates superior
accuracy and speed (0.3 sec. per scene) on ScanNet200 and ARKitScenes indoor
benchmarks compared to existing methods. We outperform a strong two-stage
method that leverages our class-agnostic detector with a ViT CLIP-based OV
classifier and a baseline incorporating multi-view depth estimator on both
accuracy and speed.

</details>


### [162] [PAUL: Uncertainty-Guided Partition and Augmentation for Robust Cross-View Geo-Localization under Noisy Correspondence](https://arxiv.org/abs/2508.20066)
*Zheng Li,Yanming Guo,WenZhe Liu,Xueyi Zhang,Zhaoyun Ding,Long Xu,Mingrui Lao*

Main category: cs.CV

TL;DR: 本文提出了PAUL框架来解决跨视角地理定位中的噪声对应问题，通过不确定性学习和选择性增强来处理GPS漂移导致的图像对未对齐问题


<details>
  <summary>Details</summary>
Motivation: 现有跨视角地理定位方法假设训练图像对完美对齐，但实际应用中GPS漂移等因素导致系统性的对齐偏移，只有部分对应关系存在，这种噪声对应问题在当前研究中关注不足

Method: 提出PAUL框架，通过不确定性感知协同增强和证据协同训练来估计数据不确定性，基于此对训练数据进行分区和增强。选择性地增强具有高对应置信度的区域，并利用不确定性估计来细化特征学习

Result: 综合实验验证了PAUL各组成部分的有效性，在各种噪声比例下 consistently 优于其他竞争性噪声对应驱动方法

Conclusion: PAUL框架通过不确定性驱动的分区和增强策略，有效解决了跨视角地理定位中的噪声对应问题，为从理想化基准到实际应用的过渡提供了有效解决方案

Abstract: Cross-view geo-localization is a critical task for UAV navigation, event
detection, and aerial surveying, as it enables matching between drone-captured
and satellite imagery. Most existing approaches embed multi-modal data into a
joint feature space to maximize the similarity of paired images. However, these
methods typically assume perfect alignment of image pairs during training,
which rarely holds true in real-world scenarios. In practice, factors such as
urban canyon effects, electromagnetic interference, and adverse weather
frequently induce GPS drift, resulting in systematic alignment shifts where
only partial correspondences exist between pairs. Despite its prevalence, this
source of noisy correspondence has received limited attention in current
research. In this paper, we formally introduce and address the Noisy
Correspondence on Cross-View Geo-Localization (NC-CVGL) problem, aiming to
bridge the gap between idealized benchmarks and practical applications. To this
end, we propose PAUL (Partition and Augmentation by Uncertainty Learning), a
novel framework that partitions and augments training data based on estimated
data uncertainty through uncertainty-aware co-augmentation and evidential
co-training. Specifically, PAUL selectively augments regions with high
correspondence confidence and utilizes uncertainty estimation to refine feature
learning, effectively suppressing noise from misaligned pairs. Distinct from
traditional filtering or label correction, PAUL leverages both data uncertainty
and loss discrepancy for targeted partitioning and augmentation, thus providing
robust supervision for noisy samples. Comprehensive experiments validate the
effectiveness of individual components in PAUL,which consistently achieves
superior performance over other competitive noisy-correspondence-driven methods
in various noise ratios.

</details>


### [163] [Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies](https://arxiv.org/abs/2508.20072)
*Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Liuao Pei,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo*

Main category: cs.CV

TL;DR: 提出Discrete Diffusion VLA方法，使用离散扩散模型在单一Transformer中处理视觉-语言-动作任务，通过渐进式精炼和自适应解码顺序提升动作生成的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA解码器要么采用固定的自回归生成顺序，要么需要专门的连续扩散训练和迭代采样，缺乏统一且可扩展的架构。

Method: 使用离散扩散模型对离散化动作块进行建模，采用与VLM骨干网络相同的交叉熵目标进行训练，支持并行解码和二次重掩码机制。

Result: 在LIBERO上达到96.3%平均成功率，SimplerEnv Fractal上71.2%视觉匹配率，SimplerEnv Bridge上49.3%总体性能，优于自回归和连续扩散基线。

Conclusion: 离散扩散动作解码器支持精确的动作建模和一致性训练，为将VLA扩展到更大模型和数据集奠定了基础。

Abstract: Vision-Language-Action (VLA) models adapt large vision-language backbones to
map images and instructions to robot actions. However, prevailing VLA decoders
either generate actions autoregressively in a fixed left-to-right order or
attach continuous diffusion or flow matching heads outside the backbone,
demanding specialized training and iterative sampling that hinder a unified,
scalable architecture. We present Discrete Diffusion VLA, a single-transformer
policy that models discretized action chunks with discrete diffusion and is
trained with the same cross-entropy objective as the VLM backbone. The design
retains diffusion's progressive refinement paradigm while remaining natively
compatible with the discrete token interface of VLMs. Our method achieves an
adaptive decoding order that resolves easy action elements before harder ones
and uses secondary remasking to revisit uncertain predictions across refinement
rounds, which improves consistency and enables robust error correction. This
unified decoder preserves pretrained vision language priors, supports parallel
decoding, breaks the autoregressive bottleneck, and reduces the number of
function evaluations. Discrete Diffusion VLA achieves 96.3% avg. SR on LIBERO,
71.2% visual matching on SimplerEnv Fractal and 49.3% overall on SimplerEnv
Bridge, improving over both autoregressive and continuous diffusion baselines.
These findings indicate that discrete-diffusion action decoder supports precise
action modeling and consistent training, laying groundwork for scaling VLA to
larger models and datasets.

</details>


### [164] [Seam360GS: Seamless 360° Gaussian Splatting from Real-World Omnidirectional Images](https://arxiv.org/abs/2508.20080)
*Changha Shin,Woong Oh Cho,Seon Joo Kim*

Main category: cs.CV

TL;DR: 通过3D高斯拟合渐变技术优化双鱼眼摄像机模型，从不完美的360度图像生成无缝渲染效果


<details>
  <summary>Details</summary>
Motivation: 消费级双鱼眼系统因镜头分离和角度异常导致不完美全景图，需要一种方法来治理这些视觉效应

Method: 将双鱼眼摄像机模型集成到3D高斯拟合渐变流程，联合优化3D高斯参数和模拟镜头间隔、角度异常的校准变量

Result: 在真实数据集上评估显示，该方法能从不完美图像生成无缝渲染效果，性能超过现有360度渲染模型

Conclusion: 该框架通过模拟双鱼眼摄像机的实际效应，能够将不完美全景输入转换为无缺陷的新视角生成

Abstract: 360-degree visual content is widely shared on platforms such as YouTube and
plays a central role in virtual reality, robotics, and autonomous navigation.
However, consumer-grade dual-fisheye systems consistently yield imperfect
panoramas due to inherent lens separation and angular distortions. In this
work, we introduce a novel calibration framework that incorporates a
dual-fisheye camera model into the 3D Gaussian splatting pipeline. Our approach
not only simulates the realistic visual artifacts produced by dual-fisheye
cameras but also enables the synthesis of seamlessly rendered 360-degree
images. By jointly optimizing 3D Gaussian parameters alongside calibration
variables that emulate lens gaps and angular distortions, our framework
transforms imperfect omnidirectional inputs into flawless novel view synthesis.
Extensive evaluations on real-world datasets confirm that our method produces
seamless renderings-even from imperfect images-and outperforms existing
360-degree rendering models.

</details>


### [165] [AudioStory: Generating Long-Form Narrative Audio with Large Language Models](https://arxiv.org/abs/2508.20088)
*Yuxin Guo,Teng Wang,Yuying Ge,Shijie Ma,Yixiao Ge,Wei Zou,Ying Shan*

Main category: cs.CV

TL;DR: AudioStory是一个统一的文本到音频生成框架，通过整合大语言模型和TTA系统来生成结构化的长篇音频叙事，解决了现有方法在长音频生成中缺乏时序连贯性和组合推理能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频生成方法在合成短音频片段方面表现出色，但在生成长篇叙事音频时面临时序连贯性和组合推理的挑战，需要一种能够保持场景过渡连贯性和情感语调一致性的解决方案。

Method: AudioStory采用解耦的桥接机制，将LLM与扩散模型的协作分为两个专门组件：桥接查询用于事件内语义对齐，残差查询用于跨事件连贯性保持。同时采用端到端训练，统一指令理解和音频生成。

Result: 实验结果表明AudioStory在单音频生成和叙事音频生成方面均优于先前的TTA基线方法，在指令跟随能力和音频保真度方面都有显著提升。

Conclusion: AudioStory通过创新的解耦桥接机制和端到端训练框架，成功解决了长音频叙事生成的挑战，为结构化音频内容创作提供了有效的解决方案。

Abstract: Recent advances in text-to-audio (TTA) generation excel at synthesizing short
audio clips but struggle with long-form narrative audio, which requires
temporal coherence and compositional reasoning. To address this gap, we propose
AudioStory, a unified framework that integrates large language models (LLMs)
with TTA systems to generate structured, long-form audio narratives. AudioStory
possesses strong instruction-following reasoning generation capabilities. It
employs LLMs to decompose complex narrative queries into temporally ordered
sub-tasks with contextual cues, enabling coherent scene transitions and
emotional tone consistency. AudioStory has two appealing features: (1)
Decoupled bridging mechanism: AudioStory disentangles LLM-diffuser
collaboration into two specialized components, i.e., a bridging query for
intra-event semantic alignment and a residual query for cross-event coherence
preservation. (2) End-to-end training: By unifying instruction comprehension
and audio generation within a single end-to-end framework, AudioStory
eliminates the need for modular training pipelines while enhancing synergy
between components. Furthermore, we establish a benchmark AudioStory-10K,
encompassing diverse domains such as animated soundscapes and natural sound
narratives. Extensive experiments show the superiority of AudioStory on both
single-audio generation and narrative audio generation, surpassing prior TTA
baselines in both instruction-following ability and audio fidelity. Our code is
available at https://github.com/TencentARC/AudioStory

</details>


### [166] [Bridging Domain Gaps for Fine-Grained Moth Classification Through Expert-Informed Adaptation and Foundation Model Priors](https://arxiv.org/abs/2508.20089)
*Ross J Gardiner,Guillaume Mougeot,Sareh Rowlands,Benno I Simmons,Flemming Helsing,Toke Thomas Høye*

Main category: cs.CV

TL;DR: 提出轻量级分类方法，结合专家标注数据和BioCLIP2知识蒸馏，在丹麦蛾类识别中实现高精度且计算成本显著降低


<details>
  <summary>Details</summary>
Motivation: 自动相机系统采集的蛾类图像标注对理解昆虫减少至关重要，但野外图像与标准图像存在域偏移问题，准确物种识别具有挑战性

Method: 结合有限专家标注的野外数据和BioCLIP2基础模型的知识蒸馏，采用ConvNeXt-tiny架构构建轻量级分类模型

Result: 在101种丹麦蛾类的AMI相机系统实验中，BioCLIP2显著优于其他方法，蒸馏后的轻量模型达到相当精度且计算成本大幅降低

Conclusion: 为开发高效昆虫监测系统和弥合细粒度分类的域差距提供了实用指导

Abstract: Labelling images of Lepidoptera (moths) from automated camera systems is
vital for understanding insect declines. However, accurate species
identification is challenging due to domain shifts between curated images and
noisy field imagery. We propose a lightweight classification approach,
combining limited expert-labelled field data with knowledge distillation from
the high-performance BioCLIP2 foundation model into a ConvNeXt-tiny
architecture. Experiments on 101 Danish moth species from AMI camera systems
demonstrate that BioCLIP2 substantially outperforms other methods and that our
distilled lightweight model achieves comparable accuracy with significantly
reduced computational cost. These insights offer practical guidelines for the
development of efficient insect monitoring systems and bridging domain gaps for
fine-grained classification.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [167] [Robust Recursive Query Parallelism in Graph Database Management Systems](https://arxiv.org/abs/2508.19379)
*Anurag Chakraborty,Semih Salihoğlu*

Main category: cs.DB

TL;DR: 该论文研究了图数据库管理系统中递归连接查询的多核并行处理，提出了基于morsel分发策略的混合并行方法，结合源节点级别和边界级别的并行化，并在Kuzu GDBMS中实现验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在并行化递归查询时存在局限性，要么只在源节点级别并行化（morsel-driven parallelism），要么只在边界级别并行化。需要探索更有效的并行策略来提升图数据库性能。

Method: 提出morsel分发策略的设计空间，实现混合策略（同时使用源节点和边界级别的morsel），以及多源morsel策略。在Kuzu GDBMS中实现这些策略并进行系统评估。

Result: 混合策略在两种现有方法表现良好时都能捕获其行为，在它们受限时表现更优。多源morsel策略在查询中有足够多源节点时能减少扫描次数。

Conclusion: 混合morsel分发策略是并行化递归查询的稳健方法，多源morsel分配在适当条件下能带来性能收益。

Abstract: Efficient multi-core parallel processing of recursive join queries is
critical for achieving good performance in graph database management systems
(GDBMSs). Prior work adopts two broad approaches. First is the state of the art
morsel-driven parallelism, whose vanilla application in GDBMSs parallelizes
computations at the source node level. Second is to parallelize each iteration
of the computation at the frontier level. We show that these approaches can be
seen as part of a design space of morsel dispatching policies based on picking
different granularities of morsels. We then empirically study the question of
which policies parallelize better in practice under a variety of datasets and
query workloads that contain one to many source nodes. We show that these two
policies can be combined in a hybrid policy that issues morsels both at the
source node and frontier levels. We then show that the multi-source
breadth-first search optimization from prior work can also be modeled as a
morsel dispatching policy that packs multiple source nodes into multi-source
morsels. We implement these policies inside a single system, the Kuzu GDBMS,
and evaluate them both within Kuzu and across other systems. We show that the
hybrid policy captures the behavior of both source morsel-only and frontier
morsel-only policies in cases when these approaches parallelize well, and
out-perform them on queries when they are limited, and propose it as a robust
approach to parallelizing recursive queries. We further show that assigning
multi-sources is beneficial, as it reduces the amount of scans, but only when
there is enough sources in the query.

</details>


### [168] [Bootstrapping Learned Cost Models with Synthetic SQL Queries](https://arxiv.org/abs/2508.19807)
*Michael Nidd,Christoph Miksovic,Thomas Gschwind,Francesco Fusco,Andrea Giovannini,Ioana Giurgiu*

Main category: cs.DB

TL;DR: 利用生成式AI技术创建质量更高的合成SQL查询数据集，在减少45%训练查询的情况下提升学习成本模型的预测准确性


<details>
  <summary>Details</summary>
Motivation: 需要实际的数据库工作负载来进行压力测试、漏洞测试以及成本和性能优化，而学习成本模型需要多样化的SQL查询进行训练

Method: 采用受生成式AI和大语言模型启发的现代合成数据生成技术，创建高质量的数据集用于学习成本模型的训练

Result: 与竞争性生成方法相比，可以在减少45%训练查询的情况下提高学习成本模型的预测准确性

Conclusion: 生成式AI技术能够生成高质量的合成SQL查询数据，为学习成本模型提供更有效的训练数据，从而提升数据库性能优化和测试的效果

Abstract: Having access to realistic workloads for a given database instance is
extremely important to enable stress and vulnerability testing, as well as to
optimize for cost and performance. Recent advances in learned cost models have
shown that when enough diverse SQL queries are available, one can effectively
and efficiently predict the cost of running a given query against a specific
database engine. In this paper, we describe our experience in exploiting modern
synthetic data generation techniques, inspired by the generative AI and LLM
community, to create high-quality datasets enabling the effective training of
such learned cost models. Initial results show that we can improve a learned
cost model's predictive accuracy by training it with 45% fewer queries than
when using competitive generation approaches.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [169] [HAP: Hybrid Adaptive Parallelism for Efficient Mixture-of-Experts Inference](https://arxiv.org/abs/2508.19373)
*Haoran Lin,Xianzhi Yu,Kang Zhao,Han Bao,Zongyuan Zhan,Ting Hu,Wulong Liu,Zekun Yin,Xin Li,Weiguo Liu*

Main category: cs.DC

TL;DR: HAP是一种动态混合并行策略，通过层次化分解MoE模型架构并利用整数线性规划优化配置，显著提升MoE推理效率，在不同GPU平台上实现1.57-1.77倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型推理系统采用静态并行策略，无法适应不同推理场景的计算需求变化，缺乏灵活性来持续获得最优性能。

Method: 将MoE架构层次化分解为注意力模块和专家模块，为每个模块构建专门的推理延迟模拟模型，建立全面的并行策略搜索空间，使用整数线性规划求解最优混合并行配置。

Result: 在A100、A6000和V100 GPU平台上分别实现1.68倍、1.77倍和1.57倍的加速，性能优于主流TP策略，且在Mixtral和Qwen系列模型上展现出色泛化能力。

Conclusion: HAP通过动态选择混合并行策略，有效解决了MoE模型推理中的性能优化问题，为不同硬件平台和模型配置提供了高效的自适应推理解决方案。

Abstract: Current inference systems for Mixture-of-Experts (MoE) models primarily
employ static parallelization strategies. However, these static approaches
cannot consistently achieve optimal performance across different inference
scenarios, as they lack the flexibility to adapt to varying computational
requirements. In this work, we propose HAP (Hybrid Adaptive Parallelism), a
novel method that dynamically selects hybrid parallel strategies to enhance MoE
inference efficiency. The fundamental innovation of HAP lies in hierarchically
decomposing MoE architectures into two distinct computational modules: the
Attention module and the Expert module, each augmented with a specialized
inference latency simulation model. This decomposition promotes the
construction of a comprehensive search space for seeking model parallel
strategies. By leveraging Integer Linear Programming (ILP), HAP could solve the
optimal hybrid parallel configurations to maximize inference efficiency under
varying computational constraints. Our experiments demonstrate that HAP
consistently determines parallel configurations that achieve comparable or
superior performance to the TP strategy prevalent in mainstream inference
systems. Compared to the TP-based inference, HAP-based inference achieves
speedups of 1.68x, 1.77x, and 1.57x on A100, A6000, and V100 GPU platforms,
respectively. Furthermore, HAP showcases remarkable generalization capability,
maintaining performance effectiveness across diverse MoE model configurations,
including Mixtral and Qwen series models.

</details>


### [170] [Formal Modeling and Verification of the Algorand Consensus Protocol in CADP](https://arxiv.org/abs/2508.19452)
*Andrea Esposito,Francesco P. Rossi,Marco Bernardo,Francesco Fabris,Hubert Garavel*

Main category: cs.DC

TL;DR: 本文对Algorand共识协议进行了形式化建模和验证，使用概率进程演算方法分析协议在正常和恶意攻击场景下的行为，并通过CADP验证工具进行等价性检查。


<details>
  <summary>Details</summary>
Motivation: 为了对Algorand区块链共识协议进行严格的形式化验证，确保其安全性和正确性，特别是在面对恶意节点攻击时的鲁棒性。

Method: 使用概率进程演算建立Algorand共识协议的代数模型，通过CADP验证工具包实现基于等价性检查的非干扰框架来分析恶意攻击场景。

Result: 验证了协议在无对抗情况下的正确性，分析了恶意节点强制提交空块而非提议块的影响，揭示了协议在对抗假设下的鲁棒性和局限性。

Conclusion: 这项工作展示了形式化方法在分析区块链共识算法中的附加价值，为Algorand协议的安全验证提供了理论基础和实用工具。

Abstract: Algorand is a scalable and secure permissionless blockchain that achieves
proof-of-stake consensus via cryptographic self-sortition and binary Byzantine
agreement. In this paper, we present a process algebraic model of the Algorand
consensus protocol with the aim of enabling rigorous formal verification. Our
model captures the behavior of participants with respect to the structured
alternation of consensus steps toward a committee-based agreement by means of a
probabilistic process calculus. We validate the correctness of the protocol in
the absence of adversaries and then extend our model to capture the influence
of coordinated malicious nodes that can force the commit of an empty block
instead of the proposed one. The adversarial scenario is analyzed by using an
equivalence-checking-based noninterference framework that we have implemented
in the CADP verification toolkit. In addition to highlighting both the
robustness and the limitations of the Algorand protocol under adversarial
assumptions, this work illustrates the added value of using formal methods for
the analysis of blockchain consensus algorithms.

</details>


### [171] [Towards 6G Intelligence: The Role of Generative AI in Future Wireless Networks](https://arxiv.org/abs/2508.19495)
*Muhammad Ahmed Mohsin,Junaid Ahmad,Muhammad Hamza Nawaz,Muhammad Ali Jamshed*

Main category: cs.DC

TL;DR: 本文探讨了生成式人工智能（GenAI）作为6G网络实现环境智能（AmI）的核心技术，通过生成合成数据、语义消息翻译、网络预测和数字孪生更新等能力，将6G从快速网络转变为智能生态系统。


<details>
  <summary>Details</summary>
Motivation: 实现全球规模的环境智能需要6G网络具备实时感知、推理和行动能力，而传统AI无法完全满足这些需求，因此需要GenAI来填补关键的技术空白。

Method: 回顾了基础GenAI模型（GANs、VAEs、扩散模型和生成式变换器），并将其与频谱共享、超可靠低延迟通信、智能安全和情境感知数字孪生等AmI用例相结合，同时探讨6G使能技术对分布式GenAI的支持。

Result: 研究表明GenAI能够有效生成合成传感器数据、翻译用户意图、预测网络条件和更新数字孪生，同时6G的边缘计算、物联网群、智能反射面和非地面网络等技术可以加速分布式GenAI的部署。

Conclusion: GenAI不是外围附加技术，而是将6G转变为环境智能生态系统的基础要素，但仍需解决能效设备训练、可信合成数据、联邦生成学习和AmI标准化等开放挑战。

Abstract: Ambient intelligence (AmI) is a computing paradigm in which physical
environments are embedded with sensing, computation, and communication so they
can perceive people and context, decide appropriate actions, and respond
autonomously. Realizing AmI at global scale requires sixth generation (6G)
wireless networks with capabilities for real time perception, reasoning, and
action aligned with human behavior and mobility patterns. We argue that
Generative Artificial Intelligence (GenAI) is the creative core of such
environments. Unlike traditional AI, GenAI learns data distributions and can
generate realistic samples, making it well suited to close key AmI gaps,
including generating synthetic sensor and channel data in under observed areas,
translating user intent into compact, semantic messages, predicting future
network conditions for proactive control, and updating digital twins without
compromising privacy.
  This chapter reviews foundational GenAI models, GANs, VAEs, diffusion models,
and generative transformers, and connects them to practical AmI use cases,
including spectrum sharing, ultra reliable low latency communication,
intelligent security, and context aware digital twins. We also examine how 6G
enablers, such as edge and fog computing, IoT device swarms, intelligent
reflecting surfaces (IRS), and non terrestrial networks, can host or accelerate
distributed GenAI. Finally, we outline open challenges in energy efficient on
device training, trustworthy synthetic data, federated generative learning, and
AmI specific standardization. We show that GenAI is not a peripheral addition,
but a foundational element for transforming 6G from a faster network into an
ambient intelligent ecosystem.

</details>


### [172] [Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference](https://arxiv.org/abs/2508.19559)
*Rongzhi Li,Ruogu Du,Zefang Chu,Sida Zhao,Chunlei Han,Zuocheng Shi,Yiwen Shao,Huanle Han,Long Huang,Zherui Liu,Shufan Liu*

Main category: cs.DC

TL;DR: HeteroScale是一个针对Prefill-Decode解耦架构的协调自动扩缩框架，通过拓扑感知调度和基于生产环境实证研究的新指标策略，解决了异构硬件利用、网络瓶颈和阶段不平衡问题，在数万GPU的生产环境中显著提升了GPU利用率和节省了大量资源。


<details>
  <summary>Details</summary>
Motivation: 传统自动扩缩器在处理大型语言模型服务时效果不佳，特别是对于现代的Prefill-Decode解耦架构。这种架构虽然强大，但带来了异构硬件利用效率低、网络瓶颈以及prefill和decode阶段严重不平衡等操作挑战。

Method: HeteroScale结合了拓扑感知调度器（适应异构硬件和网络约束）和基于大规模生产环境自动扩缩信号实证研究的新指标驱动策略。通过使用单一稳健指标来联合扩缩prefill和decode资源池，保持架构平衡的同时确保高效、自适应的资源管理。

Result: 在数万GPU的大规模生产环境中部署，HeteroScale将平均GPU利用率显著提升了26.6个百分点，每天节省数十万GPU小时，同时维持严格的服务级别目标。

Conclusion: HeteroScale有效解决了Prefill-Decode解耦架构的服务扩缩挑战，通过协调的自动扩缩框架实现了显著的资源利用效率提升和成本节约，证明了其在生产环境中的实用性和有效性。

Abstract: Serving Large Language Models (LLMs) is a GPU-intensive task where
traditional autoscalers fall short, particularly for modern Prefill-Decode
(P/D) disaggregated architectures. This architectural shift, while powerful,
introduces significant operational challenges, including inefficient use of
heterogeneous hardware, network bottlenecks, and critical imbalances between
prefill and decode stages. We introduce HeteroScale, a coordinated autoscaling
framework that addresses the core challenges of P/D disaggregated serving.
HeteroScale combines a topology-aware scheduler that adapts to heterogeneous
hardware and network constraints with a novel metric-driven policy derived from
the first large-scale empirical study of autoscaling signals in production. By
leveraging a single, robust metric to jointly scale prefill and decode pools,
HeteroScale maintains architectural balance while ensuring efficient, adaptive
resource management. Deployed in a massive production environment on tens of
thousands of GPUs, HeteroScale has proven its effectiveness, increasing average
GPU utilization by a significant 26.6 percentage points and saving hundreds of
thousands of GPU-hours daily, all while upholding stringent service level
objectives.

</details>


### [173] [Beyond the Bermuda Triangle of Contention: IOMMU Interference in Mixed Criticality Systems](https://arxiv.org/abs/2508.19670)
*Diogo Costa,Jose Martins,Sandro Pinto*

Main category: cs.DC

TL;DR: 这篇论文分析了混合关键性系统中IOMMU结构的竞争效应，发现小内存交易的翻译开销会导致进程执行时间的不可预测性，最高可延迟DMA交易1.79倍。


<details>
  <summary>Details</summary>
Motivation: 混合关键性系统集成异构计算平台后，加速器和DMA设备作为独立总线主控直接访问内存，导致安全和时序预测性挑战。IOMMU在调节内存访问时存在性能干扰问题，但其影响尚未得到充分研究。

Method: 使用Xilinx UltraScale+ ZCU104平台分析IOMMU结构内部的竞争效应，重点研究共享TLB、缓存效应和翻译开销导致的时序不可预测性问题。

Result: 实验结果显示IOMMU干扰主要影响小内存交易，翻译开销显著影响执行时间。在Arm SMMUv2实现中，小字节传输的DMA交易可被延迟达1.79倍。

Conclusion: IOMMU结构的共享特性会导致时序不可预测性，尤其是对小内存交易的影响显著。这些竞争效应在不同架构下可能呈现相似行为，需要在混合关键性系统设计中重点考虑。

Abstract: As Mixed Criticality Systems (MCSs) evolve, they increasingly integrate
heterogeneous computing platforms, combining general-purpose processors with
specialized accelerators such as AI engines, GPUs, and high-speed networking
interfaces. This heterogeneity introduces challenges, as these accelerators and
DMA-capable devices act as independent bus masters, directly accessing memory.
Consequently, ensuring both security and timing predictability in such
environments becomes critical. To address these concerns, the Input-Output
Memory Management Unit (IOMMU) plays a key role in mediating and regulating
memory access, preventing unauthorized transactions while enforcing isolation
and access control policies. While prior work has explored IOMMU-related
side-channel vulnerabilities from a security standpoint, its role in
performance interference remains largely unexplored. Moreover, many of the same
architectural properties that enable side-channel leakage, such as shared TLBs,
caching effects, and translation overheads, can also introduce timing
unpredictability. In this work, we analyze the contention effects within IOMMU
structures using the Xilinx UltraScale+ ZCU104 platform, demonstrating how
their shared nature introduce unpredictable delays. Our findings reveal that
IOMMU-induced interference primarily affects small memory transactions, where
translation overheads significantly impact execution time. Additionally, we
hypothesize that contention effects arising from IOTLBs exhibit similar
behavior across architectures due to shared caching principles, such as
prefetching and hierarchical TLB structures. Notably, our experiments show that
IOMMU interference can delay DMA transactions by up to 1.79x for lower-size
transfers on the Arm SMMUv2 implementation.

</details>


### [174] [Separation of Three or More Autonomous Mobile Models under Hierarchical Schedulers](https://arxiv.org/abs/2508.19805)
*Shota Naito,Tsukasa Ninomiya,Koichi Wada*

Main category: cs.DC

TL;DR: 这篇论文通过多个新问题和细粒度分析，探索了移动机器人系统中观测能力、内存和同步性之间的复杂交互作用，扩展了计算模型分离地图。


<details>
  <summary>Details</summary>
Motivation: 理解移动机器人系统的计算能力是分布式计算中的基础挑战。虽然之前的工作主要关注模型间的两两分离，但这篇论文要探索机器人能力、光信标可观测性和调度器同步性如何以更复杂的方式相互作用。

Method: 通过引入多个新的计算问题（ETE、HET、TAR(d)*等）来进行细粒度分析，对比不同模型下的解决能力，包括异步设置下的分类分析。

Result: 证明了ETE问题仅在最强模型（全同步机器人与全互相光标）中可解；异步环境下显示了不同模型间的细粒度分离；揭示了内部内存在对称设置中的局限性。

Conclusion: 这些结果扩展了已知的14个标准机器人模型的分离地图，揭示了只有通过高阶比较才能看到的结构现象，为移动机器人系统的计算能力提供了更深入的理解。

Abstract: Understanding the computational power of mobile robot systems is a
fundamental challenge in distributed computing. While prior work has focused on
pairwise separations between models, we explore how robot capabilities, light
observability, and scheduler synchrony interact in more complex ways.
  We first show that the Exponential Times Expansion (ETE) problem is solvable
only in the strongest model -- fully-synchronous robots with full mutual lights
($\mathcal{LUMT}^F$). We then introduce the Hexagonal Edge Traversal (HET) and
TAR(d)* problems to demonstrate how internal memory and lights interact with
synchrony: under weak synchrony, internal memory alone is insufficient, while
full synchrony can substitute for both lights and memory.
  In the asynchronous setting, we classify problems such as LP-MLCv, VEC, and
ZCC to show fine-grained separations between $\mathcal{FSTA}$ and
$\mathcal{FCOM}$ robots. We also analyze Vertex Traversal Rendezvous (VTR) and
Leave Place Convergence (LP-Cv), illustrating the limitations of internal
memory in symmetric settings.
  These results extend the known separation map of 14 canonical robot models,
revealing structural phenomena only visible through higher-order comparisons.
Our work provides new impossibility criteria and deepens the understanding of
how observability, memory, and synchrony collectively shape the computational
power of mobile robots.

</details>


### [175] [HPC Digital Twins for Evaluating Scheduling Policies, Incentive Structures and their Impact on Power and Cooling](https://arxiv.org/abs/2508.20016)
*Matthias Maiterth,Wesley H. Brewer,Jaya S. Kuruvella,Arunavo Dey,Tanzima Z. Islam,Kevin Menear,Dmitry Duplyakin,Rashadul Kabir,Tapasya Patki,Terry Jones,Feiyi Wang*

Main category: cs.DC

TL;DR: 首个将调度与数字孪生技术集成的高性能计算框架，支持在部署前进行参数配置和调度决策的影响分析


<details>
  <summary>Details</summary>
Motivation: 传统调度器评估方法局限于部署后分析或模拟器，无法模拟相关基础设施，需要能够在部署前进行what-if研究的解决方案

Method: 开发首个具有调度功能的数字孪生框架，集成多种顶级HPC系统数据集，实现外部调度模拟器集成，支持激励结构和机器学习调度的评估

Result: 创建了支持HPC系统what-if场景评估的数字孪生元框架，能够评估可持续性和对模拟系统的影响

Conclusion: 该工作为HPC系统调度提供了创新的数字孪生方法，实现了部署前的参数配置和调度决策影响分析，为原型调度提供了新途径

Abstract: Schedulers are critical for optimal resource utilization in high-performance
computing. Traditional methods to evaluate schedulers are limited to
post-deployment analysis, or simulators, which do not model associated
infrastructure. In this work, we present the first-of-its-kind integration of
scheduling and digital twins in HPC. This enables what-if studies to understand
the impact of parameter configurations and scheduling decisions on the physical
assets, even before deployment, or regarching changes not easily realizable in
production. We (1) provide the first digital twin framework extended with
scheduling capabilities, (2) integrate various top-tier HPC systems given their
publicly available datasets, (3) implement extensions to integrate external
scheduling simulators. Finally, we show how to (4) implement and evaluate
incentive structures, as-well-as (5) evaluate machine learning based
scheduling, in such novel digital-twin based meta-framework to prototype
scheduling. Our work enables what-if scenarios of HPC systems to evaluate
sustainability, and the impact on the simulated system.

</details>


### [176] [Federated Fine-Tuning of Sparsely-Activated Large Language Models on Resource-Constrained Devices](https://arxiv.org/abs/2508.19078)
*Fahao Chen,Jie Wan,Peng Li,Zhou Su,Dongxiao Yu*

Main category: cs.DC

TL;DR: FLUX是一个联邦学习系统，专门用于在资源受限设备上对MoE大语言模型进行联邦微调，通过量化分析、专家合并和动态角色分配实现4.75倍加速


<details>
  <summary>Details</summary>
Motivation: 现有方法无法有效解决MoE大语言模型在联邦学习中的计算挑战，存在不实际的系统假设和缺乏对MoE特性的考虑

Method: 提出三个关键技术：1）基于量化的本地分析估计专家激活；2）自适应层感知专家合并减少资源消耗；3）动态专家角色分配的探索-利用策略

Result: 在LLaMA-MoE和DeepSeek-MoE上的实验表明，FLUX显著优于现有方法，时间到准确率加速达到4.75倍

Conclusion: FLUX系统成功解决了资源受限环境下MoE模型的联邦微调问题，为边缘设备上的大模型训练提供了实用解决方案

Abstract: Federated fine-tuning of Mixture-of-Experts (MoE)-based large language models
(LLMs) is challenging due to their massive computational requirements and the
resource constraints of participants. Existing working attempts to fill this
gap through model quantization, computation offloading, or expert pruning.
However, they cannot achieve desired performance due to impractical system
assumptions and a lack of consideration for MoE-specific characteristics. In
this paper, we propose FLUX, a system designed to enable federated fine-tuning
of MoE-based LLMs across participants with constrained computing resources
(e.g., consumer-grade GPUs), aiming to minimize time-to-accuracy. FLUX
introduces three key innovations: (1) quantization-based local profiling to
estimate expert activation with minimal overhead, (2) adaptive layer-aware
expert merging to reduce resource consumption while preserving accuracy, and
(3) dynamic expert role assignment using an exploration-exploitation strategy
to balance tuning and non-tuning experts. Extensive experiments on LLaMA-MoE
and DeepSeek-MoE with multiple benchmark datasets demonstrate that FLUX
significantly outperforms existing methods, achieving up to 4.75X speedup in
time-to-accuracy.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [177] [Connectivity Analysis of LoRaWAN-Based Non-Terrestrial Networks for Subterranean mMTC](https://arxiv.org/abs/2508.19350)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 该研究探索了将地下传感器网络与非地面网络（无人机、高空平台、低轨卫星）集成的可行性，开发了蒙特卡洛模拟器评估连接性能，发现LoRa SF7适合短距离无人机通信，LR-FHSS适合大规模地下传感器网络场景。


<details>
  <summary>Details</summary>
Motivation: 解决恶劣环境下无线地下传感器网络通信可靠性下降的问题，利用非地面网络基础设施为大规模地下监测应用提供可靠连接。

Method: 开发蒙特卡洛模拟器，整合多层地下衰减模型、3GPP非地面网络路径损耗模型和两种LoRaWAN调制方案（LoRa和LR-FHSS）。

Result: LoRa SF7适用于农村环境的短距离无人机通信，LR-FHSS调制在高空平台和低轨卫星场景中表现优异，具有足够的链路预算和抗干扰能力。

Conclusion: 地下到非地面网络连接的成功概率受监测环境、设备数量、埋藏深度和土壤体积含水量等因素显著影响，不同调制方案适用于不同的非地面网络平台。

Abstract: Wireless underground sensor networks (WUSNs) offer significant social and
economic benefits by enabling the monitoring of subterranean entities. However,
the communication reliability of WUSNs diminishes in harsh environments where
terrestrial network infrastructure is either unavailable or unreliable. To
address this challenge, we explore the feasibility of integrating buried
massive machine-type communication (mMTC) sensors with non-terrestrial networks
(NTNs), including unmanned aerial vehicles (UAVs), high-altitude platforms
(HAPs), and low Earth orbit (LEO) satellites, to establish underground-to-NTN
connectivity for various large-scale underground monitoring applications. To
assess the effectiveness of underground-to-NTN connectivity, we develop a Monte
Carlo simulator that incorporates a multi-layer underground attenuation model,
the 3GPP empirical path loss model for various NTN platforms, and two LoRaWAN
modulation schemes, i.e., LoRa and LoRa-frequency hopping spread spectrum
(LR-FHSS). Our results evidence that LoRa SF7 is a strong candidate for
short-range UAV communication in rural environments, while LR-FHSS modulation
proves to be a promising option for HAP and LEO satellite platforms in massive
WUSNs scenarios thanks to its adequate link budget and robustness to the
interference. Finally, we demonstrate that the success probability of
underground-to-NTN connectivity using LoRa and LR-FHSS is significantly
affected by factors such as the monitoring environment, the number of devices,
burial depth, and the soil's volumetric water content.

</details>


### [178] [Experimental Insights from OpenAirInterface 5G positioning Testbeds: Challenges and solutions](https://arxiv.org/abs/2508.19736)
*Mohsen Ahadi,Adeel Malik,Omid Esrafilian,Florian Kaltenberger,Cedric Thienot*

Main category: cs.NI

TL;DR: 本文通过三个5G定位测试床实验，展示了使用开源OpenAirInterface和UL-TDoA技术实现1-2米定位精度的可行性，并提出了PSO优化方法和AI/ML数据驱动定位框架。


<details>
  <summary>Details</summary>
Motivation: 5G NR是实现智慧城市和智能工厂精确定位的关键技术，但现有系统面临同步误差、多径传播和部署几何等挑战，需要开发更鲁棒的定位解决方案。

Method: 使用三个基于开源OpenAirInterface的5G测试床，采用UL-TDoA技术和新集成的LMF功能，在室内工厂和室外场景进行实验。提出了定制化的ToA/TDoA滤波和基于粒子群优化的位置估计算法，以及利用CIR等非传统测量数据的AI/ML定位框架。

Result: 在不同测试床中实现了90%情况下1-2米的定位精度，验证了5G定位系统的可行性，并公开了收集的数据集以支持社区研究。

Conclusion: 研究证明了5G定位系统在实际部署中的可行性，提出的PSO优化和AI/ML方法为克服同步和多径挑战提供了有效解决方案，为鲁棒5G定位系统设计提供了实用见解。

Abstract: 5G New Radio (NR) is a key enabler of accurate positioning in smart cities
and smart factories. This paper presents the experimental results from three 5G
positioning testbeds running open-source OpenAirInterface (OAI) gNB and Core
Network (CN), using Uplink Time Difference of Arrival (UL-TDoA) with the newly
integrated Location Management Function (LMF). The testbeds are deployed across
both indoor factories and outdoor scenarios with O-RAN Radio Units (RUs),
following a 3GPP-compliant system model. The experiments highlight the impact
of synchronization impairments, multipath propagation, and deployment geometry
on positioning accuracy. To address these challenges, we propose tailored ToA
and TDoA filtering as well as a novel position estimation method based on
Particle Swarm Optimization (PSO) within the LMF pipeline. Moreover, we show a
beyond-5G framework that leverages non-conventional measurements such as
Channel Impulse Response (CIR) to train and test Artificial Intelligence and
Machine Learning (AI/ML) models for data-driven positioning. The results
demonstrate the feasibility of achieving 1-2 meter positioning accuracy in 90%
of cases in different testbeds, offering practical insights for the design of
robust 5G positioning systems. Moreover, we publicly release the datasets
collected in this work to support the research within the 5G positioning
community.

</details>


### [179] [Secure Multi-LLM Agentic AI and Agentification for Edge General Intelligence by Zero-Trust: A Survey](https://arxiv.org/abs/2508.19870)
*Yinqiu Liu,Ruichen Zhang,Haoxiang Luo,Yijing Lin,Geng Sun,Dusit Niyato,Hongyang Du,Zehui Xiong,Yonggang Wen,Abbas Jamalipour,Dong In Kim,Ping Zhang*

Main category: cs.NI

TL;DR: 这篇论文提出了重视集成边缘智能中多重LLM系统的零信任安全框架，分析了安全风险并提出了模型级和系统级的安全机制分类。


<details>
  <summary>Details</summary>
Motivation: 多重LLM系统在边缘智能中的协作特性引入了重大安全漏洞，包括不安全的通信、扩大的攻击面和跨域数据泄漏，传统边界安全方案无法有效应对。

Method: 通过系统分析多LLM系统在EGI环境中的安全风险，提出零信任多LLM框架的视野，并将零信任安全机制分为模型级和系统级方法。模型级包括强势识别、上下文感知访问控制等；系统级包括主动维护、区块链管理等。

Result: 该调查提供了首个应用零信任安全到多LLM系统的系统性研究，为边缘智能中的多重LLM协作提供了理论基础和实践策略，确定了关键的研究方向。

Conclusion: 零信任安全框架是应对边缘智能中多重LLM系统安全挑战的关键解决方案，通过"永不信任、始终验证"的原则，可以有效地管理协作性安全风险。

Abstract: Agentification serves as a critical enabler of Edge General Intelligence
(EGI), transforming massive edge devices into cognitive agents through
integrating Large Language Models (LLMs) and perception, reasoning, and acting
modules. These agents collaborate across heterogeneous edge infrastructures,
forming multi-LLM agentic AI systems that leverage collective intelligence and
specialized capabilities to tackle complex, multi-step tasks. However, the
collaborative nature of multi-LLM systems introduces critical security
vulnerabilities, including insecure inter-LLM communications, expanded attack
surfaces, and cross-domain data leakage that traditional perimeter-based
security cannot adequately address. To this end, this survey introduces
zero-trust security of multi-LLM in EGI, a paradigmatic shift following the
``never trust, always verify'' principle. We begin by systematically analyzing
the security risks in multi-LLM systems within EGI contexts. Subsequently, we
present the vision of a zero-trust multi-LLM framework in EGI. We then survey
key technical progress to facilitate zero-trust multi-LLM systems in EGI.
Particularly, we categorize zero-trust security mechanisms into model- and
system-level approaches. The former and latter include strong identification,
context-aware access control, etc., and proactive maintenance, blockchain-based
management, etc., respectively. Finally, we identify critical research
directions. This survey serves as the first systematic treatment of zero-trust
applied to multi-LLM systems, providing both theoretical foundations and
practical strategies.

</details>


### [180] [2SYN: Congestion-Aware Multihoming](https://arxiv.org/abs/2508.20044)
*Kfir Toledo,Isaac Keslassy*

Main category: cs.NI

TL;DR: 2SYN是首个面向任意目的地的拥塞感知多宿主算法，能动态选择最优路径，在真实环境中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 当前多宿主路由器采用简单的拥塞无感知机制，无法避免拥塞路径，需要更智能的路由选择方案

Method: 开发动态路径选择算法，可处理未知目的地，并在Linux系统中实现

Result: 在LTE和有线链路的真实实验中，2SYN能动态适应连接质量，性能优于替代方案

Conclusion: 2SYN帮助企业通过多宿主能力更好地管理网络

Abstract: When sending flows to arbitrary destinations, current multihoming routers
adopt simple congestion-oblivious mechanisms. Therefore, they cannot avoid
congested paths.
  In this paper, we introduce 2SYN, the first congestion-aware multihoming
algorithm that works for any destination. We explain how it dynamically selects
a preferred path for new connections, even given previously-unseen
destinations. We further demonstrate that it can be easily implemented in
Linux. Finally, in a real-world experiment with either LTE or a wired link, we
show how 2SYN dynamically adapts to the quality of the connection and
outperforms alternative approaches. Thus, 2SYN helps companies better manage
their networks by leveraging their multihoming capabilities.

</details>


### [181] [A First Look at Inter-Cell Interference in the Wild](https://arxiv.org/abs/2508.20060)
*Daqian Ding,Yibo Pi,Cailian Chen*

Main category: cs.NI

TL;DR: 对运营4G/5G网络的首次测量研究显示，小区间干扰普遍存在且缺乏协调管理，导致用户设备遭受不必要干扰，特别是在频率选择性信道衰落情况下信号质量显著下降。


<details>
  <summary>Details</summary>
Motivation: 尽管小区间干扰管理已研究数十年，但其在实际网络中的有效性仍未得到充分探索，需要填补这一研究空白。

Method: 通过测量研究方法，从网络部署、信道分配、时频资源分配和网络配置四个主要维度分析运营4G/5G网络的小区间干扰问题。

Result: 研究发现小区间干扰普遍存在，基站之间缺乏干扰协调，即使在频谱资源未充分利用的情况下，基站仍优先使用相同的时频资源集，导致跨小区干扰。

Conclusion: 测量结果显示通过小区间干扰管理可以显著改善信号质量，存在巨大的优化机会。

Abstract: In cellular networks, inter-cell interference management has been studied for
decades, yet its real-world effectiveness remains under-explored. To bridge
this gap, we conduct a first measurement study of inter-cell interference for
operational 4G/5G networks. Our findings reveal the prevalence of inter-cell
interference and a surprising absence of interference coordination among
operational base stations. As a result, user equipments experience unnecessary
interference, which causes significant signal quality degradation, especially
under frequency-selective channel fading. We examine the inter-cell
interference issues from four major perspectives: network deployment, channel
assignment, time-frequency resource allocation, and network configuration. In
none of these dimensions is inter-cell interference effectively managed.
Notably, even when spectrum resources are underutilized and simple strategies
could effectively mitigate inter-cell interference, base stations consistently
prioritize using the same set of time-frequency resources, causing interference
across cells. Our measurements reveal substantial opportunities for improving
signal quality by inter-cell interference management.

</details>


### [182] [ML-MaxProp: Bridging Machine Learning and Delay-Tolerant Routing for Resilient Post-Disaster Communication](https://arxiv.org/abs/2508.20077)
*Tao Xiuyuan,Milena Radenkovic*

Main category: cs.NI

TL;DR: 本文提出ML-MaxProp协议，通过机器学习增强DTN路由性能，在灾难场景中显著提升通信可靠性


<details>
  <summary>Details</summary>
Motivation: 灾难场景中传统DTN协议面临稀疏相遇、缓冲区短缺和连接不稳定的挑战，需要更智能的自适应路由方案

Method: 基于监督机器学习，结合相遇频率、跳数、缓冲区占用等上下文特征，实时预测中继节点适用性，改进MaxProp协议

Result: 在ONE仿真环境中，ML-MaxProp相比基线协议实现了更高的投递概率、更低延迟和更少开销，改进效果显著且稳健

Conclusion: ML-MaxProp是一个轻量级、自适应的实用解决方案，能够在地面基础设施崩溃时维持关键任务通信

Abstract: In disaster-stricken and large-scale urban emergency scenarios, ensuring
reliable communication remains a formidable challenge, as collapsed
infrastructure, unpredictable mobility, and severely constrained resources
disrupt conventional networks. Delay-Tolerant Networks (DTNs), though resilient
through their store-carry-forward paradigm, reveal the fundamental weaknesses
of classical protocols - Epidemic, Spray-and-Wait, and MaxProp - when
confronted with sparse encounters, buffer shortages, and volatile connectivity.
To address these obstacles, this study proposes ML-MaxProp, a hybrid routing
protocol that strengthens MaxProp with supervised machine learning. By
leveraging contextual features such as encounter frequency, hop count, buffer
occupancy, message age, and time-to-live (TTL), ML-MaxProp predicts relay
suitability in real time, transforming rigid heuristics into adaptive
intelligence. Extensive simulations in the ONE environment using the Helsinki
SPMBM mobility model show that ML-MaxProp consistently surpasses baseline
protocols, achieving higher delivery probability, lower latency, and reduced
overhead. Statistical validation further shows that these improvements are both
significant and robust, even under highly resource-constrained and unstable
conditions. Overall, this work shows that ML-MaxProp is not just an incremental
refinement but a lightweight, adaptive, and practical solution to one of the
hardest challenges in DTNs: sustaining mission-critical communication when
infrastructure collapses and every forwarding decision becomes critical.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [183] [Stack Trace-Based Crash Deduplication with Transformer Adaptation](https://arxiv.org/abs/2508.19449)
*Md Afif Al Mamun,Gias Uddin,Lan Xia,Longyu Zhang*

Main category: cs.SE

TL;DR: dedupT是一个基于Transformer的崩溃报告去重方法，通过整体建模堆栈轨迹而非孤立帧，显著优于现有深度学习和传统方法


<details>
  <summary>Details</summary>
Motivation: 自动化崩溃报告系统产生大量重复报告，传统基于字符串相似度或深度学习的堆栈轨迹去重方法无法有效捕捉上下文和结构关系

Method: 使用预训练语言模型适配堆栈轨迹，然后利用其嵌入训练全连接网络来进行重复崩溃排名

Result: 在四个公开数据集上，dedupT相比最佳深度学习基线平均倒数排名提升超过15%，相比传统方法提升达9%，在检测唯一崩溃报告方面获得更高的ROC-AUC

Conclusion: 该工作推动了现代自然语言处理技术在软件工程中的集成，为基于堆栈轨迹的崩溃去重提供了有效解决方案

Abstract: Automated crash reporting systems generate large volumes of duplicate
reports, overwhelming issue-tracking systems and increasing developer workload.
Traditional stack trace-based deduplication methods, relying on string
similarity, rule-based heuristics, or deep learning (DL) models, often fail to
capture the contextual and structural relationships within stack traces. We
propose dedupT, a transformer-based approach that models stack traces
holistically rather than as isolated frames. dedupT first adapts a pretrained
language model (PLM) to stack traces, then uses its embeddings to train a
fully-connected network (FCN) to rank duplicate crashes effectively. Extensive
experiments on real-world datasets show that dedupT outperforms existing DL and
traditional methods (e.g., sequence alignment and information retrieval
techniques) in both duplicate ranking and unique crash detection, significantly
reducing manual triage effort. On four public datasets, dedupT improves Mean
Reciprocal Rank (MRR) often by over 15% compared to the best DL baseline and up
to 9% over traditional methods while achieving higher Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) in detecting unique crash
reports. Our work advances the integration of modern natural language
processing (NLP) techniques into software engineering, providing an effective
solution for stack trace-based crash deduplication.

</details>


### [184] [Functional Consistency of LLM Code Embeddings: A Self-Evolving Data Synthesis Framework for Benchmarking](https://arxiv.org/abs/2508.19558)
*Zhuohao Li,Wenqing Chen,Jianxing Yu,Zhichao Lu*

Main category: cs.SE

TL;DR: 这篇论文研究了LLM代码嵌入的功能一致性，提出了一种功能导向的代码自成长框架来构建更丰富的测试数据集，并证明通过该框架训练的嵌入模型在多个下游任务上都显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于代码克隆检测，强调语法相似性而忽视了功能理解。文本嵌入模型虽然在文本任务上表现优异，但其对代码功能语义的反映能力仍不明确。

Method: 提出了一种新的数据合成框架Functionality-Oriented Code Self-Evolution，通过定义4个语义和语法类别，从单个代码实例生成四种独特变体，构建更多样化和挑战性的测试数据集。

Result: 在代码克隆检测、代码功能一致性识别和代码检索三个下游任务上进行了大量实验，结果显示使用该框架训练的嵌入模型性能显著提升。

Conclusion: 该研究提出的数据合成框架有效提升了嵌入模型对代码功能语义的理解能力，具有良好的通用性和推广性，推动了代码功能理解领域的发展。

Abstract: Embedding models have demonstrated strong performance in tasks like
clustering, retrieval, and feature extraction while offering computational
advantages over generative models and cross-encoders. Benchmarks such as MTEB
have shown that text embeddings from large language models (LLMs) capture rich
semantic information, but their ability to reflect code-level functional
semantics remains unclear. Existing studies largely focus on code clone
detection, which emphasizes syntactic similarity and overlooks functional
understanding. In this paper, we focus on the functional consistency of LLM
code embeddings, which determines if two code snippets perform the same
function regardless of syntactic differences. We propose a novel data synthesis
framework called Functionality-Oriented Code Self-Evolution to construct
diverse and challenging benchmarks. Specifically, we define code examples
across four semantic and syntactic categories and find that existing datasets
predominantly capture syntactic properties. Our framework generates four unique
variations from a single code instance, providing a broader spectrum of code
examples that better reflect functional differences. Extensive experiments on
three downstream tasks-code clone detection, code functional consistency
identification, and code retrieval-demonstrate that embedding models
significantly improve their performance when trained on our evolved datasets.
These results highlight the effectiveness and generalization of our data
synthesis framework, advancing the functional understanding of code.

</details>


### [185] [The Influence of Code Comments on the Perceived Helpfulness of Stack Overflow Posts](https://arxiv.org/abs/2508.19610)
*Kathrin Figl,Maria Kirchner,Sebastian Baltes,Michael Felderer*

Main category: cs.SE

TL;DR: 代码注释显著提升Stack Overflow答案的感知帮助性，块注释比行内注释更受新手青睐，而表面特征如答案位置和得分影响较小


<details>
  <summary>Details</summary>
Motivation: 理解代码注释如何影响Stack Overflow答案的感知帮助性，因为重用理解不足的代码可能导致严重问题

Method: 在线实验模拟Stack Overflow环境（n=91），比较有注释和无注释代码的感知帮助性

Result: 块注释和行内注释都被认为比无注释代码显著更有帮助；新手更偏好块注释；答案位置和得分等表面特征重要性较低

Conclusion: 研究结果有助于改进社区驱动平台的实用性，并为AI代码生成工具提供针对性提示策略，以生成更易读的代码片段

Abstract: Question-and-answer platforms such as Stack Overflow have become an important
way for software developers to share and retrieve knowledge. However, reusing
poorly understood code can lead to serious problems, such as bugs or security
vulnerabilities. To better understand how code comments affect the perceived
helpfulness of Stack Overflow answers, we conducted an online experiment
simulating a Stack Overflow environment (n=91). The results indicate that both
block and inline comments are perceived as significantly more helpful than
uncommented source code. Moreover, novices rated code snippets with block
comments as more helpful than those with inline comments. Interestingly, other
surface features, such as the position of an answer and its answer score, were
considered less important. The content of Stack Overflow has been a major
source for training large language models. AI-based coding assistants such as
GitHub Copilot, which are based on these models, might change the way Stack
Overflow is used. However, our findings have implications beyond this specific
platform. First, they may help to improve the relevance of community-driven
platforms such as Stack Overflow, which provide human advice and explanations
of code solutions, complementing AI-based support for software developers.
Second, since chat-based AI tools can be prompted to generate code in different
ways, knowing which properties influence perceived helpfulness might lead to
targeted prompting strategies to generate more readable code snippets.

</details>


### [186] [Leveraging LLMs for Automated Translation of Legacy Code: A Case Study on PL/SQL to Java Transformation](https://arxiv.org/abs/2508.19663)
*Lola Solovyeva,Eduardo Carneiro Oliveira,Shiyu Fan,Alper Tuncay,Shamil Gareev,Andrea Capiluppi*

Main category: cs.SE

TL;DR: 本研究探讨了使用大语言模型将PL/SQL代码翻译为Java的可行性，通过定制提示策略在有限数据集上实现了语法准确和功能正确的代码转换。


<details>
  <summary>Details</summary>
Motivation: VT遗留系统包含250万行PL/SQL代码，缺乏一致的文档和自动化测试，给重构和现代化带来了重大挑战。

Method: 利用包含10个PL/SQL-Java代码对和15个Java类的数据集，评估多个LLM，并提出结合链式引导推理和n-shot提示的定制提示策略。

Result: 该方法能有效指导LLM生成语法准确的翻译代码并实现功能正确性，但受限于小样本量和有限的测试用例访问。

Conclusion: 这些发现为大规模遗留系统现代化的可扩展自动化解决方案奠定了基础。

Abstract: The VT legacy system, comprising approximately 2.5 million lines of PL/SQL
code, lacks consistent documentation and automated tests, posing significant
challenges for refactoring and modernisation. This study investigates the
feasibility of leveraging large language models (LLMs) to assist in translating
PL/SQL code into Java for the modernised "VTF3" system. By leveraging a dataset
comprising 10 PL/SQL-to-Java code pairs and 15 Java classes, which collectively
established a domain model for the translated files, multiple LLMs were
evaluated. Furthermore, we propose a customized prompting strategy that
integrates chain-of-guidance reasoning with $n$-shot prompting. Our findings
indicate that this methodology effectively guides LLMs in generating
syntactically accurate translations while also achieving functional
correctness. However, the findings are limited by the small sample size of
available code files and the restricted access to test cases used for
validating the correctness of the generated code. Nevertheless, these findings
lay the groundwork for scalable, automated solutions in modernising large
legacy systems.

</details>


### [187] [Enabling Content Management Systems as an Information Source in Model-driven Projects](https://arxiv.org/abs/2508.19797)
*Joan Giner-Miguelez,Abel Gómez,Jordi Cabot*

Main category: cs.SE

TL;DR: 提出一个模型基于框架来发现和表示无头CMS的信息模型，生成中间件库以支持软件开发过程中的CMS集成


<details>
  <summary>Details</summary>
Motivation: 无头CMS已成为重要的信息系统组件，但缺乏自动化工具来发现和管理其高度定制的信息模型，目前主要靠手工处理效率低且易出错

Method: 开发能够发现和显式表示CMS信息模型的框架，设计CMS模型与其他组件的交互方式，生成平台无关的中间件库提供对CMS的访问

Result: 完整框架已开源并在线可用，能够支持软件开发过程中的CMS集成

Conclusion: 该框架有效解决了无头CMS集成中的信息模型发现和管理问题，提高了开发效率和质量

Abstract: Content Management Systems (CMSs) are the most popular tool when it comes to
create and publish content across the web. Recently, CMSs have evolved,
becoming \emph{headless}. Content served by a \emph{headless CMS} aims to be
consumed by other applications and services through REST APIs rather than by
human users through a web browser. This evolution has enabled CMSs to become a
notorious source of content to be used in a variety of contexts beyond pure web
navigation. As such, CMS have become an important component of many information
systems. Unfortunately, we still lack the tools to properly discover and manage
the information stored in a CMS, often highly customized to the needs of a
specific domain. Currently, this is mostly a time-consuming and error-prone
manual process.
  In this paper, we propose a model-based framework to facilitate the
integration of headless CMSs in software development processes. Our framework
is able to discover and explicitly represent the information schema behind the
CMS. This facilitates designing the interaction between the CMS model and other
components consuming that information. These interactions are then generated as
part of a middleware library that offers platform-agnostic access to the CMS to
all the client applications. The complete framework is open-source and
available online.

</details>


### [188] [Towards a fundamental theory of modeling discrete systems](https://arxiv.org/abs/2508.19803)
*Peter Fettke,Wolfgang Reisig*

Main category: cs.SE

TL;DR: 本文提出了Heraklit建模框架作为数字时代建模的新方法，旨在解决传统建模理论面临的挑战


<details>
  <summary>Details</summary>
Motivation: 数字时代对建模提出了新的挑战，需要新的基础理论来应对这些挑战，因为建模在科学和工程中具有核心重要性

Method: 引入Heraklit建模框架作为新的建模方法，但具体技术细节在摘要中未详细说明

Result: 提出了Heraklit建模框架，但具体实验结果或性能指标在摘要中未提及

Conclusion: 建模是数字时代的基础性问题，需要新的理论框架，未来工作将关注建模的正确性、信息概念和不变性描述

Abstract: Modeling is a central concern in both science and engineering. However, we
need a new fundamental theory to address the challenges of the digital age. In
this paper, we first explain why modeling is fundamental and which challenges
must be addressed in the digital world. As a main contribution, we introduce
the Heraklit modeling framework as a new approach to modeling. We conclude with
some general remarks. Future work will involve the correctness of modeling, the
notion of information, and the description of invariance in modeling.

</details>


### [189] [On the Future of Software Reuse in the Era of AI Native Software Engineering](https://arxiv.org/abs/2508.19834)
*Antero Taivalsaari,Tommi Mikkonen,Cesare Pautasso*

Main category: cs.SE

TL;DR: 论文探讨AI辅助生成式软件重用的影响，指出其类似于货物崇拜开发，并提出研究议程来解决相关问题


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和生成式软件重用成为软件开发的核心，传统的有机开发方法正在被"AI原生"方法取代，这引发了新的软件重用形式，需要研究其影响和问题

Method: 通过讨论AI辅助生成式软件重用的含义，提出相关问题，并定义研究议程来应对这种新兴方法的核心问题

Result: 识别了AI辅助生成式软件重用带来的新挑战和问题，强调了其与货物崇拜开发的相似性

Conclusion: 需要制定系统的研究议程来解决AI辅助生成式软件重用带来的核心问题，以确保这种新兴开发方法的可持续性和可靠性

Abstract: Software development is currently under a paradigm shift in which artificial
intelligence and generative software reuse are taking the center stage in
software creation. Earlier opportunistic software reuse practices and organic
software development methods are rapidly being replaced by "AI Native"
approaches in which developers place their trust on code that has been
generated by artificial intelligence. This is leading to a new form of software
reuse that is conceptually not all that different from cargo cult development.
In this paper we discuss the implications of AI-assisted generative software
reuse, bring forth relevant questions, and define a research agenda for
tackling the central issues associated with this emerging approach.

</details>


### [190] [Generative AI for Testing of Autonomous Driving Systems: A Survey](https://arxiv.org/abs/2508.19882)
*Qunying Song,He Ye,Mark Harman,Federica Sarro*

Main category: cs.SE

TL;DR: 本文系统综述了生成式AI在自动驾驶系统测试中的应用，分析了91项相关研究，总结了6个主要应用类别、评估工具和现有局限性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需要在大规模部署前进行广泛测试以确保安全性和功能性，但实现高效测试仍面临挑战。生成式AI因其强大的情境理解、复杂任务推理和多样化输出能力，在ADS测试中展现出巨大潜力。

Method: 通过系统分析91项相关研究，将生成式AI在ADS测试中的应用归纳为6个主要类别，主要围绕基于场景的测试。同时综述了评估使用的数据集、模拟器、ADS系统、指标和基准。

Result: 识别了生成式AI在ADS测试中的27个局限性，总结了现有方法的有效性，并整理了广泛使用的评估工具和基准。

Conclusion: 本综述提供了生成式AI在ADS测试中应用的全面概览和实践见解，突出了现有挑战，并为这个快速发展的领域指明了未来研究方向。

Abstract: Autonomous driving systems (ADS) have been an active area of research, with
the potential to deliver significant benefits to society. However, before
large-scale deployment on public roads, extensive testing is necessary to
validate their functionality and safety under diverse driving conditions.
Therefore, different testing approaches are required, and achieving effective
and efficient testing of ADS remains an open challenge. Recently, generative AI
has emerged as a powerful tool across many domains, and it is increasingly
being applied to ADS testing due to its ability to interpret context, reason
about complex tasks, and generate diverse outputs. To gain a deeper
understanding of its role in ADS testing, we systematically analyzed 91
relevant studies and synthesized their findings into six major application
categories, primarily centered on scenario-based testing of ADS. We also
reviewed their effectiveness and compiled a wide range of datasets, simulators,
ADS, metrics, and benchmarks used for evaluation, while identifying 27
limitations. This survey provides an overview and practical insights into the
use of generative AI for testing ADS, highlights existing challenges, and
outlines directions for future research in this rapidly evolving field.

</details>


### [191] [Smart Contract Intent Detection with Pre-trained Programming Language Model](https://arxiv.org/abs/2508.20086)
*Youwei Huang,Jianwen Li,Sen Fang,Yao Li,Peng Yang,Bin Hu,Tao Zhang*

Main category: cs.SE

TL;DR: SmartIntentNN2是基于深度学习的智能合约恶意意图检测模型，通过整合BERT预训练语言模型和BiLSTM网络，在10种意图分类上达到0.927的F1分数，性能优于前代模型。


<details>
  <summary>Details</summary>
Motivation: 智能合约开发中的恶意意图可能导致重大经济损失，需要有效的检测方法来识别不安全意图。

Method: 结合基于BERT的预训练语言模型（在16,000个真实智能合约上使用掩码语言建模目标训练）和双向LSTM网络进行多标签分类，保留K-means聚类的意图突出机制。

Result: 在10种不同意图类别分类中达到0.927的F1分数，相比前代模型的0.8633有显著提升。

Conclusion: SmartIntentNN2成为智能合约意图检测的最先进模型，展示了深度学习方法在智能合约安全分析中的有效性。

Abstract: Malicious intent in smart contract development can lead to substantial
economic losses. SmartIntentNN is a deep learning model specifically designed
to identify unsafe intents in smart contracts. This model integrates the
Universal Sentence Encoder, a K-means clustering-based intent highlighting
mechanism, and a Bidirectional Long Short-Term Memory network for multi-label
classification, achieving an F1 of 0.8633 in distinguishing ten different
intent categories. In this study, we present an upgraded version of this model,
SmartIntentNN2 (Smart Contract Intent Neural Network V2). A significant
enhancement in V2 is the incorporation of a BERT-based pre-trained language
model, which has been trained on a dataset of 16,000 real smart contracts using
a Masked Language Modeling objective. SmartIntentNN2 retains the BiLSTM-based
multi-label classification network. With an improved F1 of 0.927, V2
demonstrates enhanced performance compared to its predecessor, establishing
itself as the state-of-the-art model for smart contract intent detection.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [192] [Inference on Partially Identified Parameters with Separable Nuisance Parameters: a Two-Stage Method](https://arxiv.org/abs/2508.19853)
*Xunkang Tian*

Main category: econ.EM

TL;DR: 提出一个两阶段方法用于处理带有可分离干扰参数的部分识别矩不等式模型，通过方差校正的卡方检验构建置信集，并应用于美国汽车市场进入退出成本的结构估计


<details>
  <summary>Details</summary>
Motivation: 解决在矩不等式模型中直接消除干扰参数困难或导致保守性的问题，需要一种能够处理干扰参数估计误差的有效推断方法

Method: 两阶段方法：第一阶段单独估计干扰参数，第二阶段使用经过方差校正的精炼卡方检验构建感兴趣参数的识别集

Result: 在温和条件下建立了方法的渐近有效性，并描述了有限样本性质，方法在结构估计应用中表现出良好性能

Conclusion: 该方法为处理带有可分离干扰参数的部分识别模型提供了有效的推断工具，具有广泛的适用性和良好的实践表现

Abstract: This paper develops a two-stage method for inference on partially identified
parameters in moment inequality models with separable nuisance parameters. In
the first stage, the nuisance parameters are estimated separately, and in the
second stage, the identified set for the parameters of interest is constructed
using a refined chi-squared test with variance correction that accounts for the
first-stage estimation error. We establish the asymptotic validity of the
proposed method under mild conditions and characterize its finite-sample
properties. The method is broadly applicable to models where direct elimination
of nuisance parameters is difficult or introduces conservativeness. Its
practical performance is illustrated through an application: structural
estimation of entry and exit costs in the U.S. vehicle market based on Wollmann
(2018).

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [193] [Training for Obsolescence? The AI-Driven Education Trap](https://arxiv.org/abs/2508.19625)
*Andrew J. Peterson*

Main category: econ.GN

TL;DR: 人工智能在教育中的应用存在信息失故，教育规划者只考虑AI的教学效率改善，而忽视了它对就业市场薪资的压制效应，导致技能不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 人工智能同时影响教育个人资本生产和劳动力市场需求，单独分析这些效应可能导致教育资源的严重误配。

Method: 建立了一个教育规划者模型，其AI采用决策仅基于教学生产力考虑，而未内部化AI对未来技能薪资的压制效应。基于预调查，假设这两种效应存在正相关性。

Result: 信息失故导致技能不匹配问题，这种不匹配随着AI普及度增加而单调增长。忽视非计价非认知技能和学校对AI的内生过度投资会进一步加剧这种不匹配。

Conclusion: 如果不与期望市场信号相结合，促进教育AI化的政策可能反而会破坏学生的长期人力资本。尤其是当AI依赖排斥了通过知识挑战培养的持久性等非认知技能时，问题更为严重。

Abstract: Artificial intelligence simultaneously transforms human capital production in
schools and its demand in labor markets. Analyzing these effects in isolation
can lead to a significant misallocation of educational resources. We model an
educational planner whose decision to adopt AI is driven by its teaching
productivity, failing to internalize AI's future wage-suppressing effect on
those same skills. Our core assumption, motivated by a pilot survey, is that
there is a positive correlation between these two effects. This drives our
central proposition: this information failure creates a skill mismatch that
monotonically increases with AI prevalence. Extensions show the mismatch is
exacerbated by the neglect of unpriced non-cognitive skills and by a school's
endogenous over-investment in AI. Our findings caution that policies promoting
AI in education, if not paired with forward-looking labor market signals, may
paradoxically undermine students' long-term human capital, especially if
reliance on AI crowds out the development of unpriced non-cognitive skills,
such as persistence, that are forged through intellectual struggle.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [194] [Delegated Contracting](https://arxiv.org/abs/2508.19326)
*João Thereze,Udayan Vaidya*

Main category: econ.TH

TL;DR: 论文研究了委托人通过知情代表进行合同设计的委托机制问题，证明了委托人可以通过约束代表提供的合同菜单来实现任何直接机制可实现的成果，并应用于政府采购、销售委托和合伙解散等多个场景。


<details>
  <summary>Details</summary>
Motivation: 研究委托人无法直接与代理人互动，必须通过知情代表进行合同设计的情况，探讨在这种委托机制下如何实现最优结果。

Method: 通过理论分析证明委托人可以通过约束代表提供的合同菜单来实现任何满足占优策略激励相容和事后参与约束的直接机制可实现的成果，并将该结果应用于多个具体场景进行验证。

Result: 证明了委托机制可以实现与直接机制相同的效果；在政府采购中应委托筛选合同区间；销售委托中通过退货政策可实现无收入损失；合伙解散需要中介才能实现效率。

Conclusion: 委托合同设计在某些情况下会阻碍效率，但通过选择合适的代表和设计适当的约束机制，可以恢复效率实现最优结果。

Abstract: A principal seeks to contract with an agent but must do so through an
informed delegate. Although the principal cannot directly mediate the
interaction, she can constrain the menus of contracts the delegate may offer.
We show that the principal can implement any outcome that is implementable
through a direct mechanism satisfying dominant strategy incentive compatibility
and ex-post participation for the agent. We apply this result to several
settings. First, we show that a government that delegates procurement to a
budget-indulgent agency should delegate an interval of screening contracts.
Second, we show that a seller can delegate sales to an intermediary without
revenue loss, provided she can commit to a return policy. Third, in contrast to
centralized mechanism design, we demonstrate that no partnership can be
efficiently dissolved in the absence of a mediator. Finally, we discuss when
delegated contracting obstructs efficiency, and when choosing the right
delegate may help restore it.

</details>


### [195] [Preference for Verifiability](https://arxiv.org/abs/2508.19585)
*Hendrik Rommeswinkel*

Main category: econ.TH

TL;DR: 该论文提出了一个决策模型，决策者在无法观察行动后果时，会关注后果是否能够被事后验证。模型通过偏好公理化表征，决策者选择能够最大化可验证事件中最坏后果期望效用的行动。


<details>
  <summary>Details</summary>
Motivation: 研究决策者在无法直接观察行动后果的情况下，除了期望效用外，还会考虑后果是否能够被事后验证的动机。

Method: 通过公理化方法表征决策模型，基于决策者对行动的偏好来唯一确定其期望能够验证的事件集合。

Result: 提出了一个决策框架，决策者选择能够最大化可验证事件中最坏后果期望效用的行动，解释了为什么决策者可能选择效率较低但可验证性更好的选项。

Conclusion: 该模型为理解决策者在不确定性下考虑可验证性的行为提供了理论框架，特别是在需要向利益相关者证明成果的场景中具有重要意义。

Abstract: Decision makers may face situations in which they cannot observe the
consequences that result from their actions. In such decisions, motivations
other than the expected utility of consequences may play a role. The present
paper axiomatically characterizes a decision model in which the decision maker
cares about whether it can be ex post verified that a good consequence has been
achieved. Preferences over acts uniquely characterize a set of events that the
decision maker expects to be able to verify in case they occur. The decision
maker chooses the act that maximizes the expected utility across verifiable
events of the worst possible consequence that may have occurred.
  For example, a firm choosing between different carbon emission reduction
technologies may find some technologies to leave ex post more uncertainty about
the level of emission reduction than other technologies. The firm may care
about proving to its stakeholders that a certain amount of carbon reduction has
been achieved and may employ privately obtained evidence to do so. It may
choose in expectation less efficient technologies if the achieved carbon
reduction is better verifiable using the expected future evidence.

</details>


### [196] [Dynamic Delegation with Reputation Feedback](https://arxiv.org/abs/2508.19676)
*Georgy Lukyanov,Anna Vlasova*

Main category: econ.TH

TL;DR: 这篇论文研究了动态委托中的声誉反馈机制，专家根据声誉调整建议截断点，计算出递归均衡解，并推导出可测预测和应用于医疗决策的结果。


<details>
  <summary>Details</summary>
Motivation: 研究长期专家在声誉反馈下向一系列执行者提供建议的动态委托问题，执行者的努力水平受当前声誉影响，从而改变结果的信息内容和信念更新。

Method: 通过求解一个递归的、基于信念的均衡来分析动态委托模型，并提出了一个识别条件（失败至少和成功一样信息富有）来推导声誉保守主义。

Result: 建议是专家信号的声誉依赖截断点；识别条件导致声誉保守主义（截断点随声誉增加而提高）。声誉在能干类型下是次马汀兼，在不能干类型下是超马汀兼。成功依赖奖金可以实现任何目标实验率。

Conclusion: 该框架提供了可测试的预测和一个用于手术决策（手术vs保守治疗）的测量地图，为动态委托问题提供了理论基础和实践应用。

Abstract: We study dynamic delegation with reputation feedback: a long-lived expert
advises a sequence of implementers whose effort responds to current reputation,
altering outcome informativeness and belief updates. We solve for a recursive,
belief-based equilibrium and show that advice is a reputation-dependent cutoff
in the expert's signal. A diagnosticity condition - failures at least as
informative as successes - implies reputational conservatism: the cutoff
(weakly) rises with reputation. Comparative statics are transparent: greater
private precision or a higher good-state prior lowers the cutoff, whereas
patience (value curvature) raises it. Reputation is a submartingale under
competent types and a supermartingale under less competent types; we separate
boundary hitting into learning (news generated infinitely often) versus no-news
absorption. A success-contingent bonus implements any target experimentation
rate with a plug-in calibration in a Gaussian benchmark. The framework yields
testable predictions and a measurement map for surgery (operate vs.
conservative care).

</details>


### [197] [Public Persuasion with Endogenous Fact-Checking](https://arxiv.org/abs/2508.19682)
*Georgy Lukyanov,Samuel Safaryan*

Main category: econ.TH

TL;DR: 研究公共说服中发送者面对具有异质验证成本的大众受众时的最优信息策略，发现验证成本降低时发送者反而会提供更少信息（混淆策略），并扩展到伪造和暴力等事后工具的分析


<details>
  <summary>Details</summary>
Motivation: 研究在受众可以以不同成本验证信息真实性的情况下，发送者如何设计公共信息策略，特别是在事实核查技术不断改进的背景下

Method: 建立理论模型，发送者事前承诺公共信息策略但需满足事后真实性约束，接收者选择性验证，分析验证成本分布变化对最优信息策略的影响

Result: 主要发现反向比较静态：当验证变得更便宜时，最优公共信号严格变得信息量更少（Blackwell序），极端主张会引发更多审查，发送者最优选择信息粗化

Conclusion: 验证能力的提升反而导致发送者采用混淆策略，框架可扩展到伪造和暴力等事后工具，为改善事实核查环境下的宣传策略提供理论解释

Abstract: We study public persuasion when a sender faces a mass audience that can
verify the state at heterogeneous costs. The sender commits ex ante to a public
information policy but must satisfy an ex post truthfulness constraint on
verifiable content (EPIC). Receivers verify selectively, generating a verifying
mass that depends on the public posterior mu. This yields an indirect value
v(mu;F) and a concavification problem under implementability. Our main result
is a reverse comparative static: when verification becomes cheaper (an FOSD
improvement in F), v becomes more concave and the optimal public signal is
strictly less informative (Blackwell). Intuitively, greater verifiability makes
extreme claims invite scrutiny, so the sender optimally coarsens information -
"confusion as strategy." We extend the model to two ex post instruments:
falsification (continuous manipulation) and violence (a fixed-cost discrete
tool), and characterize threshold substitutions from persuasion to manipulation
and repression. The framework speaks to propaganda under improving
fact-checking.

</details>


### [198] [Risky Advice and Reputational Bias](https://arxiv.org/abs/2508.19707)
*Georgy Lukyanov,Anna Vlasova,Maria Ziskelevich*

Main category: econ.TH

TL;DR: 该研究分析了声誉激励下的专家建议行为，特别关注卖方股票研究。分析师根据私有信号给出建议，声誉影响客户实施努力程度。研究发现高声誉分析师更保守，但条件命中率更高。


<details>
  <summary>Details</summary>
Motivation: 研究声誉激励如何影响专家建议行为，特别是在金融分析领域，理解分析师在声誉压力下的决策模式和市场影响。

Method: 建立递归信念均衡模型，分析师接收连续私有信号，推荐风险或安全行动，建议和结果公开，客户实施努力取决于当前声誉。

Result: 发现建议遵循信号截断规则；在诊断不对称性下，截断值随声誉增加（声誉保守主义）；信号精度越高或成功先验越高，截断值越低；职业关注越强，截断值越高。

Conclusion: 模型预测高声誉分析师做出更少风险建议但获得更高条件命中率，阐明了委员会阈值和监控机制如何影响行为，成功相关奖金可通过闭式映射实现目标实验率。

Abstract: We study expert advice under reputational incentives, with sell-side equity
research as the lead application. A long-lived analyst receives a continuous
private signal about a binary payoff and recommends a risky (Buy) or safe
action. Recommendations and outcomes are public, and clients' implementation
effort depends on current reputation. In a recursive, belief-based equilibrium:
(i) advice follows a cutoff in the signal; (ii) under a simple diagnosticity
asymmetry, the cutoff is (weakly) increasing in reputation (reputational
conservatism); and (iii) comparative statics are transparent - higher signal
precision or a higher success prior lowers the cutoff, whereas stronger career
concerns raise it. A success-contingent bonus implements any target
experimentation rate via a closed-form mapping. The model predicts that
high-reputation analysts make fewer risky calls yet attain higher conditional
hit rates, and it clarifies how committee thresholds and monitoring regimes
shift behavior.

</details>


### [199] [Contesting fake news](https://arxiv.org/abs/2508.19837)
*Daniel Rehsmann,Béatrice Roussillon,Paul Schweinzer*

Main category: econ.TH

TL;DR: 本文通过排序锦标赛模型分析信用品市场中不完美标签下的企业竞争行为，企业通过策略性信息发布来操纵标签的总体精确度


<details>
  <summary>Details</summary>
Motivation: 研究信用品市场中企业如何通过策略性信息发布来操纵产品质量标签的精确度，这种标签作为公共品指导消费者决策但可能被企业战略利用

Method: 采用排序锦标赛模型，分析不对称企业在信用品市场中的竞争行为，企业通过联合且竞争性地控制标签的总体精确度来影响产品质量排名

Result: 企业有动机策略性地放大或抵消竞争对手的信息发布，从而操纵产品标签的总体精确度和排名区分能力

Conclusion: 该理论框架适用于多个采用标签或排名的信用品行业，包括学术部门、绿色认证、电影和投资机会等领域

Abstract: We model competition on a credence goods market governed by an imperfect
label, signaling high quality, as a rank-order tournament between firms. In
this market interaction, asymmetric firms jointly and competitively control the
aggregate precision of a label ranking the competitors' qualities by releasing
individual information. While the labels and the aggregated information they
are based on can be seen as a public good guiding the consumers' purchasing
decisions, individual firms have incentives to strategically amplify or
counteract the competitors' information emission, thereby manipulating the
aggregate precision of product labeling, i.e., the underlying ranking's
discriminatory power. Elements of the introduced theory are applicable to
several (credence-good) industries that employ labels or rankings, including
academic departments, ``green'' certification, movies, and investment
opportunities.

</details>


### [200] [Misperception and informativeness in statistical discrimination](https://arxiv.org/abs/2508.20053)
*Matteo Escudé,Paula Onuchic,Ludvig Sinander,Quitzé Valenzuela-Stookey*

Main category: econ.TH

TL;DR: 研究信息与先验（错误）认知在劳动力市场统计歧视模型中的相互作用，分析信息增加对平均工资的影响，并识别改善信息缩小工资差距的条件


<details>
  <summary>Details</summary>
Motivation: 探讨统计歧视模型中信息质量和先验认知如何影响劳动力市场的工资决定和群体间工资差距

Method: 使用Phelps-Aigner-Cain类型的统计歧视模型，将信息增加对平均工资的影响分解为工具性成分和认知修正成分

Result: 发现认知修正项在群体被低估时为非负，被高估时为非正；识别了改善信息能够缩小工资差距的具体条件

Conclusion: 信息质量的提升可以通过更好的工人-任务匹配和修正先验错误认知来影响工资水平，在特定条件下能够有效减少群体间的工资差距

Abstract: We study the interplay of information and prior (mis)perceptions in a
Phelps-Aigner-Cain-type model of statistical discrimination in the labor
market. We decompose the effect on average pay of an increase in how
informative observables are about workers' skill into a non-negative
instrumental component, reflecting increased surplus due to better matching of
workers with tasks, and a perception-correcting component capturing how extra
information diminishes the importance of prior misperceptions about the
distribution of skills in the worker population. We sign the
perception-correcting term: it is non-negative (non-positive) if the population
was ex-ante under-perceived (over-perceived). We then consider the implications
for pay gaps between equally-skilled populations that differ in information,
perceptions, or both, and identify conditions under which improving information
narrows pay gaps.

</details>
