<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 13]
- [cs.CL](#cs.CL) [Total: 49]
- [cs.CV](#cs.CV) [Total: 86]
- [cs.DB](#cs.DB) [Total: 1]
- [cs.DC](#cs.DC) [Total: 12]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 11]
- [econ.EM](#econ.EM) [Total: 4]
- [econ.GN](#econ.GN) [Total: 4]
- [eess.IV](#eess.IV) [Total: 3]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [A Study on the Application of Artificial Intelligence in Ecological Design](https://arxiv.org/abs/2507.11595)
*Hengyue Zhao*

Main category: cs.AI

TL;DR: 探讨AI能否推动人与自然从支配关系转向共生关系，并通过案例研究展示AI在生态设计中的创新应用。


<details>
  <summary>Details</summary>
Motivation: 研究AI如何通过数据分析和生态修复技术，改变传统的生态设计理论与方法，促进人与自然的和谐共生。

Method: 通过案例研究分析艺术家和设计师如何利用AI进行数据分析和图像识别，并结合强化学习与植物修复技术进行生态设计。

Result: 研究发现AI不仅能扩展创意方法，还能重新定义生态设计的理论与实践，为可持续技术生态系统提供研究路径。

Conclusion: AI在连接科学洞察、艺术实践和环境管理方面具有潜力，为未来可持续生态系统的研究提供了方向。

Abstract: This paper asks whether our relationship with nature can move from human
dominance to genuine interdependence, and whether artificial intelligence (AI)
can mediate that shift. We examine a new ecological-design paradigm in which AI
interacts with non-human life forms. Through case studies we show how artists
and designers apply AI for data analysis, image recognition, and ecological
restoration, producing results that differ from conventional media. We argue
that AI not only expands creative methods but also reframes the theory and
practice of ecological design. Building on the author's prototype for
AI-assisted water remediation, the study proposes design pathways that couple
reinforcement learning with plant-based phytoremediation. The findings
highlight AI's potential to link scientific insight, artistic practice, and
environmental stewardship, offering a roadmap for future research on
sustainable, technology-enabled ecosystems.

</details>


### [2] [General Modular Harness for LLM Agents in Multi-Turn Gaming Environments](https://arxiv.org/abs/2507.11633)
*Yuxuan Zhang,Haoyang Yu,Lanxiang Hu,Haojian Jin,Hao Zhang*

Main category: cs.AI

TL;DR: 提出了一种模块化设计的LLM代理框架，整合感知、记忆和推理组件，提升多轮游戏环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 通过模块化设计，避免领域特定工程，提升通用代理的适应性。

Method: 采用经典和现代游戏套件作为测试平台，分析各模块在动态交互环境中的作用。

Result: 实验表明该框架显著提升游戏性能，不同模块在不同场景中表现各异。

Conclusion: 模块化设计有效推进通用代理的发展，游戏作为测试平台具有广泛适用性。

Abstract: We introduce a modular harness design for LLM agents that composes of
perception, memory, and reasoning components, enabling a single LLM or VLM
backbone to tackle a wide spectrum of multi turn gaming environments without
domain-specific engineering. Using classic and modern game suites as
low-barrier, high-diversity testbeds, our framework provides a unified workflow
for analyzing how each module affects performance across dynamic interactive
settings. Extensive experiments demonstrate that the harness lifts gameplay
performance consistently over un-harnessed baselines and reveals distinct
contribution patterns, for example, memory dominates in long-horizon puzzles
while perception is critical in vision noisy arcades. These findings highlight
the effectiveness of our modular harness design in advancing general-purpose
agent, given the familiarity and ubiquity of games in everyday human
experience.

</details>


### [3] [Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification](https://arxiv.org/abs/2507.11662)
*Moises Andrade,Joonhyuk Cha,Brandon Ho,Vriksha Srihari,Karmesh Yadav,Zsolt Kira*

Main category: cs.AI

TL;DR: 该论文探讨了多模态大型语言模型（MLLMs）作为验证器的潜力，并发现其存在‘同意偏见’问题。作者提出了一种名为‘自我基础验证（SGV）’的轻量级方法，显著提升了MLLMs的验证性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏明确成功标准的领域（如计算机使用）中，如何扩展验证器的应用是一个挑战。MLLMs因其世界知识、人类偏好对齐和推理能力被视为潜在解决方案。

Method: 论文提出了自我基础验证（SGV），通过无条件生成和条件生成两步，利用MLLMs自身的采样机制来提升验证效果。

Result: SGV方法显著提升了MLLMs的验证性能，准确率和故障检测率提高了20个百分点，并在多个任务中实现了实时监督，性能超越之前最佳方法48%。

Conclusion: SGV方法有效解决了MLLMs作为验证器时的‘同意偏见’问题，显著提升了其在复杂任务中的验证能力。

Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key
for AI progress in domains like math and board games. However, extending these
gains to domains without clear-cut success criteria (e.g.,computer use) remains
a challenge: while humans can recognize suitable outcomes, translating this
intuition into scalable rules is non-trivial. Multimodal Large Language
Models(MLLMs) emerge as a promising solution, given their world knowledge,
human-preference alignment, and reasoning skills. We evaluate MLLMs as
verifiers of agent trajectories across web navigation, computer use, and
robotic manipulation, and identify a critical limitation: agreement bias, a
strong tendency for MLLMs to favor information in their context window, often
generating chains of thought to rationalize flawed behavior. This bias is
pervasive across models, resilient to test-time scaling, and can impact several
methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs
despite MLLMs showing strong, human-aligned priors on desired behavior. To
address this, we propose Self-Grounded Verification (SGV), a lightweight method
that enables more effective use of MLLMs' knowledge and reasoning by harnessing
their own sampling mechanisms via unconditional and conditional generation. SGV
operates in two steps: first, the MLLM is elicited to retrieve broad priors
about task completion, independent of the data under evaluation. Then,
conditioned on self-generated priors, it reasons over and evaluates a candidate
trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in
accuracy and failure detection rates, and can perform real-time supervision of
heterogeneous agents, boosting task completion of a GUI specialist in OSWorld,
a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting
a new state of the art on the benchmark, surpassing the previous best by 48%.

</details>


### [4] [ClarifAI: Enhancing AI Interpretability and Transparency through Case-Based Reasoning and Ontology-Driven Approach for Improved Decision-Making](https://arxiv.org/abs/2507.11733)
*Srikanth Vemula*

Main category: cs.AI

TL;DR: ClarifAI结合案例推理和本体驱动方法，提升AI透明度和可解释性，适用于高风险的决策场景。


<details>
  <summary>Details</summary>
Motivation: 解决AI在决策支持中透明度和可解释性的需求，满足不同利益相关者的复杂解释要求。

Method: 结合案例推理（CBR）和本体驱动方法，设计理论框架和架构蓝图。

Result: ClarifAI能显著提升AI系统的可解释性，适用于多领域和高风险环境。

Conclusion: ClarifAI为AI系统的透明度和可解释性提供了创新解决方案，支持关键决策过程。

Abstract: This Study introduces Clarity and Reasoning Interface for Artificial
Intelligence(ClarifAI), a novel approach designed to augment the transparency
and interpretability of artificial intelligence (AI) in the realm of improved
decision making. Leveraging the Case-Based Reasoning (CBR) methodology and
integrating an ontology-driven approach, ClarifAI aims to meet the intricate
explanatory demands of various stakeholders involved in AI-powered
applications. The paper elaborates on ClarifAI's theoretical foundations,
combining CBR and ontologies to furnish exhaustive explanation mechanisms. It
further elaborates on the design principles and architectural blueprint,
highlighting ClarifAI's potential to enhance AI interpretability across
different sectors and its applicability in high-stake environments. This
research delineates the significant role of ClariAI in advancing the
interpretability of AI systems, paving the way for its deployment in critical
decision-making processes.

</details>


### [5] [Auto-Formulating Dynamic Programming Problems with Large Language Models](https://arxiv.org/abs/2507.11737)
*Chenyu Zhou,Jingyuan Yang,Linwei Xin,Yitian Chen,Ziyan He,Dongdong Ge*

Main category: cs.AI

TL;DR: 论文提出DP-Bench基准和DPLM模型，利用DualReflect数据生成方法解决动态规划问题，性能优于现有LLM。


<details>
  <summary>Details</summary>
Motivation: 动态规划（DP）建模传统上依赖专家知识，LLM有潜力自动化这一过程，但面临数据稀缺和随机性挑战。

Method: 引入DP-Bench基准和DPLM模型，采用DualReflect合成数据生成方法，结合前向和后向生成策略。

Result: DPLM在性能上媲美顶级LLM，并在难题上超越它们；DualReflect在低数据和高数据场景下各有优势。

Conclusion: DualReflect的前向和后向生成策略互补，结合使用能有效提升DP问题建模能力。

Abstract: Dynamic programming (DP) is a fundamental method in operations research, but
formulating DP models has traditionally required expert knowledge of both the
problem context and DP techniques. Large Language Models (LLMs) offer the
potential to automate this process. However, DP problems pose unique challenges
due to their inherently stochastic transitions and the limited availability of
training data. These factors make it difficult to directly apply existing
LLM-based models or frameworks developed for other optimization problems, such
as linear or integer programming. We introduce DP-Bench, the first benchmark
covering a wide range of textbook-level DP problems to enable systematic
evaluation. We present Dynamic Programming Language Model (DPLM), a
7B-parameter specialized model that achieves performance comparable to
state-of-the-art LLMs like OpenAI's o1 and DeepSeek-R1, and surpasses them on
hard problems. Central to DPLM's effectiveness is DualReflect, our novel
synthetic data generation pipeline, designed to scale up training data from a
limited set of initial examples. DualReflect combines forward generation for
diversity and backward generation for reliability. Our results reveal a key
insight: backward generation is favored in low-data regimes for its strong
correctness guarantees, while forward generation, though lacking such
guarantees, becomes increasingly valuable at scale for introducing diverse
formulations. This trade-off highlights the complementary strengths of both
approaches and the importance of combining them.

</details>


### [6] [Survey of Swarm Intelligence Approaches to Search Documents Based On Semantic Similarity](https://arxiv.org/abs/2507.11787)
*Chandrashekar Muniyappa,Eunjin Kim*

Main category: cs.AI

TL;DR: 本文综述了基于群体智能算法的语义相似性文档搜索的最新进展，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 群体智能（SI）因其高效性在人工智能领域广受欢迎，通过模拟自然界生物行为解决实际问题，尤其在计算机优化问题中表现突出。本文旨在总结其在语义相似性文档搜索中的应用。

Method: 通过文献综述，分析群体智能算法在语义相似性文档搜索中的最新应用和发展。

Result: 总结了群体智能算法在该领域的有效性，并识别了当前研究的局限性。

Conclusion: 建议未来研究应进一步优化算法性能，并探索更多实际应用场景。

Abstract: Swarm Intelligence (SI) is gaining a lot of popularity in artificial
intelligence, where the natural behavior of animals and insects is observed and
translated into computer algorithms called swarm computing to solve real-world
problems. Due to their effectiveness, they are applied in solving various
computer optimization problems. This survey will review all the latest
developments in Searching for documents based on semantic similarity using
Swarm Intelligence algorithms and recommend future research directions.

</details>


### [7] [A Parallel CPU-GPU Framework for Cost-Bounded DFS with Applications to IDA* and BTS](https://arxiv.org/abs/2507.11916)
*Ehsan Futuhi,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 论文提出了一种利用GPU并行计算优化深度优先搜索（DFS）的方法，特别是成本受限深度优先搜索（CB-DFS），并扩展了Batch IDA*和Batch BTS算法。


<details>
  <summary>Details</summary>
Motivation: GPU技术的快速发展为经典搜索算法的优化提供了新机会，但目前很少有算法在搜索过程中充分利用GPU。

Method: 提出了一种批处理GPU计算的CB-DFS方法，结合CPU和GPU的并行能力，扩展了Batch IDA*和Batch BTS算法。

Result: 在3x3魔方和4x4滑块拼图（STP）上验证了方法的有效性，并分析了超参数、启发式网络大小和硬件资源对性能的影响。

Conclusion: 研究表明，GPU计算可以高效地批处理于DFS中，同时保持最优性保证。

Abstract: The rapid advancement of GPU technology has unlocked powerful parallel
processing capabilities, creating new opportunities to enhance classic search
algorithms. A recent successful application of GPUs is in compressing large
pattern database (PDB) heuristics using neural networks while preserving
heuristic admissibility. However, very few algorithms have been designed to
exploit GPUs during search. Several variants of A* exist that batch GPU
computations. In this paper we introduce a method for batching GPU computations
in depth first search. In particular, we describe a new cost-bounded
depth-first search (CB-DFS) method that leverages the combined parallelism of
modern CPUs and GPUs. This is used to create algorithms like \emph{Batch IDA*},
an extension of the Iterative Deepening A* (IDA*) algorithm, or Batch BTS, an
extensions of Budgeted Tree Search. Our approach builds on the general approach
used by Asynchronous Parallel IDA* (AIDA*), while maintaining optimality
guarantees. We evaluate the approach on the 3x3 Rubik's Cube and 4x4 sliding
tile puzzle (STP), showing that GPU operations can be efficiently batched in
DFS. Additionally, we conduct extensive experiments to analyze the effects of
hyperparameters, neural network heuristic size, and hardware resources on
performance.

</details>


### [8] [Aime: Towards Fully-Autonomous Multi-Agent Framework](https://arxiv.org/abs/2507.11988)
*Yexuan Shi,Mingyu Wang,Yunxiang Cao,Hongjie Lai,Junjian Lan,Xin Han,Yu Wang,Jie Geng,Zhenan Li,Zihao Xia,Xiang Chen,Chen Li,Jian Xu,Wenbo Duan,Yuanshuo Zhu*

Main category: cs.AI

TL;DR: Aime是一个新型多智能体框架，通过动态反应式规划和执行解决传统plan-and-execute框架的局限性，显著提升多智能体系统的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体系统在动态环境中因静态规划和执行、固定能力及低效通信而表现不佳，Aime旨在解决这些问题。

Method: Aime采用动态规划器、动态角色工厂和集中进度管理模块，实现实时策略调整、按需角色创建和全局状态感知。

Result: 在多个基准测试中，Aime表现优于现有最先进的专用智能体，展示了更高的适应性和任务成功率。

Conclusion: Aime为多智能体协作提供了更灵活、高效的框架，适用于复杂动态环境。

Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are
emerging as a powerful paradigm for solving complex, multifaceted problems.
However, the potential of these systems is often constrained by the prevalent
plan-and-execute framework, which suffers from critical limitations: rigid plan
execution, static agent capabilities, and inefficient communication. These
weaknesses hinder their adaptability and robustness in dynamic environments.
This paper introduces Aime, a novel multi-agent framework designed to overcome
these challenges through dynamic, reactive planning and execution. Aime
replaces the conventional static workflow with a fluid and adaptive
architecture. Its core innovations include: (1) a Dynamic Planner that
continuously refines the overall strategy based on real-time execution
feedback; (2) an Actor Factory that implements Dynamic Actor instantiation,
assembling specialized agents on-demand with tailored tools and knowledge; and
(3) a centralized Progress Management Module that serves as a single source of
truth for coherent, system-wide state awareness. We empirically evaluated Aime
on a diverse suite of benchmarks spanning general reasoning (GAIA), software
engineering (SWE-bench Verified), and live web navigation (WebVoyager). The
results demonstrate that Aime consistently outperforms even highly specialized
state-of-the-art agents in their respective domains. Its superior adaptability
and task success rate establish Aime as a more resilient and effective
foundation for multi-agent collaboration.

</details>


### [9] [Understanding visual attention beehind bee-inspired UAV navigation](https://arxiv.org/abs/2507.11992)
*Pranav Rajbhandari,Abhi Veda,Matthew Garratt,Mandayam Srinivasan,Sridhar Ravi*

Main category: cs.AI

TL;DR: 论文研究了基于光学流的强化学习代理在无人机导航中的应用，发现代理主要关注光学流中的不连续区域和大流量区域，模拟了昆虫的飞行行为。


<details>
  <summary>Details</summary>
Motivation: 生物系统（如蜜蜂）利用有限感官和计算能力实现飞行和避障，启发研究者探索基于光学流的无人机导航策略。

Method: 通过强化学习训练代理在隧道中导航，仅使用光学流作为感官输入，并分析其注意力模式。

Result: 代理主要关注光学流中的不连续区域和大流量区域，行为类似昆虫，且在不同代理中表现一致。

Conclusion: 这种策略可能适用于开发简单的无人机显式控制法则。

Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the
capacity of biological systems for flight and obstacle avoidance despite
limited sensory and computational capabilities. In particular, honeybees mainly
use the sensory input of optic flow, the apparent motion of objects in their
visual field, to navigate cluttered environments. In our work, we train a
Reinforcement Learning agent to navigate a tunnel with obstacles using only
optic flow as sensory input. We inspect the attention patterns of trained
agents to determine the regions of optic flow on which they primarily base
their motor decisions. We find that agents trained in this way pay most
attention to regions of discontinuity in optic flow, as well as regions with
large optic flow magnitude. The trained agents appear to navigate a cluttered
tunnel by avoiding the obstacles that produce large optic flow, while
maintaining a centered position in their environment, which resembles the
behavior seen in flying insects. This pattern persists across independently
trained agents, which suggests that this could be a good strategy for
developing a simple explicit control law for physical UAVs.

</details>


### [10] [Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs](https://arxiv.org/abs/2507.12110)
*Ye Han,Lijun Zhang,Dejian Meng,Zhuang Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种拓扑增强的多智能体强化学习方法（TPE-MARL），用于优化混合交通中联网自动驾驶车辆（CAVs）的协作决策，通过压缩高维状态空间和平衡探索与利用，显著提升了交通效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习（MARL）在联合状态-动作空间指数增长的情况下，探索与利用的权衡尤为困难。本文旨在解决这一挑战，特别是在混合交通中CAVs的协作决策问题。

Method: 1. 构建动态交通流的博弈拓扑张量，压缩高维状态信息；2. 基于QMIX算法，结合访问计数和智能体互信息，建立拓扑增强的MARL框架。

Result: 实验表明，TPE-MARL在交通效率、安全性、决策平滑性和任务完成度上表现优异，且在混合和全自动驾驶场景中决策合理性达到或超过人类驾驶员水平。

Conclusion: TPE-MARL通过拓扑张量和探索优化，有效解决了MARL中的探索-利用问题，为CAVs的协作决策提供了高效解决方案。

Abstract: The exploration-exploitation trade-off constitutes one of the fundamental
challenges in reinforcement learning (RL), which is exacerbated in multi-agent
reinforcement learning (MARL) due to the exponential growth of joint
state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL)
method for optimizing cooperative decision-making of connected and autonomous
vehicles (CAVs) in mixed traffic. This work presents two primary contributions:
First, we construct a game topology tensor for dynamic traffic flow,
effectively compressing high-dimensional traffic state information and decrease
the search space for MARL algorithms. Second, building upon the designed game
topology tensor and using QMIX as the backbone RL algorithm, we establish a
topology-enhanced MARL framework incorporating visit counts and agent mutual
information. Extensive simulations across varying traffic densities and CAV
penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations
encompassing training dynamics, exploration patterns, macroscopic traffic
performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL
successfully balances exploration and exploitation. Consequently, it exhibits
superior performance in terms of traffic efficiency, safety, decision
smoothness, and task completion. Furthermore, the algorithm demonstrates
decision-making rationality comparable to or exceeding that of human drivers in
both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is
available at
\href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.

</details>


### [11] [Partially Observable Reference Policy Programming: Solving POMDPs Sans Numerical Optimisation](https://arxiv.org/abs/2507.12186)
*Edward Kim,Hanna Kurniawati*

Main category: cs.AI

TL;DR: 提出了一种新的在线近似POMDP求解器，通过深度采样未来历史并逐步更新策略，性能损失受限于采样误差的平均值而非最大值。


<details>
  <summary>Details</summary>
Motivation: 解决在线规划中采样稀疏性问题，提升动态环境下的决策性能。

Method: 提出Partially Observable Reference Policy Programming算法，结合深度采样和逐步策略更新。

Result: 理论证明性能损失受限于采样误差平均值，实验表明在动态环境中显著优于现有方法。

Conclusion: 该算法在理论和实践中均表现出色，适用于大规模动态环境问题。

Abstract: This paper proposes Partially Observable Reference Policy Programming, a
novel anytime online approximate POMDP solver which samples meaningful future
histories very deeply while simultaneously forcing a gradual policy update. We
provide theoretical guarantees for the algorithm's underlying scheme which say
that the performance loss is bounded by the average of the sampling
approximation errors rather than the usual maximum, a crucial requirement given
the sampling sparsity of online planning. Empirical evaluations on two
large-scale problems with dynamically evolving environments -- including a
helicopter emergency scenario in the Corsica region requiring approximately 150
planning steps -- corroborate the theoretical results and indicate that our
solver considerably outperforms current online benchmarks.

</details>


### [12] [BuildEvo: Designing Building Energy Consumption Forecasting Heuristics via LLM-driven Evolution](https://arxiv.org/abs/2507.12207)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: BuildEvo框架利用大型语言模型（LLMs）自动设计高效且可解释的建筑能耗预测启发式方法，结合物理原理和数据，实现高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法精度不足，而高级模型缺乏透明性且忽视物理原理，难以泛化。

Method: 通过进化过程引导LLMs构建和优化启发式方法，结合建筑特性和操作数据的物理洞察。

Result: 在基准测试中达到最先进性能，泛化能力提升且预测逻辑透明。

Conclusion: BuildEvo推动了自动化设计稳健、基于物理的启发式方法，为复杂能源系统提供可信模型。

Abstract: Accurate building energy forecasting is essential, yet traditional heuristics
often lack precision, while advanced models can be opaque and struggle with
generalization by neglecting physical principles. This paper introduces
BuildEvo, a novel framework that uses Large Language Models (LLMs) to
automatically design effective and interpretable energy prediction heuristics.
Within an evolutionary process, BuildEvo guides LLMs to construct and enhance
heuristics by systematically incorporating physical insights from building
characteristics and operational data (e.g., from the Building Data Genome
Project 2). Evaluations show BuildEvo achieves state-of-the-art performance on
benchmarks, offering improved generalization and transparent prediction logic.
This work advances the automated design of robust, physically grounded
heuristics, promoting trustworthy models for complex energy systems.

</details>


### [13] [Xiangqi-R1: Enhancing Spatial Strategic Reasoning in LLMs for Chinese Chess via Reinforcement Learning](https://arxiv.org/abs/2507.12215)
*Yuhao Chen,Shuochen Liu,Yuanjie Lyu,Chao Zhang,Jiayao Shi,Tong Xu*

Main category: cs.AI

TL;DR: 论文探讨了大型语言模型（LLMs）在空间战略推理（如中国象棋）中的不足，并提出了一种多阶段训练框架Xiangqi-R1，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在空间战略推理中的能力，尤其是复杂且完全可观测的棋盘游戏（如中国象棋），填补现有研究的空白。

Method: 采用多阶段训练框架：1) 微调合法移动预测；2) 结合战略注释；3) 通过GRPO强化学习优化推理稳定性。

Result: Xiangqi-R1相比通用LLMs，合法移动率提升18%，分析准确率提高22%。

Conclusion: 该框架为在空间复杂领域开发通用战略智能提供了可行路径。

Abstract: Game playing has long served as a fundamental benchmark for evaluating
Artificial General Intelligence (AGI). While Large Language Models (LLMs) have
demonstrated impressive capabilities in general reasoning, their effectiveness
in spatial strategic reasoning, which is critical for complex and fully
observable board games, remains insufficiently explored. In this work, we adopt
Chinese Chess (Xiangqi) as a challenging and rich testbed due to its intricate
rules and spatial complexity. To advance LLMs' strategic competence in such
environments, we propose a training framework tailored to Xiangqi, built upon a
large-scale dataset of five million board-move pairs enhanced with expert
annotations and engine evaluations. Building on this foundation, we introduce
Xiangqi-R1, a 7B-parameter model trained in multi-stage manner: (1) fine-tuning
for legal move prediction to capture basic spatial rules, (2) incorporating
strategic annotations to improve decision-making, and (3) applying
reinforcement learning via Group Relative Policy Optimization (GRPO) with
multi-dimensional reward signals to enhance reasoning stability. Our
Experimental results indicate that, despite their size and power,
general-purpose LLMs struggle to achieve satisfactory performance in these
tasks. Compared to general-purpose LLMs, Xiangqi-R1 greatly advances with an
18% rise in move legality and a 22% boost in analysis accuracy. Our results
point to a promising path for creating general strategic intelligence in
spatially complex areas.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [14] [Subjective Evaluation Profile Analysis of Science Fiction Short Stories and its Critical-Theoretical Significance](https://arxiv.org/abs/2507.11582)
*Kazuyoshi Otsuka*

Main category: cs.CL

TL;DR: 研究将大语言模型（LLMs）作为“主观文学评论家”，探讨其在文学评估中的审美偏好和评价模式。通过十篇日本科幻短篇小说的翻译和六种先进LLMs的评估，发现评价一致性和模式存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在文学评估中的表现，揭示其是否具有类似人类批评流派的个体化评价特征。

Method: 将十篇日本科幻小说翻译为英文，由六种LLMs在七次独立会话中评估，使用主成分分析和聚类技术分析数据。

Result: 发现评价一致性差异显著（α值1.00至0.35），识别出五种评价模式，且不同模型的评价词汇具有独特性。

Conclusion: LLMs可能具备类似人类批评流派的个体化评价特征，而非中性基准工具。

Abstract: This study positions large language models (LLMs) as "subjective literary
critics" to explore aesthetic preferences and evaluation patterns in literary
assessment. Ten Japanese science fiction short stories were translated into
English and evaluated by six state-of-the-art LLMs across seven independent
sessions. Principal component analysis and clustering techniques revealed
significant variations in evaluation consistency ({\alpha} ranging from 1.00 to
0.35) and five distinct evaluation patterns. Additionally, evaluation variance
across stories differed by up to 4.5-fold, with TF-IDF analysis confirming
distinctive evaluation vocabularies for each model. Our seven-session
within-day protocol using an original Science Fiction corpus strategically
minimizes external biases, allowing us to observe implicit value systems shaped
by RLHF and their influence on literary judgment. These findings suggest that
LLMs may possess individual evaluation characteristics similar to human
critical schools, rather than functioning as neutral benchmarkers.

</details>


### [15] [MapIQ: Benchmarking Multimodal Large Language Models for Map Question Answering](https://arxiv.org/abs/2507.11625)
*Varun Srivastava,Fan Lei,Srija Mukhopadhyay,Vivek Gupta,Ross Maciejewski*

Main category: cs.CL

TL;DR: 论文介绍了MapIQ基准数据集，用于评估多模态大语言模型（MLLMs）在地图视觉问答（Map-VQA）中的表现，覆盖多种地图类型和主题，并探讨了地图设计变化对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有Map-VQA研究主要局限于等值区域图，覆盖的主题和任务有限，因此需要更全面的数据集和评估方法。

Method: 构建MapIQ数据集，包含14,706个问题-答案对，覆盖三种地图类型和六个主题，评估多种MLLMs在六项视觉分析任务中的表现，并测试地图设计变化的影响。

Result: MLLMs在Map-VQA任务中表现不一，地图设计变化（如颜色方案、图例设计）显著影响模型性能，揭示了模型的鲁棒性和对地理知识的依赖。

Conclusion: MapIQ为Map-VQA研究提供了更全面的基准，揭示了MLLMs的局限性，并提出了改进方向。

Abstract: Recent advancements in multimodal large language models (MLLMs) have driven
researchers to explore how well these models read data visualizations, e.g.,
bar charts, scatter plots. More recently, attention has shifted to visual
question answering with maps (Map-VQA). However, Map-VQA research has primarily
focused on choropleth maps, which cover only a limited range of thematic
categories and visual analytical tasks. To address these gaps, we introduce
MapIQ, a benchmark dataset comprising 14,706 question-answer pairs across three
map types: choropleth maps, cartograms, and proportional symbol maps spanning
topics from six distinct themes (e.g., housing, crime). We evaluate multiple
MLLMs using six visual analytical tasks, comparing their performance against
one another and a human baseline. An additional experiment examining the impact
of map design changes (e.g., altered color schemes, modified legend designs,
and removal of map elements) provides insights into the robustness and
sensitivity of MLLMs, their reliance on internal geographic knowledge, and
potential avenues for improving Map-VQA performance.

</details>


### [16] [Cross-lingual Few-shot Learning for Persian Sentiment Analysis with Incremental Adaptation](https://arxiv.org/abs/2507.11634)
*Farideh Majidi,Ziaeddin Beheshtifard*

Main category: cs.CL

TL;DR: 研究探讨了使用少样本学习和增量学习方法在波斯语中进行跨语言情感分析，目标是开发一个能在有限数据下利用高资源语言先验知识的模型。


<details>
  <summary>Details</summary>
Motivation: 解决波斯语情感分析中数据稀缺的问题，同时利用高资源语言的知识提升模型性能。

Method: 采用XLM-RoBERTa、mDeBERTa和DistilBERT三种预训练多语言模型，通过少样本和增量学习方法在波斯语数据上微调。

Result: mDeBERTa和XLM-RoBERTa表现最佳，达到96%的准确率。

Conclusion: 结合少样本学习、增量学习和多语言预训练模型是有效的跨语言情感分析方法。

Abstract: This research examines cross-lingual sentiment analysis using few-shot
learning and incremental learning methods in Persian. The main objective is to
develop a model capable of performing sentiment analysis in Persian using
limited data, while getting prior knowledge from high-resource languages. To
achieve this, three pre-trained multilingual models (XLM-RoBERTa, mDeBERTa, and
DistilBERT) were employed, which were fine-tuned using few-shot and incremental
learning approaches on small samples of Persian data from diverse sources,
including X, Instagram, Digikala, Snappfood, and Taaghche. This variety enabled
the models to learn from a broad range of contexts. Experimental results show
that the mDeBERTa and XLM-RoBERTa achieved high performances, reaching 96%
accuracy on Persian sentiment analysis. These findings highlight the
effectiveness of combining few-shot learning and incremental learning with
multilingual pre-trained models.

</details>


### [17] [Partitioner Guided Modal Learning Framework](https://arxiv.org/abs/2507.11661)
*Guimin Hu,Yi Xin,Lijie Hu,Zhihong Zhu,Hasti Seifi*

Main category: cs.CL

TL;DR: PgM是一种多模态学习框架，通过模态分区器将模态表示分为单模态和配对模态特征，分别学习并解码，适用于多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 多模态学习需要充分利用单模态和跨模态交互的特征，但现有方法未能明确区分和优化这两类特征。

Method: PgM框架包含模态分区器、单模态学习器、配对模态学习器和单配对模态解码器，分别处理单模态和配对模态特征。

Result: 实验证明PgM在四种多模态任务中有效，且具有可迁移性，特征分布可视化提供了深入见解。

Conclusion: PgM通过明确区分和优化单模态与配对模态特征，提升了多模态学习的灵活性和性能。

Abstract: Multimodal learning benefits from multiple modal information, and each
learned modal representations can be divided into uni-modal that can be learned
from uni-modal training and paired-modal features that can be learned from
cross-modal interaction. Building on this perspective, we propose a
partitioner-guided modal learning framework, PgM, which consists of the modal
partitioner, uni-modal learner, paired-modal learner, and uni-paired modal
decoder. Modal partitioner segments the learned modal representation into
uni-modal and paired-modal features. Modal learner incorporates two dedicated
components for uni-modal and paired-modal learning. Uni-paired modal decoder
reconstructs modal representation based on uni-modal and paired-modal features.
PgM offers three key benefits: 1) thorough learning of uni-modal and
paired-modal features, 2) flexible distribution adjustment for uni-modal and
paired-modal representations to suit diverse downstream tasks, and 3) different
learning rates across modalities and partitions. Extensive experiments
demonstrate the effectiveness of PgM across four multimodal tasks and further
highlight its transferability to existing models. Additionally, we visualize
the distribution of uni-modal and paired-modal features across modalities and
tasks, offering insights into their respective contributions.

</details>


### [18] [ExpliCIT-QA: Explainable Code-Based Image Table Question Answering](https://arxiv.org/abs/2507.11694)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Pedro Alonso Doval,Jorge Alcalde Vesteiro,Héctor Cerezo-Costas*

Main category: cs.CL

TL;DR: ExpliCIT-QA是一个多模态表格问答系统，通过模块化设计提供可解释的答案，包括表格理解、语言推理、代码生成与执行，以及自然语言解释。


<details>
  <summary>Details</summary>
Motivation: 解决端到端表格问答系统中可解释性的不足，特别是在敏感领域（如金融和医疗）中对结果审计的需求。

Method: 系统采用模块化设计，包括多模态表格理解、语言推理、自动代码生成与执行，以及自然语言解释。

Result: 在TableVQA-Bench基准测试中表现优于现有基线，提升了可解释性和透明度。

Conclusion: ExpliCIT-QA为敏感领域的应用提供了可审计的解决方案，填补了表格问答系统的可解释性空白。

Abstract: We present ExpliCIT-QA, a system that extends our previous MRT approach for
tabular question answering into a multimodal pipeline capable of handling
complex table images and providing explainable answers. ExpliCIT-QA follows a
modular design, consisting of: (1) Multimodal Table Understanding, which uses a
Chain-of-Thought approach to extract and transform content from table images;
(2) Language-based Reasoning, where a step-by-step explanation in natural
language is generated to solve the problem; (3) Automatic Code Generation,
where Python/Pandas scripts are created based on the reasoning steps, with
feedback for handling errors; (4) Code Execution to compute the final answer;
and (5) Natural Language Explanation that describes how the answer was
computed. The system is built for transparency and auditability: all
intermediate outputs, parsed tables, reasoning steps, generated code, and final
answers are available for inspection. This strategy works towards closing the
explainability gap in end-to-end TableVQA systems. We evaluated ExpliCIT-QA on
the TableVQA-Bench benchmark, comparing it with existing baselines. We
demonstrated improvements in interpretability and transparency, which open the
door for applications in sensitive domains like finance and healthcare where
auditing results are critical.

</details>


### [19] [CRABS: A syntactic-semantic pincer strategy for bounding LLM interpretation of Python notebooks](https://arxiv.org/abs/2507.11742)
*Meng Li,Timothy M. McPhillips,Dingmin Wang,Shin-Rong Tsai,Bertram Ludäscher*

Main category: cs.CL

TL;DR: 论文提出CRABS方法，结合浅层语法分析和LLM，解决Python笔记本信息流和依赖关系识别的挑战，效果显著。


<details>
  <summary>Details</summary>
Motivation: 识别Python笔记本中的信息流和操作对重用和适应新任务至关重要，但现有方法（如LLM）存在幻觉和长上下文问题。

Method: 提出CRABS策略，结合语法分析和LLM，通过捕获和解析边界策略识别笔记本的真实数据输入输出。

Result: 在50个Kaggle笔记本上测试，LLM解决98%的歧义，CRABS在信息流和依赖关系识别上F1分数分别达98%和99%。

Conclusion: CRABS方法有效解决了笔记本理解问题，结合语法分析和LLM的策略具有高效性和准确性。

Abstract: Recognizing the information flows and operations comprising data science and
machine learning Python notebooks is critical for evaluating, reusing, and
adapting notebooks for new tasks. Investigating a notebook via re-execution
often is impractical due to the challenges of resolving data and software
dependencies. While Large Language Models (LLMs) pre-trained on large codebases
have demonstrated effectiveness in understanding code without running it, we
observe that they fail to understand some realistic notebooks due to
hallucinations and long-context challenges. To address these issues, we propose
a notebook understanding task yielding an information flow graph and
corresponding cell execution dependency graph for a notebook, and demonstrate
the effectiveness of a pincer strategy that uses limited syntactic analysis to
assist full comprehension of the notebook using an LLM. Our Capture and Resolve
Assisted Bounding Strategy (CRABS) employs shallow syntactic parsing and
analysis of the abstract syntax tree (AST) to capture the correct
interpretation of a notebook between lower and upper estimates of the
inter-cell I/O sets, then uses an LLM to resolve remaining ambiguities via
cell-by-cell zero-shot learning, thereby identifying the true data inputs and
outputs of each cell. We evaluate and demonstrate the effectiveness of our
approach using an annotated dataset of 50 representative, highly up-voted
Kaggle notebooks that together represent 3454 actual cell inputs and outputs.
The LLM correctly resolves 1397 of 1425 (98%) ambiguities left by analyzing the
syntactic structure of these notebooks. Across 50 notebooks, CRABS achieves
average F1 scores of 98% identifying cell-to-cell information flows and 99%
identifying transitive cell execution dependencies.

</details>


### [20] [AI Wizards at CheckThat! 2025: Enhancing Transformer-Based Embeddings with Sentiment for Subjectivity Detection in News Articles](https://arxiv.org/abs/2507.11764)
*Matteo Fasulo,Luca Babboni,Luca Tedeschini*

Main category: cs.CL

TL;DR: AI Wizards团队在CLEF 2025 CheckThat! Lab Task 1中，通过结合情感分数与句子表示，提升了基于Transformer的分类器性能，并在多语言和零样本设置中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 研究旨在改进新闻文章句子主观性检测任务，尤其是在多语言和零样本场景下的泛化能力。

Method: 通过集成情感分数（来自辅助模型）与句子表示，优化了Transformer模型（如mDeBERTaV3-base、ModernBERT-base和Llama3.2-1B），并采用决策阈值校准处理类别不平衡问题。

Result: 情感特征显著提升了性能（尤其是主观F1分数），团队在希腊语任务中排名第一（Macro F1 = 0.51）。

Conclusion: 结合情感特征的Transformer模型在多语言主观性检测任务中表现优异，具有实际应用潜力。

Abstract: This paper presents AI Wizards' participation in the CLEF 2025 CheckThat! Lab
Task 1: Subjectivity Detection in News Articles, classifying sentences as
subjective/objective in monolingual, multilingual, and zero-shot settings.
Training/development datasets were provided for Arabic, German, English,
Italian, and Bulgarian; final evaluation included additional unseen languages
(e.g., Greek, Romanian, Polish, Ukrainian) to assess generalization. Our
primary strategy enhanced transformer-based classifiers by integrating
sentiment scores, derived from an auxiliary model, with sentence
representations, aiming to improve upon standard fine-tuning. We explored this
sentiment-augmented architecture with mDeBERTaV3-base, ModernBERT-base
(English), and Llama3.2-1B. To address class imbalance, prevalent across
languages, we employed decision threshold calibration optimized on the
development set. Our experiments show sentiment feature integration
significantly boosts performance, especially subjective F1 score. This
framework led to high rankings, notably 1st for Greek (Macro F1 = 0.51).

</details>


### [21] [Tracing Facts or just Copies? A critical investigation of the Competitions of Mechanisms in Large Language Models](https://arxiv.org/abs/2507.11809)
*Dante Campregher,Yanxu Chen,Sander Hoffman,Maria Heuss*

Main category: cs.CL

TL;DR: 本文通过可重复性研究探讨了大型语言模型（LLMs）如何处理相互矛盾的事实与反事实信息，重点关注注意力头的作用。研究试图复现并调和三项近期研究的结果，分析了注意力头强度与事实输出比例的关系，评估了关于注意力头抑制机制的竞争假设，并研究了这些注意力模式的领域特异性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解LLMs如何管理相互矛盾的信息，特别是注意力头在抑制反事实或促进事实输出中的作用，以调和现有研究的分歧。

Method: 研究方法包括复现三项相关研究，使用机制解释工具分析注意力头强度与事实输出比例的关系，评估竞争假设，并研究注意力模式的领域特异性。

Result: 研究发现，促进事实输出的注意力头通过通用的复制抑制而非选择性反事实抑制实现其功能，且其行为具有领域依赖性，较大模型表现出更专业化和类别敏感的模式。

Conclusion: 结论表明，注意力头的抑制机制是通用的，而非针对反事实的选择性抑制，且其行为受模型规模和领域影响。

Abstract: This paper presents a reproducibility study examining how Large Language
Models (LLMs) manage competing factual and counterfactual information, focusing
on the role of attention heads in this process. We attempt to reproduce and
reconcile findings from three recent studies by Ortu et al., Yu, Merullo, and
Pavlick and McDougall et al. that investigate the competition between
model-learned facts and contradictory context information through Mechanistic
Interpretability tools. Our study specifically examines the relationship
between attention head strength and factual output ratios, evaluates competing
hypotheses about attention heads' suppression mechanisms, and investigates the
domain specificity of these attention patterns. Our findings suggest that
attention heads promoting factual output do so via general copy suppression
rather than selective counterfactual suppression, as strengthening them can
also inhibit correct facts. Additionally, we show that attention head behavior
is domain-dependent, with larger models exhibiting more specialized and
category-sensitive patterns.

</details>


### [22] [ILID: Native Script Language Identification for Indian Languages](https://arxiv.org/abs/2507.11832)
*Yash Ingle,Pruthwik Mishra*

Main category: cs.CL

TL;DR: 论文发布了一个包含23万句英语和22种印度官方语言的数据集，并开发了基于机器学习和深度学习的基线模型，用于语言识别任务。


<details>
  <summary>Details</summary>
Motivation: 语言识别是NLP的基础任务，尤其在嘈杂、简短和代码混合的环境中更具挑战性，特别是在印度语言中，它们具有相似性但又有显著差异。

Method: 创建了一个新数据集，并利用机器学习和深度学习的最新方法开发了基线模型。

Result: 基线模型在语言识别任务中表现与最先进模型相当。

Conclusion: 发布的数据集和模型为印度语言识别研究提供了有力支持。

Abstract: The language identification task is a crucial fundamental step in NLP. Often
it serves as a pre-processing step for widely used NLP applications such as
multilingual machine translation, information retrieval, question and
answering, and text summarization. The core challenge of language
identification lies in distinguishing languages in noisy, short, and code-mixed
environments. This becomes even harder in case of diverse Indian languages that
exhibit lexical and phonetic similarities, but have distinct differences. Many
Indian languages share the same script making the task even more challenging.
In this paper, we release a dataset of 230K sentences consisting of English and
all 22 official Indian languages labeled with their language identifiers where
data in most languages are newly created. We also develop and release robust
baseline models using state-of-the-art approaches in machine learning and deep
learning that can aid the research in this field. Our baseline models are
comparable to the state-of-the-art models for the language identification task.

</details>


### [23] [Your LLM Knows the Future: Uncovering Its Multi-Token Prediction Potential](https://arxiv.org/abs/2507.11851)
*Mohammad Samragh,Arnav Kundu,David Harrison,Kumari Nishu,Devang Naik,Minsik Cho,Mehrdad Farajtabar*

Main category: cs.CL

TL;DR: 提出一种新框架，通过联合预测多个后续标记，显著提升自回归语言模型的推理速度和并行性。


<details>
  <summary>Details</summary>
Motivation: 自回归语言模型因逐标记生成的顺序性限制了推理速度和并行性，尤其在文本方向和语义较确定的后期生成阶段。

Method: 结合掩码输入、门控LoRA、轻量采样器、辅助训练损失和推测生成策略，实现多标记联合预测。

Result: 代码和数学生成速度提升近5倍，通用聊天和知识任务提升近2.5倍，且质量无损失。

Conclusion: 新框架有效提升了自回归模型的生成效率，同时保持了生成质量。

Abstract: Autoregressive language models are constrained by their inherently sequential
nature, generating one token at a time. This paradigm limits inference speed
and parallelism, especially during later stages of generation when the
direction and semantics of text are relatively certain. In this work, we
propose a novel framework that leverages the inherent knowledge of vanilla
autoregressive language models about future tokens, combining techniques to
realize this potential and enable simultaneous prediction of multiple
subsequent tokens. Our approach introduces several key innovations: (1) a
masked-input formulation where multiple future tokens are jointly predicted
from a common prefix; (2) a gated LoRA formulation that preserves the original
LLM's functionality, while equipping it for multi-token prediction; (3) a
lightweight, learnable sampler module that generates coherent sequences from
the predicted future tokens; (4) a set of auxiliary training losses, including
a consistency loss, to enhance the coherence and accuracy of jointly generated
tokens; and (5) a speculative generation strategy that expands tokens
quadratically in the future while maintaining high fidelity. Our method
achieves significant speedups through supervised fine-tuning on pretrained
models. For example, it generates code and math nearly 5x faster, and improves
general chat and knowledge tasks by almost 2.5x. These gains come without any
loss in quality.

</details>


### [24] [Cross-Domain Transfer and Few-Shot Learning for Personal Identifiable Information Recognition](https://arxiv.org/abs/2507.11862)
*Junhong Ye,Xu Yuan,Xinying Qiu*

Main category: cs.CL

TL;DR: 研究探讨了跨领域模型迁移、多领域数据融合和样本高效学习在PII识别中的效果，发现法律领域数据对传记文本迁移效果好，医疗领域则较差。


<details>
  <summary>Details</summary>
Motivation: 研究PII识别的准确性对自动化文本匿名化至关重要。

Method: 使用医疗、法律和传记领域的标注语料库，评估模型在领域内性能、跨领域迁移性、数据融合和少样本学习方面的表现。

Result: 法律领域数据对传记文本迁移效果好，医疗领域较差；数据融合效果因领域而异；低专业化领域仅需10%训练数据即可实现高质量识别。

Conclusion: 跨领域迁移和数据融合的效果因领域而异，样本高效学习在特定领域可行。

Abstract: Accurate recognition of personally identifiable information (PII) is central
to automated text anonymization. This paper investigates the effectiveness of
cross-domain model transfer, multi-domain data fusion, and sample-efficient
learning for PII recognition. Using annotated corpora from healthcare (I2B2),
legal (TAB), and biography (Wikipedia), we evaluate models across four
dimensions: in-domain performance, cross-domain transferability, fusion, and
few-shot learning. Results show legal-domain data transfers well to
biographical texts, while medical domains resist incoming transfer. Fusion
benefits are domain-specific, and high-quality recognition is achievable with
only 10% of training data in low-specialization domains.

</details>


### [25] [COLA-GEC: A Bidirectional Framework for Enhancing Grammatical Acceptability and Error Correction](https://arxiv.org/abs/2507.11867)
*Xiangyu Yang,Xinying Qiu*

Main category: cs.CL

TL;DR: COLA-GEC框架通过双向知识转移提升语法错误纠正（GEC）和语法可接受性判断（COLA）任务，实现多语言基准的最新成果。


<details>
  <summary>Details</summary>
Motivation: GEC和COLA任务共享语法知识但独立发展，需通过双向框架实现知识互补。

Method: 利用GEC数据增强语法可接受性模型，并通过动态损失函数将语法信号融入GEC训练。

Result: 在多语言基准上取得最优表现，但标点错误纠正仍有挑战。

Conclusion: COLA-GEC框架为语法建模的未来改进提供了方向。

Abstract: Grammatical Error Correction (GEC) and grammatical acceptability judgment
(COLA) are core tasks in natural language processing, sharing foundational
grammatical knowledge yet typically evolving independently. This paper
introduces COLA-GEC, a novel bidirectional framework that enhances both tasks
through mutual knowledge transfer. First, we augment grammatical acceptability
models using GEC datasets, significantly improving their performance across
multiple languages. Second, we integrate grammatical acceptability signals into
GEC model training via a dynamic loss function, effectively guiding corrections
toward grammatically acceptable outputs. Our approach achieves state-of-the-art
results on several multilingual benchmarks. Comprehensive error analysis
highlights remaining challenges, particularly in punctuation error correction,
providing insights for future improvements in grammatical modeling.

</details>


### [26] [DualReward: A Dynamic Reinforcement Learning Framework for Cloze Tests Distractor Generation](https://arxiv.org/abs/2507.11875)
*Tianyou Huang,Xinglu Chen,Jingshen Zhang,Xinying Qiu,Ruiying Niu*

Main category: cs.CL

TL;DR: DualReward是一种新颖的强化学习框架，用于自动生成完形填空测试的干扰项，通过双奖励结构和自适应缩放机制优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法主要依赖监督学习或静态生成模型，无法动态区分人类创建的干扰项和模型生成的候选干扰项，因此需要一种更灵活的框架。

Method: 采用双奖励结构和自适应缩放机制，动态调整奖励信号强度，基于模型性能和置信度。

Result: 在CLOTH-F和MCQ数据集上表现优于现有方法，尤其在多样化的跨域数据上提升显著（P@1提高3.48-3.86%）。

Conclusion: DualReward框架能有效平衡从可靠人类示例中学习和探索高质量干扰项，适用于自动化测试生成。

Abstract: This paper introduces DualReward, a novel reinforcement learning framework
for automatic distractor generation in cloze tests. Unlike conventional
approaches that rely primarily on supervised learning or static generative
models, our method employs a dual reward structure with adaptive scaling that
differentiates between human-created gold standard distractors and
model-generated candidates. The framework dynamically adjusts reward signal
intensity based on model performance and confidence. We evaluate our approach
on both passage-level (CLOTH-F) and sentence-level (MCQ) cloze test datasets,
demonstrating consistent improvements over state-of-the-art baselines.
Experimental results show that our adaptive reward scaling mechanism provides
modest but consistent benefits on homogeneous datasets (CLOTH-F) and more
substantial improvements (3.48-3.86% in P@1) on diverse, cross-domain data
(MCQ), suggesting its particular effectiveness for handling varied question
types and domains. Our work offers a flexible framework that effectively
balances learning from reliable human examples while exploring novel,
high-quality distractors for automated test generation.

</details>


### [27] [BlockBPE: Parallel BPE Tokenization](https://arxiv.org/abs/2507.11941)
*Amos You*

Main category: cs.CL

TL;DR: BlockBPE是一种并行GPU实现的BPE算法，优化了批量推理工作流，比现有方法快2-2.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有CPU绑定的BPE实现（如HuggingFace Tokenizers和tiktoken）在批量推理中效率低下，BlockBPE旨在解决这一问题。

Method: BlockBPE通过消除Regex预分词步骤，实现高度并行化的分词合并，复杂度降至O(nd)。

Result: 在高批量推理任务中，BlockBPE的吞吐量比tiktoken高2倍，比HuggingFace Tokenizers高2.5倍。

Conclusion: BlockBPE显著提升了GPU上的分词效率，适合高吞吐量场景。

Abstract: Tokenization is a critical preprocessing step in large language model
pipelines, yet widely-used implementations remain CPU-bound and suboptimal for
batch inference workflows on GPU. We present BlockBPE, a parallel GPU
implementation of byte-pair encoding (BPE) that achieves near linear-time
complexity under realistic assumptions and is optimized for high-throughput,
batch inference. Unlike existing Rust-based tokenizers such as HuggingFace
Tokenizers or OpenAI's tiktoken-whose runtimes are dominated by Regex
pre-tokenization and exhibit $O(n \log n)$ runtime-BlockBPE eliminates the
Regex pre-tokenization which leads to small loss in generation quality, but
enables highly parallelized token merges within thread blocks, reducing overall
complexity to $O(nd)$ where $d \ll n$. On high-batch inference workloads,
BlockBPE achieves up to 2x higher throughput than tiktoken and 2.5x over
HuggingFace Tokenizers.

</details>


### [28] [LLMs Encode Harmfulness and Refusal Separately](https://arxiv.org/abs/2507.11878)
*Jiachen Zhao,Jing Huang,Zhengxuan Wu,David Bau,Weiyan Shi*

Main category: cs.CL

TL;DR: LLMs internally encode harmfulness as a separate concept from refusal, and steering along these directions reveals distinct behaviors. This insight enables a practical safety application called Latent Guard.


<details>
  <summary>Details</summary>
Motivation: To understand if LLMs truly grasp harmfulness beyond just refusing harmful instructions, and to explore their internal safety mechanisms.

Method: Identified separate harmfulness and refusal directions in LLMs, tested their effects through steering, and developed Latent Guard as a safety application.

Result: Harmfulness is encoded separately from refusal; certain jailbreak methods reduce refusal signals without altering harmfulness beliefs. Latent Guard performs comparably to dedicated safeguard models.

Conclusion: LLMs' internal understanding of harmfulness is robust, offering a new perspective for AI safety research and applications.

Abstract: LLMs are trained to refuse harmful instructions, but do they truly understand
harmfulness beyond just refusing? Prior work has shown that LLMs' refusal
behaviors can be mediated by a one-dimensional subspace, i.e., a refusal
direction. In this work, we identify a new dimension to analyze safety
mechanisms in LLMs, i.e., harmfulness, which is encoded internally as a
separate concept from refusal. There exists a harmfulness direction that is
distinct from the refusal direction. As causal evidence, steering along the
harmfulness direction can lead LLMs to interpret harmless instructions as
harmful, but steering along the refusal direction tends to elicit refusal
responses directly without reversing the model's judgment on harmfulness.
Furthermore, using our identified harmfulness concept, we find that certain
jailbreak methods work by reducing the refusal signals without reversing the
model's internal belief of harmfulness. We also find that adversarially
finetuning models to accept harmful instructions has minimal impact on the
model's internal belief of harmfulness. These insights lead to a practical
safety application: The model's latent harmfulness representation can serve as
an intrinsic safeguard (Latent Guard) for detecting unsafe inputs and reducing
over-refusals that is robust to finetuning attacks. For instance, our Latent
Guard achieves performance comparable to or better than Llama Guard 3 8B, a
dedicated finetuned safeguard model, across different jailbreak methods. Our
findings suggest that LLMs' internal understanding of harmfulness is more
robust than their refusal decision to diverse input instructions, offering a
new perspective to study AI safety

</details>


### [29] [Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language Models](https://arxiv.org/abs/2507.11882)
*Bo Zeng,Chenyang Lyu,Sinuo Liu,Mingyan Zeng,Minghao Wu,Xuanfan Ni,Tianqi Shi,Yu Zhao,Yefeng Liu,Chenyu Zhu,Ruizhe Li,Jiahui Geng,Qing Li,Yu Tong,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 论文提出了一个多语言指令跟随基准Marco-Bench-MIF，覆盖30种语言，解决了现有数据集在语言和文化适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有指令跟随数据集多为英语或机器翻译，限制了多语言场景的适用性。

Method: 通过结合翻译与验证的混合流程，创建了本地化的多语言版本Marco-Bench-MIF。

Result: 评估发现高低资源语言间存在25-35%的准确率差距，模型规模影响性能45-60%，机器翻译数据低估准确率7-22%。

Conclusion: Marco-Bench-MIF揭示了多语言指令跟随的挑战，如关键词一致性和跨语言约束遵循。

Abstract: Instruction-following capability has become a major ability to be evaluated
for Large Language Models (LLMs). However, existing datasets, such as IFEval,
are either predominantly monolingual and centered on English or simply machine
translated to other languages, limiting their applicability in multilingual
contexts. In this paper, we present an carefully-curated extension of IFEval to
a localized multilingual version named Marco-Bench-MIF, covering 30 languages
with varying levels of localization. Our benchmark addresses linguistic
constraints (e.g., modifying capitalization requirements for Chinese) and
cultural references (e.g., substituting region-specific company names in
prompts) via a hybrid pipeline combining translation with verification. Through
comprehensive evaluation of 20+ LLMs on our Marco-Bench-MIF, we found that: (1)
25-35% accuracy gap between high/low-resource languages, (2) model scales
largely impact performance by 45-60% yet persists script-specific challenges,
and (3) machine-translated data underestimates accuracy by7-22% versus
localized data. Our analysis identifies challenges in multilingual instruction
following, including keyword consistency preservation and compositional
constraint adherence across languages. Our Marco-Bench-MIF is available at
https://github.com/AIDC-AI/Marco-Bench-MIF.

</details>


### [30] [A Survey of Deep Learning for Geometry Problem Solving](https://arxiv.org/abs/2507.11936)
*Jianzhe Ma,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: 本文综述了深度学习在几何问题求解中的应用，包括任务总结、方法回顾、评估指标分析及未来挑战讨论。


<details>
  <summary>Details</summary>
Motivation: 几何问题求解是数学推理的关键领域，涉及教育和人工智能评估等多个重要领域，深度学习技术的发展推动了相关研究。

Method: 通过综述方法，总结了几何问题求解的任务、深度学习方法、评估指标及未来方向。

Result: 提供了深度学习在几何问题求解中的全面参考，并创建了持续更新的论文列表。

Conclusion: 本文旨在促进几何问题求解领域的进一步发展，为研究提供实用参考。

Abstract: Geometry problem solving is a key area of mathematical reasoning, which is
widely involved in many important fields such as education, mathematical
ability assessment of artificial intelligence, and multimodal ability
assessment. In recent years, the rapid development of deep learning technology,
especially the rise of multimodal large language models, has triggered a
widespread research boom. This paper provides a survey of the applications of
deep learning in geometry problem solving, including (i) a comprehensive
summary of the relevant tasks in geometry problem solving; (ii) a thorough
review of related deep learning methods; (iii) a detailed analysis of
evaluation metrics and methods; and (iv) a critical discussion of the current
challenges and future directions that can be explored. Our goal is to provide a
comprehensive and practical reference of deep learning for geometry problem
solving to promote further developments in this field. We create a continuously
updated list of papers on GitHub: https://github.com/majianz/dl4gps.

</details>


### [31] [POLYCHARTQA: Benchmarking Large Vision-Language Models with Multilingual Chart Question Answering](https://arxiv.org/abs/2507.11939)
*Yichen Xu,Liangyu Chen,Liang Zhang,Wenxuan Wang,Qin Jin*

Main category: cs.CL

TL;DR: PolyChartQA是一个多语言图表问答基准，覆盖10种语言，旨在解决现有基准的英语中心化问题。


<details>
  <summary>Details</summary>
Motivation: 现有图表理解基准主要针对英语，限制了其全球适用性。

Method: 采用解耦管道生成多语言图表，结合先进LLM翻译和严格质量控制。

Result: 实验显示英语与其他语言（尤其是非拉丁文字的低资源语言）存在显著性能差距。

Conclusion: PolyChartQA为推进全球包容性视觉语言模型奠定了基础。

Abstract: Charts are a universally adopted medium for interpreting and communicating
data. However, existing chart understanding benchmarks are predominantly
English-centric, limiting their accessibility and applicability to global
audiences. In this paper, we present PolyChartQA, the first large-scale
multilingual chart question answering benchmark covering 22,606 charts and
26,151 question-answering pairs across 10 diverse languages. PolyChartQA is
built using a decoupled pipeline that separates chart data from rendering code,
allowing multilingual charts to be flexibly generated by simply translating the
data and reusing the code. We leverage state-of-the-art LLM-based translation
and enforce rigorous quality control in the pipeline to ensure the linguistic
and semantic consistency of the generated multilingual charts. PolyChartQA
facilitates systematic evaluation of multilingual chart understanding.
Experiments on both open- and closed-source large vision-language models reveal
a significant performance gap between English and other languages, especially
low-resource ones with non-Latin scripts. This benchmark lays a foundation for
advancing globally inclusive vision-language models.

</details>


### [32] [DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression](https://arxiv.org/abs/2507.11942)
*Yi Zhao,Zuchao Li,Hai Zhao,Baoyuan Qi,Guoming Liu*

Main category: cs.CL

TL;DR: 论文提出了一种动态注意力感知的任务无关提示压缩方法（DAC），通过结合信息熵和注意力信息，动态感知压缩过程中的熵变化，实现细粒度压缩。实验证明DAC在多领域任务和LLMs中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖信息熵压缩词汇单元，但忽略了注意力关键令牌和压缩过程中熵的变化。

Method: 提出动态注意力感知方法（DAC），整合熵和注意力信息，动态感知熵变化。

Result: 在LongBench、GSM8K和BBH等多个领域的实验中，DAC表现稳健且显著优于现有方法。

Conclusion: DAC通过动态整合熵和注意力信息，实现了高效的提示压缩，适用于多种任务和LLMs。

Abstract: Task-agnostic prompt compression leverages the redundancy in natural language
to reduce computational overhead and enhance information density within
prompts, especially in long-context scenarios. Existing methods predominantly
rely on information entropy as the metric to compress lexical units, aiming to
achieve minimal information loss. However, these approaches overlook two
critical aspects: (i) the importance of attention-critical tokens at the
algorithmic level, and (ii) shifts in information entropy during the
compression process. Motivated by these challenges, we propose a dynamic
attention-aware approach for task-agnostic prompt compression (DAC). This
approach effectively integrates entropy and attention information, dynamically
sensing entropy shifts during compression to achieve fine-grained prompt
compression. Extensive experiments across various domains, including LongBench,
GSM8K, and BBH, show that DAC consistently yields robust and substantial
improvements across a diverse range of tasks and LLMs, offering compelling
evidence of its efficacy.

</details>


### [33] [IAM: Efficient Inference through Attention Mapping between Different-scale LLMs](https://arxiv.org/abs/2507.11953)
*Yi Zhao,Zuchao Li,Hai Zhao*

Main category: cs.CL

TL;DR: IAM框架通过利用不同规模LLM间注意力矩阵的高相似性，优化注意力计算和KV缓存使用，提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在长上下文中的资源消耗问题，现有方法未充分利用外部信息。

Method: 分析注意力矩阵相似性，提出IAM框架，实现小规模与大规模LLM间的注意力映射。

Result: IAM加速预填充15%，减少KV缓存使用22.1%，且性能损失小。

Conclusion: IAM具有通用性，与现有KV缓存优化方法正交，是提升LLM效率的有效工具。

Abstract: LLMs encounter significant challenges in resource consumption nowadays,
especially with long contexts. Despite extensive efforts dedicate to enhancing
inference efficiency, these methods primarily exploit internal sparsity within
the models, without leveraging external information for optimization. We
identify the high similarity of attention matrices across different-scale LLMs,
which offers a novel perspective for optimization. We first conduct a
comprehensive analysis of how to measure similarity, how to select mapping
Layers and whether mapping is consistency. Based on these insights, we
introduce the IAM framework, which achieves dual benefits of accelerated
attention computation and reduced KV cache usage by performing attention
mapping between small and large LLMs. Our experimental results demonstrate that
IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without
appreciably sacrificing performance. Experiments on different series of models
show the generalizability of IAM. Importantly, it is also orthogonal to many
existing KV cache optimization methods, making it a versatile addition to the
current toolkit for enhancing LLM efficiency.

</details>


### [34] [The benefits of query-based KGQA systems for complex and temporal questions in LLM era](https://arxiv.org/abs/2507.11954)
*Artem Alekseev,Mikhail Chaichuk,Miron Butko,Alexander Panchenko,Elena Tutubalina,Oleg Somov*

Main category: cs.CL

TL;DR: 论文提出了一种基于查询的多阶段知识图谱问答框架，用于提升多跳和时间问题的性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多跳推理和时间问题上的不足，提供模块化替代方案。

Method: 采用多阶段查询生成框架，结合新颖的实体链接和谓词匹配方法，利用CoT推理。

Result: 在多跳和时间问答数据集上表现出色，展示了小型语言模型的潜力。

Conclusion: 基于查询的多阶段框架能有效提升多跳和时间问答性能。

Abstract: Large language models excel in question-answering (QA) yet still struggle
with multi-hop reasoning and temporal questions. Query-based knowledge graph QA
(KGQA) offers a modular alternative by generating executable queries instead of
direct answers. We explore multi-stage query-based framework for WikiData QA,
proposing multi-stage approach that enhances performance on challenging
multi-hop and temporal benchmarks. Through generalization and rejection
studies, we evaluate robustness across multi-hop and temporal QA datasets.
Additionally, we introduce a novel entity linking and predicate matching method
using CoT reasoning. Our results demonstrate the potential of query-based
multi-stage KGQA framework for improving multi-hop and temporal QA with small
language models. Code and data: https://github.com/ar2max/NLDB-KGQA-System

</details>


### [35] [PoTPTQ: A Two-step Power-of-Two Post-training for LLMs](https://arxiv.org/abs/2507.11959)
*Xinyu Wang,Vahid Partovi Nia,Peng Lu,Jerry Huang,Xiao-Wen Chang,Boxing Chen,Yufei Cui*

Main category: cs.CL

TL;DR: 论文提出了一种新型的PoT量化框架，用于LLM权重，显著提升了低精度格式的准确性，并通过高效反量化加速推理。


<details>
  <summary>Details</summary>
Motivation: LLMs部署因高计算资源需求而困难，现有PoT量化在GPU上效果不佳。

Method: 提出两步骤后训练算法：初始化量化尺度并优化，实现高效反量化。

Result: 在2-和3-bit格式下超越现有整数量化方法，反量化速度提升显著。

Conclusion: 新型PoT量化框架在低精度和推理速度上优于现有方法。

Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing (NLP) tasks. However, their deployment is
challenging due to the substantial computational resources required.
Power-of-two (PoT) quantization is a general tool to counteract this
difficulty. Albeit previous works on PoT quantization can be efficiently
dequantized on CPUs using fixed-point addition, it showed less effectiveness on
GPUs. The reason is entanglement of the sign bit and sequential bit
manipulations needed for dequantization. We propose a novel POT quantization
framework for LLM weights that (i) outperforms state-of-the-art accuracy in
extremely low-precision number formats, and (ii) enables faster inference
through more efficient dequantization. To maintain the accuracy of the
quantized model, we introduce a two-step post-training algorithm: (i)
initialize the quantization scales with a robust starting point, and (ii)
refine these scales using a minimal calibration set. The performance of our PoT
post-training algorithm surpasses the current state-of-the-art in integer
quantization, particularly at low precisions such as 2- and 3-bit formats. Our
PoT quantization accelerates the dequantization step required for the floating
point inference and leads to $3.67\times$ speed up on a NVIDIA V100, and
$1.63\times$ on a NVIDIA RTX 4090, compared to uniform integer dequantization.

</details>


### [36] [Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation](https://arxiv.org/abs/2507.11966)
*Ziyu Ge,Gabriel Chua,Leanne Tan,Roy Ka-Wei Lee*

Main category: cs.CL

TL;DR: 提出了一种两阶段框架，用于在低资源语言对中保留毒性内容的翻译，以新加坡英语为例，通过人工验证的少样本提示工程和模型优化，提高了翻译质量和文化敏感性。


<details>
  <summary>Details</summary>
Motivation: 在线交流中，低资源语言和方言的翻译系统常无法保留本地俚语、混合代码和文化嵌入的有害言论标记，需要一种能处理毒性内容的方法。

Method: 1. 人工验证的少样本提示工程，筛选和排序新加坡英语示例；2. 通过直接和回译优化模型-提示对。

Result: 定量人工评估证实了框架的有效性和效率，提高了翻译质量并支持文化敏感的审核。

Conclusion: 该框架不仅提升了翻译质量，还通过支持低资源环境中的文化敏感审核，强调了在现实应用中保留社会语言细微差别的重要性。

Abstract: As online communication increasingly incorporates under-represented languages
and colloquial dialects, standard translation systems often fail to preserve
local slang, code-mixing, and culturally embedded markers of harmful speech.
Translating toxic content between low-resource language pairs poses additional
challenges due to scarce parallel data and safety filters that sanitize
offensive expressions. In this work, we propose a reproducible, two-stage
framework for toxicity-preserving translation, demonstrated on a code-mixed
Singlish safety corpus. First, we perform human-verified few-shot prompt
engineering: we iteratively curate and rank annotator-selected Singlish-target
examples to capture nuanced slang, tone, and toxicity. Second, we optimize
model-prompt pairs by benchmarking several large language models using semantic
similarity via direct and back-translation. Quantitative human evaluation
confirms the effectiveness and efficiency of our pipeline. Beyond improving
translation quality, our framework contributes to the safety of multicultural
LLMs by supporting culturally sensitive moderation and benchmarking in
low-resource contexts. By positioning Singlish as a testbed for inclusive NLP,
we underscore the importance of preserving sociolinguistic nuance in real-world
applications such as content moderation and regional platform governance.

</details>


### [37] [Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker](https://arxiv.org/abs/2507.11972)
*Yuhong Zhang,Jialu Li,Shilai Yang,Yuchen Xu,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.CL

TL;DR: 研究比较了人类与大型语言模型（LLMs）在阅读理解中的表现，通过图结构分析发现LLMs在语言理解上具有高度一致性。


<details>
  <summary>Details</summary>
Motivation: 探索人类与LLMs在语言理解上的差异，以优化人机协同学习策略。

Method: 使用LLM将文本转化为图结构（节点和边），并通过眼动数据验证重要节点的注视分布。

Result: LLMs在图拓扑结构层面表现出高度一致的语言理解能力。

Conclusion: 研究为人类与AI的协同学习提供了新视角，验证了图结构分析的潜力。

Abstract: Reading comprehension is a fundamental skill in human cognitive development.
With the advancement of Large Language Models (LLMs), there is a growing need
to compare how humans and LLMs understand language across different contexts
and apply this understanding to functional tasks such as inference, emotion
interpretation, and information retrieval. Our previous work used LLMs and
human biomarkers to study the reading comprehension process. The results showed
that the biomarkers corresponding to words with high and low relevance to the
inference target, as labeled by the LLMs, exhibited distinct patterns,
particularly when validated using eye-tracking data. However, focusing solely
on individual words limited the depth of understanding, which made the
conclusions somewhat simplistic despite their potential significance. This
study used an LLM-based AI agent to group words from a reading passage into
nodes and edges, forming a graph-based text representation based on semantic
meaning and question-oriented prompts. We then compare the distribution of eye
fixations on important nodes and edges. Our findings indicate that LLMs exhibit
high consistency in language understanding at the level of graph topological
structure. These results build on our previous findings and offer insights into
effective human-AI co-learning strategies.

</details>


### [38] [Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness](https://arxiv.org/abs/2507.11979)
*Yuki Sakamoto,Takahisa Uchida,Hiroshi Ishiguro*

Main category: cs.CL

TL;DR: 研究探讨了价值相似性对LLM代理关系建立的影响，发现价值相似性高的代理之间信任和亲密感更强。


<details>
  <summary>Details</summary>
Motivation: 探索人工社会中价值相似性是否像人类社会一样影响关系建立。

Method: 通过两个实验：初步实验评估LLM中价值可控性，主实验分析价值相似性对代理间信任和亲密感的影响。

Result: 价值相似性高的代理对表现出更强的信任和亲密感。

Conclusion: LLM代理模拟可作为社会科学理论的有效测试平台，并揭示了价值影响关系建立的机制。

Abstract: Large language models (LLMs) have emerged as powerful tools for simulating
complex social phenomena using human-like agents with specific traits. In human
societies, value similarity is important for building trust and close
relationships; however, it remains unexplored whether this principle holds true
in artificial societies comprising LLM agents. Therefore, this study
investigates the influence of value similarity on relationship-building among
LLM agents through two experiments. First, in a preliminary experiment, we
evaluated the controllability of values in LLMs to identify the most effective
model and prompt design for controlling the values. Subsequently, in the main
experiment, we generated pairs of LLM agents imbued with specific values and
analyzed their mutual evaluations of trust and interpersonal closeness
following a dialogue. The experiments were conducted in English and Japanese to
investigate language dependence. The results confirmed that pairs of agents
with higher value similarity exhibited greater mutual trust and interpersonal
closeness. Our findings demonstrate that the LLM agent simulation serves as a
valid testbed for social science theories, contributes to elucidating the
mechanisms by which values influence relationship building, and provides a
foundation for inspiring new theories and insights into the social sciences.

</details>


### [39] [Simplifications are Absolutists: How Simplified Language Reduces Word Sense Awareness in LLM-Generated Definitions](https://arxiv.org/abs/2507.11981)
*Lukas Ellinger,Miriam Anschütz,Georg Groh*

Main category: cs.CL

TL;DR: 研究探讨了简化对多义词定义质量的影响，发现简化会显著降低定义的完整性，增加误解风险。通过微调模型，可以显著提升多义词定义的质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在不同目标群体（如儿童或语言学习者）中提供多义词定义时，简化可能导致关键信息丢失，误导用户。

Method: 使用两种新的评估数据集，测试多个LLM模型（如DeepSeek v3、Llama 4等），并通过LLM-as-Judge和人工标注评估简化对定义质量的影响。

Result: 简化显著降低了定义的完整性，但通过微调Llama 3.1 8B模型，可以显著提升多义词定义的质量。

Conclusion: 教育NLP需要在简单性和完整性之间取得平衡，以确保为所有学习者提供可靠、上下文感知的定义。

Abstract: Large Language Models (LLMs) can provide accurate word definitions and
explanations for any context. However, the scope of the definition changes for
different target groups, like children or language learners. This is especially
relevant for homonyms, words with multiple meanings, where oversimplification
might risk information loss by omitting key senses, potentially misleading
users who trust LLM outputs. We investigate how simplification impacts homonym
definition quality across three target groups: Normal, Simple, and ELI5. Using
two novel evaluation datasets spanning multiple languages, we test DeepSeek v3,
Llama 4 Maverick, Qwen3-30B A3B, GPT-4o mini, and Llama 3.1 8B via LLM-as-Judge
and human annotations. Our results show that simplification drastically
degrades definition completeness by neglecting polysemy, increasing the risk of
misunderstanding. Fine-tuning Llama 3.1 8B with Direct Preference Optimization
substantially improves homonym response quality across all prompt types. These
findings highlight the need to balance simplicity and completeness in
educational NLP to ensure reliable, context-aware definitions for all learners.

</details>


### [40] [Improving Data and Parameter Efficiency of Neural Language Models Using Representation Analysis](https://arxiv.org/abs/2507.12004)
*Josip Jukić*

Main category: cs.CL

TL;DR: 该论文研究了神经语言模型中的数据与参数效率问题，提出了基于表示平滑性的新优化技术，并结合主动学习和参数高效微调，显著提升了模型性能与效率。


<details>
  <summary>Details</summary>
Motivation: 解决神经语言模型在数据与参数效率方面的挑战，通过表示分析和优化技术提升模型的鲁棒性和泛化能力。

Method: 1. 分析语言表示特性并提出基于Jacobian和Hessian矩阵的平滑性正则化方法；2. 结合主动学习与参数高效微调，提出无需验证集的早停技术；3. 利用上下文学习增强弱监督，有效利用未标注数据。

Result: 实验表明，这些方法在性能、稳定性和效率上显著优于传统方法，尤其在低资源环境中表现突出。

Conclusion: 论文提出的技术显著提升了语言模型的数据与参数效率，为低资源场景提供了实用解决方案。

Abstract: This thesis addresses challenges related to data and parameter efficiency in
neural language models, with a focus on representation analysis and the
introduction of new optimization techniques. The first part examines the
properties and dynamics of language representations within neural models,
emphasizing their significance in enhancing robustness and generalization. It
proposes innovative approaches based on representation smoothness, including
regularization strategies that utilize Jacobian and Hessian matrices to
stabilize training and mitigate sensitivity to input perturbations. The second
part focuses on methods to significantly enhance data and parameter efficiency
by integrating active learning strategies with parameter-efficient fine-tuning,
guided by insights from representation smoothness analysis. It presents
smoothness-informed early-stopping techniques designed to eliminate the need
for labeled validation sets and proposes innovative combinations of active
learning and parameter-efficient fine-tuning to reduce labeling efforts and
computational resources. Extensive experimental evaluations across various NLP
tasks demonstrate that these combined approaches substantially outperform
traditional methods in terms of performance, stability, and efficiency. The
third part explores weak supervision techniques enhanced by in-context learning
to effectively utilize unlabeled data, further reducing dependence on extensive
labeling. It shows that using in-context learning as a mechanism for weak
supervision enables models to better generalize from limited labeled data by
leveraging unlabeled examples more effectively during training. Comprehensive
empirical evaluations confirm significant gains in model accuracy,
adaptability, and robustness, especially in low-resource settings and dynamic
data environments.

</details>


### [41] [A Comparative Approach to Assessing Linguistic Creativity of Large Language Models and Humans](https://arxiv.org/abs/2507.12039)
*Anca Dinu,Andra-Maria Florescu,Alina Resceanu*

Main category: cs.CL

TL;DR: 论文介绍了一种通用的语言创造力测试，用于评估人类和大型语言模型（LLMs）在生成新词和短语方面的能力。结果显示，LLMs在所有评估标准上均优于人类，且在八项任务中的六项表现更好。人类更倾向于扩展性创造力（E-creativity），而LLMs则偏向固定性创造力（F-creativity）。


<details>
  <summary>Details</summary>
Motivation: 评估人类和LLMs在语言创造力方面的差异，探索LLMs在生成新词和短语上的能力。

Method: 设计包含多种任务的测试，评估生成新词和短语的能力，使用OCSAI工具自动评估答案的原创性、精细度和灵活性。

Result: LLMs在所有评估标准上优于人类，且在六项任务中表现更好。人类更倾向于E-creativity，LLMs则偏向F-creativity。

Conclusion: LLMs在语言创造力方面表现优异，但与人类的创造力类型存在差异，未来研究可进一步探索这种差异的深层原因。

Abstract: The following paper introduces a general linguistic creativity test for
humans and Large Language Models (LLMs). The test consists of various tasks
aimed at assessing their ability to generate new original words and phrases
based on word formation processes (derivation and compounding) and on
metaphorical language use. We administered the test to 24 humans and to an
equal number of LLMs, and we automatically evaluated their answers using OCSAI
tool for three criteria: Originality, Elaboration, and Flexibility. The results
show that LLMs not only outperformed humans in all the assessed criteria, but
did better in six out of the eight test tasks. We then computed the uniqueness
of the individual answers, which showed some minor differences between humans
and LLMs. Finally, we performed a short manual analysis of the dataset, which
revealed that humans are more inclined towards E(extending)-creativity, while
LLMs favor F(ixed)-creativity.

</details>


### [42] [Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited](https://arxiv.org/abs/2507.12059)
*Anthony G Cohn,Robert E Blackwell*

Main category: cs.CL

TL;DR: 研究测试了28种大型语言模型（LLMs）在方向推理任务中的表现，发现即使是较新的大型推理模型也无法在所有问题上可靠地确定正确方向。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在方向推理任务中的能力，探索其局限性。

Method: 使用基于模板生成的基准测试，测试LLMs在不同场景下确定正确方向的能力。

Result: 即使是较新的模型也无法在所有问题上可靠地确定正确方向。

Conclusion: LLMs在方向推理任务中仍存在局限性，需进一步改进。

Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason
about cardinal directions (CDs) using a benchmark generated from a set of
templates, extensively testing an LLM's ability to determine the correct CD
given a particular scenario. The templates allow for a number of degrees of
variation such as means of locomotion of the agent involved, and whether set in
the first, second or third person. Even the newer Large Reasoning Models are
unable to reliably determine the correct CD for all questions. This paper
summarises and extends earlier work presented at COSIT-24.

</details>


### [43] [StylOch at PAN: Gradient-Boosted Trees with Frequency-Based Stylometric Features](https://arxiv.org/abs/2507.12064)
*Jeremi K. Ochab,Mateusz Matias,Tymoteusz Boba,Tomasz Walkowiak*

Main category: cs.CL

TL;DR: 论文提出了一种基于模块化风格计量管道的二元AI检测方法，使用spaCy模型预处理文本并提取特征，采用轻量梯度提升机作为分类器。


<details>
  <summary>Details</summary>
Motivation: 探索一种非神经网络的、计算成本低但可解释的AI生成文本检测方法。

Method: 使用spaCy模型进行文本预处理和特征提取，结合轻量梯度提升机作为分类器，并利用大规模训练集优化参数。

Result: 通过大规模训练集和参数优化，提高了分类器的性能。

Conclusion: 该方法在保持计算效率和可解释性的同时，有效检测AI生成文本。

Abstract: This submission to the binary AI detection task is based on a modular
stylometric pipeline, where: public spaCy models are used for text
preprocessing (including tokenisation, named entity recognition, dependency
parsing, part-of-speech tagging, and morphology annotation) and extracting
several thousand features (frequencies of n-grams of the above linguistic
annotations); light-gradient boosting machines are used as the classifier. We
collect a large corpus of more than 500 000 machine-generated texts for the
classifier's training. We explore several parameter options to increase the
classifier's capacity and take advantage of that training set. Our approach
follows the non-neural, computationally inexpensive but explainable approach
found effective previously.

</details>


### [44] [BOOKCOREF: Coreference Resolution at Book Scale](https://arxiv.org/abs/2507.12075)
*Giuliano Martinelli,Tommaso Bonomo,Pere-Lluís Huguet Cabot,Roberto Navigli*

Main category: cs.CL

TL;DR: 论文提出了BOOKCOREF，首个书籍规模的共指消解基准，解决了现有基准在小到中等规模文档上的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有共指消解基准（如LitBank）无法评估长文本（如书籍规模）的系统能力，需要新的解决方案。

Method: 开发了一种自动标注管道，用于生成高质量的全叙事文本共指消解标注，并创建了BOOKCOREF基准。

Result: 实验表明，该自动流程稳健，BOOKCOREF使当前长文档共指消解系统性能提升高达+20 CoNLL-F1。

Conclusion: BOOKCOREF填补了书籍规模共指消解基准的空白，揭示了当前模型在长文本上的不足，鼓励未来研究。

Abstract: Coreference Resolution systems are typically evaluated on benchmarks
containing small- to medium-scale documents. When it comes to evaluating long
texts, however, existing benchmarks, such as LitBank, remain limited in length
and do not adequately assess system capabilities at the book scale, i.e., when
co-referring mentions span hundreds of thousands of tokens. To fill this gap,
we first put forward a novel automatic pipeline that produces high-quality
Coreference Resolution annotations on full narrative texts. Then, we adopt this
pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with
an average document length of more than 200,000 tokens. We carry out a series
of experiments showing the robustness of our automatic procedure and
demonstrating the value of our resource, which enables current long-document
coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full
books. Moreover, we report on the new challenges introduced by this
unprecedented book-scale setting, highlighting that current models fail to
deliver the same performance they achieve on smaller documents. We release our
data and code to encourage research and development of new book-scale
Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.

</details>


### [45] [Findings of MEGA: Maths Explanation with LLMs using the Socratic Method for Active Learning](https://arxiv.org/abs/2507.12079)
*Tosin Adewumi,Foteini Simistira Liwicki,Marcus Liwicki,Viktor Gardelli,Lama Alkhaled,Hamam Mokayed*

Main category: cs.CL

TL;DR: 研究比较了结合苏格拉底法、思维链推理、简化游戏化和形成性反馈的MEGA方法与传统的逐步思维链方法，发现MEGA在数学学习中更有效，尤其在解决难题时表现更优。


<details>
  <summary>Details</summary>
Motivation: 许多学生在数学学习中遇到困难，导致他们回避数学相关学科。研究旨在通过创新教学方法（MEGA）改善这一问题。

Method: 采用组内设计，随机分配问题给大学生参与者，比较MEGA与传统方法的效果。使用GSM8K和MATH数据集，测试GPT4o和Claude 3.5 Sonnet模型。

Result: MEGA方法在两种数据集上均被学生认为更有利于学习，尤其在MATH数据集中表现显著优于传统方法（47.5% vs 26.67%）。

Conclusion: MEGA方法在数学学习中，尤其是解决难题时，比传统方法更有效。

Abstract: This paper presents an intervention study on the effects of the combined
methods of (1) the Socratic method, (2) Chain of Thought (CoT) reasoning, (3)
simplified gamification and (4) formative feedback on university students'
Maths learning driven by large language models (LLMs). We call our approach
Mathematics Explanations through Games by AI LLMs (MEGA). Some students
struggle with Maths and as a result avoid Math-related discipline or subjects
despite the importance of Maths across many fields, including signal
processing. Oftentimes, students' Maths difficulties stem from suboptimal
pedagogy. We compared the MEGA method to the traditional step-by-step (CoT)
method to ascertain which is better by using a within-group design after
randomly assigning questions for the participants, who are university students.
Samples (n=60) were randomly drawn from each of the two test sets of the Grade
School Math 8K (GSM8K) and Mathematics Aptitude Test of Heuristics (MATH)
datasets, based on the error margin of 11%, the confidence level of 90%, and a
manageable number of samples for the student evaluators. These samples were
used to evaluate two capable LLMs at length (Generative Pretrained Transformer
4o (GPT4o) and Claude 3.5 Sonnet) out of the initial six that were tested for
capability. The results showed that students agree in more instances that the
MEGA method is experienced as better for learning for both datasets. It is even
much better than the CoT (47.5% compared to 26.67%) in the more difficult MATH
dataset, indicating that MEGA is better at explaining difficult Maths problems.

</details>


### [46] [Iterative Augmentation with Summarization Refinement (IASR) Evaluation for Unstructured Survey data Modeling and Analysis](https://arxiv.org/abs/2507.12126)
*Payal Bhattad,Sai Manoj Pudukotai Dinakarrao,Anju Gupta*

Main category: cs.CL

TL;DR: 本文提出了一个评估框架，用于基于大语言模型（LLM）的文本增强，包括可扩展性分析和迭代增强与摘要细化（IASR），验证了GPT-3.5 Turbo在语义保真度、多样性和生成效率上的最佳表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本增强技术在语义保留方面的不足，特别是在大规模或迭代生成中导致的冗余和不稳定性问题。

Method: 提出两个评估组件：可扩展性分析（衡量语义一致性）和迭代增强与摘要细化（IASR，评估递归释义中的语义漂移）。

Result: 实验表明，GPT-3.5 Turbo在语义保真度、多样性和生成效率上表现最佳；在实际任务中，该方法使主题粒度增加400%并完全消除主题重叠。

Conclusion: 验证了所提框架在结构化评估LLM增强技术中的实用性，适用于实际NLP流程。

Abstract: Text data augmentation is a widely used strategy for mitigating data sparsity
in natural language processing (NLP), particularly in low-resource settings
where limited samples hinder effective semantic modeling. While augmentation
can improve input diversity and downstream interpretability, existing
techniques often lack mechanisms to ensure semantic preservation during
large-scale or iterative generation, leading to redundancy and instability.
This work introduces a principled evaluation framework for large language model
(LLM) based text augmentation, comprising two components: (1) Scalability
Analysis, which measures semantic consistency as augmentation volume increases,
and (2) Iterative Augmentation with Summarization Refinement (IASR), which
evaluates semantic drift across recursive paraphrasing cycles. Empirical
evaluations across state-of-the-art LLMs show that GPT-3.5 Turbo achieved the
best balance of semantic fidelity, diversity, and generation efficiency.
Applied to a real-world topic modeling task using BERTopic with GPT-enhanced
few-shot labeling, the proposed approach results in a 400% increase in topic
granularity and complete elimination of topic overlaps. These findings
validated the utility of the proposed frameworks for structured evaluation of
LLM-based augmentation in practical NLP pipelines.

</details>


### [47] [Overview of the Sensemaking Task at the ELOQUENT 2025 Lab: LLMs as Teachers, Students and Evaluators](https://arxiv.org/abs/2507.12143)
*Pavel Šindelář,Ondřej Bojar*

Main category: cs.CL

TL;DR: ELOQUENT的Sensemaking任务评估生成模型通过三步测试（提问、回答、评分），发现LLM在回答和评分任务中存在局限性。


<details>
  <summary>Details</summary>
Motivation: 旨在为生成语言模型建立可测试的高标准评估框架。

Method: 通过三步测试（提问、回答、评分）评估模型，使用多语言和多来源材料，并对比自动与人工评估。

Result: LLM在提问任务中难以评估问题质量，回答任务中表现尚可但受限，评分任务中易误判。

Conclusion: 需改进评估策略，尤其是提问和评分任务，以提升生成模型的可靠性。

Abstract: ELOQUENT is a set of shared tasks that aims to create easily testable
high-level criteria for evaluating generative language models. Sensemaking is
one such shared task.
  In Sensemaking, we try to assess how well generative models ``make sense out
of a given text'' in three steps inspired by exams in a classroom setting: (1)
Teacher systems should prepare a set of questions, (2) Student systems should
answer these questions, and (3) Evaluator systems should score these answers,
all adhering rather strictly to a given set of input materials.
  We report on the 2025 edition of Sensemaking, where we had 7 sources of test
materials (fact-checking analyses of statements, textbooks, transcribed
recordings of a lecture, and educational videos) spanning English, German,
Ukrainian, and Czech languages.
  This year, 4 teams participated, providing us with 2 Teacher submissions, 2
Student submissions, and 2 Evaluator submissions. We added baselines for
Teacher and Student using commercial large language model systems. We devised a
fully automatic evaluation procedure, which we compare to a minimalistic manual
evaluation.
  We were able to make some interesting observations. For the first task, the
creation of questions, better evaluation strategies will still have to be
devised because it is difficult to discern the quality of the various candidate
question sets. In the second task, question answering, the LLMs examined
overall perform acceptably, but restricting their answers to the given input
texts remains problematic. In the third task, evaluation of question answers,
our adversarial tests reveal that systems using the LLM-as-a-Judge paradigm
erroneously rate both garbled question-answer pairs and answers to mixed-up
questions as acceptable.

</details>


### [48] [Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production](https://arxiv.org/abs/2507.12208)
*Michael Carl,Takanori Mizowaki,Aishvarya Ray,Masaru Yamada,Devi Sri Bandaru,Xinyue Ren*

Main category: cs.CL

TL;DR: 论文提出了一种行为翻译风格空间（BTSS），用于描述可能的翻译行为模式，并通过多层结构分析眼动和手指运动等行为数据，揭示背后的认知和情感过程。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解翻译行为背后的高阶认知和情感状态，以及如何通过行为数据揭示这些隐藏的加工结构。

Method: 方法包括分析击键和眼动数据，构建多层次的BTSS模型，并将其作为计算翻译代理的基础。

Result: 研究结果表明，BTSS能够有效模拟翻译过程中的情感、自动行为和认知动态。

Conclusion: 结论指出BTSS为理解翻译行为提供了新视角，并为开发计算翻译代理奠定了基础。

Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that
describes possible behavioural translation patterns. The suggested BTSS is
organized as a hierarchical structure that entails various embedded processing
layers. We posit that observable translation behaviour - i.e., eye and finger
movements - is fundamental when executing the physical act of translation but
it is caused and shaped by higher-order cognitive processes and affective
translation states. We analyse records of keystrokes and gaze data as
indicators of the hidden mental processing structure and organize the
behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the
basis for a computational translation agent to simulate the temporal dynamics
of affect, automatized behaviour and cognition during human translation
production.

</details>


### [49] [Towards few-shot isolated word reading assessment](https://arxiv.org/abs/2507.12217)
*Reuben Smit,Retief Louw,Herman Kamper*

Main category: cs.CL

TL;DR: 研究提出了一种基于自监督学习（SSL）模型的少样本方法，用于低资源环境下孤立词阅读评估，但发现SSL表示在处理儿童语音时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 在低资源环境中，传统的自动语音识别（ASR）方法可能不适用，因此需要探索替代方案。

Method: 使用SSL模型的中间层编码输入儿童语音和成人参考模板，并研究离散化SSL特征和模板的质心平均等设计选项。

Result: 实验显示，成人语音表现良好，但儿童语音输入性能显著下降，即使使用儿童模板。

Conclusion: 尽管SSL表示在低资源语音任务中表现良好，但在少样本分类系统中处理儿童数据时存在局限性。

Abstract: We explore an ASR-free method for isolated word reading assessment in
low-resource settings. Our few-shot approach compares input child speech to a
small set of adult-provided reference templates. Inputs and templates are
encoded using intermediate layers from large self-supervised learned (SSL)
models. Using an Afrikaans child speech benchmark, we investigate design
options such as discretising SSL features and barycentre averaging of the
templates. Idealised experiments show reasonable performance for adults, but a
substantial drop for child speech input, even with child templates. Despite the
success of employing SSL representations in low-resource speech tasks, our work
highlights the limitations of SSL representations for processing child data
when used in a few-shot classification system.

</details>


### [50] [Improving Contextual ASR via Multi-grained Fusion with Large Language Models](https://arxiv.org/abs/2507.12252)
*Shilin Zhou,Zhenghua Li*

Main category: cs.CL

TL;DR: 提出了一种多粒度融合方法，结合了词级和短语级融合的优势，利用大语言模型（LLM）提升自动语音识别（ASR）中关键词识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR模型在通用语音转录中表现良好，但在识别上下文相关的关键词（如专有名词或用户特定实体）时表现不佳。

Method: 提出了一种多粒度融合方法，结合了词级和短语级融合的优势，并采用后融合策略将ASR的声学信息与LLM的上下文知识相结合。

Result: 在中英文数据集上的实验表明，该方法在关键词相关指标上达到了最先进的性能，同时保持了非关键词文本的高准确性。

Conclusion: 词级和短语级组件在多粒度框架中相互补充，显著提升了性能，代码和模型将公开。

Abstract: While end-to-end Automatic Speech Recognition (ASR) models have shown
impressive performance in transcribing general speech, they often struggle to
accurately recognize contextually relevant keywords, such as proper nouns or
user-specific entities.
  Previous approaches have explored leveraging keyword dictionaries in the
textual modality to improve keyword recognition, either through token-level
fusion that guides token-by-token generation or phrase-level fusion that
enables direct copying of keyword phrases.
  However, these methods operate at different granularities and have their own
limitations.
  In this paper, we propose a novel multi-grained fusion approach that jointly
leverages the strengths of both token-level and phrase-level fusion with Large
Language Models (LLMs).
  Our approach incorporates a late-fusion strategy that elegantly combines
ASR's acoustic information with LLM's rich contextual knowledge, balancing
fine-grained token precision with holistic phrase-level understanding.
  Experiments on Chinese and English datasets demonstrate that our approach
achieves state-of-the-art performance on keyword-related metrics while
preserving high accuracy on non-keyword text.
  Ablation studies further confirm that the token-level and phrase-level
components both contribute significantly to the performance gains,
complementing each other in our joint multi-grained framework.
  The code and models will be publicly available at https://github.com/.

</details>


### [51] [Translationese-index: Using Likelihood Ratios for Graded and Generalizable Measurement of Translationese](https://arxiv.org/abs/2507.12260)
*Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu*

Main category: cs.CL

TL;DR: 提出了一种新的量化翻译腔的指标T-index，通过对比微调的语言模型计算，验证了其鲁棒性和高效性。


<details>
  <summary>Details</summary>
Motivation: 量化翻译腔（translationese）的测量，填补现有机器翻译质量评估指标的不足。

Method: 使用对比微调的语言模型计算T-index，并通过合成数据集和真实翻译数据集验证其通用性和有效性。

Result: T-index能有效捕捉翻译腔，与人工标注相关性高（Pearson's r=0.568），且与现有MT质量评估指标相关性低。

Conclusion: T-index可作为机器翻译质量评估的补充指标，具有实际应用价值。

Abstract: In this paper, we propose the first quantitative measure for translationese
-- the translationese-index (T-index) for graded and generalizable measurement
of translationese, computed from the likelihood ratios of two contrastively
fine-tuned language models (LMs). We use a synthesized dataset and a dataset
with translations in the wild to evaluate T-index's generalizability in
cross-domain settings and its validity against human judgments. Our results
show that T-index is both robust and efficient. T-index scored by two 0.5B LMs
fine-tuned on only 1-5k pairs of synthetic data can well capture translationese
in the wild. We find that the relative differences in T-indices between
translations can well predict pairwise translationese annotations obtained from
human annotators; and the absolute values of T-indices correlate well with
human ratings of degrees of translationese (Pearson's $r = 0.568$).
Additionally, the correlation between T-index and existing machine translation
(MT) quality estimation (QE) metrics such as BLEU and COMET is low, suggesting
that T-index is not covered by these metrics and can serve as a complementary
metric in MT QE.

</details>


### [52] [Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes](https://arxiv.org/abs/2507.12261)
*Johann Frei,Nils Feldhus,Lisa Raithel,Roland Roller,Alexander Meyer,Frank Kramer*

Main category: cs.CL

TL;DR: Infherno是一个基于LLM代理、代码执行和医学术语数据库的端到端框架，用于将自由格式的临床笔记转换为结构化FHIR资源，解决了现有方法的泛化性和结构一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如模块化规则系统或LLM指令调优）在将临床笔记转换为FHIR资源时泛化性和结构一致性不足。

Method: 提出Infherno框架，结合LLM代理、代码执行和医学术语数据库工具，确保生成的FHIR资源符合文档模式。

Result: Infherno在预测FHIR资源方面表现接近人类基线，支持临床数据集成和跨机构互操作性。

Conclusion: Infherno通过端到端框架有效解决了临床笔记到FHIR资源的转换问题，提升了泛化性和结构一致性。

Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard
has established itself as a desirable format for interoperability between
complex health data. Previous attempts at automating the translation from
free-form clinical notes into structured FHIR resources rely on modular,
rule-based systems or LLMs with instruction tuning and constrained decoding.
Since they frequently suffer from limited generalizability and structural
inconformity, we propose an end-to-end framework powered by LLM agents, code
execution, and healthcare terminology database tools to address these issues.
Our solution, called Infherno, is designed to adhere to the FHIR document
schema and competes well with a human baseline in predicting FHIR resources
from unstructured text. The implementation features a front end for custom and
synthetic data and both local and proprietary models, supporting clinical data
integration processes and interoperability across institutions.

</details>


### [53] [Text-ADBench: Text Anomaly Detection Benchmark based on LLMs Embedding](https://arxiv.org/abs/2507.12295)
*Feng Xiao,Jicong Fan*

Main category: cs.CL

TL;DR: 该论文提出了一个文本异常检测的基准测试，通过多种预训练语言模型和多领域数据集系统评估了嵌入质量对异常检测效果的影响，并开源了工具包。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准化的基准测试，现有文本异常检测方法的评估和比较受到限制，阻碍了创新方法的发展。

Method: 利用多种预训练语言模型（如GloVe、BERT、LLaMa等）的嵌入，结合多领域文本数据集和全面的评估指标（如AUROC、AUPRC），进行系统评估。

Result: 研究发现嵌入质量对异常检测效果至关重要，且深度学习方法在LLM嵌入下并未优于传统浅层算法（如KNN、Isolation Forest）。此外，跨模型性能矩阵表现出低秩特性。

Conclusion: 该工作为未来研究提供了基准工具包，支持高效模型评估和选择，推动了文本异常检测系统的稳健性和可扩展性研究。

Abstract: Text anomaly detection is a critical task in natural language processing
(NLP), with applications spanning fraud detection, misinformation
identification, spam detection and content moderation, etc. Despite significant
advances in large language models (LLMs) and anomaly detection algorithms, the
absence of standardized and comprehensive benchmarks for evaluating the
existing anomaly detection methods on text data limits rigorous comparison and
development of innovative approaches. This work performs a comprehensive
empirical study and introduces a benchmark for text anomaly detection,
leveraging embeddings from diverse pre-trained language models across a wide
array of text datasets. Our work systematically evaluates the effectiveness of
embedding-based text anomaly detection by incorporating (1) early language
models (GloVe, BERT); (2) multiple LLMs (LLaMa-2, LLama-3, Mistral, OpenAI
(small, ada, large)); (3) multi-domain text datasets (news, social media,
scientific publications); (4) comprehensive evaluation metrics (AUROC, AUPRC).
Our experiments reveal a critical empirical insight: embedding quality
significantly governs anomaly detection efficacy, and deep learning-based
approaches demonstrate no performance advantage over conventional shallow
algorithms (e.g., KNN, Isolation Forest) when leveraging LLM-derived
embeddings.In addition, we observe strongly low-rank characteristics in
cross-model performance matrices, which enables an efficient strategy for rapid
model evaluation (or embedding evaluation) and selection in practical
applications. Furthermore, by open-sourcing our benchmark toolkit that includes
all embeddings from different models and code at
https://github.com/jicongfan/Text-Anomaly-Detection-Benchmark, this work
provides a foundation for future research in robust and scalable text anomaly
detection systems.

</details>


### [54] [Chain-of-Descriptions: Improving Code LLMs for VHDL Code Generation and Summarization](https://arxiv.org/abs/2507.12308)
*Prashanth Vijayaraghavan,Apoorva Nitsure,Charles Mackin,Luyao Shi,Stefano Ambrogio,Arvind Haran,Viresh Paruthi,Ali Elzein,Dan Coops,David Beymer,Tyler Baldwin,Ehsan Degan*

Main category: cs.CL

TL;DR: 该论文评估了现有代码LLMs在VHDL代码生成和摘要任务中的表现，发现其性能不足，并提出了一种名为Chain-of-Descriptions (CoDes)的新方法以显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在通用代码任务中表现优异，但在硬件描述语言（如VHDL）中的研究和优化不足，亟需填补这一空白。

Method: 提出CoDes方法，通过生成一系列中间描述步骤（基于问题陈述或VHDL代码），并将其与原始输入结合，以提升LLMs的性能。

Result: 实验表明，CoDes方法在VHDL-Eval和VHDL-Xform数据集上显著优于标准提示策略。

Conclusion: CoDes不仅提升了VHDL代码生成和摘要的质量，还为未来优化代码LLMs提供了框架。

Abstract: Large Language Models (LLMs) have become widely used across diverse NLP tasks
and domains, demonstrating their adaptability and effectiveness. In the realm
of Electronic Design Automation (EDA), LLMs show promise for tasks like
Register-Transfer Level (RTL) code generation and summarization. However,
despite the proliferation of LLMs for general code-related tasks, there's a
dearth of research focused on evaluating and refining these models for hardware
description languages (HDLs), notably VHDL. In this study, we evaluate the
performance of existing code LLMs for VHDL code generation and summarization
using various metrics and two datasets -- VHDL-Eval and VHDL-Xform. The latter,
an in-house dataset, aims to gauge LLMs' understanding of functionally
equivalent code. Our findings reveal consistent underperformance of these
models across different metrics, underscoring a significant gap in their
suitability for this domain. To address this challenge, we propose
Chain-of-Descriptions (CoDes), a novel approach to enhance the performance of
LLMs for VHDL code generation and summarization tasks. CoDes involves
generating a series of intermediate descriptive steps based on: (i) the problem
statement for code generation, and (ii) the VHDL code for summarization. These
steps are then integrated with the original input prompt (problem statement or
code) and provided as input to the LLMs to generate the final output. Our
experiments demonstrate that the CoDes approach significantly surpasses the
standard prompting strategy across various metrics on both datasets. This
method not only improves the quality of VHDL code generation and summarization
but also serves as a framework for future research aimed at enhancing code LLMs
for VHDL.

</details>


### [55] [Exploring Gender Bias in Alzheimer's Disease Detection: Insights from Mandarin and Greek Speech Perception](https://arxiv.org/abs/2507.12356)
*Liu He,Yuanchao Li,Rui Feng,XinRan Han,Yin-Long Liu,Yuwei Yang,Zude Zhu,Jiahong Yuan*

Main category: cs.CL

TL;DR: 研究发现阿尔茨海默病（AD）语音感知中存在性别偏见，男性语音更易被识别为AD，尤其是在中文语音中。声学分析显示男性语音的shimmer值与AD感知显著相关。


<details>
  <summary>Details</summary>
Motivation: 探究性别偏见在AD语音感知中的影响，为开发更公平的AD检测模型提供依据。

Method: 通过16名中文听众对中文和希腊语音的感知实验，结合声学分析（如shimmer值和语音部分）。

Result: 男性语音更频繁被识别为AD，shimmer值与AD感知显著相关，语言对AD感知无显著影响。

Conclusion: 性别偏见在AD语音感知中起关键作用，需在模型开发中解决，并进一步验证跨语言性能。

Abstract: Gender bias has been widely observed in speech perception tasks, influenced
by the fundamental voicing differences between genders. This study reveals a
gender bias in the perception of Alzheimer's Disease (AD) speech. In a
perception experiment involving 16 Chinese listeners evaluating both Chinese
and Greek speech, we identified that male speech was more frequently identified
as AD, with this bias being particularly pronounced in Chinese speech. Acoustic
analysis showed that shimmer values in male speech were significantly
associated with AD perception, while speech portion exhibited a significant
negative correlation with AD identification. Although language did not have a
significant impact on AD perception, our findings underscore the critical role
of gender bias in AD speech perception. This work highlights the necessity of
addressing gender bias when developing AD detection models and calls for
further research to validate model performance across different linguistic
contexts.

</details>


### [56] [Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate](https://arxiv.org/abs/2507.12370)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CL

TL;DR: 论文提出了一种多智能体辩论框架，用于提升大语言模型（LLMs）在检测和解决用户请求模糊性方面的能力，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在处理用户请求时存在模糊性问题，需要更有效的方法来提升其理解和解决能力。

Method: 设计了基于三种LLM架构（Llama3-8B、Gemma2-9B和Mistral-7B变体）的多智能体辩论框架，并使用包含多样模糊性的数据集进行评估。

Result: 辩论框架显著提升了Llama3-8B和Mistral-7B变体的性能，其中Mistral-7B主导的辩论成功率高达76.7%，尤其在复杂模糊性和高效共识方面表现突出。

Conclusion: 多智能体辩论框架是一种有效的方法，能够增强LLM的能力，为开发更鲁棒和自适应的语言理解系统提供了重要启示。

Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in
understanding and generating human language, contributing to more natural
interactions with complex systems. However, they face challenges such as
ambiguity in user requests processed by LLMs. To address these challenges, this
paper introduces and evaluates a multi-agent debate framework designed to
enhance detection and resolution capabilities beyond single models. The
framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and
Mistral-7B variants) and a dataset with diverse ambiguities. The debate
framework markedly enhanced the performance of Llama3-8B and Mistral-7B
variants over their individual baselines, with Mistral-7B-led debates achieving
a notable 76.7% success rate and proving particularly effective for complex
ambiguities and efficient consensus. While acknowledging varying model
responses to collaborative strategies, these findings underscore the debate
framework's value as a targeted method for augmenting LLM capabilities. This
work offers important insights for developing more robust and adaptive language
understanding systems by showing how structured debates can lead to improved
clarity in interactive systems.

</details>


### [57] [Web-Browsing LLMs Can Access Social Media Profiles and Infer User Demographics](https://arxiv.org/abs/2507.12372)
*Meysam Alizadeh,Fabrizio Gilardi,Zeynab Samei,Mohsen Mosleh*

Main category: cs.CL

TL;DR: 论文探讨了具备网页浏览能力的大型语言模型（LLMs）如何通过用户名推断社交媒体用户的 demographics，展示了其潜力与风险。


<details>
  <summary>Details</summary>
Motivation: 传统LLMs依赖静态数据，而具备实时网页浏览能力的LLMs可以访问社交媒体内容，但其对社交媒体数据的直接检索与分析能力尚未被研究。

Method: 使用合成数据集（48个X/Twitter账户）和调查数据集（1,384名国际参与者），评估LLMs通过用户名推断用户 demographics 的能力。

Result: LLMs能够访问社交媒体内容并较准确地预测用户 demographics，但可能引入性别和政治偏见。

Conclusion: 该能力对计算社会科学有潜力，但也存在滥用风险，建议限制公共应用中的使用，仅保留已验证研究用途的受控访问。

Abstract: Large language models (LLMs) have traditionally relied on static training
data, limiting their knowledge to fixed snapshots. Recent advancements,
however, have equipped LLMs with web browsing capabilities, enabling real time
information retrieval and multi step reasoning over live web content. While
prior studies have demonstrated LLMs ability to access and analyze websites,
their capacity to directly retrieve and analyze social media data remains
unexplored. Here, we evaluate whether web browsing LLMs can infer demographic
attributes of social media users given only their usernames. Using a synthetic
dataset of 48 X (Twitter) accounts and a survey dataset of 1,384 international
participants, we show that these models can access social media content and
predict user demographics with reasonable accuracy. Analysis of the synthetic
dataset further reveals how LLMs parse and interpret social media profiles,
which may introduce gender and political biases against accounts with minimal
activity. While this capability holds promise for computational social science
in the post API era, it also raises risks of misuse particularly in information
operations and targeted advertising underscoring the need for safeguards. We
recommend that LLM providers restrict this capability in public facing
applications, while preserving controlled access for verified research
purposes.

</details>


### [58] [Probing for Arithmetic Errors in Language Models](https://arxiv.org/abs/2507.12379)
*Yucheng Sun,Alessandro Stolfo,Mrinmaya Sachan*

Main category: cs.CL

TL;DR: 论文研究了语言模型内部激活是否能用于检测算术错误，通过简单探针解码隐藏状态，训练轻量级错误检测器，并扩展到复杂任务，最终证明探针能指导选择性重新提示，提高任务准确性。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型内部激活是否能够检测算术错误，以实现轻量级的模型自我纠正。

Method: 从3位数加法开始，训练简单探针解码隐藏状态；扩展到结构化思维链任务，训练轻量级错误检测器；利用探针指导选择性重新提示。

Result: 探针能准确解码模型预测和正确答案；错误检测器准确率超90%；探针在复杂任务中表现良好，能提高任务准确性。

Conclusion: 算术错误可通过内部激活预测，简单探针为轻量级模型自我纠正提供了可行路径。

Abstract: We investigate whether internal activations in language models can be used to
detect arithmetic errors. Starting with a controlled setting of 3-digit
addition, we show that simple probes can accurately decode both the model's
predicted output and the correct answer from hidden states, regardless of
whether the model's output is correct. Building on this, we train lightweight
error detectors that predict model correctness with over 90% accuracy. We then
extend our analysis to structured chain-of-thought traces on addition-only
GSM8K problems and find that probes trained on simple arithmetic generalize
well to this more complex setting, revealing consistent internal
representations. Finally, we demonstrate that these probes can guide selective
re-prompting of erroneous reasoning steps, improving task accuracy with minimal
disruption to correct outputs. Our findings suggest that arithmetic errors can
be anticipated from internal activations alone, and that simple probes offer a
viable path toward lightweight model self-correction.

</details>


### [59] [Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data](https://arxiv.org/abs/2507.12425)
*Chandana Cheerla*

Main category: cs.CL

TL;DR: 提出了一种改进的RAG框架，结合混合检索策略和元数据感知过滤，显著提升了企业数据处理的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在处理异构企业数据时的局限性，如静态预训练、短上下文窗口和格式多样性问题。

Method: 采用混合检索策略（密集嵌入和BM25）、元数据过滤、语义分块和量化索引，结合人工反馈和对话记忆。

Result: 实验显示Precision@5提升15%，Recall@5提升13%，Mean Reciprocal Rank提升16%，定性评估得分显著提高。

Conclusion: 该框架能有效提供准确、全面且上下文相关的企业任务响应，未来将扩展至多模态数据和代理检索。

Abstract: Organizations increasingly rely on proprietary enterprise data, including HR
records, structured reports, and tabular documents, for critical
decision-making. While Large Language Models (LLMs) have strong generative
capabilities, they are limited by static pretraining, short context windows,
and challenges in processing heterogeneous data formats. Conventional
Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but
often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval
strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by
metadata-aware filtering with SpaCy NER and cross-encoder reranking. The
framework applies semantic chunking to maintain textual coherence and retains
tabular data structures to preserve row-column integrity. Quantized indexing
optimizes retrieval efficiency, while human-in-the-loop feedback and
conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5
increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74),
and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative
evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness
(4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale.
These results demonstrate the framework's effectiveness in delivering accurate,
comprehensive, and contextually relevant responses for enterprise tasks. Future
work includes extending to multimodal data and integrating agent-based
retrieval. The source code will be released at
https://github.com/CheerlaChandana/Enterprise-Chatbot

</details>


### [60] [Can We Predict Alignment Before Models Finish Thinking? Towards Monitoring Misaligned Reasoning Models](https://arxiv.org/abs/2507.12428)
*Yik Siu Chan,Zheng-Xin Yong,Stephen H. Bach*

Main category: cs.CL

TL;DR: 通过分析推理语言模型的思维链（CoTs）预测最终输出的安全性，发现基于激活的线性探针优于文本方法，且能提前预测。


<details>
  <summary>Details</summary>
Motivation: 研究思维链（CoTs）是否可用于预测最终输出的有害内容，以提升模型安全性。

Method: 评估多种监控方法（人类、大语言模型、文本分类器），比较基于CoT文本和激活的预测效果。

Result: 基于CoT激活的线性探针显著优于文本方法，能提前预测安全性，且结果泛化性强。

Conclusion: 轻量级探针可实现实时安全监控，为生成过程提供早期干预。

Abstract: Open-weights reasoning language models generate long chains-of-thought (CoTs)
before producing a final response, which improves performance but introduces
additional alignment risks, with harmful content often appearing in both the
CoTs and the final outputs. In this work, we investigate if we can use CoTs to
predict final response misalignment. We evaluate a range of monitoring
approaches, including humans, highly-capable large language models, and text
classifiers, using either CoT text or activations. First, we find that a simple
linear probe trained on CoT activations can significantly outperform all
text-based methods in predicting whether a final response will be safe or
unsafe. CoT texts are often unfaithful and can mislead humans and classifiers,
while model latents (i.e., CoT activations) offer a more reliable predictive
signal. Second, the probe makes accurate predictions before reasoning
completes, achieving strong performance even when applied to early CoT
segments. These findings generalize across model sizes, families, and safety
benchmarks, suggesting that lightweight probes could enable real-time safety
monitoring and early intervention during generation.

</details>


### [61] [S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling](https://arxiv.org/abs/2507.12451)
*Suman Adhya,Debarshi Kumar Sanyal*

Main category: cs.CL

TL;DR: S2WTM提出了一种新的主题建模方法，通过利用球形切片Wasserstein距离解决VAE-NTMs中的后验坍塌问题，生成更一致和多样化的主题。


<details>
  <summary>Details</summary>
Motivation: VAE-NTMs在建模高维文本数据的超球面潜在表示时，常因KL散度项消失导致后验坍塌，影响潜在表示效果。

Method: S2WTM采用单位超球面上的先验分布，并利用球形切片Wasserstein距离对齐后验分布与先验。

Result: 实验表明，S2WTM优于现有主题模型，生成的主题更一致和多样化，且在下游任务中表现更好。

Conclusion: S2WTM有效解决了后验坍塌问题，提升了主题建模的性能。

Abstract: Modeling latent representations in a hyperspherical space has proven
effective for capturing directional similarities in high-dimensional text data,
benefiting topic modeling. Variational autoencoder-based neural topic models
(VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical
structure. However, VAE-NTMs often suffer from posterior collapse, where the KL
divergence term in the objective function highly diminishes, leading to
ineffective latent representations. To mitigate this issue while modeling
hyperspherical structure in the latent space, we propose the Spherical Sliced
Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior
distribution supported on the unit hypersphere and leverages the Spherical
Sliced-Wasserstein distance to align the aggregated posterior distribution with
the prior. Experimental results demonstrate that S2WTM outperforms
state-of-the-art topic models, generating more coherent and diverse topics
while improving performance on downstream tasks.

</details>


### [62] [Language Models Improve When Pretraining Data Matches Target Tasks](https://arxiv.org/abs/2507.12466)
*David Mizrahi,Anders Boesen Lindbo Larsen,Jesse Allardice,Suzie Petryk,Yuri Gorokhov,Jeffrey Li,Alex Fang,Josh Gardner,Tom Gunter,Afshin Dehghan*

Main category: cs.CL

TL;DR: 论文提出了一种名为BETR的显式优化数据选择方法，通过将预训练文档与基准测试示例对齐，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索显式优化数据选择对模型性能的影响，而非传统的隐式迭代优化。

Method: 提出BETR方法，通过嵌入基准示例和预训练文档到共享空间，基于相似性评分选择数据，并训练轻量级分类器预测全库分数。

Result: 实验表明，BETR在10项任务中的9项上表现优于基线，计算效率提升2.1倍，且适用于不同规模的模型。

Conclusion: 结论是直接匹配预训练数据与目标任务能精确塑造模型能力，且数据选择策略需根据模型规模调整。

Abstract: Every data selection method inherently has a target. In practice, these
targets often emerge implicitly through benchmark-driven iteration: researchers
develop selection strategies, train models, measure benchmark performance, then
refine accordingly. This raises a natural question: what happens when we make
this optimization explicit? To explore this, we propose benchmark-targeted
ranking (BETR), a simple method that selects pretraining documents based on
similarity to benchmark training examples. BETR embeds benchmark examples and a
sample of pretraining documents in a shared space, scores this sample by
similarity to benchmarks, then trains a lightweight classifier to predict these
scores for the full corpus. We compare data selection methods by training over
500 models spanning $10^{19}$ to $10^{22}$ FLOPs and fitting scaling laws to
them. From this, we find that simply aligning pretraining data to evaluation
benchmarks using BETR achieves a 2.1x compute multiplier over DCLM-Baseline
(4.7x over unfiltered data) and improves performance on 9 out of 10 tasks
across all scales. BETR also generalizes well: when targeting a diverse set of
benchmarks disjoint from our evaluation suite, it still matches or outperforms
baselines. Our scaling analysis further reveals a clear trend: larger models
require less aggressive filtering. Overall, our findings show that directly
matching pretraining data to target tasks precisely shapes model capabilities
and highlight that optimal selection strategies must adapt to model scale.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [63] [An Memory-Efficient Framework for Deformable Transformer with Neural Architecture Search](https://arxiv.org/abs/2507.11549)
*Wendong Mao,Mingfan Zhao,Jianfeng Guan,Qiwei Dong,Zhongfeng Wang*

Main category: cs.CV

TL;DR: 本文提出了一种硬件友好的优化框架，用于解决可变形注意力变换器（DAT）在硬件部署中的内存访问问题，通过NAS和切片策略优化性能。


<details>
  <summary>Details</summary>
Motivation: DAT在计算机视觉任务中表现出色，但其数据依赖的采样机制导致不规则内存访问模式，难以高效部署。现有方法要么硬件开销高，要么牺牲模型精度。

Method: 提出基于神经架构搜索（NAS）的切片策略，自动划分输入特征为均匀块；设计FPGA验证系统测试性能。

Result: 在ImageNet-1K上，精度仅下降0.2%；在FPGA上，DRAM访问次数减少至现有方法的18%。

Conclusion: 该框架在保持精度的同时显著提升了硬件效率，适用于边缘计算场景。

Abstract: Deformable Attention Transformers (DAT) have shown remarkable performance in
computer vision tasks by adaptively focusing on informative image regions.
However, their data-dependent sampling mechanism introduces irregular memory
access patterns, posing significant challenges for efficient hardware
deployment. Existing acceleration methods either incur high hardware overhead
or compromise model accuracy. To address these issues, this paper proposes a
hardware-friendly optimization framework for DAT. First, a neural architecture
search (NAS)-based method with a new slicing strategy is proposed to
automatically divide the input feature into uniform patches during the
inference process, avoiding memory conflicts without modifying model
architecture. The method explores the optimal slice configuration by jointly
optimizing hardware cost and inference accuracy. Secondly, an FPGA-based
verification system is designed to test the performance of this framework on
edge-side hardware. Algorithm experiments on the ImageNet-1K dataset
demonstrate that our hardware-friendly framework can maintain have only 0.2%
accuracy drop compared to the baseline DAT. Hardware experiments on Xilinx FPGA
show the proposed method reduces DRAM access times to 18% compared with
existing DAT acceleration methods.

</details>


### [64] [Deformable Dynamic Convolution for Accurate yet Efficient Spatio-Temporal Traffic Prediction](https://arxiv.org/abs/2507.11550)
*Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim*

Main category: cs.CV

TL;DR: 论文提出了一种名为DDCN的新方法，用于高效且准确的时空交通预测，解决了传统方法在异构性和可扩展性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如GNN）在捕捉时空异构性和处理大规模数据时存在局限性，需要预定义邻接矩阵且计算复杂。

Method: DDCN通过动态应用可变形滤波器，结合编码器-解码器结构和注意力机制，提升对重要特征的捕捉能力。

Result: 在四个真实数据集上的实验表明，DDCN性能优越，验证了CNN方法在时空交通预测中的潜力。

Conclusion: DDCN是一种高效且准确的时空交通预测方法，克服了传统方法的局限性。

Abstract: Spatio-temporal traffic prediction plays a key role in intelligent
transportation systems by enabling accurate prediction in complex urban areas.
Although not only accuracy but also efficiency for scalability is important,
some previous methods struggle to capture heterogeneity such as varying traffic
patterns across regions and time periods. Moreover, Graph Neural Networks
(GNNs), which are the mainstream of traffic prediction, not only require
predefined adjacency matrix, but also limit scalability to large-scale data
containing many nodes due to their inherent complexity. To overcome these
limitations, we propose Deformable Dynamic Convolution Network (DDCN) for
accurate yet efficient traffic prediction. Traditional Convolutional Neural
Networks (CNNs) are limited in modeling non-Euclidean spatial structures and
spatio-temporal heterogeneity, DDCN overcomes these challenges by dynamically
applying deformable filters based on offset. Specifically, DDCN decomposes
transformer-style CNN to encoder-decoder structure, and applies proposed
approaches to the spatial and spatio-temporal attention blocks of the encoder
to emphasize important features. The decoder, composed of feed-forward module,
complements the output of the encoder. This novel structure make DDCN can
perform accurate yet efficient traffic prediction. In comprehensive experiments
on four real-world datasets, DDCN achieves competitive performance, emphasizing
the potential and effectiveness of CNN-based approaches for spatio-temporal
traffic prediction.

</details>


### [65] [Inversion-DPO: Precise and Efficient Post-Training for Diffusion Models](https://arxiv.org/abs/2507.11554)
*Zejian Li,Yize Li,Chenye Meng,Zhongni Liu,Yang Ling,Shengyuan Zhang,Guang Yang,Changyuan Yang,Zhiyuan Yang,Lingyun Sun*

Main category: cs.CV

TL;DR: Inversion-DPO是一种新的对齐框架，通过DDIM反演优化扩散模型，无需奖励模型，提高了训练效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法计算开销大且可能影响模型精度，Inversion-DPO旨在解决这些问题。

Method: 利用DDIM反演将DPO应用于扩散模型，避免了奖励建模和后验采样的复杂性。

Result: 在文本到图像生成和组合图像生成任务中表现优异，生成高保真且组合一致的图像。

Conclusion: Inversion-DPO为扩散模型的高效高精度对齐提供了新途径，适用于复杂生成任务。

Abstract: Recent advancements in diffusion models (DMs) have been propelled by
alignment methods that post-train models to better conform to human
preferences. However, these approaches typically require computation-intensive
training of a base model and a reward model, which not only incurs substantial
computational overhead but may also compromise model accuracy and training
efficiency. To address these limitations, we propose Inversion-DPO, a novel
alignment framework that circumvents reward modeling by reformulating Direct
Preference Optimization (DPO) with DDIM inversion for DMs. Our method conducts
intractable posterior sampling in Diffusion-DPO with the deterministic
inversion from winning and losing samples to noise and thus derive a new
post-training paradigm. This paradigm eliminates the need for auxiliary reward
models or inaccurate appromixation, significantly enhancing both precision and
efficiency of training. We apply Inversion-DPO to a basic task of text-to-image
generation and a challenging task of compositional image generation. Extensive
experiments show substantial performance improvements achieved by Inversion-DPO
compared to existing post-training methods and highlight the ability of the
trained generative models to generate high-fidelity compositionally coherent
images. For the post-training of compostitional image geneation, we curate a
paired dataset consisting of 11,140 images with complex structural annotations
and comprehensive scores, designed to enhance the compositional capabilities of
generative models. Inversion-DPO explores a new avenue for efficient,
high-precision alignment in diffusion models, advancing their applicability to
complex realistic generation tasks. Our code is available at
https://github.com/MIGHTYEZ/Inversion-DPO

</details>


### [66] [Reprogramming Vision Foundation Models for Spatio-Temporal Forecasting](https://arxiv.org/abs/2507.11558)
*Changlu Chen,Yanbin Liu,Chaoxi Niu,Ling Chen,Tianqing Zhu*

Main category: cs.CV

TL;DR: ST-VFM是一个新颖的框架，通过重新编程视觉基础模型（VFMs）来解决时空预测任务中的时空建模问题，采用双分支架构和两个专用重编程阶段，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在自然语言处理和计算机视觉中表现出色，但在时空预测任务中，大型语言模型（LLMs）难以捕捉丰富的时空相关性。ST-VFM旨在利用VFMs的空间先验知识，解决其缺乏时间建模能力和模态差异的问题。

Method: ST-VFM采用双分支架构，结合原始时空输入和辅助时空流输入，并通过两个重编程阶段（预VFM和后VFM）嵌入时间上下文和动态交互。

Result: 在十个时空数据集上的实验表明，ST-VFM优于现有基线，展示了其在不同VFM主干（如DINO、CLIP、DEIT）中的有效性和鲁棒性。

Conclusion: ST-VFM是一个强大的通用框架，为时空预测任务提供了一种有效的解决方案。

Abstract: Foundation models have achieved remarkable success in natural language
processing and computer vision, demonstrating strong capabilities in modeling
complex patterns. While recent efforts have explored adapting large language
models (LLMs) for time-series forecasting, LLMs primarily capture
one-dimensional sequential dependencies and struggle to model the richer
spatio-temporal (ST) correlations essential for accurate ST forecasting. In
this paper, we present \textbf{ST-VFM}, a novel framework that systematically
reprograms Vision Foundation Models (VFMs) for general-purpose spatio-temporal
forecasting. While VFMs offer powerful spatial priors, two key challenges arise
when applying them to ST tasks: (1) the lack of inherent temporal modeling
capacity and (2) the modality gap between visual and ST data. To address these,
ST-VFM adopts a \emph{dual-branch architecture} that integrates raw ST inputs
with auxiliary ST flow inputs, where the flow encodes lightweight temporal
difference signals interpretable as dynamic spatial cues. To effectively
process these dual-branch inputs, ST-VFM introduces two dedicated reprogramming
stages. The \emph{pre-VFM reprogramming} stage applies a Temporal-Aware Token
Adapter to embed temporal context and align both branches into VFM-compatible
feature spaces. The \emph{post-VFM reprogramming} stage introduces a Bilateral
Cross-Prompt Coordination module, enabling dynamic interaction between branches
through prompt-based conditioning, thus enriching joint representation learning
without modifying the frozen VFM backbone. Extensive experiments on ten
spatio-temporal datasets show that ST-VFM outperforms state-of-the-art
baselines, demonstrating effectiveness and robustness across VFM backbones
(e.g., DINO, CLIP, DEIT) and ablation studies, establishing it as a strong
general framework for spatio-temporal forecasting.

</details>


### [67] [Expert Operational GANS: Towards Real-Color Underwater Image Restoration](https://arxiv.org/abs/2507.11562)
*Ozer Can Devecioglu,Serkan Kiranyaz,Mehmet Yamac,Moncef Gabbouj*

Main category: cs.CV

TL;DR: xOp-GAN是一种新型GAN模型，通过多个专家生成器网络解决水下图像恢复问题，每个生成器专注于特定质量范围的图像恢复，并通过判别器选择最佳结果。


<details>
  <summary>Details</summary>
Motivation: 传统单生成器GAN模型难以应对水下图像恢复中复杂的视觉退化问题，因此需要一种能覆盖多种质量范围的方法。

Method: 提出xOp-GAN，包含多个专家生成器，每个生成器针对特定质量范围的图像进行训练，判别器在推理阶段选择最佳恢复结果。

Result: 在LSUI数据集上，xOp-GAN的PSNR达到25.16 dB，显著优于单回归器模型。

Conclusion: xOp-GAN通过多生成器结构和判别器的动态选择机制，显著提升了水下图像恢复的性能。

Abstract: The wide range of deformation artifacts that arise from complex light
propagation, scattering, and depth-dependent attenuation makes the underwater
image restoration to remain a challenging problem. Like other single deep
regressor networks, conventional GAN-based restoration methods struggle to
perform well across this heterogeneous domain, since a single generator network
is typically insufficient to capture the full range of visual degradations. In
order to overcome this limitation, we propose xOp-GAN, a novel GAN model with
several expert generator networks, each trained solely on a particular subset
with a certain image quality. Thus, each generator can learn to maximize its
restoration performance for a particular quality range. Once a xOp-GAN is
trained, each generator can restore the input image and the best restored image
can then be selected by the discriminator based on its perceptual confidence
score. As a result, xOP-GAN is the first GAN model with multiple generators
where the discriminator is being used during the inference of the regression
task. Experimental results on benchmark Large Scale Underwater Image (LSUI)
dataset demonstrates that xOp-GAN achieves PSNR levels up to 25.16 dB,
surpassing all single-regressor models by a large margin even, with reduced
complexity.

</details>


### [68] [Data-Driven Meta-Analysis and Public-Dataset Evaluation for Sensor-Based Gait Age Estimation](https://arxiv.org/abs/2507.11571)
*Varun Velankar*

Main category: cs.CV

TL;DR: 该论文通过元分析和实验研究，评估了步态识别年龄的准确性，并提出了降低误差的实用指南。


<details>
  <summary>Details</summary>
Motivation: 步态识别年龄在医疗、安全和人机交互中有重要应用，需要提高准确性。

Method: 结合元分析、大规模实验（如ResNet34模型和Grad-CAM）和多传感器融合技术。

Result: 卷积神经网络平均误差为4.2年，多传感器融合可降至3.4年；深度网络准确率高达96%。

Conclusion: 通过综合方法，论文为实际应用中步态年龄误差降至3年以下提供了基准和指南。

Abstract: Estimating a person's age from their gait has important applications in
healthcare, security and human-computer interaction. In this work, we review
fifty-nine studies involving over seventy-five thousand subjects recorded with
video, wearable and radar sensors. We observe that convolutional neural
networks produce an average error of about 4.2 years, inertial-sensor models
about 4.5 years and multi-sensor fusion as low as 3.4 years, with notable
differences between lab and real-world data. We then analyse sixty-three
thousand eight hundred forty-six gait cycles from the OU-ISIR Large-Population
dataset to quantify correlations between age and five key metrics: stride
length, walking speed, step cadence, step-time variability and joint-angle
entropy, with correlation coefficients of at least 0.27. Next, we fine-tune a
ResNet34 model and apply Grad-CAM to reveal that the network attends to the
knee and pelvic regions, consistent with known age-related gait changes.
Finally, on a one hundred thousand sample subset of the VersatileGait database,
we compare support vector machines, decision trees, random forests, multilayer
perceptrons and convolutional neural networks, finding that deep networks
achieve up to 96 percent accuracy while processing each sample in under 0.1
seconds. By combining a broad meta-analysis with new large-scale experiments
and interpretable visualizations, we establish solid performance baselines and
practical guidelines for reducing gait-age error below three years in
real-world scenarios.

</details>


### [69] [What cat is that? A re-id model for feral cats](https://arxiv.org/abs/2507.11575)
*Victor Caquilpan*

Main category: cs.CV

TL;DR: 论文探讨了利用改进的PPGNet模型（PPGNet-Cat）通过图像识别野猫，以监控其对澳大利亚野生动物的影响。


<details>
  <summary>Details</summary>
Motivation: 野猫对澳大利亚野生动物造成严重威胁，需通过图像识别技术加强监控。

Method: 改进PPGNet模型（PPGNet-Cat），结合对比学习方法如ArcFace损失，适用于野猫图像。

Result: PPGNet-Cat表现优异，mAP达0.86，rank-1准确率0.95。

Conclusion: PPGNet-Cat是一种高效的野猫识别模型，适用于监控工作。

Abstract: Feral cats exert a substantial and detrimental impact on Australian wildlife,
placing them among the most dangerous invasive species worldwide. Therefore,
closely monitoring these cats is essential labour in minimising their effects.
In this context, the potential application of Re-Identification (re-ID) emerges
to enhance monitoring activities for these animals, utilising images captured
by camera traps. This project explores different CV approaches to create a
re-ID model able to identify individual feral cats in the wild. The main
approach consists of modifying a part-pose guided network (PPGNet) model,
initially used in the re-ID of Amur tigers, to be applicable for feral cats.
This adaptation, resulting in PPGNet-Cat, which incorporates specific
modifications to suit the characteristics of feral cats images. Additionally,
various experiments were conducted, particularly exploring contrastive learning
approaches such as ArcFace loss. The main results indicate that PPGNet-Cat
excels in identifying feral cats, achieving high performance with a mean
Average Precision (mAP) of 0.86 and a rank-1 accuracy of 0.95. These outcomes
establish PPGNet-Cat as a competitive model within the realm of re-ID.

</details>


### [70] [SketchDNN: Joint Continuous-Discrete Diffusion for CAD Sketch Generation](https://arxiv.org/abs/2507.11579)
*Sathvik Chereddy,John Femiani*

Main category: cs.CV

TL;DR: SketchDNN提出了一种生成CAD草图的模型，通过统一的连续-离散扩散过程联合建模连续参数和离散类别标签，创新性地使用高斯-Softmax扩散方法，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决CAD草图中原始参数化的异构性和原始元素的排列不变性两大挑战。

Method: 采用高斯-Softmax扩散方法，通过高斯噪声扰动logits并通过softmax变换投影到概率单纯形上。

Result: 在SketchGraphs数据集上，FID从16.04降至7.80，NLL从84.8降至81.33，实现了CAD草图生成的最新水平。

Conclusion: SketchDNN通过创新的扩散方法，显著提升了CAD草图的生成质量，成为该领域的新标杆。

Abstract: We present SketchDNN, a generative model for synthesizing CAD sketches that
jointly models both continuous parameters and discrete class labels through a
unified continuous-discrete diffusion process. Our core innovation is
Gaussian-Softmax diffusion, where logits perturbed with Gaussian noise are
projected onto the probability simplex via a softmax transformation,
facilitating blended class labels for discrete variables. This formulation
addresses 2 key challenges, namely, the heterogeneity of primitive
parameterizations and the permutation invariance of primitives in CAD sketches.
Our approach significantly improves generation quality, reducing Fr\'echet
Inception Distance (FID) from 16.04 to 7.80 and negative log-likelihood (NLL)
from 84.8 to 81.33, establishing a new state-of-the-art in CAD sketch
generation on the SketchGraphs dataset.

</details>


### [71] [Interpretable Prediction of Lymph Node Metastasis in Rectal Cancer MRI Using Variational Autoencoders](https://arxiv.org/abs/2507.11638)
*Benjamin Keel,Aaron Quyn,David Jayne,Maryam Mohsin,Samuel D. Relton*

Main category: cs.CV

TL;DR: 论文提出了一种基于变分自编码器（VAE）的特征编码模型，用于直肠癌淋巴结转移（LNM）的分期诊断，替代了现有方法中的大型预训练卷积神经网络（CNN）。


<details>
  <summary>Details</summary>
Motivation: 现有基于淋巴结大小、形状和纹理形态的放射学标准诊断准确性有限，而VAE通过重建图像直接编码视觉特征，生成解耦且结构化的潜在空间，更具可解释性。

Method: 使用VAE作为特征编码器，结合多层感知机（MLP），在168名未接受新辅助治疗的患者的MRI数据集上进行训练和验证。

Result: 提出的VAE-MLP模型在MRI数据集上达到了最先进的性能，交叉验证指标为AUC 0.86 +/- 0.05，敏感性0.79 +/- 0.06，特异性0.85 +/- 0.05。

Conclusion: VAE-MLP模型在直肠癌LNM分期中表现出色，具有较高的诊断准确性和可解释性。

Abstract: Effective treatment for rectal cancer relies on accurate lymph node
metastasis (LNM) staging. However, radiological criteria based on lymph node
(LN) size, shape and texture morphology have limited diagnostic accuracy. In
this work, we investigate applying a Variational Autoencoder (VAE) as a feature
encoder model to replace the large pre-trained Convolutional Neural Network
(CNN) used in existing approaches. The motivation for using a VAE is that the
generative model aims to reconstruct the images, so it directly encodes visual
features and meaningful patterns across the data. This leads to a disentangled
and structured latent space which can be more interpretable than a CNN. Models
are deployed on an in-house MRI dataset with 168 patients who did not undergo
neo-adjuvant treatment. The post-operative pathological N stage was used as the
ground truth to evaluate model predictions. Our proposed model 'VAE-MLP'
achieved state-of-the-art performance on the MRI dataset, with cross-validated
metrics of AUC 0.86 +/- 0.05, Sensitivity 0.79 +/- 0.06, and Specificity 0.85
+/- 0.05. Code is available at:
https://github.com/benkeel/Lymph_Node_Classification_MIUA.

</details>


### [72] [Posture-Driven Action Intent Inference for Playing style and Fatigue Assessment](https://arxiv.org/abs/2507.11642)
*Abhishek Jaiswal,Nisheeth Srivastava*

Main category: cs.CV

TL;DR: 论文提出了一种基于姿势的心理状态推断方法，通过板球运动验证其有效性，解决了敏感数据收集的挑战。


<details>
  <summary>Details</summary>
Motivation: 姿势推断在疲劳诊断、伤害预防和性能提升中有潜力，但面临敏感数据收集的挑战。体育场景为数据积累提供了替代方案。

Method: 利用板球运动的活动视频，通过运动分析区分攻击性和防守性击球意图。

Result: 方法在区分意图上达到75% F1分数和80% AUC-ROC，表明姿势信号强。

Conclusion: 研究为体育分析和跨领域行为分析提供了通用技术，并解决了数据标注限制。

Abstract: Posture-based mental state inference has significant potential in diagnosing
fatigue, preventing injury, and enhancing performance across various domains.
Such tools must be research-validated with large datasets before being
translated into practice. Unfortunately, such vision diagnosis faces serious
challenges due to the sensitivity of human subject data. To address this, we
identify sports settings as a viable alternative for accumulating data from
human subjects experiencing diverse emotional states. We test our hypothesis in
the game of cricket and present a posture-based solution to identify human
intent from activity videos. Our method achieves over 75\% F1 score and over
80\% AUC-ROC in discriminating aggressive and defensive shot intent through
motion analysis. These findings indicate that posture leaks out strong signals
for intent inference, even with inherent noise in the data pipeline.
Furthermore, we utilize existing data statistics as weak supervision to
validate our findings, offering a potential solution for overcoming data
labelling limitations. This research contributes to generalizable techniques
for sports analytics and also opens possibilities for applying human behavior
analysis across various fields.

</details>


### [73] [VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization](https://arxiv.org/abs/2507.11653)
*Hannah Shafferman,Annika Thomas,Jouko Kinnari,Michael Ricard,Jose Nino,Jonathan How*

Main category: cs.CV

TL;DR: VISTA是一种新型的全局定位框架，通过对象分割、跟踪和子图匹配，解决了视角变化和季节变化带来的定位挑战，性能优于基线方法且内存占用极低。


<details>
  <summary>Details</summary>
Motivation: 解决在无结构环境中因视角变化、季节变化等因素导致的全局定位难题。

Method: 结合前端对象分割与跟踪管道，以及子图对应搜索，利用几何一致性对齐参考帧。

Result: 在季节和倾斜角度数据集上，召回率提升69%，内存占用仅为基线方法的0.6%。

Conclusion: VISTA无需领域特定训练即可实现跨视角和季节的稳定定位，适用于资源受限平台。

Abstract: Global localization is critical for autonomous navigation, particularly in
scenarios where an agent must localize within a map generated in a different
session or by another agent, as agents often have no prior knowledge about the
correlation between reference frames. However, this task remains challenging in
unstructured environments due to appearance changes induced by viewpoint
variation, seasonal changes, spatial aliasing, and occlusions -- known failure
modes for traditional place recognition methods. To address these challenges,
we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame
Alignment), a novel open-set, monocular global localization framework that
combines: 1) a front-end, object-based, segmentation and tracking pipeline,
followed by 2) a submap correspondence search, which exploits geometric
consistencies between environment maps to align vehicle reference frames. VISTA
enables consistent localization across diverse camera viewpoints and seasonal
changes, without requiring any domain-specific training or finetuning. We
evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a
69% improvement in recall over baseline methods. Furthermore, we maintain a
compact object-based map that is only 0.6% the size of the most
memory-conservative baseline, making our approach capable of real-time
implementation on resource-constrained platforms.

</details>


### [74] [Seeing the Signs: A Survey of Edge-Deployable OCR Models for Billboard Visibility Analysis](https://arxiv.org/abs/2507.11730)
*Maciej Szankin,Vidhyananth Venkatasamy,Lihang Ying*

Main category: cs.CV

TL;DR: 论文比较了多模态视觉语言模型（VLMs）与传统CNN-based OCR在户外广告文本识别中的表现，发现轻量级CNN在裁剪文本识别上仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 解决户外广告文本识别在复杂场景下的挑战，验证VLMs与传统方法的优劣。

Method: 系统性地评测了Qwen 2.5 VL 3B、InternVL3和SmolVLM2等VLMs与PaddleOCRv4在公开数据集上的表现，并加入合成天气干扰。

Result: VLMs在整体场景理解上表现优异，但轻量级CNN在裁剪文本识别上更高效且计算成本低。

Conclusion: 轻量级CNN适用于边缘部署，同时公开了天气增强的评测基准和代码以促进未来研究。

Abstract: Outdoor advertisements remain a critical medium for modern marketing, yet
accurately verifying billboard text visibility under real-world conditions is
still challenging. Traditional Optical Character Recognition (OCR) pipelines
excel at cropped text recognition but often struggle with complex outdoor
scenes, varying fonts, and weather-induced visual noise. Recently, multimodal
Vision-Language Models (VLMs) have emerged as promising alternatives, offering
end-to-end scene understanding with no explicit detection step. This work
systematically benchmarks representative VLMs - including Qwen 2.5 VL 3B,
InternVL3, and SmolVLM2 - against a compact CNN-based OCR baseline
(PaddleOCRv4) across two public datasets (ICDAR 2015 and SVT), augmented with
synthetic weather distortions to simulate realistic degradation. Our results
reveal that while selected VLMs excel at holistic scene reasoning, lightweight
CNN pipelines still achieve competitive accuracy for cropped text at a fraction
of the computational cost-an important consideration for edge deployment. To
foster future research, we release our weather-augmented benchmark and
evaluation code publicly.

</details>


### [75] [Beyond Task-Specific Reasoning: A Unified Conditional Generative Framework for Abstract Visual Reasoning](https://arxiv.org/abs/2507.11761)
*Fan Shi,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: 论文提出了一种统一的条件生成求解器（UCGS），旨在通过单一框架解决多种抽象视觉推理（AVR）任务，避免了任务特定设计的需求，并展示了零样本推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前深度AVR求解器通常需要针对不同任务进行特定设计或参数调整，增加了成本和复杂性。本文旨在通过统一框架解决这一问题。

Method: 将AVR任务重新定义为问题面板中目标图像可预测性的估计问题，并训练一个条件生成模型来统一解决多种任务。

Result: 实验表明，UCGS通过多任务训练，能够在多种AVR任务中展示抽象推理能力，并具备零样本推理能力。

Conclusion: UCGS提供了一种高效且通用的方法来解决AVR任务，减少了任务特定设计的依赖，并展示了强大的泛化能力。

Abstract: Abstract visual reasoning (AVR) enables humans to quickly discover and
generalize abstract rules to new scenarios. Designing intelligent systems with
human-like AVR abilities has been a long-standing topic in the artificial
intelligence community. Deep AVR solvers have recently achieved remarkable
success in various AVR tasks. However, they usually use task-specific designs
or parameters in different tasks. In such a paradigm, solving new tasks often
means retraining the model, and sometimes retuning the model architectures,
which increases the cost of solving AVR problems. In contrast to task-specific
approaches, this paper proposes a novel Unified Conditional Generative Solver
(UCGS), aiming to address multiple AVR tasks in a unified framework. First, we
prove that some well-known AVR tasks can be reformulated as the problem of
estimating the predictability of target images in problem panels. Then, we
illustrate that, under the proposed framework, training one conditional
generative model can solve various AVR tasks. The experiments show that with a
single round of multi-task training, UCGS demonstrates abstract reasoning
ability across various AVR tasks. Especially, UCGS exhibits the ability of
zero-shot reasoning, enabling it to perform abstract reasoning on problems from
unseen AVR tasks in the testing phase.

</details>


### [76] [CorrMoE: Mixture of Experts with De-stylization Learning for Cross-Scene and Cross-Domain Correspondence Pruning](https://arxiv.org/abs/2507.11834)
*Peiwen Xia,Tangfei Liao,Wei Zhu,Danhuai Zhao,Jianjun Ke,Kaihao Zhang,Tong Lu,Tao Wang*

Main category: cs.CV

TL;DR: CorrMoE是一个新的对应关系修剪框架，通过去风格化双分支和双融合专家混合模块，提升了跨域和跨场景变化下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稠密对应关系集中剔除异常点时，通常假设视觉域一致，忽视了多样场景结构带来的挑战。

Method: 提出De-stylization Dual Branch处理域偏移，通过风格混合减少域特定表示的影响；设计Bi-Fusion Mixture of Experts模块，通过线性复杂度注意力和动态专家路由自适应整合多视角特征。

Result: 在基准数据集上的实验表明，CorrMoE在准确性和泛化性上优于现有方法。

Conclusion: CorrMoE通过创新的模块设计，有效解决了跨域和跨场景的对应关系修剪问题，代码和预训练模型已开源。

Abstract: Establishing reliable correspondences between image pairs is a fundamental
task in computer vision, underpinning applications such as 3D reconstruction
and visual localization. Although recent methods have made progress in pruning
outliers from dense correspondence sets, they often hypothesize consistent
visual domains and overlook the challenges posed by diverse scene structures.
In this paper, we propose CorrMoE, a novel correspondence pruning framework
that enhances robustness under cross-domain and cross-scene variations. To
address domain shift, we introduce a De-stylization Dual Branch, performing
style mixing on both implicit and explicit graph features to mitigate the
adverse influence of domain-specific representations. For scene diversity, we
design a Bi-Fusion Mixture of Experts module that adaptively integrates
multi-perspective features through linear-complexity attention and dynamic
expert routing. Extensive experiments on benchmark datasets demonstrate that
CorrMoE achieves superior accuracy and generalization compared to
state-of-the-art methods. The code and pre-trained models are available at
https://github.com/peiwenxia/CorrMoE.

</details>


### [77] [ProtoConNet: Prototypical Augmentation and Alignment for Open-Set Few-Shot Image Classification](https://arxiv.org/abs/2507.11845)
*Kexuan Shi,Zhuang Qi,Jingjing Zhu,Lei Meng,Yaochen Zhang,Haibei Huang,Xiangxu Meng*

Main category: cs.CV

TL;DR: ProtoConNet提出了一种结合背景信息的原型增强与对齐方法，通过三个模块提升小样本开放集图像分类的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅利用单张图像的视觉信息，忽略了上下文信息的整合，导致性能受限。

Method: ProtoConNet包含聚类数据选择（CDS）、上下文增强语义细化（CSR）和原型对齐（PA）三个模块，分别用于数据多样性挖掘、上下文整合和特征对齐。

Result: 在两个数据集上的实验表明，ProtoConNet在小样本场景下提升了表示学习效果，并能有效识别开放集样本。

Conclusion: ProtoConNet通过整合上下文信息和优化特征空间，显著优于现有方法。

Abstract: Open-set few-shot image classification aims to train models using a small
amount of labeled data, enabling them to achieve good generalization when
confronted with unknown environments. Existing methods mainly use visual
information from a single image to learn class representations to distinguish
known from unknown categories. However, these methods often overlook the
benefits of integrating rich contextual information. To address this issue,
this paper proposes a prototypical augmentation and alignment method, termed
ProtoConNet, which incorporates background information from different samples
to enhance the diversity of the feature space, breaking the spurious
associations between context and image subjects in few-shot scenarios.
Specifically, it consists of three main modules: the clustering-based data
selection (CDS) module mines diverse data patterns while preserving core
features; the contextual-enhanced semantic refinement (CSR) module builds a
context dictionary to integrate into image representations, which boosts the
model's robustness in various scenarios; and the prototypical alignment (PA)
module reduces the gap between image representations and class prototypes,
amplifying feature distances for known and unknown classes. Experimental
results from two datasets verified that ProtoConNet enhances the effectiveness
of representation learning in few-shot scenarios and identifies open-set
samples, making it superior to existing methods.

</details>


### [78] [From Coarse to Nuanced: Cross-Modal Alignment of Fine-Grained Linguistic Cues and Visual Salient Regions for Dynamic Emotion Recognition](https://arxiv.org/abs/2507.11892)
*Yu Liu,Leyuan Qu,Hanlei Shi,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: GRACE方法通过动态运动建模、语义文本细化和跨模态对齐，提升了动态面部表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用文本中的情感线索，且缺乏有效过滤无关面部动态的机制。

Method: GRACE结合了动态运动建模、语义文本细化（CATE模块）和基于熵正则化最优传输的跨模态对齐。

Result: 在三个基准数据集上，GRACE显著提升了识别性能，特别是在模糊或不平衡情感类别中，达到SOTA。

Conclusion: GRACE通过精细的跨模态对齐和情感感知文本增强，有效解决了DFER中的关键问题。

Abstract: Dynamic Facial Expression Recognition (DFER) aims to identify human emotions
from temporally evolving facial movements and plays a critical role in
affective computing. While recent vision-language approaches have introduced
semantic textual descriptions to guide expression recognition, existing methods
still face two key limitations: they often underutilize the subtle emotional
cues embedded in generated text, and they have yet to incorporate sufficiently
effective mechanisms for filtering out facial dynamics that are irrelevant to
emotional expression. To address these gaps, We propose GRACE, Granular
Representation Alignment for Cross-modal Emotion recognition that integrates
dynamic motion modeling, semantic text refinement, and token-level cross-modal
alignment to facilitate the precise localization of emotionally salient
spatiotemporal features. Our method constructs emotion-aware textual
descriptions via a Coarse-to-fine Affective Text Enhancement (CATE) module and
highlights expression-relevant facial motion through a motion-difference
weighting mechanism. These refined semantic and visual signals are aligned at
the token level using entropy-regularized optimal transport. Experiments on
three benchmark datasets demonstrate that our method significantly improves
recognition performance, particularly in challenging settings with ambiguous or
imbalanced emotion classes, establishing new state-of-the-art (SOTA) results in
terms of both UAR and WAR.

</details>


### [79] [Spatial Frequency Modulation for Semantic Segmentation](https://arxiv.org/abs/2507.11893)
*Linwei Chen,Ying Fu,Lin Gu,Dezhi Zheng,Jifeng Dai*

Main category: cs.CV

TL;DR: 提出了一种空间频率调制（SFM）方法，通过调制高频特征到低频以减轻下采样时的混叠问题，并通过解调恢复高频信息，提升语义分割精度。


<details>
  <summary>Details</summary>
Motivation: 高频信息对语义分割精度至关重要，但下采样层可能导致混叠或失真，因此需要一种方法保留高频细节。

Method: 提出SFM，包括自适应重采样（ARS）调制高频特征和多重尺度自适应上采样（MSAU）解调，可无缝集成到多种架构中。

Result: 方法有效减轻混叠并保留细节，验证了在图像分类、对抗鲁棒性、实例分割等任务中的广泛适用性。

Conclusion: SFM通过调制和解调高频特征，显著提升了语义分割等任务的性能，具有广泛的应用潜力。

Abstract: High spatial frequency information, including fine details like textures,
significantly contributes to the accuracy of semantic segmentation. However,
according to the Nyquist-Shannon Sampling Theorem, high-frequency components
are vulnerable to aliasing or distortion when propagating through downsampling
layers such as strided-convolution. Here, we propose a novel Spatial Frequency
Modulation (SFM) that modulates high-frequency features to a lower frequency
before downsampling and then demodulates them back during upsampling.
Specifically, we implement modulation through adaptive resampling (ARS) and
design a lightweight add-on that can densely sample the high-frequency areas to
scale up the signal, thereby lowering its frequency in accordance with the
Frequency Scaling Property. We also propose Multi-Scale Adaptive Upsampling
(MSAU) to demodulate the modulated feature and recover high-frequency
information through non-uniform upsampling This module further improves
segmentation by explicitly exploiting information interaction between densely
and sparsely resampled areas at multiple scales. Both modules can seamlessly
integrate with various architectures, extending from convolutional neural
networks to transformers. Feature visualization and analysis confirm that our
method effectively alleviates aliasing while successfully retaining details
after demodulation. Finally, we validate the broad applicability and
effectiveness of SFM by extending it to image classification, adversarial
robustness, instance segmentation, and panoptic segmentation tasks. The code is
available at
\href{https://github.com/Linwei-Chen/SFM}{https://github.com/Linwei-Chen/SFM}.

</details>


### [80] [SEPose: A Synthetic Event-based Human Pose Estimation Dataset for Pedestrian Monitoring](https://arxiv.org/abs/2507.11910)
*Kaustav Chanda,Aayush Atul Verma,Arpitsinh Vaghela,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: SEPose是一个基于事件的合成人体姿态估计数据集，用于固定行人感知，填补了真实数据不足的空白。


<details>
  <summary>Details</summary>
Motivation: 解决行人监测系统中因数据不足而难以应对挑战性条件的问题。

Method: 使用CARLA模拟器和动态视觉传感器生成SEPose数据集，包含近350K标注行人姿态关键点。

Result: 在真实事件数据上验证了SEPose的模拟到现实泛化能力。

Conclusion: SEPose为事件传感器在行人监测中的应用提供了有效的数据支持。

Abstract: Event-based sensors have emerged as a promising solution for addressing
challenging conditions in pedestrian and traffic monitoring systems. Their
low-latency and high dynamic range allow for improved response time in
safety-critical situations caused by distracted walking or other unusual
movements. However, the availability of data covering such scenarios remains
limited. To address this gap, we present SEPose -- a comprehensive synthetic
event-based human pose estimation dataset for fixed pedestrian perception
generated using dynamic vision sensors in the CARLA simulator. With nearly 350K
annotated pedestrians with body pose keypoints from the perspective of fixed
traffic cameras, SEPose is a comprehensive synthetic multi-person pose
estimation dataset that spans busy and light crowds and traffic across diverse
lighting and weather conditions in 4-way intersections in urban, suburban, and
rural environments. We train existing state-of-the-art models such as RVT and
YOLOv8 on our dataset and evaluate them on real event-based data to demonstrate
the sim-to-real generalization capabilities of the proposed dataset.

</details>


### [81] [Dark-EvGS: Event Camera as an Eye for Radiance Field in the Dark](https://arxiv.org/abs/2507.11931)
*Jingqian Wu,Peiqi Duan,Zongqiang Wang,Changwei Wang,Boxin Shi,Edmund Y. Lam*

Main category: cs.CV

TL;DR: 提出Dark-EvGS框架，利用事件相机和3D高斯泼溅技术，在低光环境下重建多视角明亮帧，并通过三重监督和色调匹配提升效果。


<details>
  <summary>Details</summary>
Motivation: 传统相机在低光环境下因动态范围限制和运动模糊难以捕捉清晰多视角图像，事件相机和高斯泼溅技术可解决此问题，但现有方法仍面临噪声和色调不一致的挑战。

Method: 提出Dark-EvGS框架，结合三重监督和色调匹配模块，利用事件相机数据重建明亮帧，并创建首个真实数据集验证。

Result: 实验表明，该方法在低光条件下优于现有方法，成功重建辐射场。

Conclusion: Dark-EvGS为低光环境下的多视角图像重建提供有效解决方案，代码和数据已公开。

Abstract: In low-light environments, conventional cameras often struggle to capture
clear multi-view images of objects due to dynamic range limitations and motion
blur caused by long exposure. Event cameras, with their high-dynamic range and
high-speed properties, have the potential to mitigate these issues.
Additionally, 3D Gaussian Splatting (GS) enables radiance field reconstruction,
facilitating bright frame synthesis from multiple viewpoints in low-light
conditions. However, naively using an event-assisted 3D GS approach still faced
challenges because, in low light, events are noisy, frames lack quality, and
the color tone may be inconsistent. To address these issues, we propose
Dark-EvGS, the first event-assisted 3D GS framework that enables the
reconstruction of bright frames from arbitrary viewpoints along the camera
trajectory. Triplet-level supervision is proposed to gain holistic knowledge,
granular details, and sharp scene rendering. The color tone matching block is
proposed to guarantee the color consistency of the rendered frames.
Furthermore, we introduce the first real-captured dataset for the event-guided
bright frame synthesis task via 3D GS-based radiance field reconstruction.
Experiments demonstrate that our method achieves better results than existing
methods, conquering radiance field reconstruction under challenging low-light
conditions. The code and sample data are included in the supplementary
material.

</details>


### [82] [Hyperphantasia: A Benchmark for Evaluating the Mental Visualization Capabilities of Multimodal LLMs](https://arxiv.org/abs/2507.11932)
*Mohammad Shahab Sepehri,Berk Tinaz,Zalan Fabian,Mahdi Soltanolkotabi*

Main category: cs.CV

TL;DR: 论文提出了Hyperphantasia基准，用于评估多模态大语言模型（MLLMs）的心理可视化能力，发现其与人类表现存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 当前基准主要评估被动视觉感知，缺乏对主动构建视觉模式以支持问题解决能力的评估，而心理可视化是人类认知的核心能力。

Method: 设计了包含四个程序生成任务的Hyperphantasia基准，分三个难度级别，并评估了最先进模型的性能。

Result: 评估显示MLLMs与人类表现存在显著差距，部分模型能识别视觉模式，但心理可视化仍是挑战。

Conclusion: 心理可视化是当前MLLMs的开放挑战，强化学习可能有助于提升视觉模拟能力。

Abstract: Mental visualization, the ability to construct and manipulate visual
representations internally, is a core component of human cognition and plays a
vital role in tasks involving reasoning, prediction, and abstraction. Despite
the rapid progress of Multimodal Large Language Models (MLLMs), current
benchmarks primarily assess passive visual perception, offering limited insight
into the more active capability of internally constructing visual patterns to
support problem solving. Yet mental visualization is a critical cognitive skill
in humans, supporting abilities such as spatial navigation, predicting physical
trajectories, and solving complex visual problems through imaginative
simulation. To bridge this gap, we introduce Hyperphantasia, a synthetic
benchmark designed to evaluate the mental visualization abilities of MLLMs
through four carefully constructed puzzles. Each task is procedurally generated
and presented at three difficulty levels, enabling controlled analysis of model
performance across increasing complexity. Our comprehensive evaluation of
state-of-the-art models reveals a substantial gap between the performance of
humans and MLLMs. Additionally, we explore the potential of reinforcement
learning to improve visual simulation capabilities. Our findings suggest that
while some models exhibit partial competence in recognizing visual patterns,
robust mental visualization remains an open challenge for current MLLMs.

</details>


### [83] [RaDL: Relation-aware Disentangled Learning for Multi-Instance Text-to-Image Generation](https://arxiv.org/abs/2507.11947)
*Geon Park,Seon Bin Kim,Gunho Jung,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本文提出了一种关系感知解耦学习（RaDL）框架，用于解决多实例图像生成中的关系差异和属性泄漏问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多实例图像生成中难以处理实例间的关系差异和多个属性泄漏问题。

Method: RaDL通过可学习参数增强实例特定属性，并利用关系注意力生成关系感知图像特征。

Result: 在COCO-Position、COCO-MIG和DrawBench等基准测试中，RaDL在位置准确性、多属性考虑和实例关系方面表现优于现有方法。

Conclusion: RaDL是解决多实例图像生成中关系和属性问题的有效方案。

Abstract: With recent advancements in text-to-image (T2I) models, effectively
generating multiple instances within a single image prompt has become a crucial
challenge. Existing methods, while successful in generating positions of
individual instances, often struggle to account for relationship discrepancy
and multiple attributes leakage. To address these limitations, this paper
proposes the relation-aware disentangled learning (RaDL) framework. RaDL
enhances instance-specific attributes through learnable parameters and
generates relation-aware image features via Relation Attention, utilizing
action verbs extracted from the global prompt. Through extensive evaluations on
benchmarks such as COCO-Position, COCO-MIG, and DrawBench, we demonstrate that
RaDL outperforms existing methods, showing significant improvements in
positional accuracy, multiple attributes consideration, and the relationships
between instances. Our results present RaDL as the solution for generating
images that consider both the relationships and multiple attributes of each
instance within the multi-instance image.

</details>


### [84] [Prototypical Progressive Alignment and Reweighting for Generalizable Semantic Segmentation](https://arxiv.org/abs/2507.11955)
*Yuhang Zhang,Zhengyu Zhang,Muxin Liao,Shishun Tian,Wenbin Zou,Lu Zhang,Chen Xu*

Main category: cs.CV

TL;DR: PPAR框架通过渐进对齐和原型重加权策略，结合CLIP模型，提升了语义分割的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在原型对齐、数据过拟合和特征适应性方面的不足。

Method: 定义OTP和VTP原型，采用渐进对齐和重加权机制。

Result: 在多个基准测试中达到最优性能。

Conclusion: PPAR有效提升了语义分割的泛化能力。

Abstract: Generalizable semantic segmentation aims to perform well on unseen target
domains, a critical challenge due to real-world applications requiring high
generalizability. Class-wise prototypes, representing class centroids, serve as
domain-invariant cues that benefit generalization due to their stability and
semantic consistency. However, this approach faces three challenges. First,
existing methods often adopt coarse prototypical alignment strategies, which
may hinder performance. Second, naive prototypes computed by averaging source
batch features are prone to overfitting and may be negatively affected by
unrelated source data. Third, most methods treat all source samples equally,
ignoring the fact that different features have varying adaptation difficulties.
To address these limitations, we propose a novel framework for generalizable
semantic segmentation: Prototypical Progressive Alignment and Reweighting
(PPAR), leveraging the strong generalization ability of the CLIP model.
Specifically, we define two prototypes: the Original Text Prototype (OTP) and
Visual Text Prototype (VTP), generated via CLIP to serve as a solid base for
alignment. We then introduce a progressive alignment strategy that aligns
features in an easy-to-difficult manner, reducing domain gaps gradually.
Furthermore, we propose a prototypical reweighting mechanism that estimates the
reliability of source data and adjusts its contribution, mitigating the effect
of irrelevant or harmful features (i.e., reducing negative transfer). We also
provide a theoretical analysis showing the alignment between our method and
domain generalization theory. Extensive experiments across multiple benchmarks
demonstrate that PPAR achieves state-of-the-art performance, validating its
effectiveness.

</details>


### [85] [Language-Guided Contrastive Audio-Visual Masked Autoencoder with Automatically Generated Audio-Visual-Text Triplets from Videos](https://arxiv.org/abs/2507.11967)
*Yuchi Ishikawa,Shota Nakada,Hokuto Munakata,Kazuhiro Saito,Tatsuya Komatsu,Yoshimitsu Aoki*

Main category: cs.CV

TL;DR: 提出LG-CAV-MAE模型，通过结合文本编码器改进音频-视觉表示学习，自动生成高质量音频-视觉-文本三元组，显著提升检索和分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 改进音频-视觉表示学习，通过引入文本模态增强模型的多模态学习能力。

Method: 集成预训练文本编码器到对比音频-视觉掩码自编码器中，自动生成音频-视觉-文本三元组，使用CLAP过滤确保对齐。

Result: 在检索任务中recall@10提升5.6%，分类任务提升3.2%。

Conclusion: LG-CAV-MAE通过多模态学习和自动生成数据，显著优于现有方法。

Abstract: In this paper, we propose Language-Guided Contrastive Audio-Visual Masked
Autoencoders (LG-CAV-MAE) to improve audio-visual representation learning.
LG-CAV-MAE integrates a pretrained text encoder into contrastive audio-visual
masked autoencoders, enabling the model to learn across audio, visual and text
modalities. To train LG-CAV-MAE, we introduce an automatic method to generate
audio-visual-text triplets from unlabeled videos. We first generate frame-level
captions using an image captioning model and then apply CLAP-based filtering to
ensure strong alignment between audio and captions. This approach yields
high-quality audio-visual-text triplets without requiring manual annotations.
We evaluate LG-CAV-MAE on audio-visual retrieval tasks, as well as an
audio-visual classification task. Our method significantly outperforms existing
approaches, achieving up to a 5.6% improvement in recall@10 for retrieval tasks
and a 3.2% improvement for the classification task.

</details>


### [86] [Watch, Listen, Understand, Mislead: Tri-modal Adversarial Attacks on Short Videos for Content Appropriateness Evaluation](https://arxiv.org/abs/2507.11968)
*Sahid Hossain Mustakim,S M Jishanul Islam,Ummay Maria Muna,Montasir Chowdhury,Mohammed Jawwadul Islam,Sadia Ahmmed,Tashfia Sikder,Syed Tasdid Azam Dhrubo,Swakkhar Shatabda*

Main category: cs.CV

TL;DR: 论文提出了一种评估多模态大语言模型（MLLMs）三模态安全性的框架，包括SVMA数据集和ChimeraBreak攻击策略，揭示了模型在短视频内容中的显著漏洞。


<details>
  <summary>Details</summary>
Motivation: 当前的安全评估多基于单模态攻击，未能全面应对多模态联合攻击的脆弱性，尤其是在短视频内容中。

Method: 提出了SVMA数据集和ChimeraBreak三模态攻击策略，同时挑战视觉、听觉和语义推理路径。

Result: 实验显示MLLMs存在显著漏洞，攻击成功率（ASR）高，并揭示了模型对良性或违规内容的分类偏见。

Conclusion: 研究为开发更鲁棒和安全的MLLMs提供了重要见解。

Abstract: Multimodal Large Language Models (MLLMs) are increasingly used for content
moderation, yet their robustness in short-form video contexts remains
underexplored. Current safety evaluations often rely on unimodal attacks,
failing to address combined attack vulnerabilities. In this paper, we introduce
a comprehensive framework for evaluating the tri-modal safety of MLLMs. First,
we present the Short-Video Multimodal Adversarial (SVMA) dataset, comprising
diverse short-form videos with human-guided synthetic adversarial attacks.
Second, we propose ChimeraBreak, a novel tri-modal attack strategy that
simultaneously challenges visual, auditory, and semantic reasoning pathways.
Extensive experiments on state-of-the-art MLLMs reveal significant
vulnerabilities with high Attack Success Rates (ASR). Our findings uncover
distinct failure modes, showing model biases toward misclassifying benign or
policy-violating content. We assess results using LLM-as-a-judge, demonstrating
attack reasoning efficacy. Our dataset and findings provide crucial insights
for developing more robust and safe MLLMs.

</details>


### [87] [GS-Bias: Global-Spatial Bias Learner for Single-Image Test-Time Adaptation of Vision-Language Models](https://arxiv.org/abs/2507.11969)
*Zhaohong Huang,Yuxin Zhang,Jingjing Xie,Fei Chao,Rongrong Ji*

Main category: cs.CV

TL;DR: GS-Bias是一种高效的测试时适应方法，通过全局和空间偏置学习提升视觉语言模型的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在性能和效率之间难以平衡，要么调整文本提示开销大，要么手工增强视觉特征效果不稳定。

Method: GS-Bias引入全局偏置和空间偏置，直接添加到预训练模型的输出中，避免全反向传播，提高效率。

Result: 在15个基准数据集上达到最优性能，例如在跨数据集和领域泛化中分别提升2.23%和2.72%，内存使用仅为TPT的6.5%。

Conclusion: GS-Bias在高效性和性能上均优于现有方法，为测试时适应提供了新思路。

Abstract: Recent advances in test-time adaptation (TTA) for Vision-Language Models
(VLMs) have garnered increasing attention, particularly through the use of
multiple augmented views of a single image to boost zero-shot generalization.
Unfortunately, existing methods fail to strike a satisfactory balance between
performance and efficiency, either due to excessive overhead of tuning text
prompts or unstable benefits from handcrafted, training-free visual feature
enhancement. In this paper, we present Global-Spatial Bias Learner (GS-Bias),
an efficient and effective TTA paradigm that incorporates two learnable biases
during TTA, unfolded as the global bias and spatial bias. Particularly, the
global bias captures the global semantic features of a test image by learning
consistency across augmented views, while spatial bias learns the semantic
coherence between regions in the image's spatial visual representation. It is
worth highlighting that these two sets of biases are directly added to the
logits outputed by the pretrained VLMs, which circumvent the full
backpropagation through VLM that hinders the efficiency of existing TTA
methods. This endows GS-Bias with extremely high efficiency while achieving
state-of-the-art performance on 15 benchmark datasets. For example, it achieves
a 2.23% improvement over TPT in cross-dataset generalization and a 2.72%
improvement in domain generalization, while requiring only 6.5% of TPT's memory
usage on ImageNet.

</details>


### [88] [EC-Diff: Fast and High-Quality Edge-Cloud Collaborative Inference for Diffusion Models](https://arxiv.org/abs/2507.11980)
*Jiajian Xie,Shengyu Zhang,Zhou Zhao,Fan Wu,Fei Wu*

Main category: cs.CV

TL;DR: EC-Diff通过梯度噪声估计和最优切换点选择，加速扩散模型的云端推理，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有混合边缘-云协作框架中，云端去噪时间过长或步骤不足会导致推理延迟或语义模糊，影响边缘模型输出一致性。

Method: 提出K步噪声近似策略减少云端推理频率，并设计两阶段贪心搜索算法优化噪声近似和边缘模型切换参数。

Result: 实验表明，EC-Diff在生成质量上优于边缘推理，推理速度比云端快2倍。

Conclusion: EC-Diff有效平衡了推理速度与生成质量，为扩散模型的实际应用提供了高效解决方案。

Abstract: Diffusion Models have shown remarkable proficiency in image and video
synthesis. As model size and latency increase limit user experience, hybrid
edge-cloud collaborative framework was recently proposed to realize fast
inference and high-quality generation, where the cloud model initiates
high-quality semantic planning and the edge model expedites later-stage
refinement. However, excessive cloud denoising prolongs inference time, while
insufficient steps cause semantic ambiguity, leading to inconsistency in edge
model output. To address these challenges, we propose EC-Diff that accelerates
cloud inference through gradient-based noise estimation while identifying the
optimal point for cloud-edge handoff to maintain generation quality.
Specifically, we design a K-step noise approximation strategy to reduce cloud
inference frequency by using noise gradients between steps and applying cloud
inference periodically to adjust errors. Then we design a two-stage greedy
search algorithm to efficiently find the optimal parameters for noise
approximation and edge model switching. Extensive experiments demonstrate that
our method significantly enhances generation quality compared to edge
inference, while achieving up to an average $2\times$ speedup in inference
compared to cloud inference. Video samples and source code are available at
https://ec-diff.github.io/.

</details>


### [89] [Unsupervised Part Discovery via Descriptor-Based Masked Image Restoration with Optimized Constraints](https://arxiv.org/abs/2507.11985)
*Jiahao Xia,Yike Wu,Wenjian Huang,Jianguo Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为MPAE的无监督部件发现方法，通过掩码自编码器学习部件描述符，并在复杂场景中鲁棒地发现有意义部件。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏细粒度标签，部件级特征研究较少，现有无监督方法在跨类别和场景中鲁棒性不足。

Method: MPAE通过掩码图像学习部件描述符和特征图，利用局部特征与描述符的相似性填充掩码区域，从而对齐部件形状。

Result: MPAE在多种类别和场景中鲁棒地发现了与实际物体形状匹配的部件。

Conclusion: MPAE为无监督部件发现提供了有效解决方案，支持跨类别和场景的部件识别，并应对遮挡挑战。

Abstract: Part-level features are crucial for image understanding, but few studies
focus on them because of the lack of fine-grained labels. Although unsupervised
part discovery can eliminate the reliance on labels, most of them cannot
maintain robustness across various categories and scenarios, which restricts
their application range. To overcome this limitation, we present a more
effective paradigm for unsupervised part discovery, named Masked Part
Autoencoder (MPAE). It first learns part descriptors as well as a feature map
from the inputs and produces patch features from a masked version of the
original images. Then, the masked regions are filled with the learned part
descriptors based on the similarity between the local features and descriptors.
By restoring these masked patches using the part descriptors, they become
better aligned with their part shapes, guided by appearance features from
unmasked patches. Finally, MPAE robustly discovers meaningful parts that
closely match the actual object shapes, even in complex scenarios. Moreover,
several looser yet more effective constraints are proposed to enable MPAE to
identify the presence of parts across various scenarios and categories in an
unsupervised manner. This provides the foundation for addressing challenges
posed by occlusion and for exploring part similarity across multiple
categories. Extensive experiments demonstrate that our method robustly
discovers meaningful parts across various categories and scenarios. The code is
available at the project https://github.com/Jiahao-UTS/MPAE.

</details>


### [90] [Style Composition within Distinct LoRA modules for Traditional Art](https://arxiv.org/abs/2507.11986)
*Jaehyun Lee,Wonhark Park,Wonsik Shin,Hyunho Lee,Hyoung Min Na,Nojun Kwak*

Main category: cs.CV

TL;DR: 提出一种零样本扩散管道，通过融合不同风格模型的去噪潜在空间，实现区域特定风格混合。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在风格混合中难以控制区域和风格主导的问题。

Method: 利用低噪声潜在空间携带更强风格信息的特点，通过空间掩码融合不同风格模型的潜在空间，并结合ControlNet的深度图条件。

Result: 定性和定量实验表明，该方法能根据掩码实现区域特定风格混合。

Conclusion: 该方法成功实现了用户引导的区域风格混合，同时保持各风格的真实性。

Abstract: Diffusion-based text-to-image models have achieved remarkable results in
synthesizing diverse images from text prompts and can capture specific artistic
styles via style personalization. However, their entangled latent space and
lack of smooth interpolation make it difficult to apply distinct painting
techniques in a controlled, regional manner, often causing one style to
dominate. To overcome this, we propose a zero-shot diffusion pipeline that
naturally blends multiple styles by performing style composition on the
denoised latents predicted during the flow-matching denoising process of
separately trained, style-specialized models. We leverage the fact that
lower-noise latents carry stronger stylistic information and fuse them across
heterogeneous diffusion pipelines using spatial masks, enabling precise,
region-specific style control. This mechanism preserves the fidelity of each
individual style while allowing user-guided mixing. Furthermore, to ensure
structural coherence across different models, we incorporate depth-map
conditioning via ControlNet into the diffusion framework. Qualitative and
quantitative experiments demonstrate that our method successfully achieves
region-specific style mixing according to the given masks.

</details>


### [91] [ID-EA: Identity-driven Text Enhancement and Adaptation with Textual Inversion for Personalized Text-to-Image Generation](https://arxiv.org/abs/2507.11990)
*Hyun-Jun Jin,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ID-EA框架通过ID-Enhancer和ID-Adapter改进文本嵌入与视觉身份嵌入的对齐，显著提升个性化肖像生成中的身份一致性，并实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 当前Textual Inversion方法在个性化肖像生成中难以保持面部身份一致性，主要因文本与视觉嵌入空间的身份语义不对齐。

Method: ID-EA包含ID-Enhancer和ID-Adapter：前者通过文本ID锚点优化视觉身份嵌入，后者调整预训练UNet模型的交叉注意力模块以保持身份。

Result: ID-EA在身份保持指标上显著优于现有方法，且计算效率高，生成速度比现有方法快约15倍。

Conclusion: ID-EA通过改进文本与视觉嵌入的对齐，解决了身份一致性问题，同时提升了计算效率。

Abstract: Recently, personalized portrait generation with a text-to-image diffusion
model has significantly advanced with Textual Inversion, emerging as a
promising approach for creating high-fidelity personalized images. Despite its
potential, current Textual Inversion methods struggle to maintain consistent
facial identity due to semantic misalignments between textual and visual
embedding spaces regarding identity. We introduce ID-EA, a novel framework that
guides text embeddings to align with visual identity embeddings, thereby
improving identity preservation in a personalized generation. ID-EA comprises
two key components: the ID-driven Enhancer (ID-Enhancer) and the ID-conditioned
Adapter (ID-Adapter). First, the ID-Enhancer integrates identity embeddings
with a textual ID anchor, refining visual identity embeddings derived from a
face recognition model using representative text embeddings. Then, the
ID-Adapter leverages the identity-enhanced embedding to adapt the text
condition, ensuring identity preservation by adjusting the cross-attention
module in the pre-trained UNet model. This process encourages the text features
to find the most related visual clues across the foreground snippets. Extensive
quantitative and qualitative evaluations demonstrate that ID-EA substantially
outperforms state-of-the-art methods in identity preservation metrics while
achieving remarkable computational efficiency, generating personalized
portraits approximately 15 times faster than existing approaches.

</details>


### [92] [SAMST: A Transformer framework based on SAM pseudo label filtering for remote sensing semi-supervised semantic segmentation](https://arxiv.org/abs/2507.11994)
*Jun Yin,Fei Wu,Yupeng Ren,Jisheng Huang,Qiankun Li,Heng jin,Jianhai Fu,Chanjie Cui*

Main category: cs.CV

TL;DR: SAMST是一种半监督语义分割方法，利用Segment Anything Model（SAM）的零样本泛化和边界检测能力，通过迭代优化伪标签提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决公共遥感数据因分辨率和类别定义不一致导致的通用性不足问题，利用大量未标注数据提升语义分割效果。

Method: 结合监督模型自训练和基于SAM的伪标签优化器，包括阈值过滤、提示生成和标签细化模块。

Result: 在Potsdam数据集上验证了SAMST的有效性和可行性，提升了伪标签精度和模型性能。

Conclusion: SAMST通过结合大模型的泛化能力和小模型的训练效率，解决了遥感语义分割中标注数据不足的挑战。

Abstract: Public remote sensing datasets often face limitations in universality due to
resolution variability and inconsistent land cover category definitions. To
harness the vast pool of unlabeled remote sensing data, we propose SAMST, a
semi-supervised semantic segmentation method. SAMST leverages the strengths of
the Segment Anything Model (SAM) in zero-shot generalization and boundary
detection. SAMST iteratively refines pseudo-labels through two main components:
supervised model self-training using both labeled and pseudo-labeled data, and
a SAM-based Pseudo-label Refiner. The Pseudo-label Refiner comprises three
modules: a Threshold Filter Module for preprocessing, a Prompt Generation
Module for extracting connected regions and generating prompts for SAM, and a
Label Refinement Module for final label stitching. By integrating the
generalization power of large models with the training efficiency of small
models, SAMST improves pseudo-label accuracy, thereby enhancing overall model
performance. Experiments on the Potsdam dataset validate the effectiveness and
feasibility of SAMST, demonstrating its potential to address the challenges
posed by limited labeled data in remote sensing semantic segmentation.

</details>


### [93] [AU-Blendshape for Fine-grained Stylized 3D Facial Expression Manipulation](https://arxiv.org/abs/2507.12001)
*Hao Li,Ju Dai,Feng Zhou,Kaida Ning,Lei Li,Junjun Pan*

Main category: cs.CV

TL;DR: 论文提出了AUBlendSet数据集和AUBlendNet网络，用于细粒度的3D面部表情操纵，解决了现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在实现细粒度风格化3D面部表情操纵方面存在不足，需要更合适的数据集和方法。

Method: 基于32种标准面部动作单元（AUs）和500个身份，构建AUBlendSet数据集，并提出AUBlendNet网络学习不同风格的AU-Blendshape基向量。

Result: 通过实验验证了AUBlendSet和AUBlendNet在风格化表情操纵、语音驱动动画和情感识别数据增强中的有效性。

Conclusion: AUBlendSet和AUBlendNet在3D面部动画任务中具有重要潜力，填补了相关领域的空白。

Abstract: While 3D facial animation has made impressive progress, challenges still
exist in realizing fine-grained stylized 3D facial expression manipulation due
to the lack of appropriate datasets. In this paper, we introduce the
AUBlendSet, a 3D facial dataset based on AU-Blendshape representation for
fine-grained facial expression manipulation across identities. AUBlendSet is a
blendshape data collection based on 32 standard facial action units (AUs)
across 500 identities, along with an additional set of facial postures
annotated with detailed AUs. Based on AUBlendSet, we propose AUBlendNet to
learn AU-Blendshape basis vectors for different character styles. AUBlendNet
predicts, in parallel, the AU-Blendshape basis vectors of the corresponding
style for a given identity mesh, thereby achieving stylized 3D emotional facial
manipulation. We comprehensively validate the effectiveness of AUBlendSet and
AUBlendNet through tasks such as stylized facial expression manipulation,
speech-driven emotional facial animation, and emotion recognition data
augmentation. Through a series of qualitative and quantitative experiments, we
demonstrate the potential and importance of AUBlendSet and AUBlendNet in 3D
facial animation tasks. To the best of our knowledge, AUBlendSet is the first
dataset, and AUBlendNet is the first network for continuous 3D facial
expression manipulation for any identity through facial AUs. Our source code is
available at https://github.com/wslh852/AUBlendNet.git.

</details>


### [94] [Frequency-Dynamic Attention Modulation for Dense Prediction](https://arxiv.org/abs/2507.12006)
*Linwei Chen,Lin Gu,Ying Fu*

Main category: cs.CV

TL;DR: 提出了一种名为FDAM的新策略，通过动态调制ViTs的频率响应，解决了现有Transformer架构中频率消失的问题，提升了视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: ViTs中的注意力机制导致每层充当低通滤波器，堆叠层架构引发频率消失，丢失关键细节和纹理。

Method: FDAM包含Attention Inversion（AttInv）和Frequency Dynamic Scaling（FreqScale），通过电路理论动态调制频率响应。

Result: 在SegFormer、DeiT和MaskDINO等模型上表现提升，适用于语义分割、目标检测和实例分割等任务，并在遥感检测中取得SOTA结果。

Conclusion: FDAM有效避免了表示崩溃，显著提升了ViTs在多种视觉任务中的性能。

Abstract: Vision Transformers (ViTs) have significantly advanced computer vision,
demonstrating strong performance across various tasks. However, the attention
mechanism in ViTs makes each layer function as a low-pass filter, and the
stacked-layer architecture in existing transformers suffers from frequency
vanishing. This leads to the loss of critical details and textures. We propose
a novel, circuit-theory-inspired strategy called Frequency-Dynamic Attention
Modulation (FDAM), which can be easily plugged into ViTs. FDAM directly
modulates the overall frequency response of ViTs and consists of two
techniques: Attention Inversion (AttInv) and Frequency Dynamic Scaling
(FreqScale). Since circuit theory uses low-pass filters as fundamental
elements, we introduce AttInv, a method that generates complementary high-pass
filtering by inverting the low-pass filter in the attention matrix, and
dynamically combining the two. We further design FreqScale to weight different
frequency components for fine-grained adjustments to the target response
function. Through feature similarity analysis and effective rank evaluation, we
demonstrate that our approach avoids representation collapse, leading to
consistent performance improvements across various models, including SegFormer,
DeiT, and MaskDINO. These improvements are evident in tasks such as semantic
segmentation, object detection, and instance segmentation. Additionally, we
apply our method to remote sensing detection, achieving state-of-the-art
results in single-scale settings. The code is available at
\href{https://github.com/Linwei-Chen/FDAM}{https://github.com/Linwei-Chen/FDAM}.

</details>


### [95] [Dual form Complementary Masking for Domain-Adaptive Image Segmentation](https://arxiv.org/abs/2507.12008)
*Jiawen Wang,Yinda Chen,Xiaoyu Liu,Che Liu,Dong Liu,Jianqing Gao,Zhiwei Xiong*

Main category: cs.CV

TL;DR: 论文将掩码图像建模（MIM）重新定义为稀疏信号重建问题，提出MaskTwins框架，通过互补掩码增强特征提取，在无监督域适应（UDA）中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅将掩码视为图像变形，缺乏理论分析，未能充分利用掩码重建的潜力。

Method: 将掩码重建视为稀疏信号问题，理论证明互补掩码的优越性，提出MaskTwins框架，直接整合掩码重建到训练流程。

Result: MaskTwins在自然和生物图像分割中优于基线方法，无需单独预训练即可提取域不变特征。

Conclusion: MaskTwins为域自适应分割提供了新范式，展示了掩码重建在特征提取中的显著优势。

Abstract: Recent works have correlated Masked Image Modeling (MIM) with consistency
regularization in Unsupervised Domain Adaptation (UDA). However, they merely
treat masking as a special form of deformation on the input images and neglect
the theoretical analysis, which leads to a superficial understanding of masked
reconstruction and insufficient exploitation of its potential in enhancing
feature extraction and representation learning. In this paper, we reframe
masked reconstruction as a sparse signal reconstruction problem and
theoretically prove that the dual form of complementary masks possesses
superior capabilities in extracting domain-agnostic image features. Based on
this compelling insight, we propose MaskTwins, a simple yet effective UDA
framework that integrates masked reconstruction directly into the main training
pipeline. MaskTwins uncovers intrinsic structural patterns that persist across
disparate domains by enforcing consistency between predictions of images masked
in complementary ways, enabling domain generalization in an end-to-end manner.
Extensive experiments verify the superiority of MaskTwins over baseline methods
in natural and biological image segmentation. These results demonstrate the
significant advantages of MaskTwins in extracting domain-invariant features
without the need for separate pre-training, offering a new paradigm for
domain-adaptive segmentation.

</details>


### [96] [Deep Neural Encoder-Decoder Model to Relate fMRI Brain Activity with Naturalistic Stimuli](https://arxiv.org/abs/2507.12009)
*Florian David,Michael Chan,Elenor Morgenroth,Patrik Vuilleumier,Dimitri Van De Ville*

Main category: cs.CV

TL;DR: 提出了一种端到端的深度神经编码-解码模型，用于编码和解码自然刺激下的大脑活动，通过fMRI数据实现视觉输入的重建。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用深度学习模型填补自然电影刺激与fMRI数据之间的时间分辨率差距，并探索视觉解码的神经机制。

Method: 采用时间卷积层的编码-解码架构，利用连续电影帧的时间相关性，预测视觉皮层及其周围体素的活动。

Result: 模型成功重建了视觉输入，并发现中枕区、梭状区和距状区对解码贡献最大，分别对应形状感知、复杂识别和基础视觉特征处理。

Conclusion: 研究表明深度学习模型可以作为一种工具，探索电影中视觉处理的神经机制。

Abstract: We propose an end-to-end deep neural encoder-decoder model to encode and
decode brain activity in response to naturalistic stimuli using functional
magnetic resonance imaging (fMRI) data. Leveraging temporally correlated input
from consecutive film frames, we employ temporal convolutional layers in our
architecture, which effectively allows to bridge the temporal resolution gap
between natural movie stimuli and fMRI acquisitions. Our model predicts
activity of voxels in and around the visual cortex and performs reconstruction
of corresponding visual inputs from neural activity. Finally, we investigate
brain regions contributing to visual decoding through saliency maps. We find
that the most contributing regions are the middle occipital area, the fusiform
area, and the calcarine, respectively employed in shape perception, complex
recognition (in particular face perception), and basic visual features such as
edges and contrasts. These functions being strongly solicited are in line with
the decoder's capability to reconstruct edges, faces, and contrasts. All in
all, this suggests the possibility to probe our understanding of visual
processing in films using as a proxy the behaviour of deep learning models such
as the one proposed in this paper.

</details>


### [97] [SS-DC: Spatial-Spectral Decoupling and Coupling Across Visible-Infrared Gap for Domain Adaptive Object Detection](https://arxiv.org/abs/2507.12017)
*Xiwei Zhang,Chunjin Yang,Yiming Xiao,Runtong Zhang,Fanman Meng*

Main category: cs.CV

TL;DR: 提出了一种基于解耦-耦合策略的SS-DC框架，用于RGB-IR域自适应目标检测，通过光谱分解和空间-光谱耦合提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将RGB域视为统一域，忽略了其多子域（如白天、夜晚、雾天）的特性，解耦域不变和域特定特征有助于提升RGB-IR域适应。

Method: 设计了光谱自适应幂等解耦（SAID）模块，结合滤波器组和自蒸馏解耦损失；提出空间-光谱耦合方法，联合耦合域不变特征。

Result: 在多个RGB-IR数据集上显著提升基线性能，优于现有UDAOD方法，包括基于FLIR-ADAS的新实验协议。

Conclusion: 解耦-耦合策略有效提升RGB-IR域自适应目标检测性能，光谱和空间特征联合处理是关键。

Abstract: Unsupervised domain adaptive object detection (UDAOD) from the visible domain
to the infrared (RGB-IR) domain is challenging. Existing methods regard the RGB
domain as a unified domain and neglect the multiple subdomains within it, such
as daytime, nighttime, and foggy scenes. We argue that decoupling the
domain-invariant (DI) and domain-specific (DS) features across these multiple
subdomains is beneficial for RGB-IR domain adaptation. To this end, this paper
proposes a new SS-DC framework based on a decoupling-coupling strategy. In
terms of decoupling, we design a Spectral Adaptive Idempotent Decoupling (SAID)
module in the aspect of spectral decomposition. Due to the style and content
information being highly embedded in different frequency bands, this module can
decouple DI and DS components more accurately and interpretably. A novel filter
bank-based spectral processing paradigm and a self-distillation-driven
decoupling loss are proposed to improve the spectral domain decoupling. In
terms of coupling, a new spatial-spectral coupling method is proposed, which
realizes joint coupling through spatial and spectral DI feature pyramids.
Meanwhile, this paper introduces DS from decoupling to reduce the domain bias.
Extensive experiments demonstrate that our method can significantly improve the
baseline performance and outperform existing UDAOD methods on multiple RGB-IR
datasets, including a new experimental protocol proposed in this paper based on
the FLIR-ADAS dataset.

</details>


### [98] [Dataset Ownership Verification for Pre-trained Masked Models](https://arxiv.org/abs/2507.12022)
*Yuechen Xie,Jie Song,Yicheng Shan,Xiaoyan Zhang,Yuanyu Wan,Shengxuming Zhang,Jiarui Duan,Mingli Song*

Main category: cs.CV

TL;DR: 论文提出了一种针对掩码模型的数据集所有权验证方法DOV4MM，解决了现有技术无法直接应用于掩码模型的问题。


<details>
  <summary>Details</summary>
Motivation: 高质量开源数据集对深度学习发展至关重要，但其所有权保护面临挑战，现有验证技术不适用于掩码模型。

Method: 基于掩码信息重建难度的差异，提出DOV4MM方法验证黑盒模型是否在目标数据集上预训练。

Result: 在多个掩码图像和语言模型上验证，DOV4MM显著优于现有方法，p值远低于0.05。

Conclusion: DOV4MM为掩码模型的数据集所有权验证提供了有效解决方案，保护了数据集所有者的权益。

Abstract: High-quality open-source datasets have emerged as a pivotal catalyst driving
the swift advancement of deep learning, while facing the looming threat of
potential exploitation. Protecting these datasets is of paramount importance
for the interests of their owners. The verification of dataset ownership has
evolved into a crucial approach in this domain; however, existing verification
techniques are predominantly tailored to supervised models and contrastive
pre-trained models, rendering them ill-suited for direct application to the
increasingly prevalent masked models. In this work, we introduce the inaugural
methodology addressing this critical, yet unresolved challenge, termed Dataset
Ownership Verification for Masked Modeling (DOV4MM). The central objective is
to ascertain whether a suspicious black-box model has been pre-trained on a
particular unlabeled dataset, thereby assisting dataset owners in safeguarding
their rights. DOV4MM is grounded in our empirical observation that when a model
is pre-trained on the target dataset, the difficulty of reconstructing masked
information within the embedding space exhibits a marked contrast to models not
pre-trained on that dataset. We validated the efficacy of DOV4MM through ten
masked image models on ImageNet-1K and four masked language models on
WikiText-103. The results demonstrate that DOV4MM rejects the null hypothesis,
with a $p$-value considerably below 0.05, surpassing all prior approaches. Code
is available at https://github.com/xieyc99/DOV4MM.

</details>


### [99] [MVAR: MultiVariate AutoRegressive Air Pollutants Forecasting Model](https://arxiv.org/abs/2507.12023)
*Xu Fan,Zhihao Wang,Yuetan Lin,Yan Zhang,Yang Xiang,Hao Li*

Main category: cs.CV

TL;DR: 提出了一种多变量自回归空气污染物预测模型（MVAR），通过减少对长时间窗口输入的依赖并提高数据利用效率，解决了现有研究中单污染物预测的局限性。


<details>
  <summary>Details</summary>
Motivation: 空气污染物对环境和人类健康构成重大威胁，现有研究多关注单污染物预测，忽略了污染物间的相互作用及其空间响应多样性。

Method: 设计了多变量自回归训练范式，支持120小时长期序列预测，并开发了气象耦合空间变换器模块，灵活结合气象预报数据。

Result: 实验结果表明，MVAR模型优于现有方法，验证了其架构的有效性。

Conclusion: MVAR模型为多变量空气污染物预测提供了高效解决方案，并构建了标准化数据集支持未来研究。

Abstract: Air pollutants pose a significant threat to the environment and human health,
thus forecasting accurate pollutant concentrations is essential for pollution
warnings and policy-making. Existing studies predominantly focus on
single-pollutant forecasting, neglecting the interactions among different
pollutants and their diverse spatial responses. To address the practical needs
of forecasting multivariate air pollutants, we propose MultiVariate
AutoRegressive air pollutants forecasting model (MVAR), which reduces the
dependency on long-time-window inputs and boosts the data utilization
efficiency. We also design the Multivariate Autoregressive Training Paradigm,
enabling MVAR to achieve 120-hour long-term sequential forecasting.
Additionally, MVAR develops Meteorological Coupled Spatial Transformer block,
enabling the flexible coupling of AI-based meteorological forecasts while
learning the interactions among pollutants and their diverse spatial responses.
As for the lack of standardized datasets in air pollutants forecasting, we
construct a comprehensive dataset covering 6 major pollutants across 75 cities
in North China from 2018 to 2023, including ERA5 reanalysis data and FuXi-2.0
forecast data. Experimental results demonstrate that the proposed model
outperforms state-of-the-art methods and validate the effectiveness of the
proposed architecture.

</details>


### [100] [3D-MoRe: Unified Modal-Contextual Reasoning for Embodied Question Answering](https://arxiv.org/abs/2507.12026)
*Rongtao Xu,Han Gao,Mingming Yu,Dong An,Shunpeng Chen,Changwei Wang,Li Guo,Xiaodan Liang,Shibiao Xu*

Main category: cs.CV

TL;DR: 3D-MoRe是一种新范式，利用基础模型生成大规模3D-语言数据集，用于室内场景任务，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 满足室内场景任务（如问答和密集标注）对多样化、可扩展数据的需求。

Method: 整合多模态嵌入、跨模态交互和语言模型解码器，处理自然语言指令和3D场景数据。

Result: 在ScanQA和ScanRefer任务中，CIDEr分数分别提升2.15%和1.84%。

Conclusion: 3D-MoRe有效生成高质量数据，性能优于现有方法，代码和数据集将开源。

Abstract: With the growing need for diverse and scalable data in indoor scene tasks,
such as question answering and dense captioning, we propose 3D-MoRe, a novel
paradigm designed to generate large-scale 3D-language datasets by leveraging
the strengths of foundational models. The framework integrates key components,
including multi-modal embedding, cross-modal interaction, and a language model
decoder, to process natural language instructions and 3D scene data. This
approach facilitates enhanced reasoning and response generation in complex 3D
environments. Using the ScanNet 3D scene dataset, along with text annotations
from ScanQA and ScanRefer, 3D-MoRe generates 62,000 question-answer (QA) pairs
and 73,000 object descriptions across 1,513 scenes. We also employ various data
augmentation techniques and implement semantic filtering to ensure high-quality
data. Experiments on ScanQA demonstrate that 3D-MoRe significantly outperforms
state-of-the-art baselines, with the CIDEr score improving by 2.15\%.
Similarly, on ScanRefer, our approach achieves a notable increase in CIDEr@0.5
by 1.84\%, highlighting its effectiveness in both tasks. Our code and generated
datasets will be publicly released to benefit the community, and both can be
accessed on the https://3D-MoRe.github.io.

</details>


### [101] [SGLoc: Semantic Localization System for Camera Pose Estimation from 3D Gaussian Splatting Representation](https://arxiv.org/abs/2507.12027)
*Beining Xu,Siting Zhu,Hesheng Wang*

Main category: cs.CV

TL;DR: SGLoc是一种新颖的定位系统，通过利用3D高斯泼溅（3DGS）表示和语义信息直接回归相机姿态，无需初始姿态先验。


<details>
  <summary>Details</summary>
Motivation: 解决无需初始姿态先验的全局定位问题，利用语义信息提升定位精度。

Method: 采用多级姿态回归策略和基于语义的全局检索算法，逐步估计和优化查询图像的6DoF姿态。

Result: 在12scenes和7scenes数据集上表现优于基线方法，展示了无需初始姿态先验的全局定位能力。

Conclusion: SGLoc通过结合语义信息和3DGS表示，实现了高效的全局定位，具有广泛的应用潜力。

Abstract: We propose SGLoc, a novel localization system that directly regresses camera
poses from 3D Gaussian Splatting (3DGS) representation by leveraging semantic
information. Our method utilizes the semantic relationship between 2D image and
3D scene representation to estimate the 6DoF pose without prior pose
information. In this system, we introduce a multi-level pose regression
strategy that progressively estimates and refines the pose of query image from
the global 3DGS map, without requiring initial pose priors. Moreover, we
introduce a semantic-based global retrieval algorithm that establishes
correspondences between 2D (image) and 3D (3DGS map). By matching the extracted
scene semantic descriptors of 2D query image and 3DGS semantic representation,
we align the image with the local region of the global 3DGS map, thereby
obtaining a coarse pose estimation. Subsequently, we refine the coarse pose by
iteratively optimizing the difference between the query image and the rendered
image from 3DGS. Our SGLoc demonstrates superior performance over baselines on
12scenes and 7scenes datasets, showing excellent capabilities in global
localization without initial pose prior. Code will be available at
https://github.com/IRMVLab/SGLoc.

</details>


### [102] [Intra-view and Inter-view Correlation Guided Multi-view Novel Class Discovery](https://arxiv.org/abs/2507.12029)
*Xinhang Wan,Jiyuan Liu,Qian Qu,Suyuan Liu,Chuyu Zhang,Fangdi Wang,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出了一种名为IICMVNCD的新框架，用于多视图数据中的新类发现，解决了现有方法对单视图数据的依赖和伪标签不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有新类发现方法主要针对单视图数据，且依赖伪标签导致性能不稳定，无法适应多视图数据（如多组学数据）的需求。

Method: 通过矩阵分解在视图内捕获已知类和新类的分布相似性，并在视图间利用已知类的关系指导新类聚类，动态调整视图权重。

Result: 实验验证了所提方法的有效性。

Conclusion: IICMVNCD是首个探索多视图新类发现的框架，解决了现有方法的局限性。

Abstract: In this paper, we address the problem of novel class discovery (NCD), which
aims to cluster novel classes by leveraging knowledge from disjoint known
classes. While recent advances have made significant progress in this area,
existing NCD methods face two major limitations. First, they primarily focus on
single-view data (e.g., images), overlooking the increasingly common multi-view
data, such as multi-omics datasets used in disease diagnosis. Second, their
reliance on pseudo-labels to supervise novel class clustering often results in
unstable performance, as pseudo-label quality is highly sensitive to factors
such as data noise and feature dimensionality. To address these challenges, we
propose a novel framework named Intra-view and Inter-view Correlation Guided
Multi-view Novel Class Discovery (IICMVNCD), which is the first attempt to
explore NCD in multi-view setting so far. Specifically, at the intra-view
level, leveraging the distributional similarity between known and novel
classes, we employ matrix factorization to decompose features into
view-specific shared base matrices and factor matrices. The base matrices
capture distributional consistency among the two datasets, while the factor
matrices model pairwise relationships between samples. At the inter-view level,
we utilize view relationships among known classes to guide the clustering of
novel classes. This includes generating predicted labels through the weighted
fusion of factor matrices and dynamically adjusting view weights of known
classes based on the supervision loss, which are then transferred to novel
class learning. Experimental results validate the effectiveness of our proposed
approach.

</details>


### [103] [MoViAD: Modular Visual Anomaly Detection](https://arxiv.org/abs/2507.12049)
*Manuel Barusco,Francesco Borsatti,Arianna Stropeni,Davide Dalle Pezze,Gian Antonio Susto*

Main category: cs.CV

TL;DR: MoViAD是一个模块化库，旨在加速视觉异常检测（VAD）的研究和部署，提供多种场景支持和实用工具。


<details>
  <summary>Details</summary>
Motivation: 解决VAD领域异常数据稀缺和无监督训练的挑战，促进研究和实际应用。

Method: 开发MoViAD库，集成先进模型、训练器、数据集和实用工具，支持多种场景和部署需求。

Result: MoViAD提供高效、灵活的解决方案，适用于研究和工程需求。

Conclusion: MoViAD为VAD领域的研究和部署提供了强大支持，兼具易用性和扩展性。

Abstract: VAD is a critical field in machine learning focused on identifying deviations
from normal patterns in images, often challenged by the scarcity of anomalous
data and the need for unsupervised training. To accelerate research and
deployment in this domain, we introduce MoViAD, a comprehensive and highly
modular library designed to provide fast and easy access to state-of-the-art
VAD models, trainers, datasets, and VAD utilities. MoViAD supports a wide array
of scenarios, including continual, semi-supervised, few-shots, noisy, and many
more. In addition, it addresses practical deployment challenges through
dedicated Edge and IoT settings, offering optimized models and backbones, along
with quantization and compression utilities for efficient on-device execution
and distributed inference. MoViAD integrates a selection of backbones, robust
evaluation VAD metrics (pixel-level and image-level) and useful profiling tools
for efficiency analysis. The library is designed for fast, effortless
deployment, enabling machine learning engineers to easily use it for their
specific setup with custom models, datasets, and backbones. At the same time,
it offers the flexibility and extensibility researchers need to develop and
experiment with new methods.

</details>


### [104] [InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing](https://arxiv.org/abs/2507.12060)
*Kun-Hsiang Lin,Yu-Wen Tseng,Kang-Yang Huang,Jhih-Ciang Wu,Wen-Huang Cheng*

Main category: cs.CV

TL;DR: InstructFLIP是一种基于视觉语言模型（VLM）的指令调优框架，通过文本指导增强跨域泛化能力，显著提升人脸反欺骗（FAS）系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决人脸反欺骗中攻击类型语义理解不足和跨域训练冗余两大挑战。

Method: 结合视觉语言模型（VLM）增强视觉输入理解，采用元域策略学习统一模型，并设计内容与风格分离的指令调优框架InstructFLIP。

Result: 在多个域上超越现有最优模型（SOTA），显著减少训练冗余。

Conclusion: InstructFLIP通过文本指导和域统一学习，有效提升了FAS系统的泛化能力和效率。

Abstract: Face anti-spoofing (FAS) aims to construct a robust system that can withstand
diverse attacks. While recent efforts have concentrated mainly on cross-domain
generalization, two significant challenges persist: limited semantic
understanding of attack types and training redundancy across domains. We
address the first by integrating vision-language models (VLMs) to enhance the
perception of visual input. For the second challenge, we employ a meta-domain
strategy to learn a unified model that generalizes well across multiple
domains. Our proposed InstructFLIP is a novel instruction-tuned framework that
leverages VLMs to enhance generalization via textual guidance trained solely on
a single domain. At its core, InstructFLIP explicitly decouples instructions
into content and style components, where content-based instructions focus on
the essential semantics of spoofing, and style-based instructions consider
variations related to the environment and camera characteristics. Extensive
experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA
models in accuracy and substantially reducing training redundancy across
diverse domains in FAS. Project website is available at
https://kunkunlin1221.github.io/InstructFLIP.

</details>


### [105] [MS-DETR: Towards Effective Video Moment Retrieval and Highlight Detection by Joint Motion-Semantic Learning](https://arxiv.org/abs/2507.12062)
*Hongxu Ma,Guanshuo Wang,Fufu Yu,Qiong Jia,Shouhong Ding*

Main category: cs.CV

TL;DR: MS-DETR框架通过统一学习运动-语义特征，提升视频时刻检索和高光检测任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有DETR框架未充分利用视频内容中时间运动与空间语义的复杂关系。

Method: 提出MS-DETR，编码器显式建模运动与语义的模态内相关性，解码器利用任务间相关性进行精确定位与边界划分，并通过生成策略和数据增强解决稀疏性问题。

Result: 在四个基准测试中超越现有最优模型。

Conclusion: MS-DETR通过运动-语义特征统一学习，显著提升了视频时刻检索和高光检测的性能。

Abstract: Video Moment Retrieval (MR) and Highlight Detection (HD) aim to pinpoint
specific moments and assess clip-wise relevance based on the text query. While
DETR-based joint frameworks have made significant strides, there remains
untapped potential in harnessing the intricate relationships between temporal
motion and spatial semantics within video content. In this paper, we propose
the Motion-Semantics DETR (MS-DETR), a framework that captures rich
motion-semantics features through unified learning for MR/HD tasks. The encoder
first explicitly models disentangled intra-modal correlations within motion and
semantics dimensions, guided by the given text queries. Subsequently, the
decoder utilizes the task-wise correlation across temporal motion and spatial
semantics dimensions to enable precise query-guided localization for MR and
refined highlight boundary delineation for HD. Furthermore, we observe the
inherent sparsity dilemma within the motion and semantics dimensions of MR/HD
datasets. To address this issue, we enrich the corpus from both dimensions by
generation strategies and propose contrastive denoising learning to ensure the
above components learn robustly and effectively. Extensive experiments on four
MR/HD benchmarks demonstrate that our method outperforms existing
state-of-the-art models by a margin. Our code is available at
https://github.com/snailma0229/MS-DETR.git.

</details>


### [106] [Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics](https://arxiv.org/abs/2507.12083)
*Muleilan Pei,Shaoshuai Shi,Xuesong Chen,Xu Liu,Shaojie Shen*

Main category: cs.CV

TL;DR: 论文提出了一种基于规划视角的运动预测方法，通过先推理行为意图再预测轨迹的策略，结合逆向强化学习和分层解码器，显著提升了轨迹预测的准确性和置信度。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统中交通代理运动预测的挑战，强调直接预测轨迹的现有方法缺乏对行为意图的显式建模，提出从规划角度重新思考任务。

Method: 采用逆向强化学习（IRL）框架，先编码场景和代理为向量表示，再通过查询中心范式聚合特征，生成奖励分布以推理意图，最后用分层解码器生成轨迹。

Result: 在Argoverse和nuScenes数据集上表现优异，显著提升了预测置信度，性能优于现有方法。

Conclusion: 通过显式建模行为意图和奖励驱动的推理，该方法为运动预测提供了更可靠且可解释的解决方案。

Abstract: Motion forecasting for on-road traffic agents presents both a significant
challenge and a critical necessity for ensuring safety in autonomous driving
systems. In contrast to most existing data-driven approaches that directly
predict future trajectories, we rethink this task from a planning perspective,
advocating a "First Reasoning, Then Forecasting" strategy that explicitly
incorporates behavior intentions as spatial guidance for trajectory prediction.
To achieve this, we introduce an interpretable, reward-driven intention
reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL)
scheme. Our method first encodes traffic agents and scene elements into a
unified vectorized representation, then aggregates contextual features through
a query-centric paradigm. This enables the derivation of a reward distribution,
a compact yet informative representation of the target agent's behavior within
the given scene context via IRL. Guided by this reward heuristic, we perform
policy rollouts to reason about multiple plausible intentions, providing
valuable priors for subsequent trajectory generation. Finally, we develop a
hierarchical DETR-like decoder integrated with bidirectional selective state
space models to produce accurate future trajectories along with their
associated probabilities. Extensive experiments on the large-scale Argoverse
and nuScenes motion forecasting datasets demonstrate that our approach
significantly enhances trajectory prediction confidence, achieving highly
competitive performance relative to state-of-the-art methods.

</details>


### [107] [YOLOv8-SMOT: An Efficient and Robust Framework for Real-Time Small Object Tracking via Slice-Assisted Training and Adaptive Association](https://arxiv.org/abs/2507.12087)
*Xiang Yu,Xinyao Liu,Guang Liang*

Main category: cs.CV

TL;DR: 论文提出了一种针对无人机视角下小型敏捷多目标（如鸟类）跟踪的冠军解决方案，通过检测和关联层面的创新，显著提升了跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决无人机视角下小型多目标跟踪的三大挑战：目标外观特征稀缺、相机与目标动态复杂纠缠、密集群体行为导致的遮挡和身份模糊。

Method: 采用跟踪-检测范式，提出SliceTrain训练增强框架优化小目标检测，设计独立于外观的跟踪器，结合运动方向维护和自适应相似度度量。

Result: 在SMOT4SB公开测试集上达到SO-HOTA分数55.205，表现最优。

Conclusion: 验证了框架在解决复杂现实SMOT问题中的有效性和先进性，代码将开源。

Abstract: Tracking small, agile multi-objects (SMOT), such as birds, from an Unmanned
Aerial Vehicle (UAV) perspective is a highly challenging computer vision task.
The difficulty stems from three main sources: the extreme scarcity of target
appearance features, the complex motion entanglement caused by the combined
dynamics of the camera and the targets themselves, and the frequent occlusions
and identity ambiguity arising from dense flocking behavior. This paper details
our championship-winning solution in the MVA 2025 "Finding Birds" Small
Multi-Object Tracking Challenge (SMOT4SB), which adopts the
tracking-by-detection paradigm with targeted innovations at both the detection
and association levels. On the detection side, we propose a systematic training
enhancement framework named \textbf{SliceTrain}. This framework, through the
synergy of 'deterministic full-coverage slicing' and 'slice-level stochastic
augmentation, effectively addresses the problem of insufficient learning for
small objects in high-resolution image training. On the tracking side, we
designed a robust tracker that is completely independent of appearance
information. By integrating a \textbf{motion direction maintenance (EMA)}
mechanism and an \textbf{adaptive similarity metric} combining \textbf{bounding
box expansion and distance penalty} into the OC-SORT framework, our tracker can
stably handle irregular motion and maintain target identities. Our method
achieves state-of-the-art performance on the SMOT4SB public test set, reaching
an SO-HOTA score of \textbf{55.205}, which fully validates the effectiveness
and advancement of our framework in solving complex real-world SMOT problems.
The source code will be made available at
https://github.com/Salvatore-Love/YOLOv8-SMOT.

</details>


### [108] [Non-Adaptive Adversarial Face Generation](https://arxiv.org/abs/2507.12107)
*Sunpill Kim,Seunghun Paik,Chanwoo Hwang,Minsu Kim,Jae Hong Seo*

Main category: cs.CV

TL;DR: 提出一种生成对抗性人脸的新方法，利用FRS特征空间的结构特性，通过单次非自适应查询实现高成功率。


<details>
  <summary>Details</summary>
Motivation: 对抗性攻击对FRS构成严重威胁，现有方法依赖迭代优化或迁移性，效率低且不灵活。

Method: 利用FRS特征空间中共享属性的子空间（如性别或种族），生成对抗性人脸，无需迭代优化。

Result: 仅需100张人脸图像的单次查询，对AWS CompareFaces API的成功率超过93%。

Conclusion: 该方法高效且灵活，能生成具有特定属性的对抗性人脸，无需依赖迁移性或多次查询。

Abstract: Adversarial attacks on face recognition systems (FRSs) pose serious security
and privacy threats, especially when these systems are used for identity
verification. In this paper, we propose a novel method for generating
adversarial faces-synthetic facial images that are visually distinct yet
recognized as a target identity by the FRS. Unlike iterative optimization-based
approaches (e.g., gradient descent or other iterative solvers), our method
leverages the structural characteristics of the FRS feature space. We figure
out that individuals sharing the same attribute (e.g., gender or race) form an
attributed subsphere. By utilizing such subspheres, our method achieves both
non-adaptiveness and a remarkably small number of queries. This eliminates the
need for relying on transferability and open-source surrogate models, which
have been a typical strategy when repeated adaptive queries to commercial FRSs
are impossible. Despite requiring only a single non-adaptive query consisting
of 100 face images, our method achieves a high success rate of over 93% against
AWS's CompareFaces API at its default threshold. Furthermore, unlike many
existing attacks that perturb a given image, our method can deliberately
produce adversarial faces that impersonate the target identity while exhibiting
high-level attributes chosen by the adversary.

</details>


### [109] [BRUM: Robust 3D Vehicle Reconstruction from 360 Sparse Images](https://arxiv.org/abs/2507.12095)
*Davide Di Nucci,Matteo Tomei,Guido Borghi,Luca Ciuffreda,Roberto Vezzani,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏视图输入的车辆3D重建方法，通过改进高斯泼溅技术和引入选择性光度损失，结合DUSt3R架构提升相机姿态估计，实现了高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法如NeRF和高斯泼溅依赖密集输入视图，限制了实际应用。本文旨在解决稀疏视图下的车辆重建问题。

Method: 结合深度图和鲁棒的姿态估计架构，改进高斯泼溅技术，引入选择性光度损失，并使用DUSt3R架构替代传统SfM。

Result: 在多个基准测试中达到最先进性能，即使在输入受限条件下也能实现高质量重建。

Conclusion: 该方法显著提升了稀疏视图下的车辆3D重建质量，具有广泛的应用潜力。

Abstract: Accurate 3D reconstruction of vehicles is vital for applications such as
vehicle inspection, predictive maintenance, and urban planning. Existing
methods like Neural Radiance Fields and Gaussian Splatting have shown
impressive results but remain limited by their reliance on dense input views,
which hinders real-world applicability. This paper addresses the challenge of
reconstructing vehicles from sparse-view inputs, leveraging depth maps and a
robust pose estimation architecture to synthesize novel views and augment
training data. Specifically, we enhance Gaussian Splatting by integrating a
selective photometric loss, applied only to high-confidence pixels, and
replacing standard Structure-from-Motion pipelines with the DUSt3R architecture
to improve camera pose estimation. Furthermore, we present a novel dataset
featuring both synthetic and real-world public transportation vehicles,
enabling extensive evaluation of our approach. Experimental results demonstrate
state-of-the-art performance across multiple benchmarks, showcasing the
method's ability to achieve high-quality reconstructions even under constrained
input conditions.

</details>


### [110] [Wavelet-based Decoupling Framework for low-light Stereo Image Enhancement](https://arxiv.org/abs/2507.12188)
*Shuangli Du,Siming Yan,Zhenghao Shi,Zhenzhen You,Lu Sun*

Main category: cs.CV

TL;DR: 提出一种基于小波变换的低光立体图像增强方法，通过特征空间解耦解决现有方法特征纠缠和黑盒问题。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法将所有退化因素编码在单一潜在空间中，导致特征高度纠缠和黑盒特性，易陷入捷径学习。

Method: 利用小波变换将特征空间分解为低频分支（用于光照调整）和多个高频分支（用于纹理增强），并设计高频引导的跨视角交互模块（HF-CIM）和细节纹理增强模块（DTEM）。

Result: 实验表明，该方法在光照调整和高频信息恢复方面具有显著优势。

Conclusion: 通过小波变换和特征空间解耦，有效提升了低光立体图像的增强效果。

Abstract: Low-light images suffer from complex degradation, and existing enhancement
methods often encode all degradation factors within a single latent space. This
leads to highly entangled features and strong black-box characteristics, making
the model prone to shortcut learning. To mitigate the above issues, this paper
proposes a wavelet-based low-light stereo image enhancement method with feature
space decoupling. Our insight comes from the following findings: (1) Wavelet
transform enables the independent processing of low-frequency and
high-frequency information. (2) Illumination adjustment can be achieved by
adjusting the low-frequency component of a low-light image, extracted through
multi-level wavelet decomposition. Thus, by using wavelet transform the feature
space is decomposed into a low-frequency branch for illumination adjustment and
multiple high-frequency branches for texture enhancement. Additionally, stereo
low-light image enhancement can extract useful cues from another view to
improve enhancement. To this end, we propose a novel high-frequency guided
cross-view interaction module (HF-CIM) that operates within high-frequency
branches rather than across the entire feature space, effectively extracting
valuable image details from the other view. Furthermore, to enhance the
high-frequency information, a detail and texture enhancement module (DTEM) is
proposed based on cross-attention mechanism. The model is trained on a dataset
consisting of images with uniform illumination and images with non-uniform
illumination. Experimental results on both real and synthetic images indicate
that our algorithm offers significant advantages in light adjustment while
effectively recovering high-frequency information. The code and dataset are
publicly available at: https://github.com/Cherisherr/WDCI-Net.git.

</details>


### [111] [DeepShade: Enable Shade Simulation by Text-conditioned Image Generation](https://arxiv.org/abs/2507.12103)
*Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的DeepShade方法，用于生成随时间变化的阴影图像，并结合对比学习提升性能，最终应用于实际路线规划。


<details>
  <summary>Details</summary>
Motivation: 热浪对公共健康构成威胁，但现有地图系统因卫星图像噪声和训练数据不足而无法有效利用阴影信息。

Method: 1. 构建包含多样地理区域的阴影数据集；2. 提出DeepShade模型，结合RGB与Canny边缘层，并引入对比学习。

Result: 模型在生成阴影图像方面表现优异，并成功应用于实际路线规划。

Conclusion: 该研究为极端天气下的城市规划提供了参考，具有潜在的实际应用价值。

Abstract: Heatwaves pose a significant threat to public health, especially as global
warming intensifies. However, current routing systems (e.g., online maps) fail
to incorporate shade information due to the difficulty of estimating shades
directly from noisy satellite imagery and the limited availability of training
data for generative models. In this paper, we address these challenges through
two main contributions. First, we build an extensive dataset covering diverse
longitude-latitude regions, varying levels of building density, and different
urban layouts. Leveraging Blender-based 3D simulations alongside building
outlines, we capture building shadows under various solar zenith angles
throughout the year and at different times of day. These simulated shadows are
aligned with satellite images, providing a rich resource for learning shade
patterns. Second, we propose the DeepShade, a diffusion-based model designed to
learn and synthesize shade variations over time. It emphasizes the nuance of
edge features by jointly considering RGB with the Canny edge layer, and
incorporates contrastive learning to capture the temporal change rules of
shade. Then, by conditioning on textual descriptions of known conditions (e.g.,
time of day, solar angles), our framework provides improved performance in
generating shade images. We demonstrate the utility of our approach by using
our shade predictions to calculate shade ratios for real-world route planning
in Tempe, Arizona. We believe this work will benefit society by providing a
reference for urban planning in extreme heat weather and its potential
practical applications in the environment.

</details>


### [112] [Revealing the Ancient Beauty: Digital Reconstruction of Temple Tiles using Computer Vision](https://arxiv.org/abs/2507.12195)
*Arkaprabha Basu*

Main category: cs.CV

TL;DR: 论文提出三种创新技术（Fractal Convolution、SSTF和Super Resolution）用于印度文化遗产的保护与修复，结合机器学习和计算机视觉技术，实现高效且经济的自动化处理。


<details>
  <summary>Details</summary>
Motivation: 现代数字化方法为文化遗产保护带来革命性变化，但印度古迹的特殊性需要定制化技术，以平衡传统与创新。

Method: 1. Fractal Convolution用于图像分割；2. SSTF结合MosaicSlice数据增强技术修复Bankura陶庙；3. Super Resolution提升图像质量。

Result: 方法实现了高精度修复和细节保留，成本可控，自动化程度高。

Conclusion: 研究为文化遗产保护提供了高效且美观的解决方案，推动了该领域的创新与效率提升。

Abstract: Modern digitised approaches have dramatically changed the preservation and
restoration of cultural treasures, integrating computer scientists into
multidisciplinary projects with ease. Machine learning, deep learning, and
computer vision techniques have revolutionised developing sectors like 3D
reconstruction, picture inpainting,IoT-based methods, genetic algorithms, and
image processing with the integration of computer scientists into
multidisciplinary initiatives. We suggest three cutting-edge techniques in
recognition of the special qualities of Indian monuments, which are famous for
their architectural skill and aesthetic appeal. First is the Fractal
Convolution methodology, a segmentation method based on image processing that
successfully reveals subtle architectural patterns within these irreplaceable
cultural buildings. The second is a revolutionary Self-Sensitive Tile Filling
(SSTF) method created especially for West Bengal's mesmerising Bankura
Terracotta Temples with a brand-new data augmentation method called MosaicSlice
on the third. Furthermore, we delve deeper into the Super Resolution strategy
to upscale the images without losing significant amount of quality. Our methods
allow for the development of seamless region-filling and highly detailed tiles
while maintaining authenticity using a novel data augmentation strategy within
affordable costs introducing automation. By providing effective solutions that
preserve the delicate balance between tradition and innovation, this study
improves the subject and eventually ensures unrivalled efficiency and aesthetic
excellence in cultural heritage protection. The suggested approaches advance
the field into an era of unmatched efficiency and aesthetic quality while
carefully upholding the delicate equilibrium between tradition and innovation.

</details>


### [113] [Out-of-distribution data supervision towards biomedical semantic segmentation](https://arxiv.org/abs/2507.12105)
*Yiquan Gao,Duohui Xu*

Main category: cs.CV

TL;DR: Med-OoD框架通过引入OoD数据监督，解决了医学图像分割中前景与背景误分类的问题，无需外部数据或额外标注，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割网络在有限和不完美的数据集上容易发生前景与背景的误分类，OoD数据在其他视觉任务中的强大表现启发了这一研究。

Method: 提出Med-OoD框架，将OoD数据监督引入全监督医学图像分割，无需外部数据、特征正则化目标或额外标注，且无需修改网络架构。

Result: 实验表明Med-OoD显著减少了像素误分类，在Lizard数据集上性能大幅提升，甚至仅用OoD数据训练的网络达到了76.1% mIoU。

Conclusion: Med-OoD为医学图像分割提供了一种高效的数据中心化解决方案，同时展示了OoD数据的新学习范式，值得进一步研究。

Abstract: Biomedical segmentation networks easily suffer from the unexpected
misclassification between foreground and background objects when learning on
limited and imperfect medical datasets. Inspired by the strong power of
Out-of-Distribution (OoD) data on other visual tasks, we propose a data-centric
framework, Med-OoD to address this issue by introducing OoD data supervision
into fully-supervised biomedical segmentation with none of the following needs:
(i) external data sources, (ii) feature regularization objectives, (iii)
additional annotations. Our method can be seamlessly integrated into
segmentation networks without any modification on the architectures. Extensive
experiments show that Med-OoD largely prevents various segmentation networks
from the pixel misclassification on medical images and achieves considerable
performance improvements on Lizard dataset. We also present an emerging
learning paradigm of training a medical segmentation network completely using
OoD data devoid of foreground class labels, surprisingly turning out 76.1% mIoU
as test result. We hope this learning paradigm will attract people to rethink
the roles of OoD data. Code is made available at
https://github.com/StudioYG/Med-OoD.

</details>


### [114] [LidarPainter: One-Step Away From Any Lidar View To Novel Guidance](https://arxiv.org/abs/2507.12114)
*Yuzhou Ji,Ke Ma,Hong Cai,Anchun Zhang,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: LidarPainter是一种基于扩散模型的实时方法，用于从稀疏LiDAR数据中恢复高质量驾驶场景视图，解决了现有方法在一致性、变形和速度上的局限性。


<details>
  <summary>Details</summary>
Motivation: 动态驾驶场景重建在数字孪生系统和自动驾驶模拟中非常重要，但现有方法在偏离输入轨迹时会出现质量下降问题。

Method: 提出LidarPainter，一种一步扩散模型，从稀疏LiDAR条件和有伪影的渲染中实时恢复一致的驾驶视图。

Result: 实验表明，LidarPainter在速度、质量和资源效率上优于现有方法，比StreetCrafter快7倍且仅需五分之一GPU内存。

Conclusion: LidarPainter不仅实现了高质量重建，还支持通过文本提示生成多样化风格，扩展了现有资产库。

Abstract: Dynamic driving scene reconstruction is of great importance in fields like
digital twin system and autonomous driving simulation. However, unacceptable
degradation occurs when the view deviates from the input trajectory, leading to
corrupted background and vehicle models. To improve reconstruction quality on
novel trajectory, existing methods are subject to various limitations including
inconsistency, deformation, and time consumption. This paper proposes
LidarPainter, a one-step diffusion model that recovers consistent driving views
from sparse LiDAR condition and artifact-corrupted renderings in real-time,
enabling high-fidelity lane shifts in driving scene reconstruction. Extensive
experiments show that LidarPainter outperforms state-of-the-art methods in
speed, quality and resource efficiency, specifically 7 x faster than
StreetCrafter with only one fifth of GPU memory required. LidarPainter also
supports stylized generation using text prompts such as "foggy" and "night",
allowing for a diverse expansion of the existing asset library.

</details>


### [115] [Site-Level Fine-Tuning with Progressive Layer Freezing: Towards Robust Prediction of Bronchopulmonary Dysplasia from Day-1 Chest Radiographs in Extremely Preterm Infants](https://arxiv.org/abs/2507.12269)
*Sybelle Goedicke-Fritz,Michelle Bous,Annika Engel,Matthias Flotho,Pascal Hirsch,Hannah Wittig,Dino Milanovic,Dominik Mohr,Mathias Kaspar,Sogand Nemat,Dorothea Kerner,Arno Bücker,Andreas Keller,Sascha Meyer,Michael Zemlin,Philipp Flotho*

Main category: cs.CV

TL;DR: 该研究开发了一种基于深度学习的模型，利用出生24小时内的胸部X光片预测极低出生体重婴儿的中/重度支气管肺发育不良（BPD）结局，AUROC为0.78。


<details>
  <summary>Details</summary>
Motivation: BPD是一种慢性肺病，预防干预措施具有高风险，因此早期预测BPD结局至关重要，以避免对低风险婴儿的不必要毒性。

Method: 研究使用163名极低出生体重婴儿的胸部X光片，通过微调ResNet-50模型，结合渐进层冻结和CutMix增强技术，预测BPD结局。

Result: 最佳模型的AUROC为0.78，显著优于ImageNet初始化和传统IRDS分级方法。

Conclusion: 研究表明，领域特定的预训练和渐进冻结技术能够有效预测BPD，且具有临床可行性。

Abstract: Bronchopulmonary dysplasia (BPD) is a chronic lung disease affecting 35% of
extremely low birth weight infants. Defined by oxygen dependence at 36 weeks
postmenstrual age, it causes lifelong respiratory complications. However,
preventive interventions carry severe risks, including neurodevelopmental
impairment, ventilator-induced lung injury, and systemic complications.
Therefore, early BPD prognosis and prediction of BPD outcome is crucial to
avoid unnecessary toxicity in low risk infants. Admission radiographs of
extremely preterm infants are routinely acquired within 24h of life and could
serve as a non-invasive prognostic tool. In this work, we developed and
investigated a deep learning approach using chest X-rays from 163 extremely
low-birth-weight infants ($\leq$32 weeks gestation, 401-999g) obtained within
24 hours of birth. We fine-tuned a ResNet-50 pretrained specifically on adult
chest radiographs, employing progressive layer freezing with discriminative
learning rates to prevent overfitting and evaluated a CutMix augmentation and
linear probing. For moderate/severe BPD outcome prediction, our best performing
model with progressive freezing, linear probing and CutMix achieved an AUROC of
0.78 $\pm$ 0.10, balanced accuracy of 0.69 $\pm$ 0.10, and an F1-score of 0.67
$\pm$ 0.11. In-domain pre-training significantly outperformed ImageNet
initialization (p = 0.031) which confirms domain-specific pretraining to be
important for BPD outcome prediction. Routine IRDS grades showed limited
prognostic value (AUROC 0.57 $\pm$ 0.11), confirming the need of learned
markers. Our approach demonstrates that domain-specific pretraining enables
accurate BPD prediction from routine day-1 radiographs. Through progressive
freezing and linear probing, the method remains computationally feasible for
site-level implementation and future federated learning deployments.

</details>


### [116] [Open-Vocabulary Indoor Object Grounding with 3D Hierarchical Scene Graph](https://arxiv.org/abs/2507.12123)
*Sergey Linok,Gleb Naumov*

Main category: cs.CV

TL;DR: OVIGo-3DHSG是一种基于3D分层场景图的开放词汇室内物体定位方法，结合了开放词汇基础模型和传感器数据处理，通过分层表示和大型语言模型实现多步推理。


<details>
  <summary>Details</summary>
Motivation: 解决复杂查询中对物体空间关系的理解问题，提升室内环境的空间推理能力。

Method: 利用RGB-D帧序列构建分层场景图，结合大型语言模型进行多步推理，利用层间和层内连接增强空间上下文理解。

Result: 在Habitat Matterport 3D多楼层场景中验证了语义和几何准确性，表现优于现有方法。

Conclusion: OVIGo-3DHSG在空间推理和室内环境理解方面具有强大潜力。

Abstract: We propose OVIGo-3DHSG method - Open-Vocabulary Indoor Grounding of objects
using 3D Hierarchical Scene Graph. OVIGo-3DHSG represents an extensive indoor
environment over a Hierarchical Scene Graph derived from sequences of RGB-D
frames utilizing a set of open-vocabulary foundation models and sensor data
processing. The hierarchical representation explicitly models spatial relations
across floors, rooms, locations, and objects. To effectively address complex
queries involving spatial reference to other objects, we integrate the
hierarchical scene graph with a Large Language Model for multistep reasoning.
This integration leverages inter-layer (e.g., room-to-object) and intra-layer
(e.g., object-to-object) connections, enhancing spatial contextual
understanding. We investigate the semantic and geometry accuracy of
hierarchical representation on Habitat Matterport 3D Semantic multi-floor
scenes. Our approach demonstrates efficient scene comprehension and robust
object grounding compared to existing methods. Overall OVIGo-3DHSG demonstrates
strong potential for applications requiring spatial reasoning and understanding
of indoor environments. Related materials can be found at
https://github.com/linukc/OVIGo-3DHSG.

</details>


### [117] [Block-based Symmetric Pruning and Fusion for Efficient Vision Transformers](https://arxiv.org/abs/2507.12125)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin Li,Yu-Ming Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: BSPF-ViT通过联合修剪Q/K令牌并考虑令牌交互，显著降低了ViT的计算成本，同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: ViT的高计算成本限制了实际应用，现有方法独立修剪Q/K令牌导致性能下降。

Method: 提出BSPF-ViT，联合修剪Q/K令牌，考虑令牌交互，并通过相似性融合压缩保留的令牌。

Result: 在DeiT-T和DeiT-S上分别提升1.3%和2.0%的ImageNet分类准确率，计算开销减少50%，速度提升40%。

Conclusion: BSPF-ViT在降低计算成本的同时提高了ViT的性能，优于现有方法。

Abstract: Vision Transformer (ViT) has achieved impressive results across various
vision tasks, yet its high computational cost limits practical applications.
Recent methods have aimed to reduce ViT's $O(n^2)$ complexity by pruning
unimportant tokens. However, these techniques often sacrifice accuracy by
independently pruning query (Q) and key (K) tokens, leading to performance
degradation due to overlooked token interactions. To address this limitation,
we introduce a novel {\bf Block-based Symmetric Pruning and Fusion} for
efficient ViT (BSPF-ViT) that optimizes the pruning of Q/K tokens jointly.
Unlike previous methods that consider only a single direction, our approach
evaluates each token and its neighbors to decide which tokens to retain by
taking token interaction into account. The retained tokens are compressed
through a similarity fusion step, preserving key information while reducing
computational costs. The shared weights of Q/K tokens create a symmetric
attention matrix, allowing pruning only the upper triangular part for speed up.
BSPF-ViT consistently outperforms state-of-the-art ViT methods at all pruning
levels, increasing ImageNet classification accuracy by 1.3% on DeiT-T and 2.0%
on DeiT-S, while reducing computational overhead by 50%. It achieves 40%
speedup with improved accuracy across various ViTs.

</details>


### [118] [Learning Pixel-adaptive Multi-layer Perceptrons for Real-time Image Enhancement](https://arxiv.org/abs/2507.12135)
*Junyu Lou,Xiaorui Zhao,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出了一种结合双边网格和MLP的BPAM框架，用于图像增强，解决了现有方法在非线性和局部变化处理上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有双边网格方法仅限于线性变换，而传统MLP方法难以处理局部变化，BPAM框架旨在解决这些问题。

Method: 通过生成包含MLP参数的双边网格，动态为每个像素分配独特的MLP参数，并提出网格分解策略和指导图优化参数生成。

Result: 在公开数据集上表现优于现有方法，同时保持实时处理能力。

Conclusion: BPAM框架有效结合了双边网格的空间建模能力和MLP的非线性映射能力，提升了图像增强效果。

Abstract: Deep learning-based bilateral grid processing has emerged as a promising
solution for image enhancement, inherently encoding spatial and intensity
information while enabling efficient full-resolution processing through slicing
operations. However, existing approaches are limited to linear affine
transformations, hindering their ability to model complex color relationships.
Meanwhile, while multi-layer perceptrons (MLPs) excel at non-linear mappings,
traditional MLP-based methods employ globally shared parameters, which is hard
to deal with localized variations. To overcome these dual challenges, we
propose a Bilateral Grid-based Pixel-Adaptive Multi-layer Perceptron (BPAM)
framework. Our approach synergizes the spatial modeling of bilateral grids with
the non-linear capabilities of MLPs. Specifically, we generate bilateral grids
containing MLP parameters, where each pixel dynamically retrieves its unique
transformation parameters and obtain a distinct MLP for color mapping based on
spatial coordinates and intensity values. In addition, we propose a novel grid
decomposition strategy that categorizes MLP parameters into distinct types
stored in separate subgrids. Multi-channel guidance maps are used to extract
category-specific parameters from corresponding subgrids, ensuring effective
utilization of color information during slicing while guiding precise parameter
generation. Extensive experiments on public datasets demonstrate that our
method outperforms state-of-the-art methods in performance while maintaining
real-time processing capabilities.

</details>


### [119] [AD-GS: Object-Aware B-Spline Gaussian Splatting for Self-Supervised Autonomous Driving](https://arxiv.org/abs/2507.12137)
*Jiawei Xu,Kai Deng,Zexin Fan,Shenlong Wang,Jin Xie,Jian Yang*

Main category: cs.CV

TL;DR: AD-GS是一种自监督框架，用于从单一日志中高质量渲染驾驶场景，无需手动标注。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖昂贵的手动标注或自监督方法无法准确捕捉动态对象运动，导致渲染伪影。

Method: 结合局部感知B样条曲线和全局感知三角函数的学习运动模型，动态高斯表示对象，双向时间可见性掩码。

Result: 在无标注方法中表现显著优于现有技术，与依赖标注的方法竞争。

Conclusion: AD-GS提供了一种高效且高质量的无标注动态场景渲染解决方案。

Abstract: Modeling and rendering dynamic urban driving scenes is crucial for
self-driving simulation. Current high-quality methods typically rely on costly
manual object tracklet annotations, while self-supervised approaches fail to
capture dynamic object motions accurately and decompose scenes properly,
resulting in rendering artifacts. We introduce AD-GS, a novel self-supervised
framework for high-quality free-viewpoint rendering of driving scenes from a
single log. At its core is a novel learnable motion model that integrates
locality-aware B-spline curves with global-aware trigonometric functions,
enabling flexible yet precise dynamic object modeling. Rather than requiring
comprehensive semantic labeling, AD-GS automatically segments scenes into
objects and background with the simplified pseudo 2D segmentation, representing
objects using dynamic Gaussians and bidirectional temporal visibility masks.
Further, our model incorporates visibility reasoning and physically rigid
regularization to enhance robustness. Extensive evaluations demonstrate that
our annotation-free model significantly outperforms current state-of-the-art
annotation-free methods and is competitive with annotation-dependent
approaches.

</details>


### [120] [Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models](https://arxiv.org/abs/2507.12318)
*Samuel Lavoie,Michael Noukhovitch,Aaron Courville*

Main category: cs.CV

TL;DR: 论文提出离散潜在码（DLC）作为扩散模型的输入条件表示，提升生成保真度和组合性，实现超出训练分布的样本生成。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型成功的关键在于输入条件表示，探索理想表示应具备的特性：提升样本保真度、易于生成且具有组合性。

Method: 引入离散潜在码（DLC），基于自监督学习的Simplicial Embeddings，生成离散令牌序列作为图像表示。

Result: DLC显著提升无条件图像生成的保真度，并在ImageNet上达到新SOTA；组合DLC可生成超出训练分布的样本。

Conclusion: DLC为扩散模型提供高效、组合性强的条件表示，支持文本到图像生成，扩展了模型的应用范围。

Abstract: We argue that diffusion models' success in modeling complex distributions is,
for the most part, coming from their input conditioning. This paper
investigates the representation used to condition diffusion models from the
perspective that ideal representations should improve sample fidelity, be easy
to generate, and be compositional to allow out-of-training samples generation.
We introduce Discrete Latent Code (DLC), an image representation derived from
Simplicial Embeddings trained with a self-supervised learning objective. DLCs
are sequences of discrete tokens, as opposed to the standard continuous image
embeddings. They are easy to generate and their compositionality enables
sampling of novel images beyond the training distribution. Diffusion models
trained with DLCs have improved generation fidelity, establishing a new
state-of-the-art for unconditional image generation on ImageNet. Additionally,
we show that composing DLCs allows the image generator to produce
out-of-distribution samples that coherently combine the semantics of images in
diverse ways. Finally, we showcase how DLCs can enable text-to-image generation
by leveraging large-scale pretrained language models. We efficiently finetune a
text diffusion language model to generate DLCs that produce novel samples
outside of the image generator training distribution.

</details>


### [121] [Neural Human Pose Prior](https://arxiv.org/abs/2507.12138)
*Michal Heker,Sefy Kararlitsky,David Tolpin*

Main category: cs.CV

TL;DR: 提出了一种基于归一化流的神经先验方法，用于建模人体姿态分布，解决了6D旋转流形上的分布建模问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为启发式或表达能力有限，需要一种灵活且稳定的方法来建模人体姿态的先验分布。

Method: 使用RealNVP学习6D旋转格式的姿态密度，通过反转Gram-Schmidt过程解决流形上的分布建模问题。

Result: 通过定性和定量评估验证了方法的有效性，并通过消融实验分析了其影响。

Conclusion: 为人体运动捕捉和重建提供了概率基础，支持旋转框架的兼容性。

Abstract: We introduce a principled, data-driven approach for modeling a neural prior
over human body poses using normalizing flows. Unlike heuristic or
low-expressivity alternatives, our method leverages RealNVP to learn a flexible
density over poses represented in the 6D rotation format. We address the
challenge of modeling distributions on the manifold of valid 6D rotations by
inverting the Gram-Schmidt process during training, enabling stable learning
while preserving downstream compatibility with rotation-based frameworks. Our
architecture and training pipeline are framework-agnostic and easily
reproducible. We demonstrate the effectiveness of the learned prior through
both qualitative and quantitative evaluations, and we analyze its impact via
ablation studies. This work provides a sound probabilistic foundation for
integrating pose priors into human motion capture and reconstruction pipelines.

</details>


### [122] [Cluster Contrast for Unsupervised Visual Representation Learning](https://arxiv.org/abs/2507.12359)
*Nikolaos Giakoumoglou,Tania Stathaki*

Main category: cs.CV

TL;DR: Cluster Contrast (CueCo) 是一种结合对比学习和聚类方法的无监督视觉表示学习方法，通过同时分散和对齐特征表示，显著提升了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 近年来，对比学习和聚类方法在无监督视觉表示学习中取得了显著进展，但如何结合两者的优势仍是一个挑战。CueCo旨在通过同时优化对比损失和聚类目标，提升特征表示的质量。

Method: CueCo使用两个神经网络（查询网络和关键网络），关键网络通过查询输出的慢移动平均更新。通过对比损失增强类间分离，通过聚类目标提升类内紧凑性。

Result: 在CIFAR-10、CIFAR-100和ImageNet-100上，CueCo分别实现了91.40%、68.56%和78.65%的top-1分类准确率。

Conclusion: CueCo通过结合对比学习和聚类方法，为无监督视觉表示学习开辟了新方向。

Abstract: We introduce Cluster Contrast (CueCo), a novel approach to unsupervised
visual representation learning that effectively combines the strengths of
contrastive learning and clustering methods. Inspired by recent advancements,
CueCo is designed to simultaneously scatter and align feature representations
within the feature space. This method utilizes two neural networks, a query and
a key, where the key network is updated through a slow-moving average of the
query outputs. CueCo employs a contrastive loss to push dissimilar features
apart, enhancing inter-class separation, and a clustering objective to pull
together features of the same cluster, promoting intra-class compactness. Our
method achieves 91.40% top-1 classification accuracy on CIFAR-10, 68.56% on
CIFAR-100, and 78.65% on ImageNet-100 using linear evaluation with a ResNet-18
backbone. By integrating contrastive learning with clustering, CueCo sets a new
direction for advancing unsupervised visual representation learning.

</details>


### [123] [Fine-Grained Image Recognition from Scratch with Teacher-Guided Data Augmentation](https://arxiv.org/abs/2507.12157)
*Edwin Arkel Rios,Fernando Mikael,Oswin Gosal,Femiloye Oyerinde,Hao-Chun Liang,Bo-Cheng Lai,Min-Chun Hu*

Main category: cs.CV

TL;DR: 论文提出了一种无需预训练模型的高性能细粒度图像识别（FGIR）框架TGDA，通过数据增强和知识蒸馏实现任务特定架构设计，在低分辨率和高分辨率场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FGIR方法依赖预训练模型，限制了在资源受限环境中的适应性和任务特定架构的发展。

Method: 引入TGDA框架，结合数据感知增强和细粒度感知教师模型的弱监督，通过知识蒸馏实现从零开始训练。

Result: 在多个FGIR基准测试中，TGDA框架性能优于或匹配现有预训练方法，低分辨率场景下提升23%准确率，参数和计算量显著减少。

Conclusion: TGDA为细粒度视觉系统提供了一种高效且适应性强的替代方案，减少了对预训练的依赖。

Abstract: Fine-grained image recognition (FGIR) aims to distinguish visually similar
sub-categories within a broader class, such as identifying bird species. While
most existing FGIR methods rely on backbones pretrained on large-scale datasets
like ImageNet, this dependence limits adaptability to resource-constrained
environments and hinders the development of task-specific architectures
tailored to the unique challenges of FGIR.
  In this work, we challenge the conventional reliance on pretrained models by
demonstrating that high-performance FGIR systems can be trained entirely from
scratch. We introduce a novel training framework, TGDA, that integrates
data-aware augmentation with weak supervision via a fine-grained-aware teacher
model, implemented through knowledge distillation. This framework unlocks the
design of task-specific and hardware-aware architectures, including LRNets for
low-resolution FGIR and ViTFS, a family of Vision Transformers optimized for
efficient inference.
  Extensive experiments across three FGIR benchmarks over diverse settings
involving low-resolution and high-resolution inputs show that our method
consistently matches or surpasses state-of-the-art pretrained counterparts. In
particular, in the low-resolution setting, LRNets trained with TGDA improve
accuracy by up to 23\% over prior methods while requiring up to 20.6x less
parameters, lower FLOPs, and significantly less training data. Similarly,
ViTFS-T can match the performance of a ViT B-16 pretrained on ImageNet-21k
while using 15.3x fewer trainable parameters and requiring orders of magnitudes
less data. These results highlight TGDA's potential as an adaptable alternative
to pretraining, paving the way for more efficient fine-grained vision systems.

</details>


### [124] [Hybrid Ensemble Approaches: Optimal Deep Feature Fusion and Hyperparameter-Tuned Classifier Ensembling for Enhanced Brain Tumor Classification](https://arxiv.org/abs/2507.12177)
*Zahid Ullah,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的双集成框架，结合预训练深度学习模型和超参数优化的机器学习模型，以提高脑肿瘤MRI诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: MRI诊断中的人为因素（如疲劳、经验不足）可能导致误诊，因此需要更精确的自动化方法。

Method: 采用预训练深度学习模型进行特征提取，结合超参数优化的机器学习分类器，并通过数据预处理和增强提升效果。

Result: 实验表明，特征融合和分类器融合显著提升了分类性能，超参数优化进一步增强了效果。

Conclusion: 该方法在脑肿瘤分类中优于现有技术，各组件对准确性均有贡献。

Abstract: Magnetic Resonance Imaging (MRI) is widely recognized as the most reliable
tool for detecting tumors due to its capability to produce detailed images that
reveal their presence. However, the accuracy of diagnosis can be compromised
when human specialists evaluate these images. Factors such as fatigue, limited
expertise, and insufficient image detail can lead to errors. For example, small
tumors might go unnoticed, or overlap with healthy brain regions could result
in misidentification. To address these challenges and enhance diagnostic
precision, this study proposes a novel double ensembling framework, consisting
of ensembled pre-trained deep learning (DL) models for feature extraction and
ensembled fine-tuned hyperparameter machine learning (ML) models to efficiently
classify brain tumors. Specifically, our method includes extensive
preprocessing and augmentation, transfer learning concepts by utilizing various
pre-trained deep convolutional neural networks and vision transformer networks
to extract deep features from brain MRI, and fine-tune hyperparameters of ML
classifiers. Our experiments utilized three different publicly available Kaggle
MRI brain tumor datasets to evaluate the pre-trained DL feature extractor
models, ML classifiers, and the effectiveness of an ensemble of deep features
along with an ensemble of ML classifiers for brain tumor classification. Our
results indicate that the proposed feature fusion and classifier fusion improve
upon the state of the art, with hyperparameter fine-tuning providing a
significant enhancement over the ensemble method. Additionally, we present an
ablation study to illustrate how each component contributes to accurate brain
tumor classification.

</details>


### [125] [AutoVDC: Automated Vision Data Cleaning Using Vision-Language Models](https://arxiv.org/abs/2507.12414)
*Santosh Vasa,Aditi Ramadwar,Jnana Rama Krishna Darabattula,Md Zafar Anwar,Stanislaw Antol,Andrei Vatavu,Thomas Monninger,Sihao Ding*

Main category: cs.CV

TL;DR: AutoVDC框架利用视觉语言模型自动检测视觉数据集中的错误标注，提升数据质量，验证显示其高效性。


<details>
  <summary>Details</summary>
Motivation: 人工标注存在缺陷且成本高，需自动化方法提升数据集质量。

Method: 利用Vision-Language Models (VLMs)自动识别错误标注，并在KITTI和nuImages数据集上验证。

Result: AutoVDC在错误检测和数据清理实验中表现优异，显著提升数据集可靠性。

Conclusion: AutoVDC能有效提升自动驾驶大规模数据集的准确性和可靠性。

Abstract: Training of autonomous driving systems requires extensive datasets with
precise annotations to attain robust performance. Human annotations suffer from
imperfections, and multiple iterations are often needed to produce high-quality
datasets. However, manually reviewing large datasets is laborious and
expensive. In this paper, we introduce AutoVDC (Automated Vision Data Cleaning)
framework and investigate the utilization of Vision-Language Models (VLMs) to
automatically identify erroneous annotations in vision datasets, thereby
enabling users to eliminate these errors and enhance data quality. We validate
our approach using the KITTI and nuImages datasets, which contain object
detection benchmarks for autonomous driving. To test the effectiveness of
AutoVDC, we create dataset variants with intentionally injected erroneous
annotations and observe the error detection rate of our approach. Additionally,
we compare the detection rates using different VLMs and explore the impact of
VLM fine-tuning on our pipeline. The results demonstrate our method's high
performance in error detection and data cleaning experiments, indicating its
potential to significantly improve the reliability and accuracy of large-scale
production datasets in autonomous driving.

</details>


### [126] [QuRe: Query-Relevant Retrieval through Hard Negative Sampling in Composed Image Retrieval](https://arxiv.org/abs/2507.12416)
*Jaehyun Kwak,Ramahdani Muhammad Izaaz Inhar,Se-Young Yun,Sung-Ju Lee*

Main category: cs.CV

TL;DR: QuRe通过优化奖励模型和硬负采样策略，减少CIR中的假阴性，提升检索结果与人类偏好的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有CIR方法仅关注目标图像检索，忽视其他图像的相关性，导致假阴性问题，影响用户满意度。

Method: 提出QuRe方法，结合奖励模型优化和硬负采样策略，选择相关性分数陡降后的图像作为负样本。

Result: 在FashionIQ和CIRR数据集上达到最优性能，并在HP-FashionIQ数据集上表现出与人类偏好最强的一致性。

Conclusion: QuRe有效解决了CIR中的假阴性问题，提升了检索结果的质量和用户满意度。

Abstract: Composed Image Retrieval (CIR) retrieves relevant images based on a reference
image and accompanying text describing desired modifications. However, existing
CIR methods only focus on retrieving the target image and disregard the
relevance of other images. This limitation arises because most methods
employing contrastive learning-which treats the target image as positive and
all other images in the batch as negatives-can inadvertently include false
negatives. This may result in retrieving irrelevant images, reducing user
satisfaction even when the target image is retrieved. To address this issue, we
propose Query-Relevant Retrieval through Hard Negative Sampling (QuRe), which
optimizes a reward model objective to reduce false negatives. Additionally, we
introduce a hard negative sampling strategy that selects images positioned
between two steep drops in relevance scores following the target image, to
effectively filter false negatives. In order to evaluate CIR models on their
alignment with human satisfaction, we create Human-Preference FashionIQ
(HP-FashionIQ), a new dataset that explicitly captures user preferences beyond
target retrieval. Extensive experiments demonstrate that QuRe achieves
state-of-the-art performance on FashionIQ and CIRR datasets while exhibiting
the strongest alignment with human preferences on the HP-FashionIQ dataset. The
source code is available at https://github.com/jackwaky/QuRe.

</details>


### [127] [RODS: Robust Optimization Inspired Diffusion Sampling for Detecting and Reducing Hallucination in Generative Models](https://arxiv.org/abs/2507.12201)
*Yiqi Tian,Pengfei Jin,Mingze Yuan,Na Li,Bo Zeng,Quanzheng Li*

Main category: cs.CV

TL;DR: RODS是一种基于优化的扩散采样方法，通过几何线索检测和纠正高风险采样步骤，减少幻觉，提升生成模型的鲁棒性和保真度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的采样过程容易因分数近似不准确而产生幻觉，需要一种无需重新训练且计算成本低的方法来改善。

Method: 通过优化视角重新解释扩散采样，引入RODS方法，利用损失景观的几何线索检测和纠正高风险步骤，平滑采样轨迹并自适应调整扰动。

Result: 在AFHQv2、FFHQ和11k-hands数据集上，RODS检测到70%以上的幻觉样本并纠正超过25%，同时不引入新伪影。

Conclusion: RODS显著提升了扩散模型的采样质量和鲁棒性，为生成建模提供了一种高效且低成本的改进方案。

Abstract: Diffusion models have achieved state-of-the-art performance in generative
modeling, yet their sampling procedures remain vulnerable to hallucinations,
often stemming from inaccuracies in score approximation. In this work, we
reinterpret diffusion sampling through the lens of optimization and introduce
RODS (Robust Optimization-inspired Diffusion Sampler), a novel method that
detects and corrects high-risk sampling steps using geometric cues from the
loss landscape. RODS enforces smoother sampling trajectories and adaptively
adjusts perturbations, reducing hallucinations without retraining and at
minimal additional inference cost. Experiments on AFHQv2, FFHQ, and 11k-hands
demonstrate that RODS improves both sampling fidelity and robustness, detecting
over 70% of hallucinated samples and correcting more than 25%, all while
avoiding the introduction of new artifacts.

</details>


### [128] [MGFFD-VLM: Multi-Granularity Prompt Learning for Face Forgery Detection with VLM](https://arxiv.org/abs/2507.12232)
*Tao Chen,Jingyi Zhang,Decheng Liu,Chunlei Peng*

Main category: cs.CV

TL;DR: 论文提出了一种新的深度伪造检测框架MGFFD-VLM，通过扩展数据集和改进训练策略，提升了视觉大语言模型在伪造检测和解释性方面的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分利用面部质量相关属性，且缺乏有效的训练策略。

Method: 扩展了VQA数据集为DD-VQA+，引入Attribute-Driven Hybrid LoRA策略、多粒度提示学习和伪造感知训练策略。

Result: 实验表明，该方法在文本伪造判断和分析上优于现有方法，准确率更高。

Conclusion: MGFFD-VLM框架显著提升了伪造检测的准确性和解释性。

Abstract: Recent studies have utilized visual large language models (VLMs) to answer
not only "Is this face a forgery?" but also "Why is the face a forgery?" These
studies introduced forgery-related attributes, such as forgery location and
type, to construct deepfake VQA datasets and train VLMs, achieving high
accuracy while providing human-understandable explanatory text descriptions.
However, these methods still have limitations. For example, they do not fully
leverage face quality-related attributes, which are often abnormal in forged
faces, and they lack effective training strategies for forgery-aware VLMs. In
this paper, we extend the VQA dataset to create DD-VQA+, which features a
richer set of attributes and a more diverse range of samples. Furthermore, we
introduce a novel forgery detection framework, MGFFD-VLM, which integrates an
Attribute-Driven Hybrid LoRA Strategy to enhance the capabilities of Visual
Large Language Models (VLMs). Additionally, our framework incorporates
Multi-Granularity Prompt Learning and a Forgery-Aware Training Strategy. By
transforming classification and forgery segmentation results into prompts, our
method not only improves forgery classification but also enhances
interpretability. To further boost detection performance, we design multiple
forgery-related auxiliary losses. Experimental results demonstrate that our
approach surpasses existing methods in both text-based forgery judgment and
analysis, achieving superior accuracy.

</details>


### [129] [Generate to Ground: Multimodal Text Conditioning Boosts Phrase Grounding in Medical Vision-Language Models](https://arxiv.org/abs/2507.12236)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 生成式文本到图像扩散模型在医学影像中实现零样本短语定位，性能优于当前判别式方法，并通过Bimodal Bias Merging（BBM）进一步提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 探索生成式模型在医学影像中短语定位的潜力，以提升疾病定位的准确性和可解释性。

Method: 使用文本到图像扩散模型，结合跨注意力图，并通过BBM后处理技术优化定位结果。

Result: 生成式模型在零样本任务中表现卓越，mIoU分数是当前判别式方法的两倍。

Conclusion: 生成式模型为医学影像中的短语定位提供了更有效的范式，具有临床应用潜力。

Abstract: Phrase grounding, i.e., mapping natural language phrases to specific image
regions, holds significant potential for disease localization in medical
imaging through clinical reports. While current state-of-the-art methods rely
on discriminative, self-supervised contrastive models, we demonstrate that
generative text-to-image diffusion models, leveraging cross-attention maps, can
achieve superior zero-shot phrase grounding performance. Contrary to prior
assumptions, we show that fine-tuning diffusion models with a frozen,
domain-specific language model, such as CXR-BERT, substantially outperforms
domain-agnostic counterparts. This setup achieves remarkable improvements, with
mIoU scores doubling those of current discriminative methods. These findings
highlight the underexplored potential of generative models for phrase grounding
tasks. To further enhance performance, we introduce Bimodal Bias Merging (BBM),
a novel post-processing technique that aligns text and image biases to identify
regions of high certainty. BBM refines cross-attention maps, achieving even
greater localization accuracy. Our results establish generative approaches as a
more effective paradigm for phrase grounding in the medical imaging domain,
paving the way for more robust and interpretable applications in clinical
practice. The source code and model weights are available at
https://github.com/Felix-012/generate_to_ground.

</details>


### [130] [Calisthenics Skills Temporal Video Segmentation](https://arxiv.org/abs/2507.12245)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 论文提出了一种自动识别和分割静态健美操技能视频的方法，并创建了一个标注数据集，展示了基线方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 健美操技能评估需要自动化工具来辅助训练和比赛评分，但目前缺乏针对静态技能时间分割的研究。

Method: 创建了一个标注视频数据集，并提出基线方法进行技能时间分割。

Result: 结果显示该方法可行，但仍有改进空间。

Conclusion: 研究为健美操领域的自动化工具开发提供了初步基础。

Abstract: Calisthenics is a fast-growing bodyweight discipline that consists of
different categories, one of which is focused on skills. Skills in calisthenics
encompass both static and dynamic elements performed by athletes. The
evaluation of static skills is based on their difficulty level and the duration
of the hold. Automated tools able to recognize isometric skills from a video by
segmenting them to estimate their duration would be desirable to assist
athletes in their training and judges during competitions. Although the video
understanding literature on action recognition through body pose analysis is
rich, no previous work has specifically addressed the problem of calisthenics
skill temporal video segmentation. This study aims to provide an initial step
towards the implementation of automated tools within the field of Calisthenics.
To advance knowledge in this context, we propose a dataset of video footage of
static calisthenics skills performed by athletes. Each video is annotated with
a temporal segmentation which determines the extent of each skill. We hence
report the results of a baseline approach to address the problem of skill
temporal segmentation on the proposed dataset. The results highlight the
feasibility of the proposed problem, while there is still room for improvement.

</details>


### [131] [Comparative Analysis of CNN Performance in Keras, PyTorch and JAX on PathMNIST](https://arxiv.org/abs/2507.12248)
*Anida Nezović,Jalal Romano,Nada Marić,Medina Kapo,Amila Akagić*

Main category: cs.CV

TL;DR: 该研究比较了Keras、PyTorch和JAX在医学图像分类任务中的性能，使用PathMNIST数据集评估训练效率、分类准确性和推理速度。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习框架在医学图像分类中广泛应用，但它们在性能上的比较研究较少，需要进一步探索。

Method: 通过在不同框架（Keras、PyTorch、JAX）中实现CNN，并使用PathMNIST数据集进行基准测试，评估训练效率、分类准确性和推理速度。

Result: 研究揭示了计算速度和模型准确性之间的权衡，为医学图像分析提供了实用建议。

Conclusion: 该研究为医学图像分析领域的研究者和从业者提供了关于框架选择的实用见解。

Abstract: Deep learning has significantly advanced the field of medical image
classification, particularly with the adoption of Convolutional Neural Networks
(CNNs). Various deep learning frameworks such as Keras, PyTorch and JAX offer
unique advantages in model development and deployment. However, their
comparative performance in medical imaging tasks remains underexplored. This
study presents a comprehensive analysis of CNN implementations across these
frameworks, using the PathMNIST dataset as a benchmark. We evaluate training
efficiency, classification accuracy and inference speed to assess their
suitability for real-world applications. Our findings highlight the trade-offs
between computational speed and model accuracy, offering valuable insights for
researchers and practitioners in medical image analysis.

</details>


### [132] [Interpreting Radiologist's Intention from Eye Movements in Chest X-ray Diagnosis](https://arxiv.org/abs/2507.12461)
*Trong-Thang Pham,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: RadGazeIntent是一种基于深度学习的模型，旨在捕捉放射科医生在解读医学图像时的意图驱动行为。


<details>
  <summary>Details</summary>
Motivation: 现有模型未能捕捉放射科医生在注视背后的意图，而理解这种意图对提升医学图像分析至关重要。

Method: 采用基于Transformer的架构，处理注视数据的时间和空间维度，将其转化为诊断意图的粗粒度表示。

Result: RadGazeIntent在三个意图标记数据集（RadSeq、RadExplore、RadHybrid）上均优于基线方法。

Conclusion: RadGazeIntent成功建模了放射科医生的意图驱动行为，为医学图像分析提供了新视角。

Abstract: Radiologists rely on eye movements to navigate and interpret medical images.
A trained radiologist possesses knowledge about the potential diseases that may
be present in the images and, when searching, follows a mental checklist to
locate them using their gaze. This is a key observation, yet existing models
fail to capture the underlying intent behind each fixation. In this paper, we
introduce a deep learning-based approach, RadGazeIntent, designed to model this
behavior: having an intention to find something and actively searching for it.
Our transformer-based architecture processes both the temporal and spatial
dimensions of gaze data, transforming fine-grained fixation features into
coarse, meaningful representations of diagnostic intent to interpret
radiologists' goals. To capture the nuances of radiologists' varied
intention-driven behaviors, we process existing medical eye-tracking datasets
to create three intention-labeled subsets: RadSeq (Systematic Sequential
Search), RadExplore (Uncertainty-driven Exploration), and RadHybrid (Hybrid
Pattern). Experimental results demonstrate RadGazeIntent's ability to predict
which findings radiologists are examining at specific moments, outperforming
baseline methods across all intention-labeled datasets.

</details>


### [133] [FADE: Adversarial Concept Erasure in Flow Models](https://arxiv.org/abs/2507.12283)
*Zixuan Fu,Yan Ren,Finn Carter,Chenyue Wang,Ze Niu,Dacheng Yu,Emily Davis,Bo Zhang*

Main category: cs.CV

TL;DR: 提出了一种名为FADE的新方法，用于从文本到图像扩散模型中删除指定概念，确保隐私和公平性，同时保持模型生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面表现出色，但也存在隐私泄露和偏见传播的风险。

Method: FADE结合了轨迹感知的微调策略和对抗性目标，以最小化被删除概念与模型输出之间的互信息。

Result: FADE在概念删除性能和图像质量上优于现有方法，提升了5-10%的调和平均值。

Conclusion: FADE为安全公平的生成建模设定了新标准，无需从头训练即可删除指定概念。

Abstract: Diffusion models have demonstrated remarkable image generation capabilities,
but also pose risks in privacy and fairness by memorizing sensitive concepts or
perpetuating biases. We propose a novel \textbf{concept erasure} method for
text-to-image diffusion models, designed to remove specified concepts (e.g., a
private individual or a harmful stereotype) from the model's generative
repertoire. Our method, termed \textbf{FADE} (Fair Adversarial Diffusion
Erasure), combines a trajectory-aware fine-tuning strategy with an adversarial
objective to ensure the concept is reliably removed while preserving overall
model fidelity. Theoretically, we prove a formal guarantee that our approach
minimizes the mutual information between the erased concept and the model's
outputs, ensuring privacy and fairness. Empirically, we evaluate FADE on Stable
Diffusion and FLUX, using benchmarks from prior work (e.g., object, celebrity,
explicit content, and style erasure tasks from MACE). FADE achieves
state-of-the-art concept removal performance, surpassing recent baselines like
ESD, UCE, MACE, and ANT in terms of removal efficacy and image quality.
Notably, FADE improves the harmonic mean of concept removal and fidelity by
5--10\% over the best prior method. We also conduct an ablation study to
validate each component of FADE, confirming that our adversarial and
trajectory-preserving objectives each contribute to its superior performance.
Our work sets a new standard for safe and fair generative modeling by
unlearning specified concepts without retraining from scratch.

</details>


### [134] [Efficient Calisthenics Skills Classification through Foreground Instance Selection and Depth Estimation](https://arxiv.org/abs/2507.12292)
*Antonio Finocchiaro,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: 该论文提出了一种直接进行健美操技能分类的方法，通过深度估计和运动员区域提取替代传统的高计算成本姿态估计，显著提升了效率和分类精度。


<details>
  <summary>Details</summary>
Motivation: 传统基于姿态估计的健美操技能识别方法计算成本高、推理时间长，限制了实时应用和移动设备的适用性。

Method: 利用Depth Anything V2进行深度估计，YOLOv10进行运动员定位，通过分割主体而非依赖姿态估计技术。

Result: 方法在RGB图像块上推理速度快38.3倍，深度图像块的分类精度更高（0.837 vs. 0.815）。

Conclusion: 该方法不仅性能优越，模块化设计还支持未来灵活改进和实际应用适配。

Abstract: Calisthenics skill classification is the computer vision task of inferring
the skill performed by an athlete from images, enabling automatic performance
assessment and personalized analytics. Traditional methods for calisthenics
skill recognition are based on pose estimation methods to determine the
position of skeletal data from images, which is later fed to a classification
algorithm to infer the performed skill. Despite the progress in human pose
estimation algorithms, they still involve high computational costs, long
inference times, and complex setups, which limit the applicability of such
approaches in real-time applications or mobile devices. This work proposes a
direct approach to calisthenics skill recognition, which leverages depth
estimation and athlete patch retrieval to avoid the computationally expensive
human pose estimation module. Using Depth Anything V2 for depth estimation and
YOLOv10 for athlete localization, we segment the subject from the background
rather than relying on traditional pose estimation techniques. This strategy
increases efficiency, reduces inference time, and improves classification
accuracy. Our approach significantly outperforms skeleton-based methods,
achieving 38.3x faster inference with RGB image patches and improved
classification accuracy with depth patches (0.837 vs. 0.815). Beyond these
performance gains, the modular design of our pipeline allows for flexible
replacement of components, enabling future enhancements and adaptation to
real-world applications.

</details>


### [135] [Unsupervised Monocular 3D Keypoint Discovery from Multi-View Diffusion Priors](https://arxiv.org/abs/2507.12336)
*Subin Jeon,In Cho,Junyoung Hong,Seon Joo Kim*

Main category: cs.CV

TL;DR: KeyDiff3D是一个无监督的单目3D关键点估计框架，利用预训练的多视角扩散模型生成几何先验，仅需单视角图像即可实现3D关键点预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的手动标注或多视角校准图像，而KeyDiff3D旨在通过单视角图像实现高效且准确的3D关键点估计。

Method: 利用预训练的多视角扩散模型生成多视角图像作为监督信号，并提取其2D多视角特征构建3D特征体积，将隐式3D先验转化为显式特征。

Result: 在Human3.6M、Stanford Dogs等数据集上验证了方法的准确性、泛化能力，并展示了从单图像生成3D对象的可操作性。

Conclusion: KeyDiff3D通过扩散模型的几何先验实现了高效的无监督3D关键点估计，并扩展了3D对象的生成与操作能力。

Abstract: This paper introduces KeyDiff3D, a framework for unsupervised monocular 3D
keypoints estimation that accurately predicts 3D keypoints from a single image.
While previous methods rely on manual annotations or calibrated multi-view
images, both of which are expensive to collect, our method enables monocular 3D
keypoints estimation using only a collection of single-view images. To achieve
this, we leverage powerful geometric priors embedded in a pretrained multi-view
diffusion model. In our framework, this model generates multi-view images from
a single image, serving as a supervision signal to provide 3D geometric cues to
our model. We also use the diffusion model as a powerful 2D multi-view feature
extractor and construct 3D feature volumes from its intermediate
representations. This transforms implicit 3D priors learned by the diffusion
model into explicit 3D features. Beyond accurate keypoints estimation, we
further introduce a pipeline that enables manipulation of 3D objects generated
by the diffusion model. Experimental results on diverse aspects and datasets,
including Human3.6M, Stanford Dogs, and several in-the-wild and out-of-domain
datasets, highlight the effectiveness of our method in terms of accuracy,
generalization, and its ability to enable manipulation of 3D objects generated
by the diffusion model from a single image.

</details>


### [136] [Improving Lightweight Weed Detection via Knowledge Distillation](https://arxiv.org/abs/2507.12344)
*Ahmet Oğuz Saltık,Max Voigt,Sourav Modak,Mike Beckworth,Anthony Stein*

Main category: cs.CV

TL;DR: 论文研究了通道知识蒸馏（CWD）和掩码生成蒸馏（MGD）在轻量级模型中的应用，以提高实时智能喷洒系统中的杂草检测性能。实验表明，CWD和MGD显著提升了模型精度，且不影响模型复杂度。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的平台上部署高精度杂草检测模型具有挑战性，尤其是在区分视觉相似的杂草种类时。

Method: 使用YOLO11x作为教师模型，YOLO11n作为学生模型，通过CWD和MGD进行知识蒸馏。

Result: CWD和MGD分别提升了2.5%和1.9%的mAP50，并在嵌入式设备上验证了实时部署的可行性。

Conclusion: CWD和MGD是提高深度学习杂草检测精度的有效、高效且实用的方法。

Abstract: Weed detection is a critical component of precision agriculture, facilitating
targeted herbicide application and reducing environmental impact. However,
deploying accurate object detection models on resource-limited platforms
remains challenging, particularly when differentiating visually similar weed
species commonly encountered in plant phenotyping applications. In this work,
we investigate Channel-wise Knowledge Distillation (CWD) and Masked Generative
Distillation (MGD) to enhance the performance of lightweight models for
real-time smart spraying systems. Utilizing YOLO11x as the teacher model and
YOLO11n as both reference and student, both CWD and MGD effectively transfer
knowledge from the teacher to the student model. Our experiments, conducted on
a real-world dataset comprising sugar beet crops and four weed types (Cirsium,
Convolvulus, Fallopia, and Echinochloa), consistently show increased AP50
across all classes. The distilled CWD student model achieves a notable
improvement of 2.5% and MGD achieves 1.9% in mAP50 over the baseline without
increasing model complexity. Additionally, we validate real-time deployment
feasibility by evaluating the student YOLO11n model on Jetson Orin Nano and
Raspberry Pi 5 embedded devices, performing five independent runs to evaluate
performance stability across random seeds. These findings confirm CWD and MGD
as an effective, efficient, and practical approach for improving deep
learning-based weed detection accuracy in precision agriculture and plant
phenotyping scenarios.

</details>


### [137] [Text-driven Multiplanar Visual Interaction for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.12382)
*Kaiwen Huang,Yi Zhou,Huazhu Fu,Yizhe Zhang,Chen Gong,Tao Zhou*

Main category: cs.CV

TL;DR: 提出了一种名为Text-SemiSeg的文本驱动多平面视觉交互框架，用于半监督医学图像分割，通过文本增强视觉特征，实验证明其优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像标注成本高的问题，利用文本信息增强视觉语义理解，填补3D医学影像任务中文本数据研究的空白。

Method: 框架包含三个模块：文本增强多平面表示（TMR）、类别感知语义对齐（CSA）和动态认知增强（DCA），分别实现文本-视觉交互、跨模态语义对齐和减少标注与未标注数据分布差异。

Result: 在三个公共数据集上的实验表明，该模型能有效利用文本信息增强视觉特征，性能优于其他方法。

Conclusion: Text-SemiSeg框架通过文本驱动的方式提升了半监督医学图像分割的性能，为相关任务提供了新思路。

Abstract: Semi-supervised medical image segmentation is a crucial technique for
alleviating the high cost of data annotation. When labeled data is limited,
textual information can provide additional context to enhance visual semantic
understanding. However, research exploring the use of textual data to enhance
visual semantic embeddings in 3D medical imaging tasks remains scarce. In this
paper, we propose a novel text-driven multiplanar visual interaction framework
for semi-supervised medical image segmentation (termed Text-SemiSeg), which
consists of three main modules: Text-enhanced Multiplanar Representation (TMR),
Category-aware Semantic Alignment (CSA), and Dynamic Cognitive Augmentation
(DCA). Specifically, TMR facilitates text-visual interaction through planar
mapping, thereby enhancing the category awareness of visual features. CSA
performs cross-modal semantic alignment between the text features with
introduced learnable variables and the intermediate layer of visual features.
DCA reduces the distribution discrepancy between labeled and unlabeled data
through their interaction, thus improving the model's robustness. Finally,
experiments on three public datasets demonstrate that our model effectively
enhances visual features with textual information and outperforms other
methods. Our code is available at https://github.com/taozh2017/Text-SemiSeg.

</details>


### [138] [OD-VIRAT: A Large-Scale Benchmark for Object Detection in Realistic Surveillance Environments](https://arxiv.org/abs/2507.12396)
*Hayat Ullah,Abbas Khan,Arslan Munir,Hari Kalva*

Main category: cs.CV

TL;DR: 提出了两个视觉目标检测基准OD-VIRAT Large和OD-VIRAT Tiny，用于评估复杂环境下的人体监控模型性能。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的监控系统需要多样化和具有挑战性的数据集，以全面评估模型性能。

Method: 创建了两个包含丰富标注的数据集，并评估了多种先进目标检测架构（如RETMDET、YOLOX等）在这些数据集上的表现。

Result: OD-VIRAT Large包含8.7百万标注实例，OD-VIRAT Tiny包含288,901标注实例，实验为复杂监控场景下的目标检测提供了基准。

Conclusion: 该工作为开发更高效和鲁棒的目标检测架构奠定了基础，并提供了对现有模型性能的深入见解。

Abstract: Realistic human surveillance datasets are crucial for training and evaluating
computer vision models under real-world conditions, facilitating the
development of robust algorithms for human and human-interacting object
detection in complex environments. These datasets need to offer diverse and
challenging data to enable a comprehensive assessment of model performance and
the creation of more reliable surveillance systems for public safety. To this
end, we present two visual object detection benchmarks named OD-VIRAT Large and
OD-VIRAT Tiny, aiming at advancing visual understanding tasks in surveillance
imagery. The video sequences in both benchmarks cover 10 different scenes of
human surveillance recorded from significant height and distance. The proposed
benchmarks offer rich annotations of bounding boxes and categories, where
OD-VIRAT Large has 8.7 million annotated instances in 599,996 images and
OD-VIRAT Tiny has 288,901 annotated instances in 19,860 images. This work also
focuses on benchmarking state-of-the-art object detection architectures,
including RETMDET, YOLOX, RetinaNet, DETR, and Deformable-DETR on this object
detection-specific variant of VIRAT dataset. To the best of our knowledge, it
is the first work to examine the performance of these recently published
state-of-the-art object detection architectures on realistic surveillance
imagery under challenging conditions such as complex backgrounds, occluded
objects, and small-scale objects. The proposed benchmarking and experimental
settings will help in providing insights concerning the performance of selected
object detection models and set the base for developing more efficient and
robust object detection architectures.

</details>


### [139] [InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization](https://arxiv.org/abs/2507.12420)
*Haoyuan Liu,Hiroshi Watanabe*

Main category: cs.CV

TL;DR: 论文提出了一种新的损失函数InterpIoU，通过插值框解决IoU在非重叠情况下的不可微问题，并避免现有几何惩罚导致的边界框扩大问题。进一步提出Dynamic InterpIoU，动态调整插值系数，显著提升了小物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有IoU损失函数依赖手工设计的几何惩罚，对框的形状、大小和分布敏感，导致小物体检测性能不佳和边界框扩大问题。

Method: 提出InterpIoU，利用插值框与目标框的IoU作为损失项，避免手工惩罚；进一步提出Dynamic InterpIoU，动态调整插值系数。

Result: 在COCO、VisDrone和PASCAL VOC数据集上，InterpIoU和Dynamic InterpIoU均优于现有IoU损失函数，尤其在小物体检测中表现突出。

Conclusion: InterpIoU和Dynamic InterpIoU通过插值框优化IoU损失，解决了现有方法的局限性，显著提升了检测性能。

Abstract: Bounding box regression (BBR) is fundamental to object detection, where the
regression loss is crucial for accurate localization. Existing IoU-based losses
often incorporate handcrafted geometric penalties to address IoU's
non-differentiability in non-overlapping cases and enhance BBR performance.
However, these penalties are sensitive to box shape, size, and distribution,
often leading to suboptimal optimization for small objects and undesired
behaviors such as bounding box enlargement due to misalignment with the IoU
objective. To address these limitations, we propose InterpIoU, a novel loss
function that replaces handcrafted geometric penalties with a term based on the
IoU between interpolated boxes and the target. By using interpolated boxes to
bridge the gap between predictions and ground truth, InterpIoU provides
meaningful gradients in non-overlapping cases and inherently avoids the box
enlargement issue caused by misaligned penalties. Simulation results further
show that IoU itself serves as an ideal regression target, while existing
geometric penalties are both unnecessary and suboptimal. Building on InterpIoU,
we introduce Dynamic InterpIoU, which dynamically adjusts interpolation
coefficients based on IoU values, enhancing adaptability to scenarios with
diverse object distributions. Experiments on COCO, VisDrone, and PASCAL VOC
show that our methods consistently outperform state-of-the-art IoU-based losses
across various detection frameworks, with particularly notable improvements in
small object detection, confirming their effectiveness.

</details>


### [140] [DVFL-Net: A Lightweight Distilled Video Focal Modulation Network for Spatio-Temporal Action Recognition](https://arxiv.org/abs/2507.12426)
*Hayat Ullah,Muhammad Ali Shafique,Abbas Khan,Arslan Munir*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级的视频焦点调制网络DVFL-Net，通过知识蒸馏和时空特征调制，在保持高性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在视频识别中表现出色，但其计算成本高，难以在设备上高效部署。因此，需要一种轻量化的解决方案。

Method: DVFL-Net结合知识蒸馏和时空焦点调制，从大型预训练教师模型中提取时空知识，并利用前向KL散度传递局部和全局上下文。

Result: DVFL-Net在多个基准测试中表现出色，实现了性能与效率的平衡，内存占用低、计算量少且精度高。

Conclusion: DVFL-Net是一种适用于实时人类动作识别的高效解决方案，兼具高性能和低计算成本。

Abstract: The landscape of video recognition has evolved significantly, shifting from
traditional Convolutional Neural Networks (CNNs) to Transformer-based
architectures for improved accuracy. While 3D CNNs have been effective at
capturing spatiotemporal dynamics, recent Transformer models leverage
self-attention to model long-range spatial and temporal dependencies. Despite
achieving state-of-the-art performance on major benchmarks, Transformers remain
computationally expensive, particularly with dense video data. To address this,
we propose a lightweight Video Focal Modulation Network, DVFL-Net, which
distills spatiotemporal knowledge from a large pre-trained teacher into a
compact nano student model, enabling efficient on-device deployment. DVFL-Net
utilizes knowledge distillation and spatial-temporal feature modulation to
significantly reduce computation while preserving high recognition performance.
We employ forward Kullback-Leibler (KL) divergence alongside spatio-temporal
focal modulation to effectively transfer both local and global context from the
Video-FocalNet Base (teacher) to the proposed VFL-Net (student). We evaluate
DVFL-Net on UCF50, UCF101, HMDB51, SSV2, and Kinetics-400, benchmarking it
against recent state-of-the-art methods in Human Action Recognition (HAR).
Additionally, we conduct a detailed ablation study analyzing the impact of
forward KL divergence. The results confirm the superiority of DVFL-Net in
achieving an optimal balance between performance and efficiency, demonstrating
lower memory usage, reduced GFLOPs, and strong accuracy, making it a practical
solution for real-time HAR applications.

</details>


### [141] [Traffic-Aware Pedestrian Intention Prediction](https://arxiv.org/abs/2507.12433)
*Fahimeh Orvati Nia,Hai Lin*

Main category: cs.CV

TL;DR: 提出了一种结合交通信号状态和场景信息的时空图卷积网络（TA-STGCN），显著提升了行人意图预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在行人意图预测中常忽略动态交通信号和场景信息，而这对自动驾驶的安全导航至关重要。

Method: 提出TA-STGCN，整合交通信号状态（红、黄、绿）和边界框尺寸作为关键特征，捕捉复杂城市环境中的时空依赖关系。

Result: 在PIE数据集上，TA-STGCN比基线模型准确率提升4.75%。

Conclusion: TA-STGCN通过动态交通信号和场景信息的整合，显著提升了行人意图预测的准确性。

Abstract: Accurate pedestrian intention estimation is crucial for the safe navigation
of autonomous vehicles (AVs) and hence attracts a lot of research attention.
However, current models often fail to adequately consider dynamic traffic
signals and contextual scene information, which are critical for real-world
applications. This paper presents a Traffic-Aware Spatio-Temporal Graph
Convolutional Network (TA-STGCN) that integrates traffic signs and their states
(Red, Yellow, Green) into pedestrian intention prediction. Our approach
introduces the integration of dynamic traffic signal states and bounding box
size as key features, allowing the model to capture both spatial and temporal
dependencies in complex urban environments. The model surpasses existing
methods in accuracy. Specifically, TA-STGCN achieves a 4.75% higher accuracy
compared to the baseline model on the PIE dataset, demonstrating its
effectiveness in improving pedestrian intention prediction.

</details>


### [142] [Describe Anything Model for Visual Question Answering on Text-rich Images](https://arxiv.org/abs/2507.12441)
*Yen-Linh Vu,Dinh-Thang Duong,Truong-Binh Duong,Anh-Khoi Nguyen,Thanh-Huy Nguyen,Le Thien Phuc Nguyen,Jianhua Xing,Xingjian Li,Tianyang Wang,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DAM-QA利用DAM的区域感知能力改进文本密集图像的VQA任务，通过多区域视图聚合答案，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究DAM的区域级描述能力是否有助于文本密集图像的VQA任务，尤其是需要提取细粒度文本信息的场景。

Method: 提出DAM-QA框架，结合DAM的区域感知能力，设计多区域视图聚合机制，优化文本相关证据的识别。

Result: 在六个VQA基准测试中表现优于基线DAM，DocVQA上提升7+分，参数更少且性能接近通用VLMs。

Conclusion: DAM类模型在文本密集VQA任务中潜力巨大，高效使用和集成策略可缩小与通用VLMs的差距。

Abstract: Recent progress has been made in region-aware vision-language modeling,
particularly with the emergence of the Describe Anything Model (DAM). DAM is
capable of generating detailed descriptions of any specific image areas or
objects without the need for additional localized image-text alignment
supervision. We hypothesize that such region-level descriptive capability is
beneficial for the task of Visual Question Answering (VQA), especially in
challenging scenarios involving images with dense text. In such settings, the
fine-grained extraction of textual information is crucial to producing correct
answers. Motivated by this, we introduce DAM-QA, a framework with a tailored
evaluation protocol, developed to investigate and harness the region-aware
capabilities from DAM for the text-rich VQA problem that requires reasoning
over text-based information within images. DAM-QA incorporates a mechanism that
aggregates answers from multiple regional views of image content, enabling more
effective identification of evidence that may be tied to text-related elements.
Experiments on six VQA benchmarks show that our approach consistently
outperforms the baseline DAM, with a notable 7+ point gain on DocVQA. DAM-QA
also achieves the best overall performance among region-aware models with fewer
parameters, significantly narrowing the gap with strong generalist VLMs. These
results highlight the potential of DAM-like models for text-rich and broader
VQA tasks when paired with efficient usage and integration strategies. Our code
is publicly available at https://github.com/Linvyl/DAM-QA.git.

</details>


### [143] [Vision-based Perception for Autonomous Vehicles in Obstacle Avoidance Scenarios](https://arxiv.org/abs/2507.12449)
*Van-Hoang-Anh Phan,Chi-Tam Nguyen,Doan-Trung Au,Thanh-Danh Phan,Minh-Thien Duong,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于摄像头感知和Frenet-Pure Pursuit规划的障碍物避障系统，结合YOLOv11和目标深度估计模型，在校园环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为确保自动驾驶车辆的安全性，需要高效的障碍物避障系统。

Method: 采用摄像头感知模块（YOLOv11和Depth Anything V2）和Frenet-Pure Pursuit规划策略。

Result: 系统在多样场景中表现良好，有效避障。

Conclusion: 提出的方法在复杂环境中提升了自动驾驶的避障能力。

Abstract: Obstacle avoidance is essential for ensuring the safety of autonomous
vehicles. Accurate perception and motion planning are crucial to enabling
vehicles to navigate complex environments while avoiding collisions. In this
paper, we propose an efficient obstacle avoidance pipeline that leverages a
camera-only perception module and a Frenet-Pure Pursuit-based planning
strategy. By integrating advancements in computer vision, the system utilizes
YOLOv11 for object detection and state-of-the-art monocular depth estimation
models, such as Depth Anything V2, to estimate object distances. A comparative
analysis of these models provides valuable insights into their accuracy,
efficiency, and robustness in real-world conditions. The system is evaluated in
diverse scenarios on a university campus, demonstrating its effectiveness in
handling various obstacles and enhancing autonomous navigation. The video
presenting the results of the obstacle avoidance experiments is available at:
https://www.youtube.com/watch?v=FoXiO5S_tA8

</details>


### [144] [Mitigating Object Hallucinations via Sentence-Level Early Intervention](https://arxiv.org/abs/2507.12455)
*Shangpin Peng,Senqiao Yang,Li Jiang,Zhuotao Tian*

Main category: cs.CV

TL;DR: SENTINEL框架通过句子级早期干预和领域内偏好学习，显著减少多模态大语言模型的幻觉问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在跨模态理解中存在幻觉问题，现有方法成本高或引入数据分布不匹配。

Method: 通过迭代采样模型输出、验证对象存在性并分类句子，构建上下文感知偏好数据，使用C-DPO损失训练模型。

Result: SENTINEL将幻觉减少90%以上，在幻觉和通用能力基准测试中优于现有方法。

Conclusion: SENTINEL框架在减少幻觉和保持模型能力方面表现出色，具有推广潜力。

Abstract: Multimodal large language models (MLLMs) have revolutionized cross-modal
understanding but continue to struggle with hallucinations - fabricated content
contradicting visual inputs. Existing hallucination mitigation methods either
incur prohibitive computational costs or introduce distribution mismatches
between training data and model outputs. We identify a critical insight:
hallucinations predominantly emerge at the early stages of text generation and
propagate through subsequent outputs. To address this, we propose **SENTINEL**
(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain
pr**E**ference **L**earning), a framework that eliminates dependency on human
annotations. Specifically, we first bootstrap high-quality in-domain preference
pairs by iteratively sampling model outputs, validating object existence
through cross-checking with two open-vocabulary detectors, and classifying
sentences into hallucinated/non-hallucinated categories. Subsequently, we use
context-coherent positive samples and hallucinated negative samples to build
context-aware preference data iteratively. Finally, we train models using a
context-aware preference loss (C-DPO) that emphasizes discriminative learning
at the sentence level where hallucinations initially manifest. Experimental
results show that SENTINEL can reduce hallucinations by over 90\% compared to
the original model and outperforms the previous state-of-the-art method on both
hallucination benchmarks and general capabilities benchmarks, demonstrating its
superiority and generalization ability. The models, datasets, and code are
available at https://github.com/pspdada/SENTINEL.

</details>


### [145] [SpatialTrackerV2: 3D Point Tracking Made Easy](https://arxiv.org/abs/2507.12462)
*Yuxi Xiao,Jianyuan Wang,Nan Xue,Nikita Karaev,Yuri Makarov,Bingyi Kang,Xing Zhu,Hujun Bao,Yujun Shen,Xiaowei Zhou*

Main category: cs.CV

TL;DR: SpatialTrackerV2是一种基于单目视频的前馈3D点跟踪方法，通过统一点跟踪、单目深度和相机姿态估计，实现了高性能的3D跟踪。


<details>
  <summary>Details</summary>
Motivation: 超越现有基于现成组件的模块化3D跟踪方法，探索点跟踪、深度估计和相机姿态之间的内在联系。

Method: 将世界空间3D运动分解为场景几何、相机自运动和像素级物体运动，采用全可微分和端到端架构，支持跨多种数据集的训练。

Result: 性能优于现有3D跟踪方法30%，与领先的动态3D重建方法精度相当，但速度快50倍。

Conclusion: SpatialTrackerV2通过联合学习几何和运动，实现了高效且高性能的3D点跟踪。

Abstract: We present SpatialTrackerV2, a feed-forward 3D point tracking method for
monocular videos. Going beyond modular pipelines built on off-the-shelf
components for 3D tracking, our approach unifies the intrinsic connections
between point tracking, monocular depth, and camera pose estimation into a
high-performing and feedforward 3D point tracker. It decomposes world-space 3D
motion into scene geometry, camera ego-motion, and pixel-wise object motion,
with a fully differentiable and end-to-end architecture, allowing scalable
training across a wide range of datasets, including synthetic sequences, posed
RGB-D videos, and unlabeled in-the-wild footage. By learning geometry and
motion jointly from such heterogeneous data, SpatialTrackerV2 outperforms
existing 3D tracking methods by 30%, and matches the accuracy of leading
dynamic 3D reconstruction approaches while running 50$\times$ faster.

</details>


### [146] [MMHU: A Massive-Scale Multimodal Benchmark for Human Behavior Understanding](https://arxiv.org/abs/2507.12463)
*Renjie Li,Ruijie Ye,Mingyang Wu,Hao Frank Yang,Zhiwen Fan,Hezhen Hu,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 提出MMHU，一个大规模的人类行为分析基准，包含丰富的注释，如运动、轨迹、意图等，用于自动驾驶领域。


<details>
  <summary>Details</summary>
Motivation: 理解人类行为对开发安全驾驶系统至关重要，但目前缺乏全面的评估基准。

Method: 开发了包含57k运动片段和1.73M帧的数据集，结合多种来源，并采用人机协作标注流程。

Result: 提供了多任务基准，包括运动预测、生成和行为问答，为自动驾驶行为理解提供广泛评估。

Conclusion: MMHU填补了自动驾驶领域人类行为理解评估的空白，为未来研究提供了重要资源。

Abstract: Humans are integral components of the transportation ecosystem, and
understanding their behaviors is crucial to facilitating the development of
safe driving systems. Although recent progress has explored various aspects of
human behavior$\unicode{x2014}$such as motion, trajectories, and
intention$\unicode{x2014}$a comprehensive benchmark for evaluating human
behavior understanding in autonomous driving remains unavailable. In this work,
we propose $\textbf{MMHU}$, a large-scale benchmark for human behavior analysis
featuring rich annotations, such as human motion and trajectories, text
description for human motions, human intention, and critical behavior labels
relevant to driving safety. Our dataset encompasses 57k human motion clips and
1.73M frames gathered from diverse sources, including established driving
datasets such as Waymo, in-the-wild videos from YouTube, and self-collected
data. A human-in-the-loop annotation pipeline is developed to generate rich
behavior captions. We provide a thorough dataset analysis and benchmark
multiple tasks$\unicode{x2014}$ranging from motion prediction to motion
generation and human behavior question answering$\unicode{x2014}$thereby
offering a broad evaluation suite. Project page :
https://MMHU-Benchmark.github.io.

</details>


### [147] [CytoSAE: Interpretable Cell Embeddings for Hematology](https://arxiv.org/abs/2507.12464)
*Muhammed Furkan Dasdelen,Hyesu Lim,Michele Buck,Katharina S. Götze,Carsten Marr,Steffen Schneider*

Main category: cs.CV

TL;DR: CytoSAE是一种稀疏自编码器，用于医学图像分析，能发现形态学相关概念并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像领域缺乏解释基础模型推理的工具，SAEs在视觉领域的成功启发了其在医学图像中的应用。

Method: 提出CytoSAE，基于40,000多张外周血单细胞图像训练，适用于多样化和跨域数据集。

Result: CytoSAE能识别形态学相关概念，生成患者和疾病特异性概念，并在AML亚型分类任务中表现优异。

Conclusion: CytoSAE在提供亚细胞级解释的同时，性能与最先进方法相当，具有临床应用潜力。

Abstract: Sparse autoencoders (SAEs) emerged as a promising tool for mechanistic
interpretability of transformer-based foundation models. Very recently, SAEs
were also adopted for the visual domain, enabling the discovery of visual
concepts and their patch-wise attribution to tokens in the transformer model.
While a growing number of foundation models emerged for medical imaging, tools
for explaining their inferences are still lacking. In this work, we show the
applicability of SAEs for hematology. We propose CytoSAE, a sparse autoencoder
which is trained on over 40,000 peripheral blood single-cell images. CytoSAE
generalizes to diverse and out-of-domain datasets, including bone marrow
cytology, where it identifies morphologically relevant concepts which we
validated with medical experts. Furthermore, we demonstrate scenarios in which
CytoSAE can generate patient-specific and disease-specific concepts, enabling
the detection of pathognomonic cells and localized cellular abnormalities at
the patch level. We quantified the effect of concepts on a patient-level AML
subtype classification task and show that CytoSAE concepts reach performance
comparable to the state-of-the-art, while offering explainability on the
sub-cellular level. Source code and model weights are available at
https://github.com/dynamical-inference/cytosae.

</details>


### [148] [PhysX: Physical-Grounded 3D Asset Generation](https://arxiv.org/abs/2507.12465)
*Ziang Cao,Zhaoxi Chen,Linag Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: 论文提出PhysX，一种物理基础的3D资产生成方法，包括数据集PhysXNet和生成框架PhysXGen，填补了物理标注3D数据的空白。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型忽视物理属性，限制了在仿真和具身AI等领域的应用。

Method: 提出PhysXNet数据集和PhysXGen框架，通过双分支架构将物理知识注入预训练的3D结构空间。

Result: 实验验证了框架的优越性能和泛化能力。

Conclusion: PhysX为生成物理AI提供了新范式，代码和数据将开源以促进研究。

Abstract: 3D modeling is moving from virtual to physical. Existing 3D generation
primarily emphasizes geometries and textures while neglecting physical-grounded
modeling. Consequently, despite the rapid development of 3D generative models,
the synthesized 3D assets often overlook rich and important physical
properties, hampering their real-world application in physical domains like
simulation and embodied AI. As an initial attempt to address this challenge, we
propose \textbf{PhysX}, an end-to-end paradigm for physical-grounded 3D asset
generation. 1) To bridge the critical gap in physics-annotated 3D datasets, we
present PhysXNet - the first physics-grounded 3D dataset systematically
annotated across five foundational dimensions: absolute scale, material,
affordance, kinematics, and function description. In particular, we devise a
scalable human-in-the-loop annotation pipeline based on vision-language models,
which enables efficient creation of physics-first assets from raw 3D assets.2)
Furthermore, we propose \textbf{PhysXGen}, a feed-forward framework for
physics-grounded image-to-3D asset generation, injecting physical knowledge
into the pre-trained 3D structural space. Specifically, PhysXGen employs a
dual-branch architecture to explicitly model the latent correlations between 3D
structures and physical properties, thereby producing 3D assets with plausible
physical predictions while preserving the native geometry quality. Extensive
experiments validate the superior performance and promising generalization
capability of our framework. All the code, data, and models will be released to
facilitate future research in generative physical AI.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [149] [SIEVE: Effective Filtered Vector Search with Collection of Indexes](https://arxiv.org/abs/2507.11907)
*Zhaoheng Li,Silu Huang,Wei Ding,Yongjoo Park,Jianjun Chen*

Main category: cs.DB

TL;DR: 提出了一种基于多索引构建的过滤向量搜索方法，解决了现有图遍历方法在硬约束条件下效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有图遍历方法在硬约束条件下效率低下，无法满足广泛谓词范围的需求。

Method: 构建多个索引服务于不同谓词形式，通过三维分析模型优化索引大小、搜索时间和召回率，并动态选择最优索引。

Result: 在多种数据集上表现优异，速度提升高达8.06倍，构建时间低至1%，内存占用仅为标准HNSW图的2.15倍。

Conclusion: 该方法在过滤向量搜索中具有显著优势，适用于不同选择性和形式的谓词。

Abstract: Many real-world tasks such as recommending videos with the kids tag can be
reduced to finding most similar vectors associated with hard predicates. This
task, filtered vector search, is challenging as prior state-of-the-art
graph-based (unfiltered) similarity search techniques quickly degenerate when
hard constraints are considered. That is, effective graph-based filtered
similarity search relies on sufficient connectivity for reaching the most
similar items within just a few hops. To consider predicates, recent works
propose modifying graph traversal to visit only the items that may satisfy
predicates. However, they fail to offer the just-a-few-hops property for a wide
range of predicates: they must restrict predicates significantly or lose
efficiency if only a small fraction of items satisfy predicates.
  We propose an opposite approach: instead of constraining traversal, we build
many indexes each serving different predicate forms. For effective
construction, we devise a three-dimensional analytical model capturing
relationships among index size, search time, and recall, with which we follow a
workload-aware approach to pack as many useful indexes as possible into a
collection. At query time, the analytical model is employed yet again to
discern the one that offers the fastest search at a given recall. We show
superior performance and support on datasets with varying selectivities and
forms: our approach achieves up to 8.06x speedup while having as low as 1%
build time versus other indexes, with less than 2.15x memory of a standard HNSW
graph and modest knowledge of past workloads.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [150] [The AI Shadow War: SaaS vs. Edge Computing Architectures](https://arxiv.org/abs/2507.11545)
*Rhea Pritham Marpu,Kevin J McNamara,Preeti Gupta*

Main category: cs.DC

TL;DR: 本文探讨了集中式云AI与分散式边缘AI的竞争，重点分析了计算能力、能效和数据隐私。边缘AI在性能和能效上挑战云AI，并因其数据主权和环保优势而快速增长。


<details>
  <summary>Details</summary>
Motivation: 研究集中式云AI与分散式边缘AI的竞争，揭示边缘AI在性能、能效和数据隐私方面的优势。

Method: 通过分析计算能力、能效和数据隐私，比较边缘AI与云AI的性能。

Result: 边缘AI在能效上具有10,000倍优势，数据主权更强，市场预计快速增长。

Conclusion: 边缘AI的分布式方法更高效，未来将形成混合边缘-云生态系统。

Abstract: The very DNA of AI architecture presents conflicting paths: centralized
cloud-based models (Software-as-a-Service) versus decentralized edge AI (local
processing on consumer devices). This paper analyzes the competitive
battleground across computational capability, energy efficiency, and data
privacy. Recent breakthroughs show edge AI challenging cloud systems on
performance, leveraging innovations like test-time training and
mixture-of-experts architectures. Crucially, edge AI boasts a 10,000x
efficiency advantage: modern ARM processors consume merely 100 microwatts
forinference versus 1 watt for equivalent cloud processing. Beyond efficiency,
edge AI secures data sovereignty by keeping processing local, dismantling
single points of failure in centralized architectures. This democratizes access
throughaffordable hardware, enables offline functionality, and reduces
environmental impact by eliminating data transmission costs. The edge AI market
projects explosive growth from $9 billion in 2025 to $49.6 billion by 2030
(38.5% CAGR), fueled by privacy demands and real-time analytics. Critical
applications including personalized education, healthcare monitoring,
autonomous transport, and smart infrastructure rely on edge AI's ultra-low
latency (5-10ms versus 100-500ms for cloud). The convergence of architectural
innovation with fundamental physics confirms edge AI's distributed approach
aligns with efficient information processing, signaling the inevitable
emergence of hybrid edge-cloud ecosystems.

</details>


### [151] [A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing](https://arxiv.org/abs/2507.11560)
*Xin Wang,Xiao Huan Li,Xun Wang*

Main category: cs.DC

TL;DR: 论文提出了一种针对IIoT边缘计算环境的AIGC任务卸载框架，首次考虑了模型切换带来的延迟和能耗，并通过MADDPG-MATO算法优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于云计算的生成模型难以满足IIoT环境中AIGC任务的实时需求，而边缘计算虽能降低延迟，但动态任务和资源限制带来新挑战。

Method: 提出多智能体协作的AIGC任务卸载框架，设计基于MADDPG-MATO的算法，优化延迟和能耗。

Result: 实验显示，MADDPG-MATO在延迟、能耗和任务完成率上均优于基线算法。

Conclusion: 该算法在动态高负载IIoT环境中表现出鲁棒性和高效性。

Abstract: The integration of the Industrial Internet of Things (IIoT) with Artificial
Intelligence-Generated Content (AIGC) offers new opportunities for smart
manufacturing, but it also introduces challenges related to
computation-intensive tasks and low-latency demands. Traditional generative
models based on cloud computing are difficult to meet the real-time
requirements of AIGC tasks in IIoT environments, and edge computing can
effectively reduce latency through task offloading. However, the dynamic nature
of AIGC tasks, model switching delays, and resource constraints impose higher
demands on edge computing environments. To address these challenges, this paper
proposes an AIGC task offloading framework tailored for IIoT edge computing
environments, considering the latency and energy consumption caused by AIGC
model switching for the first time. IIoT devices acted as multi-agent
collaboratively offload their dynamic AIGC tasks to the most appropriate edge
servers deployed with different generative models. A model aware AIGC task
offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient
(MADDPG-MATO) is devised to minimize the latency and energy. Experimental
results show that MADDPG-MATO outperforms baseline algorithms, achieving an
average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72%
increase in task completion rate across four sets of experiments with model
numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is
robust and efficient in dynamic, high-load IIoT environments.

</details>


### [152] [Environmentally-Conscious Cloud Orchestration Considering Geo-Distributed Data Centers](https://arxiv.org/abs/2507.11563)
*Giulio Attenni,Novella Bartolini*

Main category: cs.DC

TL;DR: 本文提出了一种理论框架，用于在云环境中实现环保意识的作业部署和迁移，旨在最小化资源供应的环境影响，同时满足可持续性要求。


<details>
  <summary>Details</summary>
Motivation: 随着对可持续云服务需求的增长，客户需要基于可持续性指标选择数据中心运营商，并准确报告其服务的生态足迹。

Method: 分析可持续性报告，定义数据中心的环境影响概况，建立优化模型以平衡多种环境因素和用户偏好。

Result: 模拟案例研究表明，该方法相比仅优化单一可持续性因素的基线策略具有潜力。

Conclusion: 该框架为云服务的可持续性优化提供了理论支持，并展示了多因素平衡的优势。

Abstract: This paper presents a theoretical discussion for environmentally-conscious
job deployment and migration in cloud environments, aiming to minimize the
environmental impact of resource provisioning while incorporating
sustainability requirements. As the demand for sustainable cloud services
grows, it is crucial for cloud customers to select data center operators based
on sustainability metrics and to accurately report the ecological footprint of
their services. To this end, we analyze sustainability reports and define
comprehensive environmental impact profiles for data centers, incorporating key
sustainability indicators. We formalize the problem as an optimization model,
balancing multiple environmental factors while respecting user preferences. A
simulative case study demonstrates the {potential} of our approach compared to
baseline strategies that optimize for single sustainability factors.

</details>


### [153] [PGT-I: Scaling Spatiotemporal GNNs with Memory-Efficient Distributed Training](https://arxiv.org/abs/2507.11683)
*Seth Ockerman,Amal Gueroudji,Tanwi Mallick,Yixuan He,Line Pouchard,Robert Ross,Shivaram Venkataraman*

Main category: cs.DC

TL;DR: PGT-I扩展了PyTorch Geometric Temporal，通过分布式数据并行训练和两种新策略（index-batching和distributed-index-batching），显著降低内存开销，实现大规模ST-GNN训练。


<details>
  <summary>Details</summary>
Motivation: 现有分布式训练框架对时空模型支持不足，且未充分利用时空数据特性，限制了ST-GNN在大规模数据集上的应用。

Method: 提出PGT-I，结合分布式数据并行训练和两种索引技术（index-batching和distributed-index-batching），动态构建时空快照以减少内存占用。

Result: 在PeMS数据集上首次实现全图训练，内存峰值降低89%，128 GPU下速度提升13.1倍。

Conclusion: PGT-I为大规模时空图神经网络训练提供了高效解决方案。

Abstract: Spatiotemporal graph neural networks (ST-GNNs) are powerful tools for
modeling spatial and temporal data dependencies. However, their applications
have been limited primarily to small-scale datasets because of memory
constraints. While distributed training offers a solution, current frameworks
lack support for spatiotemporal models and overlook the properties of
spatiotemporal data. Informed by a scaling study on a large-scale workload, we
present PyTorch Geometric Temporal Index (PGT-I), an extension to PyTorch
Geometric Temporal that integrates distributed data parallel training and two
novel strategies: index-batching and distributed-index-batching. Our index
techniques exploit spatiotemporal structure to construct snapshots dynamically
at runtime, significantly reducing memory overhead, while
distributed-index-batching extends this approach by enabling scalable
processing across multiple GPUs. Our techniques enable the first-ever training
of an ST-GNN on the entire PeMS dataset without graph partitioning, reducing
peak memory usage by up to 89\% and achieving up to a 13.1x speedup over
standard DDP with 128 GPUs.

</details>


### [154] [Arctic Inference with Shift Parallelism: Fast and Efficient Open Source Inference System for Enterprise AI](https://arxiv.org/abs/2507.11830)
*Samyam Rajbhandari,Mert Hidayetoglu,Aurick Qiao,Ye Wang,Juncheng Yang,Jeff Rasley,Michael Wyatt,Yuxiong He*

Main category: cs.DC

TL;DR: Arctic Inference通过动态并行策略和优化技术，显著提升了AI推理的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统在延迟、吞吐量和成本之间存在权衡，无法满足实际需求。

Method: 采用Shift Parallelism动态并行策略，结合推测解码、SwiftKV计算减少和优化的嵌入推理。

Result: 实现了请求完成速度提升3.4倍，生成速度提升1.75倍，嵌入推理达到1.6M tokens/sec每GPU。

Conclusion: Arctic Inference为企业和社区提供了高效、低成本的AI推理解决方案。

Abstract: Inference is now the dominant AI workload, yet existing systems force
trade-offs between latency, throughput, and cost. Arctic Inference, an
open-source vLLM plugin from Snowflake AI Research, introduces Shift
Parallelism, a dynamic parallelism strategy that adapts to real-world traffic
while integrating speculative decoding, SwiftKV compute reduction, and
optimized embedding inference. It achieves up to 3.4 times faster request
completion, 1.75 times faster generation, and 1.6M tokens/sec per GPU for
embeddings, outperforming both latency- and throughput-optimized deployments.
Already powering Snowflake Cortex AI, Arctic Inference delivers
state-of-the-art, cost-effective inference for enterprise AI and is now
available to the community.

</details>


### [155] [Performance Assessment of Load Balancing Methods in Cloud Computing: Analysis of Round Robin, Equally Spread, and Throttled Strategies Using Cloud Analyst](https://arxiv.org/abs/2507.11899)
*Saeid Aghasoleymani Najafabadi*

Main category: cs.DC

TL;DR: 论文研究了云计算中的负载均衡策略，比较了不同算法在集中式和分布式环境下的性能，发现分布式资源布局能显著提升响应时间，并强调了智能动态负载均衡的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着云计算工作负载的动态性和不可预测性增加，传统的静态负载均衡方法已无法满足需求，需要更智能和自适应的策略来优化资源分配和服务质量。

Method: 使用Cloud Analyst模拟工具，评估了集中式和分布式资源布局下不同负载均衡算法（如Round Robin、Equally Spread和Throttled）的性能。

Result: 在单一数据中心中，Round Robin算法表现略优；而在分布式环境中，Equally Spread和Throttled算法在降低响应时间和运营成本方面更具竞争力。

Conclusion: 智能动态负载均衡和资源管理策略对优化云计算的性能和成本至关重要，未来需持续评估和整合新兴技术以保持竞争力。

Abstract: Load balancing plays a pivotal role in cloud computing, ensuring that
resources are optimally allocated to maintain high service quality and
operational efficiency. As workloads in cloud environments become increasingly
dynamic and unpredictable, load balancing strategies are evolving from
traditional static methods to more adaptive and intelligent approaches. In this
study, the Cloud Analyst simulation tool was used to evaluate the performance
of different load balancing algorithms under various scenarios, including both
centralized and distributed resource setups. The results highlight that while
the Round Robin algorithm yields slightly better processing times within a
single data center, Equally Spread and Throttled techniques perform
competitively, especially when network latency is considered. More importantly,
when resources are distributed across multiple data centers, response times are
significantly reduced, emphasizing the value of proximity and efficient load
distribution. In these distributed environments, Equally Spread and Throttled
algorithms not only maintain quick response times but also contribute to lower
operational costs. These findings demonstrate the necessity of strategic
resource placement and proactive infrastructure planning to balance performance
and cost. Adopting intelligent, dynamic load balancing and resource management
practices can help organizations meet evolving cloud demands, optimize costs,
and maintain a competitive advantage. Continuous evaluation and integration of
emerging technologies are crucial for sustaining effective and scalable cloud
operations.

</details>


### [156] [Making Serverless Computing Extensible: A Case Study of Serverless Data Analytics](https://arxiv.org/abs/2507.11929)
*Minchen Yu,Yinghao Ren,Jiamu Zhao,Jiaqi Li*

Main category: cs.DC

TL;DR: 本文提出了一种可扩展的无服务器计算设计原则，通过Proteus平台实现，支持开发者定制控制行为以优化性能，同时保持共享易用性。


<details>
  <summary>Details</summary>
Motivation: 解决通用无服务器平台性能不足与专用系统复杂性之间的权衡问题。

Method: 提出可扩展设计原则，并在Proteus平台中实现，引入决策工作流抽象以定制控制行为。

Result: 初步结果显示Proteus能优化分析查询执行并支持细粒度资源共享。

Conclusion: 可扩展设计原则为无服务器计算提供了性能优化与易用性的平衡方案。

Abstract: Serverless computing has attracted a broad range of applications due to its
ease of use and resource elasticity. However, developing serverless
applications often poses a dilemma -- relying on general-purpose serverless
platforms can fall short of delivering satisfactory performance for complex
workloads, whereas building application-specific serverless systems undermines
the simplicity and generality. In this paper, we propose an extensible design
principle for serverless computing. We argue that a platform should enable
developers to extend system behaviors for domain-specialized optimizations
while retaining a shared, easy-to-use serverless environment. We take data
analytics as a representative serverless use case and realize this design
principle in Proteus. Proteus introduces a novel abstraction of decision
workflows, allowing developers to customize control-plane behaviors for
improved application performance. Preliminary results show that Proteus's
prototype effectively optimizes analytical query execution and supports
fine-grained resource sharing across diverse applications.

</details>


### [157] [NineToothed: A Triton-Based High-Level Domain-Specific Language for Machine Learning](https://arxiv.org/abs/2507.11978)
*Jiacheng Huang,Zimin Li,Yinghui Li,Haojie Wang*

Main category: cs.DC

TL;DR: NineToothed是一种面向机器学习的领域特定语言（DSL），通过将串行代码自动转换为并行代码，简化了开发过程，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 当前DSL（如Triton）要求开发者具备并行编程专业知识并处理低层细节，增加了开发与维护难度。因此，需要一种支持串行编程的新模型。

Method: NineToothed提供串行语义，包含基于张量的元编程（TOM）语言和代码生成器，自动将串行代码转换为高性能并行代码。

Result: 评估显示，NineToothed在简化开发的同时，性能与Triton相当。

Conclusion: NineToothed通过串行编程模型显著降低了开发复杂度，同时保持了高性能，适用于机器学习工作负载。

Abstract: The emergence of deep learning domain-specific languages (DSLs) has
substantially reduced the obstacles in developing high-performance,
cross-platform compute kernels. However, current DSLs, such as Triton, still
demand that developers possess expertise in parallel programming and expose
them to many low-level details. This requirement complicates the development
process and adds to the difficulty of maintaining compute kernels.
Consequently, developing a new programming model that supports serial
programming for deep learning workloads is crucial.
  This paper introduces NineToothed, a domain-specific language that offers
serial semantics for machine learning programming. Through the automatic
transformation of serial code into parallel code, NineToothed significantly
streamlines the development process while causing minimal performance
degradation. NineToothed encompasses (1) a language with tensor-oriented
metaprogramming (TOM) that adopts the arrange-and-apply paradigm, enabling the
expression of tiled computations without the need to manage low-level details
and (2) a code generator for generating high-performance parallel code. Our
evaluation results indicate that NineToothed can greatly simplify compute
kernel development while maintaining performance comparable to that of Triton.

</details>


### [158] [ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum](https://arxiv.org/abs/2507.12032)
*Brian-Frederik Jahnke,René Brinkhege,Jan Peter Meyer,Daniel Tebernum,Falk Howar*

Main category: cs.DC

TL;DR: ARRC是一个基于软件工程设计原则的推荐系统，用于在边缘-云系统中实现安全、透明且低成本的资源优化，显著减少操作员工作量并提高计算利用率。


<details>
  <summary>Details</summary>
Motivation: 解决边缘-云系统中资源优化面临的异构平台、抽象层复杂性和缺乏可解释性与可维护性的问题。

Method: 引入ARRC，一个封装优化逻辑的可审计代理系统，通过共享接口协调，提供跨层资源推荐并直接集成到操作员工作流中。

Result: 在多区域工业部署中，ARRC减少操作员工作量50%以上，计算利用率提升7.7倍，错误率低于5%。

Conclusion: ARRC展示了可解释的推荐架构在生产规模下可持续提升效率和可维护性，为资源管理提供了透明、可维护的自动化框架。

Abstract: Achieving sustainable, explainable, and maintainable automation for resource
optimization is a core challenge across the edge-cloud continuum. Persistent
overprovisioning and operational complexity often stem from heterogeneous
platforms and layered abstractions, while systems lacking explainability and
maintainability become fragile, impede safe recovery, and accumulate technical
debt. Existing solutions are frequently reactive, limited to single abstraction
layers, or require intrusive platform changes, leaving efficiency and
maintainability gains unrealized.
  This paper addresses safe, transparent, and low-effort resource optimization
in dynamic, multi-tenant edge-cloud systems, without disrupting operator
workflows or increasing technical debt. We introduce ARRC, a recommender system
rooted in software engineering design principles, which delivers explainable,
cross-layer resource recommendations directly into operator workflows (such as
tickets and GitOps pull requests). ARRC encapsulates optimization logic in
specialized, auditable agents coordinated via a shared interface, supporting
maintainability and extensibility through transparency and the ability to
inspect both recommendations and their rationale.
  Empirical evaluation in a multi-region industrial deployment shows that ARRC
reduces operator workload by over 50%, improves compute utilization by up to
7.7x, and maintains error rates below 5%, with most benefits achieved through
incremental, operator-approved changes. This demonstrates that explainable,
recommendation-based architectures can achieve sustainable efficiency and
maintainability improvements at production scale.
  ARRC provides an empirically evaluated framework for integrating explainable,
workflow-driven automation into resource management, intended to advance best
practices for robust, maintainable, and transparent edge-cloud continuum
platforms.

</details>


### [159] [Distributed Algorithms for Potential Problems](https://arxiv.org/abs/2507.12038)
*Alkida Balliu,Thomas Boudier,Francesco d'Amore,Dennis Olivetti,Gustav Schmid,Jukka Suomela*

Main category: cs.DC

TL;DR: 本文提出了一种快速分布式算法，用于解决局部势问题，包括局部最优割问题，在确定性及随机LOCAL模型中均可在对数多项式轮数内完成。


<details>
  <summary>Details</summary>
Motivation: 局部势问题的分布式轮复杂度存在较大上下界差距，尤其是局部最优割问题，当前上界仅为暴力解的O(n)轮，而确定性模型下界为Ω(log n)，随机模型下界为Ω(log log n)。

Method: 提出了一种针对有界度图中所有局部势问题的分布式算法，包括局部最优割问题。

Result: 在有界度图中，所有局部势问题（包括局部最优割）可在确定性及随机LOCAL模型中以对数多项式轮数（log^O(1) n）解决。

Conclusion: 局部最优割问题的确定性轮复杂度被确定为对数多项式轮数（log^Θ(1) n），填补了上下界之间的巨大差距。

Abstract: In this work we present a fast distributed algorithm for local potential
problems: these are graph problems where the task is to find a locally optimal
solution where no node can unilaterally improve the utility in its local
neighborhood by changing its own label. A simple example of such a problem is
the task of finding a locally optimal cut, i.e., a cut where for each node at
least half of its incident edges are cut edges. The distributed round
complexity of locally optimal cut has been wide open; the problem is known to
require $\Omega(\log n)$ rounds in the deterministic LOCAL model and
$\Omega(\log \log n)$ rounds in the randomized LOCAL model, but the only known
upper bound is the trivial brute-force solution of $O(n)$ rounds. Locally
optimal cut in bounded-degree graphs is perhaps the simplest example of a
locally checkable labeling problem for which there is still such a large gap
between current upper and lower bounds. We show that in bounded-degree graphs,
all local potential problems, including locally optimal cut, can be solved in
$\log^{O(1)} n$ rounds, both in the deterministic and randomized LOCAL models.
In particular, the deterministic round complexity of the locally optimal cut
problem is now settled to $\log^{\Theta(1)} n$.

</details>


### [160] [Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso](https://arxiv.org/abs/2507.12106)
*Antonio Salis,Gabriele Troina,Gianluca Boanelli,Marco Ottaviano,Paola Fortini,Soraya Versace*

Main category: cs.DC

TL;DR: 论文探讨了通过物联网和数据分析技术优化城市绿地管理，提升市民生活质量。


<details>
  <summary>Details</summary>
Motivation: 公共绿地对城市居民健康和福祉至关重要，但传统管理方式效率不足，需技术创新支持。

Method: 采用物联网系统、数据驱动平台和机器学习算法，实时监测树木和绿地状态，优化灌溉和决策。

Result: 开发了基于云的实时决策支持平台，通过智能传感器和预测模型优化绿地管理。

Conclusion: 数字化和物联网技术可提升城市绿地可持续管理，增强环境韧性，改善市民生活质量。

Abstract: The efficient design and management of public green spaces is a key factor in
promoting the health and well-being of urban population, as emphasized by the
WHO, UNEP, and EEA. These areas serve as the "green lungs" of the urban
ecosystem, playing a vital role in enhancing quality of life thanks to the
provision of ecosystem services. In this context, the Smart Green City use case
in Campobasso municipality, funded by the Italian Ministry of Enterprises
(MIMIT), emerges as an innovative model for the sustainable management of green
urban areas through the adoption of an advanced system of emerging technologies
integrated and interoperable. The project integrates IoT systems and
data-driven governance platforms, enabling real-time monitoring of the health
status of trees and green areas via a Decision Support System (DSS). It also
facilitates the collection and analysis of data from diverse sources, including
weather conditions, air quality, soil moisture, pollution levels. The resulting
cloud-based platform supports a holistic real time decision making for green
urban managers, technical experts and operational staff. It enables intelligent
control and management of urban green spaces using Tree Talker sensors,
integrated with soil moisture and water potential monitoring systems. Thanks to
predictive models based on machine learning algorithms and real time data
provided by IoT sensors, irrigation of public parks can be optimized by
providing suggestions on when and how much water to apply. Customized alerts
layers are also activated warning users when monitored parameters, such as soil
temperature, humidity, or water potential, exceed predefined thresholds. This
Use Case demonstrates how digitalization, IoT sensors fusion and technological
innovation can support sustainable urban governance, fostering environmental
resilience and improving citizens quality of life.

</details>


### [161] [Toward Efficient SpMV in Sparse LLMs via Block Extraction and Compressed Storage](https://arxiv.org/abs/2507.12205)
*Junqing Lin,Jingwei Sun,Mingge Lu,Guangzhong Sun*

Main category: cs.DC

TL;DR: EC-SpMV是一种针对稀疏大语言模型（LLM）推理优化的GPU加速方法，通过分层块提取算法和新型压缩稀疏格式（EC-CSR）显著提升性能并减少存储开销。


<details>
  <summary>Details</summary>
Motivation: 稀疏矩阵-向量乘法（SpMV）在稀疏LLM本地部署中成为性能瓶颈，现有方法未能充分利用稀疏LLM的结构模式，导致性能不佳和存储开销过大。

Method: 提出分层块提取算法捕获稀疏LLM的多粒度块结构，并设计EC-CSR格式通过增量索引减少存储开销和提高内存访问效率。

Result: 在LLaMA和OPT模型的真实稀疏权重矩阵上测试，EC-SpMV比现有SpMV库快6.44倍，存储开销比CSR减少55.4%。

Conclusion: EC-SpMV有效解决了稀疏LLM推理中的SpMV性能瓶颈，显著提升了计算效率和存储利用率。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) has become a critical performance
bottleneck in the local deployment of sparse Large Language Models (LLMs),
where inference predominantly operates on workloads during the decoder phase
with a batch size of one. Existing SpMV kernels and sparse matrix formats,
originally designed for scientific computing, fail to exploit the unique
structure patterns inherent in sparse LLMs, resulting in suboptimal performance
and excessive storage overhead. This paper presents EC-SpMV, a GPU-optimized
SpMV approach for accelerating sparse LLM inference. EC-SpMV introduces (1) a
hierarchical block extraction algorithm that captures multiple granularities of
block structures within sparse LLMs, and (2) a novel compressed sparse format
(EC-CSR) that employs delta indexing to reduce storage overhead and enhance
memory access efficiency. Evaluated on real sparse weight matrices from LLaMA
and OPT models, EC-SpMV achieves up to 6.44x speedup over state-of-the-art SpMV
libraries and reduces storage overhead by up to 55.4% compared to CSR.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [162] [Towards a Non-Binary View of IPv6 Adoption](https://arxiv.org/abs/2507.11678)
*Sulyab Thottungal Valapu,John Heidemann*

Main category: cs.NI

TL;DR: 当前IPv6部署状态分析：用户流量、服务器和云服务IPv6采用情况，发现部署不均衡，存在改进空间。


<details>
  <summary>Details</summary>
Motivation: 研究IPv6部署的现状，超越二元视角，探讨用户、服务器和云服务中IPv6的实际使用情况。

Method: 从客户端、服务器和云服务三个角度分析IPv6流量和部署情况，包括用户流量模式、网站IPv6准备情况和云服务支持。

Result: 用户IPv6流量波动大（标准差15%），仅12.5%的顶级网站完全支持IPv6，云服务IPv6采用率因易用性差异显著。

Conclusion: IPv6部署虽在增长，但服务滞后，需改进云服务易用性以提升采用率。

Abstract: Twelve years have passed since World IPv6 Launch Day, but what is the current
state of IPv6 deployment? Prior work has examined IPv6 status as a binary: can
you use IPv6, or not? As deployment increases we must consider a more nuanced,
non-binary perspective on IPv6: how much and often can a user or a service use
IPv6? We consider this question as a client, server, and cloud provider.
Considering the client's perspective, we observe user traffic. We see that the
fraction of IPv6 traffic a user sends varies greatly, both across users and
day-by-day, with a standard deviation of over 15%. We show this variation
occurs for two main reasons. First, IPv6 traffic is primarily human-generated,
thus showing diurnal patterns. Second, some services are IPv6-forward and
others IPv6-laggards, so as users do different things their fraction of IPv6
varies. We look at server-side IPv6 adoption in two ways. First, we expand
analysis of web services to examine how many are only partially IPv6 enabled
due to their reliance on IPv4-only resources. Our findings reveal that only
12.5% of top 100k websites qualify as fully IPv6-ready. Finally, we examine
cloud support for IPv6. Although all clouds and CDNs support IPv6, we find that
tenant deployment rates vary significantly across providers. We find that ease
of enabling IPv6 in the cloud is correlated with tenant IPv6 adoption rates,
and recommend best practices for cloud providers to improve IPv6 adoption. Our
results suggest IPv6 deployment is growing, but many services lag, presenting a
potential for improvement.

</details>


### [163] [On QoE-Aware Traffic Management for Real-time, Interactive Video with Time-variant Spatial Complexity](https://arxiv.org/abs/2507.11798)
*Szilveszter Nádas,Lars Ernström,David Lindero,Jonathan Lynam*

Main category: cs.NI

TL;DR: 研究了空间复杂度与视频体验质量（QoE）的关系，提出基于效用的动态资源分配方法，优于静态分配和均等QoE分配。


<details>
  <summary>Details</summary>
Motivation: 探索实时交互视频中空间复杂度与QoE的关系，优化资源分配以提升性能。

Method: 分析不同内容类型的空间复杂度变化，引入效用概念管理资源分配偏好，比较动态与静态分配方法。

Result: 动态QoE感知资源分配显著优于静态分配，基于效用的方法提高平均QoE并控制最差情况。

Conclusion: 效用驱动的动态资源分配是优化视频QoE的有效方法。

Abstract: We analyzed spatial complexity, defined as the relationship between the
required bitrate and a corresponding picture Quality of Experience (QoE)
metric, for realistic, long, real-time, interactive video clips. Apart from
variation across different content types, e.g., game genres, we discovered
time-variability within a clip from second to second, and explored the
ramifications for traffic management. We introduced utility as an elegant way
to manage resource sharing preferences. Our analysis of resource sharing
methods shows that frequent QoE-aware reallocation has significant performance
advantages compared to static rate allocation, even in case the latter is based
on rich information about long-term average spatial complexity. We have also
shown that utility-based resource allocation has clear advantages over methods
targeting equal QoE allocation, it increases the average QoE, while it still
controls the worst case QoE.

</details>


### [164] [Native-AI Empowered Scalable Architectures and Solutions for Future Non-Terrestrial Networks: An Overview](https://arxiv.org/abs/2507.11935)
*Jikang Deng,Fizza Hassan,Hui Zhou,Saad Al-Ahmadi,Mohamed-Slim Alouini,Daniel B. Da Costa*

Main category: cs.NI

TL;DR: 本文探讨了将开放无线接入网络（ORAN）与非地面网络（NTN）结合的框架，以解决NTN在开发和运维（DevOps）生命周期中的挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 6G网络中，NTN和ORAN的结合需求日益增长，但NTN的高海拔和移动性带来了开发和运维的挑战，缺乏原生AI能力阻碍了智能和可扩展的网络管理。

Method: 提出基于ORAN的NTN框架，详细讨论了灵活的前传分割、增强的RAN智能控制器（RICs）、可扩展部署架构和多域服务管理。

Result: 通过ORAN的开放性、虚拟化和智能优势，解决了NTN的DevOps挑战，并提出了未来研究方向。

Conclusion: ORAN与NTN的结合为6G网络提供了高效、可靠和灵活的解决方案，未来可进一步与其他技术结合并探索更多用例。

Abstract: As the path toward 6G networks is being charted, the emerging applications
have motivated evolutions of network architectures to realize the efficient,
reliable, and flexible wireless networks. Among the potential architectures,
the non-terrestrial network (NTN) and open radio access network (ORAN) have
received increasing interest from both academia and industry. Although the
deployment of NTNs ensures coverage, enhances spectral efficiency, and improves
the resilience of wireless networks. The high altitude and mobility of NTN
present new challenges in the development and operations (DevOps) lifecycle,
hindering intelligent and scalable network management due to the lack of native
artificial intelligence (AI) capability. With the advantages of ORAN in
disaggregation, openness, virtualization, and intelligence, several works
propose integrating ORAN principles into the NTN, focusing mainly on ORAN
deployment options based on transparent and regenerative systems. However, a
holistic view of how to effectively combine ORAN and NTN throughout the DevOps
lifecycle is still missing, especially regarding how intelligent ORAN addresses
the scalability challenges in NTN. Motivated by this, in this paper, we first
provide the background knowledge about ORAN and NTN, outline the
state-of-the-art research on ORAN for NTNs, and present the DevOps challenges
that motivate the adoption of ORAN solutions. We then propose the ORAN-based
NTN framework, discussing its features and architectures in detail. These
include the discussion about flexible fronthaul split, RAN intelligent
controllers (RICs) enhancement for distributed learning, scalable deployment
architecture, and multi-domain service management. Finally, the future research
directions, including combinations of the ORAN-based NTN framework and other
enabling technologies and schemes, as well as the candidate use cases, are
highlighted.

</details>


### [165] [FastReChain: Highly Responsive and Low-Overhead Centralized Route Scheduling in Clos Datacenter Networks](https://arxiv.org/abs/2507.12265)
*Zihan Zhu,Dongchao Wu,Zhanbang Zhang,Jian Yang*

Main category: cs.NI

TL;DR: 提出了一种集中式调度算法，支持动态调度，适用于光交换机数据中心网络，实现理论最大吞吐量且重排次数接近最小。


<details>
  <summary>Details</summary>
Motivation: 解决数据中心网络中光交换机因无缓冲和长切换时间导致的动态调度问题。

Method: 采用替换链概念和位集优化技术，设计集中式调度算法。

Result: 算法在双向Clos网络中实现最大吞吐量，重排次数少，运行时间显著优于其他算法。

Conclusion: 该算法高效灵活，适用于实际环境，支持动态调度需求。

Abstract: Ever since Clos topologies were used in datacenter networks (DCNs), a
practical centralized scheduling algorithm that supports dynamic scheduling has
been absent. The introduction of optical switches in DCNs as a future-proof
solution exacerbates this problem due to several properties of optical
switches, such as the fact that they are generally bufferless and therefore
rely on centralized scheduling, and that they have long switching times and
therefore require the number of rearrangements to be minimized.
  In this paper, we propose a centralized scheduling algorithm that achieves
theoretical maximum throughput even in one-rate bidirectional Clos networks,
while producing schemes with near-minimal numbers of rearrangements. It is the
only algorithm that directly supports bidirectional Clos networks and has a
time efficiency high enough to support dynamic scheduling to date. For static
minimal rewiring, its running time ranges from a fraction to a few hundredths
of other algorithms, and the number of rearrangements has also been steadily
improved, allowing for more frequent adjustments and less impact on ongoing
communications. In addition, the algorithm is very flexible and can support
various functional requirements in real-world environments. We achieve this
result through the replacement chain concept and bitset optimization.

</details>


### [166] [LLM-Based Config Synthesis requires Disambiguation](https://arxiv.org/abs/2507.12443)
*Rajdeep Mondal,Nikolaj Bjorner,Todd Millstein,Alan Tang,George Varghese*

Main category: cs.NI

TL;DR: 论文探讨了LLM在程序合成中的意图模糊问题，提出了一个原型系统Clarify，通过Disambiguator模块帮助明确用户意图，并在小规模合成工作负载上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在程序合成中因用户意图模糊导致的配置合成问题，特别是在网络路由策略和ACL配置中。

Method: 提出原型系统Clarify，结合LLM和Disambiguator模块，通过用户交互明确意图，并验证合成结果。

Result: 在小型合成工作负载上成功实现了路由策略的增量合成和验证。

Conclusion: Clarify系统有效解决了LLM在程序合成中的意图模糊问题，其方法适用于其他需要明确意图的场景。

Abstract: Beyond hallucinations, another problem in program synthesis using LLMs is
ambiguity in user intent. We illustrate the ambiguity problem in a networking
context for LLM-based incremental configuration synthesis of route-maps and
ACLs. These structures frequently overlap in header space, making the relative
priority of actions impossible for the LLM to infer without user interaction.
Measurements in a large cloud identify complex ACLs with 100's of overlaps,
showing ambiguity is a real problem. We propose a prototype system, Clarify,
which uses an LLM augmented with a new module called a Disambiguator that helps
elicit user intent. On a small synthetic workload, Clarify incrementally
synthesizes routing policies after disambiguation and then verifies them. Our
treatment of ambiguities is useful more generally when the intent of updates
can be correctly synthesized by LLMs, but their integration is ambiguous and
can lead to different global behaviors.

</details>


### [167] [CRAFT: Latency and Cost-Aware Genetic-Based Framework for Node Placement in Edge-Fog Environments](https://arxiv.org/abs/2507.12445)
*Soheil Mahdizadeh,Amir Mahdi Rasouli,Mohammad Pourashory,Sadra Galavani,Mohsen Ansari*

Main category: cs.NI

TL;DR: 本文提出了一种基于遗传算法的边缘和雾节点部署策略，旨在最小化延迟和成本，实验结果显示延迟降低2.77%，成本减少31.15%。


<details>
  <summary>Details</summary>
Motivation: 物联网中的延迟问题至关重要，云计算无法满足实时需求，边缘和雾计算通过将计算节点靠近用户提供了更低延迟和更强处理能力。

Method: 采用遗传算法优化边缘和雾节点的部署策略，以最小化延迟和系统成本。

Result: 仿真结果表明，提出的框架实现了延迟降低2.77%和成本减少31.15%。

Conclusion: 基于遗传算法的节点部署策略有效降低了延迟和成本，为物联网中的实时需求提供了可行解决方案。

Abstract: Reducing latency in the Internet of Things (IoT) is a critical concern. While
cloud computing facilitates communication, it falls short of meeting real-time
requirements reliably. Edge and fog computing have emerged as viable solutions
by positioning computing nodes closer to end users, offering lower latency and
increased processing power. An edge-fog framework comprises various components,
including edge and fog nodes, whose strategic placement is crucial as it
directly impacts latency and system cost. This paper presents an effective and
tunable node placement strategy based on a genetic algorithm to address the
optimization problem of deploying edge and fog nodes. The main objective is to
minimize latency and cost through optimal node placement. Simulation results
demonstrate that the proposed framework achieves up to 2.77% latency and 31.15%
cost reduction.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [168] [Quantum circuits are just a phase](https://arxiv.org/abs/2507.11676)
*Chris Heunen,Louis Lemonnier,Christopher McNally,Alex Rice*

Main category: cs.PL

TL;DR: 提出了一种新型量子编程语言，通过相位操作和子空间选择提升抽象性和表达力，展示了其通用性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前量子编程语言抽象层次低，阻碍了可扩展性和高级推理，需要更抽象的编程构造。

Method: 结合全局相位操作和量子版“if let”构造，聚焦于特征分解、共轭和受控酉操作。

Result: 证明了语言的通用性，自然表达了多种量子算法，并实现了原型编译器。

Conclusion: 该语言为更抽象和结构化的量子编程提供了原则性和实用的步骤。

Abstract: Quantum programs today are written at a low level of abstraction - quantum
circuits akin to assembly languages - and even advanced quantum programming
languages essentially function as circuit description languages. This state of
affairs impedes scalability, clarity, and support for higher-level reasoning.
More abstract and expressive quantum programming constructs are needed.
  To this end, we introduce a novel yet simple quantum programming language for
generating unitaries from "just a phase"; we combine a (global) phase operation
that captures phase shifts with a quantum analogue of the "if let" construct
that captures subspace selection via pattern matching. This minimal language
lifts the focus from quantum gates to eigendecomposition, conjugation, and
controlled unitaries; common building blocks in quantum algorithm design.
  We demonstrate several aspects of the expressive power of our language in
several ways. Firstly, we establish that our representation is universal by
deriving a universal quantum gate set. Secondly, we show that important quantum
algorithms can be expressed naturally and concisely, including Grover's search
algorithm, Hamiltonian simulation, Quantum Fourier Transform, Quantum Signal
Processing, and the Quantum Eigenvalue Transformation. Furthermore, we give
clean denotational semantics grounded in categorical quantum mechanics.
Finally, we implement a prototype compiler that efficiently translates terms of
our language to quantum circuits, and prove that it is sound with respect to
these semantics. Collectively, these contributions show that this construct
offers a principled and practical step toward more abstract and structured
quantum programming.

</details>


### [169] [Towards Relational Contextual Equality Saturation](https://arxiv.org/abs/2507.11897)
*Tyler Hou,Shadaj Laddad,Joseph M. Hellerstein*

Main category: cs.PL

TL;DR: 本文探讨了如何将上下文等式饱和技术扩展到关系模型中，总结了现有方法及其应用，并指出了关键挑战。


<details>
  <summary>Details</summary>
Motivation: 将上下文等式饱和技术扩展到关系模型（如egglog）中，以支持更复杂的程序优化。

Method: 总结了现有的上下文等式饱和方法，并尝试将其与关系模型结合。

Result: 提出了将上下文等式饱和扩展到关系模型的方向，并识别了主要挑战。

Conclusion: 上下文等式饱和在关系模型中的应用具有潜力，但仍需解决关键挑战。

Abstract: Equality saturation is a powerful technique for program optimization.
Contextual equality saturation extends this to support rewrite rules that are
conditioned on where a term appears in an expression. Existing work has brought
contextual reasoning to egg; in this paper, we share our ongoing work to extend
this to relational equality saturation in egglog. We summarize the existing
approaches to contextual equality saturation, outline its main applications,
and identify key challenges in combining this approach with relational models.

</details>


### [170] [Picat Through the Lens of Advent of Code](https://arxiv.org/abs/2507.11731)
*Neng-Fa Zhou,Cristian Grozea,Håkan Kjellerstrand,Oisín Mac Fhearaí*

Main category: cs.PL

TL;DR: 本文展示了使用Picat语言解决2024年Advent of Code问题的优势，特别是其约束求解和表格功能。


<details>
  <summary>Details</summary>
Motivation: Advent of Code问题虽不针对特定语言，但某些类型（如逆向工程和路径查找）特别适合Picat，因其内置功能。

Method: 利用Picat的SAT约束求解、模式匹配、回溯和表格功能，实现问题的简洁高效解决。

Result: Picat能比命令式语言更高效、简洁地解决问题。

Conclusion: Picat的多范式特性使其在解决特定类型问题时具有显著优势。

Abstract: Picat is a logic-based, multi-paradigm programming language that integrates
features from logic, functional, constraint, and imperative programming
paradigms. This paper presents solutions to several problems from the 2024
Advent of Code (AoC). While AoC problems are not designed for any specific
programming language, certain problem types, such as reverse engineering and
path-finding, are particularly well-suited to Picat due to its built-in
constraint solving, pattern matching, backtracking, and dynamic programming
with tabling. This paper demonstrates that Picat's features, especially its
SAT-based constraint solving and tabling, enable concise, declarative, and
highly efficient implementations of problems that would require significantly
more effort in imperative languages.

</details>


### [171] [Universal Synthesis of Differentiably Tunable Numerical Abstract Transformers](https://arxiv.org/abs/2507.11827)
*Shaurya Gomber,Debangshu Banerjee,Gagandeep Singh*

Main category: cs.PL

TL;DR: 提出了一种通用变换器合成算法，用于构建适用于多面体数值域的抽象变换器家族，并通过梯度引导搜索优化其性能。


<details>
  <summary>Details</summary>
Motivation: 现有数值抽象解释器依赖手工定制的变换器，缺乏通用性，限制了扩展性和精确组合推理。

Method: 提出通用变换器合成算法，支持二次有界守卫操作符（QGO），并引入自适应梯度引导（AGG）搜索策略。

Result: USTAD框架在Zones、Octagons和Polyhedra域中成功构建了精确且可调的变换器家族，显著优于基线。

Conclusion: 通用算法和梯度引导搜索有效解决了现有方法的局限性，提升了数值抽象解释的灵活性和精确性。

Abstract: Numerical abstract interpretation is a widely used framework for the static
analysis of numerical programs. However, existing numerical abstract
interpreters rely on hand-crafted, instruction-specific transformers tailored
to each domain, with no general algorithm for handling common operations across
domains. This limits extensibility, prevents precise compositional reasoning
over instruction sequences, and forces all downstream tasks to use the same
fixed transformer regardless of their precision, efficiency, or task-specific
requirements. To address these limitations, we propose a universal transformer
synthesis algorithm that constructs a parametric family of sound abstract
transformers for any given polyhedral numerical domain and a concrete operator
from the class of Quadratic-Bounded Guarded Operators (QGO), which includes
both individual instructions and structured sequences. Each instantiation in
this family is sound by construction, enabling downstream analyses to adapt the
transformer to their particular needs. The space of transformers is
differentiable but complex. To efficiently explore this space of transformers,
we introduce the Adaptive Gradient Guidance (AGG) procedure, a gradient-guided
search strategy that steers the search process based on downstream analysis
objectives and runtime constraints. We implement these ideas in the USTAD
framework and evaluate their effectiveness across three numerical abstract
domains: Zones, Octagons, and Polyhedra. Our results demonstrate that the
universal synthesis algorithm successfully constructs sound families of
transformers across domains, and that USTAD achieves significant, tunable
precision gains over baselines by leveraging compositional reasoning and
efficient gradient-guided traversal of the transformer space.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [172] [Decision Models for Selecting Architecture Patterns and Strategies in Quantum Software Systems](https://arxiv.org/abs/2507.11671)
*Mst Shamima Aktar,Peng Liang,Muhammad Waseem,Amjed Tahir,Mojtaba Shahin,Muhammad Azeem Akbar,Arif Ali Khan,Aakash Ahmad,Musengamana Jean de Dieu,Ruiyin Li*

Main category: cs.SE

TL;DR: 该研究提出决策模型，帮助量子软件开发者选择架构模式和策略，解决量子软件系统设计中的复杂性和缺乏指南的问题。


<details>
  <summary>Details</summary>
Motivation: 量子软件开发者在选择和实施架构模式与策略时面临复杂性和缺乏指南的挑战。

Method: 通过数据挖掘（GitHub和Stack Exchange）和系统文献综述收集相关模式和策略，构建决策模型，并通过半结构化访谈评估模型的有效性。

Result: 决策模型在熟悉度、可理解性、完整性和实用性方面得到验证，能有效辅助开发者选择模式和策略。

Conclusion: 提出的决策模型为量子软件系统的架构设计提供了实用工具，数据集公开以便社区进一步研究。

Abstract: Quantum software represents disruptive technologies in terms of
quantum-specific software systems, services, and applications - leverage the
principles of quantum mechanics via programmable quantum bits (Qubits) that
manipulate quantum gates (QuGates) - to achieve quantum supremacy in computing.
Quantum software architecture enables quantum software developers to abstract
away implementation-specific details (i.e., mapping of Qubits and QuGates to
high-level architectural components and connectors). Architectural patterns and
strategies can provide reusable knowledge and best practices to engineer
quantum software systems effectively and efficiently. However, quantum software
practitioners face significant challenges in selecting and implementing
appropriate patterns and strategies due to the complexity of quantum software
systems and the lack of guidelines. To address these challenges, this study
proposes decision models for selecting patterns and strategies in six critical
design areas in quantum software systems: Communication, Decomposition, Data
Processing, Fault Tolerance, Integration and Optimization, and Algorithm
Implementation. These decision models are constructed based on data collected
from both a mining study (i.e., GitHub and Stack Exchange) and a Systematic
Literature Review, which were used to identify relevant patterns and strategies
with their involved Quality Attributes (QAs). We then conducted semi-structured
interviews with 16 quantum software practitioners to evaluate the familiarity,
understandability, completeness, and usefulness of the proposed decision
models. The results show that the proposed decision models can aid
practitioners in selecting suitable patterns and strategies to address the
challenges related to the architecture design of quantum software systems. The
dataset is available at [6], allowing the community to reproduce and build upon
our findings.

</details>


### [173] [MetaLint: Generalizable Idiomatic Code Quality Analysis through Instruction-Following and Easy-to-Hard Generalization](https://arxiv.org/abs/2507.11687)
*Atharva Naik,Lawanya Baghel,Dhakshin Govindarajan,Darsh Agrawal,Daniel Fried,Carolyn Rose*

Main category: cs.SE

TL;DR: MetaLint是一个基于指令调优的框架，用于代码质量分析，能够适应新代码模式而无需重新训练，优于传统静态方法。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在代码生成方面表现优异，但在代码质量分析上受限于静态训练数据，难以适应不断变化的最佳实践。

Method: MetaLint通过指令调优合成数据，支持从易到难的泛化，无需重新训练即可适应新代码模式。

Result: MetaLint在未见的PEP习语检测上F-score达70.37%，召回率70.43%，定位准确率26.73%，性能接近更大模型。

Conclusion: MetaLint展示了未来代码质量分析的潜力，尤其在适应性和泛化能力上表现突出。

Abstract: Large Language Models, though successful in code generation, struggle with
code quality analysis because they are limited by static training data and
can't easily adapt to evolving best practices. We introduce MetaLint, a new
instruction-following framework that formulates code quality analysis as the
task of detecting and fixing problematic semantic code fragments or code idioms
based on high-level specifications. Unlike conventional approaches that train
models on static, rule-based data, MetaLint employs instruction tuning on
synthetic linter-generated data to support easy-to-hard generalization,
enabling models to adapt to novel or complex code patterns without retraining.
To evaluate this, we construct a benchmark of challenging idioms inspired by
real-world coding standards such as Python Enhancement Proposals (PEPs) and
assess whether MetaLint-trained models reason adaptively or simply memorize.
Our results show that MetaLint improves generalization to unseen PEP idioms,
achieving a 70.37% F-score on idiom detection with the highest recall (70.43%)
among all evaluated models. It also achieves 26.73% on localization,
competitive for its 4B parameter size and comparable to larger state-of-the-art
models like o3-mini, highlighting its potential for future-proof code quality
analysis.

</details>


### [174] [REST in Pieces: RESTful Design Rule Violations in Student-Built Web Apps](https://arxiv.org/abs/2507.11689)
*Sergio Di Meglio,Valeria Pontillo,Luigi Libero Lucio Starace*

Main category: cs.SE

TL;DR: 研究发现，计算机科学本科课程中软件质量常被忽视，学生代码质量普遍较低，尤其是在REST API设计方面存在大量基础性错误。


<details>
  <summary>Details</summary>
Motivation: 探讨计算机科学本科课程中软件质量教育的不足，以及学生代码质量对行业实践的适应性问题。

Method: 通过自动化静态分析管道，评估40个由三年级学生在Web技术课程中开发的全栈Web应用程序的REST API设计规则遵循情况。

Result: 结果显示，学生在API设计中普遍违反基础规范，如端点路径缺少连字符（98%）、复数形式错误（88%）和HTTP方法误用（83%）。

Conclusion: 研究强调需要加强API设计的教学，并建议采用自动化工具提升学生项目的代码质量。

Abstract: In Computer Science Bachelor's programs, software quality is often
underemphasized due to limited time and a focus on foundational skills, leaving
many students unprepared for industry expectations. To better understand the
typical quality of student code and inform both education and hiring practices,
we analyze 40 full-stack web applications developed in a third-year Web
Technologies course. Using an automated static analysis pipeline, we assess
adherence to REST API design rules. Results reveal frequent violations of
foundational conventions, such as missing hyphens in endpoint paths (98%),
incorrect pluralization (88%), and misuse of HTTP methods (83%). These findings
highlight the need for more focused instruction on API design and support the
adoption of automated tools to improve code quality in student projects.

</details>


### [175] [Extremal Testing for Network Software using LLMs](https://arxiv.org/abs/2507.11898)
*Rathin Singha,Harry Qian,Srinath Saikrishnan,Tracy Zhao,Ryan Beckett,Siva Kesava Reddy Kakarla,George Varghese*

Main category: cs.SE

TL;DR: 利用LLM自动化网络软件的极端测试，通过生成违反约束的输入发现新bug，并扩展到集中式网络软件和过滤代码生成。


<details>
  <summary>Details</summary>
Motivation: 传统极端测试依赖人工，效率低且易遗漏。LLM可自动化生成极端输入，提高测试覆盖率和效率。

Method: 分两步：1. 用LLM生成输入约束（如DNS名称长度限制）；2. 生成违反约束的测试用例。

Result: 成功为HTTP、BGP和DNS实现生成极端测试，发现新bug，并扩展到集中式网络软件和过滤代码。

Conclusion: LLM生成的极端测试优于传统边界值分析，未来可通过代理AI进一步自动化。

Abstract: Physicists often manually consider extreme cases when testing a theory. In
this paper, we show how to automate extremal testing of network software using
LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS
name length limits); then ask the LLM to generate tests that violate the
constraints. We demonstrate how easy this process is by generating extremal
tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs.
We show how this methodology extends to centralized network software such as
shortest path algorithms, and how LLMs can generate filtering code to reject
extremal input. We propose using agentic AI to further automate extremal
testing. LLM-generated extremal testing goes beyond an old technique in
software testing called Boundary Value Analysis.

</details>


### [176] [GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities](https://arxiv.org/abs/2507.12367)
*Diganta Misra,Nizar Islah,Victor May,Brice Rauby,Zihan Wang,Justine Gehring,Antonio Orvieto,Muawiz Chaudhary,Eilif B. Muller,Irina Rish,Samira Ebrahimi Kahou,Massimo Caccia*

Main category: cs.SE

TL;DR: GitChameleon是一个新的数据集，用于评估AI在特定库版本下的代码生成能力，通过执行单元测试验证功能准确性。现有模型在此任务上表现不佳，成功率仅为48-51%。


<details>
  <summary>Details</summary>
Motivation: 软件库的快速更新对代码生成提出了挑战，现有基准缺乏基于执行的评估。

Method: 引入GitChameleon数据集，包含328个Python代码完成问题，每个问题绑定特定库版本并附带可执行单元测试。

Result: 评估显示当前先进模型在此任务上表现有限，企业模型成功率仅为48-51%。

Conclusion: GitChameleon为理解动态代码库的挑战提供了基准，并推动开发更可靠的AI代码生成方法。

Abstract: The rapid evolution of software libraries poses a considerable hurdle for
code generation, necessitating continuous adaptation to frequent version
updates while preserving backward compatibility. While existing code evolution
benchmarks provide valuable insights, they typically lack execution-based
evaluation for generating code compliant with specific library versions. To
address this, we introduce GitChameleon, a novel, meticulously curated dataset
comprising 328 Python code completion problems, each conditioned on specific
library versions and accompanied by executable unit tests. GitChameleon
rigorously evaluates the capacity of contemporary large language models (LLMs),
LLM-powered agents, code assistants, and RAG systems to perform
version-conditioned code generation that demonstrates functional accuracy
through execution. Our extensive evaluations indicate that state-of-the-art
systems encounter significant challenges with this task; enterprise models
achieving baseline success rates in the 48-51\% range, underscoring the
intricacy of the problem. By offering an execution-based benchmark emphasizing
the dynamic nature of code libraries, GitChameleon enables a clearer
understanding of this challenge and helps guide the development of more
adaptable and dependable AI code generation methods. We make the dataset and
evaluation code publicly available at
https://github.com/mrcabbage972/GitChameleonBenchmark.

</details>


### [177] [A Task Taxonomy for Conformance Checking](https://arxiv.org/abs/2507.11976)
*Jana-Rebecca Rehse,Michael Grohs,Finn Klessascheck,Lisa-Marie Klein,Tatiana von Landesberger,Luise Pufahl*

Main category: cs.SE

TL;DR: 本文提出了一种任务分类法，用于系统化一致性检查分析中的任务，以帮助研究人员明确可视化的目的。


<details>
  <summary>Details</summary>
Motivation: 当前一致性检查工具的可视化方式多样，但其分析目的不明确，缺乏系统化的理解，难以评估其有效性。

Method: 结合过程挖掘和可视化分析的概念，提出任务分类法，分类一致性检查分析中的任务。

Result: 任务分类法明确了可视化目的，支持研究人员更有效地评估和设计一致性检查工具。

Conclusion: 该分类法促进了过程挖掘和可视化分析领域的合作，为一致性检查工具的设计提供了理论基础。

Abstract: Conformance checking is a sub-discipline of process mining, which compares
observed process traces with a process model to analyze whether the process
execution conforms with or deviates from the process design. Organizations can
leverage this analysis, for example to check whether their processes comply
with internal or external regulations or to identify potential improvements.
Gaining these insights requires suitable visualizations, which make complex
results accessible and actionable. So far, however, the development of
conformance checking visualizations has largely been left to tool vendors. As a
result, current tools offer a wide variety of visual representations for
conformance checking, but the analytical purposes they serve often remain
unclear. However, without a systematic understanding of these purposes, it is
difficult to evaluate the visualizations' usefulness. Such an evaluation hence
requires a deeper understanding of conformance checking as an analysis domain.
To this end, we propose a task taxonomy, which categorizes the tasks that can
occur when conducting conformance checking analyses. This taxonomy supports
researchers in determining the purpose of visualizations, specifying relevant
conformance checking tasks in terms of their goal, means, constraint type, data
characteristics, data target, and data cardinality. Combining concepts from
process mining and visual analytics, we address researchers from both
disciplines to enable and support closer collaborations.

</details>


### [178] [LLAMA: Multi-Feedback Smart Contract Fuzzing Framework with LLM-Guided Seed Generation](https://arxiv.org/abs/2507.12084)
*Keke Gai,Haochen Liang,Jing Yu,Liehuang Zhu,Dusit Niyato*

Main category: cs.SE

TL;DR: LLAMA是一个基于大型语言模型（LLMs）的多反馈智能合约模糊测试框架，通过结合LLMs、进化变异策略和混合测试技术，显著提升了覆盖率和漏洞检测能力。


<details>
  <summary>Details</summary>
Motivation: 智能合约在区块链生态系统中至关重要，但现有模糊测试工具在变异调度方面研究不足，影响了测试效果。

Method: LLAMA采用分层提示策略生成初始种子，多反馈优化机制改进种子生成与变异调度，并结合进化模糊引擎动态调整变异操作。

Result: 实验显示LLAMA在指令覆盖率和分支覆盖率上分别达到91%和90%，检测出132个已知漏洞。

Conclusion: LLAMA在智能合约安全测试中表现出高效性、适应性和实用性。

Abstract: Smart contracts play a pivotal role in blockchain ecosystems, and fuzzing
remains an important approach to securing smart contracts. Even though mutation
scheduling is a key factor influencing fuzzing effectiveness, existing fuzzers
have primarily explored seed scheduling and generation, while mutation
scheduling has been rarely addressed by prior work. In this work, we propose a
Large Language Models (LLMs)-based Multi-feedback Smart Contract Fuzzing
framework (LLAMA) that integrates LLMs, evolutionary mutation strategies, and
hybrid testing techniques. Key components of the proposed LLAMA include: (i) a
hierarchical prompting strategy that guides LLMs to generate semantically valid
initial seeds, coupled with a lightweight pre-fuzzing phase to select
high-potential inputs; (ii) a multi-feedback optimization mechanism that
simultaneously improves seed generation, seed selection, and mutation
scheduling by leveraging runtime coverage and dependency feedback; and (iii) an
evolutionary fuzzing engine that dynamically adjusts mutation operator
probabilities based on effectiveness, while incorporating symbolic execution to
escape stagnation and uncover deeper vulnerabilities. Our experiments
demonstrate that LLAMA outperforms state-of-the-art fuzzers in both coverage
and vulnerability detection. Specifically, it achieves 91% instruction coverage
and 90% branch coverage, while detecting 132 out of 148 known vulnerabilities
across diverse categories. These results highlight LLAMA's effectiveness,
adaptability, and practicality in real-world smart contract security testing
scenarios.

</details>


### [179] [From Static to Intelligent: Evolving SaaS Pricing with LLMs](https://arxiv.org/abs/2507.12104)
*Francisco Javier Cavero,Juan C. Alonso,Antonio Ruiz-Cortés*

Main category: cs.SE

TL;DR: 论文提出了一种基于LLM的自动化工具AI4Pricing2Yaml，用于将静态HTML定价转换为智能定价（iPricing），以解决SaaS定价管理的复杂性和人工错误问题。


<details>
  <summary>Details</summary>
Motivation: SaaS市场的快速扩张导致定价管理复杂化，缺乏自动化工具限制了定价模型的评估和优化能力。

Method: 采用LLM驱动的技术，结合网页抓取和信息提取，将静态HTML定价转换为动态、机器可读的iPricing。

Result: 在30个商业SaaS网站上的验证表明，系统能有效提取定价要素，但仍面临幻觉、复杂结构和动态内容的挑战。

Conclusion: 自动化智能定价转换有望提升SaaS定价管理的效率和一致性，未来研究将优化提取能力和系统适应性。

Abstract: The SaaS paradigm has revolutionized software distribution by offering
flexible pricing options to meet diverse customer needs. However, the rapid
expansion of the SaaS market has introduced significant complexity for DevOps
teams, who must manually manage and evolve pricing structures, an approach that
is both time-consuming and prone to errors. The absence of automated tools for
pricing analysis restricts the ability to efficiently evaluate, optimize, and
scale these models. This paper proposes leveraging intelligent pricing
(iPricing), dynamic, machine-readable pricing models, as a solution to these
challenges. Intelligent pricing enables competitive analysis, streamlines
operational decision-making, and supports continuous pricing evolution in
response to market dynamics, leading to improved efficiency and accuracy. We
present an LLM-driven approach that automates the transformation of static HTML
pricing into iPricing, significantly improving efficiency and consistency while
minimizing human error. Our implementation, AI4Pricing2Yaml, features a basic
Information Extractor that uses web scraping and LLMs technologies to extract
essential pricing components, plans, features, usage limits, and add-ons, from
SaaS websites. Validation against a dataset of 30 distinct commercial SaaS,
encompassing over 150 intelligent pricings, demonstrates the system's
effectiveness in extracting the desired elements across all steps. However,
challenges remain in addressing hallucinations, complex structures, and dynamic
content. This work highlights the potential of automating intelligent pricing
transformation to streamline SaaS pricing management, offering implications for
improved consistency and scalability in an increasingly intricate pricing
landscape. Future research will focus on refining extraction capabilities and
enhancing the system's adaptability to a wider range of SaaS websites.

</details>


### [180] [An Online A/B Testing Decision Support System for Web Usability Assessment Based on a Linguistic Decision-making Methodology: Case of Study a Virtual Learning Environment](https://arxiv.org/abs/2507.12118)
*Noe Zermeño,Cristina Zuheros,Lucas Daniel Del Rosso Calache,Francisco Herrera,Rosana Montes*

Main category: cs.SE

TL;DR: 提出了一种基于用户中心方法的网页可用性评估方法，结合A/B测试和角色扮演，应用于实际案例。


<details>
  <summary>Details</summary>
Motivation: 提升用户界面满意度，解决现有工具在评估设计时支持不足的问题。

Method: 结合设计思维和语言决策方法，通过角色扮演和可用性测试（如SUS）进行评估，并整合到A/B测试决策支持系统中。

Result: 在墨西哥瓜达拉哈拉大学的Moodle平台上进行了实际案例评估。

Conclusion: 该方法有效支持网页可用性评估，结合用户参与和A/B测试，提升了评估的全面性。

Abstract: In recent years, attention has increasingly focused on enhancing user
satisfaction with user interfaces, spanning both mobile applications and
websites. One fundamental aspect of human-machine interaction is the concept of
web usability. In order to assess web usability, the A/B testing technique
enables the comparison of data between two designs. Expanding the scope of
tests to include the designs being evaluated, in conjunction with the
involvement of both real and fictional users, presents a challenge for which
few online tools offer support. We propose a methodology for web usability
evaluation based on user-centered approaches such as design thinking and
linguistic decision-making, named Linguistic Decision-Making for Web Usability
Evaluation. This engages people in role-playing scenarios and conducts a number
of usability tests, including the widely recognized System Usability Scale. We
incorporate the methodology into a decision support system based on A/B
testing. We use real users in a case study to assess three Moodle platforms at
the University of Guadalajara, Mexico.

</details>


### [181] [MERA Code: A Unified Framework for Evaluating Code Generation Across Tasks](https://arxiv.org/abs/2507.12284)
*Artem Chervyakov,Alexander Kharitonov,Pavel Zadorozhny,Adamenko Pavel,Rodion Levichev,Dmitrii Vorobev,Dmitrii Salikhov,Aidar Valeev,Alena Pestova,Maria Dziuba,Ilseyar Alimova,Artem Zavgorodnev,Aleksandr Medvedev,Stanislav Moiseev,Elena Bruches,Daniil Grebenkin,Roman Derunets,Vikulov Vladimir,Anton Emelyanov,Dmitrii Babaev,Vladimir V. Ivanov,Valentin Malykh,Alena Fenogenova*

Main category: cs.SE

TL;DR: MERA Code是一个新的基准测试，专注于评估俄语代码生成LLM的性能，填补了现有基准测试在代码质量和实际应用中的空白。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估主要关注自然语言任务，忽视了代码质量和实际性能，导致对模型真实能力的理解不足。

Method: 提出MERA Code基准，包含11个任务和8种编程语言，提供开源代码库、评分系统和平台。

Result: 评估了开源和前沿API模型，分析了其在非英语语言中的局限性。

Conclusion: 公开发布MERA Code以指导未来研究，推动模型开发并标准化评估流程。

Abstract: Advancements in LLMs have enhanced task automation in software engineering;
however, current evaluations primarily focus on natural language tasks,
overlooking code quality. Most benchmarks prioritize high-level reasoning over
executable code and real-world performance, leaving gaps in understanding true
capabilities and risks associated with these models in production. To address
this issue, we propose MERA Code, a new addition to the MERA benchmark family,
specifically focused on evaluating code for the latest code generation LLMs in
Russian. This benchmark includes 11 evaluation tasks that span 8 programming
languages. Our proposed evaluation methodology features a taxonomy that
outlines the practical coding skills necessary for models to complete these
tasks. The benchmark comprises an open-source codebase for users to conduct
MERA assessments, a scoring system compatible with various programming
environments, and a platform featuring a leaderboard and submission system. We
evaluate open LLMs and frontier API models, analyzing their limitations in
terms of practical coding tasks in non-English languages. We are publicly
releasing MERA to guide future research, anticipate groundbreaking features in
model development, and standardize evaluation procedures.

</details>


### [182] [SWE-Perf: Can Language Models Optimize Code Performance on Real-World Repositories?](https://arxiv.org/abs/2507.12415)
*Xinyi He,Qian Liu,Mingzhe Du,Lin Yan,Zhijie Fan,Yiming Huang,Zejian Yuan,Zejun Ma*

Main category: cs.SE

TL;DR: SWE-Perf是首个针对LLM在真实仓库环境中代码性能优化任务的基准测试，包含140个实例，揭示了现有LLM与专家级优化性能之间的显著差距。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在代码性能优化方面的能力，填补现有研究的空白。

Method: 引入SWE-Perf基准测试，包含140个实例，评估文件级和仓库级方法（如Agentless和OpenHands）。

Result: 现有LLM与专家级优化性能之间存在显著差距。

Conclusion: SWE-Perf为新兴领域的研究提供了重要机会。

Abstract: Code performance optimization is paramount in real-world software engineering
and critical for production-level systems. While Large Language Models (LLMs)
have demonstrated impressive capabilities in code generation and bug fixing,
their proficiency in enhancing code performance at the repository level remains
largely unexplored. To address this gap, we introduce SWE-Perf, the first
benchmark specifically designed to systematically evaluate LLMs on code
performance optimization tasks within authentic repository contexts. SWE-Perf
comprises 140 carefully curated instances, each derived from
performance-improving pull requests from popular GitHub repositories. Each
benchmark instance includes the relevant codebase, target functions,
performance-related tests, expert-authored patches, and executable
environments. Through a comprehensive evaluation of representative methods that
span file-level and repo-level approaches (e.g., Agentless and OpenHands), we
reveal a substantial capability gap between existing LLMs and expert-level
optimization performance, highlighting critical research opportunities in this
emerging field.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [183] [Inference on Optimal Policy Values and Other Irregular Functionals via Smoothing](https://arxiv.org/abs/2507.11780)
*Justin Whitehouse,Morgane Austern,Vasilis Syrgkanis*

Main category: econ.EM

TL;DR: 论文提出了一种基于软最大平滑的估计器，用于估计最优治疗策略的价值，避免了参数限制和不现实的边界假设，同时实现了√n收敛速率。


<details>
  <summary>Details</summary>
Motivation: 构建最优治疗策略价值的置信区间是因果推断中的重要问题，但现有方法存在参数假设过强或计算复杂等问题。

Method: 通过控制一阶偏差和二阶余项，提出了一种基于软最大平滑的估计器，适用于涉及干扰组件的评分最大值参数估计。

Result: 该估计器实现了√n收敛速率，避免了参数限制和不现实的边界假设，且通常具有统计效率。

Conclusion: 软最大平滑方法为解决非可微函数估计问题提供了一种有效且实用的解决方案。

Abstract: Constructing confidence intervals for the value of an optimal treatment
policy is an important problem in causal inference. Insight into the optimal
policy value can guide the development of reward-maximizing, individualized
treatment regimes. However, because the functional that defines the optimal
value is non-differentiable, standard semi-parametric approaches for performing
inference fail to be directly applicable. Existing approaches for handling this
non-differentiability fall roughly into two camps. In one camp are estimators
based on constructing smooth approximations of the optimal value. These
approaches are computationally lightweight, but typically place unrealistic
parametric assumptions on outcome regressions. In another camp are approaches
that directly de-bias the non-smooth objective. These approaches don't place
parametric assumptions on nuisance functions, but they either require the
computation of intractably-many nuisance estimates, assume unrealistic
$L^\infty$ nuisance convergence rates, or make strong margin assumptions that
prohibit non-response to a treatment. In this paper, we revisit the problem of
constructing smooth approximations of non-differentiable functionals. By
carefully controlling first-order bias and second-order remainders, we show
that a softmax smoothing-based estimator can be used to estimate parameters
that are specified as a maximum of scores involving nuisance components. In
particular, this includes the value of the optimal treatment policy as a
special case. Our estimator obtains $\sqrt{n}$ convergence rates, avoids
parametric restrictions/unrealistic margin assumptions, and is often
statistically efficient.

</details>


### [184] [Data Synchronization at High Frequencies](https://arxiv.org/abs/2507.12220)
*Xinbing Kong,Cheng Liu,Bin Wu*

Main category: econ.EM

TL;DR: 论文提出了一种新的数据同步框架，通过矩阵补全方法解决高频金融市场中的异步交易问题，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 高频金融市场中的异步交易导致计量分析偏差，影响风险估计和投资组合决策，现有同步方法存在信息丢失和价格滞后问题。

Method: 将数据同步问题转化为约束矩阵补全问题，通过最小化核范数恢复潜在价格增量矩阵，利用大规模线性系统约束。

Result: 理论证明估计量的存在性和唯一性，实证显示方法显著降低同步误差，修正系统性风险估计偏差，提高投资组合夏普比率。

Conclusion: 该框架为揭示资产价格真实动态提供了强大工具，对高频风险管理、算法交易和计量推断有直接应用价值。

Abstract: Asynchronous trading in high-frequency financial markets introduces
significant biases into econometric analysis, distorting risk estimates and
leading to suboptimal portfolio decisions. Existing synchronization methods,
such as the previous-tick approach, suffer from information loss and create
artificial price staleness. We introduce a novel framework that recasts the
data synchronization challenge as a constrained matrix completion problem. Our
approach recovers the potential matrix of high-frequency price increments by
minimizing its nuclear norm -- capturing the underlying low-rank factor
structure -- subject to a large-scale linear system derived from observed,
asynchronous price changes. Theoretically, we prove the existence and
uniqueness of our estimator and establish its convergence rate. A key
theoretical insight is that our method accurately and robustly leverages
information from both frequently and infrequently traded assets, overcoming a
critical difficulty of efficiency loss in traditional methods. Empirically,
using extensive simulations and a large panel of S&P 500 stocks, we demonstrate
that our method substantially outperforms established benchmarks. It not only
achieves significantly lower synchronization errors, but also corrects the bias
in systematic risk estimates (i.e., eigenvalues) and the estimate of betas
caused by stale prices. Crucially, portfolios constructed using our
synchronized data yield consistently and economically significant higher
out-of-sample Sharpe ratios. Our framework provides a powerful tool for
uncovering the true dynamics of asset prices, with direct implications for
high-frequency risk management, algorithmic trading, and econometric inference.

</details>


### [185] [Forecasting Climate Policy Uncertainty: Evidence from the United States](https://arxiv.org/abs/2507.12276)
*Donia Besher,Anirban Sengupta,Tanujit Chakraborty*

Main category: econ.EM

TL;DR: 该研究利用贝叶斯结构时间序列（BSTS）模型预测美国气候政策不确定性（CPU）指数，结合经济指标、金融周期数据和公众情绪等协变量，验证了BSTS模型在长期预测中的优越性。


<details>
  <summary>Details</summary>
Motivation: 气候政策不确定性（CPU）对绿色技术投资和监管规划有显著影响，尤其在经济压力时期会增加公众对气候改革的抵触。因此，准确预测CPU对政策制定至关重要。

Method: 研究采用贝叶斯结构时间序列（BSTS）模型，结合动态特征选择机制（基于spike-and-slab先验）处理大量协变量，并通过脉冲响应分析验证特征有效性。

Result: 实验表明，BSTS模型在长期预测中优于传统和深度学习框架，且宏观金融冲击对CPU的影响随时间变化。

Conclusion: BSTS模型能有效预测CPU，尤其在长期预测中表现突出，为政策制定提供了可靠工具。

Abstract: Forecasting Climate Policy Uncertainty (CPU) is essential as policymakers
strive to balance economic growth with environmental goals. High levels of CPU
can slow down investments in green technologies, make regulatory planning more
difficult, and increase public resistance to climate reforms, especially during
times of economic stress. This study addresses the challenge of forecasting the
US CPU index by building the Bayesian Structural Time Series (BSTS) model with
a large set of covariates, including economic indicators, financial cycle data,
and public sentiments captured through Google Trends. The key strength of the
BSTS model lies in its ability to efficiently manage a large number of
covariates through its dynamic feature selection mechanism based on the
spike-and-slab prior. To validate the effectiveness of the selected features of
the BSTS model, an impulse response analysis is performed. The results show
that macro-financial shocks impact CPU in different ways over time. Numerical
experiments are performed to evaluate the performance of the BSTS model with
exogenous variables on the US CPU dataset over different forecasting horizons.
The empirical results confirm that BSTS consistently outperforms classical and
deep learning frameworks, particularly for semi-long-term and long-term
forecasts.

</details>


### [186] [Catching Bid-rigging Cartels with Graph Attention Neural Networks](https://arxiv.org/abs/2507.12369)
*David Imhof,Emanuel W Viklund,Martin Huber*

Main category: econ.EM

TL;DR: 提出了一种基于图注意力网络（GATs）的新方法，用于检测合谋行为，并在多国市场数据上验证了其高效性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在检测合谋行为时存在局限性，需要一种更高效且可迁移的深度学习算法。

Method: 利用图注意力网络（GATs）构建预测模型，结合先验研究中的特征，测试于13个市场的跨国数据集。

Result: 模型在跨市场预测中表现优异，准确率在80%至90%之间，最佳配置达到91%，优于传统集成方法。

Conclusion: GATs为竞争监管机构提供了一种高效的工具，可用于筛查潜在的市场合谋行为。

Abstract: We propose a novel application of graph attention networks (GATs), a type of
graph neural network enhanced with attention mechanisms, to develop a deep
learning algorithm for detecting collusive behavior, leveraging predictive
features suggested in prior research. We test our approach on a large dataset
covering 13 markets across seven countries. Our results show that predictive
models based on GATs, trained on a subset of the markets, can be effectively
transferred to other markets, achieving accuracy rates between 80\% and 90\%,
depending on the hyperparameter settings. The best-performing configuration,
applied to eight markets from Switzerland and the Japanese region of Okinawa,
yields an average accuracy of 91% for cross-market prediction. When extended to
12 markets, the method maintains a strong performance with an average accuracy
of 84\%, surpassing traditional ensemble approaches in machine learning. These
results suggest that GAT-based detection methods offer a promising tool for
competition authorities to screen markets for potential cartel activity.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [187] [Orchestrating the Implementation of the Smart City](https://arxiv.org/abs/2507.12267)
*Filippo Marchesani*

Main category: econ.GN

TL;DR: 本章探讨智慧城市的六个核心维度（经济、交通、环境、人、生活、治理），强调其相互依赖性和整体协调的必要性。


<details>
  <summary>Details</summary>
Motivation: 研究智慧城市的核心维度及其整合对可持续城市发展的重要性。

Method: 基于Giffinger等人（2007）及后续文献，结合制度案例（如设立数字创新市政办公室）分析。

Result: 信息通信技术是关键推动力，但需与人力和社会资本结合；治理和内部能力影响智慧转型。

Conclusion: 智慧城市应视为技术、人和治理动态互动的整体生态系统，需以人为本，确保包容性和公民参与。

Abstract: This chapter explores the six core dimensions of smart cities (i.e. smart
economy, mobility, environment, people, living, and governance) emphasizing
their interdependence and the need for holistic orchestration. Building on
Giffinger et al. (2007) and subsequent literature, it argues that integrating
these dimensions is crucial for sustainable urban development. ICT plays a key
enabling role but must be complemented by human and social capital. Through
institutional examples, such as the creation of dedicated municipal offices for
digital innovation, the chapter illustrates how governance and internal
capacity shape smart transitions. A human-centric approach is also essential,
ensuring inclusivity, creativity, and active civic participation. Ultimately,
smart cities must be viewed as cohesive urban ecosystems where technology,
people, and governance interact dynamically.

</details>


### [188] [International promotion patterns in the smart city literature: Exploring the role of geography in affecting local drivers and smart cities' outcomes](https://arxiv.org/abs/2507.12281)
*Filippo Marchesani,Francesca Masciarelli,Andrea Bikfalvi*

Main category: econ.GN

TL;DR: 本文通过系统文献综述分析了2008年至2021年顶级期刊中关于智慧城市国际推广的研究，填补了多学科背景下智慧城市全球认可度的研究空白。


<details>
  <summary>Details</summary>
Motivation: 智慧城市的发展对城市环境的影响已有广泛讨论，但其全球认可度因多学科性质仍不明确，需要系统性研究。

Method: 对2008年至2021年顶级同行评审期刊中的文献进行系统性综述。

Result: 提供了现有文献的全面分析，揭示了智慧城市国际推广的研究现状。

Conclusion: 研究填补了智慧城市全球认可度的研究空白，为未来研究提供了基础。

Abstract: The rise of smart cities represents a significant trend in urban development.
However, only in recent years has attention shifted toward the international
promotion of these cities. Despite ongoing academic discussions on the impact
of smart city development on urban environments, the global recognition of
smart cities remains uncertain due to their multidisciplinary nature. To
address this, we conducted a systematic literature review of articles published
in top-tier peer-reviewed journals from 2008 to December 2021, offering a
comprehensive analysis of the existing literature.

</details>


### [189] [Causality analysis of electricity market liberalization on electricity price using novel Machine Learning methods](https://arxiv.org/abs/2507.12331)
*Orr Shahar,Stefan Lessmann,Daniel Traian Pele*

Main category: econ.GN

TL;DR: 论文研究了电力市场自由化对美国电价的影响，提出因果机器学习（Causal ML）作为新方法，发现自由化短期内使电价下降7%。


<details>
  <summary>Details</summary>
Motivation: 能源与金融市场的关联日益重要，研究电力市场自由化的影响可为政策制定者提供新见解。

Method: 采用因果机器学习方法，比较不同模型的性能，重点分析DeepProbCP框架。

Result: DeepProbCP框架表现最优，电力市场自由化短期内使电价下降7%。

Conclusion: 因果机器学习适用于能源政策干预，电力市场自由化对电价有显著短期影响。

Abstract: Relationships between the energy and the finance markets are increasingly
important. Understanding these relationships is vital for policymakers and
other stakeholders as the world faces challenges such as satisfying humanity's
increasing need for energy and the effects of climate change. In this paper, we
investigate the causal effect of electricity market liberalization on the
electricity price in the US. By performing this analysis, we aim to provide new
insights into the ongoing debate about the benefits of electricity market
liberalization. We introduce Causal Machine Learning as a new approach for
interventions in the energy-finance field. The development of machine learning
in recent years opened the door for a new branch of machine learning models for
causality impact, with the ability to extract complex patterns and
relationships from the data. We discuss the advantages of causal ML methods and
compare the performance of ML-based models to shed light on the applicability
of causal ML frameworks to energy policy intervention cases. We find that the
DeepProbCP framework outperforms the other frameworks examined. In addition, we
find that liberalization of, and individual players' entry to, the electricity
market resulted in a 7% decrease in price in the short term.

</details>


### [190] [The Case against Scale: Empirical Evidence of Underperformance in Large Secondary Funds](https://arxiv.org/abs/2507.12436)
*Jitesh Gurav*

Main category: econ.GN

TL;DR: 论文质疑大基金在私募二级市场的优势，实证表明小基金表现更优，建议投资者调整策略。


<details>
  <summary>Details</summary>
Motivation: 分析大基金在私募二级市场的流行现象，并质疑其实际优势。

Method: 通过实证研究比较大基金与小基金的内部收益率（IRRs）。

Result: 小基金的表现优于大基金。

Conclusion: 投资者应重新评估策略，优先考虑小基金。

Abstract: The paper analyses the increasing popularity of large funds in the secondary
private equity market, which are pegged on the perceived larger scale
advantages of operational efficiency and fewer manager relationships (Reuter &
Zitzewitz, 2021). However, it has been proved empirically that smaller funds
perform better than the big ones in terms of their internal rates of return
(IRRs). This work questions this authoritative view, providing evidence of
outperformance of smaller funds relative to their larger counterparts. This
research shows us the benefits that smaller funds possess. Thus, investors must
revisit their allocation strategy to prioritize larger funds automatically
(Gualandris et al.,2021).

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [191] [CompressedVQA-HDR: Generalized Full-reference and No-reference Quality Assessment Models for Compressed High Dynamic Range Videos](https://arxiv.org/abs/2507.11900)
*Wei Sun,Linhan Cao,Kang Fu,Dandan Zhu,Jun Jia,Menghan Hu,Xiongkuo Min,Guangtao Zhai*

Main category: eess.IV

TL;DR: CompressedVQA-HDR是一个针对HDR视频质量评估的VQA框架，采用Swin Transformer和SigLip 2作为骨干网络，分别用于全参考和无参考模型，通过预训练和微调策略在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有VQA方法对HDR视频的泛化能力不足，需要一种能够有效评估压缩视频质量的方法。

Method: 采用Swin Transformer和SigLip 2作为骨干网络，分别构建全参考和无参考模型，通过预训练和微调策略优化性能。

Result: 模型在多个数据集上表现优异，CompressedVQA-HDR-FR在IEEE ICME 2025挑战赛中获第一名。

Conclusion: CompressedVQA-HDR框架在HDR视频质量评估中表现出色，为压缩视频质量评估提供了新方法。

Abstract: Video compression is a standard procedure applied to all videos to minimize
storage and transmission demands while preserving visual quality as much as
possible. Therefore, evaluating the visual quality of compressed videos is
crucial for guiding the practical usage and further development of video
compression algorithms. Although numerous compressed video quality assessment
(VQA) methods have been proposed, they often lack the generalization capability
needed to handle the increasing diversity of video types, particularly high
dynamic range (HDR) content. In this paper, we introduce CompressedVQA-HDR, an
effective VQA framework designed to address the challenges of HDR video quality
assessment. Specifically, we adopt the Swin Transformer and SigLip 2 as the
backbone networks for the proposed full-reference (FR) and no-reference (NR)
VQA models, respectively. For the FR model, we compute deep structural and
textural similarities between reference and distorted frames using
intermediate-layer features extracted from the Swin Transformer as its
quality-aware feature representation. For the NR model, we extract the global
mean of the final-layer feature maps from SigLip 2 as its quality-aware
representation. To mitigate the issue of limited HDR training data, we
pre-train the FR model on a large-scale standard dynamic range (SDR) VQA
dataset and fine-tune it on the HDRSDR-VQA dataset. For the NR model, we employ
an iterative mixed-dataset training strategy across multiple compressed VQA
datasets, followed by fine-tuning on the HDRSDR-VQA dataset. Experimental
results show that our models achieve state-of-the-art performance compared to
existing FR and NR VQA models. Moreover, CompressedVQA-HDR-FR won first place
in the FR track of the Generalizable HDR & SDR Video Quality Measurement Grand
Challenge at IEEE ICME 2025. The code is available at
https://github.com/sunwei925/CompressedVQA-HDR.

</details>


### [192] [Identifying Signatures of Image Phenotypes to Track Treatment Response in Liver Disease](https://arxiv.org/abs/2507.12012)
*Matthias Perkonigg,Nina Bastati,Ahmed Ba-Ssalamah,Peter Mesenbrink,Alexander Goehler,Miljen Martic,Xiaofei Zhou,Michael Trauner,Georg Langs*

Main category: eess.IV

TL;DR: 无监督机器学习通过深度聚类网络识别肝脏MRI图像中的组织模式，量化治疗反应，并在非酒精性脂肪性肝炎患者中验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 量化与疾病进展和治疗反应相关的图像模式对个体化治疗和新疗法开发至关重要。

Method: 使用深度聚类网络对医学图像块进行编码和聚类，建立组织词汇表，捕捉治疗相关的组织变化。

Result: 该方法在随机对照试验中优于非成像指标，并能预测活检特征。

Conclusion: 该方法可广泛应用于非侵入性影像数据，为疾病监测和治疗评估提供新工具。

Abstract: Quantifiable image patterns associated with disease progression and treatment
response are critical tools for guiding individual treatment, and for
developing novel therapies. Here, we show that unsupervised machine learning
can identify a pattern vocabulary of liver tissue in magnetic resonance images
that quantifies treatment response in diffuse liver disease. Deep clustering
networks simultaneously encode and cluster patches of medical images into a
low-dimensional latent space to establish a tissue vocabulary. The resulting
tissue types capture differential tissue change and its location in the liver
associated with treatment response. We demonstrate the utility of the
vocabulary on a randomized controlled trial cohort of non-alcoholic
steatohepatitis patients. First, we use the vocabulary to compare longitudinal
liver change in a placebo and a treatment cohort. Results show that the method
identifies specific liver tissue change pathways associated with treatment, and
enables a better separation between treatment groups than established
non-imaging measures. Moreover, we show that the vocabulary can predict biopsy
derived features from non-invasive imaging data. We validate the method on a
separate replication cohort to demonstrate the applicability of the proposed
method.

</details>


### [193] [Benchmarking and Explaining Deep Learning Cortical Lesion MRI Segmentation in Multiple Sclerosis](https://arxiv.org/abs/2507.12092)
*Nataliia Molchanova,Alessandro Cagol,Mario Ocampo-Pineda,Po-Jui Lu,Matthias Weigel,Xinjie Chen,Erin Beck,Charidimos Tsagkas,Daniel Reich,Colin Vanden Bulcke,Anna Stolting,Serena Borrelli,Pietro Maggi,Adrien Depeursinge,Cristina Granziera,Henning Mueller,Pedro M. Gordaliza,Meritxell Bach Cuadra*

Main category: eess.IV

TL;DR: 该论文提出了一个多中心基准测试，用于检测和分割多发性硬化症中的皮质病变，使用nnU-Net框架进行优化，并分析了模型在不同数据条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 皮质病变在多发性硬化症中具有重要诊断和预后价值，但由于MRI表现不明显、专家标注困难以及缺乏标准化方法，临床应用受限。

Method: 使用656个MRI扫描数据，基于nnU-Net框架进行优化，并通过域外测试评估模型泛化能力。

Result: 模型在域内和域外的F1分数分别为0.64和0.5，展示了较强的病变检测能力。

Conclusion: 研究分析了数据变异性、病变模糊性和协议差异对模型性能的影响，并提出了未来临床应用的改进建议，同时公开了代码和模型。

Abstract: Cortical lesions (CLs) have emerged as valuable biomarkers in multiple
sclerosis (MS), offering high diagnostic specificity and prognostic relevance.
However, their routine clinical integration remains limited due to subtle
magnetic resonance imaging (MRI) appearance, challenges in expert annotation,
and a lack of standardized automated methods. We propose a comprehensive
multi-centric benchmark of CL detection and segmentation in MRI. A total of 656
MRI scans, including clinical trial and research data from four institutions,
were acquired at 3T and 7T using MP2RAGE and MPRAGE sequences with
expert-consensus annotations. We rely on the self-configuring nnU-Net
framework, designed for medical imaging segmentation, and propose adaptations
tailored to the improved CL detection. We evaluated model generalization
through out-of-distribution testing, demonstrating strong lesion detection
capabilities with an F1-score of 0.64 and 0.5 in and out of the domain,
respectively. We also analyze internal model features and model errors for a
better understanding of AI decision-making. Our study examines how data
variability, lesion ambiguity, and protocol differences impact model
performance, offering future recommendations to address these barriers to
clinical adoption. To reinforce the reproducibility, the implementation and
models will be publicly accessible and ready to use at
https://github.com/Medical-Image-Analysis-Laboratory/ and
https://doi.org/10.5281/zenodo.15911797.

</details>
