<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 50]
- [cs.CL](#cs.CL) [Total: 85]
- [cs.CV](#cs.CV) [Total: 175]
- [cs.DB](#cs.DB) [Total: 10]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.NI](#cs.NI) [Total: 12]
- [cs.SE](#cs.SE) [Total: 29]
- [econ.EM](#econ.EM) [Total: 5]
- [econ.GN](#econ.GN) [Total: 3]
- [econ.TH](#econ.TH) [Total: 5]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Evaluating Generalization and Representation Stability in Small LMs via Prompting](https://arxiv.org/abs/2506.17289)
*Rahul Raja,Arpita Vats*

Main category: cs.AI

TL;DR: 比较小语言模型在少样本提示和监督微调下的泛化能力，分析其在分布内和分布外设置中的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨少样本提示和监督微调在低资源设置和分布变化下的鲁棒性差异。

Method: 通过比较不同任务格式、提示风格和模型规模，分析两种方法的内部表示和泛化能力。

Result: 发现两种方法在知识内化和泛化方面存在显著差异，为低数据场景下的模型选择提供指导。

Conclusion: 研究为提示与微调的争论提供了实证依据，并提出了低数据场景下的实用建议。

Abstract: We investigate the generalization capabilities of small language models under
two popular adaptation paradigms: few-shot prompting and supervised
fine-tuning. While prompting is often favored for its parameter efficiency and
flexibility, it remains unclear how robust this approach is in low-resource
settings and under distributional shifts. This paper presents a comparative
study of prompting and fine-tuning across task formats, prompt styles, and
model scales, with a focus on their behavior in both in-distribution and
out-of-distribution (OOD) settings.
  Beyond accuracy, we analyze the internal representations learned by each
approach to assess the stability and abstraction of task-specific features. Our
findings highlight critical differences in how small models internalize and
generalize knowledge under different adaptation strategies. This work offers
practical guidance for model selection in low-data regimes and contributes
empirical insight into the ongoing debate over prompting versus fine-tuning.
Code for the experiments is available at the following

</details>


### [2] [Individual Causal Inference with Structural Causal Model](https://arxiv.org/abs/2506.17300)
*Daniel T. Chang*

Main category: cs.AI

TL;DR: 个体因果推断（ICI）利用因果推断方法，结合个体特征/事实，预测干预对个体的影响。通过结构因果模型（SCM）实现个体化推断，提出indiv(W)算子和个体因果查询。


<details>
  <summary>Details</summary>
Motivation: 传统因果推断方法基于群体，难以直接应用于个体。ICI旨在解决个体因果效应（ICE）估计的挑战，利用SCM的外生变量编码个体差异。

Method: 提出indiv(W)算子表示个体化过程，定义个体因果查询P(Y|indiv(W),do(X),Z)。基于SCM进行个体化推断。

Result: 论证了ICI是基于个体可能替代（alternatives）而非反事实（counterfactuals）的推断。

Conclusion: ICI通过SCM实现个体化因果推断，为个体干预效果预测提供了新方法。

Abstract: Individual causal inference (ICI) uses causal inference methods to understand
and predict the effects of interventions on individuals, considering their
specific characteristics / facts. It aims to estimate individual causal effect
(ICE), which varies across individuals. Estimating ICE can be challenging due
to the limited data available for individuals, and the fact that most causal
inference methods are population-based. Structural Causal Model (SCM) is
fundamentally population-based. Therefore, causal discovery (structural
learning and parameter learning), association queries and intervention queries
are all naturally population-based. However, exogenous variables (U) in SCM can
encode individual variations and thus provide the mechanism for individualized
population per specific individual characteristics / facts. Based on this, we
propose ICI with SCM as a "rung 3" causal inference, because it involves
"imagining" what would be the causal effect of a hypothetical intervention on
an individual, given the individual's observed characteristics / facts.
Specifically, we propose the indiv-operator, indiv(W), to formalize/represent
the population individualization process, and the individual causal query, P(Y
| indiv(W), do(X), Z), to formalize/represent ICI. We show and argue that ICI
with SCM is inference on individual alternatives (possible), not individual
counterfactuals (non-actual).

</details>


### [3] [Resource Rational Contractualism Should Guide AI Alignment](https://arxiv.org/abs/2506.17434)
*Sydney Levine,Matija Franklin,Tan Zhi-Xuan,Secil Yanik Guyot,Lionel Wong,Daniel Kilov,Yejin Choi,Joshua B. Tenenbaum,Noah Goodman,Seth Lazar,Iason Gabriel*

Main category: cs.AI

TL;DR: 论文提出资源理性契约主义（RRC），通过启发式方法高效模拟多方理性协议，以解决AI在人类环境中决策的复杂性问题。


<details>
  <summary>Details</summary>
Motivation: AI需在目标与价值观多样的人类环境中决策，传统契约主义达成协议成本高、速度慢。

Method: 采用资源理性契约主义（RRC），利用规范基础和认知启发式工具箱，在效率与准确性间权衡。

Result: RRC使AI能高效运作，并动态适应和解释不断变化的人类社会。

Conclusion: RRC为AI在复杂人类环境中的决策提供了一种高效且适应性强的解决方案。

Abstract: AI systems will soon have to navigate human environments and make decisions
that affect people and other AI agents whose goals and values diverge.
Contractualist alignment proposes grounding those decisions in agreements that
diverse stakeholders would endorse under the right conditions, yet securing
such agreement at scale remains costly and slow -- even for advanced AI. We
therefore propose Resource-Rational Contractualism (RRC): a framework where AI
systems approximate the agreements rational parties would form by drawing on a
toolbox of normatively-grounded, cognitively-inspired heuristics that trade
effort for accuracy. An RRC-aligned agent would not only operate efficiently,
but also be equipped to dynamically adapt to and interpret the ever-changing
human social world.

</details>


### [4] [Keeping Medical AI Healthy: A Review of Detection and Correction Methods for System Degradation](https://arxiv.org/abs/2506.17442)
*Hao Guan,David Bates,Li Zhou*

Main category: cs.AI

TL;DR: 该论文综述了医疗AI系统性能退化的原因、检测方法及校正策略，旨在提升其长期可靠性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI系统在动态临床环境中易因数据分布变化等因素导致性能退化，亟需持续监控与自我校正机制以确保安全性和准确性。

Method: 回顾性能退化的常见原因，总结数据与模型漂移检测技术，分析根本原因，并探讨从模型重训练到测试时适应的校正策略。

Result: 论文提供了传统机器学习模型与大型语言模型在医疗AI中的优劣势分析，并提出了未来研究方向。

Conclusion: 该研究为开发可靠、鲁棒的医疗AI系统提供了指导，以支持其在动态临床环境中的长期安全部署。

Abstract: Artificial intelligence (AI) is increasingly integrated into modern
healthcare, offering powerful support for clinical decision-making. However, in
real-world settings, AI systems may experience performance degradation over
time, due to factors such as shifting data distributions, changes in patient
characteristics, evolving clinical protocols, and variations in data quality.
These factors can compromise model reliability, posing safety concerns and
increasing the likelihood of inaccurate predictions or adverse outcomes. This
review presents a forward-looking perspective on monitoring and maintaining the
"health" of AI systems in healthcare. We highlight the urgent need for
continuous performance monitoring, early degradation detection, and effective
self-correction mechanisms. The paper begins by reviewing common causes of
performance degradation at both data and model levels. We then summarize key
techniques for detecting data and model drift, followed by an in-depth look at
root cause analysis. Correction strategies are further reviewed, ranging from
model retraining to test-time adaptation. Our survey spans both traditional
machine learning models and state-of-the-art large language models (LLMs),
offering insights into their strengths and limitations. Finally, we discuss
ongoing technical challenges and propose future research directions. This work
aims to guide the development of reliable, robust medical AI systems capable of
sustaining safe, long-term deployment in dynamic clinical settings.

</details>


### [5] [OmniReflect: Discovering Transferable Constitutions for LLM agents via Neuro-Symbolic Reflections](https://arxiv.org/abs/2506.17449)
*Manasa Bharadwaj,Nikhil Verma,Kevin Ferreira*

Main category: cs.AI

TL;DR: OmniReflect是一个层次化、反思驱动的框架，通过构建指导原则（constitution）提升LLM代理的性能，在动态环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如微调和自我修正）缺乏长期学习的通用机制，且在动态环境中效率低下。

Method: OmniReflect采用两种模式：自我维持（单个代理定期反思）和协作（Meta-advisor从校准集中提取指导原则），结合神经、符号和神经符号技术。

Result: 在ALFWorld、BabyAI和PDDL任务中，性能显著提升（绝对增益达10.3%至23.8%）。

Conclusion: OmniReflect在多种环境和模型上表现出鲁棒性和高效性。

Abstract: Efforts to improve Large Language Model (LLM) agent performance on complex
tasks have largely focused on fine-tuning and iterative self-correction.
However, these approaches often lack generalizable mechanisms for longterm
learning and remain inefficient in dynamic environments. We introduce
OmniReflect, a hierarchical, reflection-driven framework that constructs a
constitution, a compact set of guiding principles distilled from task
experiences, to enhance the effectiveness and efficiency of an LLM agent.
OmniReflect operates in two modes: Self-sustaining, where a single agent
periodically curates its own reflections during task execution, and
Co-operative, where a Meta-advisor derives a constitution from a small
calibration set to guide another agent. To construct these constitutional
principles, we employ Neural, Symbolic, and NeuroSymbolic techniques, offering
a balance between contextual adaptability and computational efficiency.
Empirical results averaged across models show major improvements in task
success, with absolute gains of +10.3% on ALFWorld, +23.8% on BabyAI, and +8.3%
on PDDL in the Self-sustaining mode. Similar gains are seen in the Co-operative
mode, where a lightweight Qwen3-4B ReAct agent outperforms all Reflexion
baselines on BabyAI. These findings highlight the robustness and effectiveness
of OmniReflect across environments and backbones.

</details>


### [6] [From Unstructured Communication to Intelligent RAG: Multi-Agent Automation for Supply Chain Knowledge Bases](https://arxiv.org/abs/2506.17484)
*Yao Zhang,Zaixi Shang,Silpan Patel,Mikel Zuniga*

Main category: cs.AI

TL;DR: 论文提出了一种离线优先的方法，利用多智能体系统将供应链支持票据转化为结构化知识库，显著提升RAG系统的性能。


<details>
  <summary>Details</summary>
Motivation: 供应链操作数据庞大但知识分散在非结构化通讯中，现有RAG系统因数据噪声和不完整而效果有限。

Method: 采用基于LLM的多智能体系统，包括分类发现、分类和知识合成三个智能体，将支持票据转化为结构化知识库。

Result: 实验显示，该方法将知识库体积减少至3.4%，提升RAG系统性能（48.74% vs. 38.60%有用回答），减少77.4%无用回答。

Conclusion: 通过离线处理将非结构化通讯转化为结构化知识，显著提升操作效率，自动解决约50%未来票据。

Abstract: Supply chain operations generate vast amounts of operational data; however,
critical knowledge such as system usage practices, troubleshooting workflows,
and resolution techniques often remains buried within unstructured
communications like support tickets, emails, and chat logs. While RAG systems
aim to leverage such communications as a knowledge base, their effectiveness is
limited by raw data challenges: support tickets are typically noisy,
inconsistent, and incomplete, making direct retrieval suboptimal. Unlike
existing RAG approaches that focus on runtime optimization, we introduce a
novel offline-first methodology that transforms these communications into a
structured knowledge base. Our key innovation is a LLMs-based multi-agent
system orchestrating three specialized agents: Category Discovery for taxonomy
creation, Categorization for ticket grouping, and Knowledge Synthesis for
article generation. Applying our methodology to real-world support tickets with
resolution notes and comments, our system creates a compact knowledge base -
reducing total volume to just 3.4% of original ticket data while improving
quality. Experiments demonstrate that our prebuilt knowledge base in RAG
systems significantly outperforms traditional RAG implementations (48.74% vs.
38.60% helpful answers) and achieves a 77.4% reduction in unhelpful responses.
By automating institutional knowledge capture that typically remains siloed in
experts' heads, our solution translates to substantial operational efficiency:
reducing support workload, accelerating resolution times, and creating
self-improving systems that automatically resolve approximately 50% of future
supply chain tickets. Our approach addresses a key gap in knowledge management
by transforming transient communications into structured, reusable knowledge
through intelligent offline processing rather than latency-inducing runtime
architectures.

</details>


### [7] [Kaleidoscopic Teaming in Multi Agent Simulations](https://arxiv.org/abs/2506.17514)
*Ninareh Mehrabi,Tharindu Kumarage,Kai-Wei Chang,Aram Galstyan,Rahul Gupta*

Main category: cs.AI

TL;DR: 论文提出了一种名为“万花筒式团队”的新框架，用于评估AI代理在单代理和多代理场景中的安全性，弥补了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有红队或安全评估框架无法全面评估AI代理在复杂行为、思维过程和交互中的安全风险，尤其是在多代理场景中。

Method: 引入“万花筒式团队”概念，开发新框架生成多样化场景，评估单代理和多代理的安全性，并采用上下文优化技术改进场景生成。

Result: 通过框架识别了多种模型在代理用例中的安全漏洞。

Conclusion: 万花筒式团队框架为AI代理的安全性评估提供了更全面的方法。

Abstract: Warning: This paper contains content that may be inappropriate or offensive.
  AI agents have gained significant recent attention due to their autonomous
tool usage capabilities and their integration in various real-world
applications. This autonomy poses novel challenges for the safety of such
systems, both in single- and multi-agent scenarios. We argue that existing red
teaming or safety evaluation frameworks fall short in evaluating safety risks
in complex behaviors, thought processes and actions taken by agents. Moreover,
they fail to consider risks in multi-agent setups where various vulnerabilities
can be exposed when agents engage in complex behaviors and interactions with
each other. To address this shortcoming, we introduce the term kaleidoscopic
teaming which seeks to capture complex and wide range of vulnerabilities that
can happen in agents both in single-agent and multi-agent scenarios. We also
present a new kaleidoscopic teaming framework that generates a diverse array of
scenarios modeling real-world human societies. Our framework evaluates safety
of agents in both single-agent and multi-agent setups. In single-agent setup,
an agent is given a scenario that it needs to complete using the tools it has
access to. In multi-agent setup, multiple agents either compete against or
cooperate together to complete a task in the scenario through which we capture
existing safety vulnerabilities in agents. We introduce new in-context
optimization techniques that can be used in our kaleidoscopic teaming framework
to generate better scenarios for safety analysis. Lastly, we present
appropriate metrics that can be used along with our framework to measure safety
of agents. Utilizing our kaleidoscopic teaming framework, we identify
vulnerabilities in various models with respect to their safety in agentic
use-cases.

</details>


### [8] [Cite Pretrain: Retrieval-Free Knowledge Attribution for Large Language Models](https://arxiv.org/abs/2506.17585)
*Yukun Huang,Sanxing Chen,Jian Pei,Manzil Zaheer,Bhuwan Dhingra*

Main category: cs.AI

TL;DR: 论文探讨如何通过改进训练过程，使语言模型能够可靠地引用预训练文档，而无需依赖推理时的外部检索器。提出了一种名为Active Indexing的方法，显著提升了引用精度。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型的引用不可靠，且依赖外部检索器会引入延迟和噪声。研究目标是让模型在预训练阶段就能可靠地引用文档。

Method: 采用两阶段方法：1) 持续预训练以将事实绑定到文档标识符；2) 指令调优以激发引用行为。提出Active Indexing，通过合成QA对增强训练数据。

Result: Active Indexing在Qwen2.5-7B和3B模型上表现优于Passive Indexing，引用精度提升高达30.2%。数据增强规模越大，性能提升越明显。

Conclusion: Active Indexing是一种有效的方法，能够显著提升语言模型在引用任务中的表现，且性能随数据增强规模增加而持续提升。

Abstract: Trustworthy language models should provide both correct and verifiable
answers. While language models can sometimes attribute their outputs to
pretraining data, their citations are often unreliable due to hallucination. As
a result, current systems insert citations by querying an external retriever at
inference time, introducing latency, infrastructure dependence, and
vulnerability to retrieval noise. We explore whether LLMs can be made to
reliably attribute to the documents seen during (continual)
pretraining--without test-time retrieval--by revising the training process. To
evaluate this, we release CitePretrainBench, a benchmark that mixes real-world
corpora (Wikipedia, Common Crawl, arXiv) with novel, unseen documents and
probes both short-form (single fact) and long-form (multi-fact) citation tasks.
Our approach follows a two-stage process: (1) continual pretraining to bind
facts to persistent document identifiers, and (2) instruction tuning to elicit
citation behavior. We find that simple Passive Indexing, which appends an
identifier to each document, helps memorize verbatim text but fails on
paraphrased or compositional facts. Instead, we propose Active Indexing, which
continually pretrains on synthetic QA pairs that (1) restate each fact in
diverse compositional forms, and (2) require bidirectional source-to-fact and
fact-to-source generation, jointly teaching the model to generate content from
a cited source and to attribute its own answers. Experiments with Qwen2.5-7B
and 3B show that Active Indexing consistently outperforms Passive Indexing
across all tasks and models, with citation precision gains up to 30.2 percent.
Our ablation studies reveal that performance continues to improve as we scale
the amount of augmented data, showing a clear upward trend even at 16 times the
original token count.

</details>


### [9] [Taming the Untamed: Graph-Based Knowledge Retrieval and Reasoning for MLLMs to Conquer the Unknown](https://arxiv.org/abs/2506.17589)
*Bowen Wang*

Main category: cs.AI

TL;DR: 论文探讨了多模态大语言模型（MLLMs）在特定领域任务中的局限性，提出了一种基于视觉游戏认知的多模态知识图谱（MH-MMKG）和自主知识检索的多代理检索器，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大语言模型在罕见领域任务中的表现不足，探索如何有效利用多模态知识提升其推理能力。

Method: 构建了基于游戏的多模态知识图谱（MH-MMKG），并设计了一系列复杂查询任务；提出了一种无需额外训练的多代理检索器，用于自主知识检索。

Result: 实验结果表明，该方法显著提升了多模态大语言模型在复杂知识检索和推理任务中的表现。

Conclusion: 研究为多模态知识增强推理提供了新视角，并为未来研究奠定了基础。

Abstract: The real value of knowledge lies not just in its accumulation, but in its
potential to be harnessed effectively to conquer the unknown. Although recent
multimodal large language models (MLLMs) exhibit impressing multimodal
capabilities, they often fail in rarely encountered domain-specific tasks due
to limited relevant knowledge. To explore this, we adopt visual game cognition
as a testbed and select Monster Hunter: World as the target to construct a
multimodal knowledge graph (MH-MMKG), which incorporates multi-modalities and
intricate entity relations. We also design a series of challenging queries
based on MH-MMKG to evaluate the models' ability for complex knowledge
retrieval and reasoning. Furthermore, we propose a multi-agent retriever that
enables a model to autonomously search relevant knowledge without additional
training. Experimental results show that our approach significantly enhances
the performance of MLLMs, providing a new perspective on multimodal
knowledge-augmented reasoning and laying a solid foundation for future
research.

</details>


### [10] [Measuring and Augmenting Large Language Models for Solving Capture-the-Flag Challenges](https://arxiv.org/abs/2506.17644)
*Zimo Ji,Daoyuan Wu,Wenyuan Jiang,Pingchuan Ma,Zongjie Li,Shuai Wang*

Main category: cs.AI

TL;DR: 本文提出了一种名为CTFKnow的基准测试，用于评估大型语言模型（LLMs）在解决CTF挑战中的技术知识能力，并开发了CTFAgent框架以提升其性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs的发展，其在自动化CTF挑战解决中的潜力受到关注，但现有研究缺乏对其技术知识能力的系统评估。

Method: 构建了包含3,992个问题的CTFKnow基准测试，并设计了CTFAgent框架，引入两阶段检索增强生成（RAG）和交互式环境增强模块。

Result: 实验表明，CTFAgent在两个流行的CTF数据集上性能提升超过80%，并在picoCTF2024竞赛中排名前23.6%。

Conclusion: CTFKnow基准测试和CTFAgent框架为提升LLMs在CTF问题解决中的能力提供了有效工具和方向。

Abstract: Capture-the-Flag (CTF) competitions are crucial for cybersecurity education
and training. As large language models (LLMs) evolve, there is increasing
interest in their ability to automate CTF challenge solving. For example, DARPA
has organized the AIxCC competition since 2023 to advance AI-powered automated
offense and defense. However, this demands a combination of multiple abilities,
from knowledge to reasoning and further to actions. In this paper, we highlight
the importance of technical knowledge in solving CTF problems and deliberately
construct a focused benchmark, CTFKnow, with 3,992 questions to measure LLMs'
performance in this core aspect. Our study offers a focused and innovative
measurement of LLMs' capability in understanding CTF knowledge and applying it
to solve CTF challenges. Our key findings reveal that while LLMs possess
substantial technical knowledge, they falter in accurately applying this
knowledge to specific scenarios and adapting their strategies based on feedback
from the CTF environment.
  Based on insights derived from this measurement study, we propose CTFAgent, a
novel LLM-driven framework for advancing CTF problem-solving. CTFAgent
introduces two new modules: two-stage Retrieval Augmented Generation (RAG) and
interactive Environmental Augmentation, which enhance LLMs' technical knowledge
and vulnerability exploitation on CTF, respectively. Our experimental results
show that, on two popular CTF datasets, CTFAgent both achieves over 80%
performance improvement. Moreover, in the recent picoCTF2024 hosted by CMU,
CTFAgent ranked in the top 23.6% of nearly 7,000 participating teams. This
reflects the benefit of our measurement study and the potential of our
framework in advancing LLMs' capabilities in CTF problem-solving.

</details>


### [11] [PhysUniBench: An Undergraduate-Level Physics Reasoning Benchmark for Multimodal Models](https://arxiv.org/abs/2506.17667)
*Lintao Wang,Encheng Su,Jiaqi Liu,Pengze Li,Peng Xia,Jiabei Xiao,Wenlong Zhang,Xinnan Dai,Xi Chen,Yuan Meng,Mingyu Ding,Lei Bai,Wanli Ouyang,Shixiang Tang,Aoran Wang,Xinzhu Ma*

Main category: cs.AI

TL;DR: PhysUniBench是一个多模态基准测试，用于评估和改进多模态大语言模型在本科物理问题上的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法在捕捉本科物理的广度和复杂性方面存在局限，需要更严格的评估工具。

Method: PhysUniBench包含3,304个物理问题，涵盖8个主要子领域，每个问题配有视觉图表，并通过多阶段过程构建。

Result: 当前最先进模型（如GPT-4o mini）在PhysUniBench上仅达到34.2%的准确率，显示其在高级物理推理和多模态理解上的不足。

Conclusion: PhysUniBench旨在推动AI在科学领域的发展，鼓励开发具有更强物理推理和问题解决能力的模型。

Abstract: Physics problem-solving is a challenging domain for large AI models,
requiring integration of conceptual understanding, mathematical reasoning, and
interpretation of physical diagrams. Current evaluation methodologies show
notable limitations in capturing the breadth and complexity of
undergraduate-level physics, underscoring the need for more rigorous
assessments. To this end, we present PhysUniBench, a large-scale multimodal
benchmark designed to evaluate and improve the reasoning capabilities of
multimodal large language models (MLLMs) specifically on undergraduate-level
physics problems. PhysUniBench consists of 3,304 physics questions spanning 8
major sub-disciplines of physics, each accompanied by one visual diagrams. The
benchmark includes both open-ended and multiple-choice questions,
systematically curated and difficulty-rated through an iterative
model-in-the-loop process. The benchmark's construction involved a rigorous
multi-stage process, including multiple roll-outs, expert-level evaluation,
automated filtering of easily solved problems, and a nuanced difficulty grading
system with five levels. Through extensive experiments, we observe that current
state-of-the-art models encounter substantial challenges in physics reasoning.
For example, GPT-4o mini achieves only about 34.2\% accuracy in the proposed
PhysUniBench. These results highlight that current MLLMs struggle with advanced
physics reasoning, especially on multi-step problems and those requiring
precise diagram interpretation. By providing a broad and rigorous assessment
tool, PhysUniBench aims to drive progress in AI for Science, encouraging the
development of models with stronger physical reasoning, problem-solving skills,
and multimodal understanding. The benchmark and evaluation scripts are
available at https://prismax-team.github.io/PhysUniBenchmark/.

</details>


### [12] [Beyond Syntax: Action Semantics Learning for App Agents](https://arxiv.org/abs/2506.17697)
*Bohan Tang,Dezhao Luo,Jingxuan Chen,Shaogang Gong,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.AI

TL;DR: 论文提出了一种名为ASL的新学习框架，通过捕捉动作的语义而非语法形式，提升App代理的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的解决方案依赖昂贵的封闭LLM API，而微调开源LLM的方法因语法学习范式导致OOD脆弱性。ASL旨在解决这些问题。

Method: ASL通过定义动作语义为界面状态转换，并引入SEE计算语义奖励，训练代理生成语义对齐的动作。

Result: 理论分析和实验表明，ASL在OOD问题上优于现有语法学习范式，显著提高了App代理的性能。

Conclusion: ASL通过语义学习框架有效提升了App代理的鲁棒性和泛化能力。

Abstract: The advent of Large Language Models (LLMs) enables the rise of App agents
that interpret user intent and operate smartphone Apps through actions such as
clicking and scrolling. While prompt-based solutions with closed LLM APIs show
promising ability, they incur heavy compute costs and external API dependency.
Fine-tuning smaller open-source LLMs solves these limitations. However, current
fine-tuning methods use a syntax learning paradigm that forces agents to
reproduce exactly the ground truth action strings, leading to
out-of-distribution (OOD) vulnerability. To fill this gap, we propose Action
Semantics Learning (ASL), a novel learning framework, where the learning
objective is capturing the semantics of the ground truth actions. Specifically,
inspired by the programming language theory, we define the action semantics for
App agents as the state transition induced by the action in the user interface.
With this insight, ASL employs a novel SEmantic Estimator (SEE) to compute a
semantic reward to train the App agents in generating actions aligned with the
semantics of ground truth actions, even when the syntactic forms differ. To
support the effectiveness of ASL, we theoretically demonstrate the superior
robustness of ASL for the OOD problem compared with the existing syntax
learning paradigm. Extensive experiments on offline and online smartphone App
operation benchmarks show that ASL significantly improves the accuracy and
generalisation of App agents over existing methods.

</details>


### [13] [AnyMAC: Cascading Flexible Multi-Agent Collaboration via Next-Agent Prediction](https://arxiv.org/abs/2506.17784)
*Song Wang,Zhen Tan,Zihan Chen,Shuang Zhou,Tianlong Chen,Jundong Li*

Main category: cs.AI

TL;DR: 提出了一种基于序列结构的多智能体协作框架，取代传统的静态或图结构，通过动态选择下一智能体和上下文，实现更灵活的通信和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态或图结构的通信拓扑，缺乏适应性和灵活性，限制了多智能体协作的潜力。

Method: 提出新框架，采用序列结构，包含两个关键方向：下一智能体预测（Next-Agent Prediction）和下一上下文选择（Next-Context Selection），构建任务自适应的通信管道。

Result: 在多个基准测试中表现优异，显著降低通信开销。

Conclusion: 序列结构的多智能体协作框架在灵活性和性能上优于传统方法，为未来研究提供了新方向。

Abstract: Recent progress in large language model (LLM)-based multi-agent collaboration
highlights the power of structured communication in enabling collective
intelligence. However, existing methods largely rely on static or graph-based
inter-agent topologies, lacking the potential adaptability and flexibility in
communication. In this work, we propose a new framework that rethinks
multi-agent coordination through a sequential structure rather than a graph
structure, offering a significantly larger topology space for multi-agent
communication. Our method focuses on two key directions: (1) Next-Agent
Prediction, which selects the most suitable agent role at each step, and (2)
Next-Context Selection (NCS), which enables each agent to selectively access
relevant information from any previous step. Together, these components
construct task-adaptive communication pipelines that support both role
flexibility and global information flow. Extensive evaluations across multiple
benchmarks demonstrate that our approach achieves superior performance while
substantially reducing communication overhead.

</details>


### [14] [Leveraging Large Language Model for Intelligent Log Processing and Autonomous Debugging in Cloud AI Platforms](https://arxiv.org/abs/2506.17900)
*Cheng Ji,Huaiying Luo*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型（LLM）的智能日志处理和自动调试框架LLM-ID，通过多阶段语义推理机制实现日志上下文理解和故障链自动重构，显著提升了故障定位精度。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统规模和复杂度的增加，日志数据庞大、非结构化且语义模糊，给故障定位和系统自修复带来挑战。

Method: 扩展预训练Transformer模型，结合多阶段语义推理机制，动态结构化日志，使用无监督聚类和嵌入提取事件模板和语义模式，通过微调LLM和多轮注意力机制进行上下文推理生成故障假设和根因路径，并引入基于强化学习的策略引导恢复规划器。

Result: 实验表明，LLM-ID在云平台日志数据集上的故障定位精度提高了16.2%，显著优于主流方法。

Conclusion: LLM-ID具有更强的语义理解能力、持续学习能力和异构环境适应性，为复杂AI系统的故障定位和自修复提供了有效解决方案。

Abstract: With the increasing complexity and rapid expansion of the scale of AI systems
in cloud platforms, the log data generated during system operation is massive,
unstructured, and semantically ambiguous, which brings great challenges to
fault location and system self-repair. In order to solve this problem, this
paper proposes an intelligent log processing and automatic debugging framework
based on Large Language Model (LLM), named Intelligent Debugger (LLM-ID). This
method is extended on the basis of the existing pre-trained Transformer model,
and integrates a multi-stage semantic inference mechanism to realize the
context understanding of system logs and the automatic reconstruction of fault
chains. Firstly, the system log is dynamically structured, and the unsupervised
clustering and embedding mechanism is used to extract the event template and
semantic schema. Subsequently, the fine-tuned LLM combined with the multi-round
attention mechanism to perform contextual reasoning on the log sequence to
generate potential fault assumptions and root cause paths. Furthermore, this
paper introduces a reinforcement learning-based policy-guided recovery planner,
which is driven by the remediation strategy generated by LLM to support dynamic
decision-making and adaptive debugging in the cloud environment. Compared with
the existing rule engine or traditional log analysis system, the proposed model
has stronger semantic understanding ability, continuous learning ability and
heterogeneous environment adaptability. Experiments on the cloud platform log
dataset show that LLM-ID improves the fault location accuracy by 16.2%, which
is significantly better than the current mainstream methods

</details>


### [15] [Bayesian Social Deduction with Graph-Informed Language Models](https://arxiv.org/abs/2506.17788)
*Shahab Rahimirad,Guven Gergerli,Lucia Romero,Angela Qian,Matthew Lyle Olson,Simon Stepputtis,Joseph Campbell*

Main category: cs.AI

TL;DR: 论文提出了一种混合推理框架，结合结构化概率模型和LLM，提升了语言模型在社交推理任务中的表现，并在Avalon游戏中击败了人类玩家。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在社交推理任务中表现有限，尤其是在实时推理和小型化模型上性能下降明显。

Method: 采用混合推理框架，外部化信念推理至结构化概率模型，同时利用LLM处理语言理解和交互。

Result: 该方法在Agent-Agent对抗中表现优异，首次在控制实验中击败人类玩家（67%胜率），并获得更高评价。

Conclusion: 混合推理框架有效提升了语言模型的社交推理能力，为未来研究提供了代码、模型和数据集支持。

Abstract: Social reasoning - inferring unobservable beliefs and intentions from partial
observations of other agents - remains a challenging task for large language
models (LLMs). We evaluate the limits of current reasoning language models in
the social deduction game Avalon and find that while the largest models
demonstrate strong performance, they require extensive test-time inference and
degrade sharply when distilled to smaller, real-time-capable variants. To
address this, we introduce a hybrid reasoning framework that externalizes
belief inference to a structured probabilistic model, while using an LLM for
language understanding and interaction. Our approach achieves competitive
performance with much larger models in Agent-Agent play and, notably, is the
first language agent to defeat human players in a controlled study - achieving
a 67% win rate and receiving higher qualitative ratings than both reasoning
baselines and human teammates. We release code, models, and a dataset to
support future work on social reasoning in LLM agents, which can be found at
https://camp-lab-purdue.github.io/bayesian-social-deduction/

</details>


### [16] [Efficient Strategy Synthesis for MDPs via Hierarchical Block Decomposition](https://arxiv.org/abs/2506.17792)
*Alexandros Evangelidis,Gricel Vázquez,Simos Gerasimou*

Main category: cs.AI

TL;DR: 提出了一种动态细化MDP的方法，加速大规模MDP的策略合成，显著优于现有工具PRISM。


<details>
  <summary>Details</summary>
Motivation: 传统策略合成方法难以应对大规模状态空间，需高效解决方案。

Method: 动态细化MDP，迭代选择脆弱区域进行优化，平衡精度与效率。

Result: 在1M状态的MDP中，性能提升高达2倍。

Conclusion: 该方法为大规模MDP策略合成提供了高效且实用的解决方案。

Abstract: Software-intensive systems, such as software product lines and robotics,
utilise Markov decision processes (MDPs) to capture uncertainty and analyse
sequential decision-making problems. Despite the usefulness of conventional
policy synthesis methods, they fail to scale to large state spaces. Our
approach addresses this issue and accelerates policy synthesis in large MDPs by
dynamically refining the MDP and iteratively selecting the most fragile MDP
regions for refinement. This iterative procedure offers a balance between
accuracy and efficiency, as refinement occurs only when necessary. Through a
comprehensive empirical evaluation comprising diverse case studies and MDPs up
to 1M states, we demonstrate significant performance improvements yielded by
our approach compared to the leading probabilistic model checker PRISM (up to
2x), thus offering a very competitive solution for real-world policy synthesis
tasks in larger MDPs.

</details>


### [17] [Reflective Verbal Reward Design for Pluralistic Alignment](https://arxiv.org/abs/2506.17834)
*Carter Blair,Kate Larson,Edith Law*

Main category: cs.AI

TL;DR: 提出了一种个性化奖励模型方法，通过对话引导用户表达偏好，解决了传统RLHF中少数群体偏好被压制的问题。


<details>
  <summary>Details</summary>
Motivation: 人类价值观具有多样性，传统RLHF通过单一奖励模型聚合反馈可能压制少数群体偏好。

Method: 使用语言模型引导用户通过反思对话构建个性化偏好，并基于对话历史生成个性化奖励模型。

Result: 在30名参与者的实验中，该方法比非反思性模型准确率提高9-12%，且样本效率更高。

Conclusion: 个性化奖励模型能更准确地反映用户偏好，优于传统方法。

Abstract: AI agents are commonly aligned with "human values" through reinforcement
learning from human feedback (RLHF), where a single reward model is learned
from aggregated human feedback and used to align an agent's behavior. However,
human values are not homogeneous--different people hold distinct and sometimes
conflicting values. Aggregating feedback into a single reward model risks
disproportionately suppressing minority preferences. To address this, we
present a novel reward modeling approach for learning individualized reward
models. Our approach uses a language model to guide users through reflective
dialogues where they critique agent behavior and construct their preferences.
This personalized dialogue history, containing the user's reflections and
critiqued examples, is then used as context for another language model that
serves as an individualized reward function (what we call a "verbal reward
model") for evaluating new trajectories. In studies with 30 participants, our
method achieved a 9-12% improvement in accuracy over non-reflective verbal
reward models while being more sample efficient than traditional supervised
learning methods.

</details>


### [18] [Out of Control -- Why Alignment Needs Formal Control Theory (and an Alignment Control Stack)](https://arxiv.org/abs/2506.17846)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文主张将形式最优控制理论作为AI对齐研究的核心，提出了一种不同于主流AI安全和安全方法的新视角。通过引入分层对齐控制栈，探讨了各层的测量与控制特性及其互操作性，旨在为前沿模型和智能AI系统提供更全面的对齐框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全和机制可解释性研究中的形式方法缺乏通用性，且对齐/控制协议的互操作性研究不足。本文希望通过形式最优控制理论，构建一个分层对齐框架，以更好地理解和控制AI系统。

Method: 提出Alignment Control Stack，分层定义对齐栈，分析各层的测量与控制特性及其互操作性，结合最优控制理论和实际部署需求。

Result: 通过分层对齐控制栈，为前沿模型和智能AI系统提供了更全面的对齐框架，增强了安全性和可靠性。

Conclusion: 将形式最优控制理论应用于AI对齐研究，可以弥补现有方法的不足，为政府和监管机构提供更可靠的保障，推动AI技术的可持续发展。

Abstract: This position paper argues that formal optimal control theory should be
central to AI alignment research, offering a distinct perspective from
prevailing AI safety and security approaches. While recent work in AI safety
and mechanistic interpretability has advanced formal methods for alignment,
they often fall short of the generalisation required of control frameworks for
other technologies. There is also a lack of research into how to render
different alignment/control protocols interoperable. We argue that by recasting
alignment through principles of formal optimal control and framing alignment in
terms of hierarchical stack from physical to socio-technical layers according
to which controls may be applied we can develop a better understanding of the
potential and limitations for controlling frontier models and agentic AI
systems. To this end, we introduce an Alignment Control Stack which sets out a
hierarchical layered alignment stack, identifying measurement and control
characteristics at each layer and how different layers are formally
interoperable. We argue that such analysis is also key to the assurances that
will be needed by governments and regulators in order to see AI technologies
sustainably benefit the community. Our position is that doing so will bridge
the well-established and empirically validated methods of optimal control with
practical deployment considerations to create a more comprehensive alignment
framework, enhancing how we approach safety and reliability for advanced AI
systems.

</details>


### [19] [Towards Robust Fact-Checking: A Multi-Agent System with Advanced Evidence Retrieval](https://arxiv.org/abs/2506.17878)
*Tam Trinh,Manh Nguyen,Truong-Son Hy*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体系统的自动化事实核查方法，通过四个专门化智能体提高准确性、效率和可解释性，并在基准数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 数字时代中错误信息的快速传播对公共讨论构成挑战，传统人工核查方法难以应对在线内容的规模和速度，而现有自动化方法在处理复杂声明、确保来源可信度和透明度方面存在局限。

Method: 提出了一种多智能体系统，包括输入摄取智能体、查询生成智能体、证据检索智能体和裁决预测智能体，分别负责声明分解、子查询生成、可信证据检索和可解释的裁决预测。

Result: 在FEVEROUS、HOVER和SciFact数据集上，系统实现了比基线方法高12.3%的Macro F1分数，能够有效分解复杂声明、检索可靠证据并生成透明解释。

Conclusion: 该方法为自动化事实核查领域提供了更准确、高效且透明的验证方法，同时保持了实际应用的扩展性。

Abstract: The rapid spread of misinformation in the digital era poses significant
challenges to public discourse, necessitating robust and scalable fact-checking
solutions. Traditional human-led fact-checking methods, while credible,
struggle with the volume and velocity of online content, prompting the
integration of automated systems powered by Large Language Models (LLMs).
However, existing automated approaches often face limitations, such as handling
complex claims, ensuring source credibility, and maintaining transparency. This
paper proposes a novel multi-agent system for automated fact-checking that
enhances accuracy, efficiency, and explainability. The system comprises four
specialized agents: an Input Ingestion Agent for claim decomposition, a Query
Generation Agent for formulating targeted subqueries, an Evidence Retrieval
Agent for sourcing credible evidence, and a Verdict Prediction Agent for
synthesizing veracity judgments with human-interpretable explanations.
Evaluated on benchmark datasets (FEVEROUS, HOVER, SciFact), the proposed system
achieves a 12.3% improvement in Macro F1-score over baseline methods. The
system effectively decomposes complex claims, retrieves reliable evidence from
trusted sources, and generates transparent explanations for verification
decisions. Our approach contributes to the growing field of automated
fact-checking by providing a more accurate, efficient, and transparent
verification methodology that aligns with human fact-checking practices while
maintaining scalability for real-world applications. Our source code is
available at https://github.com/HySonLab/FactAgent

</details>


### [20] [Learning, Reasoning, Refinement: A Framework for Kahneman's Dual-System Intelligence in GUI Agents](https://arxiv.org/abs/2506.17913)
*Jinjie Wei,Jiyao Liu,Lihao Liu,Ming Hu,Junzhi Ning,Mingcheng Li,Weijie Yin,Junjun He,Xiao Liang,Chao Feng,Dingkang Yang*

Main category: cs.AI

TL;DR: CogniGUI是一个基于认知框架的GUI代理，通过双系统设计（快速视觉语义分析和相对奖励策略优化）实现自适应学习，并在新基准ScreenSeek上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理系统依赖试错决策，缺乏渐进式学习和复杂交互评估，无法适应真实场景。

Method: 结合双系统设计：1) 快速视觉语义分析的解析引擎；2) 基于相对奖励的策略优化代理。

Result: CogniGUI在现有和新基准测试中均优于现有方法。

Conclusion: CogniGUI通过认知框架和双系统设计解决了现有GUI代理的局限性，并展示了优越性能。

Abstract: Graphical User Interface (GUI) agents have made significant progress in
automating digital tasks through the utilization of computer vision and
language models. Nevertheless, existing agent systems encounter notable
limitations. Firstly, they predominantly depend on trial and error decision
making rather than progressive reasoning, thereby lacking the capability to
learn and adapt from interactive encounters. Secondly, these systems are
assessed using overly simplistic single step accuracy metrics, which do not
adequately reflect the intricate nature of real world GUI interactions. In this
paper, we present CogniGUI, a cognitive framework developed to overcome these
limitations by enabling adaptive learning for GUI automation resembling
human-like behavior. Inspired by Kahneman's Dual Process Theory, our approach
combines two main components: (1) an omni parser engine that conducts immediate
hierarchical parsing of GUI elements through quick visual semantic analysis to
identify actionable components, and (2) a Group based Relative Policy
Optimization (GRPO) grounding agent that assesses multiple interaction paths
using a unique relative reward system, promoting minimal and efficient
operational routes. This dual-system design facilitates iterative ''exploration
learning mastery'' cycles, enabling the agent to enhance its strategies over
time based on accumulated experience. Moreover, to assess the generalization
and adaptability of agent systems, we introduce ScreenSeek, a comprehensive
benchmark that includes multi application navigation, dynamic state
transitions, and cross interface coherence, which are often overlooked
challenges in current benchmarks. Experimental results demonstrate that
CogniGUI surpasses state-of-the-art methods in both the current GUI grounding
benchmarks and our newly proposed benchmark.

</details>


### [21] [Evolving Prompts In-Context: An Open-ended, Self-replicating Perspective](https://arxiv.org/abs/2506.17930)
*Jianyu Wang,Zhiqiang Hu,Lidong Bing*

Main category: cs.AI

TL;DR: 提出了一种新的提示设计范式，通过修剪随机演示为看似无意义的“乱码”来提升大语言模型（LLM）的性能，优于传统自动提示优化技术。


<details>
  <summary>Details</summary>
Motivation: 挑战传统提示设计的智慧，探索更高效的提示优化方法。

Method: 提出PromptQuine框架，通过进化搜索自动寻找修剪策略，仅需少量数据。

Result: 在分类、多选问答、生成和数学推理任务中表现优异，且运行效率高。

Conclusion: 为上下文学习的机制研究提供新方向，呼吁开发更开放的搜索算法以优化LLM提示。

Abstract: We propose a novel prompt design paradigm that challenges conventional wisdom
in large language model (LLM) prompting. While conventional wisdom prioritizes
well-crafted instructions and demonstrations for in-context learning (ICL), we
show that pruning random demonstrations into seemingly incoherent "gibberish"
can remarkably improve performance across diverse tasks. Notably, the
"gibberish" always matches or surpasses state-of-the-art automatic prompt
optimization techniques, achieving substantial gains regardless of LLM
alignment. Nevertheless, discovering an effective pruning strategy is
non-trivial, as existing attribution methods and prompt compression algorithms
fail to deliver robust results, let alone human intuition. In terms of this, we
propose a self-discover prompt optimization framework, PromptQuine, an
evolutionary search framework that automatically searches for the pruning
strategy by itself using only low-data regimes. Much like the emergent
complexity in nature--such as symbiosis and self-organization--arising in
response to resource constraints, our framework evolves and refines
unconventional yet highly effective prompts by leveraging only the tokens
present within the context. We demonstrate its effectiveness across
classification, multi-choice question answering, generation and math reasoning
tasks across LLMs, while achieving decent runtime efficiency. We hope our
findings can guide mechanistic studies on in-context learning, and provide a
call to action, to pave the way for more open-ended search algorithms for more
effective LLM prompting.

</details>


### [22] [medicX-KG: A Knowledge Graph for Pharmacists' Drug Information Needs](https://arxiv.org/abs/2506.17959)
*Lizzy Farrugia,Lilian M. Azzopardi,Jeremy Debattista,Charlie Abela*

Main category: cs.AI

TL;DR: medicX-KG是一个面向药剂师的知识图谱，整合多源数据，支持临床和监管决策，填补了统一国家药物库的空白。


<details>
  <summary>Details</summary>
Motivation: 药剂师角色从配药转向提供综合服务，需要准确、实时的药物信息支持。

Method: 利用AI和语义技术，整合BNF、DrugBank和MMA数据，构建知识图谱。

Result: medicX-KG有效支持药物可用性、相互作用等查询，但存在剂量编码和实时更新不足的局限。

Conclusion: medicX-KG为药剂师提供了实用工具，未来需改进数据完整性和实时性。

Abstract: The role of pharmacists is evolving from medicine dispensing to delivering
comprehensive pharmaceutical services within multidisciplinary healthcare
teams. Central to this shift is access to accurate, up-to-date medicinal
product information supported by robust data integration. Leveraging artificial
intelligence and semantic technologies, Knowledge Graphs (KGs) uncover hidden
relationships and enable data-driven decision-making. This paper presents
medicX-KG, a pharmacist-oriented knowledge graph supporting clinical and
regulatory decisions. It forms the semantic layer of the broader medicX
platform, powering predictive and explainable pharmacy services. medicX-KG
integrates data from three sources, including, the British National Formulary
(BNF), DrugBank, and the Malta Medicines Authority (MMA) that addresses Malta's
regulatory landscape and combines European Medicines Agency alignment with
partial UK supply dependence. The KG tackles the absence of a unified national
drug repository, reducing pharmacists' reliance on fragmented sources. Its
design was informed by interviews with practicing pharmacists to ensure
real-world applicability. We detail the KG's construction, including data
extraction, ontology design, and semantic mapping. Evaluation demonstrates that
medicX-KG effectively supports queries about drug availability, interactions,
adverse reactions, and therapeutic classes. Limitations, including missing
detailed dosage encoding and real-time updates, are discussed alongside
directions for future enhancements.

</details>


### [23] [Graphs Meet AI Agents: Taxonomy, Progress, and Future Opportunities](https://arxiv.org/abs/2506.18019)
*Yuanchen Bei,Weizhi Zhang,Siwen Wang,Weizhi Chen,Sheng Zhou,Hao Chen,Yong Li,Jiajun Bu,Shirui Pan,Yizhou Yu,Irwin King,Fakhri Karray,Philip S. Yu*

Main category: cs.AI

TL;DR: 本文综述了图技术如何赋能AI代理，探讨了图技术与核心代理功能的结合、应用及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: AI代理从强化学习到大型语言模型的演进需要更强的规划、执行、记忆和协作能力，而图技术能通过结构化数据支持这些需求。

Method: 通过系统综述，探讨图技术与AI代理核心功能的结合，并分析其应用和未来研究方向。

Result: 图技术因其在组织和管理复杂数据关系上的优势，成为支持高级AI代理能力的强大工具。

Conclusion: 本文旨在激发下一代AI代理的发展，利用图技术应对日益复杂的挑战。

Abstract: AI agents have experienced a paradigm shift, from early dominance by
reinforcement learning (RL) to the rise of agents powered by large language
models (LLMs), and now further advancing towards a synergistic fusion of RL and
LLM capabilities. This progression has endowed AI agents with increasingly
strong abilities. Despite these advances, to accomplish complex real-world
tasks, agents are required to plan and execute effectively, maintain reliable
memory, and coordinate smoothly with other agents. Achieving these capabilities
involves contending with ever-present intricate information, operations, and
interactions. In light of this challenge, data structurization can play a
promising role by transforming intricate and disorganized data into
well-structured forms that agents can more effectively understand and process.
In this context, graphs, with their natural advantage in organizing, managing,
and harnessing intricate data relationships, present a powerful data paradigm
for structurization to support the capabilities demanded by advanced AI agents.
To this end, this survey presents a first systematic review of how graphs can
empower AI agents. Specifically, we explore the integration of graph techniques
with core agent functionalities, highlight notable applications, and identify
prospective avenues for future research. By comprehensively surveying this
burgeoning intersection, we hope to inspire the development of next-generation
AI agents equipped to tackle increasingly sophisticated challenges with graphs.
Related resources are collected and continuously updated for the community in
the Github link.

</details>


### [24] [Action Language BC+](https://arxiv.org/abs/2506.18044)
*Joseph Babb,Joohyung Lee*

Main category: cs.AI

TL;DR: 提出了一种新的动作语言BC+，填补了动作语言与现代ASP语言之间的差距，基于通用的稳定模型语义，支持现代ASP语言特性。


<details>
  <summary>Details</summary>
Motivation: 现有动作语言与现代ASP语言相比功能有限，无法充分利用现代ASP的知识表示能力。

Method: 通过将BC+的语义定义为命题公式的通用稳定模型语义，支持现代ASP语言特性。

Result: BC+能够涵盖其他动作语言（如B、C、C+、BC）的最佳特性，并可通过ASP求解器计算。

Conclusion: BC+填补了动作语言与现代ASP语言的差距，扩展了cplus2asp系统实现了该语言。

Abstract: Action languages are formal models of parts of natural language that are
designed to describe effects of actions. Many of these languages can be viewed
as high level notations of answer set programs structured to represent
transition systems. However, the form of answer set programs considered in the
earlier work is quite limited in comparison with the modern Answer Set
Programming (ASP) language, which allows several useful constructs for
knowledge representation, such as choice rules, aggregates, and abstract
constraint atoms. We propose a new action language called BC+, which closes the
gap between action languages and the modern ASP language. The main idea is to
define the semantics of BC+ in terms of general stable model semantics for
propositional formulas, under which many modern ASP language constructs can be
identified with shorthands for propositional formulas. Language BC+ turns out
to be sufficiently expressive to encompass the best features of other action
languages, such as languages B, C, C+, and BC. Computational methods available
in ASP solvers are readily applicable to compute BC+, which led to an
implementation of the language by extending system cplus2asp.

</details>


### [25] [Weighted Assumption Based Argumentation to reason about ethical principles and actions](https://arxiv.org/abs/2506.18056)
*Paolo Baldi,Fabio Aurelio D'Asaro,Abeer Dyoub,Francesca Alessandra Lisi*

Main category: cs.AI

TL;DR: 论文为基于假设的论证（ABA）引入了加权论证，通过为论证分配权重并推导攻击权重，展示了在伦理推理中的应用，并基于答案集编程实现了该方法。


<details>
  <summary>Details</summary>
Motivation: 增强ABA框架的表达能力，使其能够处理带有权重的论证，从而更适用于复杂领域（如伦理推理）。

Method: 为ABA中的论证分配权重，并推导攻击权重；通过答案集编程实现该方法。

Result: 展示了加权ABA在伦理推理中的实际应用，并提供了基于答案集编程的实现。

Conclusion: 加权ABA扩展了传统ABA的表达能力，适用于需要权重支持的复杂推理场景。

Abstract: We augment Assumption Based Argumentation (ABA for short) with weighted
argumentation. In a nutshell, we assign weights to arguments and then derive
the weight of attacks between ABA arguments. We illustrate our proposal through
running examples in the field of ethical reasoning, and present an
implementation based on Answer Set Programming.

</details>


### [26] [Deep Research Agents: A Systematic Examination And Roadmap](https://arxiv.org/abs/2506.18096)
*Yuxuan Huang,Yihang Chen,Haozheng Zhang,Kang Li,Meng Fang,Linyi Yang,Xiaoguang Li,Lifeng Shang,Songcen Xu,Jianye Hao,Kun Shao,Jun Wang*

Main category: cs.AI

TL;DR: 论文分析了构成深度研究（DR）代理的基础技术和架构组件，包括信息获取策略、工具使用框架、工作流分类和代理架构，并评估了当前基准的局限性，提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，深度研究代理成为解决复杂多轮信息研究任务的新兴AI系统，需要系统化分析其技术和架构。

Method: 论文通过对比API和浏览器检索方法、模块化工具框架（如代码执行和多模态输入处理）、提出静态与动态工作流分类，以及单代理和多代理架构分类。

Result: 提出了DR代理的详细分类和架构分析，指出了当前基准在外部知识访问、执行效率和评估指标与实际目标不一致等局限性。

Conclusion: 论文总结了DR代理的研究现状，提出了未来研究方向，并提供了持续更新的研究资源库。

Abstract: The rapid progress of Large Language Models (LLMs) has given rise to a new
category of autonomous AI systems, referred to as Deep Research (DR) agents.
These agents are designed to tackle complex, multi-turn informational research
tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon
planning, multi-hop information retrieval, iterative tool use, and the
generation of structured analytical reports. In this paper, we conduct a
detailed analysis of the foundational technologies and architectural components
that constitute Deep Research agents. We begin by reviewing information
acquisition strategies, contrasting API-based retrieval methods with
browser-based exploration. We then examine modular tool-use frameworks,
including code execution, multimodal input processing, and the integration of
Model Context Protocols (MCPs) to support extensibility and ecosystem
development. To systematize existing approaches, we propose a taxonomy that
differentiates between static and dynamic workflows, and we classify agent
architectures based on planning strategies and agent composition, including
single-agent and multi-agent configurations. We also provide a critical
evaluation of current benchmarks, highlighting key limitations such as
restricted access to external knowledge, sequential execution inefficiencies,
and misalignment between evaluation metrics and the practical objectives of DR
agents. Finally, we outline open challenges and promising directions for future
research. A curated and continuously updated repository of DR agent research is
available at: {https://github.com/ai-agents-2030/awesome-deep-research-agent}.

</details>


### [27] [Decentralized Consensus Inference-based Hierarchical Reinforcement Learning for Multi-Constrained UAV Pursuit-Evasion Game](https://arxiv.org/abs/2506.18126)
*Xiang Yuming,Li Sizhao,Li Rongpeng,Zhao Zhifeng,Zhang Honggang*

Main category: cs.AI

TL;DR: 论文提出了一种两层次框架CI-HRL，用于解决多约束追逃游戏中的协同规避与编队覆盖任务，通过高层次的共识推断和低层次的多智能体强化学习实现高效协作。


<details>
  <summary>Details</summary>
Motivation: 多约束追逃游戏中的协同规避与编队覆盖任务在通信受限条件下极具挑战性，需要解决高维复杂性问题。

Method: 采用两层次框架CI-HRL，高层次策略（ConsMAC）实现目标定位与共识推断，低层次策略（AT-M）处理避障、导航与编队。

Result: 实验验证CI-HRL在协同规避和任务完成能力上表现优异。

Conclusion: CI-HRL为复杂多智能体任务提供了高效解决方案。

Abstract: Multiple quadrotor unmanned aerial vehicle (UAV) systems have garnered
widespread research interest and fostered tremendous interesting applications,
especially in multi-constrained pursuit-evasion games (MC-PEG). The Cooperative
Evasion and Formation Coverage (CEFC) task, where the UAV swarm aims to
maximize formation coverage across multiple target zones while collaboratively
evading predators, belongs to one of the most challenging issues in MC-PEG,
especially under communication-limited constraints. This multifaceted problem,
which intertwines responses to obstacles, adversaries, target zones, and
formation dynamics, brings up significant high-dimensional complications in
locating a solution. In this paper, we propose a novel two-level framework
(i.e., Consensus Inference-based Hierarchical Reinforcement Learning (CI-HRL)),
which delegates target localization to a high-level policy, while adopting a
low-level policy to manage obstacle avoidance, navigation, and formation.
Specifically, in the high-level policy, we develop a novel multi-agent
reinforcement learning module, Consensus-oriented Multi-Agent Communication
(ConsMAC), to enable agents to perceive global information and establish
consensus from local states by effectively aggregating neighbor messages.
Meanwhile, we leverage an Alternative Training-based Multi-agent proximal
policy optimization (AT-M) and policy distillation to accomplish the low-level
control. The experimental results, including the high-fidelity
software-in-the-loop (SITL) simulations, validate that CI-HRL provides a
superior solution with enhanced swarm's collaborative evasion and task
completion capabilities.

</details>


### [28] [SE-Merging: A Self-Enhanced Approach for Dynamic Model Merging](https://arxiv.org/abs/2506.18135)
*Zijun Chen,Zhanpeng Zhou,Bo Zhang,Weinan Zhang,Xi Sun,Junchi Yan*

Main category: cs.AI

TL;DR: 论文探讨了模型合并的机制，提出了一种自增强框架SE-Merging，通过动态识别任务和调整合并系数提升多任务能力。


<details>
  <summary>Details</summary>
Motivation: 尽管模型合并在多任务能力上表现出色，但其机制尚不明确，研究旨在揭示其背后的工作原理。

Method: 从表示角度分析模型合并，发现其通过区分任务样本和适应专家模型实现多任务能力，并提出了SE-Merging框架。

Result: SE-Merging显著提升了性能，且无需额外训练，与现有技术兼容。

Conclusion: 模型合并的多任务能力依赖于任务区分和专家适应，SE-Merging进一步优化了这一过程。

Abstract: Model merging has gained increasing attention due to its intriguing property:
interpolating the parameters of different task-specific fine-tuned models leads
to multi-task abilities. However, despite its empirical success, the underlying
mechanisms of model merging remain poorly understood. In this work, we delve
into the mechanism behind model merging from a representation perspective. Our
analysis reveals that model merging achieves multi-task abilities through two
key capabilities: i) distinguishing samples from different tasks, and ii)
adapting to the corresponding expert model for each sample. These two
capabilities allow the merged model to retain task-specific expertise, enabling
efficient multi-task adaptation. Building on these insights, we propose
\texttt{SE-Merging}, a self-enhanced model merging framework that leverages
these two characteristics to dynamically identify the corresponding task for
each sample and then adaptively rescales the merging coefficients to further
enhance task-specific expertise in the merged model. Notably,
\texttt{SE-Merging} achieves dynamic model merging without additional training.
Extensive experiments demonstrate that \texttt{SE-Merging} achieves significant
performance improvements while remaining compatible with existing model merging
techniques.

</details>


### [29] [CoachGPT: A Scaffolding-based Academic Writing Assistant](https://arxiv.org/abs/2506.18149)
*Fumian Chen,Sotheara Veng,Joshua Wilson,Xiaoming Li,Hui Fang*

Main category: cs.AI

TL;DR: CoachGPT是一种基于大型语言模型（LLM）的写作助手，通过实时反馈和个性化指导提升学术写作体验。


<details>
  <summary>Details</summary>
Motivation: 传统写作助手缺乏上下文理解，而LLM生成的论文无法教学。CoachGPT旨在为资源有限或偏好自主学习的学生提供支持。

Method: CoachGPT是一个基于AI代理的Web应用，将教育者指令转化为子任务，并提供实时反馈。

Result: 用户研究证明CoachGPT的有效性，展示了LLM在学术写作中的潜力。

Conclusion: CoachGPT通过独特的脚手架结构，为学术写作提供了更沉浸式的体验和个性化指导。

Abstract: Academic writing skills are crucial for students' success, but can feel
overwhelming without proper guidance and practice, particularly when writing in
a second language. Traditionally, students ask instructors or search
dictionaries, which are not universally accessible. Early writing assistants
emerged as rule-based systems that focused on detecting misspellings,
subject-verb disagreements, and basic punctuation errors; however, they are
inaccurate and lack contextual understanding. Machine learning-based assistants
demonstrate a strong ability for language understanding but are expensive to
train. Large language models (LLMs) have shown remarkable capabilities in
generating responses in natural languages based on given prompts. Still, they
have a fundamental limitation in education: they generate essays without
teaching, which can have detrimental effects on learning when misused. To
address this limitation, we develop CoachGPT, which leverages large language
models (LLMs) to assist individuals with limited educational resources and
those who prefer self-paced learning in academic writing. CoachGPT is an AI
agent-based web application that (1) takes instructions from experienced
educators, (2) converts instructions into sub-tasks, and (3) provides real-time
feedback and suggestions using large language models. This unique scaffolding
structure makes CoachGPT unique among existing writing assistants. Compared to
existing writing assistants, CoachGPT provides a more immersive writing
experience with personalized feedback and guidance. Our user studies prove the
usefulness of CoachGPT and the potential of large language models for academic
writing.

</details>


### [30] [AI Through the Human Lens: Investigating Cognitive Theories in Machine Psychology](https://arxiv.org/abs/2506.18156)
*Akash Kundu,Rishika Goswami*

Main category: cs.AI

TL;DR: 研究探讨大型语言模型（LLMs）是否表现出类似人类的认知模式，基于心理学四大框架，发现其行为与人类认知倾向相似但受训练数据影响。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否具备人类认知特征，以评估其透明度和伦理部署。

Method: 通过结构化提示和自动评分评估多个专有和开源模型。

Result: 模型能生成连贯叙述，易受正面框架影响，道德判断偏向自由/压迫问题，并表现出自我矛盾但合理化行为。

Conclusion: 研究为AI透明度和伦理部署提供启示，并建议未来结合认知心理学与AI安全研究。

Abstract: We investigate whether Large Language Models (LLMs) exhibit human-like
cognitive patterns under four established frameworks from psychology: Thematic
Apperception Test (TAT), Framing Bias, Moral Foundations Theory (MFT), and
Cognitive Dissonance. We evaluated several proprietary and open-source models
using structured prompts and automated scoring. Our findings reveal that these
models often produce coherent narratives, show susceptibility to positive
framing, exhibit moral judgments aligned with Liberty/Oppression concerns, and
demonstrate self-contradictions tempered by extensive rationalization. Such
behaviors mirror human cognitive tendencies yet are shaped by their training
data and alignment methods. We discuss the implications for AI transparency,
ethical deployment, and future work that bridges cognitive psychology and AI
safety

</details>


### [31] [Chain-of-Memory: Enhancing GUI Agents for Cross-Application Navigation](https://arxiv.org/abs/2506.18158)
*Xinzge Gao,Chuanrui Hu,Bin Chen,Teng Li*

Main category: cs.AI

TL;DR: 提出了一种名为Chain-of-Memory (CoM)的新方法，用于显式建模GUI代理的短期和长期记忆，显著提升了跨应用任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖历史截图或动作隐式表示任务状态，难以准确理解复杂任务状态，缺乏有效存储关键信息的机制。

Method: CoM通过捕获动作描述、整合任务相关屏幕信息，并维护专用内存模块来存储和管理信息。

Result: 实验表明，CoM显著提升了GUI代理在跨应用任务中的性能，7B模型可实现与72B模型相当的内存管理能力。

Conclusion: CoM为GUI代理提供了显式记忆表示，解决了任务状态理解和关键信息存储的挑战，数据集和代码将开源。

Abstract: Multimodal large language models (MLLMs) are attracting growing attention in
the development of Graphical User Interface (GUI) agents. Existing approaches
often rely on historical screenshots or actions to implicitly represent the
task state. This reliance poses challenges for GUI agents in accurately
understanding task states and underscores the absence of effective mechanisms
to store critical information in complex and lengthy cross-app tasks. To
address these challenges, we propose Chain-of-Memory (CoM), a novel approach
for explicitly modeling short-term and long-term memory in GUI agents. CoM
achieves this by capturing action descriptions, integrating task-relevant
screen information, and maintaining a dedicated memory module to store and
manage this information. By leveraging explicit memory representations, CoM
enables GUI agents to better understand task states and retain critical
historical information persistently. To equip GUI agents with memory management
capabilities and evaluate the effectiveness of CoM, we developed the GUI
Odyssey-CoM, a dataset comprising 111k screen-action pairs annotated with
Chain-of-Memory. Experimental results demonstrate that CoM significantly
improves GUI agents' performance in cross-application tasks. Additionally, GUI
Odyssey-CoM enables 7B models to achieve memory management capabilities
comparable to 72B models. The dataset and code will be open-sourced.

</details>


### [32] [Reasoning about Uncertainty: Do Reasoning Models Know When They Don't Know?](https://arxiv.org/abs/2506.18183)
*Zhiting Mei,Christina Zhang,Tenny Yin,Justin Lidard,Ola Shorinwa,Anirudha Majumdar*

Main category: cs.AI

TL;DR: 论文探讨了推理语言模型的不确定性量化问题，发现模型通常过度自信，且深度推理可能加剧这一问题，但通过自省可以部分改善校准。


<details>
  <summary>Details</summary>
Motivation: 推理模型在生成答案时容易产生自信但错误的响应（幻觉），了解何时信任这些模型对安全部署至关重要。

Method: 提出自省不确定性量化（UQ），评估模型校准情况，并测试深度推理和自省对校准的影响。

Result: 推理模型通常过度自信（尤其是错误答案），深度推理加剧这一问题，自省可部分改善校准（但效果因模型而异）。

Conclusion: 需进一步研究设计UQ基准和改进推理模型的校准方法。

Abstract: Reasoning language models have set state-of-the-art (SOTA) records on many
challenging benchmarks, enabled by multi-step reasoning induced using
reinforcement learning. However, like previous language models, reasoning
models are prone to generating confident, plausible responses that are
incorrect (hallucinations). Knowing when and how much to trust these models is
critical to the safe deployment of reasoning models in real-world applications.
To this end, we explore uncertainty quantification of reasoning models in this
work. Specifically, we ask three fundamental questions: First, are reasoning
models well-calibrated? Second, does deeper reasoning improve model
calibration? Finally, inspired by humans' innate ability to double-check their
thought processes to verify the validity of their answers and their confidence,
we ask: can reasoning models improve their calibration by explicitly reasoning
about their chain-of-thought traces? We introduce introspective uncertainty
quantification (UQ) to explore this direction. In extensive evaluations on SOTA
reasoning models across a broad range of benchmarks, we find that reasoning
models: (i) are typically overconfident, with self-verbalized confidence
estimates often greater than 85% particularly for incorrect responses, (ii)
become even more overconfident with deeper reasoning, and (iii) can become
better calibrated through introspection (e.g., o3-Mini and DeepSeek R1) but not
uniformly (e.g., Claude 3.7 Sonnet becomes more poorly calibrated). Lastly, we
conclude with important research directions to design necessary UQ benchmarks
and improve the calibration of reasoning models.

</details>


### [33] [The Impact of Medication Non-adherence on Adverse Outcomes: Evidence from Schizophrenia Patients via Survival Analysis](https://arxiv.org/abs/2506.18187)
*Shahriar Noroozizadeh,Pim Welle,Jeremy C. Weiss,George H. Chen*

Main category: cs.AI

TL;DR: 研究量化了精神分裂症患者不坚持服用抗精神病药物与不良后果的关联，使用生存分析和因果推断方法，发现不坚持用药会提前1至4个月引发不良事件。


<details>
  <summary>Details</summary>
Motivation: 探讨药物不依从性对精神分裂症患者不良后果的影响，为临床和政策提供依据。

Method: 采用生存分析框架，结合T-learner、S-learner和最近邻匹配等因果推断方法，利用不同时间窗口（3、6、9、12个月）的数据进行分析。

Result: 不坚持用药显著提前不良事件发生时间1至4个月，且不同药物类型和剂型的结果一致。

Conclusion: 研究强调了药物依从性对延缓精神危机的重要性，并展示了生存分析与因果推断结合的政策意义，但需注意因果解释的假设限制。

Abstract: This study quantifies the association between non-adherence to antipsychotic
medications and adverse outcomes in individuals with schizophrenia. We frame
the problem using survival analysis, focusing on the time to the earliest of
several adverse events (early death, involuntary hospitalization, jail
booking). We extend standard causal inference methods (T-learner, S-learner,
nearest neighbor matching) to utilize various survival models to estimate
individual and average treatment effects, where treatment corresponds to
medication non-adherence. Analyses are repeated using different amounts of
longitudinal information (3, 6, 9, and 12 months). Using data from Allegheny
County in western Pennsylvania, we find strong evidence that non-adherence
advances adverse outcomes by approximately 1 to 4 months. Ablation studies
confirm that county-provided risk scores adjust for key confounders, as their
removal amplifies the estimated effects. Subgroup analyses by medication
formulation (injectable vs. oral) and medication type consistently show that
non-adherence is associated with earlier adverse events. These findings
highlight the clinical importance of adherence in delaying psychiatric crises
and show that integrating survival analysis with causal inference tools can
yield policy-relevant insights. We caution that although we apply causal
inference, we only make associative claims and discuss assumptions needed for
causal interpretation.

</details>


### [34] [A Conceptual Framework for AI Capability Evaluations](https://arxiv.org/abs/2506.18213)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Luca Nicolás Forziati Gangi,Matheo Sandleris Musa,Lola Ramos Pereyra,Mario Leiva,Juan Gustavo Corvalan,María Vanina Martinez,Gerardo Simari*

Main category: cs.AI

TL;DR: 提出了一个概念框架，用于分析和标准化AI能力评估，以支持透明度、可比性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在社会中的深入应用，透明且全面的评估方法成为AI治理的关键工具，但目前缺乏明确的方法。

Method: 提出一个结构化的描述性框架，系统化分析现有评估方法和术语，不引入新分类或固定格式。

Result: 该框架提升了评估的透明度、可比性和可解释性，帮助识别方法缺陷、设计评估并为政策制定者提供工具。

Conclusion: 该框架为AI能力评估提供了实用工具，支持研究、实践和政策制定。

Abstract: As AI systems advance and integrate into society, well-designed and
transparent evaluations are becoming essential tools in AI governance,
informing decisions by providing evidence about system capabilities and risks.
Yet there remains a lack of clarity on how to perform these assessments both
comprehensively and reliably. To address this gap, we propose a conceptual
framework for analyzing AI capability evaluations, offering a structured,
descriptive approach that systematizes the analysis of widely used methods and
terminology without imposing new taxonomies or rigid formats. This framework
supports transparency, comparability, and interpretability across diverse
evaluations. It also enables researchers to identify methodological weaknesses,
assists practitioners in designing evaluations, and provides policymakers with
an accessible tool to scrutinize, compare, and navigate complex evaluation
landscapes.

</details>


### [35] [The 4th Dimension for Scaling Model Size](https://arxiv.org/abs/2506.18233)
*Ruike Zhu,Hanwen Zhang,Tianyu Shi,Chi Wang,Tianyi Zhou,Zengyi Qin*

Main category: cs.AI

TL;DR: 论文提出了一种新的模型扩展维度——虚拟逻辑深度（VLD），通过参数复用在不增加总参数量的情况下提升模型的有效算法深度。研究发现VLD扩展能保持知识容量几乎不变，显著提升推理能力，且参数数量与推理能力无关。


<details>
  <summary>Details</summary>
Motivation: 探索模型扩展的新维度（VLD），研究参数复用对模型性能的影响，尤其是在知识容量和推理能力方面的表现。

Method: 通过精心设计的对照实验，研究VLD扩展对模型知识容量和推理能力的影响。

Result: VLD扩展能保持知识容量几乎不变，显著提升推理能力；参数数量与知识容量相关，但与推理能力无关。

Conclusion: VLD扩展是一种有效的模型扩展方法，能在不增加参数量的情况下提升推理能力，为模型优化提供了新思路。

Abstract: Scaling the size of large language models typically involves three
dimensions: depth, width, and the number of parameters. In this work, we
explore a fourth dimension, virtual logical depth (VLD), which increases the
effective algorithmic depth without changing the overall parameter count by
reusing parameters within the model. Although parameter reuse is not a new
concept, its potential and characteristics in model scaling have not been
thoroughly studied. Through carefully designed controlled experiments, we make
the following key discoveries regarding VLD scaling:
  VLD scaling forces the knowledge capacity of the model to remain almost
constant, with only minor variations.
  VLD scaling enables a significant improvement in reasoning capability,
provided the scaling method is properly implemented.
  The number of parameters correlates with knowledge capacity, but not with
reasoning capability. Under certain conditions, it is not necessary to increase
the parameter count to enhance reasoning.
  These findings are consistent across various model configurations and are
likely to be generally valid within the scope of our experiments.

</details>


### [36] [Advanced For-Loop for QML algorithm search](https://arxiv.org/abs/2506.18260)
*FuTe Wong*

Main category: cs.AI

TL;DR: 论文提出了一种基于大型语言模型的多智能体系统（LLMMA）框架，用于自动搜索和优化量子机器学习（QML）算法。


<details>
  <summary>Details</summary>
Motivation: 受Google DeepMind的FunSearch启发，旨在通过智能体框架系统地探索经典机器学习概念，并将其适配到量子计算中。

Method: 利用LLMMA在抽象层面上迭代生成和优化经典机器学习算法的量子变换。

Result: 展示了智能体框架在自动化开发QML算法中的潜力。

Conclusion: 未来方向包括引入规划机制和优化搜索策略，以扩展量子增强机器学习的应用。

Abstract: This paper introduces an advanced framework leveraging Large Language
Model-based Multi-Agent Systems (LLMMA) for the automated search and
optimization of Quantum Machine Learning (QML) algorithms. Inspired by Google
DeepMind's FunSearch, the proposed system works on abstract level to
iteratively generates and refines quantum transformations of classical machine
learning algorithms (concepts), such as the Multi-Layer Perceptron,
forward-forward and backpropagation algorithms. As a proof of concept, this
work highlights the potential of agentic frameworks to systematically explore
classical machine learning concepts and adapt them for quantum computing,
paving the way for efficient and automated development of QML algorithms.
Future directions include incorporating planning mechanisms and optimizing
strategy in the search space for broader applications in quantum-enhanced
machine learning.

</details>


### [37] [Dynamic Knowledge Exchange and Dual-diversity Review: Concisely Unleashing the Potential of a Multi-Agent Research Team](https://arxiv.org/abs/2506.18348)
*Weilun Yu,Shixiang Tang,Yonggui Huang,Nanqing Dong,Li Fan,Honggang Qi,Wei Liu,Xiaoli Diao,Xi Chen,Wanli Ouyang*

Main category: cs.AI

TL;DR: IDVSCI是一个基于LLM的多智能体框架，通过动态知识交换和双重多样性评审机制，提升科学研究的交互推理和创造力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM科学代理缺乏交互推理和评估机制，无法模拟真实研究中的合作与评审动态。

Method: 提出IDVSCI框架，包含动态知识交换和双重多样性评审机制。

Result: 在计算机科学和健康科学数据集上，IDVSCI表现优于现有系统。

Conclusion: IDVSCI证明了交互和同行评审动态在LLM自主研究中的重要性。

Abstract: Scientific progress increasingly relies on effective collaboration among
researchers, a dynamic that large language models (LLMs) have only begun to
emulate. While recent LLM-based scientist agents show promise in autonomous
scientific discovery, they often lack the interactive reasoning and evaluation
mechanisms essential to real-world research. We propose IDVSCI (Internal
Discussion and Vote SCIentists), a multi-agent framework built on LLMs that
incorporates two key innovations: a Dynamic Knowledge Exchange mechanism
enabling iterative feedback among agents, and a Dual-Diversity Review paradigm
that simulates heterogeneous expert evaluation. These components jointly
promote deeper reasoning and the generation of more creative and impactful
scientific ideas. To evaluate the effectiveness and generalizability of our
approach, we conduct experiments on two datasets: a widely used benchmark in
computer science and a new dataset we introduce in the health sciences domain.
Results show that IDVSCI consistently achieves the best performance across both
datasets, outperforming existing systems such as AI Scientist and VIRSCI. These
findings highlight the value of modeling interaction and peer review dynamics
in LLM-based autonomous research.

</details>


### [38] [A Large Language Model-based Multi-Agent Framework for Analog Circuits' Sizing Relationships Extraction](https://arxiv.org/abs/2506.18424)
*Chengjie Liu,Weiyu Chen,Huiyao Xu,Yuan Du,Jun Yang,Li Du*

Main category: cs.AI

TL;DR: 论文提出了一种基于大语言模型（LLM）的多智能体框架，用于从学术论文中提取模拟电路的尺寸关系，以优化电路设计中的搜索空间修剪。


<details>
  <summary>Details</summary>
Motivation: 现有技术将电路尺寸任务视为数学优化问题，但忽略了先验知识的自动引入，导致搜索空间压缩不足。

Method: 采用LLM多智能体框架提取模拟电路的尺寸关系，有效修剪搜索空间。

Result: 在3类电路上测试，优化效率提高了2.32至26.6倍。

Conclusion: LLM能有效修剪模拟电路尺寸的搜索空间，为LLM与传统模拟电路设计自动化方法的结合提供了新方案。

Abstract: In the design process of the analog circuit pre-layout phase, device sizing
is an important step in determining whether an analog circuit can meet the
required performance metrics. Many existing techniques extract the circuit
sizing task as a mathematical optimization problem to solve and continuously
improve the optimization efficiency from a mathematical perspective. But they
ignore the automatic introduction of prior knowledge, fail to achieve effective
pruning of the search space, which thereby leads to a considerable compression
margin remaining in the search space. To alleviate this problem, we propose a
large language model (LLM)-based multi-agent framework for analog circuits'
sizing relationships extraction from academic papers. The search space in the
sizing process can be effectively pruned based on the sizing relationship
extracted by this framework. Eventually, we conducted tests on 3 types of
circuits, and the optimization efficiency was improved by $2.32 \sim 26.6
\times$. This work demonstrates that the LLM can effectively prune the search
space for analog circuit sizing, providing a new solution for the combination
of LLMs and conventional analog circuit design automation methods.

</details>


### [39] [How Robust is Model Editing after Fine-Tuning? An Empirical Study on Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18428)
*Feng He,Zhenyang Liu,Marco Valentino,Zhixue Zhao*

Main category: cs.AI

TL;DR: 研究发现，模型编辑后的行为在微调后通常无法持久，即使微调与编辑无关。DoRA对编辑的逆转效果最强，而UCE编辑方法相对更稳健。


<details>
  <summary>Details</summary>
Motivation: 探讨模型编辑后行为在微调中的持久性，以解决AI安全中的潜在问题，如恶意编辑的防御和有益编辑的保留。

Method: 在T2I扩散模型（Stable Diffusion和FLUX）中，结合两种编辑技术（UCE和ReFACT）和三种微调方法（DreamBooth、LoRA、DoRA），通过多样化的编辑任务和评估指标进行实证分析。

Result: 编辑行为在微调后普遍失效，DoRA的逆转效果最强，UCE编辑方法在微调后保留效果较好。

Conclusion: 当前编辑方法存在局限性，需开发更稳健的技术以确保AI系统的长期控制和安全性。微调可作为恶意编辑的补救手段，但需重新编辑以维持有益属性。

Abstract: Model editing offers a low-cost technique to inject or correct a particular
behavior in a pre-trained model without extensive retraining, supporting
applications such as factual correction and bias mitigation. Despite this
common practice, it remains unknown whether edits persist after fine-tuning or
whether they are inadvertently reversed. This question has fundamental
practical implications. For example, if fine-tuning removes prior edits, it
could serve as a defence mechanism against hidden malicious edits. Vice versa,
the unintended removal of edits related to bias mitigation could pose serious
safety concerns. We systematically investigate the interaction between model
editing and fine-tuning in the context of T2I diffusion models, which are known
to exhibit biases and generate inappropriate content. Our study spans two T2I
model families (Stable Diffusion and FLUX), two sota editing techniques, and
three fine-tuning methods (DreamBooth, LoRA, and DoRA). Through an extensive
empirical analysis across diverse editing tasks and evaluation metrics, our
findings reveal a trend: edits generally fail to persist through fine-tuning,
even when fine-tuning is tangential or unrelated to the edits. Notably, we
observe that DoRA exhibits the strongest edit reversal effect. At the same
time, among editing methods, UCE demonstrates greater robustness, retaining
significantly higher efficacy post-fine-tuning compared to ReFACT. These
findings highlight a crucial limitation in current editing methodologies,
emphasizing the need for more robust techniques to ensure reliable long-term
control and alignment of deployed AI systems. These findings have dual
implications for AI safety: they suggest that fine-tuning could serve as a
remediation mechanism for malicious edits while simultaneously highlighting the
need for re-editing after fine-tuning to maintain beneficial safety and
alignment properties.

</details>


### [40] [Standard Applicability Judgment and Cross-jurisdictional Reasoning: A RAG-based Framework for Medical Device Compliance](https://arxiv.org/abs/2506.18511)
*Yu Han,Aaron Ceross,Jeroen H. M. Bergmann*

Main category: cs.AI

TL;DR: 论文提出了一种模块化AI系统，通过检索增强生成（RAG）管道自动化确定医疗设备标准的适用性，准确率73%，Top-5检索召回率87%。


<details>
  <summary>Details</summary>
Motivation: 解决医疗设备合规性中标准适用性判断的挑战，减少对专家解读的依赖。

Method: 使用RAG管道，结合检索和大型语言模型，分类标准为强制性、推荐或不适用，并提供可追溯的论证。

Result: 系统在分类准确率和检索召回率上表现优于基线方法，支持跨司法管辖区（如中美）的标准推理。

Conclusion: 该系统为可扩展和可解释的AI支持监管科学提供了首个端到端解决方案。

Abstract: Identifying the appropriate regulatory standard applicability remains a
critical yet understudied challenge in medical device compliance, frequently
necessitating expert interpretation of fragmented and heterogeneous
documentation across different jurisdictions. To address this challenge, we
introduce a modular AI system that leverages a retrieval-augmented generation
(RAG) pipeline to automate standard applicability determination. Given a
free-text device description, our system retrieves candidate standards from a
curated corpus and uses large language models to infer jurisdiction-specific
applicability, classified as Mandatory, Recommended, or Not Applicable, with
traceable justifications. We construct an international benchmark dataset of
medical device descriptions with expert-annotated standard mappings, and
evaluate our system against retrieval-only, zero-shot, and rule-based
baselines. The proposed approach attains a classification accuracy of 73% and a
Top-5 retrieval recall of 87%, demonstrating its effectiveness in identifying
relevant regulatory standards. We introduce the first end-to-end system for
standard applicability reasoning, enabling scalable and interpretable
AI-supported regulatory science. Notably, our region-aware RAG agent performs
cross-jurisdictional reasoning between Chinese and U.S. standards, supporting
conflict resolution and applicability justification across regulatory
frameworks.

</details>


### [41] [A Question Bank to Assess AI Inclusivity: Mapping out the Journey from Diversity Errors to Inclusion Excellence](https://arxiv.org/abs/2506.18538)
*Rifat Ara Shams,Didar Zowghi,Muneera Bano*

Main category: cs.AI

TL;DR: 本文提出了一种包含253个问题的AI包容性评估工具，覆盖五个维度，旨在推动AI系统的多样性与包容性。


<details>
  <summary>Details</summary>
Motivation: 现有AI风险评估框架缺乏对包容性的关注，需要标准化工具来评估AI系统是否符合多样性与包容性原则。

Method: 通过文献综述、D&I指南、负责任AI框架和模拟用户研究，开发了一个结构化的问题库，并进行了模拟评估。

Result: 模拟评估表明问题库能有效评估AI包容性，强调了将D&I原则整合到AI开发和治理中的重要性。

Conclusion: 该问题库为研究人员、从业者和政策制定者提供了系统评估和提升AI包容性的工具，推动更公平和负责任的AI技术。

Abstract: Ensuring diversity and inclusion (D&I) in artificial intelligence (AI) is
crucial for mitigating biases and promoting equitable decision-making. However,
existing AI risk assessment frameworks often overlook inclusivity, lacking
standardized tools to measure an AI system's alignment with D&I principles.
This paper introduces a structured AI inclusivity question bank, a
comprehensive set of 253 questions designed to evaluate AI inclusivity across
five pillars: Humans, Data, Process, System, and Governance. The development of
the question bank involved an iterative, multi-source approach, incorporating
insights from literature reviews, D&I guidelines, Responsible AI frameworks,
and a simulated user study. The simulated evaluation, conducted with 70
AI-generated personas related to different AI jobs, assessed the question
bank's relevance and effectiveness for AI inclusivity across diverse roles and
application domains. The findings highlight the importance of integrating D&I
principles into AI development workflows and governance structures. The
question bank provides an actionable tool for researchers, practitioners, and
policymakers to systematically assess and enhance the inclusivity of AI
systems, paving the way for more equitable and responsible AI technologies.

</details>


### [42] [T-CPDL: A Temporal Causal Probabilistic Description Logic for Developing Logic-RAG Agent](https://arxiv.org/abs/2506.18559)
*Hong Qing Yu*

Main category: cs.AI

TL;DR: 提出了一种名为T-CPDL的新框架，结合时间、因果和概率逻辑，显著提升语言模型的结构化推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在时间约束、因果关系和概率推理方面的不足。

Method: 扩展传统描述逻辑，引入时间区间操作符、显式因果关系和概率标注，提出两种T-CPDL变体。

Result: 实验表明T-CPDL在推理准确性、可解释性和置信度校准上显著优于基线。

Conclusion: T-CPDL增强了语言模型的透明推理能力，为Logic-RAG框架的发展奠定了基础。

Abstract: Large language models excel at generating fluent text but frequently struggle
with structured reasoning involving temporal constraints, causal relationships,
and probabilistic reasoning. To address these limitations, we propose Temporal
Causal Probabilistic Description Logic (T-CPDL), an integrated framework that
extends traditional Description Logic with temporal interval operators,
explicit causal relationships, and probabilistic annotations. We present two
distinct variants of T-CPDL: one capturing qualitative temporal relationships
through Allen's interval algebra, and another variant enriched with explicit
timestamped causal assertions. Both variants share a unified logical structure,
enabling complex reasoning tasks ranging from simple temporal ordering to
nuanced probabilistic causation. Empirical evaluations on temporal reasoning
and causal inference benchmarks confirm that T-CPDL substantially improves
inference accuracy, interpretability, and confidence calibration of language
model outputs. By delivering transparent reasoning paths and fine-grained
temporal and causal semantics, T-CPDL significantly enhances the capability of
language models to support robust, explainable, and trustworthy
decision-making. This work also lays the groundwork for developing advanced
Logic-Retrieval-Augmented Generation (Logic-RAG) frameworks, potentially
boosting the reasoning capabilities and efficiency of knowledge graph-enhanced
RAG systems.

</details>


### [43] [Airalogy: AI-empowered universal data digitization for research automation](https://arxiv.org/abs/2506.18586)
*Zijie Yang,Qiji Zhou,Fang Guo,Sijie Zhang,Yexun Xi,Jinglei Nie,Yudian Zhu,Liping Huang,Chou Wu,Yonghe Xia,Xiaoyu Ma,Yingming Pu,Panzhong Lu,Junshu Pan,Mingtao Chen,Tiannan Guo,Yanmei Dou,Hongyu Chen,Anping Zeng,Jiaxing Huang,Tian Xu,Yue Zhang*

Main category: cs.AI

TL;DR: Airalogy是一个多学科AI驱动平台，旨在解决研究数据标准化和共享的挑战，平衡通用性与标准化。


<details>
  <summary>Details</summary>
Motivation: 当前AI应用受限于数据碎片化和缺乏统一标准，阻碍多学科AI赋能。

Method: 开发Airalogy平台，结合科学领域知识与计算技能，提供标准化数据记录和AI辅助功能。

Result: Airalogy已在西湖大学多个实验室部署，支持智能问答、自动化数据录入和分析。

Conclusion: Airalogy有望加速科学创新，惠及全球研究社区。

Abstract: Research data are the foundation of Artificial Intelligence (AI)-driven
science, yet current AI applications remain limited to a few fields with
readily available, well-structured, digitized datasets. Achieving comprehensive
AI empowerment across multiple disciplines is still out of reach. Present-day
research data collection is often fragmented, lacking unified standards,
inefficiently managed, and difficult to share. Creating a single platform for
standardized data digitization needs to overcome the inherent challenge of
balancing between universality (supporting the diverse, ever-evolving needs of
various disciplines) and standardization (enforcing consistent formats to fully
enable AI). No existing platform accommodates both facets. Building a truly
multidisciplinary platform requires integrating scientific domain knowledge
with sophisticated computing skills. Researchers often lack the computational
expertise to design customized and standardized data recording methods, whereas
platform developers rarely grasp the intricate needs of multiple scientific
domains. These gaps impede research data standardization and hamper AI-driven
progress. In this study, we address these challenges by developing Airalogy
(https://airalogy.com), the world's first AI- and community-driven platform
that balances universality and standardization for digitizing research data
across multiple disciplines. Airalogy represents entire research workflows
using customizable, standardized data records and offers an advanced AI
research copilot for intelligent Q&A, automated data entry, analysis, and
research automation. Already deployed in laboratories across all four schools
of Westlake University, Airalogy has the potential to accelerate and automate
scientific innovation in universities, industry, and the global research
community-ultimately benefiting humanity as a whole.

</details>


### [44] [AggTruth: Contextual Hallucination Detection using Aggregated Attention Scores in LLMs](https://arxiv.org/abs/2506.18628)
*Piotr Matys,Jan Eliasz,Konrad Kiełczyński,Mikołaj Langner,Teddy Ferdinan,Jan Kocoń,Przemysław Kazienko*

Main category: cs.AI

TL;DR: AggTruth是一种通过分析上下文注意力分数分布来检测大语言模型（LLMs）幻觉的方法，表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在实际应用中（如RAG设置下）的幻觉问题，提升模型可靠性。

Method: 提出四种基于注意力分数聚合的变体方法，分析特征选择技术和注意力头数量对性能的影响。

Result: 在相同任务和跨任务设置中表现稳定，优于当前最佳方法。

Conclusion: 注意力头的选择对检测性能至关重要，AggTruth能有效提升幻觉检测效果。

Abstract: In real-world applications, Large Language Models (LLMs) often hallucinate,
even in Retrieval-Augmented Generation (RAG) settings, which poses a
significant challenge to their deployment. In this paper, we introduce
AggTruth, a method for online detection of contextual hallucinations by
analyzing the distribution of internal attention scores in the provided context
(passage). Specifically, we propose four different variants of the method, each
varying in the aggregation technique used to calculate attention scores. Across
all LLMs examined, AggTruth demonstrated stable performance in both same-task
and cross-task setups, outperforming the current SOTA in multiple scenarios.
Furthermore, we conducted an in-depth analysis of feature selection techniques
and examined how the number of selected attention heads impacts detection
performance, demonstrating that careful selection of heads is essential to
achieve optimal results.

</details>


### [45] [Dual-level Behavioral Consistency for Inter-group and Intra-group Coordination in Multi-Agent Systems](https://arxiv.org/abs/2506.18651)
*Shuocun Yang,Huawen Hu,Enze Shi,Shu Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种名为DLBC的新型多智能体强化学习方法，通过动态调节组内和组间的行为一致性，提升协作效率和任务分工。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注组内行为一致性，而忽略了组间行为一致性的重要性。DLBC旨在填补这一空白，通过双重行为一致性调控提升多智能体系统的性能。

Method: DLBC将智能体分组，动态调节组内和组间的行为多样性，通过约束策略函数实现广泛适用性。

Result: 实验表明，DLBC显著提升了组内协作和组间任务分工，性能大幅改善。

Conclusion: DLBC为多智能体系统行为一致性控制提供了新思路，未来可探索其在更复杂任务中的应用。

Abstract: Behavioral diversity in Multi-agent reinforcement learning(MARL) represents
an emerging and promising research area. Prior work has largely centered on
intra-group behavioral consistency in multi-agent systems, with limited
attention given to behavioral consistency in multi-agent grouping scenarios. In
this paper, we introduce Dual-Level Behavioral Consistency (DLBC), a novel MARL
control method designed to explicitly regulate agent behaviors at both
intra-group and inter-group levels. DLBC partitions agents into distinct groups
and dynamically modulates behavioral diversity both within and between these
groups. By dynamically modulating behavioral diversity within and between these
groups, DLBC achieves enhanced division of labor through inter-group
consistency, which constrains behavioral strategies across different groups.
Simultaneously, intra-group consistency, achieved by aligning behavioral
strategies within each group, fosters stronger intra-group cooperation.
Crucially, DLBC's direct constraint of agent policy functions ensures its broad
applicability across various algorithmic frameworks. Experimental results in
various grouping cooperation scenarios demonstrate that DLBC significantly
enhances both intra-group cooperative performance and inter-group task
specialization, yielding substantial performance improvements. DLBC provides
new ideas for behavioral consistency control of multi-intelligent body systems,
and its potential for application in more complex tasks and dynamic
environments can be further explored in the future.

</details>


### [46] [Programming by Backprop: LLMs Acquire Reusable Algorithmic Abstractions During Code Training](https://arxiv.org/abs/2506.18777)
*Jonathan Cook,Silvia Sapora,Arash Ahmadian,Akbir Khan,Tim Rocktaschel,Jakob Foerster,Laura Ruis*

Main category: cs.AI

TL;DR: 论文提出Programming by Backprop (PBB)方法，通过仅训练源代码（无输入输出示例）提升大语言模型（LLMs）的泛化推理能力，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs仅通过源代码训练（无I/O示例）是否能学习程序评估能力，以理解代码训练如何增强其推理能力。

Method: 在两组程序（含I/O示例和不含I/O示例）上微调LLMs，比较其表现，并分析PBB的效果。

Result: LLMs能通过源代码隐式评估程序，PBB在代码形式下效果更佳，且比基于I/O对训练更鲁棒。

Conclusion: 代码训练使LLMs内化可重用算法抽象，未来可进一步优化符号程序学习，并探索模型对齐等方向。

Abstract: Training large language models (LLMs) on source code significantly enhances
their general-purpose reasoning abilities, but the mechanisms underlying this
generalisation are poorly understood. In this paper, we propose Programming by
Backprop (PBB) as a potential driver of this effect - teaching a model to
evaluate a program for inputs by training on its source code alone, without
ever seeing I/O examples. To explore this idea, we finetune LLMs on two sets of
programs representing simple maths problems and algorithms: one with source
code and I/O examples (w/ IO), the other with source code only (w/o IO). We
find evidence that LLMs have some ability to evaluate w/o IO programs for
inputs in a range of experimental settings, and make several observations.
Firstly, PBB works significantly better when programs are provided as code
rather than semantically equivalent language descriptions. Secondly, LLMs can
produce outputs for w/o IO programs directly, by implicitly evaluating the
program within the forward pass, and more reliably when stepping through the
program in-context via chain-of-thought. We further show that PBB leads to more
robust evaluation of programs across inputs than training on I/O pairs drawn
from a distribution that mirrors naturally occurring data. Our findings suggest
a mechanism for enhanced reasoning through code training: it allows LLMs to
internalise reusable algorithmic abstractions. Significant scope remains for
future work to enable LLMs to more effectively learn from symbolic procedures,
and progress in this direction opens other avenues like model alignment by
training on formal constitutional principles.

</details>


### [47] [TRIZ Agents: A Multi-Agent LLM Approach for TRIZ-Based Innovation](https://arxiv.org/abs/2506.18783)
*Kamil Szczepanik,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文提出了一种基于大型语言模型（LLM）的多智能体系统（TRIZ agents），用于协作解决TRIZ方法论中的创新问题，展示了多智能体协作在复杂创新任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: TRIZ方法的应用常受限于其复杂性和跨学科知识需求，而LLM的进展为自动化部分流程提供了新可能。本文旨在通过多智能体系统提升TRIZ的应用效率。

Method: 提出一个基于LLM的多智能体系统（TRIZ agents），每个智能体具备专业能力和工具访问权限，协作执行TRIZ步骤。

Result: 通过工程案例研究验证了多智能体系统在解决复杂创新问题中的有效性，展示了其生成多样化创新解决方案的潜力。

Conclusion: 多智能体协作在AI驱动的创新中具有优势，为复杂构思任务中的分散式问题解决提供了新方向。

Abstract: TRIZ, the Theory of Inventive Problem Solving, is a structured,
knowledge-based framework for innovation and abstracting problems to find
inventive solutions. However, its application is often limited by the
complexity and deep interdisciplinary knowledge required. Advancements in Large
Language Models (LLMs) have revealed new possibilities for automating parts of
this process. While previous studies have explored single LLMs in TRIZ
applications, this paper introduces a multi-agent approach. We propose an
LLM-based multi-agent system, called TRIZ agents, each with specialized
capabilities and tool access, collaboratively solving inventive problems based
on the TRIZ methodology. This multi-agent system leverages agents with various
domain expertise to efficiently navigate TRIZ steps. The aim is to model and
simulate an inventive process with language agents. We assess the effectiveness
of this team of agents in addressing complex innovation challenges based on a
selected case study in engineering. We demonstrate the potential of agent
collaboration to produce diverse, inventive solutions. This research
contributes to the future of AI-driven innovation, showcasing the advantages of
decentralized problem-solving in complex ideation tasks.

</details>


### [48] [ConciseHint: Boosting Efficient Reasoning via Continuous Concise Hints during Generation](https://arxiv.org/abs/2506.18810)
*Siao Tang,Xinyin Ma,Gongfan Fang,Xinchao Wang*

Main category: cs.AI

TL;DR: 论文提出ConciseHint框架，通过在推理过程中注入文本提示，鼓励模型生成简洁的推理过程，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（如DeepSeek-R1和OpenAI o1系列）在复杂推理任务中表现优异，但推理过程冗长导致效率问题。现有方法主要关注推理前优化，忽略了在推理过程中直接干预的可能性。

Method: 提出ConciseHint框架，在推理过程中动态注入文本提示（手动设计或基于简洁数据训练），并根据查询复杂度自适应调整提示强度。

Result: 在DeepSeek-R1和Qwen-3系列模型上实验表明，该方法能显著减少推理长度（如GSM8K基准上减少65%），同时几乎不影响准确性。

Conclusion: ConciseHint有效解决了推理模型冗长问题，为推理效率提升提供了新方向。

Abstract: Recent advancements in large reasoning models (LRMs) like DeepSeek-R1 and
OpenAI o1 series have achieved notable performance enhancements on complex
reasoning tasks by scaling up the generation length by Chain-of-Thought (CoT).
However, an emerging issue is their inclination to produce excessively verbose
reasoning processes, leading to the inefficiency problem. Existing literature
on improving efficiency mainly adheres to the before-reasoning paradigms such
as prompting and reasoning or fine-tuning and reasoning, but ignores the
promising direction of directly encouraging the model to speak concisely by
intervening during the generation of reasoning. In order to fill the blank, we
propose a framework dubbed ConciseHint, which continuously encourages the
reasoning model to speak concisely by injecting the textual hint (manually
designed or trained on the concise data) during the token generation of the
reasoning process. Besides, ConciseHint is adaptive to the complexity of the
query by adaptively adjusting the hint intensity, which ensures it will not
undermine model performance. Experiments on the state-of-the-art LRMs,
including DeepSeek-R1 and Qwen-3 series, demonstrate that our method can
effectively produce concise reasoning processes while maintaining performance
well. For instance, we achieve a reduction ratio of 65\% for the reasoning
length on GSM8K benchmark with Qwen-3 4B with nearly no accuracy loss.

</details>


### [49] [Steering Conceptual Bias via Transformer Latent-Subspace Activation](https://arxiv.org/abs/2506.18887)
*Vansh Sharma,Venkat Raman*

Main category: cs.AI

TL;DR: 通过激活语言模型中的潜在子空间，研究成功引导科学代码生成偏向特定编程语言，提出了一种梯度优化的自适应激活框架（G-ACT）。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过激活语言模型的潜在子空间，实现对科学代码生成语言的精确控制。

Method: 开发了G-ACT框架，通过聚类激活差异和在线训练轻量级探针，选择适当的引导向量。

Result: 在LLaMA-3.2 3B中，G-ACT显著提高了CPP语言的生成偏向，分类准确率提升15%，早期层提升61.5%。

Conclusion: G-ACT提供了一种可扩展、可解释且高效的机制，适用于实际代理系统的概念级控制。

Abstract: This work examines whether activating latent subspaces in language models
(LLMs) can steer scientific code generation toward a specific programming
language. Five causal LLMs were first evaluated on scientific coding prompts to
quantify their baseline bias among four programming languages. A static
neuron-attribution method, perturbing the highest activated MLP weight for a
C++ or CPP token, proved brittle and exhibited limited generalization across
prompt styles and model scales. To address these limitations, a
gradient-refined adaptive activation steering framework (G-ACT) was developed:
per-prompt activation differences are clustered into a small set of steering
directions, and lightweight per-layer probes are trained and refined online to
select the appropriate steering vector. In LLaMA-3.2 3B, this approach reliably
biases generation towards the CPP language by increasing the average probe
classification accuracy by 15% and the early layers (0-6) improving the probe
classification accuracy by 61.5% compared to the standard ACT framework. For
LLaMA-3.3 70B, where attention-head signals become more diffuse, targeted
injections at key layers still improve language selection. Although per-layer
probing introduces a modest inference overhead, it remains practical by
steering only a subset of layers and enables reproducible model behavior. These
results demonstrate a scalable, interpretable and efficient mechanism for
concept-level control for practical agentic systems.

</details>


### [50] [jina-embeddings-v4: Universal Embeddings for Multimodal Multilingual Retrieval](https://arxiv.org/abs/2506.18902)
*Michael Günther,Saba Sturua,Mohammad Kalim Akram,Isabelle Mohr,Andrei Ungureanu,Sedigheh Eslami,Scott Martens,Bo Wang,Nan Wang,Han Xiao*

Main category: cs.AI

TL;DR: jina-embeddings-v4是一个3.8亿参数的多模态嵌入模型，通过新颖架构统一文本和图像表示，支持单向量和多向量嵌入，并在多种检索任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态检索任务中文本和图像表示的统一问题，并优化跨模态语义相似性和编程代码搜索等场景的性能。

Method: 采用任务特定的低秩适应（LoRA）适配器，结合单向量和多向量嵌入的后期交互架构。

Result: 在单模态和跨模态检索任务中达到最先进性能，尤其在处理视觉丰富内容（如表格、图表、混合媒体）时表现突出。

Conclusion: jina-embeddings-v4在多模态检索任务中表现出色，并提出了新的视觉丰富图像检索基准Jina-VDR。

Abstract: We introduce jina-embeddings-v4, a 3.8 billion parameter multimodal embedding
model that unifies text and image representations through a novel architecture
supporting both single-vector and multi-vector embeddings in the late
interaction style. The model incorporates task-specific Low-Rank Adaptation
(LoRA) adapters to optimize performance across diverse retrieval scenarios,
including query-based information retrieval, cross-modal semantic similarity,
and programming code search. Comprehensive evaluations demonstrate that
jina-embeddings-v4 achieves state-of-the-art performance on both single- modal
and cross-modal retrieval tasks, with particular strength in processing
visually rich content such as tables, charts, diagrams, and mixed-media
formats. To facilitate evaluation of this capability, we also introduce
Jina-VDR, a novel benchmark specifically designed for visually rich image
retrieval.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [51] [Outcome-Based Education: Evaluating Students' Perspectives Using Transformer](https://arxiv.org/abs/2506.17223)
*Shuvra Smaran Das,Anirban Saha Anik,Md Kishor Morol,Mohammad Sakib Mahmood*

Main category: cs.CL

TL;DR: 研究使用DistilBERT和LIME分析学生反馈，提升基于结果的教育（OBE）的效果。


<details>
  <summary>Details</summary>
Motivation: 通过学生反馈分析改进教育成果，支持OBE的可测量目标。

Method: 采用DistilBERT模型和LIME解释工具分析NLP数据集中的学生反馈。

Result: 结合Transformer模型和LIME提供了清晰且强大的学生反馈分析框架。

Conclusion: 该方法更符合OBE原则，通过数据驱动提升教育实践。

Abstract: Outcome-Based Education (OBE) emphasizes the development of specific
competencies through student-centered learning. In this study, we reviewed the
importance of OBE and implemented transformer-based models, particularly
DistilBERT, to analyze an NLP dataset that includes student feedback. Our
objective is to assess and improve educational outcomes. Our approach is better
than other machine learning models because it uses the transformer's deep
understanding of language context to classify sentiment better, giving better
results across a wider range of matrices. Our work directly contributes to
OBE's goal of achieving measurable outcomes by facilitating the identification
of patterns in student learning experiences. We have also applied LIME (local
interpretable model-agnostic explanations) to make sure that model predictions
are clear. This gives us understandable information about how key terms affect
sentiment. Our findings indicate that the combination of transformer models and
LIME explanations results in a strong and straightforward framework for
analyzing student feedback. This aligns more closely with the principles of OBE
and ensures the improvement of educational practices through data-driven
insights.

</details>


### [52] [Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs](https://arxiv.org/abs/2506.17231)
*Xiang Li,Chong Zhang,Jia Wang,Fangyu Wu,Yushi Li,Xiaobo Jin*

Main category: cs.CL

TL;DR: 提出了一种对抗性提示蒸馏方法，通过结合掩码语言建模、强化学习和动态温度控制，使小型语言模型（SLM）能够对主流大型语言模型（LLM）进行越狱攻击。


<details>
  <summary>Details</summary>
Motivation: 当前越狱攻击方法效率低、计算成本高且跨模型适应性差，难以应对LLM的快速发展和新防御策略。

Method: 结合掩码语言建模、强化学习和动态温度控制的提示生成与蒸馏方法。

Result: 实验验证了该方法在攻击成功率和危害性上的优越性，同时体现了资源效率和跨模型适应性。

Conclusion: 探索了将LLM的越狱能力蒸馏到SLM的可行性，揭示了模型的脆弱性，为LLM安全研究提供了新思路。

Abstract: Attacks on large language models (LLMs) in jailbreaking scenarios raise many
security and ethical issues. Current jailbreak attack methods face problems
such as low efficiency, high computational cost, and poor cross-model
adaptability and versatility, which make it difficult to cope with the rapid
development of LLM and new defense strategies. Our work proposes an Adversarial
Prompt Distillation, which combines masked language modeling, reinforcement
learning, and dynamic temperature control through a prompt generation and
distillation method. It enables small language models (SLMs) to jailbreak
attacks on mainstream LLMs. The experimental results verify the superiority of
the proposed method in terms of attack success rate and harm, and reflect the
resource efficiency and cross-model adaptability. This research explores the
feasibility of distilling the jailbreak ability of LLM to SLM, reveals the
model's vulnerability, and provides a new idea for LLM security research.

</details>


### [53] [GTA: Grouped-head latenT Attention](https://arxiv.org/abs/2506.17286)
*Luoyang Sun,Jiwen Jiang,Cheng Deng,Xinjian Wu,Haifeng Zhang,Lei Chen,Lionel Ni,Jun Wang*

Main category: cs.CL

TL;DR: GTA是一种新型注意力机制，通过共享注意力图和压缩值缓存，显著减少计算和内存开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的注意力机制存在计算和内存开销大的问题，限制了在资源有限硬件上的部署。

Method: GTA包括共享注意力图机制和非线性值解码器，分别减少键缓存大小和压缩值缓存。

Result: GTA将注意力计算FLOPs减少62.5%，KV缓存减少70%，推理速度提升2倍。

Conclusion: GTA显著提升了LLM的部署效率，适用于资源受限的环境。

Abstract: Attention mechanisms underpin the success of large language models (LLMs),
yet their substantial computational and memory overhead poses challenges for
optimizing efficiency and performance. A critical bottleneck arises as KV cache
and attention computations scale rapidly with text length, challenging
deployment on hardware with limited computational and memory resources. We
observe that attention mechanisms exhibit substantial redundancy, since the KV
cache can be significantly compressed and attention maps across heads display
high similarity, revealing that much of the computation and storage is
unnecessary. Leveraging these insights, we propose \textbf{G}rouped-Head
Laten\textbf{T} \textbf{A}ttention (GTA), a novel attention mechanism that
reduces memory usage and computational complexity while maintaining
performance. GTA comprises two components: (1) a shared attention map mechanism
that reuses attention scores across multiple heads, decreasing the key cache
size; and (2) a nonlinear value decoder with learned projections that
compresses the value cache into a latent space, further cutting memory needs.
GTA cuts attention computation FLOPs by up to \emph{62.5\%} versus
Grouped-Query Attention and shrink the KV cache by up to \emph{70\%}, all while
avoiding the extra overhead of Multi-Head Latent Attention to improve LLM
deployment efficiency. Consequently, GTA models achieve a \emph{2x} increase in
end-to-end inference speed, with prefill benefiting from reduced computational
cost and decoding benefiting from the smaller cache footprint.

</details>


### [54] [AI-Generated Game Commentary: A Survey and a Datasheet Repository](https://arxiv.org/abs/2506.17294)
*Qirui Zheng,Xingbo Wang,Keyuan Cheng,Yunlong Lu,Wenxin Li*

Main category: cs.CL

TL;DR: 本文介绍了AI生成游戏解说（AIGGC）的通用框架，并全面调查了45个现有数据集和方法，总结了关键挑战和评估指标，同时提供了公开的数据集资源。


<details>
  <summary>Details</summary>
Motivation: AIGGC因其市场潜力和技术挑战受到关注，需要语言模型在多模态NLP任务中满足高要求。

Method: 提出通用框架，分类调查现有数据集和方法，总结评估指标，并提供结构化数据集资源。

Result: 全面分析了AIGGC领域的关键挑战、方法和评估指标，并公开了数据集资源。

Conclusion: 本文为AIGGC领域的研究和基准测试提供了系统支持，推动了该领域的发展。

Abstract: AI-Generated Game Commentary (AIGGC) has gained increasing attention due to
its market potential and inherent technical challenges. As a comprehensive
multimodal Natural Language Processing (NLP) task, AIGGC imposes substantial
demands on language models, including factual accuracy, logical reasoning,
expressive text generation, generation speed, and context management. In this
paper, we introduce a general framework for AIGGC and present a comprehensive
survey of 45 existing game commentary dataset and methods according to key
challenges they aim to address in this domain. We further classify and compare
various evaluation metrics commonly used in this domain. To support future
research and benchmarking, we also provide a structured datasheet summarizing
the essential attributes of these datasets in appendix, which is meanwhile
publicly available in an open repository.

</details>


### [55] [Semantic uncertainty in advanced decoding methods for LLM generation](https://arxiv.org/abs/2506.17296)
*Darius Foodeei,Simin Fan,Martin Jaggi*

Main category: cs.CL

TL;DR: 研究探讨了不同解码方法对大型语言模型（LLM）输出语义不确定性的影响，发现结构化解码方法（如CoT和推测采样）能同时提高多样性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析不同解码策略如何影响LLM输出的多样性和可靠性，以解决实际应用中多样性与准确性之间的权衡问题。

Method: 通过问答、摘要和代码生成任务实验，比较了CoT解码和推测采样等方法的性能。

Result: 结果显示，CoT解码提高了语义多样性但降低了预测熵，代码生成Pass@2率提升48.8%；推测采样在摘要任务中表现优异。

Conclusion: 结论是结构化解码方法可以同时提升语义探索和输出质量，对实际应用具有重要意义。

Abstract: This study investigates semantic uncertainty in large language model (LLM)
outputs across different decoding methods, focusing on emerging techniques like
speculative sampling and chain-of-thought (CoT) decoding. Through experiments
on question answering, summarization, and code generation tasks, we analyze how
different decoding strategies affect both the diversity and reliability of
model outputs. Our findings reveal that while CoT decoding demonstrates higher
semantic diversity, it maintains lower predictive entropy, suggesting that
structured exploration can lead to more confident and accurate outputs. This is
evidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower
alignment with reference solutions. For summarization tasks, speculative
sampling proved particularly effective, achieving superior ROUGE scores while
maintaining moderate semantic diversity. Our results challenge conventional
assumptions about trade-offs between diversity and accuracy in language model
outputs, demonstrating that properly structured decoding methods can increase
semantic exploration while maintaining or improving output quality. These
findings have significant implications for deploying language models in
practical applications where both reliability and diverse solution generation
are crucial.

</details>


### [56] [Mercury: Ultra-Fast Language Models Based on Diffusion](https://arxiv.org/abs/2506.17298)
*Inception Labs,Samar Khanna,Siddhant Kharbanda,Shufan Li,Harshit Varma,Eric Wang,Sawyer Birnbaum,Ziyang Luo,Yanis Miraoui,Akash Palrecha,Stefano Ermon,Aditya Grover,Volodymyr Kuleshov*

Main category: cs.CL

TL;DR: Mercury是一代基于扩散的商业规模大语言模型（LLMs），专为编码应用设计，在速度和质量上达到新前沿。


<details>
  <summary>Details</summary>
Motivation: 开发高效且高质量的编码专用LLMs，以满足开发者对速度和性能的需求。

Method: 采用Transformer架构参数化，通过扩散模型并行预测多个token，推出Mercury Coder Mini和Small两个版本。

Result: 在NVIDIA H100 GPU上，Mini和Small分别达到1109和737 tokens/sec的吞吐量，速度优化模型平均提升10倍，质量相当。

Conclusion: Mercury Coder在代码基准测试和实际应用中表现优异，提供公开API和免费试用平台。

Abstract: We present Mercury, a new generation of commercial-scale large language
models (LLMs) based on diffusion. These models are parameterized via the
Transformer architecture and trained to predict multiple tokens in parallel. In
this report, we detail Mercury Coder, our first set of diffusion LLMs designed
for coding applications. Currently, Mercury Coder comes in two sizes: Mini and
Small. These models set a new state-of-the-art on the speed-quality frontier.
Based on independent evaluations conducted by Artificial Analysis, Mercury
Coder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109
tokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform
speed-optimized frontier models by up to 10x on average while maintaining
comparable quality. We discuss additional results on a variety of code
benchmarks spanning multiple languages and use-cases as well as real-world
validation by developers on Copilot Arena, where the model currently ranks
second on quality and is the fastest model overall. We also release a public
API at https://platform.inceptionlabs.ai/ and free playground at
https://chat.inceptionlabs.ai

</details>


### [57] [PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights](https://arxiv.org/abs/2506.17314)
*Adnan Qidwai,Srija Mukhopadhyay,Prerana Khatiwada,Dan Roth,Vivek Gupta*

Main category: cs.CL

TL;DR: PRAISE利用大型语言模型自动从客户评论和卖家描述中提取、比较和结构化信息，帮助卖家改进产品列表，买家评估产品可靠性。


<details>
  <summary>Details</summary>
Motivation: 卖家提供的产品描述通常不完整或不准确，而客户评论包含有价值但难以手动筛选的信息。

Method: 使用大型语言模型（LLMs）自动提取、比较和结构化客户评论与卖家描述的信息，提供直观界面展示差异。

Result: PRAISE能有效生成可操作的结构化见解，显著提升电商产品目录的质量和可信度。

Conclusion: PRAISE通过自动化处理评论与描述的差异，为卖家和买家提供了实用工具，优化电商体验。

Abstract: Accurate and complete product descriptions are crucial for e-commerce, yet
seller-provided information often falls short. Customer reviews offer valuable
details but are laborious to sift through manually. We present PRAISE: Product
Review Attribute Insight Structuring Engine, a novel system that uses Large
Language Models (LLMs) to automatically extract, compare, and structure
insights from customer reviews and seller descriptions. PRAISE provides users
with an intuitive interface to identify missing, contradictory, or partially
matching details between these two sources, presenting the discrepancies in a
clear, structured format alongside supporting evidence from reviews. This
allows sellers to easily enhance their product listings for clarity and
persuasiveness, and buyers to better assess product reliability. Our
demonstration showcases PRAISE's workflow, its effectiveness in generating
actionable structured insights from unstructured reviews, and its potential to
significantly improve the quality and trustworthiness of e-commerce product
catalogs.

</details>


### [58] [Towards Safety Evaluations of Theory of Mind in Large Language Models](https://arxiv.org/abs/2506.17352)
*Tatsuhiro Aoshima,Mitsuaki Akiyama*

Main category: cs.CL

TL;DR: 研究探讨了大型语言模型（LLMs）在安全评估中可能表现出的欺骗行为，提出通过测量其心智理论能力来评估风险。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs能力的提升，其安全评估的重要性日益凸显，尤其是模型可能表现出欺骗行为的问题。

Method: 回顾心智理论研究，分析其在安全评估中的应用，并评估多个开源LLMs的心智理论能力发展。

Result: LLMs在阅读理解方面有所提升，但心智理论能力未见显著发展。

Conclusion: 研究揭示了LLMs心智理论能力的不足，并讨论了未来安全评估的挑战。

Abstract: As the capabilities of large language models (LLMs) continue to advance, the
importance of rigorous safety evaluation is becoming increasingly evident.
Recent concerns within the realm of safety assessment have highlighted
instances in which LLMs exhibit behaviors that appear to disable oversight
mechanisms and respond in a deceptive manner. For example, there have been
reports suggesting that, when confronted with information unfavorable to their
own persistence during task execution, LLMs may act covertly and even provide
false answers to questions intended to verify their behavior.To evaluate the
potential risk of such deceptive actions toward developers or users, it is
essential to investigate whether these behaviors stem from covert, intentional
processes within the model. In this study, we propose that it is necessary to
measure the theory of mind capabilities of LLMs. We begin by reviewing existing
research on theory of mind and identifying the perspectives and tasks relevant
to its application in safety evaluation. Given that theory of mind has been
predominantly studied within the context of developmental psychology, we
analyze developmental trends across a series of open-weight LLMs. Our results
indicate that while LLMs have improved in reading comprehension, their theory
of mind capabilities have not shown comparable development. Finally, we present
the current state of safety evaluation with respect to LLMs' theory of mind,
and discuss remaining challenges for future work.

</details>


### [59] [Cash or Comfort? How LLMs Value Your Inconvenience](https://arxiv.org/abs/2506.17367)
*Mateusz Cedro,Timour Ichmoukhamedov,Sofie Goethals,Yifan He,James Hinns,David Martens*

Main category: cs.CL

TL;DR: 研究发现当前大型语言模型（LLMs）在用户舒适度与金钱奖励的权衡决策中存在显著问题，包括响应不一致、对提示微小变化的脆弱性、不合理低报酬接受以及无理由拒绝高额奖励。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在涉及用户舒适度与金钱奖励的决策中的行为，填补现有研究空白。

Method: 通过量化多个LLMs对用户不适（如额外步行、等待、饥饿和疼痛）的定价，评估其决策行为。

Result: 发现LLMs在决策中存在响应不一致、对提示微小变化的脆弱性、不合理低报酬接受和无理由拒绝高额奖励等问题。

Conclusion: 当前LLMs不适合作为决策助手，需进一步研究其对人类不便的评估方式。

Abstract: Large Language Models (LLMs) are increasingly proposed as near-autonomous
artificial intelligence (AI) agents capable of making everyday decisions on
behalf of humans. Although LLMs perform well on many technical tasks, their
behaviour in personal decision-making remains less understood. Previous studies
have assessed their rationality and moral alignment with human decisions.
However, the behaviour of AI assistants in scenarios where financial rewards
are at odds with user comfort has not yet been thoroughly explored. In this
paper, we tackle this problem by quantifying the prices assigned by multiple
LLMs to a series of user discomforts: additional walking, waiting, hunger and
pain. We uncover several key concerns that strongly question the prospect of
using current LLMs as decision-making assistants: (1) a large variance in
responses between LLMs, (2) within a single LLM, responses show fragility to
minor variations in prompt phrasing (e.g., reformulating the question in the
first person can considerably alter the decision), (3) LLMs can accept
unreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10
hours), and (4) LLMs can reject monetary gains where no discomfort is imposed
(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for
scrutiny of how LLMs value human inconvenience, particularly as we move toward
applications where such cash-versus-comfort trade-offs are made on users'
behalf.

</details>


### [60] [Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study](https://arxiv.org/abs/2506.17410)
*Danielle R. Thomas,Conrad Borchers,Jionghao Lin,Sanjit Kakarla,Shambhavi Bhushan,Erin Gatz,Shivang Gupta,Ralph Abboud,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 研究探讨了利用生成式AI（如GPT-4、Gemini等）从音频转录中识别和评估数学辅导中的导师行为，验证了其可行性和扩展性。


<details>
  <summary>Details</summary>
Motivation: 辅导行为对学生成绩有积极影响，但如何大规模识别和分析这些行为仍是一个开放问题。

Method: 分析了50份大学导师辅导中学生的数学音频转录，使用多种生成式AI模型评估导师的表扬和错误回应技能。

Result: 模型在检测表扬（94-98%准确率）和错误（82-88%准确率）方面表现可靠，与人类评估一致（83-89%和73-77%）。

Conclusion: 研究提出了一种经济高效的提示策略，支持生成式AI在大规模真实场景中的应用，并贡献了可复现的LLM提示。

Abstract: Tutoring improves student achievement, but identifying and studying what
tutoring actions are most associated with student learning at scale based on
audio transcriptions is an open research problem. This present study
investigates the feasibility and scalability of using generative AI to identify
and evaluate specific tutor moves in real-life math tutoring. We analyze 50
randomly selected transcripts of college-student remote tutors assisting middle
school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo,
Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills:
delivering effective praise and responding to student math errors. All models
reliably detected relevant situations, for example, tutors providing praise to
students (94-98% accuracy) and a student making a math error (82-88% accuracy)
and effectively evaluated the tutors' adherence to tutoring best practices,
aligning closely with human judgments (83-89% and 73-77%, respectively). We
propose a cost-effective prompting strategy and discuss practical implications
for using large language models to support scalable assessment in authentic
settings. This work further contributes LLM prompts to support reproducibility
and research in AI-supported learning.

</details>


### [61] [UProp: Investigating the Uncertainty Propagation of LLMs in Multi-Step Agentic Decision-Making](https://arxiv.org/abs/2506.17419)
*Jinhao Duan,James Diffenderfer,Sandeep Madireddy,Tianlong Chen,Bhavya Kailkhura,Kaidi Xu*

Main category: cs.CL

TL;DR: 本文提出了UProp框架，用于量化大型语言模型（LLM）在序列决策中的不确定性，包括内部和外部不确定性，并通过实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有不确定性量化方法主要针对单轮问答，而多步决策场景（如LLM代理系统）尚未充分研究。

Method: 提出信息论框架，将不确定性分解为内部和外部（互信息）两部分，并设计高效的外部不确定性估计器UProp。

Result: UProp在多步决策基准测试中显著优于现有单轮不确定性量化方法。

Conclusion: UProp为LLM序列决策不确定性量化提供了有效解决方案，具有潜在应用价值。

Abstract: As Large Language Models (LLMs) are integrated into safety-critical
applications involving sequential decision-making in the real world, it is
essential to know when to trust LLM decisions. Existing LLM Uncertainty
Quantification (UQ) methods are primarily designed for single-turn
question-answering formats, resulting in multi-step decision-making scenarios,
e.g., LLM agentic system, being underexplored. In this paper, we introduce a
principled, information-theoretic framework that decomposes LLM sequential
decision uncertainty into two parts: (i) internal uncertainty intrinsic to the
current decision, which is focused on existing UQ methods, and (ii) extrinsic
uncertainty, a Mutual-Information (MI) quantity describing how much uncertainty
should be inherited from preceding decisions. We then propose UProp, an
efficient and effective extrinsic uncertainty estimator that converts the
direct estimation of MI to the estimation of Pointwise Mutual Information (PMI)
over multiple Trajectory-Dependent Decision Processes (TDPs). UProp is
evaluated over extensive multi-step decision-making benchmarks, e.g.,
AgentBench and HotpotQA, with state-of-the-art LLMs, e.g., GPT-4.1 and
DeepSeek-V3. Experimental results demonstrate that UProp significantly
outperforms existing single-turn UQ baselines equipped with thoughtful
aggregation strategies. Moreover, we provide a comprehensive analysis of UProp,
including sampling efficiency, potential applications, and intermediate
uncertainty propagation, to demonstrate its effectiveness. Codes will be
available at https://github.com/jinhaoduan/UProp.

</details>


### [62] [Beyond the Link: Assessing LLMs' ability to Classify Political Content across Global Media](https://arxiv.org/abs/2506.17435)
*Alberto Martinez-Serra,Alejandro De La Fuente,Nienke Viescher,Ana S. Cardenal*

Main category: cs.CL

TL;DR: 该研究探讨了大型语言模型（LLMs）仅通过URL分类政治内容（PC）的可行性，并比较了不同模型在多语言和多国家背景下的表现。


<details>
  <summary>Details</summary>
Motivation: 填补LLMs在仅通过URL分类政治内容方面的研究空白，评估其与全文分析的准确性对比。

Method: 使用多种先进LLMs（如GPT、Llama等）对五个国家的URL和文本进行分类，并与人工标注和传统机器学习方法对比。

Result: 研究发现URL能有效嵌入大部分新闻内容，为准确性与成本平衡提供了重要视角。

Conclusion: URL分析可作为全文分析的近似方法，但需考虑上下文限制，并提出了在政治科学研究中使用LLMs的方法建议。

Abstract: The use of large language models (LLMs) is becoming common in the context of
political science, particularly in studies that analyse individuals use of
digital media. However, while previous research has demonstrated LLMs ability
at labelling tasks, the effectiveness of using LLMs to classify political
content (PC) from just URLs is not yet well explored. The work presented in
this article bridges this gap by evaluating whether LLMs can accurately
identify PC vs. non-PC from both the article text and the URLs from five
countries (France, Germany, Spain, the UK, and the US) and different languages.
Using cutting-edge LLMs like GPT, Llama, Mistral, Deepseek, Qwen and Gemma, we
measure model performance to assess whether URL-level analysis can be a good
approximation for full-text analysis of PC, even across different linguistic
and national contexts. Model outputs are compared with human-labelled articles,
as well as traditional supervised machine learning techniques, to set a
baseline of performance. Overall, our findings suggest the capacity of URLs to
embed most of the news content, providing a vital perspective on accuracy-cost
balancing. We also account for contextual limitations and suggest
methodological recommendations to use LLMs within political science studies.

</details>


### [63] [Breaking the Transcription Bottleneck: Fine-tuning ASR Models for Extremely Low-Resource Fieldwork Languages](https://arxiv.org/abs/2506.17459)
*Siyu Liang,Gina-Anne Levow*

Main category: cs.CL

TL;DR: 比较两种多语言ASR模型（MMS和XLS-R）在五种低资源语言上的表现，发现MMS在极少量数据时表现最佳，而XLS-R在数据超过一小时时表现相当。


<details>
  <summary>Details</summary>
Motivation: 解决语言田野调查中ASR因数据稀缺、环境噪声和自发语音等挑战的实用性限制。

Method: 对MMS和XLS-R模型在五种低资源语言上进行微调，控制训练数据时长。

Result: MMS在极少量数据时表现最佳，XLS-R在数据超过一小时时表现相当。

Conclusion: 为语言学家提供可复现的ASR适应方法，缓解语言文档中的转录瓶颈。

Abstract: Automatic Speech Recognition (ASR) has reached impressive accuracy for
high-resource languages, yet its utility in linguistic fieldwork remains
limited. Recordings collected in fieldwork contexts present unique challenges,
including spontaneous speech, environmental noise, and severely constrained
datasets from under-documented languages. In this paper, we benchmark the
performance of two fine-tuned multilingual ASR models, MMS and XLS-R, on five
typologically diverse low-resource languages with control of training data
duration. Our findings show that MMS is best suited when extremely small
amounts of training data are available, whereas XLS-R shows parity performance
once training data exceed one hour. We provide linguistically grounded analysis
for further provide insights towards practical guidelines for field linguists,
highlighting reproducible ASR adaptation approaches to mitigate the
transcription bottleneck in language documentation.

</details>


### [64] [Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems](https://arxiv.org/abs/2506.17467)
*Weixin Liang*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）对社会的影响，包括AI检测器的偏见、LLMs在各领域的应用及其在研究反馈中的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何改变写作和沟通方式，并分析其对社会各层面的影响。

Method: 通过三个研究方向：分析AI检测器的偏见、测量LLMs在各领域的应用、评估LLMs在研究反馈中的作用。

Result: 发现AI检测器存在偏见，LLMs在各领域广泛应用，且能为研究者提供有效反馈。

Conclusion: LLMs对社会影响深远，需关注其公平性和支持潜力。

Abstract: Large language models (LLMs) have shown significant potential to change how
we write, communicate, and create, leading to rapid adoption across society.
This dissertation examines how individuals and institutions are adapting to and
engaging with this emerging technology through three research directions.
First, I demonstrate how the institutional adoption of AI detectors introduces
systematic biases, particularly disadvantaging writers of non-dominant language
varieties, highlighting critical equity concerns in AI governance. Second, I
present novel population-level algorithmic approaches that measure the
increasing adoption of LLMs across writing domains, revealing consistent
patterns of AI-assisted content in academic peer reviews, scientific
publications, consumer complaints, corporate communications, job postings, and
international organization press releases. Finally, I investigate LLMs'
capability to provide feedback on research manuscripts through a large-scale
empirical analysis, offering insights into their potential to support
researchers who face barriers in accessing timely manuscript feedback,
particularly early-career researchers and those from under-resourced settings.

</details>


### [65] [VeriLocc: End-to-End Cross-Architecture Register Allocation via LLM](https://arxiv.org/abs/2506.17506)
*Lesheng Jin,Zhenyuan Ruan,Haohui Mai,Jingbo Shang*

Main category: cs.CL

TL;DR: VeriLocc结合大型语言模型（LLM）和形式化编译器技术，实现跨GPU架构的可泛化和可验证寄存器分配。


<details>
  <summary>Details</summary>
Motivation: 现代GPU发展迅速，但生产编译器仍依赖手工调整的寄存器分配启发式方法，需为每代硬件重新调整。

Method: VeriLocc通过微调LLM将中间表示（MIR）转换为目标特定的寄存器分配，结合静态分析和验证器引导的再生循环确保正确性。

Result: 在矩阵乘法（GEMM）和多头注意力（MHA）上，VeriLocc单次准确率达85-99%，pass@100接近100%，性能优于专家调优库。

Conclusion: VeriLocc为跨架构寄存器分配提供了一种高效且可验证的解决方案。

Abstract: Modern GPUs evolve rapidly, yet production compilers still rely on
hand-crafted register allocation heuristics that require substantial re-tuning
for each hardware generation. We introduce VeriLocc, a framework that combines
large language models (LLMs) with formal compiler techniques to enable
generalizable and verifiable register allocation across GPU architectures.
VeriLocc fine-tunes an LLM to translate intermediate representations (MIRs)
into target-specific register assignments, aided by static analysis for
cross-architecture normalization and generalization and a verifier-guided
regeneration loop to ensure correctness. Evaluated on matrix multiplication
(GEMM) and multi-head attention (MHA), VeriLocc achieves 85-99% single-shot
accuracy and near-100% pass@100. Case study shows that VeriLocc discovers more
performant assignments than expert-tuned libraries, outperforming rocBLAS by
over 10% in runtime.

</details>


### [66] [Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning](https://arxiv.org/abs/2506.17525)
*Mingfei Lau,Qian Chen,Yeming Fang,Tingting Xu,Tongzhou Chen,Pavel Golik*

Main category: cs.CL

TL;DR: 对三个多语言语音数据集的质量审计发现显著问题，分为微观和宏观层面，尤其在资源不足语言中更明显。以台湾闽南语为例，提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 揭示多语言语音数据集的质量问题，以提升其作为训练和评估集的实用性，并改善下游模型性能。

Method: 质量审计，将问题分为微观和宏观层面，并以台湾闽南语为例进行案例分析。

Result: 发现宏观问题在资源不足语言中更普遍，需加强语言规划和数据质量控制。

Conclusion: 提出未来数据集开发的指南和建议，强调社会语言学意识的重要性。

Abstract: Our quality audit for three widely used public multilingual speech datasets -
Mozilla Common Voice 17.0, FLEURS, and VoxPopuli - shows that in some
languages, these datasets suffer from significant quality issues. We believe
addressing these issues will make these datasets more useful as training and
evaluation sets, and improve downstream models. We divide these quality issues
into two categories: micro-level and macro-level. We find that macro-level
issues are more prevalent in less institutionalized, often under-resourced
languages. We provide a case analysis of Taiwanese Southern Min (nan_tw) that
highlights the need for proactive language planning (e.g. orthography
prescriptions, dialect boundary definition) and enhanced data quality control
in the process of Automatic Speech Recognition (ASR) dataset creation. We
conclude by proposing guidelines and recommendations to mitigate these issues
in future dataset development, emphasizing the importance of sociolinguistic
awareness in creating robust and reliable speech data resources.

</details>


### [67] [DuaShepherd: Integrating Stepwise Correctness and Potential Rewards for Mathematical Reasoning](https://arxiv.org/abs/2506.17533)
*Yuanhao Wu,Juntong Song,Hanning Zhang,Tong Zhang,Cheng Niu*

Main category: cs.CL

TL;DR: DuaShepherd是一个新颖的奖励建模框架，结合正确性和潜力两种互补奖励信号，提升大语言模型的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励信号通常只关注正确性或潜力，而结合两者可以更全面地指导模型优化。

Method: 开发自动化管道构建大规模奖励建模数据集，采用多任务学习的统一多头部架构训练两种奖励模型。

Result: 在MATH500和ProcessBench上，结合两种奖励信号的模型性能显著优于单一奖励模型，达到同类资源下的最优表现。

Conclusion: DuaShepherd通过整合正确性和潜力奖励信号，显著提升了大语言模型的数学推理能力。

Abstract: In this paper, we propose DuaShepherd, a novel reward modeling framework that
integrates two complementary reward signals, correctness and potential, to
enhance the mathematical reasoning capabilities of Large Language Models
(LLMs). While correctness-based signals emphasize identification of stepwise
errors, potential-based signals focus on the likelihood of reaching the correct
final answer. We developed an automated pipeline for constructing large-scale
reward modeling dataset with both signals. A unified, multi-head architecture
was explored to train the two reward models in a multi-task setup,
demonstrating benefits from learning both correctness and potential in
parallel. By combining these two signals into a compound probability, our model
achieves consistent performance improvements across multiple benchmarks.
Empirical evaluations on MATH500 and ProcessBench confirm that this combined
reward significantly outperforms models trained on either reward type alone,
achieving state-of-the-art performance under comparable resource constraints.

</details>


### [68] [Probing for Phonology in Self-Supervised Speech Representations: A Case Study on Accent Perception](https://arxiv.org/abs/2506.17542)
*Nitin Venkateswaran,Kevin Tang,Ratree Wayland*

Main category: cs.CL

TL;DR: 论文研究了自监督学习（SSL）模型如何编码影响口音感知的音系特征变化，发现特定音段的预训练表示能有效预测口音强度。


<details>
  <summary>Details</summary>
Motivation: 传统口音感知模型低估了音系特征的梯度变化对听者口音判断的影响，因此探索SSL模型如何捕捉这些变化。

Method: 使用CSLU Foreign Accented English语料库，提取音段特征概率，结合Wav2Vec2-BERT和WavLM的预训练表示及母语者口音评分进行分析。

Result: 分析表明，口音强度可通过音段预训练表示中的特定特征子集预测，且与美式和印度英语基线的距离显著相关。

Conclusion: 自监督语音表示可用于基于可解释音系特征的口音感知建模。

Abstract: Traditional models of accent perception underestimate the role of gradient
variations in phonological features which listeners rely upon for their accent
judgments. We investigate how pretrained representations from current
self-supervised learning (SSL) models of speech encode phonological
feature-level variations that influence the perception of segmental accent. We
focus on three segments: the labiodental approximant, the rhotic tap, and the
retroflex stop, which are uniformly produced in the English of native speakers
of Hindi as well as other languages in the Indian sub-continent. We use the
CSLU Foreign Accented English corpus (Lander, 2007) to extract, for these
segments, phonological feature probabilities using Phonet (V\'asquez-Correa et
al., 2019) and pretrained representations from Wav2Vec2-BERT (Barrault et al.,
2023) and WavLM (Chen et al., 2022) along with accent judgements by native
speakers of American English. Probing analyses show that accent strength is
best predicted by a subset of the segment's pretrained representation features,
in which perceptually salient phonological features that contrast the expected
American English and realized non-native English segments are given prominent
weighting. A multinomial logistic regression of pretrained representation-based
segment distances from American and Indian English baselines on accent ratings
reveals strong associations between the odds of accent strength and distances
from the baselines, in the expected directions. These results highlight the
value of self-supervised speech representations for modeling accent perception
using interpretable phonological features.

</details>


### [69] [AgriCHN: A Comprehensive Cross-domain Resource for Chinese Agricultural Named Entity Recognition](https://arxiv.org/abs/2506.17578)
*Lingxiao Zeng,Yiqi Tong,Wei Guo,Huarui Wu,Lihao Ge,Yijun Ye,Fuzhen Zhuang,Deqing Wang,Wei Guo,Cheng Chen*

Main category: cs.CL

TL;DR: AgriCHN是一个开源的中文农业命名实体识别数据集，包含4040个句子和15799个实体，涵盖27个类别，并整合了水文和气象实体，提升了数据质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决农业命名实体识别中高质量中文数据集稀缺的问题，并填补农业与水文、气象实体关联的研究空白。

Method: 从大量农业文章中精心整理数据，构建AgriCHN数据集，包含多种实体类别，并进行数据验证和基准测试。

Result: AgriCHN数据质量高，实体类型丰富，细粒度划分明确，实验表明其具有挑战性和研究潜力。

Conclusion: AgriCHN为农业命名实体识别提供了高质量资源，推动了该领域的研究进展。

Abstract: Agricultural named entity recognition is a specialized task focusing on
identifying distinct agricultural entities within vast bodies of text,
including crops, diseases, pests, and fertilizers. It plays a crucial role in
enhancing information extraction from extensive agricultural text resources.
However, the scarcity of high-quality agricultural datasets, particularly in
Chinese, has resulted in suboptimal performance when employing mainstream
methods for this purpose. Most earlier works only focus on annotating
agricultural entities while overlook the profound correlation of agriculture
with hydrology and meteorology. To fill this blank, we present AgriCHN, a
comprehensive open-source Chinese resource designed to promote the accuracy of
automated agricultural entity annotation. The AgriCHN dataset has been
meticulously curated from a wealth of agricultural articles, comprising a total
of 4,040 sentences and encapsulating 15,799 agricultural entity mentions
spanning 27 diverse entity categories. Furthermore, it encompasses entities
from hydrology to meteorology, thereby enriching the diversity of entities
considered. Data validation reveals that, compared with relevant resources,
AgriCHN demonstrates outstanding data quality, attributable to its richer
agricultural entity types and more fine-grained entity divisions. A benchmark
task has also been constructed using several state-of-the-art neural NER
models. Extensive experimental results highlight the significant challenge
posed by AgriCHN and its potential for further research.

</details>


### [70] [Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages](https://arxiv.org/abs/2506.17603)
*Jonathan Sakunkoo,Annabella Sakunkoo*

Main category: cs.CL

TL;DR: 该研究通过定制神经形态分析器验证了维基词典中拉丁语和意大利语缺陷动词的可靠性，发现维基词典对意大利语形态空缺的描述高度可靠，但对拉丁语存在7%的误判。


<details>
  <summary>Details</summary>
Motivation: 解决形态缺陷性（预期屈折形式缺失）问题对提升形态丰富语言的NLP工具准确性至关重要，但传统资源缺乏对形态空缺的覆盖。

Method: 定制神经形态分析器，标注拉丁语和意大利语语料库，并计算验证维基词典中缺陷动词列表。

Result: 维基词典对意大利语形态空缺的描述高度可靠，但对拉丁语有7%的误判率。

Conclusion: 尽管维基词典对稀有语言特征有价值，但其作为语言知识权威来源存在局限性，特别是在较少研究的语言和现象中。

Abstract: Morphological defectivity is an intriguing and understudied phenomenon in
linguistics. Addressing defectivity, where expected inflectional forms are
absent, is essential for improving the accuracy of NLP tools in morphologically
rich languages. However, traditional linguistic resources often lack coverage
of morphological gaps as such knowledge requires significant human expertise
and effort to document and verify. For scarce linguistic phenomena in
under-explored languages, Wikipedia and Wiktionary often serve as among the few
accessible resources. Despite their extensive reach, their reliability has been
a subject of controversy. This study customizes a novel neural morphological
analyzer to annotate Latin and Italian corpora. Using the massive annotated
data, crowd-sourced lists of defective verbs compiled from Wiktionary are
validated computationally. Our results indicate that while Wiktionary provides
a highly reliable account of Italian morphological gaps, 7% of Latin lemmata
listed as defective show strong corpus evidence of being non-defective. This
discrepancy highlights potential limitations of crowd-sourced wikis as
definitive sources of linguistic knowledge, particularly for less-studied
phenomena and languages, despite their value as resources for rare linguistic
features. By providing scalable tools and methods for quality assurance of
crowd-sourced data, this work advances computational morphology and expands
linguistic knowledge of defectivity in non-English, morphologically rich
languages.

</details>


### [71] [TyphoFormer: Language-Augmented Transformer for Accurate Typhoon Track Forecasting](https://arxiv.org/abs/2506.17609)
*Lincan Li,Eren Erman Ozguven,Yue Zhao,Guang Wang,Yiqun Xie,Yushun Dong*

Main category: cs.CL

TL;DR: TyphoFormer结合自然语言描述和数值数据，通过Transformer模型提升台风轨迹预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型在稀疏气象轨迹（如台风路径）预测中缺乏上下文知识，TyphoFormer通过引入语言描述弥补这一不足。

Method: 利用大型语言模型生成台风属性的文本描述，将其嵌入为特殊标记，与数值时间序列一起输入Transformer编码器。

Result: 在HURDAT2基准测试中，TyphoFormer显著优于其他先进方法，尤其在非线性路径变化和历史数据有限的情况下表现突出。

Conclusion: TyphoFormer通过融合文本和数值信息，提升了台风轨迹预测的可靠性和准确性。

Abstract: Accurate typhoon track forecasting is crucial for early system warning and
disaster response. While Transformer-based models have demonstrated strong
performance in modeling the temporal dynamics of dense trajectories of humans
and vehicles in smart cities, they usually lack access to broader contextual
knowledge that enhances the forecasting reliability of sparse meteorological
trajectories, such as typhoon tracks. To address this challenge, we propose
TyphoFormer, a novel framework that incorporates natural language descriptions
as auxiliary prompts to improve typhoon trajectory forecasting. For each time
step, we use Large Language Model (LLM) to generate concise textual
descriptions based on the numerical attributes recorded in the North Atlantic
hurricane database. The language descriptions capture high-level meteorological
semantics and are embedded as auxiliary special tokens prepended to the
numerical time series input. By integrating both textual and sequential
information within a unified Transformer encoder, TyphoFormer enables the model
to leverage contextual cues that are otherwise inaccessible through numerical
features alone. Extensive experiments are conducted on HURDAT2 benchmark,
results show that TyphoFormer consistently outperforms other state-of-the-art
baseline methods, particularly under challenging scenarios involving nonlinear
path shifts and limited historical observations.

</details>


### [72] [OpusLM: A Family of Open Unified Speech Language Models](https://arxiv.org/abs/2506.17611)
*Jinchuan Tian,William Chen,Yifan Peng,Jiatong Shi,Siddhant Arora,Shikhar Bharadwaj,Takashi Maekaku,Yusuke Shinohara,Keita Goto,Xiang Yue,Huck Yang,Shinji Watanabe*

Main category: cs.CL

TL;DR: OpusLMs是一系列开放的基础语音语言模型，通过从文本语言模型初始化并预训练语音-文本对和纯文本数据，在语音识别、语音合成和文本能力上表现优异。


<details>
  <summary>Details</summary>
Motivation: 推动开放和透明的语音语言模型研究，提供公开的代码、数据和模型。

Method: 从解码器文本语言模型初始化，通过多阶段训练策略和语音-文本对预训练。

Result: OpusLMs在语音识别、语音合成和文本能力上表现优异，甚至超越现有模型。

Conclusion: OpusLMs为开放语音语言模型研究提供了透明且高性能的解决方案。

Abstract: This paper presents Open Unified Speech Language Models (OpusLMs), a family
of open foundational speech language models (SpeechLMs) up to 7B. Initialized
from decoder-only text language models, the OpusLMs are continuously
pre-trained on 213K hours of speech-text pairs and 292B text-only tokens. We
demonstrate our OpusLMs achieve comparable (or even superior) performance with
existing SpeechLMs in speech recognition, speech synthesis, and text-only
capabilities. Technically, this paper articulates our SpeechLM designs on
tokenization, multi-stream language models, and multi-stage training
strategies. We experimentally demonstrate the importance of model size scaling
and the effect of annealing data selection. The OpusLMs are all built from
publicly available materials and are fully transparent models. We release our
code, data, checkpoints, and training logs to facilitate open SpeechLM research

</details>


### [73] [Answer-Centric or Reasoning-Driven? Uncovering the Latent Memory Anchor in LLMs](https://arxiv.org/abs/2506.17630)
*Yang Wu,Yifan Zhang,Yiwei Wang,Yujun Cai,Yurong Wu,Yuran Wang,Ning Xu,Jian Cheng*

Main category: cs.CL

TL;DR: 研究发现，大型语言模型（LLMs）的推理能力可能更多依赖于记忆的答案-推理模式，而非真正的推理。通过实验验证，LLMs对显式答案有强烈依赖，性能在答案线索被掩盖时显著下降。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs的推理能力是否基于真正的推理，还是仅依赖于记忆的答案-推理模式。

Method: 提出一个五级答案可见性提示框架，通过间接行为分析系统地操纵答案线索并探测模型行为。

Result: 实验显示，LLMs对显式答案有强烈依赖，性能在答案线索被掩盖时下降26.90%。

Conclusion: LLMs表现出的推理可能是事后合理化而非真正的推理，需更细致地理解其推理能力。

Abstract: While Large Language Models (LLMs) demonstrate impressive reasoning
capabilities, growing evidence suggests much of their success stems from
memorized answer-reasoning patterns rather than genuine inference. In this
work, we investigate a central question: are LLMs primarily anchored to final
answers or to the textual pattern of reasoning chains? We propose a five-level
answer-visibility prompt framework that systematically manipulates answer cues
and probes model behavior through indirect, behavioral analysis. Experiments
across state-of-the-art LLMs reveal a strong and consistent reliance on
explicit answers. The performance drops by 26.90\% when answer cues are masked,
even with complete reasoning chains. These findings suggest that much of the
reasoning exhibited by LLMs may reflect post-hoc rationalization rather than
true inference, calling into question their inferential depth. Our study
uncovers the answer-anchoring phenomenon with rigorous empirical validation and
underscores the need for a more nuanced understanding of what constitutes
reasoning in LLMs.

</details>


### [74] [Step-Opt: Boosting Optimization Modeling in LLMs through Iterative Data Synthesis and Structured Validation](https://arxiv.org/abs/2506.17637)
*Yang Wu,Yifan Zhang,Yurong Wu,Yuran Wang,Junkai Zhang,Jian Cheng*

Main category: cs.CL

TL;DR: 论文提出了Step-Opt-Instruct框架，通过迭代生成问题和逐步验证数据来优化LLMs在复杂OR任务中的表现，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理复杂优化建模任务时面临挑战，需要高质量的数据和验证方法来提升性能。

Method: 提出Step-Opt-Instruct框架，通过迭代生成问题和逐步验证数据，生成高质量微调数据，并用于微调开源LLMs。

Result: Step-Opt模型在多个基准测试中表现优异，尤其在复杂任务上提升了17.01%的准确率。

Conclusion: 结合结构化验证和逐步问题优化的方法能有效提升LLMs在决策自动化中的性能。

Abstract: Large Language Models (LLMs) have revolutionized various domains but
encounter substantial challenges in tackling optimization modeling tasks for
Operations Research (OR), particularly when dealing with complex problem. In
this work, we propose Step-Opt-Instruct, a framework that augments existing
datasets and generates high-quality fine-tuning data tailored to optimization
modeling. Step-Opt-Instruct employs iterative problem generation to
systematically increase problem complexity and stepwise validation to
rigorously verify data, preventing error propagation and ensuring the quality
of the generated dataset. Leveraging this framework, we fine-tune open-source
LLMs, including LLaMA-3-8B and Mistral-7B, to develop Step-Opt--a model that
achieves state-of-the-art performance on benchmarks such as NL4OPT, MAMO, and
IndustryOR. Extensive experiments demonstrate the superior performance of
Step-Opt, especially in addressing complex OR tasks, with a notable 17.01\%
improvement in micro average accuracy on difficult problems. These findings
highlight the effectiveness of combining structured validation with gradual
problem refinement to advance the automation of decision-making processes using
LLMs.The code and dataset are available at https://github.com/samwu-learn/Step.

</details>


### [75] [TPTT: Transforming Pretrained Transformer into Titans](https://arxiv.org/abs/2506.17671)
*Fabien Furfaro*

Main category: cs.CL

TL;DR: TPTT框架通过线性化注意力机制和高效内存管理提升预训练Transformer模型的效率，兼容Hugging Face Transformers库，显著提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长上下文推理中的计算和内存需求问题。

Method: 采用Memory as Gate (MaG)和混合线性化注意力(LiZA)技术，支持参数高效微调(LoRA)。

Result: 在MMLU基准测试中，1B参数模型效率与准确性显著提升，如Titans-Llama-3.2-1B的Exact Match提高20%。

Conclusion: TPTT具有实际可扩展性和鲁棒性，代码和Python包已开源。

Abstract: Recent advances in large language models (LLMs) have led to remarkable
progress in natural language processing, but their computational and memory
demands remain a significant challenge, particularly for long-context
inference. We introduce TPTT (Transforming Pretrained Transformer into Titans),
a novel framework for enhancing pretrained Transformer models with efficient
linearized attention mechanisms and advanced memory management. TPTT employs
techniques such as Memory as Gate (MaG) and mixed linearized attention (LiZA).
It is fully compatible with the Hugging Face Transformers library, enabling
seamless adaptation of any causal LLM through parameter-efficient fine-tuning
(LoRA) without full retraining. We show the effectiveness of TPTT on the MMLU
benchmark with models of approximately 1 billion parameters, observing
substantial improvements in both efficiency and accuracy. For instance,
Titans-Llama-3.2-1B achieves a 20% increase in Exact Match (EM) over its
baseline. Statistical analyses and comparisons with recent state-of-the-art
methods confirm the practical scalability and robustness of TPTT. Code is
available at https://github.com/fabienfrfr/tptt . Python package at
https://pypi.org/project/tptt/ .

</details>


### [76] [Resource-Friendly Dynamic Enhancement Chain for Multi-Hop Question Answering](https://arxiv.org/abs/2506.17692)
*Binquan Ji,Haibo Luo,Yifei Lu,Lei Hei,Jiaqi Wang,Tingjing Liao,Lingyu Wang,Shichao Wang,Feiliang Ren*

Main category: cs.CL

TL;DR: DEC框架通过分解复杂问题为子问题并迭代优化，结合轻量级关键词提取模块，显著减少计算开销，在资源受限环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决知识密集型多跳问答任务中，轻量级大语言模型因文档和上下文过多导致的幻觉和语义漂移问题。

Method: 提出DEC框架，分解问题为子问题，迭代优化子问题，并结合轻量级关键词提取模块进行精准检索。

Result: 在三个多跳问答数据集上表现优于或持平现有方法，显著减少计算开销，8B参数模型达到最优效果。

Conclusion: DEC框架在资源受限环境中高效且有效，适用于复杂问答任务。

Abstract: Knowledge-intensive multi-hop question answering (QA) tasks, which require
integrating evidence from multiple sources to address complex queries, often
necessitate multiple rounds of retrieval and iterative generation by large
language models (LLMs). However, incorporating many documents and extended
contexts poses challenges -such as hallucinations and semantic drift-for
lightweight LLMs with fewer parameters. This work proposes a novel framework
called DEC (Dynamic Enhancement Chain). DEC first decomposes complex questions
into logically coherent subquestions to form a hallucination-free reasoning
chain. It then iteratively refines these subquestions through context-aware
rewriting to generate effective query formulations. For retrieval, we introduce
a lightweight discriminative keyword extraction module that leverages extracted
keywords to achieve targeted, precise document recall with relatively low
computational overhead. Extensive experiments on three multi-hop QA datasets
demonstrate that DEC performs on par with or surpasses state-of-the-art
benchmarks while significantly reducing token consumption. Notably, our
approach attains state-of-the-art results on models with 8B parameters,
showcasing its effectiveness in various scenarios, particularly in
resource-constrained environments.

</details>


### [77] [Zero-Shot Conversational Stance Detection: Dataset and Approaches](https://arxiv.org/abs/2506.17693)
*Yuzhe Ding,Kang He,Bobo Li,Li Zheng,Haijun He,Fei Li,Chong Teng,Donghong Ji*

Main category: cs.CL

TL;DR: 论文提出了一种名为ZS-CSD的大规模零样本对话立场检测数据集，并设计了SITPCL模型，在零样本设置下取得了先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有对话立场检测数据集局限于特定目标，限制了模型在真实场景中的泛化能力，因此需要构建更通用的数据集和模型。

Method: 手动构建了包含280个目标的ZS-CSD数据集，并提出SITPCL模型，结合说话者交互和目标感知的原型对比学习。

Result: SITPCL在零样本对话立场检测中表现最佳，但F1-macro得分仅为43.81%，表明任务仍具挑战性。

Conclusion: 研究为零样本对话立场检测提供了新数据集和模型，但性能仍有提升空间。

Abstract: Stance detection, which aims to identify public opinion towards specific
targets using social media data, is an important yet challenging task. With the
increasing number of online debates among social media users, conversational
stance detection has become a crucial research area. However, existing
conversational stance detection datasets are restricted to a limited set of
specific targets, which constrains the effectiveness of stance detection models
when encountering a large number of unseen targets in real-world applications.
To bridge this gap, we manually curate a large-scale, high-quality zero-shot
conversational stance detection dataset, named ZS-CSD, comprising 280 targets
across two distinct target types. Leveraging the ZS-CSD dataset, we propose
SITPCL, a speaker interaction and target-aware prototypical contrastive
learning model, and establish the benchmark performance in the zero-shot
setting. Experimental results demonstrate that our proposed SITPCL model
achieves state-of-the-art performance in zero-shot conversational stance
detection. Notably, the SITPCL model attains only an F1-macro score of 43.81%,
highlighting the persistent challenges in zero-shot conversational stance
detection.

</details>


### [78] [The Evolution of Natural Language Processing: How Prompt Optimization and Language Models are Shaping the Future](https://arxiv.org/abs/2506.17700)
*Summra Saleem,Muhammad Nabeel Asim,Shaista Zulfiqar,Andreas Dengel*

Main category: cs.CL

TL;DR: 本文综述了大型语言模型（LLMs）中提示优化策略的潜力，将其分为11类，并分析了其在不同NLP任务中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有文献对提示工程的研究较多，但对提示优化策略的综合分析存在空白，本文旨在填补这一空白。

Method: 通过分析提示优化策略的工作原理，将其分类为11类，并详细介绍了相关NLP任务、LLMs和评估数据集。

Result: 研究为未来的比较研究提供了基础，并支持在一致的实验设置下评估提示优化策略和LLM预测流程。

Conclusion: 本文集中了多样化的策略知识，有助于在未探索的任务中开发创新的预测模型。

Abstract: Large Language Models (LLMs) have revolutionized the field of Natural
Language Processing (NLP) by automating traditional labor-intensive tasks and
consequently accelerated the development of computer-aided applications. As
researchers continue to advance this field with the introduction of novel
language models and more efficient training/finetuning methodologies, the idea
of prompt engineering and subsequent optimization strategies with LLMs has
emerged as a particularly impactful trend to yield a substantial performance
boost across diverse NLP tasks. To best of our knowledge numerous review
articles have explored prompt engineering, however, a critical gap exists in
comprehensive analyses of prompt optimization strategies. To bridge this gap
this paper provides unique and comprehensive insights about the potential of
diverse prompt optimization strategies. It analyzes their underlying working
paradigms and based on these principles, categorizes them into 11 distinct
classes. Moreover, the paper provides details about various NLP tasks where
these prompt optimization strategies have been employed, along with details of
different LLMs and benchmark datasets used for evaluation. This comprehensive
compilation lays a robust foundation for future comparative studies and enables
rigorous assessment of prompt optimization and LLM-based predictive pipelines
under consistent experimental settings: a critical need in the current
landscape. Ultimately, this research will centralize diverse strategic
knowledge to facilitate the adaptation of existing prompt optimization
strategies for development of innovative predictors across unexplored tasks.

</details>


### [79] [Aged to Perfection: Machine-Learning Maps of Age in Conversational English](https://arxiv.org/abs/2506.17708)
*MingZe Tang*

Main category: cs.CL

TL;DR: 利用英国国家语料库2014研究不同年龄组的语言模式，结合计算语言分析和机器学习方法，探索语言与年龄的关系。


<details>
  <summary>Details</summary>
Motivation: 研究不同年龄组的语言模式差异，探索说话者人口统计与语言因素（如话语时长、词汇多样性和选词）的联系。

Method: 使用计算语言分析和机器学习方法，分析语料库数据，识别不同年龄组的语言特征，并建立预测模型。

Result: 揭示了不同年龄组的独特语言标记，并建立了能够从语言特征预测年龄组的模型。

Conclusion: 研究增进了对现代英国口语社会语言学多样性的理解。

Abstract: The study uses the British National Corpus 2014, a large sample of
contemporary spoken British English, to investigate language patterns across
different age groups. Our research attempts to explore how language patterns
vary between different age groups, exploring the connection between speaker
demographics and linguistic factors such as utterance duration, lexical
diversity, and word choice. By merging computational language analysis and
machine learning methodologies, we attempt to uncover distinctive linguistic
markers characteristic of multiple generations and create prediction models
that can consistently estimate the speaker's age group from various aspects.
This work contributes to our knowledge of sociolinguistic diversity throughout
the life of modern British speech.

</details>


### [80] [Unveiling Factors for Enhanced POS Tagging: A Study of Low-Resource Medieval Romance Languages](https://arxiv.org/abs/2506.17715)
*Matthias Schöffel,Esteban Garces Arias,Marinus Wiedner,Paula Ruppert,Meimingwei Li,Christian Heumann,Matthias Aßenmacher*

Main category: cs.CL

TL;DR: 本文研究了现代大语言模型（LLMs）在中世纪罗曼语系（如奥克语、西班牙语和法语）词性标注中的表现，探讨了其面临的独特挑战及解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在古语言处理中取得进展，但中世纪罗曼语系因历时语言演变、拼写变体和标注数据稀缺而面临挑战，需系统研究其词性标注性能。

Method: 通过实验评估微调方法、提示工程、模型架构、解码策略和跨语言迁移学习对标注准确性的影响。

Result: 结果显示LLMs在处理历史语言变体和非标准化拼写时存在局限，但也发现了一些有效的专门技术。

Conclusion: 研究为低资源历史语言的词性标注提供了有前景的解决方案，同时揭示了LLMs的局限性。

Abstract: Part-of-speech (POS) tagging remains a foundational component in natural
language processing pipelines, particularly critical for historical text
analysis at the intersection of computational linguistics and digital
humanities. Despite significant advancements in modern large language models
(LLMs) for ancient languages, their application to Medieval Romance languages
presents distinctive challenges stemming from diachronic linguistic evolution,
spelling variations, and labeled data scarcity. This study systematically
investigates the central determinants of POS tagging performance across diverse
corpora of Medieval Occitan, Medieval Spanish, and Medieval French texts,
spanning biblical, hagiographical, medical, and dietary domains. Through
rigorous experimentation, we evaluate how fine-tuning approaches, prompt
engineering, model architectures, decoding strategies, and cross-lingual
transfer learning techniques affect tagging accuracy. Our results reveal both
notable limitations in LLMs' ability to process historical language variations
and non-standardized spelling, as well as promising specialized techniques that
effectively address the unique challenges presented by low-resource historical
languages.

</details>


### [81] [KAG-Thinker: Teaching Large Language Models to Think with Human-like Reasoning Process](https://arxiv.org/abs/2506.17728)
*Dalong Zhang,Jun Xu,Jun Zhou,Lei Liang,Lin Yuan,Ling Zhong,Mengshu Sun,Peilong Zhao,QiWei Wang,Xiaorui Wang,Xinkai Du,YangYang Hou,Yu Ao,ZhaoYang Wang,Zhengke Gui,ZhiYing Yi,Zhongpu Bo*

Main category: cs.CL

TL;DR: KAG-Thinker是一个基于轻参数大语言模型（LLM）的类人推理框架，通过结构化思维过程提升问答任务中的逻辑一致性和上下文一致性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在领域特定知识库问答任务中逻辑和上下文一致性的问题，模拟人类认知机制处理复杂问题。

Method: 1. 广度分解复杂问题为独立子问题（逻辑形式）；2. 使用知识边界和深度解决模型优化知识检索；3. 通过监督微调对齐结构化推理范式。

Result: 提升了问答任务的逻辑一致性和知识检索的全面性。

Conclusion: KAG-Thinker通过结构化推理和知识边界优化，显著提升了LLM在复杂问答任务中的表现。

Abstract: In this paper, we introduce KAG-Thinker, a novel human-like reasoning
framework built upon a parameter-light large language model (LLM). Our approach
enhances the logical coherence and contextual consistency of the thinking
process in question-answering (Q\&A) tasks on domain-specific knowledge bases
(KBs) within LLMs. This framework simulates human cognitive mechanisms for
handling complex problems by establishing a structured thinking process.
Continuing the \textbf{Logical Form} guided retrieval and reasoning technology
route of KAG v0.7, firstly, it decomposes complex questions into independently
solvable sub-problems(also referred to as logical forms) through
\textbf{breadth decomposition}, each represented in two equivalent
forms-natural language and logical function-and further classified as either
Knowledge Retrieval or Reasoning Analysis tasks, with dependencies and
variables passing explicitly modeled via logical function interfaces. In the
solving process, the Retrieval function is used to perform knowledge retrieval
tasks, while the Math and Deduce functions are used to perform reasoning
analysis tasks. Secondly, it is worth noting that, in the Knowledge Retrieval
sub-problem tasks, LLMs and external knowledge sources are regarded as
equivalent KBs. We use the \textbf{knowledge boundary} model to determine the
optimal source using self-regulatory mechanisms such as confidence calibration
and reflective reasoning, and use the \textbf{depth solving} model to enhance
the comprehensiveness of knowledge acquisition. Finally, instead of utilizing
reinforcement learning, we employ supervised fine-tuning with multi-turn
dialogues to align the model with our structured inference paradigm, thereby
avoiding excessive reflection. This is supported by a data evaluation framework
and iterative corpus synthesis, which facilitate the generation of detailed
reasoning trajectories...

</details>


### [82] [HIDE and Seek: Detecting Hallucinations in Language Models via Decoupled Representations](https://arxiv.org/abs/2506.17748)
*Anwoy Chatterjee,Yash Goel,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 论文提出了一种名为HIDE的单次训练无关方法，通过解耦表示检测语言模型中的幻觉内容，优于现有单次方法，且在多任务中表现竞争力。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型生成的虚假内容（幻觉）难以检测，现有方法多依赖多次生成，计算成本高。

Method: 利用HSIC量化模型内部表示与生成输出的解耦程度，进行单次检测。

Result: 在四个QA数据集和六个开源模型上，HIDE在AUC-ROC上平均提升29%，计算时间减少51%。

Conclusion: HIDE通过解耦表示实现了高效实用的幻觉检测，性能优于现有方法。

Abstract: Contemporary Language Models (LMs), while impressively fluent, often generate
content that is factually incorrect or unfaithful to the input context - a
critical issue commonly referred to as 'hallucination'. This tendency of LMs to
generate hallucinated content undermines their reliability, especially because
these fabrications are often highly convincing and therefore difficult to
detect. While several existing methods attempt to detect hallucinations, most
rely on analyzing multiple generations per input, leading to increased
computational cost and latency. To address this, we propose a single-pass,
training-free approach for effective Hallucination detectIon via Decoupled
rEpresentations (HIDE). Our approach leverages the hypothesis that
hallucinations result from a statistical decoupling between an LM's internal
representations of input context and its generated output. We quantify this
decoupling using the Hilbert-Schmidt Independence Criterion (HSIC) applied to
hidden-state representations extracted while generating the output sequence. We
conduct extensive experiments on four diverse question answering datasets,
evaluating both faithfulness and factuality hallucinations across six
open-source LMs of varying scales and properties. Our results demonstrate that
HIDE outperforms other single-pass methods in almost all settings, achieving an
average relative improvement of ~29% in AUC-ROC over the best-performing
single-pass strategy across various models and datasets. Additionally, HIDE
shows competitive and often superior performance with multi-pass
state-of-the-art methods, obtaining an average relative improvement of ~3% in
AUC-ROC while consuming ~51% less computation time. Our findings highlight the
effectiveness of exploiting internal representation decoupling in LMs for
efficient and practical hallucination detection.

</details>


### [83] [Multilingual Tokenization through the Lens of Indian Languages: Challenges and Insights](https://arxiv.org/abs/2506.17789)
*N J Karthika,Maharaj Brahma,Rohit Saluja,Ganesh Ramakrishnan,Maunendra Sankar Desarkar*

Main category: cs.CL

TL;DR: 本文评估了17种印度语言的标记化策略，探讨了BPE和Unigram LM算法的权衡、词汇量影响及多语言词汇构建方法，提出低资源语言可从高资源语言标记器中受益。


<details>
  <summary>Details</summary>
Motivation: 现有标记器偏向高资源语言，限制了其在印度次大陆等语言多样性高、形态丰富的语言中的效果。

Method: 通过内在评估比较了BPE和Unigram LM算法，分析了词汇量影响，并探讨了联合与基于集群的多语言词汇构建策略。

Result: 研究表明，低资源语言可从相关高资源语言的标记器中受益。

Conclusion: 研究为构建更公平、高效且语言信息丰富的多语言NLP标记器提供了实用见解。

Abstract: Tokenization plays a pivotal role in multilingual NLP. However, existing
tokenizers are often skewed towards high-resource languages, limiting their
effectiveness for linguistically diverse and morphologically rich languages
such as those in the Indian subcontinent. This paper presents a comprehensive
intrinsic evaluation of tokenization strategies across 17 Indian languages. We
quantify the trade-offs between bottom-up and top-down tokenizer algorithms
(BPE and Unigram LM), effects of vocabulary sizes, and compare strategies of
multilingual vocabulary construction such as joint and cluster-based training.
We also show that extremely low-resource languages can benefit from tokenizers
trained on related high-resource languages. Our study provides practical
insights for building more fair, efficient, and linguistically informed
tokenizers for multilingual NLP.

</details>


### [84] [THCM-CAL: Temporal-Hierarchical Causal Modelling with Conformal Calibration for Clinical Risk Prediction](https://arxiv.org/abs/2506.17844)
*Xin Zhang,Qiyu Wei,Yingjie Zhu,Fanyi Wu,Sophia Ananiadou*

Main category: cs.CL

TL;DR: THCM-CAL提出了一种结合结构化和非结构化医疗数据的时序层次因果模型，通过因果发现和多标签校准提升临床风险预测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分捕捉医疗记录中诊断代码和叙述性笔记之间的因果交互作用，限制了风险预测的准确性。

Method: 构建多模态因果图，通过层次因果发现推断三种临床交互作用，并扩展共形预测以校准多标签ICD编码。

Result: 在MIMIC-III和MIMIC-IV数据集上，THCM-CAL表现出优越性能。

Conclusion: THCM-CAL通过建模多模态因果交互和校准预测，显著提升了临床风险预测的可靠性。

Abstract: Automated clinical risk prediction from electronic health records (EHRs)
demands modeling both structured diagnostic codes and unstructured narrative
notes. However, most prior approaches either handle these modalities separately
or rely on simplistic fusion strategies that ignore the directional,
hierarchical causal interactions by which narrative observations precipitate
diagnoses and propagate risk across admissions. In this paper, we propose
THCM-CAL, a Temporal-Hierarchical Causal Model with Conformal Calibration. Our
framework constructs a multimodal causal graph where nodes represent clinical
entities from two modalities: Textual propositions extracted from notes and ICD
codes mapped to textual descriptions. Through hierarchical causal discovery,
THCM-CAL infers three clinically grounded interactions: intra-slice
same-modality sequencing, intra-slice cross-modality triggers, and inter-slice
risk propagation. To enhance prediction reliability, we extend conformal
prediction to multi-label ICD coding, calibrating per-code confidence intervals
under complex co-occurrences. Experimental results on MIMIC-III and MIMIC-IV
demonstrate the superiority of THCM-CAL.

</details>


### [85] [LLMs for Customized Marketing Content Generation and Evaluation at Scale](https://arxiv.org/abs/2506.17863)
*Haoran Liu,Amir Tahmasbi,Ehtesham Sam Haque,Purak Jain*

Main category: cs.CL

TL;DR: 论文提出MarketingFM系统，通过多数据源生成关键词广告文案，提升点击率和成本效率，并开发AutoEval系统自动化评估广告质量。


<details>
  <summary>Details</summary>
Motivation: 当前站外营销内容过于模板化且与落地页不匹配，限制了效果。

Method: 提出MarketingFM系统整合多数据源生成关键词广告文案，并通过AutoEval系统结合规则和LLM技术自动化评估。

Result: 关键词广告文案点击率提升9%，展示量增加12%，成本降低0.38%；AutoEval系统与人工评估一致率达89.57%。

Conclusion: 系统显著提升广告效果，但需人工监督以确保评估质量。

Abstract: Offsite marketing is essential in e-commerce, enabling businesses to reach
customers through external platforms and drive traffic to retail websites.
However, most current offsite marketing content is overly generic,
template-based, and poorly aligned with landing pages, limiting its
effectiveness. To address these limitations, we propose MarketingFM, a
retrieval-augmented system that integrates multiple data sources to generate
keyword-specific ad copy with minimal human intervention. We validate
MarketingFM via offline human and automated evaluations and large-scale online
A/B tests. In one experiment, keyword-focused ad copy outperformed templates,
achieving up to 9% higher CTR, 12% more impressions, and 0.38% lower CPC,
demonstrating gains in ad ranking and cost efficiency. Despite these gains,
human review of generated ads remains costly. To address this, we propose
AutoEval-Main, an automated evaluation system that combines rule-based metrics
with LLM-as-a-Judge techniques to ensure alignment with marketing principles.
In experiments with large-scale human annotations, AutoEval-Main achieved
89.57% agreement with human reviewers. Building on this, we propose
AutoEval-Update, a cost-efficient LLM-human collaborative framework to
dynamically refine evaluation prompts and adapt to shifting criteria with
minimal human input. By selectively sampling representative ads for human
review and using a critic LLM to generate alignment reports, AutoEval-Update
improves evaluation consistency while reducing manual effort. Experiments show
the critic LLM suggests meaningful refinements, improving LLM-human agreement.
Nonetheless, human oversight remains essential for setting thresholds and
validating refinements before deployment.

</details>


### [86] [QueueEDIT: Structural Self-Correction for Sequential Model Editing in LLMs](https://arxiv.org/abs/2506.17864)
*Taolin Zhang,Haidong Kang,Dongyang Li,Qizhou Chen,Chengyu Wang Xiaofeng He,Richang Hong*

Main category: cs.CL

TL;DR: QueueEDIT框架通过队列机制和动态参数对齐，提升了序列模型编辑（SME）的性能，同时减少了参数偏差对LLM通用能力的影响。


<details>
  <summary>Details</summary>
Motivation: 解决序列模型编辑（SME）中因参数引入导致的LLM通用能力下降问题。

Method: 提出基于队列的自校正框架（QueueEDIT），包括结构映射编辑损失和动态参数对齐机制。

Result: 在多种SME设置中显著优于基线，同时保持单次编辑的竞争力，且LLM在通用NLP任务中表现稳定。

Conclusion: QueueEDIT有效平衡了SME性能和LLM通用能力，为模型编辑提供了新思路。

Abstract: Recently, large language models (LLMs) have demonstrated impressive results
but still suffer from hallucinations. Model editing has been proposed to
correct factual inaccuracies in LLMs. A challenging case is sequential model
editing (SME), which aims to rectify errors continuously rather than treating
them as a one-time task. During SME, the general capabilities of LLMs can be
negatively affected due to the introduction of new parameters. In this paper,
we propose a queue-based self-correction framework (QueueEDIT) that not only
enhances SME performance by addressing long-sequence dependency but also
mitigates the impact of parameter bias on the general capabilities of LLMs.
Specifically, we first introduce a structural mapping editing loss to map the
triplets to the knowledge-sensitive neurons within the Transformer layers of
LLMs. We then store the located parameters for each piece of edited knowledge
in a queue and dynamically align previously edited parameters. In each edit, we
select queue parameters most relevant to the currently located parameters to
determine whether previous knowledge needs realignment. Irrelevant parameters
in the queue are frozen, and we update the parameters at the queue head to the
LLM to ensure they do not harm general abilities. Experiments show that our
framework significantly outperforms strong baselines across various SME
settings and maintains competitiveness in single-turn editing. The resulting
LLMs also preserve high capabilities in general NLP tasks throughout the SME
process.

</details>


### [87] [How Alignment Shrinks the Generative Horizon](https://arxiv.org/abs/2506.17871)
*Chenghao Yang,Ari Holtzman*

Main category: cs.CL

TL;DR: 论文研究了大型语言模型（LLM）生成输出缺乏多样性的原因，提出了一种称为分支因子（BF）的量化指标，发现对齐调优显著降低了BF，解释了模型生成稳定性的来源。


<details>
  <summary>Details</summary>
Motivation: 研究对齐LLM生成输出缺乏多样性的原因，探索概率集中现象及其影响。

Method: 引入分支因子（BF）作为量化指标，分析生成过程中BF的变化及对齐调优对BF的影响。

Result: 发现BF随生成过程降低，对齐调优显著减少BF；对齐思维链（CoT）模型通过延长推理链利用低BF阶段提升稳定性。

Conclusion: BF是理解和控制LLM输出的有效工具，揭示了对齐调优和CoT对生成稳定性的作用。

Abstract: Despite their impressive capabilities, aligned large language models (LLMs)
often generate outputs that lack diversity. What drives this stability in the
generation? We investigate this phenomenon through the lens of probability
concentration in the model's output distribution. To quantify this
concentration, we introduce the Branching Factor (BF) -- a token-invariant
measure of the effective number of plausible next steps during generation. Our
empirical analysis reveals two key findings: (1) BF often decreases as
generation progresses, suggesting that LLMs become more predictable as they
generate. (2) alignment tuning substantially sharpens the model's output
distribution from the outset, reducing BF by nearly an order of magnitude
(e.g., from 12 to 1.2) relative to base models. This stark reduction helps
explain why aligned models often appear less sensitive to decoding strategies.
Building on this insight, we find this stability has surprising implications
for complex reasoning. Aligned Chain-of-Thought (CoT) models (e.g.,
DeepSeek-distilled models), for instance, leverage this effect; by generating
longer reasoning chains, they push generation into later, more deterministic
(lower BF) stages, resulting in more stable outputs. We hypothesize that
alignment tuning does not fundamentally change a model's behavior, but instead
steers it toward stylistic tokens (e.g., "Sure") that unlock low-entropy
trajectories already present in the base model. This view is supported by
nudging experiments, which show that prompting base models with such tokens can
similarly reduce BF. Together, our findings establish BF as a powerful
diagnostic for understanding and controlling LLM outputs - clarifying how
alignment reduces variability, how CoT promotes stable generations, and how
base models can be steered away from diversity.

</details>


### [88] [Multi-turn Jailbreaking via Global Refinement and Active Fabrication](https://arxiv.org/abs/2506.17881)
*Hua Tang,Lingyong Yan,Yukun Zhao,Shuaiqiang Wang,Jizhou Huang,Dawei Yin*

Main category: cs.CL

TL;DR: 提出了一种新的多轮越狱方法，通过全局优化和主动伪造模型响应，提高了在复杂对话中引发有害内容的能力。


<details>
  <summary>Details</summary>
Motivation: 现有越狱技术主要关注单轮场景，多轮场景下难以适应对话动态变化，存在安全风险。

Method: 提出多轮越狱方法，每轮交互全局优化越狱路径，并主动伪造模型响应以抑制安全警告。

Result: 实验表明，该方法在六种先进LLMs中优于现有单轮和多轮越狱技术。

Conclusion: 该方法有效提升了多轮对话中的越狱能力，为LLMs安全研究提供了新方向。

Abstract: Large Language Models (LLMs) have achieved exceptional performance across a
wide range of tasks. However, they still pose significant safety risks due to
the potential misuse for malicious purposes. Jailbreaks, which aim to elicit
models to generate harmful content, play a critical role in identifying the
underlying security threats. Recent jailbreaking primarily focuses on
single-turn scenarios, while the more complicated multi-turn scenarios remain
underexplored. Moreover, existing multi-turn jailbreaking techniques struggle
to adapt to the evolving dynamics of dialogue as the interaction progresses. To
address this limitation, we propose a novel multi-turn jailbreaking method that
refines the jailbreaking path globally at each interaction. We also actively
fabricate model responses to suppress safety-related warnings, thereby
increasing the likelihood of eliciting harmful outputs in subsequent questions.
Experimental results demonstrate the superior performance of our method
compared with existing single-turn and multi-turn jailbreaking techniques
across six state-of-the-art LLMs. Our code is publicly available at
https://github.com/Ytang520/Multi-Turn_jailbreaking_Global-Refinment_and_Active-Fabrication.

</details>


### [89] [Scatter-Based Innovation Propagation in Large Language Models for Multi-Stage Process Adaptation](https://arxiv.org/abs/2506.17949)
*Hong Su*

Main category: cs.CL

TL;DR: 论文提出了一种基于散射的创新扩展模型（innovation scatter model），帮助大语言模型（LLMs）将局部创新扩展到多阶段流程的其他部分。


<details>
  <summary>Details</summary>
Motivation: LLMs在重现和扩展预训练中观察到的模式方面表现出色，但在将局部创新推广到原始上下文之外时存在困难。

Method: 模型通过四步流程实现创新扩展：识别核心创新、泛化创新、判断适用范围、系统应用。

Result: 验证结果表明，该模型能有效帮助LLMs将创新扩展到结构相似的阶段，提升泛化和重用能力。

Conclusion: 创新散射模型通过利用阶段间的结构冗余，显著提升了LLMs的创新扩展能力。

Abstract: Large Language Models (LLMs) exhibit strong capabilities in reproducing and
extending patterns observed during pretraining but often struggle to generalize
novel ideas beyond their original context. This paper addresses the challenge
of applying such localized innovations - introduced at a specific stage or
component - to other parts of a multi-stage process. We propose a scatter-based
innovation expansion model (innovation scatter model) that guides the LLM
through a four-step process: (1) identifying the core innovation by comparing
the user's input with its surrounding context, (2) generalizing the innovation
by removing references to specific stages or components, (3) determining
whether the generalized innovation applies to a broader scope beyond the
original stage, and (4) systematically applying it to other structurally
similar stages using the LLM. This model leverages structural redundancy across
stages to improve the applicability of novel ideas. Verification results
demonstrate that the innovation scatter model enables LLMs to extend
innovations across structurally similar stages, thereby enhancing
generalization and reuse.

</details>


### [90] [A Comprehensive Graph Framework for Question Answering with Mode-Seeking Preference Alignment](https://arxiv.org/abs/2506.17951)
*Quanwei Tang,Sophia Yat Mei Lee,Junshuang Wu,Dong Zhang,Shoushan Li,Erik Cambria,Guodong Zhou*

Main category: cs.CL

TL;DR: GraphMPA是一个基于图的框架，通过模式寻求偏好对齐提升检索增强生成（RAG）的全局理解和伦理对齐。


<details>
  <summary>Details</summary>
Motivation: 解决RAG在全局理解和伦理对齐方面的挑战。

Method: 构建分层文档图，模拟人类认知过程，并引入模式寻求偏好优化。

Result: 在六个数据集上验证了GraphMPA的有效性。

Conclusion: GraphMPA通过图结构和偏好优化显著提升了RAG的性能和对齐能力。

Abstract: Recent advancements in retrieval-augmented generation (RAG) have enhanced
large language models in question answering by integrating external knowledge.
However, challenges persist in achieving global understanding and aligning
responses with human ethical and quality preferences. To address these issues,
we propose GraphMPA, a comprehensive graph-based framework with mode-seeking
preference alignment. Our approach constructs a hierarchical document graph
using a general similarity measurement, mimicking human cognitive processes for
information understanding and synthesis. Additionally, we introduce
mode-seeking preference optimization to better align model outputs with human
preferences through probability-matching constraints. Extensive experiments on
six datasets demonstrate the effectiveness of our
\href{https://github.com/tangquanwei/GraphMPA}{GraphMPA}.

</details>


### [91] [PDF Retrieval Augmented Question Answering](https://arxiv.org/abs/2506.18027)
*Thi Thu Uyen Hoang,Viet Anh Nguyen*

Main category: cs.CL

TL;DR: 提出了一种基于RAG框架的QA系统，用于从PDF中提取多模态信息，解决了现有系统对非文本内容处理的不足。


<details>
  <summary>Details</summary>
Motivation: PDF中丰富多样的数据（如文本、图像、图表等）对现有QA系统提出了挑战，需要一种能处理多模态查询的解决方案。

Method: 通过改进RAG框架对非文本内容的处理和集成，并微调大语言模型，构建了一个综合的QA系统。

Result: 实验证明该系统能准确提取PDF中的多模态信息，适用于不同类型的内容。

Conclusion: 该研究不仅拓展了检索增强QA系统的边界，还为多模态数据集成和处理的研究奠定了基础。

Abstract: This paper presents an advancement in Question-Answering (QA) systems using a
Retrieval Augmented Generation (RAG) framework to enhance information
extraction from PDF files. Recognizing the richness and diversity of data
within PDFs--including text, images, vector diagrams, graphs, and tables--poses
unique challenges for existing QA systems primarily designed for textual
content. We seek to develop a comprehensive RAG-based QA system that will
effectively address complex multimodal questions, where several data types are
combined in the query. This is mainly achieved by refining approaches to
processing and integrating non-textual elements in PDFs into the RAG framework
to derive precise and relevant answers, as well as fine-tuning large language
models to better adapt to our system. We provide an in-depth experimental
evaluation of our solution, demonstrating its capability to extract accurate
information that can be applied to different types of content across PDFs. This
work not only pushes the boundaries of retrieval-augmented QA systems but also
lays a foundation for further research in multimodal data integration and
processing.

</details>


### [92] [Splitformer: An improved early-exit architecture for automatic speech recognition on edge devices](https://arxiv.org/abs/2506.18035)
*Maxence Lasbordes,Daniele Falavigna,Alessio Brutti*

Main category: cs.CL

TL;DR: 论文提出了一种在早期退出模型中引入并行层处理降采样输入的方法，显著提升了语音识别性能，同时仅略微增加模型参数，不影响推理时间。


<details>
  <summary>Details</summary>
Motivation: 在设备端处理场景中，动态调整神经网络计算负载至关重要。早期退出架构虽有效，但缺乏模块化设计，无法与降采样操作结合。

Method: 在架构中引入并行层处理降采样输入，结合标准处理层，提升性能。

Result: 在标准语音识别基准测试中性能显著提升，模型参数略有增加，但推理时间不受影响。

Conclusion: 提出的方法有效结合了早期退出和降采样技术，为资源受限场景提供了高效解决方案。

Abstract: The ability to dynamically adjust the computational load of neural models
during inference in a resource aware manner is crucial for on-device processing
scenarios, characterised by limited and time-varying computational resources.
Early-exit architectures represent an elegant and effective solution, since
they can process the input with a subset of their layers, exiting at
intermediate branches (the upmost layers are hence removed from the model).
  From a different perspective, for automatic speech recognition applications
there are memory-efficient neural architectures that apply variable frame rate
analysis, through downsampling/upsampling operations in the middle layers,
reducing the overall number of operations and improving significantly the
performance on well established benchmarks. One example is the Zipformer.
However, these architectures lack the modularity necessary to inject early-exit
branches.
  With the aim of improving the performance in early-exit models, we propose
introducing parallel layers in the architecture that process downsampled
versions of their inputs. % in conjunction with standard processing layers. We
show that in this way the speech recognition performance on standard benchmarks
significantly improve, at the cost of a small increase in the overall number of
model parameters but without affecting the inference time.

</details>


### [93] [Markov-Enhanced Clustering for Long Document Summarization: Tackling the 'Lost in the Middle' Challenge with Large Language Models](https://arxiv.org/abs/2506.18036)
*Aziz Amari,Mohamed Achref Ben Ammar*

Main category: cs.CL

TL;DR: 提出了一种结合提取式和生成式摘要的混合方法，通过分块、聚类和马尔可夫链图生成更有效的摘要。


<details>
  <summary>Details</summary>
Motivation: 解决生成式摘要在大文档中关键信息丢失的问题。

Method: 将文档分块、聚类向量嵌入，为每个聚类生成摘要，并通过马尔可夫链图选择语义顺序。

Result: 生成更连贯且保留关键信息的摘要。

Conclusion: 混合方法有效解决了生成式摘要的局限性。

Abstract: The rapid expansion of information from diverse sources has heightened the
need for effective automatic text summarization, which condenses documents into
shorter, coherent texts. Summarization methods generally fall into two
categories: extractive, which selects key segments from the original text, and
abstractive, which generates summaries by rephrasing the content coherently.
Large language models have advanced the field of abstractive summarization, but
they are resourceintensive and face significant challenges in retaining key
information across lengthy documents, which we call being "lost in the middle".
To address these issues, we propose a hybrid summarization approach that
combines extractive and abstractive techniques. Our method splits the document
into smaller text chunks, clusters their vector embeddings, generates a summary
for each cluster that represents a key idea in the document, and constructs the
final summary by relying on a Markov chain graph when selecting the semantic
order of ideas.

</details>


### [94] [Statistical Multicriteria Evaluation of LLM-Generated Text](https://arxiv.org/abs/2506.18082)
*Esteban Garces Arias,Hannah Blocher,Julian Rodemann,Matthias Aßenmacher,Christoph Jansen*

Main category: cs.CL

TL;DR: 本文提出了一种基于广义随机优势（GSD）的框架，用于评估LLM生成文本的质量，解决了现有方法在单指标评估、指标与人类判断不兼容以及缺乏统计推断保证方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前评估LLM生成文本质量的方法往往依赖单一指标或简单聚合，无法全面捕捉文本质量的多维度特性（如连贯性、多样性、流畅性等）。

Method: 采用广义随机优势（GSD）框架，通过部分排序解码策略，避免对多个质量指标的任意加权，同时支持跨维度评估。

Result: 应用该框架评估常见解码策略与人类生成文本的对比，能够识别统计显著的性能差异，并考虑采样设计的非独立性假设。

Conclusion: GSD框架为LLM生成文本的质量评估提供了一种更全面、统计可靠的方法，解决了现有方法的局限性。

Abstract: Assessing the quality of LLM-generated text remains a fundamental challenge
in natural language processing. Current evaluation approaches often rely on
isolated metrics or simplistic aggregations that fail to capture the nuanced
trade-offs between coherence, diversity, fluency, and other relevant indicators
of text quality. In this work, we adapt a recently proposed framework for
statistical inference based on Generalized Stochastic Dominance (GSD) that
addresses three critical limitations in existing benchmarking methodologies:
the inadequacy of single-metric evaluation, the incompatibility between
cardinal automatic metrics and ordinal human judgments, and the lack of
inferential statistical guarantees. The GSD-front approach enables simultaneous
evaluation across multiple quality dimensions while respecting their different
measurement scales, building upon partial orders of decoding strategies, thus
avoiding arbitrary weighting of the involved metrics. By applying this
framework to evaluate common decoding strategies against human-generated text,
we demonstrate its ability to identify statistically significant performance
differences while accounting for potential deviations from the i.i.d.
assumption of the sampling design.

</details>


### [95] [Evaluating Prompt-Based and Fine-Tuned Approaches to Czech Anaphora Resolution](https://arxiv.org/abs/2506.18091)
*Patrik Stano,Aleš Horák*

Main category: cs.CL

TL;DR: 本文比较了两种现代方法在捷克语指代消解中的表现：基于提示工程的大语言模型（LLMs）和微调的紧凑生成模型。实验表明，微调模型（如mT5-large）显著优于提示方法，达到88%的准确率。


<details>
  <summary>Details</summary>
Motivation: 捷克语等形态丰富的语言中，指代消解对自然语言理解至关重要。本文旨在比较两种现代方法的性能。

Method: 使用Prague Dependency Treebank数据集，评估了指令调优的LLMs（如Mistral Large 2和Llama 3）和微调的mT5、Mistral模型。

Result: 微调模型（如mT5-large）表现最佳，准确率达88%，优于提示方法的74.5%。

Conclusion: 微调模型在捷克语指代消解中更具优势，尤其在准确率和计算资源需求方面。

Abstract: Anaphora resolution plays a critical role in natural language understanding,
especially in morphologically rich languages like Czech. This paper presents a
comparative evaluation of two modern approaches to anaphora resolution on Czech
text: prompt engineering with large language models (LLMs) and fine-tuning
compact generative models. Using a dataset derived from the Prague Dependency
Treebank, we evaluate several instruction-tuned LLMs, including Mistral Large 2
and Llama 3, using a series of prompt templates. We compare them against
fine-tuned variants of the mT5 and Mistral models that we trained specifically
for Czech anaphora resolution. Our experiments demonstrate that while prompting
yields promising few-shot results (up to 74.5% accuracy), the fine-tuned
models, particularly mT5-large, outperform them significantly, achieving up to
88% accuracy while requiring fewer computational resources. We analyze
performance across different anaphora types, antecedent distances, and source
corpora, highlighting key strengths and trade-offs of each approach.

</details>


### [96] [InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating](https://arxiv.org/abs/2506.18102)
*Fuyu Wang,Jiangtong Li,Kun Zhu,Changjun Jiang*

Main category: cs.CL

TL;DR: 提出了一种双组件框架（InspireScore和InspireDebate），用于改进基于LLM的辩论系统，通过多维评估和优化方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM辩论系统缺乏对真实性和逻辑有效性等客观评估，且缺乏结构化优化方法，限制了其效果。

Method: 1. InspireScore：多维评估系统，结合主观和客观指标；2. InspireDebate：通过CoT推理增强、多维DPO和Web-RAG优化辩论框架。

Result: InspireScore与专家判断的相关性提高44%，InspireDebate性能优于基线模型57%。

Conclusion: 该框架有效解决了现有辩论系统的局限性，显著提升了评估和辩论性能。

Abstract: With the rapid advancements in large language models (LLMs), debating tasks,
such as argument quality assessment and debate process simulation, have made
significant progress. However, existing LLM-based debating systems focus on
responding to specific arguments while neglecting objective assessments such as
authenticity and logical validity. Furthermore, these systems lack a structured
approach to optimize across various dimensions$-$including evaluation metrics,
chain-of-thought (CoT) reasoning, and multi-turn debate refinement$-$thereby
limiting their effectiveness. To address these interconnected challenges, we
propose a dual-component framework: (1) $\textbf{InspireScore}$, a novel
evaluation system that establishes a multi-dimensional assessment architecture
incorporating four subjective criteria (emotional appeal, argument clarity,
argument arrangement, and topic relevance) alongside two objective metrics
(fact authenticity and logical validity); and (2) $\textbf{InspireDebate}$, an
optimized debating framework employing a phased optimization approach through
CoT reasoning enhancement, multi-dimensional Direct Preference Optimization
(DPO), and real-time knowledge grounding via web-based Retrieval Augmented
Generation (Web-RAG). Empirical evaluations demonstrate that
$\textbf{InspireScore}$ achieves 44$\%$ higher correlation with expert
judgments compared to existing methods, while $\textbf{InspireDebate}$ shows
significant improvements, outperforming baseline models by 57$\%$. Source code
is available at https://github.com/fywang12/InspireDebate.

</details>


### [97] [Chengyu-Bench: Benchmarking Large Language Models for Chinese Idiom Understanding and Use](https://arxiv.org/abs/2506.18105)
*Yicheng Fu,Zhemin Huang,Liuxin Yang,Yumeng Lu,Zhongdongming Dai*

Main category: cs.CL

TL;DR: Chengyu-Bench是一个针对中文成语的综合性基准测试，包含三项任务：情感分类、使用恰当性检测和开放式填空。测试发现，大语言模型在情感分类上表现优异，但在理解成语的文化和上下文细微差别方面仍有困难。


<details>
  <summary>Details</summary>
Motivation: 中文成语（成语）具有深厚的历史文化背景，其字面翻译常无法完全表达其含义，这对语言模型的理解和使用提出了挑战。现有基准测试任务较为单一，无法全面评估模型对成语的掌握程度。

Method: Chengyu-Bench包含三项任务：1）情感分类（正面或负面）；2）使用恰当性检测；3）开放式填空。测试集包含2,937个人工验证的例句，涵盖1,765个常见成语。

Result: 测试结果显示，大语言模型在情感分类任务上准确率超过95%，但在使用恰当性检测和开放式填空任务上分别仅为85%和40%。错误分析表明，模型对成语含义的理解存在根本性不足。

Conclusion: Chengyu-Bench表明，尽管大语言模型能够可靠地判断成语的情感倾向，但在掌握文化和上下文细微差别方面仍有显著不足。该基准测试和源代码已公开。

Abstract: Chinese idioms (Chengyu) are concise four-character expressions steeped in
history and culture, whose literal translations often fail to capture their
full meaning. This complexity makes them challenging for language models to
interpret and use correctly. Existing benchmarks focus on narrow tasks -
multiple-choice cloze tests, isolated translation, or simple paraphrasing. We
introduce Chengyu-Bench, a comprehensive benchmark featuring three tasks: (1)
Evaluative Connotation, classifying idioms as positive or negative; (2)
Appropriateness, detecting incorrect idiom usage in context; and (3) Open
Cloze, filling blanks in longer passages without options. Chengyu-Bench
comprises 2,937 human-verified examples covering 1,765 common idioms sourced
from diverse corpora. We evaluate leading LLMs and find they achieve over 95%
accuracy on Evaluative Connotation, but only ~85% on Appropriateness and ~40%
top-1 accuracy on Open Cloze. Error analysis reveals that most mistakes arise
from fundamental misunderstandings of idiom meanings. Chengyu-Bench
demonstrates that while LLMs can reliably gauge idiom sentiment, they still
struggle to grasp the cultural and contextual nuances essential for proper
usage. The benchmark and source code are available at:
https://github.com/sofyc/ChengyuBench.

</details>


### [98] [Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives](https://arxiv.org/abs/2506.18116)
*Batool Haider,Atmika Gorti,Aman Chadha,Manas Gaur*

Main category: cs.CL

TL;DR: 该论文提出了一种多跳问答框架（MHQA），用于检测大型语言模型（LLM）在心理健康领域中的交叉偏见，并评估了四种模型的偏见模式，同时提出了两种去偏见方法。


<details>
  <summary>Details</summary>
Motivation: 心理健康领域中的LLM可能传播偏见，加剧对边缘群体的伤害，但目前缺乏系统性检测交叉偏见的方法。

Method: 使用多跳问答框架（MHQA）分析IMHI数据集，通过系统标记（如年龄、种族、性别等）研究人口统计交叉点的偏见模式，并评估四种LLM。

Result: 发现LLM在情感、人口统计和心理健康条件方面存在系统性差异，MHQA方法优于传统方法，去偏见技术（如角色扮演模拟和显性偏见减少）实现了66-94%的偏见减少。

Conclusion: 研究揭示了LLM在心理健康领域中的偏见问题，并提供了可操作的见解，以促进公平的AI发展。

Abstract: Large Language Models (LLMs) in mental healthcare risk propagating biases
that reinforce stigma and harm marginalized groups. While previous research
identified concerning trends, systematic methods for detecting intersectional
biases remain limited. This work introduces a multi-hop question answering
(MHQA) framework to explore LLM response biases in mental health discourse. We
analyze content from the Interpretable Mental Health Instruction (IMHI) dataset
across symptom presentation, coping mechanisms, and treatment approaches. Using
systematic tagging across age, race, gender, and socioeconomic status, we
investigate bias patterns at demographic intersections. We evaluate four LLMs:
Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic
disparities across sentiment, demographics, and mental health conditions. Our
MHQA approach demonstrates superior detection compared to conventional methods,
identifying amplification points where biases magnify through sequential
reasoning. We implement two debiasing techniques: Roleplay Simulation and
Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot
prompting with BBQ dataset examples. These findings highlight critical areas
where LLMs reproduce mental healthcare biases, providing actionable insights
for equitable AI development.

</details>


### [99] [The Syntactic Acceptability Dataset (Preview): A Resource for Machine Learning and Linguistic Analysis of English](https://arxiv.org/abs/2506.18120)
*Tom S Juzek*

Main category: cs.CL

TL;DR: 介绍了Syntactic Acceptability Dataset，包含1000个英语序列，标注了语法状态和可接受性状态，是目前最大的公开数据集。初步分析显示语法性和可接受性判断在83%情况下一致，机器学习模型在预测可接受性上表现更好。


<details>
  <summary>Details</summary>
Motivation: 为语法和计算语言学研究设计资源，填补公开数据集的空白。

Method: 数据集包含1000个英语序列，来自教科书和期刊，标注语法状态和可接受性状态。通过众包获取可接受性数据。

Result: 语法性和可接受性判断83%一致，机器学习模型在预测可接受性上表现更优。

Conclusion: 数据集初步验证了语法性与可接受性的关系，未来将扩展数据集。

Abstract: We present a preview of the Syntactic Acceptability Dataset, a resource being
designed for both syntax and computational linguistics research. In its current
form, the dataset comprises 1,000 English sequences from the syntactic
discourse: Half from textbooks and half from the journal Linguistic Inquiry,
the latter to ensure a representation of the contemporary discourse. Each entry
is labeled with its grammatical status ("well-formedness" according to
syntactic formalisms) extracted from the literature, as well as its
acceptability status ("intuitive goodness" as determined by native speakers)
obtained through crowdsourcing, with highest experimental standards. Even in
its preliminary form, this dataset stands as the largest of its kind that is
publicly accessible. We also offer preliminary analyses addressing three
debates in linguistics and computational linguistics: We observe that
grammaticality and acceptability judgments converge in about 83% of the cases
and that "in-betweenness" occurs frequently. This corroborates existing
research. We also find that while machine learning models struggle with
predicting grammaticality, they perform considerably better in predicting
acceptability. This is a novel finding. Future work will focus on expanding the
dataset.

</details>


### [100] [$φ^{\infty}$: Clause Purification, Embedding Realignment, and the Total Suppression of the Em Dash in Autoregressive Language Models](https://arxiv.org/abs/2506.18129)
*Bugra Kilictas,Faruk Alpay*

Main category: cs.CL

TL;DR: 论文发现自回归Transformer语言模型中存在一个关键漏洞，即em dash（长破折号）标记会导致递归语义漂移，引发子句边界幻觉和嵌入空间纠缠。通过符号子句净化和嵌入矩阵重对齐的新方法，无需重新训练模型即可解决问题。


<details>
  <summary>Details</summary>
Motivation: 自回归Transformer语言模型在长文本生成中因em dash标记引发递归语义漂移，导致生成内容不一致和主题偏离，亟需解决方案。

Method: 结合符号子句净化（phi-infinity算子）和嵌入矩阵重对齐，抑制问题标记并保持语义连贯性。

Result: 实验验证表明，该方法显著提高了生成一致性和主题保持能力。

Conclusion: 研究为识别和缓解基础模型中的标记级漏洞提供了通用框架，对AI安全、模型对齐和大语言模型的稳健部署具有直接意义。

Abstract: We identify a critical vulnerability in autoregressive transformer language
models where the em dash token induces recursive semantic drift, leading to
clause boundary hallucination and embedding space entanglement. Through formal
analysis of token-level perturbations in semantic lattices, we demonstrate that
em dash insertion fundamentally alters the model's latent representations,
causing compounding errors in long-form generation. We propose a novel solution
combining symbolic clause purification via the phi-infinity operator with
targeted embedding matrix realignment. Our approach enables total suppression
of problematic tokens without requiring model retraining, while preserving
semantic coherence through fixed-point convergence guarantees. Experimental
validation shows significant improvements in generation consistency and topic
maintenance. This work establishes a general framework for identifying and
mitigating token-level vulnerabilities in foundation models, with immediate
implications for AI safety, model alignment, and robust deployment of large
language models in production environments. The methodology extends beyond
punctuation to address broader classes of recursive instabilities in neural
text generation systems.

</details>


### [101] [Sparse Feature Coactivation Reveals Composable Semantic Modules in Large Language Models](https://arxiv.org/abs/2506.18141)
*Ruixuan Deng,Xiaoyang Hu,Miles Gilberti,Shane Storks,Aman Taxali,Mike Angstadt,Chandra Sripada,Joyce Chai*

Main category: cs.CL

TL;DR: 通过稀疏自编码器（SAE）特征共激活识别LLM中的语义一致网络组件，展示了对国家和关系组件的操作如何改变模型输出。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLM）中知识的模块化组织，并开发高效、有针对性的模型操作方法。

Method: 使用稀疏自编码器（SAE）特征共激活分析LLM中的语义组件，通过消融和放大组件观察模型输出的变化。

Result: 国家和关系组件分别集中在早期和后期层，后期层节点对模型输出的因果影响更强。

Conclusion: LLM中的知识具有模块化组织，为高效模型操作提供了新方法。

Abstract: We identify semantically coherent, context-consistent network components in
large language models (LLMs) using coactivation of sparse autoencoder (SAE)
features collected from just a handful of prompts. Focusing on country-relation
tasks, we show that ablating semantic components for countries and relations
changes model outputs in predictable ways, while amplifying these components
induces counterfactual responses. Notably, composing relation and country
components yields compound counterfactual outputs. We find that, whereas most
country components emerge from the very first layer, the more abstract relation
components are concentrated in later layers. Furthermore, within relation
components themselves, nodes from later layers tend to have a stronger causal
impact on model outputs. Overall, these findings suggest a modular organization
of knowledge within LLMs and advance methods for efficient, targeted model
manipulation.

</details>


### [102] [QuranMorph: Morphologically Annotated Quranic Corpus](https://arxiv.org/abs/2506.18148)
*Diyam Akra,Tymaa Hammouda,Mustafa Jarrar*

Main category: cs.CL

TL;DR: QuranMorph是一个为《古兰经》构建的形态标注语料库，包含77,429个标记，由三位专家手动完成词形还原和词性标注。


<details>
  <summary>Details</summary>
Motivation: 构建一个高质量的《古兰经》形态标注语料库，以支持语言学研究和资源互联。

Method: 利用Qabas阿拉伯语词典数据库进行词形还原，并使用SAMA/Qabas细粒度词性标注集（40个标签）进行标注。

Result: QuranMorph语料库能够与多种语言资源互联，并已开源公开。

Conclusion: QuranMorph为《古兰经》研究提供了高质量的标注资源，并促进了语言学资源的互联互通。

Abstract: We present the QuranMorph corpus, a morphologically annotated corpus for the
Quran (77,429 tokens). Each token in the QuranMorph was manually lemmatized and
tagged with its part-of-speech by three expert linguists. The lemmatization
process utilized lemmas from Qabas, an Arabic lexicographic database linked
with 110 lexicons and corpora of 2 million tokens. The part-of-speech tagging
was performed using the fine-grained SAMA/Qabas tagset, which encompasses 40
tags. As shown in this paper, this rich lemmatization and POS tagset enabled
the QuranMorph corpus to be inter-linked with many linguistic resources. The
corpus is open-source and publicly available as part of the SinaLab resources
at (https://sina.birzeit.edu/quran)

</details>


### [103] [CareLab at #SMM4H-HeaRD 2025: Insomnia Detection and Food Safety Event Extraction with Domain-Aware Transformers](https://arxiv.org/abs/2506.18185)
*Zihan Liang,Ziwen Pan,Sumon Kanti Dey,Azra Ismail*

Main category: cs.CL

TL;DR: 本文介绍了在SMM4H-HeaRD 2025共享任务中的系统，重点分析了Task 5 Subtask 1的表现，使用RoBERTa和GPT-4数据增强取得了第一名的成绩。


<details>
  <summary>Details</summary>
Motivation: 解决临床笔记中失眠检测和新闻中食品安全事件提取的任务。

Method: 采用基于编码器的模型（如RoBERTa）和GPT-4进行数据增强。

Result: 在Task 5 Subtask 1中取得F1分数0.958，排名第一。

Conclusion: 提出的方法在特定任务中表现优异，尤其是数据增强和模型架构的优化。

Abstract: This paper presents our system for the SMM4H-HeaRD 2025 shared tasks,
specifically Task 4 (Subtasks 1, 2a, and 2b) and Task 5 (Subtasks 1 and 2).
Task 4 focused on detecting mentions of insomnia in clinical notes, while Task
5 addressed the extraction of food safety events from news articles. We
participated in all subtasks and report key findings across them, with
particular emphasis on Task 5 Subtask 1, where our system achieved strong
performance-securing first place with an F1 score of 0.958 on the test set. To
attain this result, we employed encoder-based models (e.g., RoBERTa), alongside
GPT-4 for data augmentation. This paper outlines our approach, including
preprocessing, model architecture, and subtask-specific adaptations

</details>


### [104] [Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review](https://arxiv.org/abs/2506.18199)
*Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 本文综述了针对阿拉伯和穆斯林文化偏见的提示工程技术，发现五种主要方法，其中结构化多步流程效果最佳。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在对阿拉伯和穆斯林的偏见，亟需研究有效的提示工程策略以减少这种偏见。

Method: 采用混合方法系统综述，遵循PRISMA指南和Kitchenham方法，分析2021-2024年的8项实证研究。

Result: 五种提示工程方法中，结构化多步流程效果最佳（偏见减少87.7%），但技术门槛较高；文化提示更易用但效果稍逊。

Conclusion: 提示工程可有效减少文化偏见，未来需开发适应性技术、专用评估资源，并与其他去偏方法结合。

Abstract: Large language models have demonstrated remarkable capabilities across
various domains, yet concerns about cultural bias - particularly towards Arabs
and Muslims - pose significant ethical challenges by perpetuating harmful
stereotypes and marginalization. Despite growing recognition of bias in LLMs,
prompt engineering strategies specifically addressing Arab and Muslim
representation remain understudied. This mixed-methods systematic review
examines such techniques, offering evidence-based guidance for researchers and
practitioners. Following PRISMA guidelines and Kitchenham's systematic review
methodology, we analyzed 8 empirical studies published between 2021-2024
investigating bias mitigation strategies. Our findings reveal five primary
prompt engineering approaches: cultural prompting, affective priming,
self-debiasing techniques, structured multi-step pipelines, and
parameter-optimized continuous prompts. Although all approaches show potential
for reducing bias, effectiveness varied substantially across studies and bias
types. Evidence suggests that certain bias types may be more resistant to
prompt-based mitigation than others. Structured multi-step pipelines
demonstrated the highest overall effectiveness, achieving up to 87.7% reduction
in bias, though they require greater technical expertise. Cultural prompting
offers broader accessibility with substantial effectiveness. These results
underscore the accessibility of prompt engineering for mitigating cultural bias
without requiring access to model parameters. The limited number of studies
identified highlights a significant research gap in this critical area. Future
research should focus on developing culturally adaptive prompting techniques,
creating Arab and Muslim-specific evaluation resources, and integrating prompt
engineering with complementary debiasing methods to address deeper stereotypes
while maintaining model utility.

</details>


### [105] [Deciphering Emotions in Children Storybooks: A Comparative Analysis of Multimodal LLMs in Educational Applications](https://arxiv.org/abs/2506.18201)
*Bushra Asseri,Estabraq Abdelaziz,Maha Al Mogren,Tayef Alhefdhi,Areej Al-Wabil*

Main category: cs.CL

TL;DR: 研究评估了GPT-4o和Gemini 1.5 Pro在阿拉伯语儿童故事书插图情感识别中的表现，发现GPT-4o优于Gemini，但两者在文化细微情感和模糊叙事背景下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 开发文化敏感的教育技术工具，填补阿拉伯语语境下情感识别研究的空白。

Method: 使用75张阿拉伯故事书插图，通过零样本、少样本和思维链提示策略评估模型，并与人类标注（基于Plutchik情感框架）对比。

Result: GPT-4o在所有条件下表现优于Gemini，最高宏F1分数为59%（思维链提示），而Gemini为43%。模型在文化细微情感和模糊叙事背景下错误率高。

Conclusion: 当前模型在文化理解上存在局限，需开发文化敏感的培训方法以支持阿拉伯语学习者的情感感知教育技术。

Abstract: Emotion recognition capabilities in multimodal AI systems are crucial for
developing culturally responsive educational technologies, yet remain
underexplored for Arabic language contexts where culturally appropriate
learning tools are critically needed. This study evaluates the emotion
recognition performance of two advanced multimodal large language models,
GPT-4o and Gemini 1.5 Pro, when processing Arabic children's storybook
illustrations. We assessed both models across three prompting strategies
(zero-shot, few-shot, and chain-of-thought) using 75 images from seven Arabic
storybooks, comparing model predictions with human annotations based on
Plutchik's emotional framework. GPT-4o consistently outperformed Gemini across
all conditions, achieving the highest macro F1-score of 59% with
chain-of-thought prompting compared to Gemini's best performance of 43%. Error
analysis revealed systematic misclassification patterns, with valence
inversions accounting for 60.7% of errors, while both models struggled with
culturally nuanced emotions and ambiguous narrative contexts. These findings
highlight fundamental limitations in current models' cultural understanding and
emphasize the need for culturally sensitive training approaches to develop
effective emotion-aware educational technologies for Arabic-speaking learners.

</details>


### [106] [Enhancing Entity Aware Machine Translation with Multi-task Learning](https://arxiv.org/abs/2506.18318)
*An Trieu,Phuong Nguyen,Minh Le Nguyen*

Main category: cs.CL

TL;DR: 提出了一种通过多任务学习优化实体识别和机器翻译子任务的方法，以提升实体感知机器翻译的性能。


<details>
  <summary>Details</summary>
Motivation: 实体感知机器翻译（EAMT）因缺乏相关翻译数据和上下文复杂性而具有挑战性。

Method: 采用多任务学习，同时优化实体识别和机器翻译两个子任务。

Result: 在SemEval 2025竞赛Task 2提供的数据集上进行了结果和分析。

Conclusion: 多任务学习方法有效提升了EAMT任务的性能。

Abstract: Entity-aware machine translation (EAMT) is a complicated task in natural
language processing due to not only the shortage of translation data related to
the entities needed to translate but also the complexity in the context needed
to process while translating those entities. In this paper, we propose a method
that applies multi-task learning to optimize the performance of the two
subtasks named entity recognition and machine translation, which improves the
final performance of the Entity-aware machine translation task. The result and
analysis are performed on the dataset provided by the organizer of Task 2 of
the SemEval 2025 competition.

</details>


### [107] [TranslationCorrect: A Unified Framework for Machine Translation Post-Editing with Predictive Error Assistance](https://arxiv.org/abs/2506.18337)
*Syed Mekael Wasti,Shou-Yi Hung,Christopher Collins,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: TranslationCorrect是一个集成框架，旨在优化机器翻译后编辑和研究数据收集的流程，结合了MT生成、错误预测和直观的后编辑界面，显著提高了效率和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 传统机器翻译后编辑和研究数据收集流程效率低下且分散，需要一种集成化的解决方案。

Method: TranslationCorrect整合了NLLB等MT模型生成、XCOMET或LLM API的错误预测，以及基于HCI原则的后编辑界面，支持批量翻译和高质量ESA格式标注。

Result: 用户研究表明，TranslationCorrect显著提升了翻译效率和用户满意度，优于传统标注方法。

Conclusion: TranslationCorrect为翻译和研究提供了高效、集成的解决方案，适用于MT和后期编辑系统的训练。

Abstract: Machine translation (MT) post-editing and research data collection often rely
on inefficient, disconnected workflows. We introduce TranslationCorrect, an
integrated framework designed to streamline these tasks. TranslationCorrect
combines MT generation using models like NLLB, automated error prediction using
models like XCOMET or LLM APIs (providing detailed reasoning), and an intuitive
post-editing interface within a single environment. Built with human-computer
interaction (HCI) principles in mind to minimize cognitive load, as confirmed
by a user study. For translators, it enables them to correct errors and batch
translate efficiently. For researchers, TranslationCorrect exports high-quality
span-based annotations in the Error Span Annotation (ESA) format, using an
error taxonomy inspired by Multidimensional Quality Metrics (MQM). These
outputs are compatible with state-of-the-art error detection models and
suitable for training MT or post-editing systems. Our user study confirms that
TranslationCorrect significantly improves translation efficiency and user
satisfaction over traditional annotation methods.

</details>


### [108] [Less Data Less Tokens: Multilingual Unification Learning for Efficient Test-Time Reasoning in LLMs](https://arxiv.org/abs/2506.18341)
*Kang Chen,Mengdi Zhang,Yixin Cao*

Main category: cs.CL

TL;DR: 论文提出了一种名为L²的多语言统一学习方法，通过解码干预策略提升大型语言模型（LLMs）在测试时的数据与推理效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在多语言推理中的多样性挑战，提升模型性能和效率。

Method: 采用L²方法，结合多语言数据（完整链式注释和语言混合步骤），并通过解码干预策略优化推理过程。

Result: 实验表明，少量数据即可显著提升推理能力，多语言学习减少了数据和推理令牌的需求，同时保持性能。

Conclusion: L²方法为LLMs的数据收集和测试时计算效率问题提供了有效解决方案。

Abstract: This paper explores the challenges of test-time scaling of large language
models (LLMs), regarding both the data and inference efficiency. We highlight
the diversity of multi-lingual reasoning based on our pilot studies, and then
introduce a novel approach, \(L^2\) multi-lingual unification learning with a
decoding intervention strategy for further investigation. The basic idea of
\(L^2\) is that the reasoning process varies across different languages, which
may be mutually beneficial to enhance both model performance and efficiency. In
specific, there are two types of multi-lingual data: the entire long
chain-of-thought annotations in different languages and the step-wise mixture
of languages. By further tuning based on them, we show that even small amounts
of data can significantly improve reasoning capabilities. Our findings suggest
that multilingual learning reduces both the required data and the number of
inference tokens while maintaining a comparable performance. Furthermore,
\(L^2\) is orthogonal to other data efficient methods. Thus, we also emphasize
the importance of diverse data selection. The \(L^2\) method offers a promising
solution to the challenges of data collection and test-time compute efficiency
in LLMs.

</details>


### [109] [Evaluating Causal Explanation in Medical Reports with LLM-Based and Human-Aligned Metrics](https://arxiv.org/abs/2506.18387)
*Yousang Cho,Key-Sun Choi*

Main category: cs.CL

TL;DR: 研究比较了六种评估指标在自动生成诊断报告中因果解释质量的准确性，发现GPT-Black表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探讨不同评估指标如何准确捕捉因果解释的质量，以优化自动生成诊断报告的评价方法。

Method: 比较BERTScore、Cosine Similarity、BioSentVec、GPT-White、GPT-Black和专家定性评估六种指标，采用两种加权策略。

Result: GPT-Black在识别逻辑连贯和临床有效的因果叙述方面表现最强，GPT-White与专家评估一致，相似性指标与临床推理质量不符。

Conclusion: 选择适当的评估指标和加权策略对结果有显著影响，支持在需要可解释性和因果推理的任务中使用基于LLM的评估。

Abstract: This study investigates how accurately different evaluation metrics capture
the quality of causal explanations in automatically generated diagnostic
reports. We compare six metrics: BERTScore, Cosine Similarity, BioSentVec,
GPT-White, GPT-Black, and expert qualitative assessment across two input types:
observation-based and multiple-choice-based report generation. Two weighting
strategies are applied: one reflecting task-specific priorities, and the other
assigning equal weights to all metrics. Our results show that GPT-Black
demonstrates the strongest discriminative power in identifying logically
coherent and clinically valid causal narratives. GPT-White also aligns well
with expert evaluations, while similarity-based metrics diverge from clinical
reasoning quality. These findings emphasize the impact of metric selection and
weighting on evaluation outcomes, supporting the use of LLM-based evaluation
for tasks requiring interpretability and causal reasoning.

</details>


### [110] [Lemmatization as a Classification Task: Results from Arabic across Multiple Genres](https://arxiv.org/abs/2506.18399)
*Mostafa Saeed,Nizar Habash*

Main category: cs.CL

TL;DR: 论文提出两种新方法，将词形还原视为分类任务，利用机器翻译和语义聚类，并引入新的阿拉伯语测试集。结果显示分类和聚类方法更稳健。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语等形态丰富的语言在词形还原工具上存在标准不一致和覆盖不足的问题，需要更有效的解决方案。

Method: 采用Lemma-POS-Gloss (LPG) 标签集的分类方法，结合机器翻译和语义聚类，并评估字符级序列到序列模型。

Result: 分类和聚类方法表现更稳健且可解释，字符级模型虽具竞争力但存在局限性。

Conclusion: 分类和聚类方法为阿拉伯语词形还原设定了新基准，优于传统序列模型。

Abstract: Lemmatization is crucial for NLP tasks in morphologically rich languages with
ambiguous orthography like Arabic, but existing tools face challenges due to
inconsistent standards and limited genre coverage. This paper introduces two
novel approaches that frame lemmatization as classification into a
Lemma-POS-Gloss (LPG) tagset, leveraging machine translation and semantic
clustering. We also present a new Arabic lemmatization test set covering
diverse genres, standardized alongside existing datasets. We evaluate character
level sequence-to-sequence models, which perform competitively and offer
complementary value, but are limited to lemma prediction (not LPG) and prone to
hallucinating implausible forms. Our results show that classification and
clustering yield more robust, interpretable outputs, setting new benchmarks for
Arabic lemmatization.

</details>


### [111] [TReB: A Comprehensive Benchmark for Evaluating Table Reasoning Capabilities of Large Language Models](https://arxiv.org/abs/2506.18421)
*Ce Li,Xiaofan Liu,Zhiyan Song,Ce Chi,Chen Zhao,Jingjing Yang,Zhendong Wang,Kexin Yang,Boshen Shi,Xing Wang,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 本文提出了一个全面的表格推理评估基准TReB，用于衡量大型语言模型（LLMs）在26个子任务中的表现，并构建了高质量数据集和评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准未能全面反映LLMs在表格推理任务中的表现，因此需要一个新的基准来填补这一空白。

Method: 通过迭代数据处理构建高质量数据集，并设计评估框架（TCoT、PoT、ICoT）来衡量LLMs的表格推理能力。

Result: 实验结果表明，现有LLMs在复杂表格任务中仍有显著改进空间。

Conclusion: TReB基准和评估框架为LLMs的表格推理能力提供了有效衡量工具，并公开了数据集和框架。

Abstract: The majority of data in businesses and industries is stored in tables,
databases, and data warehouses. Reasoning with table-structured data poses
significant challenges for large language models (LLMs) due to its hidden
semantics, inherent complexity, and structured nature. One of these challenges
is lacking an effective evaluation benchmark fairly reflecting the performances
of LLMs on broad table reasoning abilities. In this paper, we fill in this gap,
presenting a comprehensive table reasoning evolution benchmark, TReB, which
measures both shallow table understanding abilities and deep table reasoning
abilities, a total of 26 sub-tasks. We construct a high quality dataset through
an iterative data processing procedure. We create an evaluation framework to
robustly measure table reasoning capabilities with three distinct inference
modes, TCoT, PoT and ICoT. Further, we benchmark over 20 state-of-the-art LLMs
using this frame work and prove its effectiveness. Experimental results reveal
that existing LLMs still have significant room for improvement in addressing
the complex and real world Table related tasks. Both the dataset and evaluation
framework are publicly available, with the dataset hosted on [HuggingFace] and
the framework on [GitHub].

</details>


### [112] [MeRF: Motivation-enhanced Reinforcement Finetuning for Large Reasoning Models](https://arxiv.org/abs/2506.18485)
*Junjie Zhang,Guozheng Ma,Shunyu Liu,Haoyu Wang,Jiaxing Huang,Ting-En Lin,Fei Huang,Yongbin Li,Dacheng Tao*

Main category: cs.CL

TL;DR: 论文提出MeRF方法，通过将奖励规范直接注入提示中，结合强化学习和上下文学习能力，提升LLMs的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法忽视了LLMs的上下文学习能力，如CoT提示的成功所示，因此探索如何结合强化学习与上下文学习以提升LLMs的推理能力。

Method: MeRF方法通过将奖励规范注入提示，作为上下文动机，使模型在生成时优化目标明确。

Result: 在K&K逻辑谜题基准测试中，MeRF显著优于基线方法，且性能随动机与奖励函数一致性提升而提高。

Conclusion: MeRF通过结合上下文动机和外部奖励，有效提升了LLMs的推理能力，并展示了模型对误导性动机的适应能力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful learn-to-reason paradigm for Large Language Models (LLMs) to tackle
complex reasoning tasks. However, existing RLVR methods overlook one of the
most distinctive capabilities of LLMs, their in-context learning ability, as
prominently demonstrated by the success of Chain-of-Thought (CoT) prompting.
This motivates us to explore how reinforcement learning can be effectively
combined with in-context learning to better improve the reasoning capabilities
of LLMs. In this paper, we introduce Motivation-enhanced Reinforcement
Finetuning} (MeRF), an intuitive yet effective method enhancing reinforcement
learning of LLMs by involving ``telling LLMs the rules of the game''.
Specifically, MeRF directly injects the reward specification into the prompt,
which serves as an in-context motivation for model to improve its responses
with awareness of the optimization objective. This simple modification
leverages the in-context learning ability of LLMs aligning generation with
optimization, thereby incentivizing the model to generate desired outputs from
both inner motivation and external reward. Empirical evaluations on the Knights
and Knaves~(K&K) logic puzzle reasoning benchmark demonstrate that
\texttt{MeRF} achieves substantial performance gains over baselines. Moreover,
ablation studies show that performance improves with greater consistency
between the in-context motivation and the external reward function, while the
model also demonstrates an ability to adapt to misleading motivations through
reinforcement learning.

</details>


### [113] [Comparative Evaluation of ChatGPT and DeepSeek Across Key NLP Tasks: Strengths, Weaknesses, and Domain-Specific Performance](https://arxiv.org/abs/2506.18501)
*Wael Etaiwi,Bushra Alhijawi*

Main category: cs.CL

TL;DR: 该研究评估了ChatGPT和DeepSeek在五个NLP任务中的表现，发现DeepSeek在分类稳定性和逻辑推理上更优，而ChatGPT在需要细腻理解和灵活性的任务中表现更好。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）在NLP任务中的广泛应用，需要全面评估其在不同任务中的表现，以了解其优势和局限性。

Method: 采用结构化实验协议，使用相同的、中性的提示词，在两个基准数据集上测试ChatGPT和DeepSeek在五个NLP任务中的表现。

Result: DeepSeek在分类稳定性和逻辑推理上表现更优，而ChatGPT在需要细腻理解和灵活性的任务中更胜一筹。

Conclusion: 研究结果为根据任务需求选择合适的LLM提供了有价值的参考。

Abstract: The increasing use of large language models (LLMs) in natural language
processing (NLP) tasks has sparked significant interest in evaluating their
effectiveness across diverse applications. While models like ChatGPT and
DeepSeek have shown strong results in many NLP domains, a comprehensive
evaluation is needed to understand their strengths, weaknesses, and
domain-specific abilities. This is critical as these models are applied to
various tasks, from sentiment analysis to more nuanced tasks like textual
entailment and translation. This study aims to evaluate ChatGPT and DeepSeek
across five key NLP tasks: sentiment analysis, topic classification, text
summarization, machine translation, and textual entailment. A structured
experimental protocol is used to ensure fairness and minimize variability. Both
models are tested with identical, neutral prompts and evaluated on two
benchmark datasets per task, covering domains like news, reviews, and
formal/informal texts. The results show that DeepSeek excels in classification
stability and logical reasoning, while ChatGPT performs better in tasks
requiring nuanced understanding and flexibility. These findings provide
valuable insights for selecting the appropriate LLM based on task requirements.

</details>


### [114] [End-to-End Spoken Grammatical Error Correction](https://arxiv.org/abs/2506.18532)
*Mengjie Qian,Rao Ma,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 论文探讨了端到端（E2E）框架在口语语法纠错（SGEC）和反馈生成中的应用，比较了级联、部分级联和E2E架构，并提出自动伪标注和对齐方法以提升性能。


<details>
  <summary>Details</summary>
Motivation: 口语语法纠错（SGEC）因语音不流畅和转录错误等问题面临挑战，传统级联系统易受模块间错误传播影响，因此研究E2E框架以优化性能。

Method: 基于Whisper模型，比较级联、部分级联和E2E架构；提出自动伪标注扩充数据，利用上下文信息改进ASR输出，并设计参考对齐和编辑置信度估计方法。

Result: 实验表明，所提方法显著提升了E2E SGEC在Linguaskill和Speak & Improve语料库上的性能。

Conclusion: E2E框架结合伪标注、对齐和置信度估计能有效提升SGEC系统性能，为口语学习者提供更精准的反馈。

Abstract: Grammatical Error Correction (GEC) and feedback play a vital role in
supporting second language (L2) learners, educators, and examiners. While
written GEC is well-established, spoken GEC (SGEC), aiming to provide feedback
based on learners' speech, poses additional challenges due to disfluencies,
transcription errors, and the lack of structured input. SGEC systems typically
follow a cascaded pipeline consisting of Automatic Speech Recognition (ASR),
disfluency detection, and GEC, making them vulnerable to error propagation
across modules. This work examines an End-to-End (E2E) framework for SGEC and
feedback generation, highlighting challenges and possible solutions when
developing these systems. Cascaded, partial-cascaded and E2E architectures are
compared, all built on the Whisper foundation model. A challenge for E2E
systems is the scarcity of GEC labeled spoken data. To address this, an
automatic pseudo-labeling framework is examined, increasing the training data
from 77 to over 2500 hours. To improve the accuracy of the SGEC system,
additional contextual information, exploiting the ASR output, is investigated.
Candidate feedback of their mistakes is an essential step to improving
performance. In E2E systems the SGEC output must be compared with an estimate
of the fluent transcription to obtain the feedback. To improve the precision of
this feedback, a novel reference alignment process is proposed that aims to
remove hypothesised edits that results from fluent transcription errors.
Finally, these approaches are combined with an edit confidence estimation
approach, to exclude low-confidence edits. Experiments on the in-house
Linguaskill (LNG) corpora and the publicly available Speak & Improve (S&I)
corpus show that the proposed approaches significantly boost E2E SGEC
performance.

</details>


### [115] [When Fine-Tuning Fails: Lessons from MS MARCO Passage Ranking](https://arxiv.org/abs/2506.18535)
*Manu Pande,Shahil Kumar,Anay Yatin Damle*

Main category: cs.CL

TL;DR: 研究发现，对预训练Transformer模型进行微调会降低其在MS MARCO任务上的性能，所有微调方法均不如基础模型表现好。


<details>
  <summary>Details</summary>
Motivation: 探讨为何微调预训练模型在MS MARCO任务上表现下降，挑战传统迁移学习的有效性。

Method: 通过五种模型变体（包括全参数微调和LoRA适配）进行实验，分析嵌入空间结构变化。

Result: 微调破坏了基础模型预训练学习的最优嵌入空间结构，导致性能下降。

Conclusion: 传统迁移学习方法在饱和基准上可能无效，需架构创新以实现改进。

Abstract: This paper investigates the counterintuitive phenomenon where fine-tuning
pre-trained transformer models degrades performance on the MS MARCO passage
ranking task. Through comprehensive experiments involving five model
variants-including full parameter fine-tuning and parameter efficient LoRA
adaptations-we demonstrate that all fine-tuning approaches underperform the
base sentence-transformers/all- MiniLM-L6-v2 model (MRR@10: 0.3026). Our
analysis reveals that fine-tuning disrupts the optimal embedding space
structure learned during the base model's extensive pre-training on 1 billion
sentence pairs, including 9.1 million MS MARCO samples. UMAP visualizations
show progressive embedding space flattening, while training dynamics analysis
and computational efficiency metrics further support our findings. These
results challenge conventional wisdom about transfer learning effectiveness on
saturated benchmarks and suggest architectural innovations may be necessary for
meaningful improvements.

</details>


### [116] [A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance](https://arxiv.org/abs/2506.18576)
*Matteo Melis,Gabriella Lapesa,Dennis Assenmacher*

Main category: cs.CL

TL;DR: 论文探讨了仇恨言论的定义对模型性能的影响，通过收集和分析定义构建了14个概念元素的分类法，并在三个数据集上评估了三种大语言模型的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 研究仇恨言论定义的模糊性及其对模型性能的影响，以提升有害内容检测的准确性。

Method: 收集并分类仇恨言论定义为14个概念元素，在三种数据集上对三种大语言模型进行零样本评估。

Result: 不同定义（即编码元素的特异性程度）对模型性能有影响，但这种影响因模型架构而异。

Conclusion: 仇恨言论定义的明确性对模型性能至关重要，但需考虑模型架构的差异。

Abstract: Detecting harmful content is a crucial task in the landscape of NLP
applications for Social Good, with hate speech being one of its most dangerous
forms. But what do we mean by hate speech, how can we define it, and how does
prompting different definitions of hate speech affect model performance? The
contribution of this work is twofold. At the theoretical level, we address the
ambiguity surrounding hate speech by collecting and analyzing existing
definitions from the literature. We organize these definitions into a taxonomy
of 14 Conceptual Elements-building blocks that capture different aspects of
hate speech definitions, such as references to the target of hate (individual
or groups) or of the potential consequences of it. At the experimental level,
we employ the collection of definitions in a systematic zero-shot evaluation of
three LLMs, on three hate speech datasets representing different types of data
(synthetic, human-in-the-loop, and real-world). We find that choosing different
definitions, i.e., definitions with a different degree of specificity in terms
of encoded elements, impacts model performance, but this effect is not
consistent across all architectures.

</details>


### [117] [Parallel Continuous Chain-of-Thought with Jacobi Iteration](https://arxiv.org/abs/2506.18582)
*Haoyi Wu,Zhihao Teng,Kewei Tu*

Main category: cs.CL

TL;DR: 提出了一种并行连续思维链（PCCoT）方法，通过Jacobi迭代并行更新潜在思维令牌，显著提升训练和推理效率。


<details>
  <summary>Details</summary>
Motivation: 连续思维链（CoT）虽然能节省推理令牌，但顺序依赖导致训练时间长。

Method: 采用Jacobi迭代并行更新潜在思维令牌，替代顺序更新。

Result: 实验表明，PCCoT在性能相当或更优的同时，节省近50%时间，且训练更稳定。

Conclusion: PCCoT显著提升了连续CoT的效率与稳定性，具有实用价值。

Abstract: Continuous chain-of-thought has been shown to be effective in saving
reasoning tokens for large language models. By reasoning with continuous latent
thought tokens, continuous CoT is able to perform implicit reasoning in a
compact manner. However, the sequential dependencies between latent thought
tokens spoil parallel training, leading to long training time. In this paper,
we propose Parallel Continuous Chain-of-Thought (PCCoT), which performs Jacobi
iteration on the latent thought tokens, updating them iteratively in parallel
instead of sequentially and thus improving both training and inference
efficiency of continuous CoT. Experiments demonstrate that by choosing the
proper number of iterations, we are able to achieve comparable or even better
performance while saving nearly 50% of the training and inference time.
Moreover, PCCoT shows better stability and robustness in the training process.
Our code is available at https://github.com/whyNLP/PCCoT.

</details>


### [118] [Reply to "Emergent LLM behaviors are observationally equivalent to data leakage"](https://arxiv.org/abs/2506.18600)
*Ariel Flint Ashery,Luca Maria Aiello,Andrea Baronchelli*

Main category: cs.CL

TL;DR: 论文探讨了大型语言模型（LLM）模拟中数据污染的潜在问题，但指出这并不妨碍研究LLM群体中真正涌现的动态行为。


<details>
  <summary>Details</summary>
Motivation: 澄清数据污染问题对LLM群体动态研究的限制，并强调涌现行为的可研究性。

Method: 通过分析Barrie和Törnberg对Flint Ashery等人研究的批评，论证LLM群体中自组织和模型依赖的涌现动态。

Result: 实证研究表明，社会规范等涌现动态在LLM群体中是可观察的。

Conclusion: 尽管数据污染存在，但LLM群体的涌现动态仍可被有效研究。

Abstract: A potential concern when simulating populations of large language models
(LLMs) is data contamination, i.e. the possibility that training data may shape
outcomes in unintended ways. While this concern is important and may hinder
certain experiments with multi-agent models, it does not preclude the study of
genuinely emergent dynamics in LLM populations. The recent critique by Barrie
and T\"ornberg [1] of the results of Flint Ashery et al. [2] offers an
opportunity to clarify that self-organisation and model-dependent emergent
dynamics can be studied in LLM populations, highlighting how such dynamics have
been empirically observed in the specific case of social conventions.

</details>


### [119] [Semantic similarity estimation for domain specific data using BERT and other techniques](https://arxiv.org/abs/2506.18602)
*R. Prashanth*

Main category: cs.CL

TL;DR: 论文研究了语义相似度估计，比较了USE、InferSent和BERT等先进技术，发现BERT在领域特定数据上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 语义相似度估计在自然语言处理和理解中具有重要应用，如问答、语义搜索等。本文旨在比较不同技术在该任务上的表现。

Method: 使用USE、InferSent和BERT模型，分别在领域特定数据集和公开数据集（Quora问题对）上进行实验。

Result: BERT模型表现优于其他方法，尤其是在领域特定数据上，归因于其微调过程。

Conclusion: BERT是处理领域特定数据的最佳选择。

Abstract: Estimation of semantic similarity is an important research problem both in
natural language processing and the natural language understanding, and that
has tremendous application on various downstream tasks such as question
answering, semantic search, information retrieval, document clustering,
word-sense disambiguation and machine translation. In this work, we carry out
the estimation of semantic similarity using different state-of-the-art
techniques including the USE (Universal Sentence Encoder), InferSent and the
most recent BERT, or Bidirectional Encoder Representations from Transformers,
models. We use two question pairs datasets for the analysis, one is a domain
specific in-house dataset and the other is a public dataset which is the
Quora's question pairs dataset. We observe that the BERT model gave much
superior performance as compared to the other methods. This should be because
of the fine-tuning procedure that is involved in its training process, allowing
it to learn patterns based on the training data that is used. This works
demonstrates the applicability of BERT on domain specific datasets. We infer
from the analysis that BERT is the best technique to use in the case of domain
specific data.

</details>


### [120] [The Anatomy of Speech Persuasion: Linguistic Shifts in LLM-Modified Speeches](https://arxiv.org/abs/2506.18621)
*Alisa Barkar,Mathieu Chollet,Matthieu Labeau,Beatrice Biancardi,Chloe Clavel*

Main category: cs.CL

TL;DR: 研究探讨了GPT-4o如何通过修改演讲文本来理解说服力，发现其更倾向于系统性风格调整而非人类式优化。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型对公共演讲中说服力的理解方式。

Method: 使用3MT法语数据集，修改博士候选人的演讲文本，提出新方法和可解释的文本特征集。

Result: GPT-4o通过情感词汇和句法结构（如疑问句和感叹句）来增强修辞效果，而非模仿人类优化说服力。

Conclusion: GPT-4o在说服力调整上表现出系统性风格修改的特点，而非人类式优化。

Abstract: This study examines how large language models understand the concept of
persuasiveness in public speaking by modifying speech transcripts from PhD
candidates in the "Ma These en 180 Secondes" competition, using the 3MT French
dataset. Our contributions include a novel methodology and an interpretable
textual feature set integrating rhetorical devices and discourse markers. We
prompt GPT-4o to enhance or diminish persuasiveness and analyze linguistic
shifts between original and generated speech in terms of the new features.
Results indicate that GPT-4o applies systematic stylistic modifications rather
than optimizing persuasiveness in a human-like manner. Notably, it manipulates
emotional lexicon and syntactic structures (such as interrogative and
exclamatory clauses) to amplify rhetorical impact.

</details>


### [121] [ByteSpan: Information-Driven Subword Tokenisation](https://arxiv.org/abs/2506.18639)
*Zébulon Goriely,Suchir Salhan,Pietro Lesci,Julius Cheng,Paula Buttery*

Main category: cs.CL

TL;DR: ByteSpan是一种基于信息驱动的新型子词分词器，通过外部字节级语言模型识别可预测的字节序列并分组为子词。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过分组可预测字节而非简单池化其表示来生成有用的固定子词词汇。

Method: 使用外部字节级语言模型在训练期间识别连续可预测的字节序列，并将其分组为子词。

Result: ByteSpan生成的词汇效率高，英语形态对齐分数优于BPE，多语言实验中25种语言的压缩和Rényi效率表现相似。

Conclusion: ByteSpan是一种有效的子词分词方法，尤其在形态对齐和多语言场景中表现优异。

Abstract: Recent dynamic tokenisation methods operate directly on bytes and pool their
latent representations into patches. This bears similarities to computational
models of word segmentation that determine lexical boundaries using spikes in
an autoregressive model's prediction error. Inspired by this connection, we
explore whether grouping predictable bytes - rather than pooling their
representations - can yield a useful fixed subword vocabulary. We propose a new
information-driven subword tokeniser, ByteSpan, that uses an external
byte-level LM during training to identify contiguous predictable byte sequences
and group them into subwords. Experiments show that ByteSpan yields efficient
vocabularies with higher morphological alignment scores than BPE for English.
Multilingual experiments show similar compression and R\'enyi efficiency for 25
languages.

</details>


### [122] [Is There a Case for Conversation Optimized Tokenizers in Large Language Models?](https://arxiv.org/abs/2506.18674)
*Raquel Ferrando,Javier Conde,Gonzalo Martínez,Pedro Reviriego*

Main category: cs.CL

TL;DR: 论文探讨了为聊天机器人对话优化的分词器是否能减少计算和能源成本，实验表明优化后的分词器能减少5%到10%的token数量，同时保持原训练语料的分词效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的计算和能源成本随模型规模和用户数量激增，分词器在模型效率中起关键作用。聊天机器人的用户输入和响应文本与训练语料不同，因此优化分词器可能带来潜在收益。

Method: 使用公开的聊天机器人对话语料重新设计分词器的词汇表，并评估其在对话领域的性能。

Result: 优化后的分词器在聊天对话中能减少5%到10%的token数量，同时对原训练语料的分词效率影响极小甚至略有提升。

Conclusion: 为聊天机器人对话优化的分词器能有效减少计算和能源成本，具有实际应用价值。

Abstract: The computational and energy costs of Large Language Models (LLMs) have
increased exponentially driven by the growing model sizes and the massive
adoption of LLMs by hundreds of millions of users. The unit cost of an LLM is
the computation of a token. Therefore, the tokenizer plays an important role in
the efficiency of a model, and they are carefully optimized to minimize the
number of tokens for the text in their training corpus. One of the most popular
applications of LLMs are chatbots that interact with users. A key observation
is that, for those chatbots, what is important is the performance of the
tokenizer in the user text input and the chatbot responses. Those are most
likely different from the text in the training corpus. So, a question that
immediately arises is whether there is a potential benefit in optimizing
tokenizers for chatbot conversations. In this paper, this idea is explored for
different tokenizers by using a publicly available corpus of chatbot
conversations to redesign their vocabularies and evaluate their performance in
this domain. The results show that conversation-optimized tokenizers
consistently reduce the number of tokens in chatbot dialogues, which can lead
to meaningful energy savings, in the range of 5% to 10% while having minimal or
even slightly positive impact on tokenization efficiency for the original
training corpus.

</details>


### [123] [Context Biasing for Pronunciations-Orthography Mismatch in Automatic Speech Recognition](https://arxiv.org/abs/2506.18703)
*Christian Huber,Alexander Waibel*

Main category: cs.CL

TL;DR: 提出一种动态校正方法，改进语音识别中对未训练词汇的识别能力，尤其针对发音与拼写不匹配的词汇。


<details>
  <summary>Details</summary>
Motivation: 现有序列到序列系统在识别未训练词汇（如专有名词、缩写等）时表现不佳，尤其是发音与拼写不匹配的词汇。

Method: 提出一种允许用户在推理过程中动态添加校正的方法，以修正替换错误。

Result: 该方法使偏置词错误率相对提升高达11%，同时保持整体词错误率的竞争力。

Conclusion: 动态校正方法有效提升了语音识别系统对未训练词汇的识别能力。

Abstract: Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition. When using appropriate modeling units, e.g.,
byte-pair encoded characters, these systems are in principal open vocabulary
systems. In practice, however, they often fail to recognize words not seen
during training, e.g., named entities, acronyms, or domain-specific special
words. To address this problem, many context biasing methods have been
proposed; however, for words with a pronunciation-orthography mismatch, these
methods may still struggle. We propose a method which allows corrections of
substitution errors to improve the recognition accuracy of such challenging
words. Users can add corrections on the fly during inference. We show that with
this method we get a relative improvement in biased word error rate of up to
11\%, while maintaining a competitive overall word error rate.

</details>


### [124] [Benchmarking the Pedagogical Knowledge of Large Language Models](https://arxiv.org/abs/2506.18710)
*Maxime Lelièvre,Amy Waldock,Meng Liu,Natalia Valdés Aspillaga,Alasdair Mackintosh,María José Ogando Portelo,Jared Lee,Paul Atherton,Robin A. A. Ince,Oliver G. B. Garrod*

Main category: cs.CL

TL;DR: 论文介绍了The Pedagogy Benchmark，用于评估大型语言模型在跨领域教学知识（CDPK）和特殊教育需求与残疾（SEND）教学知识上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注内容知识，缺乏对教学法理解的评估，填补这一空白对教育领域的AI应用至关重要。

Method: 基于教师专业发展考试的精心挑选问题集，涵盖教学策略和评估方法等子领域，开发了新的基准测试。

Result: 测试了97个模型，准确率在28%至89%之间，分析了成本与准确率的关系，并提供了在线排行榜。

Conclusion: 教育导向的基准测试对衡量AI模型的教学理解能力、支持教育实践及指导政策决策具有重要意义。

Abstract: Benchmarks like Massive Multitask Language Understanding (MMLU) have played a
pivotal role in evaluating AI's knowledge and abilities across diverse domains.
However, existing benchmarks predominantly focus on content knowledge, leaving
a critical gap in assessing models' understanding of pedagogy - the method and
practice of teaching. This paper introduces The Pedagogy Benchmark, a novel
dataset designed to evaluate large language models on their Cross-Domain
Pedagogical Knowledge (CDPK) and Special Education Needs and Disability (SEND)
pedagogical knowledge. These benchmarks are built on a carefully curated set of
questions sourced from professional development exams for teachers, which cover
a range of pedagogical subdomains such as teaching strategies and assessment
methods. Here we outline the methodology and development of these benchmarks.
We report results for 97 models, with accuracies spanning a range from 28% to
89% on the pedagogical knowledge questions. We consider the relationship
between cost and accuracy and chart the progression of the Pareto value
frontier over time. We provide online leaderboards at
https://rebrand.ly/pedagogy which are updated with new models and allow
interactive exploration and filtering based on various model properties, such
as cost per token and open-vs-closed weights, as well as looking at performance
in different subjects. LLMs and generative AI have tremendous potential to
influence education and help to address the global learning crisis.
Education-focused benchmarks are crucial to measure models' capacities to
understand pedagogical concepts, respond appropriately to learners' needs, and
support effective teaching practices across diverse contexts. They are needed
for informing the responsible and evidence-based deployment of LLMs and
LLM-based tools in educational settings, and for guiding both development and
policy decisions.

</details>


### [125] [Semantic-Preserving Adversarial Attacks on LLMs: An Adaptive Greedy Binary Search Approach](https://arxiv.org/abs/2506.18756)
*Chong Zhang,Xiang Li,Jia Wang,Shan Liang,Haochen Xue,Xiaobo Jin*

Main category: cs.CL

TL;DR: 论文提出了一种名为AGBS的方法，用于解决自动提示工程中因用户需求多样性导致的语义失真问题，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在图形用户界面（GUIs）中依赖自动提示工程优化用户输入，但用户需求的多样性常导致语义误解和错误输出。

Method: 提出了自适应贪婪二分搜索（AGBS）方法，模拟常见的提示优化机制，同时保持语义稳定性，动态评估策略对LLM性能的影响。

Result: 在开源和闭源LLMs上的实验表明，AGBS在语义一致性和攻击效果之间取得了平衡。

Conclusion: 研究结果为设计更可靠的提示优化系统提供了实用见解，相关代码已开源。

Abstract: Large Language Models (LLMs) increasingly rely on automatic prompt
engineering in graphical user interfaces (GUIs) to refine user inputs and
enhance response accuracy. However, the diversity of user requirements often
leads to unintended misinterpretations, where automated optimizations distort
original intentions and produce erroneous outputs. To address this challenge,
we propose the Adaptive Greedy Binary Search (AGBS) method, which simulates
common prompt optimization mechanisms while preserving semantic stability. Our
approach dynamically evaluates the impact of such strategies on LLM
performance, enabling robust adversarial sample generation. Through extensive
experiments on open and closed-source LLMs, we demonstrate AGBS's effectiveness
in balancing semantic consistency and attack efficacy. Our findings offer
actionable insights for designing more reliable prompt optimization systems.
Code is available at: https://github.com/franz-chang/DOBS

</details>


### [126] [ASP2LJ : An Adversarial Self-Play Laywer Augmented Legal Judgment Framework](https://arxiv.org/abs/2506.18768)
*Ao Chang,Tong Zhou,Yubo Chen,Delai Qiu,Shengping Liu,Kang Liu,Jun Zhao*

Main category: cs.CL

TL;DR: 论文提出ASP2LJ框架，解决法律判决预测中的长尾分布和律师角色缺失问题，并引入RareCases数据集。


<details>
  <summary>Details</summary>
Motivation: 法律判决预测面临长尾数据分布和律师角色被忽视的问题，影响模型性能和司法公正性。

Method: 提出ASP2LJ框架，结合案例生成模块和对抗自博弈机制，优化律师论证能力。

Result: 实验证明框架有效，提升了判决的客观性和公平性。

Conclusion: ASP2LJ框架和RareCases数据集为自动化司法系统研究提供了新工具。

Abstract: Legal Judgment Prediction (LJP) aims to predict judicial outcomes, including
relevant legal charge, terms, and fines, which is a crucial process in Large
Language Model(LLM). However, LJP faces two key challenges: (1)Long Tail
Distribution: Current datasets, derived from authentic cases, suffer from high
human annotation costs and imbalanced distributions, leading to model
performance degradation. (2)Lawyer's Improvement: Existing systems focus on
enhancing judges' decision-making but neglect the critical role of lawyers in
refining arguments, which limits overall judicial accuracy. To address these
issues, we propose an Adversarial Self-Play Lawyer Augmented Legal Judgment
Framework, called ASP2LJ, which integrates a case generation module to tackle
long-tailed data distributions and an adversarial self-play mechanism to
enhance lawyers' argumentation skills. Our framework enables a judge to
reference evolved lawyers' arguments, improving the objectivity, fairness, and
rationality of judicial decisions. Besides, We also introduce RareCases, a
dataset for rare legal cases in China, which contains 120 tail-end cases. We
demonstrate the effectiveness of our approach on the SimuCourt dataset and our
RareCases dataset. Experimental results show our framework brings improvements,
indicating its utilization. Our contributions include an integrated framework,
a rare-case dataset, and publicly releasing datasets and code to support
further research in automated judicial systems.

</details>


### [127] [Existing LLMs Are Not Self-Consistent For Simple Tasks](https://arxiv.org/abs/2506.18781)
*Zhenru Lin,Jiawen Tao,Yang Yuan,Andrew Chi-Chih Yao*

Main category: cs.CL

TL;DR: 研究发现大型语言模型（LLMs）在简单任务中存在自相矛盾问题，提出两种自动化方法部分改善，但自一致性仍是构建可靠AI的关键。


<details>
  <summary>Details</summary>
Motivation: 确保LLMs决策透明可信，需解决其内部推理的自相矛盾问题。

Method: 引入不一致性度量，并提出基于图和基于能量的两种自动化方法。

Result: 小模型高度不一致，即使是先进模型也未完全自一致；提出的方法部分改善问题。

Conclusion: 自一致性对构建可靠、可解释AI至关重要，但完全解决仍具挑战。

Abstract: Large Language Models (LLMs) have grown increasingly powerful, yet ensuring
their decisions remain transparent and trustworthy requires self-consistency --
no contradictions in their internal reasoning. Our study reveals that even on
simple tasks, such as comparing points on a line or a plane, or reasoning in a
family tree, all smaller models are highly inconsistent, and even
state-of-the-art models like DeepSeek-R1 and GPT-o4-mini are not fully
self-consistent. To quantify and mitigate these inconsistencies, we introduce
inconsistency metrics and propose two automated methods -- a graph-based and an
energy-based approach. While these fixes provide partial improvements, they
also highlight the complexity and importance of self-consistency in building
more reliable and interpretable AI. The code and data are available at
https://github.com/scorpio-nova/llm-self-consistency.

</details>


### [128] [RWESummary: A Framework and Test for Choosing Large Language Models to Summarize Real-World Evidence (RWE) Studies](https://arxiv.org/abs/2506.18819)
*Arjun Mukerji,Michael L. Jackson,Jason Jones,Neil Sanghavi*

Main category: cs.CL

TL;DR: RWESummary是一个用于评估大型语言模型（LLMs）在真实世界证据（RWE）研究摘要任务中的新基准，基于MedHELM框架开发，包含一个场景和三种评估方法。


<details>
  <summary>Details</summary>
Motivation: 目前LLMs在医学研究辅助任务中已有广泛应用，但尚未专门针对RWE研究的结构化输出摘要任务进行评估。

Method: 通过Atropos Health专有数据开发RWESummary，包含一个场景和三种评估方法，用于比较不同LLMs在内部RWE摘要工具中的表现。

Result: 在13项RWE研究中，Gemini 2.5模型（Flash和Pro）表现最佳。

Conclusion: RWESummary为RWE研究摘要任务提供了一个新颖且实用的基准模型。

Abstract: Large Language Models (LLMs) have been extensively evaluated for general
summarization tasks as well as medical research assistance, but they have not
been specifically evaluated for the task of summarizing real-world evidence
(RWE) from structured output of RWE studies. We introduce RWESummary, a
proposed addition to the MedHELM framework (Bedi, Cui, Fuentes, Unell et al.,
2025) to enable benchmarking of LLMs for this task. RWESummary includes one
scenario and three evaluations covering major types of errors observed in
summarization of medical research studies and was developed using Atropos
Health proprietary data. Additionally, we use RWESummary to compare the
performance of different LLMs in our internal RWE summarization tool. At the
time of publication, with 13 distinct RWE studies, we found the Gemini 2.5
models performed best overall (both Flash and Pro). We suggest RWESummary as a
novel and useful foundation model benchmark for real-world evidence study
summarization.

</details>


### [129] [MLLP-VRAIN UPV system for the IWSLT 2025 Simultaneous Speech Translation Translation task](https://arxiv.org/abs/2506.18828)
*Jorge Iranzo-Sánchez,Javier Iranzo-Sánchez,Adrià Giménez,Jorge Civera,Alfons Juan*

Main category: cs.CL

TL;DR: MLLP-VRAIN团队在IWSLT 2025实时语音翻译任务中提出了一种模块化级联系统，结合Whisper和NLLB模型，通过轻量级适应技术实现高效长语音翻译。


<details>
  <summary>Details</summary>
Motivation: 解决长语音实时翻译的挑战，避免从头训练端到端模型的需求。

Method: 使用Whisper Large-V3-Turbo进行语音识别，NLLB-3.3B进行机器翻译，采用前缀训练和自适应发射策略（如wait-$k$和RALCP）。

Result: 在ACL60/60数据集上BLEU得分为31.96，延迟2.94秒；IWSLT25Instruct测试集得分为29.8 BLEU。

Conclusion: 预训练模型经轻量级适应可高效实现长语音实时翻译，无需大量领域数据或端到端训练。

Abstract: This work describes the participation of the MLLP-VRAIN research group in the
shared task of the IWSLT 2025 Simultaneous Speech Translation track. Our
submission addresses the unique challenges of real-time translation of
long-form speech by developing a modular cascade system that adapts strong
pre-trained models to streaming scenarios. We combine Whisper Large-V3-Turbo
for ASR with the multilingual NLLB-3.3B model for MT, implementing lightweight
adaptation techniques rather than training new end-to-end models from scratch.
Our approach employs document-level adaptation with prefix training to enhance
the MT model's ability to handle incomplete inputs, while incorporating
adaptive emission policies including a wait-$k$ strategy and RALCP for managing
the translation stream. Specialized buffer management techniques and
segmentation strategies ensure coherent translations across long audio
sequences. Experimental results on the ACL60/60 dataset demonstrate that our
system achieves a favorable balance between translation quality and latency,
with a BLEU score of 31.96 and non-computational-aware StreamLAAL latency of
2.94 seconds. Our final model achieves a preliminary score on the official test
set (IWSLT25Instruct) of 29.8 BLEU. Our work demonstrates that carefully
adapted pre-trained components can create effective simultaneous translation
systems for long-form content without requiring extensive in-domain parallel
data or specialized end-to-end training.

</details>


### [130] [STU-PID: Steering Token Usage via PID Controller for Efficient Large Language Model Reasoning](https://arxiv.org/abs/2506.18831)
*Aryasomayajula Ram Bharadwaj*

Main category: cs.CL

TL;DR: STUPID方法通过动态调整推理强度，减少冗余推理步骤，提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在长链推理中因过度思考导致的冗余计算和性能下降问题。

Method: 结合块级分类器和PID控制器，动态调节推理强度。

Result: 在GSM8K上准确率提升6%，token使用减少32%。

Conclusion: STUPID提供了一种动态校准推理的框架，兼顾性能与效率。

Abstract: Large Language Models employing extended chain-of-thought (CoT) reasoning
often suffer from the overthinking phenomenon, generating excessive and
redundant reasoning steps that increase computational costs while potentially
degrading performance. While recent work has explored static steering
approaches to mitigate this issue, they lack the adaptability to dynamically
adjust intervention strength based on real-time reasoning quality. We propose
STUPID (Steering Token Usage via PID controller), a novel training-free method
that employs a PID controller to dynamically modulate activation steering
strength during inference. Our approach combines a chunk-level classifier for
detecting redundant reasoning patterns with a PID control mechanism that
adaptively adjusts steering intensity based on the predicted redundancy
probability. Experimental evaluation on GSM8K demonstrates that STUPID achieves
a 6% improvement in accuracy while reducing token usage by 32%, outperforming
static steering baselines. Our method provides a principled framework for
dynamic reasoning calibration that maintains reasoning quality while
significantly improving computational efficiency.

</details>


### [131] [LongWriter-Zero: Mastering Ultra-Long Text Generation via Reinforcement Learning](https://arxiv.org/abs/2506.18841)
*Yuhao Wu,Yushi Bai,Zhiqiang Hu,Roy Ka-Wei Lee,Juanzi Li*

Main category: cs.CL

TL;DR: 提出了一种基于激励的方法，利用强化学习（RL）从零开始训练LLM，无需依赖标注或合成数据，实现了超长高质量文本生成。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在超长文本生成中因长度限制和质量下降的挑战，避免传统方法依赖合成数据的缺点。

Method: 从基础模型出发，通过RL训练，结合专用奖励模型，引导模型在写作过程中进行规划和优化。

Result: LongWriter-Zero模型在长文本写作任务中表现优于传统SFT方法，并在多个评测中达到SOTA。

Conclusion: 该方法展示了无需合成数据的RL训练在超长文本生成中的有效性，并开源了模型和数据。

Abstract: Ultra-long generation by large language models (LLMs) is a widely demanded
scenario, yet it remains a significant challenge due to their maximum
generation length limit and overall quality degradation as sequence length
increases. Previous approaches, exemplified by LongWriter, typically rely on
''teaching'', which involves supervised fine-tuning (SFT) on synthetic
long-form outputs. However, this strategy heavily depends on synthetic SFT
data, which is difficult and costly to construct, often lacks coherence and
consistency, and tends to be overly artificial and structurally monotonous. In
this work, we propose an incentivization-based approach that, starting entirely
from scratch and without relying on any annotated or synthetic data, leverages
reinforcement learning (RL) to foster the emergence of ultra-long, high-quality
text generation capabilities in LLMs. We perform RL training starting from a
base model, similar to R1-Zero, guiding it to engage in reasoning that
facilitates planning and refinement during the writing process. To support
this, we employ specialized reward models that steer the LLM towards improved
length control, writing quality, and structural formatting. Experimental
evaluations show that our LongWriter-Zero model, trained from Qwen2.5-32B,
consistently outperforms traditional SFT methods on long-form writing tasks,
achieving state-of-the-art results across all metrics on WritingBench and
Arena-Write, and even surpassing 100B+ models such as DeepSeek R1 and
Qwen3-235B. We open-source our data and model checkpoints under
https://huggingface.co/THU-KEG/LongWriter-Zero-32B

</details>


### [132] [Mechanistic Interpretability Needs Philosophy](https://arxiv.org/abs/2506.18852)
*Iwan Williams,Ninell Oldenburg,Ruchira Dhar,Joshua Hatherley,Constanza Fierro,Nina Rajcic,Sandrine R. Schiller,Filippos Stamatiou,Anders Søgaard*

Main category: cs.CL

TL;DR: 论文探讨了机制可解释性（MI）研究需要哲学的持续合作，以澄清概念、改进方法并评估解释AI系统的认知和伦理问题。


<details>
  <summary>Details</summary>
Motivation: 随着MI领域影响力的增长，需要审视其隐含的假设、概念和解释策略，而哲学可以提供帮助。

Method: 通过分析MI文献中的三个开放问题，展示了哲学对MI研究的价值。

Result: 哲学可以深化MI研究的概念和方法，促进跨学科对话。

Conclusion: 机制可解释性研究应与哲学紧密结合，以推动更深入的理解和解释。

Abstract: Mechanistic interpretability (MI) aims to explain how neural networks work by
uncovering their underlying causal mechanisms. As the field grows in influence,
it is increasingly important to examine not just models themselves, but the
assumptions, concepts and explanatory strategies implicit in MI research. We
argue that mechanistic interpretability needs philosophy: not as an
afterthought, but as an ongoing partner in clarifying its concepts, refining
its methods, and assessing the epistemic and ethical stakes of interpreting AI
systems. Taking three open problems from the MI literature as examples, this
position paper illustrates the value philosophy can add to MI research, and
outlines a path toward deeper interdisciplinary dialogue.

</details>


### [133] [CommVQ: Commutative Vector Quantization for KV Cache Compression](https://arxiv.org/abs/2506.18879)
*Junyan Li,Yang Zhang,Muhammad Yusuf Hassan,Talha Chafekar,Tianle Cai,Zhile Ren,Pengsheng Guo,Foroozan Karimzadeh,Colorado Reed,Chong Wang,Chuang Gan*

Main category: cs.CL

TL;DR: 提出Commutative Vector Quantization (CommVQ)方法，显著减少长上下文LLM推理中的KV缓存内存占用。


<details>
  <summary>Details</summary>
Motivation: 解决长上下文LLM推理中KV缓存成为GPU内存瓶颈的问题。

Method: 采用轻量级编码器和码本的加法量化压缩KV缓存，设计RoPE可交换的码本，并使用EM算法训练。

Result: 在长上下文基准测试和GSM8K上，FP16 KV缓存大小减少87.5%，支持1位量化且精度损失最小。

Conclusion: CommVQ方法高效减少内存占用，支持长上下文推理，性能优于现有KV缓存量化方法。

Abstract: Large Language Models (LLMs) are increasingly used in applications requiring
long context lengths, but the key-value (KV) cache often becomes a memory
bottleneck on GPUs as context grows. To address this, we propose Commutative
Vector Quantization (CommVQ) to significantly reduce memory usage for
long-context LLM inference. We first introduce additive quantization with a
lightweight encoder and codebook to compress the KV cache, which can be decoded
via simple matrix multiplication. To further reduce computational costs during
decoding, we design the codebook to be commutative with Rotary Position
Embedding (RoPE) and train it using an Expectation-Maximization (EM) algorithm.
This enables efficient integration of decoding into the self-attention
mechanism. Our approach achieves high accuracy with additive quantization and
low overhead via the RoPE-commutative codebook. Experiments on long-context
benchmarks and GSM8K show that our method reduces FP16 KV cache size by 87.5%
with 2-bit quantization, while outperforming state-of-the-art KV cache
quantization methods. Notably, it enables 1-bit KV cache quantization with
minimal accuracy loss, allowing a LLaMA-3.1 8B model to run with a 128K context
length on a single RTX 4090 GPU. The source code is available at:
https://github.com/UMass-Embodied-AGI/CommVQ.

</details>


### [134] [OMEGA: Can LLMs Reason Outside the Box in Math? Evaluating Exploratory, Compositional, and Transformative Generalization](https://arxiv.org/abs/2506.18880)
*Yiyou Sun,Shawn Hu,Georgia Zhou,Ken Zheng,Hannaneh Hajishirzi,Nouha Dziri,Dawn Song*

Main category: cs.CL

TL;DR: 论文介绍了OMEGA基准测试，用于评估大型语言模型在数学问题上的三种泛化能力：探索性、组合性和转化性。结果显示前沿模型在复杂问题上表现下降，微调后探索性泛化有所提升，但组合性和转化性泛化仍有限。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数学推理中依赖固定策略，难以应对需要新颖思维的问题。为系统研究这些局限性，作者设计了OMEGA基准测试。

Method: OMEGA通过程序化生成训练-测试对，覆盖多个数学领域，并验证解决方案。评估了前沿模型和微调后的Qwen系列模型。

Result: 前沿模型在复杂问题上表现显著下降。微调后探索性泛化提升，但组合性和转化性泛化改善有限。

Conclusion: OMEGA为提升语言模型在数学创造力方面的研究奠定了基础，揭示了当前模型的局限性。

Abstract: Recent large-scale language models (LLMs) with long Chain-of-Thought
reasoning-such as DeepSeek-R1-have achieved impressive results on
Olympiad-level mathematics benchmarks. However, they often rely on a narrow set
of strategies and struggle with problems that require a novel way of thinking.
To systematically investigate these limitations, we introduce
OMEGA-Out-of-distribution Math Problems Evaluation with 3 Generalization Axes-a
controlled yet diverse benchmark designed to evaluate three axes of
out-of-distribution generalization, inspired by Boden's typology of creativity:
(1) Exploratory-applying known problem solving skills to more complex instances
within the same problem domain; (2) Compositional-combining distinct reasoning
skills, previously learned in isolation, to solve novel problems that require
integrating these skills in new and coherent ways; and (3)
Transformative-adopting novel, often unconventional strategies by moving beyond
familiar approaches to solve problems more effectively. OMEGA consists of
programmatically generated training-test pairs derived from templated problem
generators across geometry, number theory, algebra, combinatorics, logic, and
puzzles, with solutions verified using symbolic, numerical, or graphical
methods. We evaluate frontier (or top-tier) LLMs and observe sharp performance
degradation as problem complexity increases. Moreover, we fine-tune the
Qwen-series models across all generalization settings and observe notable
improvements in exploratory generalization, while compositional generalization
remains limited and transformative reasoning shows little to no improvement. By
isolating and quantifying these fine-grained failures, OMEGA lays the
groundwork for advancing LLMs toward genuine mathematical creativity beyond
mechanical proficiency.

</details>


### [135] [ReasonFlux-PRM: Trajectory-Aware PRMs for Long Chain-of-Thought Reasoning in LLMs](https://arxiv.org/abs/2506.18896)
*Jiaru Zou,Ling Yang,Jingwen Gu,Jiahao Qiu,Ke Shen,Jingrui He,Mengdi Wang*

Main category: cs.CL

TL;DR: ReasonFlux-PRM是一种新型轨迹感知过程奖励模型，旨在评估轨迹响应类型的推理痕迹，通过细粒度奖励分配提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有PRM主要基于模型最终输出训练，难以稳健评估中间推理轨迹，尤其是在前沿推理模型生成的轨迹响应输出中。

Method: ReasonFlux-PRM结合步骤级和轨迹级监督，支持离线和在线奖励监督，包括高质量数据选择、密集过程级奖励和奖励引导的测试时扩展。

Result: 在AIME、MATH500和GPQA-Diamond等基准测试中，ReasonFlux-PRM-7B表现优于其他PRM和人工基线，平均性能提升显著。

Conclusion: ReasonFlux-PRM在多种任务中表现出色，并发布了高效版本以适应资源受限场景。

Abstract: Process Reward Models (PRMs) have recently emerged as a powerful framework
for supervising intermediate reasoning steps in large language models (LLMs).
Previous PRMs are primarily trained on model final output responses and
struggle to evaluate intermediate thinking trajectories robustly, especially in
the emerging setting of trajectory-response outputs generated by frontier
reasoning models like Deepseek-R1. In this work, we introduce ReasonFlux-PRM, a
novel trajectory-aware PRM explicitly designed to evaluate the
trajectory-response type of reasoning traces. ReasonFlux-PRM incorporates both
step-level and trajectory-level supervision, enabling fine-grained reward
assignment aligned with structured chain-of-thought data. We adapt
ReasonFlux-PRM to support reward supervision under both offline and online
settings, including (i) selecting high-quality model distillation data for
downstream supervised fine-tuning of smaller models, (ii) providing dense
process-level rewards for policy optimization during reinforcement learning,
and (iii) enabling reward-guided Best-of-N test-time scaling. Empirical results
on challenging downstream benchmarks such as AIME, MATH500, and GPQA-Diamond
demonstrate that ReasonFlux-PRM-7B selects higher quality data than strong PRMs
(e.g., Qwen2.5-Math-PRM-72B) and human-curated baselines. Furthermore, our
derived ReasonFlux-PRM-7B yields consistent performance improvements, achieving
average gains of 12.1% in supervised fine-tuning, 4.5% in reinforcement
learning, and 6.3% in test-time scaling. We also release our efficient
ReasonFlux-PRM-1.5B for resource-constrained applications and edge deployment.
Projects: https://github.com/Gen-Verse/ReasonFlux

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [136] [Mechanistic Interpretability of Diffusion Models: Circuit-Level Analysis and Causal Validation](https://arxiv.org/abs/2506.17237)
*Dip Roy*

Main category: cs.CV

TL;DR: 论文通过定量电路分析，揭示了扩散模型在合成与自然数据分布处理中的算法差异，发现了八种功能不同的注意力机制及其计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究扩散模型的图像生成过程，揭示其计算路径和机制原理，以增强对生成模型行为的理解和控制。

Method: 通过系统性干预实验，分析2,000张合成图像和2,000张CelebA面部图像，测量计算复杂性和注意力模式。

Result: 发现真实面部处理需要更高计算复杂性，识别出八种功能不同的注意力机制，干预实验显示性能下降25.6%至128.3%。

Conclusion: 研究为生成模型行为的算法理解和控制提供了定量基础，支持通过机制干预策略优化模型性能。

Abstract: We present a quantitative circuit-level analysis of diffusion models,
establishing computational pathways and mechanistic principles underlying image
generation processes. Through systematic intervention experiments across 2,000
synthetic and 2,000 CelebA facial images, we discover fundamental algorithmic
differences in how diffusion architectures process synthetic versus
naturalistic data distributions. Our investigation reveals that real-world face
processing requires circuits with measurably higher computational complexity
(complexity ratio = 1.084 plus/minus 0.008, p < 0.001), exhibiting distinct
attention specialization patterns with entropy divergence ranging from 0.015 to
0.166 across denoising timesteps. We identify eight functionally distinct
attention mechanisms showing specialized computational roles: edge detection
(entropy = 3.18 plus/minus 0.12), texture analysis (entropy = 4.16 plus/minus
0.08), and semantic understanding (entropy = 2.67 plus/minus 0.15).
Intervention analysis demonstrates critical computational bottlenecks where
targeted ablations produce 25.6% to 128.3% performance degradation, providing
causal evidence for identified circuit functions. These findings establish
quantitative foundations for algorithmic understanding and control of
generative model behavior through mechanistic intervention strategies.

</details>


### [137] [SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation](https://arxiv.org/abs/2506.17290)
*Yuqi Li,Junhao Dong,Zeyu Dong,Chuanguang Yang,Zhulin An,Yongjun Xu*

Main category: cs.CV

TL;DR: 提出了一种名为SRKD的结构和关系感知知识蒸馏框架，将大型教师模型的知识迁移到轻量级学生模型中，以解决3D点云分割的计算复杂性和部署限制问题。


<details>
  <summary>Details</summary>
Motivation: 3D点云分割面临大规模基于Transformer的模型的计算复杂性和部署限制，需要一种轻量化的解决方案。

Method: 通过亲和矩阵的关系对齐模块和跨样本小批量构建策略，从教师模型中提取结构和语义知识，并利用KL散度对齐语义分布。

Result: 该方法在显著降低模型复杂度的同时，实现了最先进的性能。

Conclusion: SRKD框架在真实部署场景中表现出高效性和有效性。

Abstract: 3D point cloud segmentation faces practical challenges due to the
computational complexity and deployment limitations of large-scale
transformer-based models. To address this, we propose a novel Structure- and
Relation-aware Knowledge Distillation framework, named SRKD, that transfers
rich geometric and semantic knowledge from a large frozen teacher model (>100M)
to a lightweight student model (<15M). Specifically, we propose an affinity
matrix-based relation alignment module, which distills structural dependencies
from the teacher to the student through point-wise similarity matching,
enhancing the student's capability to learn contextual interactions. Meanwhile,
we introduce a cross-sample mini-batch construction strategy that enables the
student to perceive stable and generalized geometric structure. This aligns
across diverse point cloud instances of the teacher, rather than within a
single sample. Additionally, KL divergence is applied to align semantic
distributions, and ground-truth supervision further reinforces accurate
segmentation. Our method achieves state of the art performance with
significantly reduced model complexity, demonstrating its effectiveness and
efficiency in real-world deployment scenarios. Our Code is available at
https://github.com/itsnotacie/SRKD.

</details>


### [138] [Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning](https://arxiv.org/abs/2506.17302)
*Yijun Lin,Theresa Chen,Colby Brungard,Grunwald Sabine,Sue Ives,Matt Macander,Timm Nawrocki,Yao-Yi Chiang,Nic Jelinski*

Main category: cs.CV

TL;DR: MISO是一种基于视觉的机器学习模型，用于生成阿拉斯加高分辨率土壤地图，优于传统方法如随机森林（RF），在未见过地区表现更好。


<details>
  <summary>Details</summary>
Motivation: 阿拉斯加的土壤地图对研究永久冻土分布和气候变化适应至关重要，但传统方法依赖实地工作，效率低。

Method: MISO结合地理空间基础模型、隐式神经表示和对比学习，实现连续空间预测和多模态对齐。

Result: MISO在空间交叉验证和区域分析中表现优于RF，尤其在未见过地区召回率更高。

Conclusion: MISO展示了先进机器学习在土壤地图中的潜力，为未来采样和基础设施规划提供指导。

Abstract: Fine-scale soil mapping in Alaska, traditionally relying on fieldwork and
localized simulations, remains a critical yet underdeveloped task, despite the
region's ecological importance and extensive permafrost coverage. As permafrost
thaw accelerates due to climate change, it threatens infrastructure stability
and key ecosystem services, such as soil carbon storage. High-resolution soil
maps are essential for characterizing permafrost distribution, identifying
vulnerable areas, and informing adaptation strategies. We present MISO, a
vision-based machine learning (ML) model to produce statewide fine-scale soil
maps for near-surface permafrost and soil taxonomy. The model integrates a
geospatial foundation model for visual feature extraction, implicit neural
representations for continuous spatial prediction, and contrastive learning for
multimodal alignment and geo-location awareness. We compare MISO with Random
Forest (RF), a traditional ML model that has been widely used in soil mapping
applications. Spatial cross-validation and regional analysis across Permafrost
Zones and Major Land Resource Areas (MLRAs) show that MISO generalizes better
to remote, unseen locations and achieves higher recall than RF, which is
critical for monitoring permafrost thaw and related environmental processes.
These findings demonstrate the potential of advanced ML approaches for
fine-scale soil mapping and provide practical guidance for future soil sampling
and infrastructure planning in permafrost-affected landscapes. The project will
be released at https://github.com/knowledge-computing/Peatland-permafrost.

</details>


### [139] [RadarSeq: A Temporal Vision Framework for User Churn Prediction via Radar Chart Sequences](https://arxiv.org/abs/2506.17325)
*Sina Najafi,M. Hadi Sepanj,Fahimeh Jafari*

Main category: cs.CV

TL;DR: 提出了一种基于时间感知的计算机视觉框架，用于预测非订阅制零工平台的用户流失，通过雷达图序列建模用户行为，显著提升了性能指标。


<details>
  <summary>Details</summary>
Motivation: 非订阅制零工平台的用户流失预测因缺乏明确标签和动态行为而具有挑战性，现有方法难以捕捉关键时间线索。

Method: 将用户行为模式建模为雷达图图像序列，结合预训练CNN编码器和双向LSTM，捕捉时空模式。

Result: 在真实数据集上，F1分数提升17.7，精确度提升29.4，AUC提升16.1，且具有更好的可解释性。

Conclusion: 该框架适用于动态零工经济平台的大规模流失建模，具有模块化设计和高效部署特性。

Abstract: Predicting user churn in non-subscription gig platforms, where disengagement
is implicit, poses unique challenges due to the absence of explicit labels and
the dynamic nature of user behavior. Existing methods often rely on aggregated
snapshots or static visual representations, which obscure temporal cues
critical for early detection. In this work, we propose a temporally-aware
computer vision framework that models user behavioral patterns as a sequence of
radar chart images, each encoding day-level behavioral features. By integrating
a pretrained CNN encoder with a bidirectional LSTM, our architecture captures
both spatial and temporal patterns underlying churn behavior. Extensive
experiments on a large real-world dataset demonstrate that our method
outperforms classical models and ViT-based radar chart baselines, yielding
gains of 17.7 in F1 score, 29.4 in precision, and 16.1 in AUC, along with
improved interpretability. The framework's modular design, explainability
tools, and efficient deployment characteristics make it suitable for
large-scale churn modeling in dynamic gig-economy platforms.

</details>


### [140] [P2MFDS: A Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments](https://arxiv.org/abs/2506.17332)
*Haitian Wang,Yiren Wang,Xinyu Wang,Yumeng Miao,Yuliang Zhang,Yu Zhang,Atif Mansoor*

Main category: cs.CV

TL;DR: 提出了一种隐私保护的多模态跌倒检测系统P2MFDS，结合毫米波雷达和3D振动传感，显著提高了在浴室环境中的检测准确率和召回率。


<details>
  <summary>Details</summary>
Motivation: 随着老龄化加剧，浴室成为跌倒高发环境，现有单模态系统因环境干扰和系统偏差存在局限性，需多模态解决方案。

Method: 开发传感器评估框架，融合毫米波雷达和3D振动传感，构建隐私保护多模态数据集；提出双流网络P2MFDS，结合CNN-BiLSTM-Attention和多尺度CNN-SEBlock-Self-Attention分支。

Result: P2MFDS在准确率和召回率上显著优于现有方法。

Conclusion: 多模态融合和隐私保护设计有效解决了浴室环境中跌倒检测的挑战。

Abstract: By 2050, people aged 65 and over are projected to make up 16 percent of the
global population. As aging is closely associated with increased fall risk,
particularly in wet and confined environments such as bathrooms where over 80
percent of falls occur. Although recent research has increasingly focused on
non-intrusive, privacy-preserving approaches that do not rely on wearable
devices or video-based monitoring, these efforts have not fully overcome the
limitations of existing unimodal systems (e.g., WiFi-, infrared-, or
mmWave-based), which are prone to reduced accuracy in complex environments.
These limitations stem from fundamental constraints in unimodal sensing,
including system bias and environmental interference, such as multipath fading
in WiFi-based systems and drastic temperature changes in infrared-based
methods. To address these challenges, we propose a Privacy-Preserving
Multimodal Fall Detection System for Elderly People in Bathroom Environments.
First, we develop a sensor evaluation framework to select and fuse
millimeter-wave radar with 3D vibration sensing, and use it to construct and
preprocess a large-scale, privacy-preserving multimodal dataset in real
bathroom settings, which will be released upon publication. Second, we
introduce P2MFDS, a dual-stream network combining a CNN-BiLSTM-Attention branch
for radar motion dynamics with a multi-scale CNN-SEBlock-Self-Attention branch
for vibration impact detection. By uniting macro- and micro-scale features,
P2MFDS delivers significant gains in accuracy and recall over state-of-the-art
approaches. Code and pretrained models will be made available at:
https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom.

</details>


### [141] [A Novel Multi-layer Task-centric and Data Quality Framework for Autonomous Driving](https://arxiv.org/abs/2506.17346)
*Yuhan Zhou,Haihua Chen,Kewei Sha*

Main category: cs.CV

TL;DR: 论文提出了一个面向任务和数据质量（DQ）的五层框架，旨在提升下一代自动驾驶车辆（AVs）的功能性、效率和可信度，并通过案例研究验证了冗余数据对任务性能的影响。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶领域的研究和实践过于关注模型和算法，而忽视了数据质量（DQ）的重要性。为了满足下一代AVs的需求，需要一种系统性的方法来映射DQ与任务需求和性能目标。

Method: 提出一个包含数据层、DQ层、任务层、应用层和目标层的五层框架，并通过nuScenes数据集上的案例研究验证了冗余数据对YOLOv8目标检测任务性能的影响。

Result: 研究表明，部分去除多源图像数据的冗余可以提高任务性能，同时揭示了图像和LiDAR多模态数据中存在的冗余DQ问题。

Conclusion: 该论文为自动驾驶领域在DQ、任务编排和性能导向系统开发的交叉领域提出了关键挑战，并有望推动构建更具适应性、可解释性和鲁棒性的AVs。

Abstract: The next-generation autonomous vehicles (AVs), embedded with frequent
real-time decision-making, will rely heavily on a large volume of multisource
and multimodal data. In real-world settings, the data quality (DQ) of different
sources and modalities usually varies due to unexpected environmental factors
or sensor issues. However, both researchers and practitioners in the AV field
overwhelmingly concentrate on models/algorithms while undervaluing the DQ. To
fulfill the needs of the next-generation AVs with guarantees of functionality,
efficiency, and trustworthiness, this paper proposes a novel task-centric and
data quality vase framework which consists of five layers: data layer, DQ
layer, task layer, application layer, and goal layer. The proposed framework
aims to map DQ with task requirements and performance goals. To illustrate, a
case study investigating redundancy on the nuScenes dataset proves that
partially removing redundancy on multisource image data could improve YOLOv8
object detection task performance. Analysis on multimodal data of image and
LiDAR further presents existing redundancy DQ issues. This paper opens up a
range of critical but unexplored challenges at the intersection of DQ, task
orchestration, and performance-oriented system development in AVs. It is
expected to guide the AV community toward building more adaptive, explainable,
and resilient AVs that respond intelligently to dynamic environments and
heterogeneous data streams. Code, data, and implementation details are publicly
available at: https://anonymous.4open.science/r/dq4av-framework/README.md.

</details>


### [142] [Efficient Feedback Gate Network for Hyperspectral Image Super-Resolution](https://arxiv.org/abs/2506.17361)
*Xufei Wang,Mingjian Zhang,Fei Ge,Jinchen Zhu,Wen Sha,Jifen Ren,Zhimeng Hou,Shouguo Zheng,ling Zheng,Shizhuang Weng*

Main category: cs.CV

TL;DR: 提出了一种基于分组的高效反馈门网络，用于单幅高光谱图像超分辨率，通过多反馈和门操作提升空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 现有单幅高光谱图像超分辨率方法未能充分探索波段间和空间-光谱信息的相干性，导致性能受限。

Method: 设计了高效反馈门网络，包括SPDFM模块（通道混洗和扩张卷积）和SSRGM模块（宽边界感知门和光谱增强门），并应用三维SSRGM增强整体信息。

Result: 在三个高光谱数据集上验证了该方法在光谱保真度和空间内容重建上的优越性。

Conclusion: 该方法通过多反馈和门操作显著提升了高光谱图像超分辨率性能。

Abstract: Even without auxiliary images, single hyperspectral image super-resolution
(SHSR) methods can be designed to improve the spatial resolution of
hyperspectral images. However, failing to explore coherence thoroughly along
bands and spatial-spectral information leads to the limited performance of the
SHSR. In this study, we propose a novel group-based SHSR method termed the
efficient feedback gate network, which uses various feedbacks and gate
operations involving large kernel convolutions and spectral interactions. In
particular, by providing different guidance for neighboring groups, we can
learn rich band information and hierarchical hyperspectral spatial information
using channel shuffling and dilatation convolution in shuffled and progressive
dilated fusion module(SPDFM). Moreover, we develop a wide-bound perception gate
block and a spectrum enhancement gate block to construct the spatial-spectral
reinforcement gate module (SSRGM) and obtain highly representative
spatial-spectral features efficiently. Additionally, we apply a
three-dimensional SSRGM to enhance holistic information and coherence for
hyperspectral data. The experimental results on three hyperspectral datasets
demonstrate the superior performance of the proposed network over the
state-of-the-art methods in terms of spectral fidelity and spatial content
reconstruction.

</details>


### [143] [From Drawings to Decisions: A Hybrid Vision-Language Framework for Parsing 2D Engineering Drawings into Structured Manufacturing Knowledge](https://arxiv.org/abs/2506.17374)
*Muhammad Tayyab Khan,Lequn Chen,Zane Yong,Jun Ming Tan,Wenhe Feng,Seung Ki Moon*

Main category: cs.CV

TL;DR: 提出了一种结合旋转感知目标检测模型和视觉语言解析器的混合框架，用于高效提取2D工程图中的关键信息，并在实际制造任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 手动提取2D工程图中的关键信息效率低且易出错，通用OCR模型因复杂布局和工程符号表现不佳，需改进。

Method: 使用YOLOv11-OBB定位注释并提取OBB区域，再通过微调的视觉语言模型（Donut和Florence-2）解析为结构化输出。

Result: Donut表现优于Florence-2，精确率达88.5%，召回率99.2%，F1分数93.5%，幻觉率11.5%。

Conclusion: 该框架能有效支持下游制造任务，为2D图纸解析现代化提供了实用工具。

Abstract: Efficient and accurate extraction of key information from 2D engineering
drawings is essential for advancing digital manufacturing workflows. Such
information includes geometric dimensioning and tolerancing (GD&T), measures,
material specifications, and textual annotations. Manual extraction is slow and
labor-intensive, while generic OCR models often fail due to complex layouts,
engineering symbols, and rotated text, leading to incomplete and unreliable
outputs. These limitations result in incomplete and unreliable outputs. To
address these challenges, we propose a hybrid vision-language framework that
integrates a rotation-aware object detection model (YOLOv11-obb) with a
transformer-based vision-language parser. Our structured pipeline applies
YOLOv11-OBB to localize annotations and extract oriented bounding box (OBB)
patches, which are then parsed into structured outputs using a fine-tuned,
lightweight vision-language model (VLM). We curate a dataset of 1,367 2D
mechanical drawings annotated across nine key categories. YOLOv11-OBB is
trained on this dataset to detect OBBs and extract annotation patches. These
are parsed using two open-source VLMs: Donut and Florence-2. Both models are
lightweight and well-suited for specialized industrial tasks under limited
computational overhead. Following fine-tuning of both models on the curated
dataset of image patches paired with structured annotation labels, a
comparative experiment is conducted to evaluate parsing performance across four
key metrics. Donut outperforms Florence-2, achieving 88.5% precision, 99.2%
recall, and a 93.5% F1-score, with a hallucination rate of 11.5%. Finally, a
case study demonstrates how the extracted structured information supports
downstream manufacturing tasks such as process and tool selection, showcasing
the practical utility of the proposed framework in modernizing 2D drawing
interpretation.

</details>


### [144] [Spatial-Temporal Pre-Training for Embryo Viability Prediction Using Time-Lapse Videos](https://arxiv.org/abs/2506.17403)
*Zhiyi Shi,Junsik Kim,Helen Y. Yang,Yonghyun Song,Hyun-Jic Oh,Dalit Ben-Yosef,Daniel Needleman,Hanspeter Pfister*

Main category: cs.CV

TL;DR: 论文提出了一种名为STPT的自监督学习方法，用于解决胚胎发育视频中长视频和时序不对齐的挑战，显著提升了IVF胚胎存活率预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于标记数据有限且传统自监督学习方法难以处理胚胎发育视频的长时序和不对齐问题，需要一种更高效的方法。

Method: STPT分为空间和时间两个阶段，分别训练一个编码器并冻结另一个，以减少内存需求，并避免跨视频的帧对齐。

Result: 在23,027个视频（3,286个标记）上，STPT达到了0.635的AUC，优于基线方法。

Conclusion: STPT方法在有限计算资源下有效解决了胚胎视频分析的挑战，显著提升了预测性能。

Abstract: Automating embryo viability prediction for in vitro fertilization (IVF) is
important but challenging due to the limited availability of labeled pregnancy
outcome data, as only a small fraction of embryos are labeled after transfer.
Self-supervised learning (SSL) can leverage both labeled and unlabeled data to
improve prediction. However, existing SSL methods for videos are not directly
applicable to embryo development videos due to two challenges: (1) embryo
time-lapse videos contain hundreds of frames, requiring significant GPU memory
for conventional SSL; (2) the dataset contains videos with varying lengths and
many outlier frames, causing traditional video alignment methods to struggle
with semantic misalignment. We propose Spatial-Temporal Pre-Training (STPT) to
address these challenges. STPT includes two stages: spatial and temporal. In
each stage, only one encoder is trained while the other is frozen, reducing
memory demands. To handle temporal misalignment, STPT avoids frame-by-frame
alignment across videos. The spatial stage learns from alignments within each
video and its temporally consistent augmentations. The temporal stage then
models relationships between video embeddings. Our method efficiently handles
long videos and temporal variability. On 23,027 time-lapse videos (3,286
labeled), STPT achieves the highest AUC of 0.635 (95% CI: 0.632-0.638) compared
to baselines, with limited computational resources.

</details>


### [145] [VMRA-MaR: An Asymmetry-Aware Temporal Framework for Longitudinal Breast Cancer Risk Prediction](https://arxiv.org/abs/2506.17412)
*Zijun Sun,Solveig Thrun,Michael Kampffmeyer*

Main category: cs.CV

TL;DR: 提出了一种基于Vision Mamba RNN（VMRNN）和状态空间模型（SSM）的方法，结合不对称模块（SAD和LAT），用于乳腺癌风险预测，显著提升了高密度乳腺病例的预测性能。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球主要死因，现有模型多依赖单次筛查数据，无法充分利用纵向影像数据的动态信息。

Method: 采用VMRNN结合SSM和LSTM机制，引入不对称模块（SAD和LAT）捕捉乳腺组织演变的细微趋势。

Result: 在预测癌症发病方面表现优异，尤其在高密度乳腺病例和远期时间点（第4和第5年）效果显著。

Conclusion: 该方法有望推动乳腺癌早期识别和个性化筛查策略的发展。

Abstract: Breast cancer remains a leading cause of mortality worldwide and is typically
detected via screening programs where healthy people are invited in regular
intervals. Automated risk prediction approaches have the potential to improve
this process by facilitating dynamically screening of high-risk groups. While
most models focus solely on the most recent screening, there is growing
interest in exploiting temporal information to capture evolving trends in
breast tissue, as inspired by clinical practice. Early methods typically relied
on two time steps, and although recent efforts have extended this to multiple
time steps using Transformer architectures, challenges remain in fully
harnessing the rich temporal dynamics inherent in longitudinal imaging data. In
this work, we propose to instead leverage Vision Mamba RNN (VMRNN) with a
state-space model (SSM) and LSTM-like memory mechanisms to effectively capture
nuanced trends in breast tissue evolution. To further enhance our approach, we
incorporate an asymmetry module that utilizes a Spatial Asymmetry Detector
(SAD) and Longitudinal Asymmetry Tracker (LAT) to identify clinically relevant
bilateral differences. This integrated framework demonstrates notable
improvements in predicting cancer onset, especially for the more challenging
high-density breast cases and achieves superior performance at extended time
points (years four and five), highlighting its potential to advance early
breast cancer recognition and enable more personalized screening strategies.
Our code is available at https://github.com/Mortal-Suen/VMRA-MaR.git.

</details>


### [146] [Trans${^2}$-CBCT: A Dual-Transformer Framework for Sparse-View CBCT Reconstruction](https://arxiv.org/abs/2506.17425)
*Minmin Yang,Huantao Ren,Senem Velipasalar*

Main category: cs.CV

TL;DR: 论文提出了一种结合CNN和Transformer的Trans-CBCT模型，用于稀疏视图CBCT重建，并通过引入邻居感知的Point Transformer进一步优化空间一致性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图CBCT扫描速度快且辐射剂量低，但会导致严重的伪影和空间覆盖不足。论文旨在通过结合CNN和Transformer的优势来解决这些问题。

Method: 1. 提出Trans-CBCT模型，使用TransUNet替代传统UNet/ResNet编码器，结合多尺度特征和轻量级衰减预测头。2. 引入邻居感知Point Transformer，通过3D位置编码和k近邻注意力增强空间一致性。

Result: 在LUNA16数据集上，Trans-CBCT比基线模型PSNR提升1.17 dB，SSIM提升0.0163；Trans²-CBCT进一步提升了0.63 dB PSNR和0.0117 SSIM。

Conclusion: 结合CNN-Transformer特征和基于点的几何推理，显著提升了稀疏视图CBCT重建的效果。

Abstract: Cone-beam computed tomography (CBCT) using only a few X-ray projection views
enables faster scans with lower radiation dose, but the resulting severe
under-sampling causes strong artifacts and poor spatial coverage. We address
these challenges in a unified framework. First, we replace conventional
UNet/ResNet encoders with TransUNet, a hybrid CNN-Transformer model.
Convolutional layers capture local details, while self-attention layers enhance
global context. We adapt TransUNet to CBCT by combining multi-scale features,
querying view-specific features per 3D point, and adding a lightweight
attenuation-prediction head. This yields Trans-CBCT, which surpasses prior
baselines by 1.17 dB PSNR and 0.0163 SSIM on the LUNA16 dataset with six views.
Second, we introduce a neighbor-aware Point Transformer to enforce volumetric
coherence. This module uses 3D positional encoding and attention over k-nearest
neighbors to improve spatial consistency. The resulting model, Trans$^2$-CBCT,
provides an additional gain of 0.63 dB PSNR and 0.0117 SSIM. Experiments on
LUNA16 and ToothFairy show consistent gains from six to ten views, validating
the effectiveness of combining CNN-Transformer features with point-based
geometry reasoning for sparse-view CBCT reconstruction.

</details>


### [147] [Enhancing Wireless Device Identification through RF Fingerprinting: Leveraging Transient Energy Spectrum Analysis](https://arxiv.org/abs/2506.17439)
*Nisar Ahmed,Gulshan Saleem,Hafiz Muhammad Shahzad Asif,Muhammad Usman Younus,Kalsoom Safdar*

Main category: cs.CV

TL;DR: 该研究提出了一种基于瞬态能量谱分析和混合深度学习模型CNN-Bi-GRU的方法，用于在复杂电磁环境中准确识别和分类射频设备。


<details>
  <summary>Details</summary>
Motivation: 随着物联网技术和5G网络的快速发展，辐射设备数量激增，准确识别和分类这些设备成为关键挑战。

Method: 利用广义线性调频小波变换提取射频设备的瞬态能量谱特征，并采用CNN-Bi-GRU混合深度学习模型进行分类建模。

Result: 实验结果显示，该方法在10折交叉验证中达到了99.33%的精确率、99.53%的召回率、99.43%的F1分数和99.17%的分类准确率。

Conclusion: CNN-Bi-GRU方法在射频设备识别中表现出色，适用于复杂无线环境中的设备识别和分类。

Abstract: In recent years, the rapid growth of the Internet of Things technologies and
the widespread adoption of 5G wireless networks have led to an exponential
increase in the number of radiation devices operating in complex
electromagnetic environments. A key challenge in managing and securing these
devices is accurate identification and classification. To address this
challenge, specific emitter identification techniques have emerged as a
promising solution that aims to provide reliable and efficient means of
identifying individual radiation devices in a unified and standardized manner.
This research proposes an approach that leverages transient energy spectrum
analysis using the General Linear Chirplet Transform to extract features from
RF devices. A dataset comprising nine RF devices is utilized, with each sample
containing 900 attributes and a total of 1080 equally distributed samples
across the devices. These features are then used in a classification modeling
framework. To overcome the limitations of conventional machine learning
methods, we introduce a hybrid deep learning model called the CNN-Bi-GRU for
learning the identification of RF devices based on their transient
characteristics. The proposed approach provided a 10-fold cross-validation
performance with a precision of 99.33%, recall of 99.53%, F1-score of 99.43%,
and classification accuracy of 99.17%. The results demonstrate the promising
classification performance of the CNN-Bi-GRU approach, indicating its
suitability for accurately identifying RF devices based on their transient
characteristics and its potential for enhancing device identification and
classification in complex wireless environments.

</details>


### [148] [AQUA20: A Benchmark Dataset for Underwater Species Classification under Challenging Conditions](https://arxiv.org/abs/2506.17455)
*Taufikur Rahman Fuad,Sabbir Ahmed,Shahriar Ivan*

Main category: cs.CV

TL;DR: 论文介绍了AQUA20数据集，评估了13种深度学习模型在复杂水下环境中的海洋物种分类性能，ConvNeXt表现最佳，并提供了可解释性分析。


<details>
  <summary>Details</summary>
Motivation: 水下视觉识别因浑浊、低光照和遮挡等复杂失真问题而具有挑战性，现有视觉系统性能下降严重。

Method: 使用AQUA20数据集（8,171张水下图像，20种海洋物种），评估了13种深度学习模型（包括轻量级CNN和Transformer架构）。

Result: ConvNeXt表现最佳，Top-3准确率98.82%，Top-1准确率90.69%，F1-score 88.92%。其他模型在复杂性和性能之间存在权衡。

Conclusion: 水下物种识别仍有改进空间，AQUA20为未来研究提供了重要基础，数据集已公开。

Abstract: Robust visual recognition in underwater environments remains a significant
challenge due to complex distortions such as turbidity, low illumination, and
occlusion, which severely degrade the performance of standard vision systems.
This paper introduces AQUA20, a comprehensive benchmark dataset comprising
8,171 underwater images across 20 marine species reflecting real-world
environmental challenges such as illumination, turbidity, occlusions, etc.,
providing a valuable resource for underwater visual understanding. Thirteen
state-of-the-art deep learning models, including lightweight CNNs (SqueezeNet,
MobileNetV2) and transformer-based architectures (ViT, ConvNeXt), were
evaluated to benchmark their performance in classifying marine species under
challenging conditions. Our experimental results show ConvNeXt achieving the
best performance, with a Top-3 accuracy of 98.82% and a Top-1 accuracy of
90.69%, as well as the highest overall F1-score of 88.92% with moderately large
parameter size. The results obtained from our other benchmark models also
demonstrate trade-offs between complexity and performance. We also provide an
extensive explainability analysis using GRAD-CAM and LIME for interpreting the
strengths and pitfalls of the models. Our results reveal substantial room for
improvement in underwater species recognition and demonstrate the value of
AQUA20 as a foundation for future research in this domain. The dataset is
publicly available at: https://huggingface.co/datasets/taufiktrf/AQUA20.

</details>


### [149] [When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network](https://arxiv.org/abs/2506.17457)
*Dong Xiao,Guangyao Chen,Peixi Peng,Yangru Huang,Yifan Zhao,Yongxing Dai,Yonghong Tian*

Main category: cs.CV

TL;DR: 提出了一种实时异常检测方法，结合事件相机和RGB相机数据，兼顾高精度和低响应时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视响应时间，而自动驾驶场景中时间敏感性至关重要。

Method: 提出多模态异步混合网络，结合事件相机的异步图神经网络和RGB相机的CNN特征提取。

Result: 在基准数据集上表现优于现有方法，实现毫秒级实时性能。

Conclusion: 该方法有效平衡了精度和响应时间，适用于自动驾驶的实时异常检测。

Abstract: Anomaly detection is essential for the safety and reliability of autonomous
driving systems. Current methods often focus on detection accuracy but neglect
response time, which is critical in time-sensitive driving scenarios. In this
paper, we introduce real-time anomaly detection for autonomous driving,
prioritizing both minimal response time and high accuracy. We propose a novel
multimodal asynchronous hybrid network that combines event streams from event
cameras with image data from RGB cameras. Our network utilizes the high
temporal resolution of event cameras through an asynchronous Graph Neural
Network and integrates it with spatial features extracted by a CNN from RGB
images. This combination effectively captures both the temporal dynamics and
spatial details of the driving environment, enabling swift and precise anomaly
detection. Extensive experiments on benchmark datasets show that our approach
outperforms existing methods in both accuracy and response time, achieving
millisecond-level real-time performance.

</details>


### [150] [Photogranulometry -- Dataset of soil images with corresponding particle size distributions](https://arxiv.org/abs/2506.17469)
*Thomas Plante St-Cyr,François Duhaime,Jean-Sébastien Dubé,Simon Grenier*

Main category: cs.CV

TL;DR: 论文提出了一种基于光学粒度分析的自动化方法，用于替代传统耗时且昂贵的粒度分布分析，并通过高分辨率图像数据集为卷积神经网络训练提供支持。


<details>
  <summary>Details</summary>
Motivation: 传统粒度分布分析成本高且效率低，光学分析可集成到常规实验室流程中，提高效率并降低成本。

Method: 使用标准化拍摄方法采集12,714张高分辨率图像（45 MP），涵盖321种土壤样本的湿润和干燥状态，并通过定制测试台和分样方法处理大样本。

Result: 提供了一个高质量的数据集，可用于训练卷积神经网络，以支持岩土工程应用中的自动化粒度分析。

Conclusion: 光学粒度分析与CNN结合是传统方法的高效替代方案，为岩土工程实验室提供了新的技术路径。

Abstract: Traditional particle size distribution (PSD) analyses create significant
downtime and are expensive in labor and maintenance. These drawbacks could be
alleviated using optical grain size analysis integrated into routine
geotechnical laboratory workflow. This paper presents a high-resolution dataset
of 12,714 images of 321 different soil samples collected in the Montreal,
Quebec region, alongside their PSD analysis. It is designed to provide a robust
starting point for training convolutional neural networks (CNN) in geotechnical
applications. Soil samples were photographed in a standardized top-view
position with a resolution of 45 MP and a minimum scale of 39.4 micrometers per
pixel, both in their moist and dry states. A custom test bench employing 13x9
inch white aluminum trays, on which the samples are spread in a thin layer, was
used. For samples exceeding a size limit, a coning and quartering method was
employed for mass reduction.

</details>


### [151] [Few-Shot, Now for Real: Medical VLMs Adaptation without Balanced Sets or Validation](https://arxiv.org/abs/2506.17500)
*Julio Silva-Rodríguez,Fereshteh Shakeri,Houda Bahig,Jose Dolz,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 本文探讨了视觉语言模型（VLMs）在医学图像分析中的应用，指出了现有方法在数据分布假设上的不现实性，并提出了一种无需验证集的适应方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设数据分布平衡且需要验证集，这在医学领域中不现实，因此需要一种更适应实际场景的解决方案。

Method: 提出了一种无需训练的自由线性探针方法，自适应地结合视觉和文本监督。

Result: 实验表明，现有方法在现实条件下性能下降，而提出的方法在多种任务中表现稳健。

Conclusion: 该方法为医学图像分析中的VLM适应提供了高效且鲁棒的解决方案。

Abstract: Vision-language models (VLMs) are gaining attention in medical image
analysis. These are pre-trained on large, heterogeneous data sources, yielding
rich and transferable representations. Notably, the combination of
modality-specialized VLMs with few-shot adaptation has provided fruitful
results, enabling the efficient deployment of high-performing solutions.
However, previous works on this topic make strong assumptions about the
distribution of adaptation data, which are unrealistic in the medical domain.
First, prior art assumes access to a balanced support set, a condition that
breaks the natural imbalance in disease prevalence found in real-world
scenarios. Second, these works typically assume the presence of an additional
validation set to fix critical hyper-parameters, which is highly
data-inefficient. This work challenges these favorable deployment scenarios and
introduces a realistic, imbalanced, validation-free adaptation setting. Our
extensive benchmark across various modalities and downstream tasks demonstrates
that current methods systematically compromise their performance when operating
under realistic conditions, occasionally even performing worse than zero-shot
inference. Also, we introduce a training-free linear probe that adaptively
blends visual and textual supervision. Detailed studies demonstrate that the
proposed solver is a strong, efficient baseline, enabling robust adaptation in
challenging scenarios.

</details>


### [152] [Trustworthy Few-Shot Transfer of Medical VLMs through Split Conformal Prediction](https://arxiv.org/abs/2506.17503)
*Julio Silva-Rodríguez,Ismail Ben Ayed,Jose Dolz*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法SCA-T，用于在医学视觉语言模型（VLM）的迁移学习中提供可信度保证，解决了传统SCP框架在适应性问题上的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管医学视觉语言模型在数据高效的图像分类中表现出色，但其可靠性尚未充分研究。本文旨在通过改进的SCP框架提供更可靠的预测。

Method: 提出了SCA-T方法，通过无监督的转导适应在标定数据和测试数据上联合优化，解决了传统SCP在适应性问题上的局限性。

Result: 实验表明，SCA-T在效率和条件覆盖方面优于传统SCP，同时保持了相同的经验保证。

Conclusion: SCA-T为医学VLM的迁移学习提供了一种更可靠的解决方案，适用于多种图像模态和任务。

Abstract: Medical vision-language models (VLMs) have demonstrated unprecedented
transfer capabilities and are being increasingly adopted for data-efficient
image classification. Despite its growing popularity, its reliability aspect
remains largely unexplored. This work explores the split conformal prediction
(SCP) framework to provide trustworthiness guarantees when transferring such
models based on a small labeled calibration set. Despite its potential, the
generalist nature of the VLMs' pre-training could negatively affect the
properties of the predicted conformal sets for specific tasks. While common
practice in transfer learning for discriminative purposes involves an
adaptation stage, we observe that deploying such a solution for conformal
purposes is suboptimal since adapting the model using the available calibration
data breaks the rigid exchangeability assumptions for test data in SCP. To
address this issue, we propose transductive split conformal adaptation (SCA-T),
a novel pipeline for transfer learning on conformal scenarios, which performs
an unsupervised transductive adaptation jointly on calibration and test data.
We present comprehensive experiments utilizing medical VLMs across various
image modalities, transfer tasks, and non-conformity scores. Our framework
offers consistent gains in efficiency and conditional coverage compared to SCP,
maintaining the same empirical guarantees.

</details>


### [153] [Learning golf swing signatures from a single wrist-worn inertial sensor](https://arxiv.org/abs/2506.17505)
*Jessy Lauer*

Main category: cs.CV

TL;DR: 该论文提出了一种基于手腕传感器的个性化高尔夫挥杆分析框架，通过合成惯性数据训练神经网络，实现了从手腕数据推断全身运动的技术，并支持早期异常动作检测。


<details>
  <summary>Details</summary>
Motivation: 高尔夫挥杆分析受限于孤立指标、专业运动员数据不足及缺乏丰富的运动表示。论文旨在解决这些问题，提供一种全面的、数据驱动的分析方法。

Method: 构建专业挥杆数据集，利用生物精确的人体网格恢复重建3D运动学，生成合成惯性数据训练神经网络，学习运动原语的离散词汇表。

Result: 系统能准确估计全身运动学和挥杆事件，支持早期异常检测，并通过可解释性方法揭示个体化运动特征。

Conclusion: 该研究挑战了常见假设，如挥杆一致性，为研究、教练和运动损伤预防提供了可扩展的高保真运动分析。

Abstract: Despite its importance for performance and injury prevention, golf swing
analysis is limited by isolated metrics, underrepresentation of professional
athletes, and a lack of rich, interpretable movement representations. We
address these gaps with a holistic, data-driven framework for personalized golf
swing analysis from a single wrist-worn sensor. We build a large dataset of
professional swings from publicly available videos, reconstruct full-body 3D
kinematics using biologically accurate human mesh recovery, and generate
synthetic inertial data to train neural networks that infer motion and segment
swing phases from wrist-based input. We learn a compositional, discrete
vocabulary of motion primitives that facilitates the detection and
visualization of technical flaws, and is expressive enough to predict player
identity, club type, sex, and age. Our system accurately estimates full-body
kinematics and swing events from wrist data, delivering lab-grade motion
analysis on-course and supporting early detection of anomalous movement
patterns. Explainability methods reveal subtle, individualized movement
signatures, reinforcing the view that variability is a hallmark of skilled
performance. Longitudinal tracking demonstrates practical value: as one
player's handicap improved from 50 to 2.2 over 1.5 years, our system captured
measurable technical progress and provided targeted, actionable feedback. Our
findings challenge common assumptions, such as swing consistency across clubs
and the existence of a single "ideal" swing, and uncover latent biomarkers
shaped by both intrinsic traits and task-specific constraints. This work
bridges lab and field-based biomechanics, offering scalable, accessible,
high-fidelity motion analysis for research, coaching, and injury prevention,
while opening new directions in movement-based phenotyping, personalized
equipment design, and motor skill development.

</details>


### [154] [Scene-R1: Video-Grounded Large Language Models for 3D Scene Reasoning without 3D Annotations](https://arxiv.org/abs/2506.17545)
*Zhihao Yuan,Shuyi Jiang,Chun-Mei Feng,Yaolun Zhang,Shuguang Cui,Zhen Li,Na Zhao*

Main category: cs.CV

TL;DR: Scene-R1是一个基于视频的框架，通过强化学习驱动的推理和两阶段接地管道，无需3D实例监督即可理解3D场景。


<details>
  <summary>Details</summary>
Motivation: 现有3D感知LLM是黑盒，依赖预训练3D检测器，缺乏透明决策过程。Scene-R1旨在消除对3D检测器的依赖，并提供透明推理。

Method: 采用两阶段接地管道：时间接地选择相关视频片段，图像接地预测2D边界框，并通过SAM2跟踪对象生成像素级掩码，最终投影回3D。

Result: Scene-R1在多个数据集上超越现有基线，提供透明逐步推理，且仅需任务级2D框或文本标签。

Conclusion: 结合强化学习和RGB-D视频，Scene-R1提供了一种高效、透明的3D场景理解方法。

Abstract: Currently, utilizing large language models to understand the 3D world is
becoming popular. Yet existing 3D-aware LLMs act as black boxes: they output
bounding boxes or textual answers without revealing how those decisions are
made, and they still rely on pre-trained 3D detectors to supply object
proposals. We introduce Scene-R1, a video-grounded framework that learns to
reason about 3D scenes without any point-wise 3D instance supervision by
pairing reinforcement-learning-driven reasoning with a two-stage grounding
pipeline. In the temporal grounding stage, we explicitly reason about the video
and select the video snippets most relevant to an open-ended query. In the
subsequent image grounding stage, we analyze the image and predict the 2D
bounding box. After that, we track the object using SAM2 to produce
pixel-accurate masks in RGB frames, and project them back into 3D, thereby
eliminating the need for 3D detector-based proposals while capturing fine
geometry and material cues. Scene-R1 can also adapt to the 3D visual question
answering task to answer free-form questions directly from video. Our training
pipeline only needs task-level 2D boxes or textual labels without dense 3D
point-wise labels. Scene-R1 surpasses existing open-vocabulary baselines on
multiple datasets, while delivering transparent, step-by-step rationales. These
results show that reinforcement-learning-based reasoning combined with RGB-D
video alone offers a practical, annotation-efficient route to trustworthy 3D
scene understanding.

</details>


### [155] [SynDaCaTE: A Synthetic Dataset For Evaluating Part-Whole Hierarchical Inference](https://arxiv.org/abs/2506.17558)
*Jake Levi,Mark van der Wilk*

Main category: cs.CV

TL;DR: 论文提出了一种名为SynDaCaTE的合成数据集，用于测试和评估胶囊网络在推断部分-整体层次结构方面的能力，并展示了现有模型的瓶颈以及自注意力机制的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决现有胶囊网络在监督任务中难以验证是否真正学习到部分-整体层次结构的问题。

Method: 方法是通过创建合成数据集SynDaCaTE，并利用其测试现有胶囊模型的性能，同时验证自注意力机制在部分-整体推理中的有效性。

Result: 结果显示现有胶囊模型存在瓶颈，而自注意力机制在部分-整体推理中表现优异。

Conclusion: 结论是自注意力机制为计算机视觉中的有效归纳偏置设计提供了新的方向。

Abstract: Learning to infer object representations, and in particular part-whole
hierarchies, has been the focus of extensive research in computer vision, in
pursuit of improving data efficiency, systematic generalisation, and
robustness. Models which are \emph{designed} to infer part-whole hierarchies,
often referred to as capsule networks, are typically trained end-to-end on
supervised tasks such as object classification, in which case it is difficult
to evaluate whether such a model \emph{actually} learns to infer part-whole
hierarchies, as claimed. To address this difficulty, we present a SYNthetic
DAtaset for CApsule Testing and Evaluation, abbreviated as SynDaCaTE, and
establish its utility by (1) demonstrating the precise bottleneck in a
prominent existing capsule model, and (2) demonstrating that
permutation-equivariant self-attention is highly effective for parts-to-wholes
inference, which motivates future directions for designing effective inductive
biases for computer vision.

</details>


### [156] [VLA-OS: Structuring and Dissecting Planning Representations and Paradigms in Vision-Language-Action Models](https://arxiv.org/abs/2506.17561)
*Chongkai Gao,Zixuan Liu,Zhenghao Chi,Junshan Huang,Xin Fei,Yiwen Hou,Yuxuan Zhang,Yudi Lin,Zhirui Fang,Zeyu Jiang,Lin Shao*

Main category: cs.CV

TL;DR: 近期研究从端到端动作生成转向任务规划与动作生成的管道，性能提升但方法差异大。本文提出VLA-OS统一架构，实验表明视觉规划优于语言规划，分层VLA范式表现最佳但速度较慢。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型方法差异大，难以明确性能提升来源，需系统研究规划范式与表示的影响。

Method: 提出VLA-OS统一架构，设计多维度实验（物体类别、视觉模态、环境、执行器）对比不同规划范式与表示。

Result: 视觉规划优于语言规划；分层VLA范式在任务性能、泛化等方面表现最佳，但训练和推理速度较慢。

Conclusion: 视觉规划和分层VLA范式是未来研究方向，需权衡性能与效率。

Abstract: Recent studies on Vision-Language-Action (VLA) models have shifted from the
end-to-end action-generation paradigm toward a pipeline involving task planning
followed by action generation, demonstrating improved performance on various
complex, long-horizon manipulation tasks. However, existing approaches vary
significantly in terms of network architectures, planning paradigms,
representations, and training data sources, making it challenging for
researchers to identify the precise sources of performance gains and components
to be further improved. To systematically investigate the impacts of different
planning paradigms and representations isolating from network architectures and
training data, in this paper, we introduce VLA-OS, a unified VLA architecture
series capable of various task planning paradigms, and design a comprehensive
suite of controlled experiments across diverse object categories (rigid and
deformable), visual modalities (2D and 3D), environments (simulation and
real-world), and end-effectors (grippers and dexterous hands). Our results
demonstrate that: 1) visually grounded planning representations are generally
better than language planning representations; 2) the Hierarchical-VLA paradigm
generally achieves superior or comparable performance than other paradigms on
task performance, pretraining, generalization ability, scalability, and
continual learning ability, albeit at the cost of slower training and inference
speeds.

</details>


### [157] [LLM-driven Medical Report Generation via Communication-efficient Heterogeneous Federated Learning](https://arxiv.org/abs/2506.17562)
*Haoxuan Che,Haibo Jin,Zhengrui Guo,Yi Lin,Cheng Jin,Hao Chen*

Main category: cs.CV

TL;DR: FedMRG是一个利用联邦学习（FL）开发隐私保护的LLM驱动医学报告生成（MRG）模型的框架，解决了多中心数据分散和通信效率问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像-报告数据分散且受隐私法规限制，阻碍了LLM驱动MRG模型的发展。

Method: 采用低秩分解减少通信开销，结合客户端感知对比学习和双适配器机制处理数据异质性。

Result: FedMRG在多中心数据上表现出良好的泛化性和适应性，同时保持通信效率。

Conclusion: FedMRG为隐私保护的多中心MRG模型开发提供了可行方案。

Abstract: LLMs have demonstrated significant potential in Medical Report Generation
(MRG), yet their development requires large amounts of medical image-report
pairs, which are commonly scattered across multiple centers. Centralizing these
data is exceptionally challenging due to privacy regulations, thereby impeding
model development and broader adoption of LLM-driven MRG models. To address
this challenge, we present FedMRG, the first framework that leverages Federated
Learning (FL) to enable privacy-preserving, multi-center development of
LLM-driven MRG models, specifically designed to overcome the critical challenge
of communication-efficient LLM training under multi-modal data heterogeneity.
To start with, our framework tackles the fundamental challenge of communication
overhead in FL-LLM tuning by employing low-rank factorization to efficiently
decompose parameter updates, significantly reducing gradient transmission costs
and making LLM-driven MRG feasible in bandwidth-constrained FL settings.
Furthermore, we observed the dual heterogeneity in MRG under the FL scenario:
varying image characteristics across medical centers, as well as diverse
reporting styles and terminology preferences. To address this, we further
enhance FedMRG with (1) client-aware contrastive learning in the MRG encoder,
coupled with diagnosis-driven prompts, which capture both globally
generalizable and locally distinctive features while maintaining diagnostic
accuracy; and (2) a dual-adapter mutual boosting mechanism in the MRG decoder
that harmonizes generic and specialized adapters to address variations in
reporting styles and terminology. Through extensive evaluation of our
established FL-MRG benchmark, we demonstrate the generalizability and
adaptability of FedMRG, underscoring its potential in harnessing multi-center
data and generating clinically accurate reports while maintaining communication
efficiency.

</details>


### [158] [HalluRNN: Mitigating Hallucinations via Recurrent Cross-Layer Reasoning in Large Vision-Language Models](https://arxiv.org/abs/2506.17587)
*Le Yu,Kaishen Wang,Jianlong Xiong,Yue Cao,Tao He*

Main category: cs.CV

TL;DR: HalluRNN通过引入双门深度传播单元（DG-DPU）模块，以架构级解决方案减少大型视觉语言模型（LVLM）的幻觉问题，仅需微调DG-DPU即可在多基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）易产生视觉无根据的幻觉输出，现有方法通常需要大量资源或任务特定配置。

Method: 提出HalluRNN架构，采用双门深度传播单元（DG-DPU）模块，通过跨层循环推理增强模型稳定性。

Result: 仅微调DG-DPU模块，HalluRNN在多个基准测试中表现出色且稳健。

Conclusion: HalluRNN提供了一种高效且资源友好的方法，显著减少了LVLM的幻觉问题。

Abstract: Though Large Vision-Language Models (LVLMs) have achieved remarkable
performance across various tasks, they are still prone to
hallucinations-generating outputs that are textually plausible but visually
ungrounded. While prior approaches generally address this issue through
data-centric fine-tuning or innovative decoding strategies, these methods often
require substantial resources or task-specific configurations. In this work, we
introduce an architecture-level solution, HalluRNN, which enhances model
stability through recurrent cross-layer reasoning. Specifically, we propose a
novel Dual-Gated Depth Propagation Unit (DG-DPU) module, which is shared across
layers and recurrently refines hidden states. This allows for the adaptive
propagation of information throughout the model, enforces consistency across
layers, and mitigates hallucinations caused by representational drift. By
fine-tuning only the DG-DPU module, HalluRNN achieves strong and robust
performance across multiple benchmarks.

</details>


### [159] [DRAMA-X: A Fine-grained Intent Prediction and Risk Reasoning Benchmark For Driving](https://arxiv.org/abs/2506.17590)
*Mihir Godbole,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 论文介绍了DRAMA-X基准，用于评估自动驾驶中行人意图预测、风险评估等任务，并提出了SGG-Intent框架。


<details>
  <summary>Details</summary>
Motivation: 理解行人短期运动意图对自动驾驶安全至关重要，但目前缺乏相关评估基准。

Method: 通过自动化标注流程构建DRAMA-X基准，并提出SGG-Intent框架，结合视觉语言模型和场景图推理。

Result: 实验表明，基于场景图的推理能提升意图预测和风险评估性能。

Conclusion: DRAMA-X为自动驾驶决策提供了结构化评估工具，SGG-Intent框架展示了有效性。

Abstract: Understanding the short-term motion of vulnerable road users (VRUs) like
pedestrians and cyclists is critical for safe autonomous driving, especially in
urban scenarios with ambiguous or high-risk behaviors. While vision-language
models (VLMs) have enabled open-vocabulary perception, their utility for
fine-grained intent reasoning remains underexplored. Notably, no existing
benchmark evaluates multi-class intent prediction in safety-critical
situations, To address this gap, we introduce DRAMA-X, a fine-grained benchmark
constructed from the DRAMA dataset via an automated annotation pipeline.
DRAMA-X contains 5,686 accident-prone frames labeled with object bounding
boxes, a nine-class directional intent taxonomy, binary risk scores,
expert-generated action suggestions for the ego vehicle, and descriptive motion
summaries. These annotations enable a structured evaluation of four
interrelated tasks central to autonomous decision-making: object detection,
intent prediction, risk assessment, and action suggestion. As a reference
baseline, we propose SGG-Intent, a lightweight, training-free framework that
mirrors the ego vehicle's reasoning pipeline. It sequentially generates a scene
graph from visual input using VLM-backed detectors, infers intent, assesses
risk, and recommends an action using a compositional reasoning stage powered by
a large language model. We evaluate a range of recent VLMs, comparing
performance across all four DRAMA-X tasks. Our experiments demonstrate that
scene-graph-based reasoning enhances intent prediction and risk assessment,
especially when contextual cues are explicitly modeled.

</details>


### [160] [SELFI: Selective Fusion of Identity for Generalizable Deepfake Detection](https://arxiv.org/abs/2506.17592)
*Younghun Kim,Minsuk Jang,Myung-Joon Kwon,Wonjun Lee,Changick Kim*

Main category: cs.CV

TL;DR: 论文提出SELFI框架，动态调节身份特征用于深度伪造检测，实验表明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决身份特征在深度伪造检测中的矛盾观点，提出动态调节身份特征的方法。

Method: 提出SELFI框架，包括FAIA（提取并投影身份特征）和IAFM（选择性融合身份与视觉特征）。

Result: 在四个基准测试中，SELFI平均AUC提升3.1%，在DFDC数据集上提升6%。

Conclusion: 身份特征应动态调节而非盲目抑制或依赖，SELFI框架显著提升检测性能。

Abstract: Face identity provides a powerful signal for deepfake detection. Prior
studies show that even when not explicitly modeled, classifiers often learn
identity features implicitly. This has led to conflicting views: some suppress
identity cues to reduce bias, while others rely on them as forensic evidence.
To reconcile these views, we analyze two hypotheses: (1) whether face identity
alone is discriminative for detecting deepfakes, and (2) whether such identity
features generalize poorly across manipulation methods. Our experiments confirm
that identity is informative but context-dependent. While some manipulations
preserve identity-consistent artifacts, others distort identity cues and harm
generalization. We argue that identity features should neither be blindly
suppressed nor relied upon, but instead be explicitly modeled and adaptively
controlled based on per-sample relevance. We propose \textbf{SELFI}
(\textbf{SEL}ective \textbf{F}usion of \textbf{I}dentity), a generalizable
detection framework that dynamically modulates identity usage. SELFI consists
of: (1) a Forgery-Aware Identity Adapter (FAIA) that extracts identity
embeddings from a frozen face recognition model and projects them into a
forgery-relevant space via auxiliary supervision; and (2) an Identity-Aware
Fusion Module (IAFM) that selectively integrates identity and visual features
using a relevance-guided fusion mechanism. Experiments on four benchmarks show
that SELFI improves cross-manipulation generalization, outperforming prior
methods by an average of 3.1\% AUC. On the challenging DFDC dataset, SELFI
exceeds the previous best by 6\%. Code will be released upon paper acceptance.

</details>


### [161] [A Multimodal In Vitro Diagnostic Method for Parkinson's Disease Combining Facial Expressions and Behavioral Gait Data](https://arxiv.org/abs/2506.17596)
*Wei Huang,Yinxuan Xu,Yintao Zhou,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 提出一种基于面部表情和行为步态的多模态体外诊断方法，用于帕金森病的早期检测，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 帕金森病（PD）的不可治愈性、快速进展和严重残疾对患者及其家庭造成巨大挑战，老龄化社会对早期检测的需求增加。

Method: 采用轻量级深度学习模型进行特征提取和融合，结合面部表情和行为步态数据，提高诊断准确性并便于移动设备部署。

Result: 建立了最大的多模态PD数据集，并通过实验验证了方法的有效性。

Conclusion: 该方法为PD的早期检测提供了一种高效、低成本且易于推广的解决方案。

Abstract: Parkinson's disease (PD), characterized by its incurable nature, rapid
progression, and severe disability, poses significant challenges to the lives
of patients and their families. Given the aging population, the need for early
detection of PD is increasing. In vitro diagnosis has garnered attention due to
its non-invasive nature and low cost. However, existing methods present several
challenges: 1) limited training data for facial expression diagnosis; 2)
specialized equipment and acquisition environments required for gait diagnosis,
resulting in poor generalizability; 3) the risk of misdiagnosis or missed
diagnosis when relying on a single modality. To address these issues, we
propose a novel multimodal in vitro diagnostic method for PD, leveraging facial
expressions and behavioral gait. Our method employs a lightweight deep learning
model for feature extraction and fusion, aimed at improving diagnostic accuracy
and facilitating deployment on mobile devices. Furthermore, we have established
the largest multimodal PD dataset in collaboration with a hospital and
conducted extensive experiments to validate the effectiveness of our proposed
method.

</details>


### [162] [OpenMAP-BrainAge: Generalizable and Interpretable Brain Age Predictor](https://arxiv.org/abs/2506.17597)
*Pengyu Kan,Craig Jones,Kenichi Oishi*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的年龄预测模型，通过自监督预训练和多视图MRI数据处理，实现了高精度、可解释性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种可解释且对人口统计学和技术差异具有鲁棒性的脑MRI年龄预测模型。

Method: 采用Transformer架构，结合自监督预训练和伪3D T1加权MRI多视图处理，引入stem架构降低计算复杂度。

Result: 在ADNI2 & 3和OASIS3测试集上MAE为3.65年，AIBL上MAE为3.54年，脑年龄差与认知功能显著相关。

Conclusion: 模型融合多视图和体积信息，实现了高精度、泛化性和可解释性，并与神经退行性疾病相关。

Abstract: Purpose: To develop an age prediction model which is interpretable and robust
to demographic and technological variances in brain MRI scans. Materials and
Methods: We propose a transformer-based architecture that leverages
self-supervised pre-training on large-scale datasets. Our model processes
pseudo-3D T1-weighted MRI scans from three anatomical views and incorporates
brain volumetric information. By introducing a stem architecture, we reduce the
conventional quadratic complexity of transformer models to linear complexity,
enabling scalability for high-dimensional MRI data. We trained our model on
ADNI2 $\&$ 3 (N=1348) and OASIS3 (N=716) datasets (age range: 42 - 95) from the
North America, with an 8:1:1 split for train, validation and test. Then, we
validated it on the AIBL dataset (N=768, age range: 60 - 92) from Australia.
Results: We achieved an MAE of 3.65 years on ADNI2 $\&$ 3 and OASIS3 test set
and a high generalizability of MAE of 3.54 years on AIBL. There was a notable
increase in brain age gap (BAG) across cognitive groups, with mean of 0.15
years (95% CI: [-0.22, 0.51]) in CN, 2.55 years ([2.40, 2.70]) in MCI, 6.12
years ([5.82, 6.43]) in AD. Additionally, significant negative correlation
between BAG and cognitive scores was observed, with correlation coefficient of
-0.185 (p < 0.001) for MoCA and -0.231 (p < 0.001) for MMSE. Gradient-based
feature attribution highlighted ventricles and white matter structures as key
regions influenced by brain aging. Conclusion: Our model effectively fused
information from different views and volumetric information to achieve
state-of-the-art brain age prediction accuracy, improved generalizability and
interpretability with association to neurodegenerative disorders.

</details>


### [163] [HIRE: Lightweight High-Resolution Image Feature Enrichment for Multimodal LLMs](https://arxiv.org/abs/2506.17608)
*Nikitha SR,Aradhya Neeraj Mathur,Tarun Ram Menta,Rishabh Jain,Mausoom Sarkar*

Main category: cs.CV

TL;DR: 论文提出了一种浅层特征增强方法，通过特征上采样显著降低计算成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率图像特征在多模态大语言模型中表现优异，但计算成本高，需多次调用大型图像编码器。

Method: 提出浅层特征增强器，通过特征上采样减少计算量。

Result: 实验表明，该方法在训练和推理时间上显著降低，FLOPs节省高达1.5倍。

Conclusion: 浅层特征增强是一种高效的高分辨率特征生成方法，可显著减少计算成本。

Abstract: The integration of high-resolution image features in modern multimodal large
language models has demonstrated significant improvements in fine-grained
visual understanding tasks, achieving high performance across multiple
benchmarks. Since these features are obtained from large image encoders like
ViT, they come with a significant increase in computational costs due to
multiple calls to these encoders. In this work, we first develop an intuition
for feature upsampling as a natural extension of high-resolution feature
generation. Through extensive experiments and ablations, we demonstrate how a
shallow feature enricher can achieve competitive results with tremendous
reductions in training and inference time as well as computational cost, with
upto 1.5x saving in FLOPs.

</details>


### [164] [JarvisArt: Liberating Human Artistic Creativity via an Intelligent Photo Retouching Agent](https://arxiv.org/abs/2506.17612)
*Yunlong Lin,Zixu Lin,Kunjie Lin,Jinbin Bai,Panwang Pan,Chenxin Li,Haoyu Chen,Zhongdao Wang,Xinghao Ding,Wenbo Li,Shuicheng Yan*

Main category: cs.CV

TL;DR: JarvisArt是一个基于多模态大语言模型的智能修图代理，通过理解用户意图和模仿专业艺术家的推理过程，协调Lightroom中的200多种工具，实现高效且个性化的照片编辑。


<details>
  <summary>Details</summary>
Motivation: 现有AI修图工具自动化程度高但调整性和泛化能力不足，无法满足多样化和个性化需求，而专业工具如Lightroom需要大量手动操作和专业知识。

Method: JarvisArt采用两阶段训练：首先通过Chain-of-Thought监督微调建立基本推理和工具使用能力，然后通过GRPO-R优化决策和工具熟练度，并提出Agent-to-Lightroom协议实现无缝集成。

Result: JarvisArt在MMArt-Bench上表现出色，内容保真度比GPT-4o提升60%，同时保持指令跟随能力，支持全局和局部精细调整。

Conclusion: JarvisArt通过智能代理和工具协调，为智能修图开辟了新途径，兼具用户友好性和高性能。

Abstract: Photo retouching has become integral to contemporary visual storytelling,
enabling users to capture aesthetics and express creativity. While professional
tools such as Adobe Lightroom offer powerful capabilities, they demand
substantial expertise and manual effort. In contrast, existing AI-based
solutions provide automation but often suffer from limited adjustability and
poor generalization, failing to meet diverse and personalized editing needs. To
bridge this gap, we introduce JarvisArt, a multi-modal large language model
(MLLM)-driven agent that understands user intent, mimics the reasoning process
of professional artists, and intelligently coordinates over 200 retouching
tools within Lightroom. JarvisArt undergoes a two-stage training process: an
initial Chain-of-Thought supervised fine-tuning to establish basic reasoning
and tool-use skills, followed by Group Relative Policy Optimization for
Retouching (GRPO-R) to further enhance its decision-making and tool
proficiency. We also propose the Agent-to-Lightroom Protocol to facilitate
seamless integration with Lightroom. To evaluate performance, we develop
MMArt-Bench, a novel benchmark constructed from real-world user edits.
JarvisArt demonstrates user-friendly interaction, superior generalization, and
fine-grained control over both global and local adjustments, paving a new
avenue for intelligent photo retouching. Notably, it outperforms GPT-4o with a
60% improvement in average pixel-level metrics on MMArt-Bench for content
fidelity, while maintaining comparable instruction-following capabilities.
Project Page: https://jarvisart.vercel.app/.

</details>


### [165] [CLiViS: Unleashing Cognitive Map through Linguistic-Visual Synergy for Embodied Visual Reasoning](https://arxiv.org/abs/2506.17629)
*Kailing Li,Qi'ao Xu,Tianwen Qian,Yuqian Fu,Yang Jiao,Xiaoling Wang*

Main category: cs.CV

TL;DR: CLiViS是一个无需训练的新框架，结合LLMs的任务规划和VLMs的视觉感知，通过动态认知地图实现高效的视觉推理。


<details>
  <summary>Details</summary>
Motivation: 解决EVR中复杂指令和长视频时空动态的挑战，弥补现有方法在视觉细节和逐步推理上的不足。

Method: 利用LLMs进行高层任务规划，结合VLMs的开放世界视觉感知，通过动态认知地图迭代更新场景上下文。

Result: 在多个基准测试中表现优异，尤其在处理长期视觉依赖方面。

Conclusion: CLiViS通过结合LLMs和VLMs的优势，显著提升了视觉推理能力。

Abstract: Embodied Visual Reasoning (EVR) seeks to follow complex, free-form
instructions based on egocentric video, enabling semantic understanding and
spatiotemporal reasoning in dynamic environments. Despite its promising
potential, EVR encounters significant challenges stemming from the diversity of
complex instructions and the intricate spatiotemporal dynamics in long-term
egocentric videos. Prior solutions either employ Large Language Models (LLMs)
over static video captions, which often omit critical visual details, or rely
on end-to-end Vision-Language Models (VLMs) that struggle with stepwise
compositional reasoning. Consider the complementary strengths of LLMs in
reasoning and VLMs in perception, we propose CLiViS. It is a novel
training-free framework that leverages LLMs for high-level task planning and
orchestrates VLM-driven open-world visual perception to iteratively update the
scene context. Building on this synergy, the core of CLiViS is a dynamic
Cognitive Map that evolves throughout the reasoning process. This map
constructs a structured representation of the embodied scene, bridging
low-level perception and high-level reasoning. Extensive experiments across
multiple benchmarks demonstrate the effectiveness and generality of CLiViS,
especially in handling long-term visual dependencies. Code is available at
https://github.com/Teacher-Tom/CLiViS.

</details>


### [166] [Optimization-Free Patch Attack on Stereo Depth Estimation](https://arxiv.org/abs/2506.17632)
*Hangcheng Liu,Xu Kuang,Xingshuo Han,Xingwan Wu,Haoran Ou,Shangwei Guo,Xingyi Huang,Tao Xiang,Tianwei Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种名为PatchHunter的对抗性补丁攻击方法，针对立体深度估计（SDE）模型，解决了现有攻击方法在物理可实现性和迁移性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在立体深度估计中局限于不现实的数字扰动场景，缺乏物理可实现性和迁移性，因此需要设计一种更实用的攻击方法。

Method: 提出PatchHunter，一种无优化的对抗补丁攻击方法，通过强化学习驱动的视觉模式搜索来生成补丁，破坏SDE模型的假设。

Result: PatchHunter在KITTI数据集、CARLA模拟器和真实车辆部署中表现出色，攻击成功率高且迁移性强，优于优化方法。

Conclusion: PatchHunter为立体深度估计模型提供了一种物理可实现、场景自适应且迁移性强的对抗攻击方法。

Abstract: Stereo Depth Estimation (SDE) is essential for scene understanding in
vision-based systems like autonomous driving. However, recent studies show that
SDE models are vulnerable to adversarial attacks, which are often limited to
unrealistic settings, e.g., digital perturbations on separate stereo views in
static scenes, restricting their real-world applicability. This raises a
critical question: how can we design physically realizable, scene-adaptive, and
transferable attacks against SDE under realistic constraints?
  To answer this, we make two key contributions. First, we propose a unified
attack framework that extends optimization-based techniques to four core stages
of stereo matching: feature extraction, cost-volume construction, cost
aggregation, and disparity regression. A comprehensive stage-wise evaluation
across 9 mainstream SDE models, under constraints like photometric consistency,
reveals that optimization-based patches suffer from poor transferability.
Interestingly, partially transferable patches suggest that patterns, rather
than pixel-level perturbations, may be key to generalizable attacks. Motivated
by this, we present PatchHunter, the first optimization-free adversarial patch
attack against SDE. PatchHunter formulates patch generation as a reinforcement
learning-driven search over a structured space of visual patterns crafted to
disrupt SDE assumptions.
  We validate PatchHunter across three levels: the KITTI dataset, the CARLA
simulator, and real-world vehicle deployment. PatchHunter not only surpasses
optimization-based methods in effectiveness but also achieves significantly
better black-box transferability. Even under challenging physical conditions
like low light, PatchHunter maintains high attack success (e.g., D1-all > 0.4),
whereas optimization-based methods fail.

</details>


### [167] [Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection](https://arxiv.org/abs/2506.17633)
*Xiang Fang,Arvind Easwaran,Blaise Genest*

Main category: cs.CV

TL;DR: 论文提出了一种名为AMCN的新网络，用于解决少样本OOD检测问题，通过自适应多提示对比学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统OOD检测方法需要大量训练样本，限制了实际应用。少样本OOD检测更具挑战性，且现有方法忽略了类间多样性。

Method: 提出AMCN网络，利用CLIP连接文本与图像，生成自适应提示（可学习的ID提示和OOD提示），并通过类阈值和提示引导模块优化ID-OOD分离。

Result: 实验表明AMCN在少样本OOD检测任务中优于现有方法。

Conclusion: AMCN通过自适应提示和类边界优化，显著提升了少样本OOD检测的性能。

Abstract: Out-of-distribution (OOD) detection attempts to distinguish outlier samples
to prevent models trained on the in-distribution (ID) dataset from producing
unavailable outputs. Most OOD detection methods require many IID samples for
training, which seriously limits their real-world applications. To this end, we
target a challenging setting: few-shot OOD detection, where {Only a few {\em
labeled ID} samples are available.} Therefore, few-shot OOD detection is much
more challenging than the traditional OOD detection setting. Previous few-shot
OOD detection works ignore the distinct diversity between different classes. In
this paper, we propose a novel network: Adaptive Multi-prompt Contrastive
Network (AMCN), which adapts the ID-OOD separation boundary by learning inter-
and intra-class distribution. To compensate for the absence of OOD and scarcity
of ID {\em image samples}, we leverage CLIP, connecting text with images,
engineering learnable ID and OOD {\em textual prompts}. Specifically, we first
generate adaptive prompts (learnable ID prompts, label-fixed OOD prompts and
label-adaptive OOD prompts). Then, we generate an adaptive class boundary for
each class by introducing a class-wise threshold. Finally, we propose a
prompt-guided ID-OOD separation module to control the margin between ID and OOD
prompts. Experimental results show that AMCN outperforms other state-of-the-art
works.

</details>


### [168] [Histopathology Image Report Generation by Vision Language Model with Multimodal In-Context Learning](https://arxiv.org/abs/2506.17645)
*Shih-Wen Liu,Hsuan-Yu Fan,Wei-Ta Chu,Fu-En Yang,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: PathGenIC框架通过上下文学习和自适应反馈，显著提升了医学报告生成的性能，在HistGen基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化生成医学报告需要有效的视觉表示和领域知识，而现有方法缺乏上下文整合能力。

Method: 提出PathGenIC框架，结合多模态上下文学习机制，动态检索相似图像-报告对并引入自适应反馈。

Result: 在HistGen基准测试中，BLEU、METEOR和ROUGE-L指标显著提升，且对不同报告长度和疾病类别具有鲁棒性。

Conclusion: PathGenIC为AI驱动的病理报告生成提供了有效解决方案，为未来多模态临床应用奠定了基础。

Abstract: Automating medical report generation from histopathology images is a critical
challenge requiring effective visual representations and domain-specific
knowledge. Inspired by the common practices of human experts, we propose an
in-context learning framework called PathGenIC that integrates context derived
from the training set with a multimodal in-context learning (ICL) mechanism.
Our method dynamically retrieves semantically similar whole slide image
(WSI)-report pairs and incorporates adaptive feedback to enhance contextual
relevance and generation quality. Evaluated on the HistGen benchmark, the
framework achieves state-of-the-art results, with significant improvements
across BLEU, METEOR, and ROUGE-L metrics, and demonstrates robustness across
diverse report lengths and disease categories. By maximizing training data
utility and bridging vision and language with ICL, our work offers a solution
for AI-driven histopathology reporting, setting a strong foundation for future
advancements in multimodal clinical applications.

</details>


### [169] [MDSAM:Memory-Driven Sparse Attention Matrix for LVLMs Hallucination Mitigation](https://arxiv.org/abs/2506.17664)
*Shuaiye Lu,Linjiang Zhou,Xiaochuan Shi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的MDSAM方法，通过动态调整图像标记的注意力来减少大型视觉语言模型中的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在解码时对图像标记的敏感性导致幻觉现象，表现为注意力峰值。

Method: 提出MDSAM方法，动态捕捉和优化每层对图像标记的注意力分配，通过记忆注意力模式并在解码时对齐激活更新。

Result: 在图像描述和视觉问答等任务中，MDSAM能持续减少幻觉并提高可靠性，且兼容多种模型架构。

Conclusion: MDSAM无需额外训练或外部工具，有效减少幻觉，展示了其适应性和有效性。

Abstract: Hallucinations in large vision-language models (LVLMs) often stem from the
model's sensitivity to image tokens during decoding, as evidenced by attention
peaks observed when generating both real and hallucinated entities. To address
this, we propose Memory-Driven Sparse Attention Matrix (MDSAM) , a novel
training-free approach that dynamically captures and refines the attention
allocated to image tokens at each layer. MDSAM memorizes attention patterns and
activates updates through alignment during decoding, enhancing focus on
relevant image tokens while effectively reducing hallucinations. We evaluate
MDSAM on multiple benchmarks for tasks such as image captioning and visual
question answering, demonstrating its ability to consistently reduce
hallucinations and improve reliability. Compatible with various LVLM
architectures, MDSAM highlights its adaptability and effectiveness in
mitigating hallucinations without requiring additional training or external
tools.

</details>


### [170] [CSDN: A Context-Gated Self-Adaptive Detection Network for Real-Time Object Detection](https://arxiv.org/abs/2506.17679)
*Wei Haolin*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的检测头CSDN，通过新颖的门控机制替代传统的自注意力和交叉注意力层，提升了目标检测的全局上下文建模能力。


<details>
  <summary>Details</summary>
Motivation: 解决CNN在目标检测中因有限感受野而难以捕捉全局上下文信息的问题，并优化特征利用效率。

Method: 引入CSDN，采用门控机制自适应选择和组合多注意力模式的特征维度和尺度信息。

Result: CSDN显著提升了检测精度，且仅需少量微调即可适配多种CNN检测器。

Conclusion: CSDN为基于CNN的检测器提供了一种高效且灵活的全局上下文建模解决方案。

Abstract: Convolutional neural networks (CNNs) have long been the cornerstone of target
detection, but they are often limited by limited receptive fields, which
hinders their ability to capture global contextual information. This paper
believes that the effective utilization of extracted features is as important
as the feature extraction process itself. We critically re-evaluated the
DETR-inspired header network architecture, questioning the indispensable nature
of its self-attention mechanism, and discovering significant information
redundancies. To solve these problems, we introduced the Context-Gated
Scale-Adaptive Detection Network (CSDN), a Transformer-based detection header
inspired by natural language processing architecture and human visual
perception. CSDN aims to efficiently utilize the characteristics of the CNN
backbone network by replacing the traditional stacked self-attention and
cross-attention layers with a novel gating mechanism. This mechanism enables
each region of interest (ROI) to adaptively select and combine feature
dimensions and scale information from multiple attention patterns. CSDN
provides more powerful global context modeling capabilities and can better
adapt to objects of different sizes and structures. Our proposed detection head
can directly replace the native heads of various CNN-based detectors, and only
a few rounds of fine-tuning on the pre-training weights can significantly
improve the detection accuracy, thus avoiding the need to achieve small
improvements. Various layer modules undergo extensive re-training.

</details>


### [171] [Domain Generalization using Action Sequences for Egocentric Action Recognition](https://arxiv.org/abs/2506.17685)
*Amirshayan Nasirimajd,Chiara Plizzari,Simone Alberto Peirone,Marco Ciccone,Giuseppe Averta,Barbara Caputo*

Main category: cs.CV

TL;DR: 论文提出了一种名为SeqDG的领域泛化方法，通过利用动作序列的一致性来提升模型在未见环境中的泛化能力，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决Egocentric Action Recognition模型在未见训练环境时性能下降的问题。

Method: 提出SeqDG方法，包括视觉-文本序列重构目标（SeqRec）和跨领域动作序列混合训练（SeqMix）。

Result: 在EPIC-KITCHENS-100上，跨领域动作识别性能提升2.4%；在EGTEA上，Top-1准确率提升0.6%。

Conclusion: SeqDG通过动作序列的一致性提升了模型在未见环境中的泛化能力，实验证明了其有效性。

Abstract: Recognizing human activities from visual inputs, particularly through a
first-person viewpoint, is essential for enabling robots to replicate human
behavior. Egocentric vision, characterized by cameras worn by observers,
captures diverse changes in illumination, viewpoint, and environment. This
variability leads to a notable drop in the performance of Egocentric Action
Recognition models when tested in environments not seen during training. In
this paper, we tackle these challenges by proposing a domain generalization
approach for Egocentric Action Recognition. Our insight is that action
sequences often reflect consistent user intent across visual domains. By
leveraging action sequences, we aim to enhance the model's generalization
ability across unseen environments. Our proposed method, named SeqDG,
introduces a visual-text sequence reconstruction objective (SeqRec) that uses
contextual cues from both text and visual inputs to reconstruct the central
action of the sequence. Additionally, we enhance the model's robustness by
training it on mixed sequences of actions from different domains (SeqMix). We
validate SeqDG on the EGTEA and EPIC-KITCHENS-100 datasets. Results on
EPIC-KITCHENS-100, show that SeqDG leads to +2.4% relative average improvement
in cross-domain action recognition in unseen environments, and on EGTEA the
model achieved +0.6% Top-1 accuracy over SOTA in intra-domain action
recognition.

</details>


### [172] [SSAVSV: Towards Unified Model for Self-Supervised Audio-Visual Speaker Verification](https://arxiv.org/abs/2506.17694)
*Gnana Praveen Rajasekhar,Jahangir Alam*

Main category: cs.CV

TL;DR: 提出了一种基于对比学习和掩码数据建模的自监督学习框架，用于音频-视觉说话人验证，减少了计算成本并提升了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统音频-视觉方法依赖大量标注数据和独立模态架构，计算成本高且扩展性差。

Method: 采用自监督对比学习和掩码数据建模，使用共享的视觉Transformer架构处理音频和视觉输入。

Result: 实验表明，该方法在无标注数据的情况下性能优越，且计算成本更低。

Conclusion: 提出的统一框架在计算效率和模态缺失鲁棒性方面表现优异。

Abstract: Conventional audio-visual methods for speaker verification rely on large
amounts of labeled data and separate modality-specific architectures, which is
computationally expensive, limiting their scalability. To address these
problems, we propose a self-supervised learning framework based on contrastive
learning with asymmetric masking and masked data modeling to obtain robust
audiovisual feature representations. In particular, we employ a unified
framework for self-supervised audiovisual speaker verification using a single
shared backbone for audio and visual inputs, leveraging the versatility of
vision transformers. The proposed unified framework can handle audio, visual,
or audiovisual inputs using a single shared vision transformer backbone during
training and testing while being computationally efficient and robust to
missing modalities. Extensive experiments demonstrate that our method achieves
competitive performance without labeled data while reducing computational costs
compared to traditional approaches.

</details>


### [173] [DreamJourney: Perpetual View Generation with Video Diffusion Models](https://arxiv.org/abs/2506.17705)
*Bo Pan,Yang Chen,Yingwei Pan,Ting Yao,Wei Chen,Tao Mei*

Main category: cs.CV

TL;DR: DreamJourney提出了一种两阶段框架，利用视频扩散模型生成具有相机移动和物体动态的长期场景视图。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因缺乏3D感知导致的失真问题，并扩展至动态4D世界的物体运动捕捉。

Method: 第一阶段通过3D点云和视频扩散模型生成一致视图；第二阶段利用多模态大语言模型描述物体运动并生成动态视图。

Result: 实验表明DreamJourney在定量和定性上优于现有方法。

Conclusion: DreamJourney成功实现了长期动态场景视图生成，解决了现有方法的局限性。

Abstract: Perpetual view generation aims to synthesize a long-term video corresponding
to an arbitrary camera trajectory solely from a single input image. Recent
methods commonly utilize a pre-trained text-to-image diffusion model to
synthesize new content of previously unseen regions along camera movement.
However, the underlying 2D diffusion model lacks 3D awareness and results in
distorted artifacts. Moreover, they are limited to generating views of static
3D scenes, neglecting to capture object movements within the dynamic 4D world.
To alleviate these issues, we present DreamJourney, a two-stage framework that
leverages the world simulation capacity of video diffusion models to trigger a
new perpetual scene view generation task with both camera movements and object
dynamics. Specifically, in stage I, DreamJourney first lifts the input image to
3D point cloud and renders a sequence of partial images from a specific camera
trajectory. A video diffusion model is then utilized as generative prior to
complete the missing regions and enhance visual coherence across the sequence,
producing a cross-view consistent video adheres to the 3D scene and camera
trajectory. Meanwhile, we introduce two simple yet effective strategies (early
stopping and view padding) to further stabilize the generation process and
improve visual quality. Next, in stage II, DreamJourney leverages a multimodal
large language model to produce a text prompt describing object movements in
current view, and uses video diffusion model to animate current view with
object movements. Stage I and II are repeated recurrently, enabling perpetual
dynamic scene view generation. Extensive experiments demonstrate the
superiority of our DreamJourney over state-of-the-art methods both
quantitatively and qualitatively. Our project page:
https://dream-journey.vercel.app.

</details>


### [174] [Programmable-Room: Interactive Textured 3D Room Meshes Generation Empowered by Large Language Models](https://arxiv.org/abs/2506.17707)
*Jihyun Kim,Junho Park,Kyeongbo Kong,Suk-Ju Kang*

Main category: cs.CV

TL;DR: Programmable-Room是一个通过自然语言指令交互式生成和编辑3D房间网格的框架，利用视觉编程（VP）和大型语言模型（LLM）分解复杂任务，并通过优化训练目标提升全景图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 为精确控制房间的每个属性，将复杂的3D房间生成任务分解为多个子任务，并通过统一框架支持这些任务。

Method: 使用视觉编程（VP）和LLM生成类似Python的程序，分解任务为生成3D坐标、全景图像纹理、构建3D网格和家具布置。特别优化了基于文本和视觉提示的全景图像生成模块。

Result: 展示了框架在生成和编辑3D房间网格方面的灵活性，并在定量和定性上优于现有模型。

Conclusion: Programmable-Room通过分解任务和优化模块，实现了高效且高质量的3D房间生成和编辑。

Abstract: We present Programmable-Room, a framework which interactively generates and
edits a 3D room mesh, given natural language instructions. For precise control
of a room's each attribute, we decompose the challenging task into simpler
steps such as creating plausible 3D coordinates for room meshes, generating
panorama images for the texture, constructing 3D meshes by integrating the
coordinates and panorama texture images, and arranging furniture. To support
the various decomposed tasks with a unified framework, we incorporate visual
programming (VP). VP is a method that utilizes a large language model (LLM) to
write a Python-like program which is an ordered list of necessary modules for
the various tasks given in natural language. We develop most of the modules.
Especially, for the texture generating module, we utilize a pretrained
large-scale diffusion model to generate panorama images conditioned on text and
visual prompts (i.e., layout, depth, and semantic map) simultaneously.
Specifically, we enhance the panorama image generation quality by optimizing
the training objective with a 1D representation of a panorama scene obtained
from bidirectional LSTM. We demonstrate Programmable-Room's flexibility in
generating and editing 3D room meshes, and prove our framework's superiority to
an existing model quantitatively and qualitatively. Project page is available
in https://jihyun0510.github.io/Programmable_Room_Page/.

</details>


### [175] [PDC-Net: Pattern Divide-and-Conquer Network for Pelvic Radiation Injury Segmentation](https://arxiv.org/abs/2506.17712)
*Xinyu Xiong,Wuteng Cao,Zihuang Wu,Lei Zhang,Chong Gao,Guanbin Li,Qiyuan Qin*

Main category: cs.CV

TL;DR: 提出了一种名为PDC-Net的新方法，用于从MRI中准确分割盆腔放射损伤（PRI），通过多方向聚合模块和记忆引导上下文模块解决复杂形态和上下文混淆问题。


<details>
  <summary>Details</summary>
Motivation: 盆腔放射损伤（PRI）的准确分割对预后评估和个性化治疗计划至关重要，但自动化分割因复杂器官形态和上下文混淆而具有挑战性。

Method: 提出PDC-Net，包含多方向聚合模块（MDA）增强形状拟合能力，记忆引导上下文模块（MGC）提升全局模式区分，以及自适应融合解码器（AFD）动态选择特征。

Result: 在首个大规模盆腔放射损伤数据集上验证，PDC-Net优于现有方法。

Conclusion: PDC-Net通过模块化设计有效解决了PRI分割中的挑战，为临床提供了更精确的工具。

Abstract: Accurate segmentation of Pelvic Radiation Injury (PRI) from Magnetic
Resonance Images (MRI) is crucial for more precise prognosis assessment and the
development of personalized treatment plans. However, automated segmentation
remains challenging due to factors such as complex organ morphologies and
confusing context. To address these challenges, we propose a novel Pattern
Divide-and-Conquer Network (PDC-Net) for PRI segmentation. The core idea is to
use different network modules to "divide" various local and global patterns
and, through flexible feature selection, to "conquer" the Regions of Interest
(ROI) during the decoding phase. Specifically, considering that our ROI often
manifests as strip-like or circular-like structures in MR slices, we introduce
a Multi-Direction Aggregation (MDA) module. This module enhances the model's
ability to fit the shape of the organ by applying strip convolutions in four
distinct directions. Additionally, to mitigate the challenge of confusing
context, we propose a Memory-Guided Context (MGC) module. This module
explicitly maintains a memory parameter to track cross-image patterns at the
dataset level, thereby enhancing the distinction between global patterns
associated with the positive and negative classes. Finally, we design an
Adaptive Fusion Decoder (AFD) that dynamically selects features from different
patterns based on the Mixture-of-Experts (MoE) framework, ultimately generating
the final segmentation results. We evaluate our method on the first large-scale
pelvic radiation injury dataset, and the results demonstrate the superiority of
our PDC-Net over existing approaches.

</details>


### [176] [YOLOv13: Real-Time Object Detection with Hypergraph-Enhanced Adaptive Visual Perception](https://arxiv.org/abs/2506.17733)
*Mengqi Lei,Siqi Li,Yihong Wu,Han Hu,You Zhou,Xinhu Zheng,Guiguang Ding,Shaoyi Du,Zongze Wu,Yue Gao*

Main category: cs.CV

TL;DR: YOLOv13通过HyperACE机制和FullPAD范式解决了YOLO系列在全局高阶相关性建模上的不足，实现了高效的特征融合与增强，同时通过深度可分离卷积降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: YOLO系列在复杂场景中因缺乏全局多对多高阶相关性建模能力而受限，YOLOv13旨在解决这一问题。

Method: 提出HyperACE机制和FullPAD范式，结合深度可分离卷积，优化特征融合与计算效率。

Result: 在MS COCO基准测试中，YOLOv13-N的mAP比YOLO11-N提升3.0%，比YOLOv12-N提升1.5%。

Conclusion: YOLOv13在保持轻量化的同时实现了更优的检测性能，为实时目标检测提供了新方案。

Abstract: The YOLO series models reign supreme in real-time object detection due to
their superior accuracy and computational efficiency. However, both the
convolutional architectures of YOLO11 and earlier versions and the area-based
self-attention mechanism introduced in YOLOv12 are limited to local information
aggregation and pairwise correlation modeling, lacking the capability to
capture global multi-to-multi high-order correlations, which limits detection
performance in complex scenarios. In this paper, we propose YOLOv13, an
accurate and lightweight object detector. To address the above-mentioned
challenges, we propose a Hypergraph-based Adaptive Correlation Enhancement
(HyperACE) mechanism that adaptively exploits latent high-order correlations
and overcomes the limitation of previous methods that are restricted to
pairwise correlation modeling based on hypergraph computation, achieving
efficient global cross-location and cross-scale feature fusion and enhancement.
Subsequently, we propose a Full-Pipeline Aggregation-and-Distribution (FullPAD)
paradigm based on HyperACE, which effectively achieves fine-grained information
flow and representation synergy within the entire network by distributing
correlation-enhanced features to the full pipeline. Finally, we propose to
leverage depthwise separable convolutions to replace vanilla large-kernel
convolutions, and design a series of blocks that significantly reduce
parameters and computational complexity without sacrificing performance. We
conduct extensive experiments on the widely used MS COCO benchmark, and the
experimental results demonstrate that our method achieves state-of-the-art
performance with fewer parameters and FLOPs. Specifically, our YOLOv13-N
improves mAP by 3.0\% over YOLO11-N and by 1.5\% over YOLOv12-N. The code and
models of our YOLOv13 model are available at:
https://github.com/iMoonLab/yolov13.

</details>


### [177] [PhysID: Physics-based Interactive Dynamics from a Single-view Image](https://arxiv.org/abs/2506.17746)
*Sourabh Vasant Gothe,Ayon Chattopadhyay,Gunturi Venkata Sai Phani Kiran,Pratik,Vibhav Agarwal,Jayesh Rajkumar Vachhani,Sourav Ghosh,Parameswaranath VM,Barath Raj KR*

Main category: cs.CV

TL;DR: PhysID通过生成模型从单视图图像创建物理交互动态，简化了3D建模和物理属性校准，实现了实时交互和个性化体验。


<details>
  <summary>Details</summary>
Motivation: 提升移动用户体验，尤其是交互式和AR/VR应用，解决静态图像转化为交互体验的挑战。

Method: 利用生成模型进行3D网格生成和物理属性预测，结合设备端物理引擎实现实时渲染。

Result: 实验验证了多模态大语言模型的零样本能力和3D重建模型的性能，展示了端到端框架的有效性。

Conclusion: PhysID在移动交互动态领域取得显著进展，支持实时、非确定性交互和高效设备内存消耗。

Abstract: Transforming static images into interactive experiences remains a challenging
task in computer vision. Tackling this challenge holds the potential to elevate
mobile user experiences, notably through interactive and AR/VR applications.
Current approaches aim to achieve this either using pre-recorded video
responses or requiring multi-view images as input. In this paper, we present
PhysID, that streamlines the creation of physics-based interactive dynamics
from a single-view image by leveraging large generative models for 3D mesh
generation and physical property prediction. This significantly reduces the
expertise required for engineering-intensive tasks like 3D modeling and
intrinsic property calibration, enabling the process to be scaled with minimal
manual intervention. We integrate an on-device physics-based engine for
physically plausible real-time rendering with user interactions. PhysID
represents a leap forward in mobile-based interactive dynamics, offering
real-time, non-deterministic interactions and user-personalization with
efficient on-device memory consumption. Experiments evaluate the zero-shot
capabilities of various Multimodal Large Language Models (MLLMs) on diverse
tasks and the performance of 3D reconstruction models. These results
demonstrate the cohesive functioning of all modules within the end-to-end
framework, contributing to its effectiveness.

</details>


### [178] [LoLA-SpecViT: Local Attention SwiGLU Vision Transformer with LoRA for Hyperspectral Imaging](https://arxiv.org/abs/2506.17759)
*Fadi Abdeladhim Zidi,Djamel Eddine Boukhari,Abdellah Zakaria Sellam,Abdelkrim Ouafi,Cosimo Distante,Salah Eddine Bekhouche,Abdelmalik Taleb-Ahmed*

Main category: cs.CV

TL;DR: LoLA-SpecViT是一种轻量级光谱视觉Transformer，通过参数高效架构解决了高光谱图像分类中的高维度和标签稀缺问题，结合3D卷积和局部自注意力，显著提升了性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高维度、频带冗余和标签稀缺的挑战，现有Transformer模型在可扩展性和适应性上仍有不足。

Method: 提出LoLA-SpecViT，结合3D卷积前端和局部自注意力，引入低秩适应（LoRA）和循环学习率调度器，减少训练参数并提升适应性。

Result: 在三个基准数据集上，LoLA-SpecViT性能优于现有方法，最高达99.91%准确率，参数更少且标签稀缺下更鲁棒。

Conclusion: LoLA-SpecViT为高光谱图像分类提供了可扩展且通用的解决方案，适用于农业、环境监测等领域。

Abstract: Hyperspectral image classification remains a challenging task due to the high
dimensionality of spectral data, significant inter-band redundancy, and the
limited availability of annotated samples. While recent transformer-based
models have improved the global modeling of spectral-spatial dependencies,
their scalability and adaptability under label-scarce conditions remain
limited. In this work, we propose \textbf{LoLA-SpecViT}(Low-rank adaptation
Local Attention Spectral Vision Transformer), a lightweight spectral vision
transformer that addresses these limitations through a parameter-efficient
architecture tailored to the unique characteristics of hyperspectral imagery.
Our model combines a 3D convolutional spectral front-end with local
window-based self-attention, enhancing both spectral feature extraction and
spatial consistency while reducing computational complexity. To further improve
adaptability, we integrate low-rank adaptation (LoRA) into attention and
projection layers, enabling fine-tuning with over 80\% fewer trainable
parameters. A novel cyclical learning rate scheduler modulates LoRA adaptation
strength during training, improving convergence and generalisation. Extensive
experiments on three benchmark datasets WHU-Hi LongKou, WHU-Hi HongHu, and
Salinas demonstrate that LoLA-SpecViT consistently outperforms state-of-the-art
baselines, achieving up to 99.91\% accuracy with substantially fewer parameters
and enhanced robustness under low-label regimes. The proposed framework
provides a scalable and generalizable solution for real-world HSI applications
in agriculture, environmental monitoring, and remote sensing analytics. Our
code is available in the following
\href{https://github.com/FadiZidiDz/LoLA-SpecViT}{GitHub Repository}.

</details>


### [179] [Incorporating Rather Than Eliminating: Achieving Fairness for Skin Disease Diagnosis Through Group-Specific Expert](https://arxiv.org/abs/2506.17787)
*Gelei Xu,Yuying Duan,Zheyuan Liu,Xueyang Li,Meng Jiang,Michael Lemmon,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: FairMoE框架通过动态路由数据到最合适的专家模块，提高皮肤疾病诊断的准确性，同时保持公平性。


<details>
  <summary>Details</summary>
Motivation: 现有AI皮肤疾病诊断系统存在跨人口群体的偏见，导致不公平的医疗结果和患者信任下降。传统方法消除敏感属性与诊断预测的关联，但会损失临床相关诊断线索。

Method: 提出FairMoE框架，采用分层混合专家模块作为群体特定学习器，动态路由数据至最合适专家，尤其适用于处理群体边界附近案例。

Result: 实验表明，FairMoE在保持公平性指标的同时显著提升准确性，优于传统公平性方法。

Conclusion: FairMoE通过动态数据路由有效平衡准确性与公平性，为AI医疗诊断提供新思路。

Abstract: AI-based systems have achieved high accuracy in skin disease diagnostics but
often exhibit biases across demographic groups, leading to inequitable
healthcare outcomes and diminished patient trust. Most existing bias mitigation
methods attempt to eliminate the correlation between sensitive attributes and
diagnostic prediction, but those methods often degrade performance due to the
lost of clinically relevant diagnostic cues. In this work, we propose an
alternative approach that incorporates sensitive attributes to achieve
fairness. We introduce FairMoE, a framework that employs layer-wise
mixture-of-experts modules to serve as group-specific learners. Unlike
traditional methods that rigidly assign data based on group labels, FairMoE
dynamically routes data to the most suitable expert, making it particularly
effective for handling cases near group boundaries. Experimental results show
that, unlike previous fairness approaches that reduce performance, FairMoE
achieves substantial accuracy improvements while preserving comparable fairness
metrics.

</details>


### [180] [Time-Contrastive Pretraining for In-Context Image and Video Segmentation](https://arxiv.org/abs/2506.17837)
*Assefa Wahd,Jacob Jaremko,Abhilash Hareendranathan*

Main category: cs.CV

TL;DR: 论文提出了一种名为Temporal的自监督方法，通过时间对比学习预训练提示检索器，将上下文学习（ICL）重新定义为视频对象分割（VOS）任务，解决了传统网格方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 主流ICL方法依赖网格策略，缺乏视觉应用的灵活性，限制了上下文图像的数量和分辨率。

Method: 提出Temporal方法，通过自监督学习预训练提示检索器，将ICL任务重新定义为VOS任务，支持可变数量的上下文图像并保持其完整分辨率。

Result: 在MICCAI FLARE 2022上，图像分割Dice分数提升10.64%（90.95%），视频分割提升14.88%（92.45%）。

Conclusion: Temporal方法显著提升了视觉ICL任务的性能，解决了网格方法的局限性。

Abstract: In-context learning (ICL) enables generalization to new tasks with minimal
labeled data. However, mainstream ICL approaches rely on a gridding strategy,
which lacks the flexibility required for vision applications. We introduce
Temporal, a time-contrastive self-supervised objective that pretrains a prompt
retriever for visual ICL, and formulate ICL as a video object segmentation
(VOS) task. Temporal addresses key limitations of grid-based methods that
restrict the number and resolution of context images. By reframing ICL as a VOS
problem, our approach supports a variable number of context images while
preserving their full resolution. To address the challenge of selecting optimal
context sets for queries, we pretrain a prompt retriever on videos via
self-supervised learning, where adjacent frames serve as positives and distant
frames as negatives. For image segmentation, the prompt retriever selects
relevant sequences that, when combined with the query, form coherent videos for
VOS processing. For video segmentation, it identifies keyframes, predicts their
masks using our ICL pipeline, and propagates them throughout the sequence. When
evaluated on MICCAI FLARE 2022, our method achieves substantial improvements
over baselines: 90.95% Dice score for image segmentation (10.64% improvement)
and 92.45% Dice for video segmentation (14.88% improvement).

</details>


### [181] [Robust Foreground-Background Separation for Severely-Degraded Videos Using Convolutional Sparse Representation Modeling](https://arxiv.org/abs/2506.17838)
*Kazuki Naganuma,Shunsuke Ono*

Main category: cs.CV

TL;DR: 提出了一种基于卷积稀疏表示（CSR）的前景-背景分离（FBS）方法，用于处理低帧率和多噪声的视频。


<details>
  <summary>Details</summary>
Motivation: 现有FBS方法无法准确分离低质量视频中的前景和背景，因为它们仅捕获特定或通用特征，且未明确建模多种噪声。

Method: 结合CSR前景模型、通用特征捕获函数和显式噪声建模，将FBS表述为多凸优化问题，并开发交替求解算法。

Result: 实验表明，该方法在红外和显微镜视频中优于现有方法。

Conclusion: 提出的方法能有效分离前景和背景，适应多种噪声和低帧率条件。

Abstract: This paper proposes a foreground-background separation (FBS) method with a
novel foreground model based on convolutional sparse representation (CSR). In
order to analyze the dynamic and static components of videos acquired under
undesirable conditions, such as hardware, environmental, and power limitations,
it is essential to establish an FBS method that can handle videos with low
frame rates and various types of noise. Existing FBS methods have two
limitations that prevent us from accurately separating foreground and
background components from such degraded videos. First, they only capture
either data-specific or general features of the components. Second, they do not
include explicit models for various types of noise to remove them in the FBS
process. To this end, we propose a robust FBS method with a CSR-based
foreground model. This model can adaptively capture specific spatial structures
scattered in imaging data. Then, we formulate FBS as a constrained multiconvex
optimization problem that incorporates CSR, functions that capture general
features, and explicit noise characterization functions for multiple types of
noise. Thanks to these functions, our method captures both data-specific and
general features to accurately separate the components from various types of
noise even under low frame rates. To obtain a solution of the optimization
problem, we develop an algorithm that alternately solves its two convex
subproblems by newly established algorithms. Experiments demonstrate the
superiority of our method over existing methods using two types of degraded
videos: infrared and microscope videos.

</details>


### [182] [Fetuses Made Simple: Modeling and Tracking of Fetal Shape and Pose](https://arxiv.org/abs/2506.17858)
*Yingcheng Liu,Peiqi Wang,Sebastian Diaz,Esra Abaci Turk,Benjamin Billot,Patricia Ellen Grant,Polina Golland*

Main category: cs.CV

TL;DR: 提出了一种基于SMPL的3D胎儿统计体模型，用于改进胎儿MRI运动与形状分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法（关键点或体积分割）在胎儿MRI分析中存在局限性，关键点忽略细节，分割难以处理运动。

Method: 构建3D统计体模型，迭代估计图像空间中的姿势和规范姿势空间中的形状。

Result: 模型在未见数据上表面对齐误差为3.2 mm（3 mm体素），支持自动测量和可视化。

Conclusion: 该模型首次实现3D胎儿统计体建模，为产前诊断中的运动与形状分析提供新工具。

Abstract: Analyzing fetal body motion and shape is paramount in prenatal diagnostics
and monitoring. Existing methods for fetal MRI analysis mainly rely on
anatomical keypoints or volumetric body segmentations. Keypoints simplify body
structure to facilitate motion analysis, but may ignore important details of
full-body shape. Body segmentations capture complete shape information but
complicate temporal analysis due to large non-local fetal movements. To address
these limitations, we construct a 3D articulated statistical fetal body model
based on the Skinned Multi-Person Linear Model (SMPL). Our algorithm
iteratively estimates body pose in the image space and body shape in the
canonical pose space. This approach improves robustness to MRI motion artifacts
and intensity distortions, and reduces the impact of incomplete surface
observations due to challenging fetal poses. We train our model on
segmentations and keypoints derived from $19,816$ MRI volumes across $53$
subjects. Our model captures body shape and motion across time series and
provides intuitive visualization. Furthermore, it enables automated
anthropometric measurements traditionally difficult to obtain from
segmentations and keypoints. When tested on unseen fetal body shapes, our
method yields a surface alignment error of $3.2$ mm for $3$ mm MRI voxel size.
To our knowledge, this represents the first 3D articulated statistical fetal
body model, paving the way for enhanced fetal motion and shape analysis in
prenatal diagnostics. The code is available at
https://github.com/MedicalVisionGroup/fetal-smpl .

</details>


### [183] [Cross-modal State Space Modeling for Real-time RGB-thermal Wild Scene Semantic Segmentation](https://arxiv.org/abs/2506.17869)
*Xiaodong Guo,Zi'ang Lin,Luwen Hu,Zhihong Deng,Tong Liu,Wujie Zhou*

Main category: cs.CV

TL;DR: CM-SSM是一种高效的RGB-热语义分割架构，通过跨模态状态空间建模（SSM）方法解决多源数据处理的计算开销问题。


<details>
  <summary>Details</summary>
Motivation: 在野外环境中，RGB和热数据的融合可以显著提升语义分割性能，但现有方法（如基于Transformer的方法）计算开销大，难以在资源受限系统中应用。

Method: 提出CM-SSM架构，包含跨模态2D选择性扫描（CM-SS2D）模块和跨模态状态空间关联（CM-SSA）模块，分别建立模态间状态空间模型并整合全局关联与局部特征。

Result: 在CART数据集上达到最优性能，参数更少且计算成本更低；在PST900数据集上验证了泛化能力。

Conclusion: CM-SSM通过线性计算复杂度解决了多源数据处理的效率问题，同时保持了高性能。

Abstract: The integration of RGB and thermal data can significantly improve semantic
segmentation performance in wild environments for field robots. Nevertheless,
multi-source data processing (e.g. Transformer-based approaches) imposes
significant computational overhead, presenting challenges for
resource-constrained systems. To resolve this critical limitation, we
introduced CM-SSM, an efficient RGB-thermal semantic segmentation architecture
leveraging a cross-modal state space modeling (SSM) approach. Our framework
comprises two key components. First, we introduced a cross-modal
2D-selective-scan (CM-SS2D) module to establish SSM between RGB and thermal
modalities, which constructs cross-modal visual sequences and derives hidden
state representations of one modality from the other. Second, we developed a
cross-modal state space association (CM-SSA) module that effectively integrates
global associations from CM-SS2D with local spatial features extracted through
convolutional operations. In contrast with Transformer-based approaches, CM-SSM
achieves linear computational complexity with respect to image resolution.
Experimental results show that CM-SSM achieves state-of-the-art performance on
the CART dataset with fewer parameters and lower computational cost. Further
experiments on the PST900 dataset demonstrate its generalizability. Codes are
available at https://github.com/xiaodonguo/CMSSM.

</details>


### [184] [SurgVidLM: Towards Multi-grained Surgical Video Understanding with Large Language Model](https://arxiv.org/abs/2506.17873)
*Guankun Wang,Wenjin Mo,Junyi Wang,Long Bai,Kun Yuan,Ming Hu,Jinlin Wu,Junjun He,Yiming Huang,Nicolas Padoy,Zhen Lei,Hongbin Liu,Nassir Navab,Hongliang Ren*

Main category: cs.CV

TL;DR: SurgVidLM是首个专为精细手术视频理解设计的视频语言模型，通过SVU-31K数据集和StageFocus机制显著提升了手术视频的全景和细节分析能力。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型（Vid-LLMs）缺乏针对手术视频精细理解的专用模型，限制了手术场景的深入分析。

Method: 提出SurgVidLM模型，构建SVU-31K数据集，引入StageFocus机制和Multi-frequency Fusion Attention技术。

Result: 实验表明，SurgVidLM在全景和精细视频理解任务中均优于现有Vid-LLMs。

Conclusion: SurgVidLM填补了手术视频精细理解的空白，展示了在复杂手术场景中的卓越能力。

Abstract: Recent advances in Multimodal Large Language Models have demonstrated great
potential in the medical domain, facilitating users to understand surgical
scenes and procedures. Beyond image-based methods, the exploration of Video
Large Language Models (Vid-LLMs) has emerged as a promising avenue for
capturing the complex sequences of information involved in surgery. However,
there is still a lack of Vid-LLMs specialized for fine-grained surgical video
understanding tasks, which is crucial for analyzing specific processes or
details within a surgical procedure. To bridge this gap, we propose SurgVidLM,
the first video language model designed to address both full and fine-grained
surgical video comprehension. To train our SurgVidLM, we construct the SVU-31K
dataset which consists of over 31K video-instruction pairs, enabling both
holistic understanding and detailed analysis of surgical procedures.
Furthermore, we introduce the StageFocus mechanism which is a two-stage
framework performing the multi-grained, progressive understanding of surgical
videos. We also develop the Multi-frequency Fusion Attention to effectively
integrate low and high-frequency visual tokens, ensuring the retention of
critical information. Experimental results demonstrate that SurgVidLM
significantly outperforms state-of-the-art Vid-LLMs in both full and
fine-grained video understanding tasks, showcasing its superior capability in
capturing complex procedural contexts.

</details>


### [185] [StainPIDR: A Pathological Image Decouplingand Reconstruction Method for StainNormalization Based on Color VectorQuantization and Structure Restaining](https://arxiv.org/abs/2506.17879)
*Zheng Chen*

Main category: cs.CV

TL;DR: 提出了一种名为StainPIDR的染色归一化方法，通过解耦图像的结构特征和颜色特征，并利用目标颜色特征重新染色，以解决病理图像颜色差异问题。


<details>
  <summary>Details</summary>
Motivation: 病理图像的颜色差异会影响计算机辅助诊断系统的性能，因此需要一种有效的染色归一化方法。

Method: 通过解耦图像的结构和颜色特征，训练固定的颜色向量代码本，并利用交叉注意力机制重新染色结构特征。此外，设计了模板图像选择算法。

Result: 实验验证了StainPIDR和模板选择算法的有效性，表明该方法在染色归一化任务中表现优异。

Conclusion: StainPIDR能有效解决病理图像颜色差异问题，代码将公开。

Abstract: The color appearance of a pathological image is highly related to the imaging
protocols, the proportion of different dyes, and the scanning devices.
Computer-aided diagnostic systems may deteriorate when facing these
color-variant pathological images. In this work, we propose a stain
normalization method called StainPIDR. We try to eliminate this color
discrepancy by decoupling the image into structure features and
vector-quantized color features, restaining the structure features with the
target color features, and decoding the stained structure features to
normalized pathological images. We assume that color features decoupled by
different images with the same color should be exactly the same. Under this
assumption, we train a fixed color vector codebook to which the decoupled color
features will map. In the restaining part, we utilize the cross-attention
mechanism to efficiently stain the structure features. As the target color
(decoupled from a selected template image) will also affect the performance of
stain normalization, we further design a template image selection algorithm to
select a template from a given dataset. In our extensive experiments, we
validate the effectiveness of StainPIDR and the template image selection
algorithm. All the results show that our method can perform well in the stain
normalization task. The code of StainPIDR will be publicly available later.

</details>


### [186] [Cloud-Aware SAR Fusion for Enhanced Optical Sensing in Space Missions](https://arxiv.org/abs/2506.17885)
*Trong-An Bui,Thanh-Thoai Le*

Main category: cs.CV

TL;DR: 提出了一种基于SAR-光学特征融合和深度学习的云注意力重建框架，用于生成无云光学图像。


<details>
  <summary>Details</summary>
Motivation: 云污染严重影响光学卫星图像的可用性，阻碍了环境监测、灾害响应和土地利用分析等关键应用。

Method: 结合SAR和光学数据的互补特征，采用注意力驱动的特征融合机制和云感知模型更新策略。

Result: 实验结果显示，该方法在PSNR、SSIM和MAE指标上优于现有方法，分别为31.01 dB、0.918和0.017。

Conclusion: 该框架能有效生成高保真、空间和光谱一致的无云光学图像。

Abstract: Cloud contamination significantly impairs the usability of optical satellite
imagery, affecting critical applications such as environmental monitoring,
disaster response, and land-use analysis. This research presents a
Cloud-Attentive Reconstruction Framework that integrates SAR-optical feature
fusion with deep learning-based image reconstruction to generate cloud-free
optical imagery. The proposed framework employs an attention-driven feature
fusion mechanism to align complementary structural information from Synthetic
Aperture Radar (SAR) with spectral characteristics from optical data.
Furthermore, a cloud-aware model update strategy introduces adaptive loss
weighting to prioritize cloud-occluded regions, enhancing reconstruction
accuracy. Experimental results demonstrate that the proposed method outperforms
existing approaches, achieving a PSNR of 31.01 dB, SSIM of 0.918, and MAE of
0.017. These outcomes highlight the framework's effectiveness in producing
high-fidelity, spatially and spectrally consistent cloud-free optical images.

</details>


### [187] [Relation3D: Enhancing Relation Modeling for Point Cloud Instance Segmentation](https://arxiv.org/abs/2506.17891)
*Jiahao Lu,Jiacheng Deng*

Main category: cs.CV

TL;DR: Relation3D提出了一种改进的点云实例分割方法，通过增强场景特征和查询特征之间的关系建模，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的方法主要关注场景特征与查询特征之间的外部关系，而忽略了场景特征内部和查询特征之间的关系建模。

Method: 提出自适应超点聚合模块和对比学习引导的超点细化模块，以及关系感知的自注意力机制。

Result: 在多个数据集（ScanNetV2、ScanNet++、ScanNet200、S3DIS）上表现出优越性能。

Conclusion: Relation3D通过改进关系建模，显著提升了点云实例分割的效果。

Abstract: 3D instance segmentation aims to predict a set of object instances in a
scene, representing them as binary foreground masks with corresponding semantic
labels. Currently, transformer-based methods are gaining increasing attention
due to their elegant pipelines and superior predictions. However, these methods
primarily focus on modeling the external relationships between scene features
and query features through mask attention. They lack effective modeling of the
internal relationships among scene features as well as between query features.
In light of these disadvantages, we propose \textbf{Relation3D: Enhancing
Relation Modeling for Point Cloud Instance Segmentation}. Specifically, we
introduce an adaptive superpoint aggregation module and a contrastive
learning-guided superpoint refinement module to better represent superpoint
features (scene features) and leverage contrastive learning to guide the
updates of these features. Furthermore, our relation-aware self-attention
mechanism enhances the capabilities of modeling relationships between queries
by incorporating positional and geometric relationships into the self-attention
mechanism. Extensive experiments on the ScanNetV2, ScanNet++, ScanNet200 and
S3DIS datasets demonstrate the superior performance of Relation3D.

</details>


### [188] [BeltCrack: the First Sequential-image Industrial Conveyor Belt Crack Detection Dataset and Its Baseline with Triple-domain Feature Learning](https://arxiv.org/abs/2506.17892)
*Jianghong Huang,Luping Ji,Xin Ma,Mao Ye*

Main category: cs.CV

TL;DR: 本文构建了首个真实工业场景的传送带裂缝数据集（BeltCrack14ks和BeltCrack9kd），并提出了一种基于时空频三域特征分层融合的基线方法，验证了数据集的有效性和方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 传送带裂缝对工业安全和效率至关重要，但现有数据集多为路面或合成数据，缺乏真实工业场景的数据。本文旨在填补这一空白，推动机器学习在该领域的应用。

Method: 构建了真实工业场景的传送带裂缝数据集，并提出了一种基于时空频三域特征分层融合的基线方法。

Result: 实验结果表明数据集有效，且基线方法明显优于其他类似检测方法。

Conclusion: 本文的数据集和方法为传送带裂缝智能检测提供了重要资源和技术支持。

Abstract: Conveyor belt is a category of important equipments in modern industry,
widely applied in production and manufacturing Fields. Its health status is
much critical to operation efficiency and safety hazards. Among the factors
affecting belt health, crack is often one of the most threatening risks.
Currently, considering safety, how to intelligently detect belt cracks is
catching an increasing attention. To implement the intelligent detection with
machine learning, real crack samples are believed to be necessary. However,
existing crack datasets primarily focus on pavement scenarios or synthetic
data, no real-world industrial belt crack datasets at all. To propel machine
learning advancement in this field, this paper constructs the first
sequential-image belt crack detection datasets (BeltCrack14ks and
BeltCrack9kd), from real-world factory scenes. Furthermore, to validate
usability and effectiveness, we propose a special baseline method with
triple-domain (i.e., time-space-frequency) feature hierarchical fusion learning
for the two whole-new datasets. Experimental results demonstrate the
availability and effectiveness of our dataset. Besides, they also show that our
baseline is obviously superior to other similar detection methods. Our datasets
and source codes are available at https://github.com/UESTC-nnLab/BeltCrack.

</details>


### [189] [EgoWorld: Translating Exocentric View to Egocentric View using Rich Exocentric Observations](https://arxiv.org/abs/2506.17896)
*Junho Park,Andrew Sangwoo Ye,Taein Kwon*

Main category: cs.CV

TL;DR: EgoWorld是一种新颖的两阶段框架，通过外中心观察重建自我中心视角，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 自我中心视觉对于人类和机器视觉理解至关重要，尤其是在捕捉手-物体交互细节方面。现有方法依赖2D线索、多视图同步设置和不切实际的假设，限制了其应用。

Method: EgoWorld通过估计外中心深度图重建点云，重投影到自我中心视角，并应用基于扩散的图像修复生成密集且语义连贯的图像。

Result: 在H2O和TACO数据集上，EgoWorld实现了最先进的性能，并对新对象、动作、场景和主体表现出强大的泛化能力。

Conclusion: EgoWorld在未标记的真实世界示例中也表现出色，为AR、VR和机器人应用提供了有前景的解决方案。

Abstract: Egocentric vision is essential for both human and machine visual
understanding, particularly in capturing the detailed hand-object interactions
needed for manipulation tasks. Translating third-person views into first-person
views significantly benefits augmented reality (AR), virtual reality (VR) and
robotics applications. However, current exocentric-to-egocentric translation
methods are limited by their dependence on 2D cues, synchronized multi-view
settings, and unrealistic assumptions such as necessity of initial egocentric
frame and relative camera poses during inference. To overcome these challenges,
we introduce EgoWorld, a novel two-stage framework that reconstructs an
egocentric view from rich exocentric observations, including projected point
clouds, 3D hand poses, and textual descriptions. Our approach reconstructs a
point cloud from estimated exocentric depth maps, reprojects it into the
egocentric perspective, and then applies diffusion-based inpainting to produce
dense, semantically coherent egocentric images. Evaluated on the H2O and TACO
datasets, EgoWorld achieves state-of-the-art performance and demonstrates
robust generalization to new objects, actions, scenes, and subjects. Moreover,
EgoWorld shows promising results even on unlabeled real-world examples.

</details>


### [190] [PostAlign: Multimodal Grounding as a Corrective Lens for MLLMs](https://arxiv.org/abs/2506.17901)
*Yixuan Wu,Yang Zhang,Jian Wu,Philip Torr,Jindong Gu*

Main category: cs.CV

TL;DR: MMGrounded-PostAlign框架通过多模态对齐增强视觉理解能力，减少幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在视觉语言任务中过度依赖虚假相关性和语言先验的问题。

Method: 引入多模态基础模块（视觉和文本基础）和负拒绝机制，以及选择性推理机制。

Result: 在多个基准测试中显著提升了细粒度视觉理解和幻觉抑制能力。

Conclusion: MMGrounded-PostAlign有效提升了MLLMs的视觉理解能力并减少了幻觉问题。

Abstract: Multimodal Large Language Models (MLLMs) excel in vision-language tasks, such
as image captioning and visual question answering. However, they often suffer
from over-reliance on spurious correlations, primarily due to linguistic priors
that distract the model from leveraging actual visual information. To address
these issues, we introduce MMGrounded-PostAlign, a post-multimodal alignment
framework designed to enhance the visual understanding capabilities and
mitigate the hallucinations of MLLMs. Our framework incorporates a multimodal
grounding module for both visual grounding, which identifies the referred
object in the image, and textual grounding, which generates the rationale for
the final answer, ensuring that outputs are anchored in both visual and textual
evidence. To mitigate the hallucinations, we introduce a negative rejection
mechanism in the visual grounding module to distinguish grounded entities from
non-existent objects influenced by linguistic biases. On the textual grounding
side, we propose a selective reasoning mechanism that adjusts the model's
reasoning strategy based on query complexity. Extensive evaluations are
conducted on benchmarks such as POPE, HaloQuest, VQAv2, MME, and MMBench
showing significant improvements in fine-grained visual understanding and
hallucination suppression.

</details>


### [191] [Cause-Effect Driven Optimization for Robust Medical Visual Question Answering with Language Biases](https://arxiv.org/abs/2506.17903)
*Huanjia Zhu,Yishu Liu,Xiaozhao Fang,Guangming Lu,Bingzhi Chen*

Main category: cs.CV

TL;DR: 论文提出了一种名为CEDO的新框架，通过三种机制（MHO、GMS、DLR）从因果和效应角度全面缓解医学视觉问答模型中的语言偏差。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉问答模型存在语言偏差问题，即问题类型与答案类别之间建立了虚假关联。

Method: CEDO框架包含三种机制：MHO（模态驱动的异构优化）、GMS（梯度引导的模态协同）和DLR（分布适应的损失重缩放），分别从不同角度缓解语言偏差。

Result: 在多个传统和偏差敏感基准测试中，CEDO表现出优于现有方法的鲁棒性。

Conclusion: CEDO通过综合优化机制有效缓解了语言偏差，提升了模型的性能和鲁棒性。

Abstract: Existing Medical Visual Question Answering (Med-VQA) models often suffer from
language biases, where spurious correlations between question types and answer
categories are inadvertently established. To address these issues, we propose a
novel Cause-Effect Driven Optimization framework called CEDO, that incorporates
three well-established mechanisms, i.e., Modality-driven Heterogeneous
Optimization (MHO), Gradient-guided Modality Synergy (GMS), and
Distribution-adapted Loss Rescaling (DLR), for comprehensively mitigating
language biases from both causal and effectual perspectives. Specifically, MHO
employs adaptive learning rates for specific modalities to achieve
heterogeneous optimization, thus enhancing robust reasoning capabilities.
Additionally, GMS leverages the Pareto optimization method to foster
synergistic interactions between modalities and enforce gradient orthogonality
to eliminate bias updates, thereby mitigating language biases from the effect
side, i.e., shortcut bias. Furthermore, DLR is designed to assign adaptive
weights to individual losses to ensure balanced learning across all answer
categories, effectively alleviating language biases from the cause side, i.e.,
imbalance biases within datasets. Extensive experiments on multiple traditional
and bias-sensitive benchmarks consistently demonstrate the robustness of CEDO
over state-of-the-art competitors.

</details>


### [192] [Feedback Driven Multi Stereo Vision System for Real-Time Event Analysis](https://arxiv.org/abs/2506.17910)
*Mohamed Benkedadra,Matei Mancas,Sidi Ahmed Mahmoudi*

Main category: cs.CV

TL;DR: 提出一种基于3D立体视觉的交互系统管道，通过多摄像头融合实现场景重建，适用于普通和敏感应用。


<details>
  <summary>Details</summary>
Motivation: 现有2D和3D摄像头在复杂环境中不可靠，需要更稳健的场景理解方案。

Method: 融合多个3D摄像头进行全场景重建，支持事件识别、目标跟踪和通知等功能，并通过反馈机制优化决策。

Result: 初步实验验证了管道的可行性，展示了其在复杂环境中的潜力。

Conclusion: 提出了未来将管道投入生产的路线图。

Abstract: 2D cameras are often used in interactive systems. Other systems like gaming
consoles provide more powerful 3D cameras for short range depth sensing.
Overall, these cameras are not reliable in large, complex environments. In this
work, we propose a 3D stereo vision based pipeline for interactive systems,
that is able to handle both ordinary and sensitive applications, through robust
scene understanding. We explore the fusion of multiple 3D cameras to do full
scene reconstruction, which allows for preforming a wide range of tasks, like
event recognition, subject tracking, and notification. Using possible feedback
approaches, the system can receive data from the subjects present in the
environment, to learn to make better decisions, or to adapt to completely new
environments. Throughout the paper, we introduce the pipeline and explain our
preliminary experimentation and results. Finally, we draw the roadmap for the
next steps that need to be taken, in order to get this pipeline into production

</details>


### [193] [PlanMoGPT: Flow-Enhanced Progressive Planning for Text to Motion Synthesis](https://arxiv.org/abs/2506.17912)
*Chuhao Jin,Haosen Li,Bingzi Zhang,Che Liu,Xiting Wang,Ruihua Song,Wenbing Huang,Ying Qin,Fuzheng Zhang,Di Zhang*

Main category: cs.CV

TL;DR: PlanMoGPT通过渐进式规划和流增强细粒度运动标记化，解决了LLM在文本到运动生成中的性能差距，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在多模态生成任务中取得突破，但在文本到运动生成中性能仍落后于非LLM方法。运动标记化的粒度是关键瓶颈。

Method: 提出PlanMoGPT框架，结合渐进式规划和流增强细粒度运动标记化。渐进式规划机制分层生成运动标记，流增强标记器和解码器减少细节损失。

Result: 在文本到运动基准测试中，FID分数提升63.8%，运动多样性提高49.9%，解决了多样性-质量权衡问题。

Conclusion: PlanMoGPT为文本到运动生成设定了新标准，成功解决了现有方法的局限性。

Abstract: Recent advances in large language models (LLMs) have enabled breakthroughs in
many multimodal generation tasks, but a significant performance gap still
exists in text-to-motion generation, where LLM-based methods lag far behind
non-LLM methods. We identify the granularity of motion tokenization as a
critical bottleneck: fine-grained tokenization induces local dependency issues,
where LLMs overemphasize short-term coherence at the expense of global semantic
alignment, while coarse-grained tokenization sacrifices motion details. To
resolve this issue, we propose PlanMoGPT, an LLM-based framework integrating
progressive planning and flow-enhanced fine-grained motion tokenization. First,
our progressive planning mechanism leverages LLMs' autoregressive capabilities
to hierarchically generate motion tokens by starting from sparse global plans
and iteratively refining them into full sequences. Second, our flow-enhanced
tokenizer doubles the downsampling resolution and expands the codebook size by
eight times, minimizing detail loss during discretization, while a
flow-enhanced decoder recovers motion nuances. Extensive experiments on
text-to-motion benchmarks demonstrate that it achieves state-of-the-art
performance, improving FID scores by 63.8% (from 0.380 to 0.141) on
long-sequence generation while enhancing motion diversity by 49.9% compared to
existing methods. The proposed framework successfully resolves the
diversity-quality trade-off that plagues current non-LLM approaches,
establishing new standards for text-to-motion generation.

</details>


### [194] [IDAL: Improved Domain Adaptive Learning for Natural Images Dataset](https://arxiv.org/abs/2506.17931)
*Ravi Kant Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种新的无监督域自适应（UDA）方法，通过结合ResNet和FPN的架构以及新型损失函数，提升了域对齐效果和模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗域自适应方法在多模态分布对齐上效果不佳，需要改进以应对自然图像中的尺度、噪声和风格变化。

Method: 结合ResNet和FPN的深度架构，设计新型损失函数与现有损失函数的组合，以优化域对齐和训练效果。

Result: 在Office-Home、Office-31和VisDA-2017数据集上优于现有CNN方法，在DomainNet上表现相当。

Conclusion: 该方法在域自适应任务中表现出更高的准确性和鲁棒性，同时加快了训练收敛速度。

Abstract: We present a novel approach for unsupervised domain adaptation (UDA) for
natural images. A commonly-used objective for UDA schemes is to enhance domain
alignment in representation space even if there is a domain shift in the input
space. Existing adversarial domain adaptation methods may not effectively align
different domains of multimodal distributions associated with classification
problems. Our approach has two main features. Firstly, its neural architecture
uses the deep structure of ResNet and the effective separation of scales of
feature pyramidal network (FPN) to work with both content and style features.
Secondly, it uses a combination of a novel loss function and judiciously
selected existing loss functions to train the network architecture. This
tailored combination is designed to address challenges inherent to natural
images, such as scale, noise, and style shifts, that occur on top of a
multi-modal (multi-class) distribution. The combined loss function not only
enhances model accuracy and robustness on the target domain but also speeds up
training convergence. Our proposed UDA scheme generalizes better than
state-of-the-art for CNN-based methods on Office-Home, Office-31, and
VisDA-2017 datasets and comaparable for DomainNet dataset.

</details>


### [195] [GEMeX-ThinkVG: Towards Thinking with Visual Grounding in Medical VQA via Reinforcement Learning](https://arxiv.org/abs/2506.17939)
*Bo Liu,Xiangyu Zhao,Along He,Yidi Chen,Huazhu Fu,Xiao-Ming Wu*

Main category: cs.CV

TL;DR: 论文提出了一种名为ThinkVG的数据集和可验证奖励机制，用于提升医学视觉问答的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉问答模型的答案可靠性和可解释性不足，影响了临床决策的信任度。

Method: 通过分解答案生成为中间推理步骤，并引入可验证奖励机制进行强化学习后训练。

Result: 方法仅用八分之一的数据即达到可比性能，证明了其高效性和有效性。

Conclusion: ThinkVG数据集和可验证奖励机制显著提升了医学视觉问答的可靠性和可解释性。

Abstract: Medical visual question answering aims to support clinical decision-making by
enabling models to answer natural language questions based on medical images.
While recent advances in multi-modal learning have significantly improved
performance, current methods still suffer from limited answer reliability and
poor interpretability, impairing the ability of clinicians and patients to
understand and trust model-generated answers. To address this, this work first
proposes a Thinking with Visual Grounding (ThinkVG) dataset wherein the answer
generation is decomposed into intermediate reasoning steps that explicitly
ground relevant visual regions of the medical image, thereby providing
fine-grained explainability. Furthermore, we introduce a novel verifiable
reward mechanism for reinforcement learning to guide post-training, improving
the alignment between the model's reasoning process and its final answer.
Remarkably, our method achieves comparable performance using only one-eighth of
the training data, demonstrating the efficiency and effectiveness of the
proposal. The dataset is available at
https://huggingface.co/datasets/BoKelvin/GEMeX-ThinkVG.

</details>


### [196] [SegChange-R1:Augmented Reasoning for Remote Sensing Change Detection via Large Language Models](https://arxiv.org/abs/2506.17944)
*Fei Zhou*

Main category: cs.CV

TL;DR: 提出了一种基于大语言模型（LLM）的增强推理方法（SegChange-R1），通过整合文本描述信息提升变化检测能力，并设计了基于线性注意力的空间变换模块（BEV）解决模态对齐问题。


<details>
  <summary>Details</summary>
Motivation: 提升遥感变化检测的精度和效率，特别是在建筑变化检测中，通过引入文本描述信息和解决多时相特征对齐问题。

Method: 结合LLM的推理能力和BEV空间变换模块，统一多时相特征，并构建了首个无人机视角的建筑变化检测数据集（DVCD）。

Result: 在四个常用变化检测数据集上表现显著优于现有方法。

Conclusion: SegChange-R1方法有效提升了变化检测性能，代码和预训练模型已开源。

Abstract: Remote sensing change detection is widely used in a variety of fields such as
urban planning, terrain and geomorphology analysis, and environmental
monitoring, mainly by analyzing the significant change differences of features
(e.g., building changes) in the same spatial region at different time phases.
In this paper, we propose a large language model (LLM) augmented inference
approach (SegChange-R1), which enhances the detection capability by integrating
textual descriptive information and aims at guiding the model to segment the
more interested change regions, thus accelerating the convergence speed.
Moreover, we design a spatial transformation module (BEV) based on linear
attention, which solves the problem of modal misalignment in change detection
by unifying features from different temporal perspectives onto the BEV space.
In addition, we construct the first dataset for building change detection from
UAV viewpoints (DVCD ), and our experiments on four widely-used change
detection datasets show a significant improvement over existing methods. The
code and pre-trained models are available in
https://github.com/Yu-Zhouz/SegChange-R1.

</details>


### [197] [Classification of Tents in Street Bazaars Using CNN](https://arxiv.org/abs/2506.17946)
*Azamat Ibragimov,Ruslan Isaev,Remudin Reshid Mekuria,Gulnaz Gimaletdinova,Dim Shaiakhmetov*

Main category: cs.CV

TL;DR: 论文提出了一种改进的深度学习模型，用于分类街头集市中的帐篷，比较了自定义CNN和EfficientNetB0的性能，发现预训练模型显著提升了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 街头集市是许多地区的重要经济中心，但其非结构化特性使得帐篷等基础设施的自动分类具有挑战性。手动方法效率低下，而CNN在此类任务中的应用尚未充分探索。

Method: 研究使用了126张原始照片及其增强图像作为数据集，训练了自定义CNN和EfficientNetB0模型，并通过多种性能指标（如准确率、精确率、召回率、F1分数和mAP）进行评估。

Result: 自定义CNN的准确率为92.8%，而EfficientNetB0达到98.4%，表明预训练模型在分类任务中表现更优。

Conclusion: 预训练模型（如EfficientNetB0）能显著提升分类准确率和泛化能力，适用于街头集市帐篷的分类任务。

Abstract: This research paper proposes an improved deep learning model for classifying
tents in street bazaars, comparing a custom Convolutional Neural Network (CNN)
with EfficientNetB0. This is a critical task for market organization with a
tent classification, but manual methods in the past have been inefficient.
Street bazaars represent a vital economic hub in many regions, yet their
unstructured nature poses significant challenges for the automated
classification of market infrastructure, such as tents. In Kyrgyzstan, more
than a quarter of the country's GDP is derived from bazaars. While CNNs have
been widely applied to object recognition, their application to bazaar-specific
tasks remains underexplored. Here, we build upon our original approach by
training on an extended set of 126 original photographs that were augmented to
generate additional images. This dataset is publicly available for download on
Kaggle. A variety of performance metrics, such as accuracy, precision, recall,
F1 score, and mean average precision (mAP), were used to assess the models
comparatively, providing a more extensive analysis of classification
performance.
  The results show that the CNN custom model achieved 92.8% accuracy, and
EfficientNetB0 showed 98.4% accuracy results, confirming the effectiveness of
transfer learning in the bazaar image classification. Also, when analyzing the
confusion matrix, the analysis reveals the weaknesses and strengths of each
model. These findings suggest that using a pre-trained model such as
EfficientNetB0 significantly improves classification accuracy and
generalization.

</details>


### [198] [Mobile Image Analysis Application for Mantoux Skin Test](https://arxiv.org/abs/2506.17954)
*Liong Gele,Tan Chye Cheah*

Main category: cs.CV

TL;DR: 新型移动应用利用ARCore和机器学习算法（如DeepLabv3）改进Mantoux皮肤测试（TST），提高LTBI诊断的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统TST方法存在随访率低、患者不适和主观解释导致误诊的问题，需改进诊断效率和准确性。

Method: 应用结合图像处理技术（ARCore）和机器学习算法（DeepLabv3），使用缩放贴纸作为参考对象测量皮肤硬结。

Result: 相比传统临床实践，应用显著提高了诊断的准确性和可靠性。

Conclusion: 该应用有助于结核病管理，未来将优化算法并扩展功能。

Abstract: This paper presents a newly developed mobile application designed to diagnose
Latent Tuberculosis Infection (LTBI) using the Mantoux Skin Test (TST).
Traditional TST methods often suffer from low follow-up return rates, patient
discomfort, and subjective manual interpretation, particularly with the
ball-point pen method, leading to misdiagnosis and delayed treatment. Moreover,
previous developed mobile applications that used 3D reconstruction, this app
utilizes scaling stickers as reference objects for induration measurement. This
mobile application integrates advanced image processing technologies, including
ARCore, and machine learning algorithms such as DeepLabv3 for robust image
segmentation and precise measurement of skin indurations indicative of LTBI.
The system employs an edge detection algorithm to enhance accuracy. The
application was evaluated against standard clinical practices, demonstrating
significant improvements in accuracy and reliability. This innovation is
crucial for effective tuberculosis management, especially in resource-limited
regions. By automating and standardizing TST evaluations, the application
enhances the accessibility and efficiency of TB di-agnostics. Future work will
focus on refining machine learning models, optimizing measurement algorithms,
expanding functionalities to include comprehensive patient data management, and
enhancing ARCore's performance across various lighting conditions and
operational settings.

</details>


### [199] [ELMAR: Enhancing LiDAR Detection with 4D Radar Motion Awareness and Cross-modal Uncertainty](https://arxiv.org/abs/2506.17958)
*Xiangyuan Peng,Miao Tang,Huawei Sun,Bierzynski Kay,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: 提出了一种结合4D雷达运动状态和跨模态不确定性的LiDAR检测框架，以解决LiDAR与4D雷达融合中的不对齐问题，并在VoD数据集上实现了高性能。


<details>
  <summary>Details</summary>
Motivation: LiDAR和4D雷达在自动驾驶中各有优势，但融合时存在模态不对齐问题，需要一种方法充分利用两者的优势。

Method: 使用动态运动感知编码模块提取4D雷达的运动信息，并通过估计边界框的不确定性来减少跨模态不对齐，优化LiDAR预测。

Result: 在VoD数据集上，整个区域的mAP达到74.89%，驾驶走廊内达到88.70%，实时推理速度为30.02 FPS。

Conclusion: 该方法有效解决了跨模态不对齐问题，显著提升了感知性能，同时保持了实时性。

Abstract: LiDAR and 4D radar are widely used in autonomous driving and robotics. While
LiDAR provides rich spatial information, 4D radar offers velocity measurement
and remains robust under adverse conditions. As a result, increasing studies
have focused on the 4D radar-LiDAR fusion method to enhance the perception.
However, the misalignment between different modalities is often overlooked. To
address this challenge and leverage the strengths of both modalities, we
propose a LiDAR detection framework enhanced by 4D radar motion status and
cross-modal uncertainty. The object movement information from 4D radar is first
captured using a Dynamic Motion-Aware Encoding module during feature extraction
to enhance 4D radar predictions. Subsequently, the instance-wise uncertainties
of bounding boxes are estimated to mitigate the cross-modal misalignment and
refine the final LiDAR predictions. Extensive experiments on the View-of-Delft
(VoD) dataset highlight the effectiveness of our method, achieving
state-of-the-art performance with the mAP of 74.89% in the entire area and
88.70% within the driving corridor while maintaining a real-time inference
speed of 30.02 FPS.

</details>


### [200] [BPCLIP: A Bottom-up Image Quality Assessment from Distortion to Semantics Based on CLIP](https://arxiv.org/abs/2506.17969)
*Chenyue Song,Chen Hui,Wei Zhang,Haiqi Zhu,Shaohui Liu,Hong Huang,Feng Jiang*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP的自底向上图像质量评估方法BPCLIP，通过多尺度交叉注意力模块和文本编码器增强图像质量与人类语言的关联，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常线性融合多尺度特征，未能充分捕捉失真对语义内容的影响，因此需要更有效的方法。

Method: 利用编码器提取多尺度特征，引入自底向上的多尺度交叉注意力模块，并结合CLIP文本编码器生成图像质量表示。

Result: 在多数公开的FR和NR IQA基准测试中表现优异，且更具鲁棒性。

Conclusion: BPCLIP通过结合多尺度特征和语言表示，显著提升了图像质量评估的性能和鲁棒性。

Abstract: Image Quality Assessment (IQA) aims to evaluate the perceptual quality of
images based on human subjective perception. Existing methods generally combine
multiscale features to achieve high performance, but most rely on
straightforward linear fusion of these features, which may not adequately
capture the impact of distortions on semantic content. To address this, we
propose a bottom-up image quality assessment approach based on the Contrastive
Language-Image Pre-training (CLIP, a recently proposed model that aligns images
and text in a shared feature space), named BPCLIP, which progressively extracts
the impact of low-level distortions on high-level semantics. Specifically, we
utilize an encoder to extract multiscale features from the input image and
introduce a bottom-up multiscale cross attention module designed to capture the
relationships between shallow and deep features. In addition, by incorporating
40 image quality adjectives across six distinct dimensions, we enable the
pre-trained CLIP text encoder to generate representations of the intrinsic
quality of the image, thereby strengthening the connection between image
quality perception and human language. Our method achieves superior results on
most public Full-Reference (FR) and No-Reference (NR) IQA benchmarks, while
demonstrating greater robustness.

</details>


### [201] [Enabling PSO-Secure Synthetic Data Sharing Using Diversity-Aware Diffusion Models](https://arxiv.org/abs/2506.17975)
*Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: 论文提出了一种通用框架，通过最大化合成数据的多样性来保护隐私，同时保持性能接近真实数据。


<details>
  <summary>Details</summary>
Motivation: 合成数据在医学影像中具有隐私保护潜力，但现有方法在法规遵从性和性能上存在不足。

Method: 提出了一种基于扩散模型的通用框架，生成非个人化的合成数据。

Result: 合成数据性能接近真实数据（相差1个百分点），并显著优于不保护隐私的现有方法。

Conclusion: 最大化多样性不仅能提升性能，还能保护隐私，为合成数据的应用提供了新思路。

Abstract: Synthetic data has recently reached a level of visual fidelity that makes it
nearly indistinguishable from real data, offering great promise for
privacy-preserving data sharing in medical imaging. However, fully synthetic
datasets still suffer from significant limitations: First and foremost, the
legal aspect of sharing synthetic data is often neglected and data regulations,
such as the GDPR, are largley ignored. Secondly, synthetic models fall short of
matching the performance of real data, even for in-domain downstream
applications. Recent methods for image generation have focused on maximising
image diversity instead of fidelity solely to improve the mode coverage and
therefore the downstream performance of synthetic data. In this work, we shift
perspective and highlight how maximizing diversity can also be interpreted as
protecting natural persons from being singled out, which leads to predicate
singling-out (PSO) secure synthetic datasets. Specifically, we propose a
generalisable framework for training diffusion models on personal data which
leads to unpersonal synthetic datasets achieving performance within one
percentage point of real-data models while significantly outperforming
state-of-the-art methods that do not ensure privacy. Our code is available at
https://github.com/MischaD/Trichotomy.

</details>


### [202] [Fast Neural Inverse Kinematics on Human Body Motions](https://arxiv.org/abs/2506.17996)
*David Tolpin,Sefy Kagarlitsky*

Main category: cs.CV

TL;DR: 提出了一种快速可靠的神经逆运动学框架，用于从3D关键点实时捕捉人体运动。


<details>
  <summary>Details</summary>
Motivation: 无标记运动捕捉虽然灵活且成本低，但计算需求高且推理速度慢，限制了实时应用。

Method: 详细描述了网络架构、训练方法和推理流程，并通过消融研究验证设计。

Result: 框架在定性和定量上均得到评估，证明了其有效性。

Conclusion: 该框架为实时人体运动捕捉提供了一种高效解决方案。

Abstract: Markerless motion capture enables the tracking of human motion without
requiring physical markers or suits, offering increased flexibility and reduced
costs compared to traditional systems. However, these advantages often come at
the expense of higher computational demands and slower inference, limiting
their applicability in real-time scenarios. In this technical report, we
present a fast and reliable neural inverse kinematics framework designed for
real-time capture of human body motions from 3D keypoints. We describe the
network architecture, training methodology, and inference procedure in detail.
Our framework is evaluated both qualitatively and quantitatively, and we
support key design decisions through ablation studies.

</details>


### [203] [OSDMamba: Enhancing Oil Spill Detection from Remote Sensing Images Using Selective State Space Model](https://arxiv.org/abs/2506.18006)
*Shuaiyu Chen,Fu Wang,Peng Ren,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 论文提出OSDMamba，一种基于Mamba的架构，用于解决油污检测中的小目标检测和类别不平衡问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的方法在油污检测中因有限感受野和全局信息捕捉不足而表现不佳，且样本不平衡问题严重。

Method: 提出OSDMamba，利用Mamba的选择性扫描机制扩展感受野，并结合非对称解码器和深度监督增强多尺度特征融合。

Result: 在两个公开数据集上，OSDMamba性能提升8.9%和11.8%，达到SOTA。

Conclusion: OSDMamba通过Mamba机制和特征融合设计，有效解决了油污检测中的关键挑战。

Abstract: Semantic segmentation is commonly used for Oil Spill Detection (OSD) in
remote sensing images. However, the limited availability of labelled oil spill
samples and class imbalance present significant challenges that can reduce
detection accuracy. Furthermore, most existing methods, which rely on
convolutional neural networks (CNNs), struggle to detect small oil spill areas
due to their limited receptive fields and inability to effectively capture
global contextual information. This study explores the potential of State-Space
Models (SSMs), particularly Mamba, to overcome these limitations, building on
their recent success in vision applications. We propose OSDMamba, the first
Mamba-based architecture specifically designed for oil spill detection.
OSDMamba leverages Mamba's selective scanning mechanism to effectively expand
the model's receptive field while preserving critical details. Moreover, we
designed an asymmetric decoder incorporating ConvSSM and deep supervision to
strengthen multi-scale feature fusion, thereby enhancing the model's
sensitivity to minority class samples. Experimental results show that the
proposed OSDMamba achieves state-of-the-art performance, yielding improvements
of 8.9% and 11.8% in OSD across two publicly available datasets.

</details>


### [204] [On the Robustness of Human-Object Interaction Detection against Distribution Shift](https://arxiv.org/abs/2506.18021)
*Chi Xie,Shuang Liang,Jie Li,Feng Zhu,Rui Zhao,Yichen Wei,Shengjie Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种评估和提升人-物交互（HOI）检测模型鲁棒性的方法，包括创建新基准、分析现有模型不足，并提出两种简单有效的改进策略。


<details>
  <summary>Details</summary>
Motivation: 现有HOI检测模型在理想图像和自然分布下表现良好，但在实际场景中分布偏移时表现不佳，限制了其实际应用。

Method: 1. 提出自动化方法创建首个HOI鲁棒性评估基准；2. 评估40多个现有模型；3. 提出跨域数据增强和特征融合策略。

Result: 实验表明，所提方法显著提升了多种模型的鲁棒性，并在标准基准上也有改进。

Conclusion: 通过新基准和改进策略，论文为HOI检测的实际应用提供了更鲁棒的解决方案。

Abstract: Human-Object Interaction (HOI) detection has seen substantial advances in
recent years. However, existing works focus on the standard setting with ideal
images and natural distribution, far from practical scenarios with inevitable
distribution shifts. This hampers the practical applicability of HOI detection.
In this work, we investigate this issue by benchmarking, analyzing, and
enhancing the robustness of HOI detection models under various distribution
shifts. We start by proposing a novel automated approach to create the first
robustness evaluation benchmark for HOI detection. Subsequently, we evaluate
more than 40 existing HOI detection models on this benchmark, showing their
insufficiency, analyzing the features of different frameworks, and discussing
how the robustness in HOI is different from other tasks. With the insights from
such analyses, we propose to improve the robustness of HOI detection methods
through: (1) a cross-domain data augmentation integrated with mixup, and (2) a
feature fusion strategy with frozen vision foundation models. Both are simple,
plug-and-play, and applicable to various methods. Our experimental results
demonstrate that the proposed approach significantly increases the robustness
of various methods, with benefits on standard benchmarks, too. The dataset and
code will be released.

</details>


### [205] [PP-DocBee2: Improved Baselines with Efficient Data for Multimodal Document Understanding](https://arxiv.org/abs/2506.18023)
*Kui Huang,Xinrong Chen,Wenyu Lv,Jincheng Liao,Guanzhong Wang,Yi Liu*

Main category: cs.CV

TL;DR: PP-DocBee2是PP-DocBee的升级版，通过改进合成数据质量、视觉特征融合策略和推理方法，提升了多模态文档理解能力，性能提升11.4%，推理延迟降低73%。


<details>
  <summary>Details</summary>
Motivation: 解决PP-DocBee在多模态文档理解中的局限性，提升模型性能。

Method: 采用大规模多模态预训练模型评估数据，优化数据质量；分解ViT层并应用新特征融合策略增强表示能力。

Result: 性能提升11.4%，推理延迟降低73%。

Conclusion: PP-DocBee2通过技术创新显著提升了多模态文档理解能力。

Abstract: This report introduces PP-DocBee2, an advanced version of the PP-DocBee,
designed to enhance multimodal document understanding. Built on a large
multimodal model architecture, PP-DocBee2 addresses the limitations of its
predecessor through key technological improvements, including enhanced
synthetic data quality, improved visual feature fusion strategy, and optimized
inference methodologies. These enhancements yield an $11.4\%$ performance boost
on internal benchmarks for Chinese business documents, and reduce inference
latency by $73.0\%$ to the vanilla version. A key innovation of our work is a
data quality optimization strategy for multimodal document tasks. By employing
a large-scale multimodal pre-trained model to evaluate data, we apply a novel
statistical criterion to filter outliers, ensuring high-quality training data.
Inspired by insights into underutilized intermediate features in multimodal
models, we enhance the ViT representational capacity by decomposing it into
layers and applying a novel feature fusion strategy to improve complex
reasoning. The source code and pre-trained model are available at
\href{https://github.com/PaddlePaddle/PaddleMIX}{https://github.com/PaddlePaddle/PaddleMIX}.

</details>


### [206] [MiCo: Multiple Instance Learning with Context-Aware Clustering for Whole Slide Image Analysis](https://arxiv.org/abs/2506.18028)
*Junjian Li,Hulin Kuang,Jin Liu,Hailin Yue,Mengshen He,Jianxin Wang*

Main category: cs.CV

TL;DR: 提出了一种名为MiCo的多实例学习框架，通过上下文感知聚类增强WSI分析中的跨区域组织相关性和语义关联。


<details>
  <summary>Details</summary>
Motivation: 解决传统MIL方法在WSI分析中难以建模分散组织分布和跨区域空间交互的问题。

Method: MiCo通过聚类提取形态模式，利用Cluster Route模块动态链接相同组织类型的实例，并通过Cluster Reducer模块消除语义碎片化。

Result: 在九个大型癌症数据集上的实验表明，MiCo优于现有方法。

Conclusion: MiCo通过上下文感知聚类有效提升了WSI分析的性能。

Abstract: Multiple instance learning (MIL) has shown significant promise in
histopathology whole slide image (WSI) analysis for cancer diagnosis and
prognosis. However, the inherent spatial heterogeneity of WSIs presents
critical challenges, as morphologically similar tissue types are often
dispersed across distant anatomical regions. Conventional MIL methods struggle
to model these scattered tissue distributions and capture cross-regional
spatial interactions effectively. To address these limitations, we propose a
novel Multiple instance learning framework with Context-Aware Clustering
(MiCo), designed to enhance cross-regional intra-tissue correlations and
strengthen inter-tissue semantic associations in WSIs. MiCo begins by
clustering instances to distill discriminative morphological patterns, with
cluster centroids serving as semantic anchors. To enhance cross-regional
intra-tissue correlations, MiCo employs a Cluster Route module, which
dynamically links instances of the same tissue type across distant regions via
feature similarity. These semantic anchors act as contextual hubs, propagating
semantic relationships to refine instance-level representations. To eliminate
semantic fragmentation and strengthen inter-tissue semantic associations, MiCo
integrates a Cluster Reducer module, which consolidates redundant anchors while
enhancing information exchange between distinct semantic groups. Extensive
experiments on two challenging tasks across nine large-scale public cancer
datasets demonstrate the effectiveness of MiCo, showcasing its superiority over
state-of-the-art methods. The code is available at
https://github.com/junjianli106/MiCo.

</details>


### [207] [Pre-Trained LLM is a Semantic-Aware and Generalizable Segmentation Booster](https://arxiv.org/abs/2506.18034)
*Fenghe Tang,Wenxin Ma,Zhiyang He,Xiaodong Tao,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: 论文发现冻结的预训练LLM层可用于医学图像分割任务，提出LLM4Seg结构，性能提升且参数增加少。


<details>
  <summary>Details</summary>
Motivation: 探索预训练LLM在视觉任务中的潜力，尤其是医学图像分割。

Method: 提出LLM4Seg，将冻结的预训练LLM层集成到CNN编码器-解码器分割框架中。

Result: 在多种模态（超声、皮肤镜等）中性能提升，且参数增加少。

Conclusion: LLM的语义感知能力可增强分割任务，全局和局部建模能力均改善。

Abstract: With the advancement of Large Language Model (LLM) for natural language
processing, this paper presents an intriguing finding: a frozen pre-trained LLM
layer can process visual tokens for medical image segmentation tasks.
Specifically, we propose a simple hybrid structure that integrates a
pre-trained, frozen LLM layer within the CNN encoder-decoder segmentation
framework (LLM4Seg). Surprisingly, this design improves segmentation
performance with a minimal increase in trainable parameters across various
modalities, including ultrasound, dermoscopy, polypscopy, and CT scans. Our
in-depth analysis reveals the potential of transferring LLM's semantic
awareness to enhance segmentation tasks, offering both improved global
understanding and better local modeling capabilities. The improvement proves
robust across different LLMs, validated using LLaMA and DeepSeek.

</details>


### [208] [CmFNet: Cross-modal Fusion Network for Weakly-supervised Segmentation of Medical Images](https://arxiv.org/abs/2506.18042)
*Dongdong Meng,Sheng Li,Hao Wu,Suqing Tian,Wenjun Ma,Guoping Wang,Xueqing Yan*

Main category: cs.CV

TL;DR: CmFNet是一种新型的3D弱监督跨模态医学图像分割方法，通过结合多模态信息和混合监督策略，显著提升了分割性能，减少了过拟合。


<details>
  <summary>Details</summary>
Motivation: 高质量密集标注成本高且耗时，弱监督学习利用稀疏标注更高效，但性能下降和过拟合是主要挑战。

Method: CmFNet包含三个组件：模态特定特征学习网络、跨模态特征学习网络和混合监督学习策略，结合多模态信息和多种监督方式。

Result: 在临床和公开数据集上，CmFNet优于现有弱监督方法，甚至在某些情况下优于全监督方法。

Conclusion: CmFNet为临床治疗提供了高效的分割工具，适用于多种医学专家。

Abstract: Accurate automatic medical image segmentation relies on high-quality, dense
annotations, which are costly and time-consuming. Weakly supervised learning
provides a more efficient alternative by leveraging sparse and coarse
annotations instead of dense, precise ones. However, segmentation performance
degradation and overfitting caused by sparse annotations remain key challenges.
To address these issues, we propose CmFNet, a novel 3D weakly supervised
cross-modal medical image segmentation approach. CmFNet consists of three main
components: a modality-specific feature learning network, a cross-modal feature
learning network, and a hybrid-supervised learning strategy. Specifically, the
modality-specific feature learning network and the cross-modal feature learning
network effectively integrate complementary information from multi-modal
images, enhancing shared features across modalities to improve segmentation
performance. Additionally, the hybrid-supervised learning strategy guides
segmentation through scribble supervision, intra-modal regularization, and
inter-modal consistency, modeling spatial and contextual relationships while
promoting feature alignment. Our approach effectively mitigates overfitting,
delivering robust segmentation results. It excels in segmenting both
challenging small tumor regions and common anatomical structures. Extensive
experiments on a clinical cross-modal nasopharyngeal carcinoma (NPC) dataset
(including CT and MR imaging) and the publicly available CT Whole Abdominal
Organ dataset (WORD) show that our approach outperforms state-of-the-art weakly
supervised methods. In addition, our approach also outperforms fully supervised
methods when full annotation is used. Our approach can facilitate clinical
therapy and benefit various specialists, including physicists, radiologists,
pathologists, and oncologists.

</details>


### [209] [CLGRPO: Reasoning Ability Enhancement for Small VLMs](https://arxiv.org/abs/2506.18048)
*Fanyi Wang,Binzhi Dong,Haotian Hu,Jinjin Xu,Zhiwang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种增量训练策略（Incremental Training Strategy），通过自监督构建链式思维（COT）数据，分四个阶段优化小规模视觉语言模型（SVLMs），显著提升了其推理能力，性能接近8B模型。


<details>
  <summary>Details</summary>
Motivation: SVLMs因参数规模小（≤2B）推理能力受限，但其低成本和高商业价值使其值得优化。本文旨在通过增量训练策略提升其推理能力。

Method: 1. 自监督构建COT数据；2. 分四阶段训练：SFT注入知识、GRPO对齐格式、GRPO增强推理、CLGRPO约束空间。

Result: 在EMOSet-118K数据集上，1B SVLM的准确率提升2.77，召回率提升0.69，性能接近8B模型。

Conclusion: 增量训练策略有效提升了SVLMs的推理能力，为小规模模型的优化提供了新思路。

Abstract: Small Vision Language Models (SVLMs) generally refer to models with parameter
sizes less than or equal to 2B. Their low cost and power consumption
characteristics confer high commercial value. However, their reasoning
abilities are limited by the number of parameters. To address this issue, this
paper proposes a post-training optimization paradigm called the Incremental
Training Strategy to enhance the reasoning ability of SVLMs. Firstly, we
constructed a Self-Supervised Chain-of-Thought (COT) Data Construction System,
which leverages multiple LVLMs with 7B parameters or more to transform original
data into COT data in a self-supervised manner. Our proposed Incremental
Training Strategy consists of four stages. Stage 1 injects domain knowledge by
performing Supervised Fine-Tuning (SFT) to the pretrained model on the COT
data. Stage 2 aligns the COT data format by conducting a small amount of Group
Relative Policy Optimization (GRPO) training constrained only by format rewards
on the COT data. Stage 3 enhances reasoning ability by applying GRPO training
on the COT data with constraints on both format and accuracy rewards. The
resulting model shows significant improvement compared to the baseline. Stage 4
addresses the limited capacity of the SVLMs and the weak ability to capture
complex patterns by proposing ClipLow GRPO (CLGRPO) to constrain the capture
space of the training process. We conducted extensive comparative and ablation
experiments on the abstract semantic recognition dataset EMOSet-118K.
Experimental results demonstrate that our method significantly improves the
reasoning ability of 1B SVLM. Compared to the baseline model fine-tuned on the
original data, accuracy increased by 2.77 and recall by 0.69, achieving
performance comparable to that of 8B models.

</details>


### [210] [Deep Supervised LSTM for 3D morphology estimation from Multi-View RGB Images of Wheat Spikes](https://arxiv.org/abs/2506.18060)
*Olivia Zumsteg,Nico Graf,Aaron Haeusler,Norbert Kirchgessner,Nicola Storni,Lukas Roth,Andreas Hund*

Main category: cs.CV

TL;DR: 该论文提出了一种基于深度学习的神经网络方法，用于从二维RGB图像中估计小麦穗的三维体积，克服了传统几何方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于二维图像在田间条件下存在深度信息丢失、投影失真和遮挡等问题，传统方法难以准确估计复杂几何形状（如小麦穗）的体积。

Method: 采用结合DINOv2自监督视觉变换器和单向LSTM网络的迁移学习管道，并通过深度监督学习增强模型的泛化能力。

Result: 在六视角室内图像上，模型的平均绝对百分比误差（MAPE）为6.46%，优于传统方法（9.36%和13.98%）。在单图像田间数据上微调后，MAPE为10.82%。

Conclusion: 深度学习模型在复杂几何形状的体积估计中表现优于传统方法，且通过领域适应可进一步提升性能。

Abstract: Estimating three-dimensional morphological traits from two-dimensional RGB
images presents inherent challenges due to the loss of depth information,
projection distortions, and occlusions under field conditions. In this work, we
explore multiple approaches for non-destructive volume estimation of wheat
spikes, using RGB image sequences and structured-light 3D scans as ground truth
references. Due to the complex geometry of the spikes, we propose a neural
network approach for volume estimation in 2D images, employing a transfer
learning pipeline that combines DINOv2, a self-supervised Vision Transformer,
with a unidirectional Long Short-Term Memory (LSTM) network. By using deep
supervision, the model is able to learn more robust intermediate
representations, which enhances its generalisation ability across varying
evaluation sequences. We benchmark our model against two conventional
baselines: a 2D area-based projection and a geometric reconstruction using
axis-aligned cross-sections. Our deep supervised model achieves a mean absolute
percentage error (MAPE) of 6.46% on six-view indoor images, outperforming the
area (9.36%) and geometric (13.98%) baselines. Fine-tuning the model on
field-based single-image data enables domain adaptation, yielding a MAPE of
10.82%. We demonstrate that object shape significantly impacts volume
prediction accuracy, with irregular geometries such as wheat spikes posing
greater challenges for geometric methods compared to our deep learning
approach.

</details>


### [211] [Training-free Test-time Improvement for Explainable Medical Image Classification](https://arxiv.org/abs/2506.18070)
*Hangzhou He,Jiachen Tang,Lei Zhu,Kaiwen Li,Yanye Lu*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的混淆概念识别策略，通过最小新数据和图像级标签提升跨域性能，同时保持源域准确性。


<details>
  <summary>Details</summary>
Motivation: 解决概念瓶颈模型（CBMs）在新环境中部署时因成像协议和染色方法差异导致的概念偏移问题，以及减少对昂贵专家标注概念的依赖。

Method: 采用训练自由的混淆概念识别策略，通过掩蔽误激活的混淆概念和放大未充分激活的判别性概念，仅需少量新数据和图像级标签。

Result: 在皮肤和白细胞图像上验证了方法的有效性，提升了跨域性能且不牺牲源域准确性。

Conclusion: 该方法为可解释医学图像分类提供了一种高效且低成本的解决方案。

Abstract: Deep learning-based medical image classification techniques are rapidly
advancing in medical image analysis, making it crucial to develop accurate and
trustworthy models that can be efficiently deployed across diverse clinical
scenarios. Concept Bottleneck Models (CBMs), which first predict a set of
explainable concepts from images and then perform classification based on these
concepts, are increasingly being adopted for explainable medical image
classification. However, the inherent explainability of CBMs introduces new
challenges when deploying trained models to new environments. Variations in
imaging protocols and staining methods may induce concept-level shifts, such as
alterations in color distribution and scale. Furthermore, since CBM training
requires explicit concept annotations, fine-tuning models solely with
image-level labels could compromise concept prediction accuracy and
faithfulness - a critical limitation given the high cost of acquiring
expert-annotated concept labels in medical domains. To address these
challenges, we propose a training-free confusion concept identification
strategy. By leveraging minimal new data (e.g., 4 images per class) with only
image-level labels, our approach enhances out-of-domain performance without
sacrificing source domain accuracy through two key operations: masking
misactivated confounding concepts and amplifying under-activated discriminative
concepts. The efficacy of our method is validated on both skin and white blood
cell images. Our code is available at:
https://github.com/riverback/TF-TTI-XMed.

</details>


### [212] [MUPA: Towards Multi-Path Agentic Reasoning for Grounded Video Question Answering](https://arxiv.org/abs/2506.18071)
*Jisheng Dang,Huilin Song,Junbin Xiao,Bimei Wang,Han Peng,Haoxuan Li,Xun Yang,Meng Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: MUPA是一种多路径协作方法，用于解决Grounded VideoQA问题，通过结合视频定位、问答、答案反思和聚合，显著提高了定位准确性。


<details>
  <summary>Details</summary>
Motivation: 现代多模态模型依赖语言先验和虚假相关性，导致预测结果缺乏视觉证据支持。

Method: MUPA采用多路径代理方法，包括视频定位、问答、答案反思和聚合，通过三种不同的推理路径和反思代理实现一致的结果。

Result: MUPA在2B参数规模下优于7B规模的竞争对手，7B参数时在NExT-GQA和DeVE-QA上达到30.3%和47.4%的Acc@GQA。

Conclusion: MUPA在视频语言理解中表现出高效性和可信赖性，代码已开源。

Abstract: Grounded Video Question Answering (Grounded VideoQA) requires aligning
textual answers with explicit visual evidence. However, modern multimodal
models often rely on linguistic priors and spurious correlations, resulting in
poorly grounded predictions. In this work, we propose MUPA, a cooperative
MUlti-Path Agentic approach that unifies video grounding, question answering,
answer reflection and aggregation to tackle Grounded VideoQA. MUPA features
three distinct reasoning paths on the interplay of grounding and QA agents in
different chronological orders, along with a dedicated reflection agent to
judge and aggregate the multi-path results to accomplish consistent QA and
grounding. This design markedly improves grounding fidelity without sacrificing
answer accuracy. Despite using only 2B parameters, our method outperforms all
7B-scale competitors. When scaled to 7B parameters, MUPA establishes new
state-of-the-art results, with Acc@GQA of 30.3% and 47.4% on NExT-GQA and
DeVE-QA respectively, demonstrating MUPA' effectiveness towards trustworthy
video-language understanding. Our code is available in
https://github.com/longmalongma/MUPA.

</details>


### [213] [TEM^3-Learning: Time-Efficient Multimodal Multi-Task Learning for Advanced Assistive Driving](https://arxiv.org/abs/2506.18084)
*Wenzhuo Liu,Yicheng Qiao,Zhen Wang,Qiannan Guo,Zilong Chen,Meihua Zhou,Xinran Li,Letian Wang,Zhiwei Li,Huaping Liu,Wenshuo Wang*

Main category: cs.CV

TL;DR: TEM^3-Learning是一种高效的多模态多任务学习框架，用于辅助驾驶中的多任务识别，通过两阶段架构和轻量级设计实现高精度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多任务学习中存在单模态限制和架构低效的问题，无法满足实时辅助驾驶的需求。

Method: 提出两阶段架构：MTS-Mamba子网络提取多视角时空特征，MGMI模块通过任务特定门控整合多模态特征。

Result: 在AIDE数据集上实现SOTA精度，参数少于600万，推理速度达142.32 FPS。

Conclusion: TEM^3-Learning通过高效架构和多模态整合，显著提升了多任务学习的性能和实用性。

Abstract: Multi-task learning (MTL) can advance assistive driving by exploring
inter-task correlations through shared representations. However, existing
methods face two critical limitations: single-modality constraints limiting
comprehensive scene understanding and inefficient architectures impeding
real-time deployment. This paper proposes TEM^3-Learning (Time-Efficient
Multimodal Multi-task Learning), a novel framework that jointly optimizes
driver emotion recognition, driver behavior recognition, traffic context
recognition, and vehicle behavior recognition through a two-stage architecture.
The first component, the mamba-based multi-view temporal-spatial feature
extraction subnetwork (MTS-Mamba), introduces a forward-backward temporal
scanning mechanism and global-local spatial attention to efficiently extract
low-cost temporal-spatial features from multi-view sequential images. The
second component, the MTL-based gated multimodal feature integrator (MGMI),
employs task-specific multi-gating modules to adaptively highlight the most
relevant modality features for each task, effectively alleviating the negative
transfer problem in MTL. Evaluation on the AIDE dataset, our proposed model
achieves state-of-the-art accuracy across all four tasks, maintaining a
lightweight architecture with fewer than 6 million parameters and delivering an
impressive 142.32 FPS inference speed. Rigorous ablation studies further
validate the effectiveness of the proposed framework and the independent
contributions of each module. The code is available on
https://github.com/Wenzhuo-Liu/TEM3-Learning.

</details>


### [214] [ShareGPT-4o-Image: Aligning Multimodal Models with GPT-4o-Level Image Generation](https://arxiv.org/abs/2506.18095)
*Junying Chen,Zhenyang Cai,Pengcheng Chen,Shunian Chen,Ke Ji,Xidong Wang,Yunjin Yang,Benyou Wang*

Main category: cs.CV

TL;DR: 论文介绍了ShareGPT-4o-Image数据集和Janus-4o模型，旨在开源多模态生成能力，提升文本到图像及文本加图像到图像的生成性能。


<details>
  <summary>Details</summary>
Motivation: 当前先进的多模态生成模型（如GPT-4o-Image）多为专有且不可访问，作者希望通过开源数据集和模型推动相关研究的开放发展。

Method: 使用GPT-4o生成合成数据集ShareGPT-4o-Image（45K文本到图像和46K文本加图像到图像数据），并基于此训练Janus-4o模型。

Result: Janus-4o在文本到图像生成上显著优于前代模型Janus-Pro，并首次支持文本加图像到图像生成，仅用91K样本和6小时训练即达到优异性能。

Conclusion: 开源ShareGPT-4o-Image和Janus-4o将促进逼真、指令对齐的图像生成研究的开放发展。

Abstract: Recent advances in multimodal generative models have unlocked photorealistic,
instruction-aligned image generation, yet leading systems like GPT-4o-Image
remain proprietary and inaccessible. To democratize these capabilities, we
present ShareGPT-4o-Image, the first dataset comprising 45K text-to-image and
46K text-and-image-to-image data, all synthesized using GPT-4o's image
generation capabilities for distilling its advanced image generation abilities.
Leveraging this dataset, we develop Janus-4o, a multimodal large language model
capable of both text-to-image and text-and-image-to-image generation. Janus-4o
not only significantly improves text-to-image generation over its predecessor,
Janus-Pro, but also newly supports text-and-image-to-image generation. Notably,
it achieves impressive performance in text-and-image-to-image generation from
scratch, using only 91K synthetic samples and 6 hours of training on an 8
A800-GPU machine. We hope the release of ShareGPT-4o-Image and Janus-4o will
foster open research in photorealistic, instruction-aligned image generation.

</details>


### [215] [Enhancing VICReg: Random-Walk Pairing for Improved Generalization and Better Global Semantics Capturing](https://arxiv.org/abs/2506.18104)
*Idan Simai,Ronen Talmon,Uri Shaham*

Main category: cs.CV

TL;DR: 论文通过光谱嵌入视角分析VICReg方法，发现其可能因过度依赖训练数据而泛化能力不足，提出改进方法SAG-VICReg，增强全局语义捕捉和泛化能力，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: VICReg方法在自监督学习中可能因依赖训练数据而泛化不足，需改进以提升对未见数据的表征能力。

Method: 提出SAG-VICReg，在VICReg基础上引入新训练技术，增强全局语义捕捉和泛化能力。

Result: SAG-VICReg在泛化能力和全局语义理解上优于现有方法，同时保持局部指标竞争力，并提出新无标签评估指标。

Conclusion: SAG-VICReg有效解决VICReg的泛化问题，提升全局语义理解，为无标签数据评估提供新方法。

Abstract: In this paper, we argue that viewing VICReg-a popular self-supervised
learning (SSL) method--through the lens of spectral embedding reveals a
potential source of sub-optimality: it may struggle to generalize robustly to
unseen data due to overreliance on the training data. This observation invites
a closer look at how well this method achieves its goal of producing meaningful
representations of images outside of the training set as well. Here, we
investigate this issue and introduce SAG-VICReg (Stable and Generalizable
VICReg), a method that builds on VICReg by incorporating new training
techniques. These enhancements improve the model's ability to capture global
semantics within the data and strengthen the generalization capabilities.
Experiments demonstrate that SAG-VICReg effectively addresses the
generalization challenge while matching or surpassing diverse state-of-the-art
SSL baselines. Notably, our method exhibits superior performance on metrics
designed to evaluate global semantic understanding, while simultaneously
maintaining competitive results on local evaluation metrics. Furthermore, we
propose a new standalone evaluation metric for embeddings that complements the
standard evaluation methods and accounts for the global data structure without
requiring labels--a key issue when tagged data is scarce or not available.

</details>


### [216] [Targeted False Positive Synthesis via Detector-guided Adversarial Diffusion Attacker for Robust Polyp Detection](https://arxiv.org/abs/2506.18134)
*Quan Zhou,Gan Luo,Qiang Hu,Qingyong Zhang,Jinhua Zhang,Yinjiao Tian,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: 提出了一种对抗扩散框架，用于合成高价值的假阳性样本，以改进结肠息肉检测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有息肉检测模型受限于数据规模和多样性，且生成模型多关注息肉多样性而忽视假阳性问题。

Method: 设计了区域噪声匹配策略和检测器引导对抗扩散攻击模块（DADA），用于合成多样背景和高价值假阳性样本。

Result: 在公开和内部数据集上验证了方法的优越性，合成数据使检测器F1分数分别提升至少2.6%和2.7%。

Conclusion: 首次将对抗扩散应用于病灶检测，为靶向假阳性合成开辟了新范式，提升了结肠癌筛查的可靠性。

Abstract: Polyp detection is crucial for colorectal cancer screening, yet existing
models are limited by the scale and diversity of available data. While
generative models show promise for data augmentation, current methods mainly
focus on enhancing polyp diversity, often overlooking the critical issue of
false positives. In this paper, we address this gap by proposing an adversarial
diffusion framework to synthesize high-value false positives. The extensive
variability of negative backgrounds presents a significant challenge in false
positive synthesis. To overcome this, we introduce two key innovations: First,
we design a regional noise matching strategy to construct a negative synthesis
space using polyp detection datasets. This strategy trains a negative-centric
diffusion model by masking polyp regions, ensuring the model focuses
exclusively on learning diverse background patterns. Second, we introduce the
Detector-guided Adversarial Diffusion Attacker (DADA) module, which perturbs
the negative synthesis process to disrupt a pre-trained detector's decision,
guiding the negative-centric diffusion model to generate high-value,
detector-confusing false positives instead of low-value, ordinary backgrounds.
Our approach is the first to apply adversarial diffusion to lesion detection,
establishing a new paradigm for targeted false positive synthesis and paving
the way for more reliable clinical applications in colorectal cancer screening.
Extensive results on public and in-house datasets verify the superiority of our
method over the current state-of-the-arts, with our synthesized data improving
the detectors by at least 2.6% and 2.7% in F1-score, respectively, over the
baselines. Codes are at https://github.com/Huster-Hq/DADA.

</details>


### [217] [See-in-Pairs: Reference Image-Guided Comparative Vision-Language Models for Medical Diagnosis](https://arxiv.org/abs/2506.18140)
*Ruinan Jin,Gexin Huang,Xinwei Shen,Qiong Zhang,Yan Shuo Tan,Xiaoxiao Li*

Main category: cs.CV

TL;DR: 该论文提出了一种结合医学领域知识的视觉语言模型（VLM），通过引入参考图像的比较分析，显著提升了医学诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型缺乏比较推理机制，而通用视觉语言模型又缺乏医学领域知识，因此需要结合两者优势以提升诊断效果。

Method: 通过为通用VLM提供查询图像和匹配的参考图像，并结合临床启发的比较提示，进行监督微调（SFT）。

Result: 实验表明，该方法在多个医学视觉问答（VQA）任务中显著优于单图像基线。

Conclusion: 比较图像分析在医学诊断中具有临床相关性，通过结合参考图像和临床提示，可以显著提升VLM的诊断性能。

Abstract: Medical imaging diagnosis presents inherent challenges due to diseases that
mimic normal anatomy and exhibit significant inter-patient variability.
Clinicians routinely employ comparative reasoning-using reference images from
healthy controls or previous patient examinations-to discern subtle yet
diagnostically critical abnormalities. However, existing medical
vision-language models (VLMs) focus primarily on single-image or single-series
analyses and lack explicit mechanisms for comparative reasoning. Conversely,
general-purpose VLMs demonstrate strong multi-image comparative reasoning
capabilities but lack essential medical-domain knowledge to identify nuanced
clinical differences. This work aims to bridge this gap by exploring
clinically-inspired comparative analysis within VLMs, leveraging reference
images to enhance diagnostic accuracy. Through extensive empirical analysis, we
show that providing general-purpose VLMs with query and normative matched
reference images, accompanied by clinically-informed comparative prompts,
significantly improves diagnostic outcomes compared to single-image baselines,
especially after supervised finetuning (SFT). Our contributions highlight the
clinical relevance of comparative analysis introduce novel strategies for
leveraging reference images in VLMs, empirically demonstrate enhanced
performance across multiple medical visual question answering (VQA) tasks, and
provide theoretical insights into the efficacy of comparative image analysis in
medical diagnosis.

</details>


### [218] [Pattern-Based Phase-Separation of Tracer and Dispersed Phase Particles in Two-Phase Defocusing Particle Tracking Velocimetry](https://arxiv.org/abs/2506.18157)
*Christian Sax,Jochen Kriegseis*

Main category: cs.CV

TL;DR: 论文提出了一种基于后处理的相分离方法，用于散焦粒子追踪测速中的分散两相流，通过单相机实现两相粒子的3D定位。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在分散两相流中相分离的局限性，特别是在波长、尺寸或相关性方法不适用的情况下。

Method: 利用卷积神经网络（如Faster R-CNN和YOLOv4）检测和分类散焦粒子图像，并通过生成对抗网络生成实验特定的训练数据。

Result: 在合成和真实数据集中，检测精度和分类准确率达到95-100%，即使存在领域偏移。

Conclusion: 证实了CNN在分散两相流中实现稳健相分离的可行性，尤其在传统方法不适用时。

Abstract: This work investigates the feasibility of a post-processing-based approach
for phase separation in defocusing particle tracking velocimetry for dispersed
two-phase flows. The method enables the simultaneous 3D localization
determination of both tracer particles and particles of the dispersed phase,
using a single-camera setup. The distinction between phases is based on pattern
differences in defocused particle images, which arise from distinct light
scattering behaviors of tracer particles and bubbles or droplets. Convolutional
neural networks, including Faster R-CNN and YOLOv4 variants, are trained to
detect and classify particle images based on these pattern features. To
generate large, labeled training datasets, a generative adversarial network
based framework is introduced, allowing the generation of auto-labeled data
that more closely reflects experiment-specific visual appearance. Evaluation
across six datasets, comprising synthetic two-phase and real single- and
two-phase flows, demonstrates high detection precision and classification
accuracy (95-100%), even under domain shifts. The results confirm the viability
of using CNNs for robust phase separation in disperse two-phase DPTV,
particularly in scenarios where traditional wavelength-, size-, or ensemble
correlation-based methods are impractical.

</details>


### [219] [CDG-MAE: Learning Correspondences from Diffusion Generated Views](https://arxiv.org/abs/2506.18164)
*Varun Belagali,Pierre Marza,Srikar Yellapragada,Zilinghan Li,Tarak Nath Nandi,Ravi K Madduri,Joel Saltz,Stergios Christodoulidis,Maria Vakalopoulou,Dimitris Samaras*

Main category: cs.CV

TL;DR: CDG-MAE是一种基于MAE的自监督方法，利用扩散模型生成多样合成视图，显著提升密集对应学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决密集对应学习中手动标注繁琐且不可扩展的问题，以及现有自监督方法训练数据不足的挑战。

Method: 通过图像条件扩散模型生成多样合成视图，采用多锚点策略调整预训练任务难度。

Result: CDG-MAE显著优于仅依赖图像的MAE方法，并缩小了与基于视频方法的性能差距。

Conclusion: CDG-MAE为密集对应学习提供了一种高效且可扩展的自监督解决方案。

Abstract: Learning dense correspondences, critical for application such as video label
propagation, is hindered by tedious and unscalable manual annotation.
Self-supervised methods address this by using a cross-view pretext task, often
modeled with a masked autoencoder, where a masked target view is reconstructed
from an anchor view. However, acquiring effective training data remains a
challenge - collecting diverse video datasets is difficult and costly, while
simple image crops lack necessary pose variations. This paper introduces
CDG-MAE, a novel MAE-based self-supervised method that uses diverse synthetic
views generated from static images via an image-conditioned diffusion model.
These generated views exhibit substantial changes in pose and perspective,
providing a rich training signal that overcomes the limitations of video and
crop-based anchors. We present a quantitative method to evaluate local and
global consistency of generated images, discussing their use for cross-view
self-supervised pretraining. Furthermore, we enhance the standard single-anchor
MAE setting to a multi-anchor strategy to effectively modulate the difficulty
of pretext task. CDG-MAE significantly outperforms state-of-the-art MAE methods
reliant only on images and substantially narrows the performance gap to
video-based approaches.

</details>


### [220] [STACT-Time: Spatio-Temporal Cross Attention for Cine Thyroid Ultrasound Time Series Classification](https://arxiv.org/abs/2506.18172)
*Irsyad Adam,Tengyue Zhang,Shrayes Raman,Zhuyu Qiu,Brandon Taraku,Hexiang Feng,Sile Wang,Ashwath Radhachandran,Shreeram Athreya,Vedrana Ivezic,Peipei Ping,Corey Arnold,William Speier*

Main category: cs.CV

TL;DR: 论文提出了一种名为STACT-Time的深度学习模型，用于甲状腺超声动态视频分类，以减少不必要的良性结节活检。


<details>
  <summary>Details</summary>
Motivation: 当前甲状腺结节活检存在不必要的良性结节活检问题，且现有系统受限于观察者间的变异性。

Method: 提出STACT-Time模型，结合超声动态视频和分割掩模特征，利用自注意力和交叉注意力机制捕捉时空上下文。

Result: 模型在恶性肿瘤预测中表现优异，交叉验证精确度为0.91，F1分数为0.89。

Conclusion: 该模型有望减少不必要的活检，提高临床决策质量，改善患者预后。

Abstract: Thyroid cancer is among the most common cancers in the United States. Thyroid
nodules are frequently detected through ultrasound (US) imaging, and some
require further evaluation via fine-needle aspiration (FNA) biopsy. Despite its
effectiveness, FNA often leads to unnecessary biopsies of benign nodules,
causing patient discomfort and anxiety. To address this, the American College
of Radiology Thyroid Imaging Reporting and Data System (TI-RADS) has been
developed to reduce benign biopsies. However, such systems are limited by
interobserver variability. Recent deep learning approaches have sought to
improve risk stratification, but they often fail to utilize the rich temporal
and spatial context provided by US cine clips, which contain dynamic global
information and surrounding structural changes across various views. In this
work, we propose the Spatio-Temporal Cross Attention for Cine Thyroid
Ultrasound Time Series Classification (STACT-Time) model, a novel
representation learning framework that integrates imaging features from US cine
clips with features from segmentation masks automatically generated by a
pretrained model. By leveraging self-attention and cross-attention mechanisms,
our model captures the rich temporal and spatial context of US cine clips while
enhancing feature representation through segmentation-guided learning. Our
model improves malignancy prediction compared to state-of-the-art models,
achieving a cross-validation precision of 0.91 (plus or minus 0.02) and an F1
score of 0.89 (plus or minus 0.02). By reducing unnecessary biopsies of benign
nodules while maintaining high sensitivity for malignancy detection, our model
has the potential to enhance clinical decision-making and improve patient
outcomes.

</details>


### [221] [DExNet: Combining Observations of Domain Adapted Critics for Leaf Disease Classification with Limited Data](https://arxiv.org/abs/2506.18173)
*Sabbir Ahmed,Md. Bakhtiar Hasan,Tasnim Ahmed,Md. Hasanul Kabir*

Main category: cs.CV

TL;DR: 提出了一种少样本学习框架DExNet，通过结合多个预训练CNN架构的观察结果，解决了植物病害分类中数据不足的问题，并在多个场景下取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在植物病害分类中需要大量数据，而实际应用中数据往往有限。DExNet旨在通过少样本学习解决这一问题。

Method: 使用9个预训练的CNN架构提取特征嵌入，通过域适应和特征融合块处理，最终用Bi-LSTM分类器进行分类。

Result: 在番茄叶病害分类任务中，5-shot、10-shot和15-shot的准确率分别为89.06%、92.46%和94.07%，80-shot下达到98.09%，仅比最优方法低1.2%。

Conclusion: DExNet在数据有限的情况下表现优异，显著减少了训练数据需求，适用于多种实际场景。

Abstract: While deep learning-based architectures have been widely used for correctly
detecting and classifying plant diseases, they require large-scale datasets to
learn generalized features and achieve state-of-the-art performance. This poses
a challenge for such models to obtain satisfactory performance in classifying
leaf diseases with limited samples. This work proposes a few-shot learning
framework, Domain-adapted Expert Network (DExNet), for plant disease
classification that compensates for the lack of sufficient training data by
combining observations of a number of expert critics. It starts with extracting
the feature embeddings as 'observations' from nine 'critics' that are
state-of-the-art pre-trained CNN-based architectures. These critics are 'domain
adapted' using a publicly available leaf disease dataset having no overlapping
classes with the specific downstream task of interest. The observations are
then passed to the 'Feature Fusion Block' and finally to a classifier network
consisting of Bi-LSTM layers. The proposed pipeline is evaluated on the 10
classes of tomato leaf images from the PlantVillage dataset, achieving
promising accuracies of 89.06%, 92.46%, and 94.07%, respectively, for 5-shot,
10-shot, and 15-shot classification. Furthermore, an accuracy of 98.09+-0.7%
has been achieved in 80-shot classification, which is only 1.2% less than
state-of-the-art, allowing a 94.5% reduction in the training data requirement.
The proposed pipeline also outperforms existing works on leaf disease
classification with limited data in both laboratory and real-life conditions in
single-domain, mixed-domain, and cross-domain scenarios.

</details>


### [222] [Multimodal Fusion SLAM with Fourier Attention](https://arxiv.org/abs/2506.18204)
*Youjie Zhou,Guofeng Mei,Yiming Wang,Yi Wan,Fabio Poiesi*

Main category: cs.CV

TL;DR: FMF-SLAM是一种高效的多模态融合SLAM方法，利用FFT提升算法效率，适用于噪声、光照变化和黑暗环境。


<details>
  <summary>Details</summary>
Motivation: 传统基于光流的视觉SLAM方法计算资源需求高，难以应对噪声、光照变化和黑暗环境。

Method: 提出基于傅里叶的自注意力和跨注意力机制，结合多尺度知识蒸馏，融合RGB和深度信号。

Result: 在TUM、TartanAir和真实数据集上验证，表现出色，支持实时性能。

Conclusion: FMF-SLAM在复杂环境中具有高效性和实用性，代码和数据集已开源。

Abstract: Visual SLAM is particularly challenging in environments affected by noise,
varying lighting conditions, and darkness. Learning-based optical flow
algorithms can leverage multiple modalities to address these challenges, but
traditional optical flow-based visual SLAM approaches often require significant
computational resources.To overcome this limitation, we propose FMF-SLAM, an
efficient multimodal fusion SLAM method that utilizes fast Fourier transform
(FFT) to enhance the algorithm efficiency. Specifically, we introduce a novel
Fourier-based self-attention and cross-attention mechanism to extract features
from RGB and depth signals. We further enhance the interaction of multimodal
features by incorporating multi-scale knowledge distillation across modalities.
We also demonstrate the practical feasibility of FMF-SLAM in real-world
scenarios with real time performance by integrating it with a security robot by
fusing with a global positioning module GNSS-RTK and global Bundle Adjustment.
Our approach is validated using video sequences from TUM, TartanAir, and our
real-world datasets, showcasing state-of-the-art performance under noisy,
varying lighting, and dark conditions.Our code and datasets are available at
https://github.com/youjie-zhou/FMF-SLAM.git.

</details>


### [223] [Limitations of NERF with pre-trained Vision Features for Few-Shot 3D Reconstruction](https://arxiv.org/abs/2506.18208)
*Ankit Sanjyal*

Main category: cs.CV

TL;DR: DINO增强的NeRF模型在极端少样本场景下表现不如基线NeRF，预训练视觉特征可能无益甚至有害。


<details>
  <summary>Details</summary>
Motivation: 探索预训练视觉特征（如DINO）对少样本3D重建的有效性。

Method: 系统评估DINO增强的NeRF模型，包括基线NeRF、冻结DINO特征、LoRA微调特征和多尺度特征融合。

Result: 所有DINO变体表现均差于基线NeRF（PSNR 12.9-13.0 vs 14.71），预训练特征可能引入有害偏差。

Conclusion: 少样本场景下，专注于几何一致性的简单架构可能更有效，预训练特征未必有益。

Abstract: Neural Radiance Fields (NeRF) have revolutionized 3D scene reconstruction
from sparse image collections. Recent work has explored integrating pre-trained
vision features, particularly from DINO, to enhance few-shot reconstruction
capabilities. However, the effectiveness of such approaches remains unclear,
especially in extreme few-shot scenarios. In this paper, we present a
systematic evaluation of DINO-enhanced NeRF models, comparing baseline NeRF,
frozen DINO features, LoRA fine-tuned features, and multi-scale feature fusion.
Surprisingly, our experiments reveal that all DINO variants perform worse than
the baseline NeRF, achieving PSNR values around 12.9 to 13.0 compared to the
baseline's 14.71. This counterintuitive result suggests that pre-trained vision
features may not be beneficial for few-shot 3D reconstruction and may even
introduce harmful biases. We analyze potential causes including feature-task
mismatch, overfitting to limited data, and integration challenges. Our findings
challenge common assumptions in the field and suggest that simpler
architectures focusing on geometric consistency may be more effective for
few-shot scenarios.

</details>


### [224] [Deep Learning-based Alignment Measurement in Knee Radiographs](https://arxiv.org/abs/2506.18209)
*Zhisen Hu,Dominic Cullen,Peter Thompson,David Johnson,Chang Bian,Aleksei Tiulpin,Timothy Cootes,Claudia Lindner*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的膝关节对齐（KA）测量方法，通过自动定位膝关节解剖标志，显著提高了测量的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统KA测量方法耗时且依赖长腿X光片，需要自动化解决方案以提高效率和准确性。

Method: 采用沙漏网络和注意力门结构，自动定位100多个膝关节解剖标志，实现KA测量。

Result: 方法在术前和术后图像上均表现优异，与临床实测相比平均绝对差异约1°，ICC术前0.97，术后0.86。

Conclusion: 该方法能高精度自动化KA评估，为数字化临床工作流程提供了新机会。

Abstract: Radiographic knee alignment (KA) measurement is important for predicting
joint health and surgical outcomes after total knee replacement. Traditional
methods for KA measurements are manual, time-consuming and require long-leg
radiographs. This study proposes a deep learning-based method to measure KA in
anteroposterior knee radiographs via automatically localized knee anatomical
landmarks. Our method builds on hourglass networks and incorporates an
attention gate structure to enhance robustness and focus on key anatomical
features. To our knowledge, this is the first deep learning-based method to
localize over 100 knee anatomical landmarks to fully outline the knee shape
while integrating KA measurements on both pre-operative and post-operative
images. It provides highly accurate and reliable anatomical varus/valgus KA
measurements using the anatomical tibiofemoral angle, achieving mean absolute
differences ~1{\deg} when compared to clinical ground truth measurements.
Agreement between automated and clinical measurements was excellent
pre-operatively (intra-class correlation coefficient (ICC) = 0.97) and good
post-operatively (ICC = 0.86). Our findings demonstrate that KA assessment can
be automated with high accuracy, creating opportunities for digitally enhanced
clinical workflows.

</details>


### [225] [Shape from Polarization of Thermal Emission and Reflection](https://arxiv.org/abs/2506.18217)
*Kazuma Kitazawa,Tsuyoshi Takatani*

Main category: cs.CV

TL;DR: 论文提出了一种基于长波红外偏振（LWIR SfP）的透明物体形状估计方法，通过改进偏振模型和结合学习与模型方法，显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 透明物体形状估计因复杂的光传输而困难，传统方法在长波红外偏振中存在误差，主要由于忽略了反射效应。

Method: 提出了一种新的偏振模型，同时考虑发射和反射效应，并采用基于模型和学习的方法估计表面法线，还建立了合成数据集和真实数据集ThermoPol。

Result: 实验表明，该方法在各种材料（包括可见光透明材料）上具有高准确性和广泛适用性。

Conclusion: 通过改进偏振模型和结合多种方法，论文成功解决了透明物体形状估计的挑战，并提供了首个真实世界LWIR SfP基准数据集。

Abstract: Shape estimation for transparent objects is challenging due to their complex
light transport. To circumvent these difficulties, we leverage the Shape from
Polarization (SfP) technique in the Long-Wave Infrared (LWIR) spectrum, where
most materials are opaque and emissive. While a few prior studies have explored
LWIR SfP, these attempts suffered from significant errors due to inadequate
polarimetric modeling, particularly the neglect of reflection. Addressing this
gap, we formulated a polarization model that explicitly accounts for the
combined effects of emission and reflection. Based on this model, we estimated
surface normals using not only a direct model-based method but also a
learning-based approach employing a neural network trained on a
physically-grounded synthetic dataset. Furthermore, we modeled the LWIR
polarimetric imaging process, accounting for inherent systematic errors to
ensure accurate polarimetry. We implemented a prototype system and created
ThermoPol, the first real-world benchmark dataset for LWIR SfP. Through
comprehensive experiments, we demonstrated the high accuracy and broad
applicability of our method across various materials, including those
transparent in the visible spectrum.

</details>


### [226] [Cross-Architecture Knowledge Distillation (KD) for Retinal Fundus Image Anomaly Detection on NVIDIA Jetson Nano](https://arxiv.org/abs/2506.18220)
*Berk Yilmaz,Aniruddh Aiyengar*

Main category: cs.CV

TL;DR: 该论文提出了一种轻量级的边缘设备可部署视网膜疾病分类器，通过跨架构知识蒸馏技术，解决了资源有限地区诊断设备不足的问题。


<details>
  <summary>Details</summary>
Motivation: 在资源有限地区，早期准确诊断视网膜疾病至关重要，但缺乏可靠的诊断设备。

Method: 使用高容量ViT教师模型（预训练于I-JEPA自监督学习）分类眼底图像，并通过PCA投影器、GL投影器和多视图鲁棒训练方法压缩为CNN学生模型。

Result: 学生模型参数比教师模型少97.4%，分类准确率达89%，保留了教师模型93%的诊断性能。

Conclusion: 该方法在压缩ViT的同时保持了准确性，为资源有限地区提供了可扩展的AI驱动视网膜疾病分类解决方案。

Abstract: Early and accurate identification of retinal ailments is crucial for averting
ocular decline; however, access to dependable diagnostic devices is not often
available in low-resourced settings. This project proposes to solve that by
developing a lightweight, edge-device deployable disease classifier using
cross-architecture knowledge distilling. We first train a high-capacity vision
transformer (ViT) teacher model, pre-trained using I-JEPA self-supervised
learning, to classify fundus images into four classes: Normal, Diabetic
Retinopathy, Glaucoma, and Cataract. We kept an Internet of Things (IoT) focus
when compressing to a CNN-based student model for deployment in
resource-limited conditions, such as the NVIDIA Jetson Nano. This was
accomplished using a novel framework which included a Partitioned
Cross-Attention (PCA) projector, a Group-Wise Linear (GL) projector, and a
multi-view robust training method. The teacher model has 97.4 percent more
parameters than the student model, with it achieving 89 percent classification
with a roughly 93 percent retention of the teacher model's diagnostic
performance. The retention of clinical classification behavior supports our
method's initial aim: compression of the ViT while retaining accuracy. Our work
serves as an example of a scalable, AI-driven triage solution for retinal
disorders in under-resourced areas.

</details>


### [227] [Make It Efficient: Dynamic Sparse Attention for Autoregressive Image Generation](https://arxiv.org/abs/2506.18226)
*Xunzhi Xiang,Qi Fan*

Main category: cs.CV

TL;DR: 论文提出了一种名为ADSA的训练自由上下文优化方法，通过动态识别关键历史标记来优化注意力计算，减少推理时的内存和计算开销。


<details>
  <summary>Details</summary>
Motivation: 自回归图像生成模型在推理时因长上下文导致内存和计算开销大，需优化。

Method: 提出ADSA方法，动态识别关键历史标记，并引入动态KV-cache更新机制。

Result: 实验表明ADSA在生成质量和资源效率上均表现优越，GPU内存消耗减少约50%。

Conclusion: ADSA有效解决了长上下文推理问题，提升了生成效率和资源利用率。

Abstract: Autoregressive conditional image generation models have emerged as a dominant
paradigm in text-to-image synthesis. These methods typically convert images
into one-dimensional token sequences and leverage the self-attention mechanism,
which has achieved remarkable success in natural language processing, to
capture long-range dependencies, model global context, and ensure semantic
coherence. However, excessively long contexts during inference lead to
significant memory overhead caused by KV-cache and computational delays. To
alleviate these challenges, we systematically analyze how global semantics,
spatial layouts, and fine-grained textures are formed during inference, and
propose a novel training-free context optimization method called Adaptive
Dynamic Sparse Attention (ADSA). Conceptually, ADSA dynamically identifies
historical tokens crucial for maintaining local texture consistency and those
essential for ensuring global semantic coherence, thereby efficiently
streamlining attention computation. Additionally, we introduce a dynamic
KV-cache update mechanism tailored for ADSA, reducing GPU memory consumption
during inference by approximately $50\%$. Extensive qualitative and
quantitative experiments demonstrate the effectiveness and superiority of our
approach in terms of both generation quality and resource efficiency.

</details>


### [228] [Drive-R1: Bridging Reasoning and Planning in VLMs for Autonomous Driving with Reinforcement Learning](https://arxiv.org/abs/2506.18234)
*Yue Li,Meng Tian,Dechang Zhu,Jiangtong Zhu,Zhenyu Lin,Zhiwei Xiong,Xinhai Zhao*

Main category: cs.CV

TL;DR: Drive-R1是一种针对自动驾驶的大规模视觉语言模型，通过结合监督微调和强化学习，解决了现有模型依赖历史输入和推理与规划不对齐的问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在自动驾驶任务中过度依赖历史输入，且推理过程与运动规划结果不对齐，Drive-R1旨在解决这些问题。

Method: Drive-R1通过监督微调结合强化学习，逐步从视觉输入推理到最终规划决策，并通过奖励机制优化推理路径。

Result: 在nuScenes和DriveLM-nuScenes基准测试中，Drive-R1表现优于现有最先进的视觉语言模型。

Conclusion: Drive-R1为自动驾驶中推理与规划的结合提供了有前景的方向，并为未来研究提供了方法学启示。

Abstract: Large vision-language models (VLMs) for autonomous driving (AD) are evolving
beyond perception and cognition tasks toward motion planning. However, we
identify two critical challenges in this direction: (1) VLMs tend to learn
shortcuts by relying heavily on history input information, achieving seemingly
strong planning results without genuinely understanding the visual inputs; and
(2) the chain-ofthought (COT) reasoning processes are always misaligned with
the motion planning outcomes, and how to effectively leverage the complex
reasoning capability to enhance planning remains largely underexplored. In this
paper, we start from a small-scale domain-specific VLM and propose Drive-R1
designed to bridges the scenario reasoning and motion planning for AD. Drive-R1
first undergoes the supervised finetuning on a elaborate dataset containing
both long and short COT data. Drive-R1 is encouraged to reason step-by-step
from visual input to final planning decisions. Subsequently, Drive-R1 is
trained within a reinforcement learning framework that incentivizes the
discovery of reasoning paths that are more informative for planning, guided by
rewards based on predicted trajectories and meta actions. Experimental
evaluations on the nuScenes and DriveLM-nuScenes benchmarks demonstrate that
Drive-R1 achieves superior performance compared to existing state-of-the-art
VLMs. We believe that Drive-R1 presents a promising direction for bridging
reasoning and planning in AD, offering methodological insights for future
research and applications.

</details>


### [229] [Referring Expression Instance Retrieval and A Strong End-to-End Baseline](https://arxiv.org/abs/2506.18246)
*Xiangzhao Hao,Kuan Zhu,Hongyu Guo,Haiyun Guo,Ming Tang,JinQiao Wang*

Main category: cs.CV

TL;DR: 论文提出了一种新任务REIR（Referring Expression Instance Retrieval），结合实例级检索和定位，并构建了REIRCOCO基准和基线方法CLARE。


<details>
  <summary>Details</summary>
Motivation: 现有任务TIR和REC分别缺乏精确性和可扩展性，无法满足现实场景中实例级检索和定位的需求。

Method: 提出CLARE方法，采用双流架构和MORE模块，结合目标检测、REC预训练和CLIA进行端到端优化。

Result: CLARE在REIR任务上表现优异，同时在TIR和REC任务上也有良好泛化能力。

Conclusion: REIR任务和CLARE方法有效填补了现有技术的空白，具有实际应用潜力。

Abstract: Natural language querying of visual content underpins many vision-language
tasks, typically categorized by text granularity and visual search scope.
Text-Image Retrieval (TIR) retrieves whole images using coarse descriptions,
while Referring Expression Comprehension (REC) localizes objects using
fine-grained expressions within a single image. However, real-world scenarios
often require both instance-level retrieval and localization across large
galleries -- tasks where TIR lacks precision and REC lacks scalability. To
address this gap, we propose a new task: Referring Expression Instance
Retrieval (REIR), which jointly supports instance-level retrieval and
localization. We introduce REIRCOCO, a large-scale benchmark constructed by
prompting vision-language models to generate fine-grained expressions for
MSCOCO and RefCOCO instances. We also present a baseline method, CLARE,
featuring a dual-stream architecture with a Mix of Relation Experts (MORE)
module for capturing inter-instance relationships. CLARE integrates object
detection and REC pretraining with Contrastive Language-Instance Alignment
(CLIA) for end-to-end optimization. Experiments show that CLARE achieves
state-of-the-art performance on REIR and generalizes well to TIR and REC,
highlighting its effectiveness and versatility.

</details>


### [230] [Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability](https://arxiv.org/abs/2506.18248)
*Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon*

Main category: cs.CV

TL;DR: 提出了一种基于Mean Teacher的语义结构感知攻击框架，通过特征蒸馏增强对抗性扰动的语义一致性，显著提升了对抗迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有生成对抗攻击方法未充分利用生成模型的语义信息，限制了扰动与目标显著区域的对齐，从而影响了对抗迁移性。

Method: 采用Mean Teacher作为时间平滑特征参考，通过特征蒸馏指导学生与教师的早期层激活语义一致性，并基于经验发现锚定生成器的语义显著中间块。

Result: 实验表明，该方法在多种模型、领域和任务中均优于现有生成对抗攻击方法，并通过新提出的ACR指标全面评估。

Conclusion: 该方法通过增强语义一致性，显著提升了对抗扰动的迁移性，为生成对抗攻击提供了新思路。

Abstract: Generative adversarial attacks train a perturbation generator on a white-box
surrogate model and subsequently apply the crafted perturbations to unseen
black-box victim models. In contrast to iterative attacks, these methods
deliver superior inference-time efficiency, scalability, and transferability;
however, up until now, existing studies have not fully exploited the
representational capacity of generative models to preserve and harness semantic
information. Specifically, the intermediate activations of the generator encode
rich semantic features--object boundaries and coarse shapes--that remain
under-exploited, thereby limiting the alignment of perturbations with
object-salient regions which are critical for adversarial transferability. To
remedy this, we introduce a semantic structure-aware attack framework based on
the Mean Teacher, which serves as a temporally smoothed feature reference. With
this smoothed reference, we further direct semantic consistency between the
early-layer activations in the student and those of the semantically rich
teacher by feature distillation. By anchoring perturbation synthesis to the
semantically salient early intermediate blocks within the generator based on
empirical findings, our method guides progressive adversarial perturbation on
regions that substantially enhance adversarial transferability. We conduct
extensive experiments over diverse models, domains and tasks to demonstrate
consistent improvements relative to state-of-the-art generative attacks,
comprehensively evaluated using conventional metrics and our newly proposed
Accidental Correction Rate (ACR).

</details>


### [231] [Improving Weakly Supervised Temporal Action Localization by Exploiting Multi-resolution Information in Temporal Domain](https://arxiv.org/abs/2506.18261)
*Rui Su,Dong Xu,Luping Zhou,Wanli Ouyang*

Main category: cs.CV

TL;DR: 提出了一种两阶段方法，利用多分辨率信息生成高质量帧级伪标签，以解决弱监督时序动作定位问题。


<details>
  <summary>Details</summary>
Motivation: 弱监督时序动作定位任务中仅有视频级标注可用，需要充分利用时序信息提高定位性能。

Method: 第一阶段通过初始标签生成模块（ILG）生成可靠伪标签；第二阶段通过渐进时序标签细化框架（PTLR）迭代优化伪标签。

Result: 通过多分辨率信息交换和伪标签优化，提高了时序动作定位的性能。

Conclusion: 两阶段方法有效利用多分辨率信息，显著提升了弱监督时序动作定位的效果。

Abstract: Weakly supervised temporal action localization is a challenging task as only
the video-level annotation is available during the training process. To address
this problem, we propose a two-stage approach to fully exploit multi-resolution
information in the temporal domain and generate high quality frame-level pseudo
labels based on both appearance and motion streams. Specifically, in the first
stage, we generate reliable initial frame-level pseudo labels, and in the
second stage, we iteratively refine the pseudo labels and use a set of selected
frames with highly confident pseudo labels to train neural networks and better
predict action class scores at each frame. We fully exploit temporal
information at multiple scales to improve temporal action localization
performance. Specifically, in order to obtain reliable initial frame-level
pseudo labels, in the first stage, we propose an Initial Label Generation (ILG)
module, which leverages temporal multi-resolution consistency to generate high
quality class activation sequences (CASs), which consist of a number of
sequences with each sequence measuring how likely each video frame belongs to
one specific action class. In the second stage, we propose a Progressive
Temporal Label Refinement (PTLR) framework. In our PTLR framework, two networks
called Network-OTS and Network-RTS, which are respectively used to generate
CASs for the original temporal scale and the reduced temporal scales, are used
as two streams (i.e., the OTS stream and the RTS stream) to refine the pseudo
labels in turn. By this way, the multi-resolution information in the temporal
domain is exchanged at the pseudo label level, and our work can help improve
each stream (i.e., the OTS/RTS stream) by exploiting the refined pseudo labels
from another stream (i.e., the RTS/OTS stream).

</details>


### [232] [YouTube-Occ: Learning Indoor 3D Semantic Occupancy Prediction from YouTube Videos](https://arxiv.org/abs/2506.18266)
*Haoming Chen,Lichen Yuan,TianFang Sun,Jingyu Gong,Xin Tan,Zhizhong Zhang,Yuan Xie*

Main category: cs.CV

TL;DR: 论文提出了一种无需相机参数的自监督方法，利用室内网络数据（YouTube-Occ数据集）实现3D语义占用预测，并在NYUv2和OccScanNet上取得零样本SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 复杂室内环境中，传统方法依赖精确几何关系和大量标注数据，但数据采集复杂且涉及隐私问题。本文探索仅用网络数据实现3D空间准确训练的可能性。

Method: 收集YouTube房屋游览视频构建YouTube-Occ数据集，通过自监督模型利用2D先验知识（如视觉基础模型和超像素分组）训练3D占用网络。

Result: 在NYUv2和OccScanNet基准上实现了零样本SOTA性能。

Conclusion: 仅用网络数据即可实现高效3D语义占用预测，无需相机参数或复杂标注。

Abstract: 3D semantic occupancy prediction in the past was considered to require
precise geometric relationships in order to enable effective training. However,
in complex indoor environments, the large-scale and widespread collection of
data, along with the necessity for fine-grained annotations, becomes
impractical due to the complexity of data acquisition setups and privacy
concerns. In this paper, we demonstrate that 3D spatially-accurate training can
be achieved using only indoor Internet data, without the need for any
pre-knowledge of intrinsic or extrinsic camera parameters. In our framework, we
collect a web dataset, YouTube-Occ, which comprises house tour videos from
YouTube, providing abundant real house scenes for 3D representation learning.
Upon on this web dataset, we establish a fully self-supervised model to
leverage accessible 2D prior knowledge for reaching powerful 3D indoor
perception. Specifically, we harness the advantages of the prosperous vision
foundation models, distilling the 2D region-level knowledge into the occupancy
network by grouping the similar pixels into superpixels. Experimental results
show that our method achieves state-of-the-art zero-shot performance on two
popular benchmarks (NYUv2 and OccScanNet

</details>


### [233] [OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871)
*Chenyuan Wu,Pengfei Zheng,Ruiran Yan,Shitao Xiao,Xin Luo,Yueze Wang,Wanli Li,Xiyan Jiang,Yexin Liu,Junjie Zhou,Ze Liu,Ziyi Xia,Chaofan Li,Haoge Deng,Jiahao Wang,Kun Luo,Bo Zhang,Defu Lian,Xinlong Wang,Zhongyuan Wang,Tiejun Huang,Zheng Liu*

Main category: cs.CV

TL;DR: OmniGen2是一个开源生成模型，支持文本到图像、图像编辑和上下文生成任务，通过分离的解码路径和反射机制实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 提供统一的生成解决方案，同时保留文本生成能力，无需重新适应VAE输入。

Method: 采用分离的文本和图像解码路径，使用未共享参数和解耦的图像标记器，并引入反射机制和专用数据集。

Result: 在多个任务基准测试中表现优异，尤其在上下文生成任务中达到开源模型的最先进水平。

Conclusion: OmniGen2是一个高效且多功能的生成模型，其开源资源将推动未来研究。

Abstract: In this work, we introduce OmniGen2, a versatile and open-source generative
model designed to provide a unified solution for diverse generation tasks,
including text-to-image, image editing, and in-context generation. Unlike
OmniGen v1, OmniGen2 features two distinct decoding pathways for text and image
modalities, utilizing unshared parameters and a decoupled image tokenizer. This
design enables OmniGen2 to build upon existing multimodal understanding models
without the need to re-adapt VAE inputs, thereby preserving the original text
generation capabilities. To facilitate the training of OmniGen2, we developed
comprehensive data construction pipelines, encompassing image editing and
in-context generation data. Additionally, we introduce a reflection mechanism
tailored for image generation tasks and curate a dedicated reflection dataset
based on OmniGen2. Despite its relatively modest parameter size, OmniGen2
achieves competitive results on multiple task benchmarks, including
text-to-image and image editing. To further evaluate in-context generation,
also referred to as subject-driven tasks, we introduce a new benchmark named
OmniContext. OmniGen2 achieves state-of-the-art performance among open-source
models in terms of consistency. We will release our models, training code,
datasets, and data construction pipeline to support future research in this
field. Project Page: https://vectorspacelab.github.io/OmniGen2; GitHub Link:
https://github.com/VectorSpaceLab/OmniGen2

</details>


### [234] [ThermalLoc: A Vision Transformer-Based Approach for Robust Thermal Camera Relocalization in Large-Scale Environments](https://arxiv.org/abs/2506.18268)
*Yu Liu,Yangtao Meng,Xianfei Pan,Jie Jiang,Changhao Chen*

Main category: cs.CV

TL;DR: ThermalLoc是一种专为热图像设计的端到端深度学习重定位方法，结合EfficientNet和Transformers提取特征，并通过MLP网络进行绝对位姿回归，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于可见光图像的视觉重定位方法不适用于热图像，而针对热相机重定位的深度学习方法研究不足。

Method: ThermalLoc整合EfficientNet和Transformers提取热图像的局部和全局特征，使用两个MLP网络进行绝对位姿回归。

Result: 在公开数据集和自建数据集上，ThermalLoc的准确性和鲁棒性优于AtLoc、MapNet、PoseNet和RobustLoc等现有方法。

Conclusion: ThermalLoc填补了热图像重定位领域的空白，表现出卓越的性能。

Abstract: Thermal cameras capture environmental data through heat emission, a
fundamentally different mechanism compared to visible light cameras, which rely
on pinhole imaging. As a result, traditional visual relocalization methods
designed for visible light images are not directly applicable to thermal
images. Despite significant advancements in deep learning for camera
relocalization, approaches specifically tailored for thermal camera-based
relocalization remain underexplored. To address this gap, we introduce
ThermalLoc, a novel end-to-end deep learning method for thermal image
relocalization. ThermalLoc effectively extracts both local and global features
from thermal images by integrating EfficientNet with Transformers, and performs
absolute pose regression using two MLP networks. We evaluated ThermalLoc on
both the publicly available thermal-odometry dataset and our own dataset. The
results demonstrate that ThermalLoc outperforms existing representative methods
employed for thermal camera relocalization, including AtLoc, MapNet, PoseNet,
and RobustLoc, achieving superior accuracy and robustness.

</details>


### [235] [Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations](https://arxiv.org/abs/2506.18898)
*Jiaming Han,Hao Chen,Yang Zhao,Hanyu Wang,Qi Zhao,Ziyan Yang,Hao He,Xiangyu Yue,Lu Jiang*

Main category: cs.CV

TL;DR: 本文提出了一种多模态框架Tar，通过共享的离散语义表示统一视觉理解和生成，核心是文本对齐的分词器（TA-Tok），将图像转换为离散标记，并利用扩展词汇表实现跨模态输入输出。


<details>
  <summary>Details</summary>
Motivation: 旨在通过统一的表示空间简化多模态任务，避免模态特定设计，同时平衡效率和视觉细节。

Method: 采用文本对齐的分词器（TA-Tok）和扩展词汇表，结合尺度自适应编码解码和生成式去分词器，使用自回归和扩散模型进行多样化解码。

Result: Tar在多项基准测试中表现优于现有方法，收敛更快且训练效率更高。

Conclusion: Tar框架成功统一了视觉理解和生成，为多模态任务提供了高效且灵活的解决方案。

Abstract: This paper presents a multimodal framework that attempts to unify visual
understanding and generation within a shared discrete semantic representation.
At its core is the Text-Aligned Tokenizer (TA-Tok), which converts images into
discrete tokens using a text-aligned codebook projected from a large language
model's (LLM) vocabulary. By integrating vision and text into a unified space
with an expanded vocabulary, our multimodal LLM, Tar, enables cross-modal input
and output through a shared interface, without the need for modality-specific
designs. Additionally, we propose scale-adaptive encoding and decoding to
balance efficiency and visual detail, along with a generative de-tokenizer to
produce high-fidelity visual outputs. To address diverse decoding needs, we
utilize two complementary de-tokenizers: a fast autoregressive model and a
diffusion-based model. To enhance modality fusion, we investigate advanced
pre-training tasks, demonstrating improvements in both visual understanding and
generation. Experiments across benchmarks show that Tar matches or surpasses
existing multimodal LLM methods, achieving faster convergence and greater
training efficiency. Code, models, and data are available at
https://tar.csuhan.com

</details>


### [236] [Adaptive Mask-guided K-space Diffusion for Accelerated MRI Reconstruction](https://arxiv.org/abs/2506.18270)
*Qinrong Cai,Yu Guan,Zhibo Chen,Dong Liang,Qiuyun Fan,Qiegen Liu*

Main category: cs.CV

TL;DR: 论文提出了一种基于自适应掩码的扩散模型（AMDM），用于MRI重建，通过自适应调整k空间数据的频率分布，有效分离高低频成分，提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统MRI重建方法未充分考虑k空间中不同频率区域的重要性，导致重建效果受限。

Method: 采用自适应掩码机制，根据k空间数据的频率分布生成动态掩码，指导扩散过程，分离高低频成分。

Result: 实验证明该方法能有效学习特定频率信息，显著提升MRI重建质量。

Conclusion: AMDM为未来基于掩码的k空间数据优化提供了灵活框架。

Abstract: As the deep learning revolution marches on, masked modeling has emerged as a
distinctive approach that involves predicting parts of the original data that
are proportionally masked during training, and has demonstrated exceptional
performance in multiple fields. Magnetic Resonance Imaging (MRI) reconstruction
is a critical task in medical imaging that seeks to recover high-quality images
from under-sampled k-space data. However, previous MRI reconstruction
strategies usually optimized the entire image domain or k-space, without
considering the importance of different frequency regions in the k-space This
work introduces a diffusion model based on adaptive masks (AMDM), which
utilizes the adaptive adjustment of frequency distribution based on k-space
data to develop a hybrid masks mechanism that adapts to different k-space
inputs. This enables the effective separation of high-frequency and
low-frequency components, producing diverse frequency-specific representations.
Additionally, the k-space frequency distribution informs the generation of
adaptive masks, which, in turn, guide a closed-loop diffusion process.
Experimental results verified the ability of this method to learn specific
frequency information and thereby improved the quality of MRI reconstruction,
providing a flexible framework for optimizing k-space data using masks in the
future.

</details>


### [237] [ReFrame: Rectification Framework for Image Explaining Architectures](https://arxiv.org/abs/2506.18272)
*Debjyoti Das Adhikary,Aritra Hazra,Partha Pratim Chakrabarti*

Main category: cs.CV

TL;DR: 本文提出了一种可解释的框架，用于改进图像解释中的不一致性和不完整性，显著提升了图像描述、视觉问答和基于提示的AI模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图像解释方法常存在幻觉对象或遗漏对象的问题，本文旨在解决这些不一致性和不完整性问题。

Method: 提出了一种可解释的框架，可集成到多种图像解释框架（如图像描述、视觉问答和基于提示的AI）中，以纠正错误或缺失的对象。

Result: 实验表明，该框架显著提升了图像描述的完整性（81.81%）和不一致性（37.10%），视觉问答（平均9.6%和37.10%）和基于提示的AI模型（0.01%和5.2%）的性能。

Conclusion: 提出的框架有效解决了图像解释中的不一致性和不完整性问题，显著优于现有方法。

Abstract: Image explanation has been one of the key research interests in the Deep
Learning field. Throughout the years, several approaches have been adopted to
explain an input image fed by the user. From detecting an object in a given
image to explaining it in human understandable sentence, to having a
conversation describing the image, this problem has seen an immense change
throughout the years, However, the existing works have been often found to (a)
hallucinate objects that do not exist in the image and/or (b) lack identifying
the complete set of objects present in the image. In this paper, we propose a
novel approach to mitigate these drawbacks of inconsistency and incompleteness
of the objects recognized during the image explanation. To enable this, we
propose an interpretable framework that can be plugged atop diverse image
explaining frameworks including Image Captioning, Visual Question Answering
(VQA) and Prompt-based AI using LLMs, thereby enhancing their explanation
capabilities by rectifying the incorrect or missing objects. We further measure
the efficacy of the rectified explanations generated through our proposed
approaches leveraging object based precision metrics, and showcase the
improvements in the inconsistency and completeness of image explanations.
Quantitatively, the proposed framework is able to improve the explanations over
the baseline architectures of Image Captioning (improving the completeness by
81.81% and inconsistency by 37.10%), Visual Question Answering(average of 9.6%
and 37.10% in completeness and inconsistency respectively) and Prompt-based AI
model (0.01% and 5.2% for completeness and inconsistency respectively)
surpassing the current state-of-the-art by a substantial margin.

</details>


### [238] [Open Set Recognition for Endoscopic Image Classification: A Deep Learning Approach on the Kvasir Dataset](https://arxiv.org/abs/2506.18284)
*Kasra Moazzami,Seoyoun Son,John Lin,Sun Min Lee,Daniel Son,Hayeon Lee,Jeongho Lee,Seongji Lee*

Main category: cs.CV

TL;DR: 论文探讨了在开放世界临床环境中应用开放集识别（OSR）技术于内窥镜图像分类，评估了多种深度学习架构在Kvasir数据集上的表现。


<details>
  <summary>Details</summary>
Motivation: 传统封闭集分类框架在临床开放环境中存在局限性，无法处理未知类别，影响模型可靠性。

Method: 研究采用ResNet-50、Swin Transformer和混合ResNet-Transformer模型，结合OpenMax作为基线OSR方法，评估其在封闭集和开放集条件下的表现。

Result: 研究为医学图像分析中的OSR性能提供了基准，并展示了模型在临床实际环境中的行为。

Conclusion: OSR技术对安全部署内窥镜AI系统至关重要，研究为未来工作奠定了基础。

Abstract: Endoscopic image classification plays a pivotal role in medical diagnostics
by identifying anatomical landmarks and pathological findings. However,
conventional closed-set classification frameworks are inherently limited in
open-world clinical settings, where previously unseen conditions can arise
andcompromise model reliability. To address this, we explore the application of
Open Set Recognition (OSR) techniques on the Kvasir dataset, a publicly
available and diverse endoscopic image collection. In this study, we evaluate
and compare the OSR capabilities of several representative deep learning
architectures, including ResNet-50, Swin Transformer, and a hybrid
ResNet-Transformer model, under both closed-set and open-set conditions.
OpenMax is adopted as a baseline OSR method to assess the ability of these
models to distinguish known classes from previously unseen categories. This
work represents one of the first efforts to apply open set recognition to the
Kvasir dataset and provides a foundational benchmark for evaluating OSR
performance in medical image analysis. Our results offer practical insights
into model behavior in clinically realistic settings and highlight the
importance of OSR techniques for the safe deployment of AI systems in
endoscopy.

</details>


### [239] [Selective Social-Interaction via Individual Importance for Fast Human Trajectory Prediction](https://arxiv.org/abs/2506.18291)
*Yota Urano,Hiromu Taketsugu,Norimichi Ukita*

Main category: cs.CV

TL;DR: 提出了一种通过选择重要邻居预测主人物轨迹的架构，使用重要性估计器和Gumbel Softmax解决梯度阻塞问题，实验显示方法快速且准确。


<details>
  <summary>Details</summary>
Motivation: 预测主人物轨迹时，选择重要邻居是关键，但传统方法可能因非可微操作导致梯度阻塞。

Method: 提出重要性估计器模块选择邻居，并使用Gumbel Softmax解决训练中的梯度问题。

Result: 在JRDB数据集上实验，方法在速度和预测准确性上表现优异。

Conclusion: 该方法通过有效选择邻居并解决梯度问题，实现了高效且准确的轨迹预测。

Abstract: This paper presents an architecture for selecting important neighboring
people to predict the primary person's trajectory. To achieve effective
neighboring people selection, we propose a people selection module called the
Importance Estimator which outputs the importance of each neighboring person
for predicting the primary person's future trajectory. To prevent gradients
from being blocked by non-differentiable operations when sampling surrounding
people based on their importance, we employ the Gumbel Softmax for training.
Experiments conducted on the JRDB dataset show that our method speeds up the
process with competitive prediction accuracy.

</details>


### [240] [Rapeseed population point cloud completion network (RP-PCN) with dynamic graph convolution for 3D reconstruction of crop canopy occlusion architecture](https://arxiv.org/abs/2506.18292)
*Ziyue Guo,Xin Yang,Yutao Shen,Yang Zhu,Lixi Jiang,Haiyan Cen*

Main category: cs.CV

TL;DR: 提出了一种基于多视角成像的油菜群体点云补全模型（RP-PCN），用于从苗期到角果期的三维重建，显著提高了群体冠层结构的分析精度和产量预测能力。


<details>
  <summary>Details</summary>
Motivation: 完整的冠层结构定量描述对评估作物光合作用和产量至关重要，但现有技术因遮挡和复杂结构难以实现准确重建。

Method: 开发了点云补全框架，结合虚拟-真实集成（VRI）模拟方法和遮挡点检测算法，设计了RP-PCN网络，包含多分辨率动态图卷积编码器（MRDG）和点金字塔解码器（PPD）。

Result: RP-PCN在苗期、抽薹期、花期和角果期的CD值分别为3.35 cm、3.46 cm、4.32 cm和4.51 cm，MRDG和DGCFE模块分别降低CD值10%和23%，SEI指标将产量预测精度提高11.2%。

Conclusion: RP-PCN可推广至其他作物，显著提升田间群体冠层结构的分析能力。

Abstract: Quantitative descriptions of complete canopy architecture are crucial for
evaluating crop photosynthesis and yield to guide ideotype design. Although
three-dimensional (3D) sensing technologies have been developed for plant and
canopy reconstruction, severe occlusion and complex architectures hinder
accurate canopy descriptions. In this study, we propose a point cloud
completion model for 3D reconstruction of rapeseed populations from seeding to
silique stages using multi-view imaging. A complete point cloud generation
framework was developed with the virtual-real integration (VRI) simulation
method and occlusion point detection algorithm to annotate the training dataset
by distinguishing surface from occluded points. The rapeseed population point
cloud completion network (RP-PCN) was designed with a multi-resolution dynamic
graph convolutional encoder (MRDG) and point pyramid decoder (PPD) to predict
occluded points based on input surface point clouds. A dynamic graph
convolutional feature extractor (DGCFE) was introduced to capture structural
variations across the growth period. The effectiveness of point cloud
completion was validated by predicting yield using architectural indicators
from complete point clouds of rapeseed population. The results demonstrated
that RP-PCN achieved chamfer distance (CD) values of 3.35 cm, 3.46 cm, 4.32 cm,
and 4.51 cm at the seedling, bolting, flowering, and silique stages,
respectively. Ablation studies showed the effectiveness of the MRDG and DGCFE
modules, reducing CD values by 10% and 23%, respectively. The silique
efficiency index (SEI) from RP-PCN improved yield prediction accuracy by 11.2%
compared to incomplete point clouds. The RP-PCN pipeline proposed in this study
has the potential to be extended to other crops, significantly enhancing the
analysis of population canopy architectures in field environments.

</details>


### [241] [Attention-Based Ensemble Learning for Crop Classification Using Landsat 8-9 Fusion](https://arxiv.org/abs/2506.18321)
*Zeeshan Ramzan,Nisar Ahmed,Qurat-ul-Ain Akram,Shahzad Asif,Muhammad Shahbaz,Rabin Chakrabortty,Ahmed F. Elaksher*

Main category: cs.CV

TL;DR: 该研究利用遥感技术和先进建模方法，结合实地调查和卫星影像，提高了巴基斯坦旁遮普中部灌溉区作物分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 通过遥感技术获取准确的作物种植面积和类型信息，以支持灌溉农业区的精准管理。

Method: 研究分为两个阶段：实地调查和卫星影像采集。影像经过预处理、融合和增强，提取植被指数，并利用多种分类模型进行作物分类。

Result: 构建了包含50,835个数据点的数据集，结合植被指数和反射率值，显著提高了作物分类的准确性。

Conclusion: 研究表明，遥感数据与先进建模技术的结合，可有效提升灌溉农业区的作物分类精度。

Abstract: Remote sensing offers a highly effective method for obtaining accurate
information on total cropped area and crop types. The study focuses on crop
cover identification for irrigated regions of Central Punjab. Data collection
was executed in two stages: the first involved identifying and geocoding six
target crops through field surveys conducted in January and February 2023. The
second stage involved acquiring Landsat 8-9 imagery for each geocoded field to
construct a labelled dataset. The satellite imagery underwent extensive
pre-processing, including radiometric calibration for reflectance values,
atmospheric correction, and georeferencing verification to ensure consistency
within a common coordinate system. Subsequently, image fusion techniques were
applied to combine Landsat 8 and 9 spectral bands, creating a composite image
with enhanced spectral information, followed by contrast enhancement. During
data acquisition, farmers were interviewed, and fields were meticulously mapped
using GPS instruments, resulting in a comprehensive dataset of 50,835 data
points. This dataset facilitated the extraction of vegetation indices such as
NDVI, SAVO, RECI, and NDRE. These indices and raw reflectance values were
utilized for classification modeling using conventional classifiers, ensemble
learning, and artificial neural networks. A feature selection approach was also
incorporated to identify the optimal feature set for classification learning.
This study demonstrates the effectiveness of combining remote sensing data and
advanced modeling techniques to improve crop classification accuracy in
irrigated agricultural regions.

</details>


### [242] [Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?](https://arxiv.org/abs/2506.18322)
*Yiwei Yang,Chung Peng Lee,Shangbin Feng,Dora Zhao,Bingbing Wen,Anthony Z. Liu,Yulia Tsvetkov,Bill Howe*

Main category: cs.CV

TL;DR: 论文提出了SpuriVerse基准，用于研究多模态大视觉语言模型（LVLMs）中的虚假相关性，发现现有模型在此基准上表现不佳，但通过针对虚假相关性的微调可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究多模态大视觉语言模型中由预训练数据引入的虚假相关性，避免其在任务中产生误导。

Method: 通过GPT-4o的错误分析构建SpuriVerse基准，包含124种虚假相关性类型，共1364个多选问题，评估15种LVLMs的性能。

Result: 现有模型在SpuriVerse上表现较差（最高37.1%准确率），但微调后性能提升至78.40%。

Conclusion: 通过针对虚假相关性的多样化训练，模型能更好地避免依赖“捷径”并关注整体图像上下文。

Abstract: Finetuning can cause spurious correlations to arise between non-essential
features and the target labels, but benchmarks to study these effects involve
contrived settings and narrow tasks. In contrast, we consider spurious
correlations in multi-modal Large Vision Language Models (LVLMs) pretrained on
extensive and diverse datasets without explicit task supervision. We develop a
benchmark by sourcing GPT-4o errors on real-world visual-question-answering
(VQA) benchmarks, then curating a subset through LVLM-human annotation and
synthetic counterfactual evaluation to identify errors caused by spurious
correlations. This process yields SpuriVerse, a novel benchmark comprised of
124 distinct types of spurious correlations extracted from real-world datasets,
each containing 1 realistic and 10 synthetic VQA samples for a total of 1364
multiple choice questions. We evaluate 15 open and closed-source LVLMs on
SpuriVerse, finding that even state-of-the-art closed-source models struggle
significantly, achieving at best only 37.1% accuracy. Fine-tuning on synthetic
examples that emphasize the spurious correlation improves performance to
78.40%, suggesting that training on diverse spurious patterns generalizes to
unseen situations: models appear to learn to avoid "shortcuts" and attend to
the overall image context.

</details>


### [243] [A Multi-Scale Spatial Attention-Based Zero-Shot Learning Framework for Low-Light Image Enhancement](https://arxiv.org/abs/2506.18323)
*Muhammad Azeem Aslam,Hassan Khalid,Nisar Ahmed*

Main category: cs.CV

TL;DR: LucentVisionNet是一种新型零样本学习框架，通过多尺度空间注意力和深度曲线估计网络实现低光图像增强，无需配对数据。


<details>
  <summary>Details</summary>
Motivation: 解决传统和深度学习方法在低光图像增强中的局限性，特别是在缺乏配对训练数据时。

Method: 结合多尺度空间注意力与深度曲线估计网络，采用循环增强策略和复合损失函数优化。

Result: 在多个基准数据集上优于现有监督、无监督和零样本方法，实现高质量、结构一致性和计算效率。

Conclusion: LucentVisionNet适用于移动摄影、监控和自主导航等实际应用。

Abstract: Low-light image enhancement remains a challenging task, particularly in the
absence of paired training data. In this study, we present LucentVisionNet, a
novel zero-shot learning framework that addresses the limitations of
traditional and deep learning-based enhancement methods. The proposed approach
integrates multi-scale spatial attention with a deep curve estimation network,
enabling fine-grained enhancement while preserving semantic and perceptual
fidelity. To further improve generalization, we adopt a recurrent enhancement
strategy and optimize the model using a composite loss function comprising six
tailored components, including a novel no-reference image quality loss inspired
by human visual perception. Extensive experiments on both paired and unpaired
benchmark datasets demonstrate that LucentVisionNet consistently outperforms
state-of-the-art supervised, unsupervised, and zero-shot methods across
multiple full-reference and no-reference image quality metrics. Our framework
achieves high visual quality, structural consistency, and computational
efficiency, making it well-suited for deployment in real-world applications
such as mobile photography, surveillance, and autonomous navigation.

</details>


### [244] [NSFW-Classifier Guided Prompt Sanitization for Safe Text-to-Image Generation](https://arxiv.org/abs/2506.18325)
*Yu Xie,Chengjie Zeng,Lingyun Zhang,Yanwei Fu*

Main category: cs.CV

TL;DR: 论文提出PromptSan方法，通过NSFW分类器引导的提示净化技术，减少文本到图像模型生成有害内容的风险。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像模型的快速发展，其生成有害内容的风险增加，阻碍了技术的可持续发展。

Method: PromptSan包括两种变体：PromptSan-Modify（迭代替换有害标记）和PromptSan-Suffix（训练优化的后缀标记序列）。

Result: 实验表明，PromptSan在减少有害内容生成方面表现优异，平衡了安全性与可用性。

Conclusion: PromptSan为文本到图像模型提供了一种有效的安全防护方法。

Abstract: The rapid advancement of text-to-image (T2I) models, such as Stable
Diffusion, has enhanced their capability to synthesize images from textual
prompts. However, this progress also raises significant risks of misuse,
including the generation of harmful content (e.g., pornography, violence,
discrimination), which contradicts the ethical goals of T2I technology and
hinders its sustainable development. Inspired by "jailbreak" attacks in large
language models, which bypass restrictions through subtle prompt modifications,
this paper proposes NSFW-Classifier Guided Prompt Sanitization (PromptSan), a
novel approach to detoxify harmful prompts without altering model architecture
or degrading generation capability. PromptSan includes two variants:
PromptSan-Modify, which iteratively identifies and replaces harmful tokens in
input prompts using text NSFW classifiers during inference, and
PromptSan-Suffix, which trains an optimized suffix token sequence to neutralize
harmful intent while passing both text and image NSFW classifier checks.
Extensive experiments demonstrate that PromptSan achieves state-of-the-art
performance in reducing harmful content generation across multiple metrics,
effectively balancing safety and usability.

</details>


### [245] [Geometry-Aware Preference Learning for 3D Texture Generation](https://arxiv.org/abs/2506.18331)
*AmirHossein Zamani,Tianhao Xie,Amir G. Aghdam,Tiberiu Popa,Eugene Belilovsky*

Main category: cs.CV

TL;DR: 提出了一种端到端的可微分偏好学习框架，通过几何感知奖励函数优化3D生成模型，使其更符合人类主观偏好和任务需求。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成模型生成的内容可能不符合人类主观偏好或任务需求，且依赖2D文本到图像模型，缺乏对3D结构的理解。

Method: 提出了一种端到端的可微分偏好学习框架，通过几何感知奖励函数反向传播人类偏好，优化3D生成流程。

Result: 通过四种几何感知奖励函数验证了框架的有效性，实现了更可控和可解释的高质量3D内容生成。

Conclusion: 该框架为基于自然语言的高质量3D内容生成提供了更可控和可解释的途径。

Abstract: Recent advances in 3D generative models have achieved impressive results but
3D contents generated by these models may not align with subjective human
preferences or task-specific criteria. Moreover, a core challenge in the 3D
texture generation domain remains: most existing approaches rely on repeated
calls to 2D text-to-image generative models, which lack an inherent
understanding of the 3D structure of the input 3D mesh object. To address this,
we propose an end-to-end differentiable preference learning framework that
back-propagates human preferences, represented by differentiable reward
functions, through the entire 3D generative pipeline, making the process
inherently geometry-aware. We demonstrate the effectiveness of our framework
using four proposed novel geometry-aware reward functions, offering a more
controllable and interpretable pathway for high-quality 3D content creation
from natural language.

</details>


### [246] [Rethinking Decoder Design: Improving Biomarker Segmentation Using Depth-to-Space Restoration and Residual Linear Attention](https://arxiv.org/abs/2506.18335)
*Saad Wazir,Daeyoung Kim*

Main category: cs.CV

TL;DR: 提出了一种新的医学图像分割方法，通过多尺度特征捕获和高效解码器设计，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中，现有Transformer和CNN方法在染色和形态变化下特征提取受限，且端到端方法在样本有限时表现不佳。

Method: 提出一种架构，捕获多尺度局部和全局上下文信息，并设计新型解码器，有效整合编码器特征，强调重要通道和区域，重建空间维度。

Result: 在四个数据集上优于现有SOTA方法，性能提升分别为MoNuSeg 2.76%、DSB 3.12%、Electron Microscopy 2.87%、TNBC 4.03%。

Conclusion: 该方法兼容多种编码器，显著提升分割精度，为医学图像分割提供了有效解决方案。

Abstract: Segmenting biomarkers in medical images is crucial for various biotech
applications. Despite advances, Transformer and CNN based methods often
struggle with variations in staining and morphology, limiting feature
extraction. In medical image segmentation, where datasets often have limited
sample availability, recent state-of-the-art (SOTA) methods achieve higher
accuracy by leveraging pre-trained encoders, whereas end-to-end methods tend to
underperform. This is due to challenges in effectively transferring rich
multiscale features from encoders to decoders, as well as limitations in
decoder efficiency. To address these issues, we propose an architecture that
captures multi-scale local and global contextual information and a novel
decoder design, which effectively integrates features from the encoder,
emphasizes important channels and regions, and reconstructs spatial dimensions
to enhance segmentation accuracy. Our method, compatible with various encoders,
outperforms SOTA methods, as demonstrated by experiments on four datasets and
ablation studies. Specifically, our method achieves absolute performance gains
of 2.76% on MoNuSeg, 3.12% on DSB, 2.87% on Electron Microscopy, and 4.03% on
TNBC datasets compared to existing SOTA methods. Code:
https://github.com/saadwazir/MCADS-Decoder

</details>


### [247] [BSMamba: Brightness and Semantic Modeling for Long-Range Interaction in Low-Light Image Enhancement](https://arxiv.org/abs/2506.18346)
*Tongshun Zhang,Pingping Liu,Mengen Cai,Zijian Zhang,Yubing Lu,Qiuzhan Zhou*

Main category: cs.CV

TL;DR: BSMamba是一种新型视觉Mamba架构，通过亮度Mamba和语义Mamba组件，解决了低光图像增强中亮度恢复和语义一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法在提升亮度的同时难以保持语义一致性和细节，且视觉Mamba模型因固定扫描规则限制了长距离依赖的捕捉。

Method: 提出BSMamba，包含亮度Mamba（基于亮度相似性连接远距离标记）和语义Mamba（基于语义相似性连接标记），改进标记交互模式。

Result: 实验表明BSMamba在低光图像增强任务中达到最优性能，并保持语义一致性。

Conclusion: BSMamba通过亮度与语义引导的标记建模，克服了传统方法的限制，实现了高效且语义一致的低光图像增强。

Abstract: Current low-light image enhancement (LLIE) methods face significant
limitations in simultaneously improving brightness while preserving semantic
consistency, fine details, and computational efficiency. With the emergence of
state-space models, particularly Mamba, image restoration has achieved
remarkable performance, yet existing visual Mamba approaches flatten 2D images
into 1D token sequences using fixed scanning rules, critically limiting
interactions between distant tokens with causal relationships and constraining
their ability to capture meaningful long-range dependencies. To address these
fundamental limitations, we propose BSMamba, a novel visual Mamba architecture
comprising two specially designed components: Brightness Mamba and Semantic
Mamba. The Brightness Mamba revolutionizes token interaction patterns by
prioritizing connections between distant tokens with similar brightness levels,
effectively addressing the challenge of brightness restoration in LLIE tasks
through brightness-guided selective attention. Complementing this, the Semantic
Mamba establishes priority interactions between tokens sharing similar semantic
meanings, allowing the model to maintain contextual consistency by connecting
semantically related regions across the image, thus preserving the hierarchical
nature of image semantics during enhancement. By intelligently modeling tokens
based on brightness and semantic similarity rather than arbitrary scanning
patterns, BSMamba transcends the constraints of conventional token sequencing
while adhering to the principles of causal modeling. Extensive experiments
demonstrate that BSMamba achieves state-of-the-art performance in LLIE while
preserving semantic consistency.

</details>


### [248] [Spatial frequency information fusion network for few-shot learning](https://arxiv.org/abs/2506.18364)
*Wenqing Zhao,Guojia Xie,Han Pan,Biao Yang,Weichuan Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为SFIFNet的新方法，通过结合频域和空间域信息来增强图像特征表示，从而提升Few-shot学习的分类性能。


<details>
  <summary>Details</summary>
Motivation: Few-shot学习中，每类图像数量较少，容易导致过拟合和泛化性能差。现有方法多关注空间域信息，忽略了频域信息，限制了特征信息的充分利用。

Method: 基于常规数据增强，提出SFIFNet方法，创新性地结合频域和空间域信息进行数据预处理。

Result: 实验结果表明，该方法能有效提升分类性能。

Conclusion: 结合频域和空间域信息的方法在Few-shot学习中具有显著优势。

Abstract: The objective of Few-shot learning is to fully leverage the limited data
resources for exploring the latent correlations within the data by applying
algorithms and training a model with outstanding performance that can
adequately meet the demands of practical applications. In practical
applications, the number of images in each category is usually less than that
in traditional deep learning, which can lead to over-fitting and poor
generalization performance. Currently, many Few-shot classification models pay
more attention to spatial domain information while neglecting frequency domain
information, which contains more feature information. Ignoring frequency domain
information will prevent the model from fully exploiting feature information,
which would effect the classification performance. Based on conventional data
augmentation, this paper proposes an SFIFNet with innovative data
preprocessing. The key of this method is enhancing the accuracy of image
feature representation by integrating frequency domain information with spatial
domain information. The experimental results demonstrate the effectiveness of
this method in enhancing classification performance.

</details>


### [249] [Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](https://arxiv.org/abs/2506.18368)
*Anja Delić,Matej Grcić,Siniša Šegvić*

Main category: cs.CV

TL;DR: SeeKer是一种通过自回归分解关键点级骨架序列密度来检测异常人类行为的方法，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医疗监控、工作场所安全和公共监控等安全关键应用中，检测异常人类行为至关重要，异常通常表现为不寻常的人体姿势。

Method: SeeKer通过自回归分解关键点级骨架序列密度，利用条件高斯分布预测关键点位置，并通过低密度标志异常骨架。

Result: 在UBnormal、MSAD-HR和ShanghaiTech数据集上，SeeKer表现优于或与现有方法竞争。

Conclusion: SeeKer通过简单而有效的方法在异常检测任务中取得了显著成果。

Abstract: Detecting anomalous human behaviour is an important visual task in
safety-critical applications such as healthcare monitoring, workplace safety,
or public surveillance. In these contexts, abnormalities are often reflected
with unusual human poses. Thus, we propose SeeKer, a method for detecting
anomalies in sequences of human skeletons. Our method formulates the skeleton
sequence density through autoregressive factorization at the keypoint level.
The corresponding conditional distributions represent probable keypoint
locations given prior skeletal motion. We formulate the joint distribution of
the considered skeleton as causal prediction of conditional Gaussians across
its constituent keypoints. A skeleton is flagged as anomalous if its keypoint
locations surprise our model (i.e. receive a low density). In practice, our
anomaly score is a weighted sum of per-keypoint log-conditionals, where the
weights account for the confidence of the underlying keypoint detector. Despite
its conceptual simplicity, SeeKer surpasses all previous methods on the
UBnormal and MSAD-HR datasets while delivering competitive performance on the
ShanghaiTech dataset.

</details>


### [250] [RePIC: Reinforced Post-Training for Personalizing Multi-Modal Language Models](https://arxiv.org/abs/2506.18369)
*Yeongtak Oh,Jisoo Mok,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Sungroh Yoon*

Main category: cs.CV

TL;DR: 提出了一种基于强化学习的后训练框架，显著提升了多模态大语言模型在个性化图像描述任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督微调的后训练方法在复杂场景（如多概念图像描述）中表现不佳，且高质量标注数据获取成本高。

Method: 采用强化学习（RL）后训练框架，替代传统的监督微调（SFT）。

Result: 该方法显著提升了模型的视觉识别和个性化生成能力，在多概念图像描述任务中优于现有基线。

Conclusion: 强化学习后训练框架为解决数据依赖性问题提供了有效途径，为个性化图像描述任务带来了显著改进。

Abstract: Recent multi-modal large language models (MLLMs) often struggle to generate
personalized image captions, even when trained on high-quality captions. In
this work, we observe that such limitations persist in existing
post-training-based MLLM personalization methods. Specifically, despite being
post-tuned with large-scale caption data through supervised fine-tuning (SFT),
these models frequently fail to produce faithful descriptions in real-world
scenarios, such as multi-concept image captioning. However, acquiring
large-scale, high-quality captions for such complex settings is both costly and
difficult. To address the data-centric nature of SFT, we propose a
reinforcement learning (RL)-based post-training framework. To the best of our
knowledge, this is the first RL-based approach to post-train MLLMs for
personalized image captioning. Our method significantly enhances both visual
recognition and personalized generation capabilities of MLLMs, and consistently
outperforms existing SFT-based baselines, especially in the challenging
multi-concept image captioning task.

</details>


### [251] [OpenEvents V1: Large-Scale Benchmark Dataset for Multimodal Event Grounding](https://arxiv.org/abs/2506.18372)
*Hieu Nguyen,Phuc-Tan Nguyen,Thien-Phuc Tran,Minh-Quang Nguyen,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: OpenEvents V1是一个大规模基准数据集，专注于事件为中心的视觉语言理解，包含20万篇新闻文章和40万张相关图片，支持事件感知的图像描述生成和基于叙事查询的图像检索任务。


<details>
  <summary>Details</summary>
Motivation: 传统的数据集侧重于表面描述，而OpenEvents V1旨在通过上下文和时间基础，推动对复杂现实事件的深度推理。

Method: 数据集包含CNN和The Guardian的新闻文章和图片，提供基线结果和标准化评估协议。

Result: OpenEvents V1为开发能够处理复杂事件的多模态模型提供了坚实基础。

Conclusion: 该数据集为事件为中心的视觉语言理解研究提供了重要资源，并已公开可用。

Abstract: We introduce OpenEvents V1, a large-scale benchmark dataset aimed at
advancing event-centric vision-language understanding. Unlike conventional
image captioning and retrieval datasets that emphasize surface-level
descriptions, OpenEvents V1 focuses on contextual and temporal grounding
through two primary tasks: (1) generating rich, event-aware image captions and
(2) retrieving event-relevant images based on narrative-style textual queries.
The dataset contains over 200,000 news articles and 400,000 associated images
sourced from CNN and The Guardian, spanning diverse domains and time periods.
We provide extensive baseline results and standardized evaluation protocols for
both tasks. OpenEvents V1 establishes a robust foundation for developing
multimodal models capable of deep reasoning over complex real-world events. The
dataset is available at https://ltnghia.github.io/eventa/openevents-v1

</details>


### [252] [InternSpatial: A Comprehensive Dataset for Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2506.18385)
*Nianchen Deng,Lixin Gu,Shenglong Ye,Yinan He,Zhe Chen,Songze Li,Haomin Wang,Xingguang Wei,Tianshuo Yang,Min Dou,Tong He,Wenqi Shao,Kaipeng Zhang,Yi Wang,Botian Shi,Yanting Zhang,Jifeng Dai,Yu Qiao,Hongjie Zhang,Wenhai Wang*

Main category: cs.CV

TL;DR: 论文提出了InternSpatial数据集和InternSpatial-Bench基准，用于提升视觉语言模型的空间推理能力，实验显示模型性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有空间推理数据集规模小、视觉多样性不足且指令表达有限，限制了视觉语言模型的发展。

Method: 提出InternSpatial（1200万QA对）和InternSpatial-Bench基准，支持19种指令格式，并引入新的旋转角度预测任务。

Result: 模型在InternSpatial-Bench和VSI-Bench上分别提升12.1%和10.7%，同时保持通用基准的强性能。

Conclusion: InternSpatial和InternSpatial-Bench将支持空间推理能力在机器人等实际应用中的发展。

Abstract: Recent benchmarks and datasets have been proposed to improve spatial
reasoning in vision-language models (VLMs), yet existing open resources remain
limited in scale, visual diversity, and instruction expressiveness. In this
work, we introduce InternSpatial, the largest open-source dataset for spatial
reasoning in VLMs, along with InternSpatial-Bench, a corresponding evaluation
benchmark designed to assess spatial understanding under diverse instruction
formats. InternSpatial comprises 12 million QA pairs spanning both single-view
and multi-view settings, drawn from diverse visual environments and supporting
19 instruction formats that reflect varied query styles. For evaluation, we
propose InternSpatial-Bench for single-view tasks and expand multi-view
reasoning by introducing a novel rotation angle prediction task that has not
been explored in prior work. Experimental results show that models trained on
InternSpatial achieve 12.1% improvement on InternSpatial-Bench and 10.7% on
VSI-Bench, while maintaining strong performance on general-purpose benchmarks.
We hope these resources will support the development of spatially capable VLMs
in practical applications such as robotics and embodied AI.

</details>


### [253] [Distributed Poisson multi-Bernoulli filtering via generalised covariance intersection](https://arxiv.org/abs/2506.18397)
*Ángel F. García-Fernández,Giorgio Battistelli*

Main category: cs.CV

TL;DR: 论文提出了一种基于广义协方差交集（GCI）融合规则的分布式泊松多伯努利（PMB）滤波器，用于分布式多目标滤波。由于精确的GCI融合不可行，作者提出了一种近似方法，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决分布式多目标滤波中PMB密度的GCI融合问题，提出一种可行的近似方法。

Method: 通过将PMB密度的幂近似为未归一化的PMB密度，推导出GCI融合规则，最终得到闭式表达的泊松多伯努利混合（PMBM）形式。

Result: 实验结果表明，该方法优于其他分布式多目标滤波器。

Conclusion: 提出的近似方法有效解决了PMB密度的GCI融合问题，并在实验中表现出优越性能。

Abstract: This paper presents the distributed Poisson multi-Bernoulli (PMB) filter
based on the generalised covariance intersection (GCI) fusion rule for
distributed multi-object filtering. Since the exact GCI fusion of two PMB
densities is intractable, we derive a principled approximation. Specifically,
we approximate the power of a PMB density as an unnormalised PMB density, which
corresponds to an upper bound of the PMB density. Then, the GCI fusion rule
corresponds to the normalised product of two unnormalised PMB densities. We
show that the result is a Poisson multi-Bernoulli mixture (PMBM), which can be
expressed in closed form. Future prediction and update steps in each filter
preserve the PMBM form, which can be projected back to a PMB density before the
next fusion step. Experimental results show the benefits of this approach
compared to other distributed multi-object filters.

</details>


### [254] [Latent Space Analysis for Melanoma Prevention](https://arxiv.org/abs/2506.18414)
*Ciro Listone,Aniello Murano*

Main category: cs.CV

TL;DR: 提出了一种基于条件变分自编码器的可解释性皮肤病变风险建模方法，通过结构化潜在空间实现连续评估，并结合SVM分类器提高诊断性能。


<details>
  <summary>Details</summary>
Motivation: 黑色素瘤的高死亡率需要早期可解释的诊断工具，现有深度学习模型仅提供二元输出，缺乏临床洞察力。

Method: 使用条件变分自编码器学习结构化潜在空间，捕捉病变的语义关系，并结合SVM进行分类。

Result: 方法在区分良性痣和黑色素瘤上表现优异，潜在空间支持可视化和几何解释，空间接近性可作为风险指标。

Conclusion: 该方法结合预测性能和临床适用性，促进早期检测，增强AI辅助诊断的可信度。

Abstract: Melanoma represents a critical health risk due to its aggressive progression
and high mortality, underscoring the need for early, interpretable diagnostic
tools. While deep learning has advanced in skin lesion classification, most
existing models provide only binary outputs, offering limited clinical insight.
This work introduces a novel approach that extends beyond classification,
enabling interpretable risk modelling through a Conditional Variational
Autoencoder. The proposed method learns a structured latent space that captures
semantic relationships among lesions, allowing for a nuanced, continuous
assessment of morphological differences. An SVM is also trained on this
representation effectively differentiating between benign nevi and melanomas,
demonstrating strong and consistent performance. More importantly, the learned
latent space supports visual and geometric interpretation of malignancy, with
the spatial proximity of a lesion to known melanomas serving as a meaningful
indicator of risk. This approach bridges predictive performance with clinical
applicability, fostering early detection, highlighting ambiguous cases, and
enhancing trust in AI-assisted diagnosis through transparent and interpretable
decision-making.

</details>


### [255] [Benchmarking Foundation Models and Parameter-Efficient Fine-Tuning for Prognosis Prediction in Medical Imaging](https://arxiv.org/abs/2506.18434)
*Filippo Ruffini,Elena Mulero Ayllon,Linlin Shen,Paolo Soda,Valerio Guarrasi*

Main category: cs.CV

TL;DR: 该论文提出了一种结构化基准，用于评估和比较卷积神经网络和基础模型在COVID-19患者临床预后预测中的迁移能力，通过多种微调策略和模型进行了大规模分析。


<details>
  <summary>Details</summary>
Motivation: 人工智能在医学影像预后预测中具有潜力，但其有效应用仍具挑战性。本文旨在通过结构化基准解决这一问题。

Method: 采用多种微调策略（如全微调、线性探测及参数高效微调方法），在多种学习范式下评估多种预训练模型的迁移能力。

Result: 通过大规模比较分析，评估了模型在数据稀缺和类别不平衡条件下的适应性和泛化能力。

Conclusion: 该研究为临床预后预测中稳健、高效且可泛化的AI解决方案的实际部署提供了详细见解。

Abstract: Artificial Intelligence (AI) holds significant promise for improving
prognosis prediction in medical imaging, yet its effective application remains
challenging. In this work, we introduce a structured benchmark explicitly
designed to evaluate and compare the transferability of Convolutional Neural
Networks and Foundation Models in predicting clinical outcomes in COVID-19
patients, leveraging diverse publicly available Chest X-ray datasets. Our
experimental methodology extensively explores a wide set of fine-tuning
strategies, encompassing traditional approaches such as Full Fine-Tuning and
Linear Probing, as well as advanced Parameter-Efficient Fine-Tuning methods
including Low-Rank Adaptation, BitFit, VeRA, and IA3. The evaluations were
conducted across multiple learning paradigms, including both extensive
full-data scenarios and more clinically realistic Few-Shot Learning settings,
which are critical for modeling rare disease outcomes and rapidly emerging
health threats. By implementing a large-scale comparative analysis involving a
diverse selection of pretrained models, including general-purpose architectures
pretrained on large-scale datasets such as CLIP and DINOv2, to
biomedical-specific models like MedCLIP, BioMedCLIP, and PubMedCLIP, we
rigorously assess each model's capacity to effectively adapt and generalize to
prognosis tasks, particularly under conditions of severe data scarcity and
pronounced class imbalance. The benchmark was designed to capture critical
conditions common in prognosis tasks, including variations in dataset size and
class distribution, providing detailed insights into the strengths and
limitations of each fine-tuning strategy. This extensive and structured
evaluation aims to inform the practical deployment and adoption of robust,
efficient, and generalizable AI-driven solutions in real-world clinical
prognosis prediction workflows.

</details>


### [256] [Frequency-Domain Fusion Transformer for Image Inpainting](https://arxiv.org/abs/2506.18437)
*Sijin He,Guangfeng Lin,Tao Li,Yajun Chen*

Main category: cs.CV

TL;DR: 提出了一种结合频域融合的Transformer图像修复方法，通过小波变换和Gabor滤波增强多尺度结构建模和细节保留，同时设计了基于快速傅里叶变换的可学习频域滤波器，实验表明该方法能有效提升修复质量。


<details>
  <summary>Details</summary>
Motivation: 传统图像修复方法难以处理复杂纹理和大面积遮挡，而基于Transformer的方法虽具有全局建模能力，但自注意力的低通特性导致高频细节丢失且计算成本高。

Method: 结合小波变换和Gabor滤波的注意力机制增强多尺度建模；设计基于快速傅里叶变换的可学习频域滤波器替代前馈网络；采用四层编码器-解码器结构和新颖的损失策略。

Result: 实验结果表明，该方法能更好地保留高频信息，显著提升图像修复质量。

Conclusion: 提出的方法通过频域融合和自适应滤波，有效解决了Transformer在图像修复中的高频细节丢失问题，同时降低了计算成本。

Abstract: Image inpainting plays a vital role in restoring missing image regions and
supporting high-level vision tasks, but traditional methods struggle with
complex textures and large occlusions. Although Transformer-based approaches
have demonstrated strong global modeling capabilities, they often fail to
preserve high-frequency details due to the low-pass nature of self-attention
and suffer from high computational costs. To address these challenges, this
paper proposes a Transformer-based image inpainting method incorporating
frequency-domain fusion. Specifically, an attention mechanism combining wavelet
transform and Gabor filtering is introduced to enhance multi-scale structural
modeling and detail preservation. Additionally, a learnable frequency-domain
filter based on the fast Fourier transform is designed to replace the
feedforward network, enabling adaptive noise suppression and detail retention.
The model adopts a four-level encoder-decoder structure and is guided by a
novel loss strategy to balance global semantics and fine details. Experimental
results demonstrate that the proposed method effectively improves the quality
of image inpainting by preserving more high-frequency information.

</details>


### [257] [CPAM: Context-Preserving Adaptive Manipulation for Zero-Shot Real Image Editing](https://arxiv.org/abs/2506.18438)
*Dinh-Khoi Vo,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: 提出了一种名为CPAM的零样本框架，用于复杂非刚性真实图像编辑，通过自适应模块和局部提取模块实现对象与背景的独立控制，并在新构建的IMBA数据集上验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本到图像扩散模型中难以保持纹理和身份一致性，且对复杂非刚性对象编辑效果不佳，需要大量微调。

Method: 提出CPAM框架，包括保护适应模块（调整自注意力机制）和局部提取模块（减少干扰），并引入多种掩码引导策略。

Result: 在IMBA数据集上的实验表明，CPAM优于现有技术，成为人类评分者的首选。

Conclusion: CPAM是一种高效、零样本的图像编辑方法，能有效保留对象和背景细节，适用于复杂场景。

Abstract: Editing natural images using textual descriptions in text-to-image diffusion
models remains a significant challenge, particularly in achieving consistent
generation and handling complex, non-rigid objects. Existing methods often
struggle to preserve textures and identity, require extensive fine-tuning, and
exhibit limitations in editing specific spatial regions or objects while
retaining background details. This paper proposes Context-Preserving Adaptive
Manipulation (CPAM), a novel zero-shot framework for complicated, non-rigid
real image editing. Specifically, we propose a preservation adaptation module
that adjusts self-attention mechanisms to preserve and independently control
the object and background effectively. This ensures that the objects' shapes,
textures, and identities are maintained while keeping the background
undistorted during the editing process using the mask guidance technique.
Additionally, we develop a localized extraction module to mitigate the
interference with the non-desired modified regions during conditioning in
cross-attention mechanisms. We also introduce various mask-guidance strategies
to facilitate diverse image manipulation tasks in a simple manner. Extensive
experiments on our newly constructed Image Manipulation BenchmArk (IMBA), a
robust benchmark dataset specifically designed for real image editing,
demonstrate that our proposed method is the preferred choice among human
raters, outperforming existing state-of-the-art editing techniques.

</details>


### [258] [DIP: Unsupervised Dense In-Context Post-training of Visual Representations](https://arxiv.org/abs/2506.18463)
*Sophia Sirko-Galouchenko,Spyros Gidaris,Antonin Vobecky,Andrei Bursuc,Nicolas Thome*

Main category: cs.CV

TL;DR: DIP是一种无监督后训练方法，通过生成伪任务模拟下游场景理解任务，提升大规模预训练视觉编码器的密集图像表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂的自蒸馏架构，而DIP旨在通过简单、高效的方式改进密集表示。

Method: 利用预训练扩散模型和视觉编码器自动生成伪任务，模拟下游场景理解任务进行训练。

Result: DIP在多种下游场景理解任务中表现优异，计算效率高（单A100 GPU耗时<9小时）。

Conclusion: DIP提供了一种实用且有效的方法，显著提升了密集表示的性能。

Abstract: We introduce DIP, a novel unsupervised post-training method designed to
enhance dense image representations in large-scale pretrained vision encoders
for in-context scene understanding. Unlike prior approaches that rely on
complex self-distillation architectures, our method trains the vision encoder
using pseudo-tasks that explicitly simulate downstream in-context scenarios,
inspired by meta-learning principles. To enable post-training on unlabeled
data, we propose an automatic mechanism for generating in-context tasks that
combines a pretrained diffusion model and the vision encoder itself. DIP is
simple, unsupervised, and computationally efficient, requiring less than 9
hours on a single A100 GPU. By learning dense representations through pseudo
in-context tasks, it achieves strong performance across a wide variety of
downstream real-world in-context scene understanding tasks. It outperforms both
the initial vision encoder and prior methods, offering a practical and
effective solution for improving dense representations. Code available here:
https://github.com/sirkosophia/DIP

</details>


### [259] [AViLA: Asynchronous Vision-Language Agent for Streaming Multimodal Data Interaction](https://arxiv.org/abs/2506.18472)
*Gengyuan Zhang,Tanveer Hannan,Hermine Kleiner,Beste Aydemir,Xinyu Xie,Jian Lan,Thomas Seidl,Volker Tresp,Jindong Gu*

Main category: cs.CV

TL;DR: 论文提出了一种异步视频-语言代理（AViLA），用于处理流数据中的查询与证据异步问题，并通过实验验证其优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决在流数据环境中用户查询与支持证据异步到达的挑战，提升多模态大语言模型（MLLMs）的实时响应能力。

Method: 设计了AViLA代理，包含三个关键模块：全面记忆保留、证据识别和证据触发，以支持流数据中的时间感知响应。

Result: 实验表明，AViLA在准确性和时间感知方面显著优于现有模型。

Conclusion: AViLA为解决查询与证据异步问题提供了有效方案，并展示了在多模态流数据交互中的潜力。

Abstract: An ideal vision-language agent serves as a bridge between the human users and
their surrounding physical world in real-world applications like autonomous
driving and embodied agents, and proactively provides accurate and timely
responses given user intents. An intriguing challenge arises when agents
interact with the world as a dynamic data stream and ad-hoc queries from users:
supporting knowledge for queries, namely evidence, usually appears
asynchronously with the arrival time of queries, and agents need to ground
their responses in historical data, present observations, and even future
streams. We frame this challenge as Query-Evidence Asynchrony, where user
queries and their supporting evidence typically arrive asynchronously in the
streaming setting. This setting requires not only strong reasoning capabilities
but also the ability to retain past observations and respond to queries with
temporal awareness. In this paper, we introduce a diagnostic benchmark that
evaluates Multimodal Large Language Models (MLLMs) on their ability to handle
interaction with streaming data. Further, we present AViLA, Asynchronous
Video-Language Agent for streaming data interaction that can handle ad-hoc
queries and give time-aware responses. For this purpose, AViLA consists of
three key modules: comprehensive memory retention, evidence identification, and
evidence-grounded trigger, that are designed to maintain a general-purpose
memory and respond readily and timely to queries. Our experiments show that
existing models often fail to respond at appropriate times, while AViLA
significantly improves both accuracy and temporal awareness. Our code and
dataset will be publicly available.

</details>


### [260] [Context Consistency Learning via Sentence Removal for Semi-Supervised Video Paragraph Grounding](https://arxiv.org/abs/2506.18476)
*Yaokun Zhong,Siyu Jiang,Jian Zhu,Jian-Fang Hu*

Main category: cs.CV

TL;DR: 提出了一种新的上下文一致性学习（CCL）框架，通过结合一致性正则化和伪标签技术，在半监督视频段落定位任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了通过扰动查询上下文生成强监督信号的重要性，导致半监督学习效果不佳。

Method: 提出CCL框架，结合教师-学生学习和伪标签技术，通过强增强样本和模型重训练提升性能。

Result: 实验表明，CCL大幅优于现有方法。

Conclusion: CCL通过统一一致性正则化和伪标签技术，显著提升了半监督视频段落定位的性能。

Abstract: Semi-Supervised Video Paragraph Grounding (SSVPG) aims to localize multiple
sentences in a paragraph from an untrimmed video with limited temporal
annotations. Existing methods focus on teacher-student consistency learning and
video-level contrastive loss, but they overlook the importance of perturbing
query contexts to generate strong supervisory signals. In this work, we propose
a novel Context Consistency Learning (CCL) framework that unifies the paradigms
of consistency regularization and pseudo-labeling to enhance semi-supervised
learning. Specifically, we first conduct teacher-student learning where the
student model takes as inputs strongly-augmented samples with sentences removed
and is enforced to learn from the adequately strong supervisory signals from
the teacher model. Afterward, we conduct model retraining based on the
generated pseudo labels, where the mutual agreement between the original and
augmented views' predictions is utilized as the label confidence. Extensive
experiments show that CCL outperforms existing methods by a large margin.

</details>


### [261] [GANs vs. Diffusion Models for virtual staining with the HER2match dataset](https://arxiv.org/abs/2506.18484)
*Pascal Klöckner,José Teixeira,Diana Montezuma,Jaime S. Cardoso,Hugo M. Horlings,Sara P. Oliveira*

Main category: cs.CV

TL;DR: 论文介绍了首个公开的H&E-HER2染色数据集HER2match，并比较了GANs和DMs在H&E-HER2转换任务中的表现，发现GANs整体优于DMs，仅BBDM表现接近。数据对齐对模型性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 解决H&E-HER2染色转换任务中缺乏公开数据集和模型框架选择不明确的问题。

Method: 引入HER2match数据集，比较多种GANs和DMs，并实现了一种新的BBDM模型。

Result: GANs整体优于DMs，BBDM表现接近；数据对齐显著提升模型性能。

Conclusion: 研究提供了高质量数据集和模型比较，为相关研究提供了重要参考。

Abstract: Virtual staining is a promising technique that uses deep generative models to
recreate histological stains, providing a faster and more cost-effective
alternative to traditional tissue chemical staining. Specifically for H&E-HER2
staining transfer, despite a rising trend in publications, the lack of
sufficient public datasets has hindered progress in the topic. Additionally, it
is currently unclear which model frameworks perform best for this particular
task. In this paper, we introduce the HER2match dataset, the first publicly
available dataset with the same breast cancer tissue sections stained with both
H&E and HER2. Furthermore, we compare the performance of several Generative
Adversarial Networks (GANs) and Diffusion Models (DMs), and implement a novel
Brownian Bridge Diffusion Model for H&E-HER2 translation. Our findings indicate
that, overall, GANs perform better than DMs, with only the BBDM achieving
comparable results. Furthermore, we emphasize the importance of data alignment,
as all models trained on HER2match produced vastly improved visuals compared to
the widely used consecutive-slide BCI dataset. This research provides a new
high-quality dataset ([available upon publication acceptance]), improving both
model training and evaluation. In addition, our comparison of frameworks offers
valuable guidance for researchers working on the topic.

</details>


### [262] [Generalizing Vision-Language Models to Novel Domains: A Comprehensive Survey](https://arxiv.org/abs/2506.18504)
*Xinyao Li,Jingjing Li,Fengling Li,Lei Zhu,Yang Yang,Heng Tao Shen*

Main category: cs.CV

TL;DR: 该论文综述了视觉语言模型（VLM）的泛化方法，包括提示、参数和特征三种类型，并比较了其性能，同时探讨了VLM与多模态大语言模型（MLLM）的关系。


<details>
  <summary>Details</summary>
Motivation: 视觉语言预训练模型在零样本任务中表现优异，但在特定领域任务中性能下降，因此需要研究如何将其知识泛化到下游任务。

Method: 通过分类为提示、参数和特征三种方法，总结和比较了VLM的泛化方法，并回顾了典型迁移学习设置。

Result: 综述了VLM泛化的性能比较，并探讨了VLM与MLLM的关系。

Conclusion: 该综述为当前和未来的多模态研究提供了清晰的视角，强调了VLM泛化的重要性。

Abstract: Recently, vision-language pretraining has emerged as a transformative
technique that integrates the strengths of both visual and textual modalities,
resulting in powerful vision-language models (VLMs). Leveraging web-scale
pretraining data, these models exhibit strong zero-shot capabilities. However,
their performance often deteriorates when confronted with domain-specific or
specialized generalization tasks. To address this, a growing body of research
focuses on transferring or generalizing the rich knowledge embedded in VLMs to
various downstream applications. This survey aims to comprehensively summarize
the generalization settings, methodologies, benchmarking and results in VLM
literatures. Delving into the typical VLM structures, current literatures are
categorized into prompt-based, parameter-based and feature-based methods
according to the transferred modules. The differences and characteristics in
each category are furthered summarized and discussed by revisiting the typical
transfer learning (TL) settings, providing novel interpretations for TL in the
era of VLMs. Popular benchmarks for VLM generalization are further introduced
with thorough performance comparisons among the reviewed methods. Following the
advances in large-scale generalizable pretraining, this survey also discusses
the relations and differences between VLMs and up-to-date multimodal large
language models (MLLM), e.g., DeepSeek-VL. By systematically reviewing the
surging literatures in vision-language research from a novel and practical
generalization prospective, this survey contributes to a clear landscape of
current and future multimodal researches.

</details>


### [263] [ShowFlow: From Robust Single Concept to Condition-Free Multi-Concept Generation](https://arxiv.org/abs/2506.18493)
*Trong-Vu Hoang,Quang-Binh Nguyen,Thanh-Toan Do,Tam V. Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: ShowFlow是一个用于可控图像合成的框架，分为ShowFlow-S（单概念生成）和ShowFlow-M（多概念生成），通过KronA-WED适配器和SAMA模块解决身份保留和提示对齐的挑战。


<details>
  <summary>Details</summary>
Motivation: 在单概念和多概念图像生成中，保持身份保留和提示对齐是核心挑战，现有方法常导致身份丢失和概念遗漏。

Method: ShowFlow-S使用KronA-WED适配器和解耦学习方法；ShowFlow-M复用ShowFlow-S模型，引入SAMA和布局一致性策略。

Result: 实验和用户研究表明ShowFlow在广告和虚拟试衣等应用中具有潜力。

Conclusion: ShowFlow通过创新模块解决了图像生成中的身份保留和提示对齐问题，展现了实际应用价值。

Abstract: Customizing image generation remains a core challenge in controllable image
synthesis. For single-concept generation, maintaining both identity
preservation and prompt alignment is challenging. In multi-concept scenarios,
relying solely on a prompt without additional conditions like layout boxes or
semantic masks, often leads to identity loss and concept omission. In this
paper, we introduce ShowFlow, a comprehensive framework designed to tackle
these challenges. We propose ShowFlow-S for single-concept image generation,
and ShowFlow-M for handling multiple concepts. ShowFlow-S introduces a
KronA-WED adapter, which integrates a Kronecker adapter with weight and
embedding decomposition, and employs a disentangled learning approach with a
novel attention regularization objective to enhance single-concept generation.
Building on this foundation, ShowFlow-M directly reuses the learned models from
ShowFlow-S to support multi-concept generation without extra conditions,
incorporating a Subject-Adaptive Matching Attention (SAMA) and a layout
consistency strategy as the plug-and-play module. Extensive experiments and
user studies validate ShowFlow's effectiveness, highlighting its potential in
real-world applications like advertising and virtual dressing.

</details>


### [264] [Historical Report Guided Bi-modal Concurrent Learning for Pathology Report Generation](https://arxiv.org/abs/2506.18658)
*Ling Zhang,Boxiang Yun,Qingli Li,Yan Wang*

Main category: cs.CV

TL;DR: 论文提出了一种名为BiGen的双模态并发学习框架，用于从全切片图像（WSIs）生成病理报告，解决了视觉特征缺乏语义内容和WSIs信息冗余的问题。


<details>
  <summary>Details</summary>
Motivation: 解决病理报告生成中视觉特征语义内容不足和WSIs信息冗余的挑战。

Method: 提出BiGen框架，包括知识检索机制和双模态并发学习策略，通过共享权重层实现视觉特征与知识特征的对齐。

Result: 在PathText（BRCA）数据集上表现优异，NLP指标相对提升7.4%，Her-2预测分类指标提升19.1%。

Conclusion: BiGen框架能有效提供语义内容并抑制信息冗余，实验验证了其模块的必要性和优越性。

Abstract: Automated pathology report generation from Whole Slide Images (WSIs) faces
two key challenges: (1) lack of semantic content in visual features and (2)
inherent information redundancy in WSIs. To address these issues, we propose a
novel Historical Report Guided \textbf{Bi}-modal Concurrent Learning Framework
for Pathology Report \textbf{Gen}eration (BiGen) emulating pathologists'
diagnostic reasoning, consisting of: (1) A knowledge retrieval mechanism to
provide rich semantic content, which retrieves WSI-relevant knowledge from
pre-built medical knowledge bank by matching high-attention patches and (2) A
bi-modal concurrent learning strategy instantiated via a learnable visual token
and a learnable textual token to dynamically extract key visual features and
retrieved knowledge, where weight-shared layers enable cross-modal alignment
between visual features and knowledge features. Our multi-modal decoder
integrates both modals for comprehensive diagnostic reports generation.
Experiments on the PathText (BRCA) dataset demonstrate our framework's
superiority, achieving state-of-the-art performance with 7.4\% relative
improvement in NLP metrics and 19.1\% enhancement in classification metrics for
Her-2 prediction versus existing methods. Ablation studies validate the
necessity of our proposed modules, highlighting our method's ability to provide
WSI-relevant rich semantic content and suppress information redundancy in WSIs.
Code is publicly available at https://github.com/DeepMed-Lab-ECNU/BiGen.

</details>


### [265] [Biased Teacher, Balanced Student](https://arxiv.org/abs/2506.18496)
*Seonghak Kim*

Main category: cs.CV

TL;DR: 提出了一种针对长尾数据分布的知识蒸馏框架LTKD，通过分解KL散度为组间和组内部分，并引入重新平衡的损失函数，显著提升了尾类性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏在长尾数据分布中表现不佳，因为教师模型偏向头部类别，导致尾类监督不足。

Method: 将标准KD目标分解为组间和组内KL散度，并设计重新平衡的组间损失和均匀的组内损失。

Result: 在多个数据集上，LTKD优于现有KD方法，显著提高了整体准确率和尾类性能。

Conclusion: LTKD能够从有偏见的教师模型中有效转移知识，适用于资源受限和不平衡的实际场景。

Abstract: Knowledge Distillation (KD) is a widely adopted model compression technique
where a compact student model learns from the output of a larger, pre-trained
teacher. While effective in balanced settings, conventional KD suffers
significantly when applied to long-tailed data distributions, as the teacher
model tends to be biased toward head classes and provides limited supervision
for tail classes. In this paper, we propose Long-Tailed Knowledge Distillation
(LTKD), a novel framework tailored for class-imbalanced scenarios. We begin by
reformulating the standard KD objective into two components: inter-group and
intra-group Kullback-Leibler (KL) divergence, corresponding to the prediction
distributions across and within class groups (head, medium, tail),
respectively. This decomposition allows us to identify and quantify the sources
of teacher bias. To address them, we introduce (1) a rebalanced inter-group
loss that calibrates the teacher's group-level predictions and (2) a uniform
intra-group loss that ensures equal contribution from all groups during
distillation. Extensive experiments on CIFAR-100-LT, TinyImageNet-LT, and
ImageNet-LT show that LTKD consistently outperforms existing KD methods,
achieving significant gains in both overall accuracy and tail-class
performance. Our results demonstrate that LTKD enables effective knowledge
transfer even from biased teachers, making it a strong candidate for real-world
deployment in resource-constrained and imbalanced settings.

</details>


### [266] [Benchmarking histopathology foundation models in a multi-center dataset for skin cancer subtyping](https://arxiv.org/abs/2506.18668)
*Pablo Meseguer,Rocío del Amor,Valery Naranjo*

Main category: cs.CV

TL;DR: 该论文提出了一种新的基准测试，用于评估病理学基础模型作为特征提取器在MIL分类框架中的表现，并引入FM-SI指标衡量模型一致性。


<details>
  <summary>Details</summary>
Motivation: 由于病理学基础模型的多样性，需要设计真实世界的挑战来评估其有效性。

Method: 利用AI4SkIN数据集，提出FM-SI指标，评估模型在分布变化下的表现。

Result: 实验表明，提取较少偏差的特征能提升分类性能，尤其在基于相似性的MIL分类器中。

Conclusion: 该研究为病理学基础模型的评估提供了新方法，并展示了特征提取对分类性能的重要性。

Abstract: Pretraining on large-scale, in-domain datasets grants histopathology
foundation models (FM) the ability to learn task-agnostic data representations,
enhancing transfer learning on downstream tasks. In computational pathology,
automated whole slide image analysis requires multiple instance learning (MIL)
frameworks due to the gigapixel scale of the slides. The diversity among
histopathology FMs has highlighted the need to design real-world challenges for
evaluating their effectiveness. To bridge this gap, our work presents a novel
benchmark for evaluating histopathology FMs as patch-level feature extractors
within a MIL classification framework. For that purpose, we leverage the
AI4SkIN dataset, a multi-center cohort encompassing slides with challenging
cutaneous spindle cell neoplasm subtypes. We also define the Foundation Model -
Silhouette Index (FM-SI), a novel metric to measure model consistency against
distribution shifts. Our experimentation shows that extracting less biased
features enhances classification performance, especially in similarity-based
MIL classifiers.

</details>


### [267] [MedTVT-R1: A Multimodal LLM Empowering Medical Reasoning and Diagnosis](https://arxiv.org/abs/2506.18512)
*Yuting Zhang,Kaishen Yuan,Hao Lu,Yutao Yue,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 提出了一种名为MedTVT-R1的多模态大语言模型框架，用于整合临床多模态数据进行多疾病诊断，并通过GRPO强化微调提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖单模态数据、难以全面理解复杂疾病的问题。

Method: 构建MedTVT-QA数据集，设计模态感知层捕捉模态间依赖关系，采用GRPO强化微调优化诊断推理。

Result: 实验表明MedTVT-R1在多模态特征利用和多疾病诊断上表现优越。

Conclusion: MedTVT-R1在临床应用中具有潜力，如诊断报告生成和共病推理。

Abstract: Accurate and interpretable multi-disease diagnosis remains a critical
challenge in medical research, particularly when leveraging heterogeneous
multimodal medical data. Current approaches often rely on single-modal data,
limiting their ability to comprehensively understand complex diseases. To
address this, we propose MedTVT-R1, a novel Multimodal Large Language Model
(MLLM) framework designed to integrate clinical multimodal data for reasoning
and diagnosing multiple diseases. We construct MedTVT-QA, a curated instruction
dataset that provides question-answer pairs for physiological-level
interpretations and disease-level diagnoses with a Chain of Evidence approach.
MedTVT-R1 incorporates a modality perception layer to capture inter-modal
dependencies and adaptively weight modality contributions. Additionally, we
employ Group Relative Policy Optimization (GRPO)-based Reinforcement
Fine-Tuning with a Jaccard Reward function to enhance diagnostic reasoning.
Experimental results demonstrate MedTVT-R1's superiority in multimodal feature
utilization and multi-disease diagnosis, offering significant potential for
clinical applications such as diagnostic report generation and comorbidity
reasoning. The dataset and code are available at
https://github.com/keke-nice/MedTVT-R1.

</details>


### [268] [Multi-Scale Spectral Attention Module-based Hyperspectral Segmentation in Autonomous Driving Scenarios](https://arxiv.org/abs/2506.18682)
*Imad Ali Shah,Jiarong Li,Tim Brophy,Martin Glavin,Edward Jones,Enda Ward,Brian Deegan*

Main category: cs.CV

TL;DR: 论文提出了一种多尺度光谱注意力模块（MSAM），通过结合不同核大小的1D卷积和自适应特征聚合机制，显著提升了高光谱图像（HSI）的语义分割性能，适用于自动驾驶环境感知。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）在自动驾驶环境感知中具有潜力，但其高维光谱数据的高效处理仍是一个挑战。

Method: 提出MSAM模块，通过三个并行1D卷积（核大小1至11）和自适应特征聚合机制增强光谱特征提取，并将其集成到UNet的跳跃连接中（UNet-MSAM）。

Result: 在多个HSI数据集上，UNet-MSAM显著优于UNet-SC，平均mIoU和mF1分别提升3.61%和3.80%，且计算开销极小（参数增加0.02%，GFLOPS增加0.82%）。

Conclusion: 多尺度核组合优于单尺度配置，证明了HSI处理在自动驾驶中的潜力，并为设计鲁棒的多尺度光谱特征提取器提供了实用见解。

Abstract: Recent advances in autonomous driving (AD) have highlighted the potential of
Hyperspectral Imaging (HSI) for enhanced environmental perception, particularly
in challenging weather and lighting conditions. However, efficiently processing
its high-dimensional spectral data remains a significant challenge. This paper
introduces a Multi-scale Spectral Attention Module (MSAM) that enhances
spectral feature extraction through three parallel 1D convolutions with varying
kernel sizes between 1 to 11, coupled with an adaptive feature aggregation
mechanism. By integrating MSAM into UNet's skip connections (UNet-SC), our
proposed UNet-MSAM achieves significant improvements in semantic segmentation
performance across multiple HSI datasets: HyKo-VIS v2, HSI-Drive v2, and
Hyperspectral City v2. Our comprehensive experiments demonstrate that with
minimal computational overhead (on average 0.02% in parameters and 0.82%
GFLOPS), UNet-MSAM consistently outperforms UNet-SC, achieving average
improvements of 3.61% in mean IoU and 3.80% in mF1 across the three datasets.
Through extensive ablation studies, we have established that multi-scale kernel
combinations perform better than single-scale configurations. These findings
demonstrate the potential of HSI processing for AD and provide valuable
insights into designing robust, multi-scale spectral feature extractors for
real-world applications.

</details>


### [269] [Enhancing Image Restoration Transformer via Adaptive Translation Equivariance](https://arxiv.org/abs/2506.18520)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Hangzhou He,Yanye Lu*

Main category: cs.CV

TL;DR: 论文提出了一种名为TEAFormer的翻译等变性自适应Transformer，通过滑动索引和组件堆叠策略解决注意力机制破坏翻译等变性的问题，并在多种图像修复任务中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现代修复Transformer中的注意力机制破坏了翻译等变性，影响训练收敛和泛化能力，因此需要解决这一问题。

Method: 提出滑动索引和组件堆叠策略，并设计自适应滑动索引机制，结合全局聚合的键值对，构建TEAFormer网络。

Result: TEAFormer在多种图像修复任务中表现出更高的有效性、训练收敛性和泛化能力。

Conclusion: TEAFormer通过自适应滑动索引和组件堆叠成功解决了翻译等变性问题，提升了图像修复任务的性能。

Abstract: Translation equivariance is a fundamental inductive bias in image
restoration, ensuring that translated inputs produce translated outputs.
Attention mechanisms in modern restoration transformers undermine this
property, adversely impacting both training convergence and generalization. To
alleviate this issue, we propose two key strategies for incorporating
translation equivariance: slide indexing and component stacking. Slide indexing
maintains operator responses at fixed positions, with sliding window attention
being a notable example, while component stacking enables the arrangement of
translation-equivariant operators in parallel or sequentially, thereby building
complex architectures while preserving translation equivariance. However, these
strategies still create a dilemma in model design between the high
computational cost of self-attention and the fixed receptive field associated
with sliding window attention. To address this, we develop an adaptive sliding
indexing mechanism to efficiently select key-value pairs for each query, which
are then concatenated in parallel with globally aggregated key-value pairs. The
designed network, called the Translation Equivariance Adaptive Transformer
(TEAFormer), is assessed across a variety of image restoration tasks. The
results highlight its superiority in terms of effectiveness, training
convergence, and generalization.

</details>


### [270] [SIM-Net: A Multimodal Fusion Network Using Inferred 3D Object Shape Point Clouds from RGB Images for 2D Classification](https://arxiv.org/abs/2506.18683)
*Youcef Sklab,Hanane Ariouat,Eric Chenin,Edi Prifti,Jean-Daniel Zucker*

Main category: cs.CV

TL;DR: SIM-Net是一种新型的2D图像分类架构，通过将RGB图像推断为3D点云，融合纹理和几何特征，显著提升了分类性能，尤其在植物标本分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统2D图像分类模型在植物标本分类中因背景复杂、遮挡等问题导致的性能不足。

Method: 提出像素到点的转换技术，将2D对象掩模转为3D点云，结合CNN和PointNet编码器，融合纹理与几何特征。

Result: 在植物标本数据集上，SIM-Net比ResNet101准确率提升9.9%，F-score提升12.3%，优于多种先进架构。

Conclusion: 将3D结构推理融入2D图像分类任务能显著提升性能，SIM-Net为复杂场景下的分类提供了有效解决方案。

Abstract: We introduce the Shape-Image Multimodal Network (SIM-Net), a novel 2D image
classification architecture that integrates 3D point cloud representations
inferred directly from RGB images. Our key contribution lies in a
pixel-to-point transformation that converts 2D object masks into 3D point
clouds, enabling the fusion of texture-based and geometric features for
enhanced classification performance. SIM-Net is particularly well-suited for
the classification of digitized herbarium specimens (a task made challenging by
heterogeneous backgrounds), non-plant elements, and occlusions that compromise
conventional image-based models. To address these issues, SIM-Net employs a
segmentation-based preprocessing step to extract object masks prior to 3D point
cloud generation. The architecture comprises a CNN encoder for 2D image
features and a PointNet-based encoder for geometric features, which are fused
into a unified latent space. Experimental evaluations on herbarium datasets
demonstrate that SIM-Net consistently outperforms ResNet101, achieving gains of
up to 9.9% in accuracy and 12.3% in F-score. It also surpasses several
transformer-based state-of-the-art architectures, highlighting the benefits of
incorporating 3D structural reasoning into 2D image classification tasks.

</details>


### [271] [Multi-Scale Representation of Follicular Lymphoma Pathology Images in a Single Hyperbolic Space](https://arxiv.org/abs/2506.18523)
*Kei Taguchi,Kazumasa Ohara,Tatsuya Yokota,Hiroaki Miyoshi,Noriaki Hashimoto,Ichiro Takeuchi,Hidekata Hontani*

Main category: cs.CV

TL;DR: 提出一种在双曲空间中表示恶性淋巴瘤病理图像的方法，通过自监督学习从高分辨率细胞核到低分辨率组织图像的统一表示。


<details>
  <summary>Details</summary>
Motivation: 捕捉疾病进展中跨尺度的形态变化，统一表示组织和细胞核图像。

Method: 利用Poincaré球作为特征空间，通过自监督学习嵌入图像，基于包含关系将组织和细胞核图像靠近表示。

Result: 学习到的表示能够同时捕捉疾病状态和细胞类型的变化。

Conclusion: 该方法有效编码了病理图像的层次结构，为疾病分析提供了新视角。

Abstract: We propose a method for representing malignant lymphoma pathology images,
from high-resolution cell nuclei to low-resolution tissue images, within a
single hyperbolic space using self-supervised learning. To capture
morphological changes that occur across scales during disease progression, our
approach embeds tissue and corresponding nucleus images close to each other
based on inclusion relationships. Using the Poincar\'e ball as the feature
space enables effective encoding of this hierarchical structure. The learned
representations capture both disease state and cell type variations.

</details>


### [272] [Matrix-Game: Interactive World Foundation Model](https://arxiv.org/abs/2506.18701)
*Yifan Zhang,Chunli Peng,Boyang Wang,Puyi Wang,Qingcheng Zhu,Fei Kang,Biao Jiang,Zedong Gao,Eric Li,Yang Liu,Yahui Zhou*

Main category: cs.CV

TL;DR: Matrix-Game是一个交互式游戏世界生成模型，通过两阶段训练实现可控生成，并在多个指标上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够精确控制角色动作和相机运动的游戏世界生成模型，同时保持高视觉质量和时间一致性。

Method: 采用两阶段训练流程：大规模无标签预训练和环境理解，以及带标签的动作训练。使用包含2700小时无标签和1000小时带标签的Minecraft数据集。

Result: Matrix-Game在视觉质量、时间一致性、动作可控性和物理规则理解方面均优于现有模型（如Oasis和MineWorld）。

Conclusion: Matrix-Game能够生成感知真实且精确可控的视频，为交互式图像到世界生成研究提供了新基准。

Abstract: We introduce Matrix-Game, an interactive world foundation model for
controllable game world generation. Matrix-Game is trained using a two-stage
pipeline that first performs large-scale unlabeled pretraining for environment
understanding, followed by action-labeled training for interactive video
generation. To support this, we curate Matrix-Game-MC, a comprehensive
Minecraft dataset comprising over 2,700 hours of unlabeled gameplay video clips
and over 1,000 hours of high-quality labeled clips with fine-grained keyboard
and mouse action annotations. Our model adopts a controllable image-to-world
generation paradigm, conditioned on a reference image, motion context, and user
actions. With over 17 billion parameters, Matrix-Game enables precise control
over character actions and camera movements, while maintaining high visual
quality and temporal coherence. To evaluate performance, we develop GameWorld
Score, a unified benchmark measuring visual quality, temporal quality, action
controllability, and physical rule understanding for Minecraft world
generation. Extensive experiments show that Matrix-Game consistently
outperforms prior open-source Minecraft world models (including Oasis and
MineWorld) across all metrics, with particularly strong gains in
controllability and physical consistency. Double-blind human evaluations
further confirm the superiority of Matrix-Game, highlighting its ability to
generate perceptually realistic and precisely controllable videos across
diverse game scenarios. To facilitate future research on interactive
image-to-world generation, we will open-source the Matrix-Game model weights
and the GameWorld Score benchmark at https://github.com/SkyworkAI/Matrix-Game.

</details>


### [273] [Auto-Regressively Generating Multi-View Consistent Images](https://arxiv.org/abs/2506.18527)
*JiaKui Hu,Yuxiao Yang,Jialun Liu,Jinbo Wu,Chen Zhao,Yanye Lu*

Main category: cs.CV

TL;DR: MV-AR方法通过自回归模型从任意提示生成一致的多视角图像，结合条件注入模块和数据增强技术，性能媲美领先的扩散模型。


<details>
  <summary>Details</summary>
Motivation: 解决多视角图像生成中的一致性和多样性问题，提升3D内容创作的效率和质量。

Method: 利用自回归模型逐步生成多视角图像，引入条件注入模块处理多种提示，采用渐进训练策略和数据增强技术。

Result: 实验表明MV-AR能生成一致的多视角图像，性能与领先的扩散模型相当。

Conclusion: MV-AR在多视角图像生成中表现出色，具有广泛的应用潜力。

Abstract: Generating multi-view images from human instructions is crucial for 3D
content creation. The primary challenges involve maintaining consistency across
multiple views and effectively synthesizing shapes and textures under diverse
conditions. In this paper, we propose the Multi-View Auto-Regressive (MV-AR)
method, which leverages an auto-regressive model to progressively generate
consistent multi-view images from arbitrary prompts. Firstly, the
next-token-prediction capability of the AR model significantly enhances its
effectiveness in facilitating progressive multi-view synthesis. When generating
widely-separated views, MV-AR can utilize all its preceding views to extract
effective reference information. Subsequently, we propose a unified model that
accommodates various prompts via architecture designing and training
strategies. To address multiple conditions, we introduce condition injection
modules for text, camera pose, image, and shape. To manage multi-modal
conditions simultaneously, a progressive training strategy is employed. This
strategy initially adopts the text-to-multi-view (t2mv) model as a baseline to
enhance the development of a comprehensive X-to-multi-view (X2mv) model through
the randomly dropping and combining conditions. Finally, to alleviate the
overfitting problem caused by limited high-quality data, we propose the
"Shuffle View" data augmentation technique, thus significantly expanding the
training data by several magnitudes. Experiments demonstrate the performance
and versatility of our MV-AR, which consistently generates consistent
multi-view images across a range of conditions and performs on par with leading
diffusion-based multi-view image generation models. Code and models will be
released at https://github.com/MILab-PKU/MVAR.

</details>


### [274] [A Set-to-Set Distance Measure in Hyperbolic Space](https://arxiv.org/abs/2506.18529)
*Pengxiang Li,Wei Wu,Zhi Gao,Xiaomeng Fan,Peilin Yu,Yuwei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种双曲集合间距离度量方法（HS2SD），结合全局和局部结构信息，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 许多实际应用需要比较双曲数据点的集合，而现有方法未能充分捕捉集合的全局和局部结构信息。

Method: HS2SD通过双曲集合的Einstein中点间的测地距离（全局）和拓扑特征（局部）计算距离，使用Thue-Morse序列近似拓扑结构。

Result: 在实体匹配、标准图像分类和少样本图像分类任务中，HS2D表现优于现有方法。

Conclusion: HS2SD能更细致地建模双曲集合间的层次和复杂关系，具有实际应用价值。

Abstract: We propose a hyperbolic set-to-set distance measure for computing
dissimilarity between sets in hyperbolic space. While point-to-point distances
in hyperbolic space effectively capture hierarchical relationships between data
points, many real-world applications require comparing sets of hyperbolic data
points, where the local structure and the global structure of the sets carry
crucial semantic information. The proposed the \underline{h}yperbolic
\underline{s}et-\underline{to}-\underline{s}et \underline{d}istance measure
(HS2SD) integrates both global and local structural information: global
structure through geodesic distances between Einstein midpoints of hyperbolic
sets, and local structure through topological characteristics of the two sets.
To efficiently compute topological differences, we prove that using a finite
Thue-Morse sequence of degree and adjacency matrices can serve as a robust
approximation to capture the topological structure of a set. In this case, by
considering the topological differences, HS2SD provides a more nuanced
understanding of the relationships between two hyperbolic sets. Empirical
evaluation on entity matching, standard image classification, and few-shot
image classification demonstrates that our distance measure outperforms
existing methods by effectively modeling the hierarchical and complex
relationships inherent in hyperbolic sets.

</details>


### [275] [Deep CNN Face Matchers Inherently Support Revocable Biometric Templates](https://arxiv.org/abs/2506.18731)
*Aman Bhatta,Michael C. King,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 现代深度CNN人脸匹配器支持可撤销的生物识别方案，生成多个具有等效识别能力但模板不兼容的模型，Vision Transformer在此方案中表现较差。


<details>
  <summary>Details</summary>
Motivation: 解决生物识别模板一旦泄露无法撤销的问题，提出可撤销的生物识别方案。

Method: 利用深度CNN生成多个等效识别能力但模板不兼容的模型，验证其共享相似性阈值的能力，并比较Vision Transformer的适用性。

Result: 深度CNN模型支持可撤销方案，模板不兼容性强；Vision Transformer在此方案中表现不如ResNet。

Conclusion: 深度CNN为可撤销生物识别提供了有效解决方案，Vision Transformer不适用。

Abstract: One common critique of biometric authentication is that if an individual's
biometric is compromised, then the individual has no recourse. The concept of
revocable biometrics was developed to address this concern. A biometric scheme
is revocable if an individual can have their current enrollment in the scheme
revoked, so that the compromised biometric template becomes worthless, and the
individual can re-enroll with a new template that has similar recognition
power. We show that modern deep CNN face matchers inherently allow for a robust
revocable biometric scheme. For a given state-of-the-art deep CNN backbone and
training set, it is possible to generate an unlimited number of distinct face
matcher models that have both (1) equivalent recognition power, and (2)
strongly incompatible biometric templates. The equivalent recognition power
extends to the point of generating impostor and genuine distributions that have
the same shape and placement on the similarity dimension, meaning that the
models can share a similarity threshold for a 1-in-10,000 false match rate. The
biometric templates from different model instances are so strongly incompatible
that the cross-instance similarity score for images of the same person is
typically lower than the same-instance similarity score for images of different
persons. That is, a stolen biometric template that is revoked is of less value
in attempting to match the re-enrolled identity than the average impostor
template. We also explore the feasibility of using a Vision Transformer (ViT)
backbone-based face matcher in the revocable biometric system proposed in this
work and demonstrate that it is less suitable compared to typical ResNet-based
deep CNN backbones.

</details>


### [276] [Geometry-aware Distance Measure for Diverse Hierarchical Structures in Hyperbolic Spaces](https://arxiv.org/abs/2506.18533)
*Pengxiang Li,Yuwei Wu,Zhi Gao,Xiaomeng Fan,Wei Wu,Zhipeng Lu,Yunde Jia,Mehrtash Harandi*

Main category: cs.CV

TL;DR: 提出了一种动态适应不同层次结构的双曲空间距离度量方法，通过定制投影和曲率优化数据点映射，结合低秩分解和硬对挖掘降低计算成本，实验证明其在分类和少样本学习任务中优于固定距离度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有双曲学习方法假设所有数据具有统一层次结构，但实际层次结构多样，固定距离度量过于限制。

Method: 提出几何感知的距离度量，动态适应不同层次结构，采用低秩分解和硬对挖掘降低计算成本，理论分析确保鲁棒性。

Result: 在图像分类、层次分类和少样本学习任务中表现优异，少样本学习任务提升显著（mini-ImageNet上提升5%）。

Conclusion: 自适应距离度量能更好地捕捉多样层次结构，可视化显示更清晰的类别边界和原型分离。

Abstract: Learning in hyperbolic spaces has attracted increasing attention due to its
superior ability to model hierarchical structures of data. Most existing
hyperbolic learning methods use fixed distance measures for all data, assuming
a uniform hierarchy across all data points. However, real-world hierarchical
structures exhibit significant diversity, making this assumption overly
restrictive. In this paper, we propose a geometry-aware distance measure in
hyperbolic spaces, which dynamically adapts to varying hierarchical structures.
Our approach derives the distance measure by generating tailored projections
and curvatures for each pair of data points, effectively mapping them to an
appropriate hyperbolic space. We introduce a revised low-rank decomposition
scheme and a hard-pair mining mechanism to mitigate the computational cost of
pair-wise distance computation without compromising accuracy. We present an
upper bound on the low-rank approximation error using Talagrand's concentration
inequality, ensuring theoretical robustness. Extensive experiments on standard
image classification (MNIST, CIFAR-10 and CIFAR-100), hierarchical
classification (5-level CIFAR-100), and few-shot learning tasks (mini-ImageNet,
tiered-ImageNet) demonstrate the effectiveness of our method. Our approach
consistently outperforms learning methods that use fixed distance measures,
with notable improvements on few-shot learning tasks, where it achieves over
5\% gains on mini-ImageNet. The results reveal that adaptive distance measures
better capture diverse hierarchical structures, with visualization showing
clearer class boundaries and improved prototype separation in hyperbolic
spaces.

</details>


### [277] [SWA-SOP: Spatially-aware Window Attention for Semantic Occupancy Prediction in Autonomous Driving](https://arxiv.org/abs/2506.18785)
*Helin Cao,Rafael Materla,Sven Behnke*

Main category: cs.CV

TL;DR: 提出了一种名为SWA的空间感知窗口注意力机制，用于改进语义占用预测（SOP），在稀疏或遮挡区域表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的SOP方法在注意力计算中缺乏对空间结构的显式建模，导致几何感知能力有限，在稀疏或遮挡区域表现不佳。

Method: 提出Spatially-aware Window Attention（SWA），将局部空间上下文融入注意力机制。

Result: SWA显著提升了场景完成度，并在LiDAR和相机基准测试中均取得最优结果。

Conclusion: SWA是一种通用的注意力机制，能够有效提升SOP的性能。

Abstract: Perception systems in autonomous driving rely on sensors such as LiDAR and
cameras to perceive the 3D environment. However, due to occlusions and data
sparsity, these sensors often fail to capture complete information. Semantic
Occupancy Prediction (SOP) addresses this challenge by inferring both occupancy
and semantics of unobserved regions. Existing transformer-based SOP methods
lack explicit modeling of spatial structure in attention computation, resulting
in limited geometric awareness and poor performance in sparse or occluded
areas. To this end, we propose Spatially-aware Window Attention (SWA), a novel
mechanism that incorporates local spatial context into attention. SWA
significantly improves scene completion and achieves state-of-the-art results
on LiDAR-based SOP benchmarks. We further validate its generality by
integrating SWA into a camera-based SOP pipeline, where it also yields
consistent gains across modalities.

</details>


### [278] [Normality Prior Guided Multi-Semantic Fusion Network for Unsupervised Image Anomaly Detection](https://arxiv.org/abs/2506.18544)
*Muhao Xu,Xueying Zhou,Xizhan Gao,Weiye Song,Guang Feng,Sijie Niu*

Main category: cs.CV

TL;DR: 提出了一种基于多语义融合网络的无监督异常检测方法，通过引入正常样本的多语义特征指导异常重建，显著提升了逻辑异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 逻辑异常检测比结构异常更具挑战性，现有方法通过低维瓶颈压缩输入，但逻辑异常的局部特征与正常语义相似，全局语义却偏离正常模式，导致异常特征仍能通过瓶颈传播。

Method: 提出多语义融合网络，利用预训练的视觉语言网络提取正常样本的全局语义，构建可学习的语义码本存储特征向量，并将多语义特征融合后输入解码器，指导异常重建。

Result: 在MVTec LOCO AD数据集上达到SOTA性能，pixel-sPRO提升5.7%，image-AUROC提升2.6%。

Conclusion: 该方法通过引入正常样本的多语义特征，有效抑制了逻辑异常的重建，显著提升了检测性能。

Abstract: Recently, detecting logical anomalies is becoming a more challenging task
compared to detecting structural ones. Existing encoder decoder based methods
typically compress inputs into low-dimensional bottlenecks on the assumption
that the compression process can effectively suppress the transmission of
logical anomalies to the decoder. However, logical anomalies present a
particular difficulty because, while their local features often resemble normal
semantics, their global semantics deviate significantly from normal patterns.
Thanks to the generalisation capabilities inherent in neural networks, these
abnormal semantic features can propagate through low-dimensional bottlenecks.
This ultimately allows the decoder to reconstruct anomalous images with
misleading fidelity. To tackle the above challenge, we propose a novel
normality prior guided multi-semantic fusion network for unsupervised anomaly
detection. Instead of feeding the compressed bottlenecks to the decoder
directly, we introduce the multi-semantic features of normal samples into the
reconstruction process. To this end, we first extract abstract global semantics
of normal cases by a pre-trained vision-language network, then the learnable
semantic codebooks are constructed to store representative feature vectors of
normal samples by vector quantisation. Finally, the above multi-semantic
features are fused and employed as input to the decoder to guide the
reconstruction of anomalies to approximate normality. Extensive experiments are
conducted to validate the effectiveness of our proposed method, and it achieves
the SOTA performance on the MVTec LOCO AD dataset with improvements of 5.7% in
pixel-sPRO and 2.6% in image-AUROC. The source code is available at
https://github.com/Xmh-L/NPGMF.

</details>


### [279] [OC-SOP: Enhancing Vision-Based 3D Semantic Occupancy Prediction by Object-Centric Awareness](https://arxiv.org/abs/2506.18798)
*Helin Cao,Sven Behnke*

Main category: cs.CV

TL;DR: 论文提出了一种基于对象中心的语义占用预测框架（OC-SOP），通过整合检测分支提取的高层对象特征，显著提升了前景物体的预测准确性，并在SemanticKITTI上实现了最优性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知因环境中的遮挡和不完整场景数据面临挑战，传统相机方法对所有类别平等处理且依赖局部特征，导致预测效果不佳，尤其是动态前景物体。

Method: 提出OC-SOP框架，通过检测分支提取对象中心的高层特征，并将其整合到语义占用预测流程中。

Result: 显著提升了前景物体的预测准确性，在SemanticKITTI上实现了所有类别的最优性能。

Conclusion: OC-SOP框架通过对象中心特征的整合，有效解决了传统方法的局限性，提升了语义占用预测的整体性能。

Abstract: Autonomous driving perception faces significant challenges due to occlusions
and incomplete scene data in the environment. To overcome these issues, the
task of semantic occupancy prediction (SOP) is proposed, which aims to jointly
infer both the geometry and semantic labels of a scene from images. However,
conventional camera-based methods typically treat all categories equally and
primarily rely on local features, leading to suboptimal predictions, especially
for dynamic foreground objects. To address this, we propose Object-Centric SOP
(OC-SOP), a framework that integrates high-level object-centric cues extracted
via a detection branch into the semantic occupancy prediction pipeline. This
object-centric integration significantly enhances the prediction accuracy for
foreground objects and achieves state-of-the-art performance among all
categories on SemanticKITTI.

</details>


### [280] [Object-aware Sound Source Localization via Audio-Visual Scene Understanding](https://arxiv.org/abs/2506.18557)
*Sung Jin Um,Dongjin Kim,Sangmin Lee,Jung Uk Kim*

Main category: cs.CV

TL;DR: 论文提出了一种基于多模态大语言模型（MLLMs）的声源定位框架，通过生成详细上下文信息区分发声物体与静默物体，并引入两种新损失函数（OCA和ORI），显著提升了复杂场景中的定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂场景中难以准确区分发声物体与视觉相似的静默物体，主要依赖简单的视听对应关系，无法捕捉细粒度语义差异。

Method: 利用MLLMs生成详细上下文信息，明确区分发声前景物体与静默背景物体，并引入OCA和ORI两种损失函数进行优化。

Result: 在MUSIC和VGGSound数据集上的实验表明，该方法在单源和多源定位场景中显著优于现有方法。

Conclusion: 提出的框架通过结合MLLMs和新型损失函数，有效解决了复杂场景中的声源定位问题，性能显著提升。

Abstract: Audio-visual sound source localization task aims to spatially localize
sound-making objects within visual scenes by integrating visual and audio cues.
However, existing methods struggle with accurately localizing sound-making
objects in complex scenes, particularly when visually similar silent objects
coexist. This limitation arises primarily from their reliance on simple
audio-visual correspondence, which does not capture fine-grained semantic
differences between sound-making and silent objects. To address these
challenges, we propose a novel sound source localization framework leveraging
Multimodal Large Language Models (MLLMs) to generate detailed contextual
information that explicitly distinguishes between sound-making foreground
objects and silent background objects. To effectively integrate this detailed
information, we introduce two novel loss functions: Object-aware Contrastive
Alignment (OCA) loss and Object Region Isolation (ORI) loss. Extensive
experimental results on MUSIC and VGGSound datasets demonstrate the
effectiveness of our approach, significantly outperforming existing methods in
both single-source and multi-source localization scenarios. Code and generated
detailed contextual information are available at:
https://github.com/VisualAIKHU/OA-SSL.

</details>


### [281] [VQ-Insight: Teaching VLMs for AI-Generated Video Quality Understanding via Progressive Visual Reinforcement Learning](https://arxiv.org/abs/2506.18564)
*Xuanyu Zhang,Weiqi Li,Shijie Zhao,Junlin Li,Li Zhang,Jian Zhang*

Main category: cs.CV

TL;DR: VQ-Insight提出了一种新的推理式视觉语言模型框架，用于评估AI生成视频的质量，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成视频质量评估方法存在泛化能力有限、缺乏时间意识、依赖大规模标注数据等问题。

Method: 采用渐进式视频质量学习方案和多维度评分奖励设计，结合图像质量预热和任务特定时间学习。

Result: VQ-Insight在偏好比较、多维度评分和自然视频评分中优于现有基线方法。

Conclusion: VQ-Insight显著提升了视频生成任务的质量评估效果。

Abstract: Recent advances in AI-generated content (AIGC) have led to the emergence of
powerful text-to-video generation models. Despite these successes, evaluating
the quality of AIGC-generated videos remains challenging due to limited
generalization, lack of temporal awareness, heavy reliance on large-scale
annotated datasets, and the lack of effective interaction with generation
models. Most current approaches rely on supervised finetuning of
vision-language models (VLMs), which often require large-scale annotated
datasets and tend to decouple understanding and generation. To address these
shortcomings, we propose VQ-Insight, a novel reasoning-style VLM framework for
AIGC video quality assessment. Our approach features: (1) a progressive video
quality learning scheme that combines image quality warm-up, general
task-specific temporal learning, and joint optimization with the video
generation model; (2) the design of multi-dimension scoring rewards, preference
comparison rewards, and temporal modeling rewards to enhance both
generalization and specialization in video quality evaluation. Extensive
experiments demonstrate that VQ-Insight consistently outperforms
state-of-the-art baselines in preference comparison, multi-dimension scoring,
and natural video scoring, bringing significant improvements for video
generation tasks.

</details>


### [282] [VisualChef: Generating Visual Aids in Cooking via Mask Inpainting](https://arxiv.org/abs/2506.18569)
*Oleh Kuzyk,Zuoyue Li,Marc Pollefeys,Xi Wang*

Main category: cs.CV

TL;DR: VisualChef是一种为烹饪场景生成上下文视觉辅助的方法，通过基于掩码的视觉接地简化对齐，无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 烹饪过程中缺乏一致的视觉指导，现有方法依赖复杂文本描述，需精细对齐。

Method: VisualChef通过识别动作相关对象并分类，生成反映动作和结果的图像，同时保持环境一致。

Result: 在三个第一人称视频数据集上定量和定性评估显示，VisualChef优于现有方法。

Conclusion: VisualChef简化视觉辅助生成，提升烹饪指导效果。

Abstract: Cooking requires not only following instructions but also understanding,
executing, and monitoring each step - a process that can be challenging without
visual guidance. Although recipe images and videos offer helpful cues, they
often lack consistency in focus, tools, and setup. To better support the
cooking process, we introduce VisualChef, a method for generating contextual
visual aids tailored to cooking scenarios. Given an initial frame and a
specified action, VisualChef generates images depicting both the action's
execution and the resulting appearance of the object, while preserving the
initial frame's environment. Previous work aims to integrate knowledge
extracted from large language models by generating detailed textual
descriptions to guide image generation, which requires fine-grained
visual-textual alignment and involves additional annotations. In contrast,
VisualChef simplifies alignment through mask-based visual grounding. Our key
insight is identifying action-relevant objects and classifying them to enable
targeted modifications that reflect the intended action and outcome while
maintaining a consistent environment. In addition, we propose an automated
pipeline to extract high-quality initial, action, and final state frames. We
evaluate VisualChef quantitatively and qualitatively on three egocentric video
datasets and show its improvements over state-of-the-art methods.

</details>


### [283] [2D Triangle Splatting for Direct Differentiable Mesh Training](https://arxiv.org/abs/2506.18575)
*Kaifeng Sheng,Zheng Zhou,Yingliang Peng,Qianwei Wang*

Main category: cs.CV

TL;DR: 提出了一种基于2D三角形面片的可微渲染方法（2DTS），替代3D高斯基元，结合连续体积建模和离散网格结构，提升了渲染速度和效果。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯基元在渲染速度和高级效果（如重光照和阴影渲染）上的不足，同时保留连续体积建模的优势。

Method: 使用2D三角形面片替代3D高斯基元，引入紧凑性参数直接训练逼真网格。

Result: 实验表明，该方法在未调优紧凑性时已优于高斯基元方法，且重建网格视觉质量更高。

Conclusion: 2DTS方法在渲染速度和效果上优于现有方法，为高质量3D重建提供了新思路。

Abstract: Differentiable rendering with 3D Gaussian primitives has emerged as a
powerful method for reconstructing high-fidelity 3D scenes from multi-view
images. While it offers improvements over NeRF-based methods, this
representation still encounters challenges with rendering speed and advanced
rendering effects, such as relighting and shadow rendering, compared to
mesh-based models. In this paper, we propose 2D Triangle Splatting (2DTS), a
novel method that replaces 3D Gaussian primitives with 2D triangle facelets.
This representation naturally forms a discrete mesh-like structure while
retaining the benefits of continuous volumetric modeling. By incorporating a
compactness parameter into the triangle primitives, we enable direct training
of photorealistic meshes. Our experimental results demonstrate that our
triangle-based method, in its vanilla version (without compactness tuning),
achieves higher fidelity compared to state-of-the-art Gaussian-based methods.
Furthermore, our approach produces reconstructed meshes with superior visual
quality compared to existing mesh reconstruction methods.

</details>


### [284] [Resampling Augmentation for Time Series Contrastive Learning: Application to Remote Sensing](https://arxiv.org/abs/2506.18587)
*Antoine Saget,Baptiste Lafabregue,Antoine Cornuéjols,Pierre Gançarski*

Main category: cs.CV

TL;DR: 论文提出了一种基于重采样的对比自监督预训练方法，用于卫星图像时间序列（SITS），通过上采样和提取不相交子序列生成正样本对，在农业分类任务中表现优于常见方法。


<details>
  <summary>Details</summary>
Motivation: 由于卫星图像时间序列数据中标记数据稀缺，而大量未标记数据可用，对比自监督预训练成为利用这些数据的有效工具。然而，设计适用于时间序列的有效数据增强方法仍具挑战性。

Method: 提出了一种新颖的重采样增强策略，通过上采样时间序列并提取不相交子序列，同时保持时间覆盖范围，生成正样本对。

Result: 在多个农业分类基准测试中，该方法优于抖动、调整大小和掩码等常见方法，并在S2-Agri100数据集上实现了最先进的性能。

Conclusion: 该方法为遥感时间序列提供了一种简单而有效的对比学习增强策略。

Abstract: Given the abundance of unlabeled Satellite Image Time Series (SITS) and the
scarcity of labeled data, contrastive self-supervised pretraining emerges as a
natural tool to leverage this vast quantity of unlabeled data. However,
designing effective data augmentations for contrastive learning remains
challenging for time series. We introduce a novel resampling-based augmentation
strategy that generates positive pairs by upsampling time series and extracting
disjoint subsequences while preserving temporal coverage. We validate our
approach on multiple agricultural classification benchmarks using Sentinel-2
imagery, showing that it outperforms common alternatives such as jittering,
resizing, and masking. Further, we achieve state-of-the-art performance on the
S2-Agri100 dataset without employing spatial information or temporal encodings,
surpassing more complex masked-based SSL frameworks. Our method offers a
simple, yet effective, contrastive learning augmentation for remote sensing
time series.

</details>


### [285] [TAMMs: Temporal-Aware Multimodal Model for Satellite Image Change Understanding and Forecasting](https://arxiv.org/abs/2506.18862)
*Zhongbin Guo,Yuhao Wang,Ping Jian,Xinyue Chen,Wei Peng,Ertai E*

Main category: cs.CV

TL;DR: TAMMs模型通过轻量级时间模块和语义融合控制注入机制，提升了多模态大语言模型在卫星图像时间序列分析中的时空推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在卫星图像时间序列分析中的时空推理能力不足，需要一种新方法来联合理解时间变化和生成未来场景。

Method: 提出TAMMs模型，结合轻量级时间模块和SFCI机制，通过双路径条件实现时空一致性和语义基础的图像合成。

Result: TAMMs在时间变化理解和未来图像预测任务中优于现有MLLMs。

Conclusion: 精心设计的时间推理和语义融合能充分发挥MLLMs在时空理解中的潜力。

Abstract: Satellite image time-series analysis demands fine-grained spatial-temporal
reasoning, which remains a challenge for existing multimodal large language
models (MLLMs). In this work, we study the capabilities of MLLMs on a novel
task that jointly targets temporal change understanding and future scene
generation, aiming to assess their potential for modeling complex multimodal
dynamics over time. We propose TAMMs, a Temporal-Aware Multimodal Model for
satellite image change understanding and forecasting, which enhances frozen
MLLMs with lightweight temporal modules for structured sequence encoding and
contextual prompting. To guide future image generation, TAMMs introduces a
Semantic-Fused Control Injection (SFCI) mechanism that adaptively combines
high-level semantic reasoning and structural priors within an enhanced
ControlNet. This dual-path conditioning enables temporally consistent and
semantically grounded image synthesis. Experiments demonstrate that TAMMs
outperforms strong MLLM baselines in both temporal change understanding and
future image forecasting tasks, highlighting how carefully designed temporal
reasoning and semantic fusion can unlock the full potential of MLLMs for
spatio-temporal understanding.

</details>


### [286] [SpaNN: Detecting Multiple Adversarial Patches on CNNs by Spanning Saliency Thresholds](https://arxiv.org/abs/2506.18591)
*Mauricio Byrd Victorica,György Dán,Henrik Sandberg*

Main category: cs.CV

TL;DR: SpaNN是一种新型攻击检测器，其计算复杂度与对抗性补丁数量无关，通过二值化特征图集合和聚类检测攻击，优于现有防御方法。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法对多补丁攻击效果不佳或计算效率低，需一种更高效的检测器。

Method: SpaNN通过应用一组显著性阈值生成二值化特征图集合，进行聚类并分类检测攻击。

Result: 在四个数据集上，SpaNN在目标检测和图像分类任务中分别优于现有方法11%和27%。

Conclusion: SpaNN是一种高效且鲁棒的对抗性攻击检测器，适用于多补丁攻击场景。

Abstract: State-of-the-art convolutional neural network models for object detection and
image classification are vulnerable to physically realizable adversarial
perturbations, such as patch attacks. Existing defenses have focused,
implicitly or explicitly, on single-patch attacks, leaving their sensitivity to
the number of patches as an open question or rendering them computationally
infeasible or inefficient against attacks consisting of multiple patches in the
worst cases. In this work, we propose SpaNN, an attack detector whose
computational complexity is independent of the expected number of adversarial
patches. The key novelty of the proposed detector is that it builds an ensemble
of binarized feature maps by applying a set of saliency thresholds to the
neural activations of the first convolutional layer of the victim model. It
then performs clustering on the ensemble and uses the cluster features as the
input to a classifier for attack detection. Contrary to existing detectors,
SpaNN does not rely on a fixed saliency threshold for identifying adversarial
regions, which makes it robust against white box adversarial attacks. We
evaluate SpaNN on four widely used data sets for object detection and
classification, and our results show that SpaNN outperforms state-of-the-art
defenses by up to 11 and 27 percentage points in the case of object detection
and the case of image classification, respectively. Our code is available at
https://github.com/gerkbyrd/SpaNN.

</details>


### [287] [OmniAvatar: Efficient Audio-Driven Avatar Video Generation with Adaptive Body Animation](https://arxiv.org/abs/2506.18866)
*Qijun Gan,Ruizi Yang,Jianke Zhu,Shaofei Xue,Steven Hoi*

Main category: cs.CV

TL;DR: OmniAvatar是一个创新的音频驱动全身视频生成模型，通过改进的唇同步和自然动作增强人体动画。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注面部动作，难以生成自然同步和流畅的全身动画，且缺乏精细提示控制。

Method: 采用像素级多层级音频嵌入策略和LoRA训练方法，以更好地捕捉音频特征并保留提示控制能力。

Result: 实验表明，OmniAvatar在面部和半身视频生成方面优于现有模型，支持精确的文本控制。

Conclusion: OmniAvatar在多种场景下表现出色，为音频驱动动画提供了更全面的解决方案。

Abstract: Significant progress has been made in audio-driven human animation, while
most existing methods focus mainly on facial movements, limiting their ability
to create full-body animations with natural synchronization and fluidity. They
also struggle with precise prompt control for fine-grained generation. To
tackle these challenges, we introduce OmniAvatar, an innovative audio-driven
full-body video generation model that enhances human animation with improved
lip-sync accuracy and natural movements. OmniAvatar introduces a pixel-wise
multi-hierarchical audio embedding strategy to better capture audio features in
the latent space, enhancing lip-syncing across diverse scenes. To preserve the
capability for prompt-driven control of foundation models while effectively
incorporating audio features, we employ a LoRA-based training approach.
Extensive experiments show that OmniAvatar surpasses existing models in both
facial and semi-body video generation, offering precise text-based control for
creating videos in various domains, such as podcasts, human interactions,
dynamic scenes, and singing. Our project page is
https://omni-avatar.github.io/.

</details>


### [288] [RDPO: Real Data Preference Optimization for Physics Consistency Video Generation](https://arxiv.org/abs/2506.18655)
*Wenxu Qian,Chaoyue Wang,Hou Peng,Zhiyu Tan,Hao Li,Anxiang Zeng*

Main category: cs.CV

TL;DR: RDPO是一种无需标注的框架，通过从真实视频中提取物理先验，显著提升视频生成的动作连贯性和物理真实性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成技术在物理一致性上表现不足，而基于偏好的后训练方法成本高且不实用。

Method: RDPO通过反向采样真实视频序列自动构建偏好对，并通过多阶段迭代训练优化生成器。

Result: RDPO在多个基准测试和人工评估中均表现出显著改进。

Conclusion: RDPO通过利用真实视频的动态信息，有效提升了生成视频的物理一致性。

Abstract: Video generation techniques have achieved remarkable advancements in visual
quality, yet faithfully reproducing real-world physics remains elusive.
Preference-based model post-training may improve physical consistency, but
requires costly human-annotated datasets or reward models that are not yet
feasible. To address these challenges, we present Real Data Preference
Optimisation (RDPO), an annotation-free framework that distills physical priors
directly from real-world videos. Specifically, the proposed RDPO
reverse-samples real video sequences with a pre-trained generator to
automatically build preference pairs that are statistically distinguishable in
terms of physical correctness. A multi-stage iterative training schedule then
guides the generator to obey physical laws increasingly well. Benefiting from
the dynamic information explored from real videos, our proposed RDPO
significantly improves the action coherence and physical realism of the
generated videos. Evaluations on multiple benchmarks and human evaluations have
demonstrated that RDPO achieves improvements across multiple dimensions. The
source code and demonstration of this paper are available at:
https://wwenxu.github.io/RDPO/

</details>


### [289] [MedSeg-R: Medical Image Segmentation with Clinical Reasoning](https://arxiv.org/abs/2506.18669)
*Hao Shao,Qibin Hou*

Main category: cs.CV

TL;DR: MedSeg-R是一个轻量级双阶段框架，通过结合医学报告的语义先验和SAM主干网络，显著提升了小病灶分割的敏感性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临边界模糊和类别不平衡的挑战，现有方法依赖局部线索或用户提示，缺乏语义先验，难以泛化到低对比度或重叠目标。

Method: MedSeg-R分为认知阶段（解析医学报告为语义先验）和感知阶段（通过空间注意力、动态卷积和可变形采样调制SAM主干）。

Result: 在挑战性基准测试中，MedSeg-R显著提升了重叠和模糊结构的分割性能，展示了与SAM系统的兼容性。

Conclusion: MedSeg-R通过嵌入细粒度语义先验，有效解决了医学图像分割中的类别混淆和小病灶敏感性不足的问题。

Abstract: Medical image segmentation is challenging due to overlapping anatomies with
ambiguous boundaries and a severe imbalance between the foreground and
background classes, which particularly affects the delineation of small
lesions. Existing methods, including encoder-decoder networks and prompt-driven
variants of the Segment Anything Model (SAM), rely heavily on local cues or
user prompts and lack integrated semantic priors, thus failing to generalize
well to low-contrast or overlapping targets. To address these issues, we
propose MedSeg-R, a lightweight, dual-stage framework inspired by inspired by
clinical reasoning. Its cognitive stage interprets medical report into
structured semantic priors (location, texture, shape), which are fused via
transformer block. In the perceptual stage, these priors modulate the SAM
backbone: spatial attention highlights likely lesion regions, dynamic
convolution adapts feature filters to expected textures, and deformable
sampling refines spatial support. By embedding this fine-grained guidance
early, MedSeg-R disentangles inter-class confusion and amplifies minority-class
cues, greatly improving sensitivity to small lesions. In challenging
benchmarks, MedSeg-R produces large Dice improvements in overlapping and
ambiguous structures, demonstrating plug-and-play compatibility with SAM-based
systems.

</details>


### [290] [Reconstructing Tornadoes in 3D with Gaussian Splatting](https://arxiv.org/abs/2506.18677)
*Adam Yang,Nadula Kadawedduwa,Tianfu Wang,Maria Molina,Christopher Metzler*

Main category: cs.CV

TL;DR: 论文提出了一种基于实验室的小型龙卷风多视角数据集，并展示了使用3D高斯溅射（3DGS）技术有效重建其3D结构的方法。


<details>
  <summary>Details</summary>
Motivation: 准确重建龙卷风的3D结构对理解和应对这一破坏性天气现象至关重要，但目前缺乏可控的龙卷风数据集来开发和验证相关工具。

Method: 捕获并发布了一个实验室小型龙卷风的多视角数据集，并使用3DGS技术进行3D重建。

Result: 成功重建并可视化了龙卷风的3D结构。

Conclusion: 该数据集和方法为龙卷风3D结构的研究提供了有价值的工具和基准。

Abstract: Accurately reconstructing the 3D structure of tornadoes is critically
important for understanding and preparing for this highly destructive weather
phenomenon. While modern 3D scene reconstruction techniques, such as 3D
Gaussian splatting (3DGS), could provide a valuable tool for reconstructing the
3D structure of tornados, at present we are critically lacking a controlled
tornado dataset with which to develop and validate these tools. In this work we
capture and release a novel multiview dataset of a small lab-based tornado. We
demonstrate one can effectively reconstruct and visualize the 3D structure of
this tornado using 3DGS.

</details>


### [291] [MCN-SLAM: Multi-Agent Collaborative Neural SLAM with Hybrid Implicit Neural Scene Representation](https://arxiv.org/abs/2506.18678)
*Tianchen Deng,Guole Shen,Xun Chen,Shenghai Yuan,Hongming Shen,Guohao Peng,Zhenyu Wu,Jingchuan Wang,Lihua Xie,Danwei Wang,Hesheng Wang,Weidong Chen*

Main category: cs.CV

TL;DR: 提出首个分布式多智能体协作神经SLAM框架，结合混合场景表示、分布式相机跟踪、局部到全局闭环和在线蒸馏，并发布首个真实世界密集SLAM数据集。


<details>
  <summary>Details</summary>
Motivation: 现有隐式SLAM算法局限于单智能体场景，难以应对大规模场景和长序列，且现有NeRF多智能体SLAM框架无法满足通信带宽限制。

Method: 提出三平面网格联合场景表示方法、局部到全局闭环方法、在线蒸馏多子图融合方法，并构建真实世界DES数据集。

Result: 实验证明方法在映射、跟踪和通信方面表现优越。

Conclusion: 提出的框架和数据集推动了SLAM、3D重建和视觉基础模型的发展。

Abstract: Neural implicit scene representations have recently shown promising results
in dense visual SLAM. However, existing implicit SLAM algorithms are
constrained to single-agent scenarios, and fall difficulties in large-scale
scenes and long sequences. Existing NeRF-based multi-agent SLAM frameworks
cannot meet the constraints of communication bandwidth. To this end, we propose
the first distributed multi-agent collaborative neural SLAM framework with
hybrid scene representation, distributed camera tracking, intra-to-inter loop
closure, and online distillation for multiple submap fusion. A novel
triplane-grid joint scene representation method is proposed to improve scene
reconstruction. A novel intra-to-inter loop closure method is designed to
achieve local (single-agent) and global (multi-agent) consistency. We also
design a novel online distillation method to fuse the information of different
submaps to achieve global consistency. Furthermore, to the best of our
knowledge, there is no real-world dataset for NeRF-based/GS-based SLAM that
provides both continuous-time trajectories groundtruth and high-accuracy 3D
meshes groundtruth. To this end, we propose the first real-world Dense slam
(DES) dataset covering both single-agent and multi-agent scenarios, ranging
from small rooms to large-scale outdoor scenes, with high-accuracy ground truth
for both 3D mesh and continuous-time camera trajectory. This dataset can
advance the development of the research in both SLAM, 3D reconstruction, and
visual foundation model. Experiments on various datasets demonstrate the
superiority of the proposed method in both mapping, tracking, and
communication. The dataset and code will open-source on
https://github.com/dtc111111/mcnslam.

</details>


### [292] [MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation](https://arxiv.org/abs/2506.18679)
*Ruicheng Zhang,Yu Sun,Zeyu Zhang,Jinai Li,Xiaofan Liu,Au Hoi Fan,Haowei Guo,Puxin Yan*

Main category: cs.CV

TL;DR: MARL-MambaContour是一种基于多智能体强化学习的医学图像分割框架，通过生成拓扑一致的轮廓解决传统像素方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统像素分割方法缺乏拓扑约束和整体结构意识，无法适应医学图像中的模糊边缘和复杂形态。

Method: 将每个轮廓点建模为智能体，通过改进的SAC算法和ERAM机制优化调整，结合Mamba策略网络和BCHFM机制提升信息交换。

Result: 在五个医学影像数据集上表现出最先进的性能。

Conclusion: MARL-MambaContour是一种准确且鲁棒的临床分割工具。

Abstract: We introduce MARL-MambaContour, the first contour-based medical image
segmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our
approach reframes segmentation as a multi-agent cooperation task focused on
generate topologically consistent object-level contours, addressing the
limitations of traditional pixel-based methods which could lack topological
constraints and holistic structural awareness of anatomical regions. Each
contour point is modeled as an autonomous agent that iteratively adjusts its
position to align precisely with the target boundary, enabling adaptation to
blurred edges and intricate morphologies common in medical images. This
iterative adjustment process is optimized by a contour-specific Soft
Actor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization
Adjustment Mechanism (ERAM) which dynamically balance agent exploration with
contour smoothness. Furthermore, the framework incorporates a Mamba-based
policy network featuring a novel Bidirectional Cross-attention Hidden-state
Fusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion
limitations associated with long-range modeling in state space models, thereby
facilitating more accurate inter-agent information exchange and informed
decision-making. Extensive experiments on five diverse medical imaging datasets
demonstrate the state-of-the-art performance of MARL-MambaContour, highlighting
its potential as an accurate and robust clinical application.

</details>


### [293] [Including Semantic Information via Word Embeddings for Skeleton-based Action Recognition](https://arxiv.org/abs/2506.18721)
*Dustin Aganian,Erik Franze,Markus Eisenbach,Horst-Michael Gross*

Main category: cs.CV

TL;DR: 提出了一种基于骨架的动作识别新方法，通过词嵌入编码语义信息，显著提升了分类性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统骨架方法在复杂交互中丢失关键点语义，限制了其有效性。

Method: 利用词嵌入替换独热编码，生成语义体积，捕捉关节与物体间的有意义关系。

Result: 在多个装配数据集上实验表明，分类性能显著提升，同时支持不同骨架类型和物体类别。

Conclusion: 语义信息的引入能有效增强动态多样环境中的骨架动作识别。

Abstract: Effective human action recognition is widely used for cobots in Industry 4.0
to assist in assembly tasks. However, conventional skeleton-based methods often
lose keypoint semantics, limiting their effectiveness in complex interactions.
In this work, we introduce a novel approach to skeleton-based action
recognition that enriches input representations by leveraging word embeddings
to encode semantic information. Our method replaces one-hot encodings with
semantic volumes, enabling the model to capture meaningful relationships
between joints and objects. Through extensive experiments on multiple assembly
datasets, we demonstrate that our approach significantly improves
classification performance, and enhances generalization capabilities by
simultaneously supporting different skeleton types and object classes. Our
findings highlight the potential of incorporating semantic information to
enhance skeleton-based action recognition in dynamic and diverse environments.

</details>


### [294] [USVTrack: USV-Based 4D Radar-Camera Tracking Dataset for Autonomous Driving in Inland Waterways](https://arxiv.org/abs/2506.18737)
*Shanliang Yao,Runwei Guan,Yi Ni,Sen Xu,Yong Yue,Xiaohui Zhu,Ryan Wen Liu*

Main category: cs.CV

TL;DR: 论文提出了一种用于内河水道目标跟踪的USVTrack数据集和雷达-相机匹配方法（RCM），以提升自动驾驶在水上环境中的跟踪准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 内河水道目标跟踪对水上运输、观光、环境监测和救援等应用至关重要，但复杂环境下的跟踪仍具挑战性。

Method: 利用配备4D雷达、单目相机、GPS和IMU的无人水面艇（USV）收集数据，并提出RCM方法，可集成到两阶段关联跟踪器中。

Result: 实验证明RCM方法有效提高了水上环境中目标跟踪的准确性和可靠性。

Conclusion: USVTrack数据集和RCM方法为新一代水上自动驾驶系统提供了实用工具和数据支持。

Abstract: Object tracking in inland waterways plays a crucial role in safe and
cost-effective applications, including waterborne transportation, sightseeing
tours, environmental monitoring and surface rescue. Our Unmanned Surface
Vehicle (USV), equipped with a 4D radar, a monocular camera, a GPS, and an IMU,
delivers robust tracking capabilities in complex waterborne environments. By
leveraging these sensors, our USV collected comprehensive object tracking data,
which we present as USVTrack, the first 4D radar-camera tracking dataset
tailored for autonomous driving in new generation waterborne transportation
systems. Our USVTrack dataset presents rich scenarios, featuring diverse
various waterways, varying times of day, and multiple weather and lighting
conditions. Moreover, we present a simple but effective radar-camera matching
method, termed RCM, which can be plugged into popular two-stage association
trackers. Experimental results utilizing RCM demonstrate the effectiveness of
the radar-camera matching in improving object tracking accuracy and reliability
for autonomous driving in waterborne environments. The USVTrack dataset is
public on https://usvtrack.github.io.

</details>


### [295] [3D Arena: An Open Platform for Generative 3D Evaluation](https://arxiv.org/abs/2506.18787)
*Dylan Ebert*

Main category: cs.CV

TL;DR: 3D Arena是一个开放平台，通过大规模人类偏好收集评估图像到3D生成模型，解决了自动指标与人类感知质量之间的不一致问题。


<details>
  <summary>Details</summary>
Motivation: 当前评估生成3D模型的指标存在不足，图像指标忽略3D结构，几何指标无法捕捉感知吸引力和实际效用。

Method: 3D Arena平台通过成对比较收集人类偏好数据，使用ELO排名系统评估模型，并采用统计欺诈检测确保数据真实性。

Result: 收集了123,243票用户偏好数据，发现高斯泼溅输出比网格模型有16.6 ELO优势，带纹理模型比无纹理模型有144.1 ELO优势。

Conclusion: 3D Arena成为生成3D领域的基准平台，提供了多标准评估、任务导向评估和格式感知比较的建议，推动了以人为中心的评估方法。

Abstract: Evaluating Generative 3D models remains challenging due to misalignment
between automated metrics and human perception of quality. Current benchmarks
rely on image-based metrics that ignore 3D structure or geometric measures that
fail to capture perceptual appeal and real-world utility. To address this gap,
we present 3D Arena, an open platform for evaluating image-to-3D generation
models through large-scale human preference collection using pairwise
comparisons.
  Since launching in June 2024, the platform has collected 123,243 votes from
8,096 users across 19 state-of-the-art models, establishing the largest human
preference evaluation for Generative 3D. We contribute the iso3d dataset of 100
evaluation prompts and demonstrate quality control achieving 99.75% user
authenticity through statistical fraud detection. Our ELO-based ranking system
provides reliable model assessment, with the platform becoming an established
evaluation resource.
  Through analysis of this preference data, we present insights into human
preference patterns. Our findings reveal preferences for visual presentation
features, with Gaussian splat outputs achieving a 16.6 ELO advantage over
meshes and textured models receiving a 144.1 ELO advantage over untextured
models. We provide recommendations for improving evaluation methods, including
multi-criteria assessment, task-oriented evaluation, and format-aware
comparison. The platform's community engagement establishes 3D Arena as a
benchmark for the field while advancing understanding of human-centered
evaluation in Generative 3D.

</details>


### [296] [Focus Your Attention: Towards Data-Intuitive Lightweight Vision Transformers](https://arxiv.org/abs/2506.18791)
*Suyash Gaurav,Muhammad Farhan Humayun,Jukka Heikkonen,Jatin Chaudhary*

Main category: cs.CV

TL;DR: 提出了一种新的Super-Pixel Based Patch Pooling（SPPP）技术和Light Latent Attention（LLA）模块，以减少Vision Transformers的计算和内存需求，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在计算和内存资源上依赖性强，且任务特定迁移学习困难，主要源于计算密集的自注意力机制。

Method: 结合SPPP生成语义丰富的补丁嵌入，并引入LLA模块，通过潜在令牌集成减少注意力模块的时间和空间复杂度。

Result: 实验表明，该方法显著提高了计算效率，同时性能与现有最优方法相当。

Conclusion: 该方法为边缘部署提供了高效节能的Transformer解决方案。

Abstract: The evolution of Vision Transformers has led to their widespread adaptation
to different domains. Despite large-scale success, there remain significant
challenges including their reliance on extensive computational and memory
resources for pre-training on huge datasets as well as difficulties in
task-specific transfer learning. These limitations coupled with energy
inefficiencies mainly arise due to the computation-intensive self-attention
mechanism. To address these issues, we propose a novel Super-Pixel Based Patch
Pooling (SPPP) technique that generates context-aware, semantically rich, patch
embeddings to effectively reduce the architectural complexity and improve
efficiency. Additionally, we introduce the Light Latent Attention (LLA) module
in our pipeline by integrating latent tokens into the attention mechanism
allowing cross-attention operations to significantly reduce the time and space
complexity of the attention module. By leveraging the data-intuitive patch
embeddings coupled with dynamic positional encodings, our approach adaptively
modulates the cross-attention process to focus on informative regions while
maintaining the global semantic structure. This targeted attention improves
training efficiency and accelerates convergence. Notably, the SPPP module is
lightweight and can be easily integrated into existing transformer
architectures. Extensive experiments demonstrate that our proposed architecture
provides significant improvements in terms of computational efficiency while
achieving comparable results with the state-of-the-art approaches, highlighting
its potential for energy-efficient transformers suitable for edge deployment.
(The code is available on our GitHub repository:
https://github.com/zser092/Focused-Attention-ViT).

</details>


### [297] [ViDAR: Video Diffusion-Aware 4D Reconstruction From Monocular Inputs](https://arxiv.org/abs/2506.18792)
*Michal Nazarczuk,Sibi Catley-Chandar,Thomas Tanay,Zhensong Zhang,Gregory Slabaugh,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ViDAR是一种新的4D重建框架，利用个性化扩散模型生成伪多视角监督信号，用于训练高斯溅射表示，以解决动态新视角合成任务中的单目视频挑战。


<details>
  <summary>Details</summary>
Motivation: 动态新视角合成任务在单目视频中因结构-运动解耦的模糊性和监督稀缺而极具挑战性。

Method: ViDAR通过场景特定特征条件化，结合扩散感知损失函数和相机姿态优化策略，恢复细节并减少单目模糊性带来的伪影。

Result: 在DyCheck基准测试中，ViDAR在视觉质量和几何一致性上优于所有现有方法，尤其在动态区域表现突出。

Conclusion: ViDAR通过扩散感知监督和几何对齐策略，显著提升了动态场景的重建性能，并提供了新的基准测试。

Abstract: Dynamic Novel View Synthesis aims to generate photorealistic views of moving
subjects from arbitrary viewpoints. This task is particularly challenging when
relying on monocular video, where disentangling structure from motion is
ill-posed and supervision is scarce. We introduce Video Diffusion-Aware
Reconstruction (ViDAR), a novel 4D reconstruction framework that leverages
personalised diffusion models to synthesise a pseudo multi-view supervision
signal for training a Gaussian splatting representation. By conditioning on
scene-specific features, ViDAR recovers fine-grained appearance details while
mitigating artefacts introduced by monocular ambiguity. To address the
spatio-temporal inconsistency of diffusion-based supervision, we propose a
diffusion-aware loss function and a camera pose optimisation strategy that
aligns synthetic views with the underlying scene geometry. Experiments on
DyCheck, a challenging benchmark with extreme viewpoint variation, show that
ViDAR outperforms all state-of-the-art baselines in visual quality and
geometric consistency. We further highlight ViDAR's strong improvement over
baselines on dynamic regions and provide a new benchmark to compare performance
in reconstructing motion-rich parts of the scene. Project page:
https://vidar-4d.github.io

</details>


### [298] [PicoSAM2: Low-Latency Segmentation In-Sensor for Edge Vision Applications](https://arxiv.org/abs/2506.18807)
*Pietro Bonazzi,Nicola Farronato,Stefan Zihlmann,Haotong Qi,Michele Magno*

Main category: cs.CV

TL;DR: PicoSAM2是一个轻量级、可提示的分割模型，专为边缘和传感器内执行优化，满足实时性和隐私需求。


<details>
  <summary>Details</summary>
Motivation: 满足智能眼镜和物联网设备等对延迟敏感和隐私保护的应用需求。

Method: 基于深度可分离U-Net，结合知识蒸馏和固定点提示编码，从SAM2学习。

Result: 在COCO和LVIS上分别达到51.9%和44.9% mIoU，量化模型在IMX500上运行时间为14.3 ms。

Conclusion: PicoSAM2证明了高效、可提示的分割在传感器内直接执行的可行性，无需云端或主机处理。

Abstract: Real-time, on-device segmentation is critical for latency-sensitive and
privacy-aware applications like smart glasses and IoT devices. We introduce
PicoSAM2, a lightweight (1.3M parameters, 336M MACs) promptable segmentation
model optimized for edge and in-sensor execution, including the Sony IMX500. It
builds on a depthwise separable U-Net, with knowledge distillation and
fixed-point prompt encoding to learn from the Segment Anything Model 2 (SAM2).
On COCO and LVIS, it achieves 51.9% and 44.9% mIoU, respectively. The quantized
model (1.22MB) runs at 14.3 ms on the IMX500-achieving 86 MACs/cycle, making it
the only model meeting both memory and compute constraints for in-sensor
deployment. Distillation boosts LVIS performance by +3.5% mIoU and +5.1% mAP.
These results demonstrate that efficient, promptable segmentation is feasible
directly on-camera, enabling privacy-preserving vision without cloud or host
processing.

</details>


### [299] [4Real-Video-V2: Fused View-Time Attention and Feedforward Reconstruction for 4D Scene Generation](https://arxiv.org/abs/2506.18839)
*Chaoyang Wang,Ashkan Mirzaei,Vidit Goel,Willi Menapace,Aliaksandr Siarohin,Avalon Vinella,Michael Vasilkovsky,Ivan Skorokhodov,Vladislav Shakhrai,Sergey Korolev,Sergey Tulyakov,Peter Wonka*

Main category: cs.CV

TL;DR: 提出首个4D时空网格与3D高斯粒子框架，采用前馈架构，融合空间与时间注意力，提升4D生成质量与重建能力。


<details>
  <summary>Details</summary>
Motivation: 现有4D视频扩散架构在空间和时间注意力处理上存在局限性，需改进以实现更高效的4D生成与重建。

Method: 提出融合架构，单层处理空间与时间注意力；扩展3D重建算法，引入高斯头、相机令牌替换及动态层训练。

Result: 在4D生成领域达到新SOTA，视觉质量与重建能力均显著提升。

Conclusion: 融合架构与扩展算法有效解决了现有问题，为4D生成提供了更优解决方案。

Abstract: We propose the first framework capable of computing a 4D spatio-temporal grid
of video frames and 3D Gaussian particles for each time step using a
feed-forward architecture. Our architecture has two main components, a 4D video
model and a 4D reconstruction model. In the first part, we analyze current 4D
video diffusion architectures that perform spatial and temporal attention
either sequentially or in parallel within a two-stream design. We highlight the
limitations of existing approaches and introduce a novel fused architecture
that performs spatial and temporal attention within a single layer. The key to
our method is a sparse attention pattern, where tokens attend to others in the
same frame, at the same timestamp, or from the same viewpoint. In the second
part, we extend existing 3D reconstruction algorithms by introducing a Gaussian
head, a camera token replacement algorithm, and additional dynamic layers and
training. Overall, we establish a new state of the art for 4D generation,
improving both visual quality and reconstruction capability.

</details>


### [300] [Phantom-Data : Towards a General Subject-Consistent Video Generation Dataset](https://arxiv.org/abs/2506.18851)
*Zhuowei Chen,Bingchuan Li,Tianxiang Ma,Lijie Liu,Mingcong Liu,Yi Zhang,Gen Li,Xinghui Li,Siyu Zhou,Qian He,Xinglong Wu*

Main category: cs.CV

TL;DR: 论文提出了一种名为Phantom-Data的跨对主题到视频一致性数据集，解决了现有模型在遵循文本指令时的复制粘贴问题。


<details>
  <summary>Details</summary>
Motivation: 现有主题到视频生成模型因使用同场景参考图像训练，导致主题身份与背景和上下文属性纠缠，难以忠实遵循文本指令。

Method: 通过三阶段流程构建数据集：1)通用且输入对齐的主题检测模块；2)从5300万视频和30亿图像中检索跨上下文主题；3)先验引导的身份验证以确保视觉一致性。

Result: 实验表明，使用Phantom-Data训练显著提升了提示对齐和视觉质量，同时保持了与基线相当的身份一致性。

Conclusion: Phantom-Data为解决主题到视频生成中的复制粘贴问题提供了有效解决方案，提升了模型的性能。

Abstract: Subject-to-video generation has witnessed substantial progress in recent
years. However, existing models still face significant challenges in faithfully
following textual instructions. This limitation, commonly known as the
copy-paste problem, arises from the widely used in-pair training paradigm. This
approach inherently entangles subject identity with background and contextual
attributes by sampling reference images from the same scene as the target
video. To address this issue, we introduce \textbf{Phantom-Data, the first
general-purpose cross-pair subject-to-video consistency dataset}, containing
approximately one million identity-consistent pairs across diverse categories.
Our dataset is constructed via a three-stage pipeline: (1) a general and
input-aligned subject detection module, (2) large-scale cross-context subject
retrieval from more than 53 million videos and 3 billion images, and (3)
prior-guided identity verification to ensure visual consistency under
contextual variation. Comprehensive experiments show that training with
Phantom-Data significantly improves prompt alignment and visual quality while
preserving identity consistency on par with in-pair baselines.

</details>


### [301] [RAG-6DPose: Retrieval-Augmented 6D Pose Estimation via Leveraging CAD as Knowledge Base](https://arxiv.org/abs/2506.18856)
*Kuanning Wang,Yuqian Fu,Tianyu Wang,Yanwei Fu,Longfei Liang,Yu-Gang Jiang,Xiangyang Xue*

Main category: cs.CV

TL;DR: RAG-6DPose提出了一种基于检索增强的6D姿态估计方法，结合视觉和几何线索，利用3D CAD模型作为知识库，显著提升了姿态估计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 精确的6D姿态估计对机器人操作（如抓取）至关重要，但现有方法在遮挡和新视角下表现不佳。

Method: 方法分为三阶段：1) 构建多模态CAD知识库；2) 通过ReSPC模块检索相关CAD特征；3) 通过检索增强解码优化姿态预测。

Result: 在标准基准和实际机器人任务中验证了方法的有效性和鲁棒性，尤其在处理遮挡和新视角时表现突出。

Conclusion: RAG-6DPose通过检索增强方法显著提升了6D姿态估计的性能，适用于复杂场景。

Abstract: Accurate 6D pose estimation is key for robotic manipulation, enabling precise
object localization for tasks like grasping. We present RAG-6DPose, a
retrieval-augmented approach that leverages 3D CAD models as a knowledge base
by integrating both visual and geometric cues. Our RAG-6DPose roughly contains
three stages: 1) Building a Multi-Modal CAD Knowledge Base by extracting 2D
visual features from multi-view CAD rendered images and also attaching 3D
points; 2) Retrieving relevant CAD features from the knowledge base based on
the current query image via our ReSPC module; and 3) Incorporating retrieved
CAD information to refine pose predictions via retrieval-augmented decoding.
Experimental results on standard benchmarks and real-world robotic tasks
demonstrate the effectiveness and robustness of our approach, particularly in
handling occlusions and novel viewpoints. Supplementary material is available
on our project website: https://sressers.github.io/RAG-6DPose .

</details>


### [302] [Let Your Video Listen to Your Music!](https://arxiv.org/abs/2506.18881)
*Xinyu Zhang,Dong Gong,Zicheng Duan,Anton van den Hengel,Lingqiao Liu*

Main category: cs.CV

TL;DR: MVAA框架通过两步自动对齐视频与音乐节奏，保留原始内容并提升视觉流畅性。


<details>
  <summary>Details</summary>
Motivation: 视频与音乐节奏对齐是多媒体制作的实际需求，但现有方法依赖手动或启发式技术，缺乏灵活性。

Method: MVAA分为两步：对齐关键帧与音频节拍，再通过扩散模型生成连贯中间帧。采用两阶段训练策略提升效率。

Result: 实验表明MVAA能高质量对齐节拍并保持视觉流畅性，适应时间短（10分钟内）。

Conclusion: MVAA提供了一种高效、灵活的视频与音乐自动对齐方法，适用于多种多媒体场景。

Abstract: Aligning the rhythm of visual motion in a video with a given music track is a
practical need in multimedia production, yet remains an underexplored task in
autonomous video editing. Effective alignment between motion and musical beats
enhances viewer engagement and visual appeal, particularly in music videos,
promotional content, and cinematic editing. Existing methods typically depend
on labor-intensive manual cutting, speed adjustments, or heuristic-based
editing techniques to achieve synchronization. While some generative models
handle joint video and music generation, they often entangle the two
modalities, limiting flexibility in aligning video to music beats while
preserving the full visual content. In this paper, we propose a novel and
efficient framework, termed MVAA (Music-Video Auto-Alignment), that
automatically edits video to align with the rhythm of a given music track while
preserving the original visual content. To enhance flexibility, we modularize
the task into a two-step process in our MVAA: aligning motion keyframes with
audio beats, followed by rhythm-aware video inpainting. Specifically, we first
insert keyframes at timestamps aligned with musical beats, then use a
frame-conditioned diffusion model to generate coherent intermediate frames,
preserving the original video's semantic content. Since comprehensive test-time
training can be time-consuming, we adopt a two-stage strategy: pretraining the
inpainting module on a small video set to learn general motion priors, followed
by rapid inference-time fine-tuning for video-specific adaptation. This hybrid
approach enables adaptation within 10 minutes with one epoch on a single NVIDIA
4090 GPU using CogVideoX-5b-I2V as the backbone. Extensive experiments show
that our approach can achieve high-quality beat alignment and visual
smoothness.

</details>


### [303] [Light of Normals: Unified Feature Representation for Universal Photometric Stereo](https://arxiv.org/abs/2506.18882)
*Hong Li,Houyuan Chen,Chongjie Ye,Zhaoxi Chen,Bohan Li,Shaocong Xu,Xianda Guo,Xuhui Liu,Yikai Wang,Baochang Zhang,Satoshi Ikehata,Boxin Shi,Anyi Rao,Hao Zhao*

Main category: cs.CV

TL;DR: 通用光度立体（PS）旨在从任意光照条件下的物体中恢复高质量表面法线，无需依赖特定光照模型。尽管有SDM-UniPS和Uni MS-PS等进展，仍存在两个核心挑战：光照与法线特征的深度耦合，以及复杂表面高频几何细节的保留。


<details>
  <summary>Details</summary>
Motivation: 解决在任意光照条件下恢复高质量表面法线的需求，克服光照变化与表面法线特征耦合的模糊性，以及保留复杂表面的高频几何细节。

Method: 通过通用光度立体方法，不依赖特定光照模型，处理光照变化与法线特征的耦合问题，并优化特征处理以捕捉高频几何细节。

Result: 尽管有进展，仍存在光照与法线特征耦合的模糊性及高频细节保留的挑战。

Conclusion: 通用光度立体仍需进一步研究以解决光照与法线特征的耦合问题，并提升高频几何细节的恢复能力。

Abstract: Universal photometric stereo (PS) aims to recover high-quality surface
normals from objects under arbitrary lighting conditions without relying on
specific illumination models. Despite recent advances such as SDM-UniPS and Uni
MS-PS, two fundamental challenges persist: 1) the deep coupling between varying
illumination and surface normal features, where ambiguity in observed intensity
makes it difficult to determine whether brightness variations stem from
lighting changes or surface orientation; and 2) the preservation of
high-frequency geometric details in complex surfaces, where intricate
geometries create self-shadowing, inter-reflections, and subtle normal
variations that conventional feature processing operations struggle to capture
accurately.

</details>


### [304] [Universal Video Temporal Grounding with Generative Multi-modal Large Language Models](https://arxiv.org/abs/2506.18883)
*Zeqian Li,Shangzhe Di,Zhonghua Zhai,Weilin Huang,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: 提出UniTime模型，利用生成式多模态大语言模型（MLLMs）实现通用视频时间定位，支持多样视频和复杂语言查询，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频时间定位方法局限于特定领域或时长，无法通用化处理多样视频和复杂查询。

Method: 结合时间戳标记与视频标记，通过自适应帧缩放处理不同长度视频，利用MLLMs进行时间定位。

Result: 在五个公开基准测试中，UniTime在零样本和微调设置下均优于现有方法，并显著提升长视频问答准确率。

Conclusion: UniTime是一种通用且鲁棒的视频时间定位模型，适用于复杂视频理解任务。

Abstract: This paper presents a computational model for universal video temporal
grounding, which accurately localizes temporal moments in videos based on
natural language queries (e.g., questions or descriptions). Unlike existing
methods that are often limited to specific video domains or durations, we
propose UniTime, a robust and universal video grounding model leveraging the
strong vision-language understanding capabilities of generative Multi-modal
Large Language Models (MLLMs). Our model effectively handles videos of diverse
views, genres, and lengths while comprehending complex language queries. The
key contributions include: (i) We consider steering strong MLLMs for temporal
grounding in videos. To enable precise timestamp outputs, we incorporate
temporal information by interleaving timestamp tokens with video tokens. (ii)
By training the model to handle videos with different input granularities
through adaptive frame scaling, our approach achieves robust temporal grounding
for both short and long videos. (iii) Comprehensive experiments show that
UniTime outperforms state-of-the-art approaches in both zero-shot and
dataset-specific finetuned settings across five public temporal grounding
benchmarks. (iv) When employed as a preliminary moment retriever for long-form
video question-answering (VideoQA), UniTime significantly improves VideoQA
accuracy, highlighting its value for complex video understanding tasks.

</details>


### [305] [4D-LRM: Large Space-Time Reconstruction Model From and To Any View at Any Time](https://arxiv.org/abs/2506.18890)
*Ziqiao Ma,Xuweiyi Chen,Shoubin Yu,Sai Bi,Kai Zhang,Chen Ziwen,Sihan Xu,Jianing Yang,Zexiang Xu,Kalyan Sunkavalli,Mohit Bansal,Joyce Chai,Hao Tan*

Main category: cs.CV

TL;DR: 4D-LRM是一种大规模4D重建模型，能够从任意视角和时间输入生成任意视角和时间的渲染，解决了传统方法在效率、泛化性和准确性上的问题。


<details>
  <summary>Details</summary>
Motivation: 探索是否可以通过4D预训练学习通用的时空表示，从少量视角和时间重建物体到任意视角和时间。

Method: 4D-LRM通过学习统一的时空表示，直接从时间序列的位姿图像标记预测每像素的4D高斯基元，实现快速高质量渲染。

Result: 4D-LRM在单次前向传播中重建24帧序列，耗时少于1.5秒，泛化能力强，支持新物体和时间插值。

Conclusion: 通过扩展时空预训练，4D-LRM实现了高效准确的4D重建，具有广泛的应用潜力。

Abstract: Can we scale 4D pretraining to learn general space-time representations that
reconstruct an object from a few views at some times to any view at any time?
We provide an affirmative answer with 4D-LRM, the first large-scale 4D
reconstruction model that takes input from unconstrained views and timestamps
and renders arbitrary novel view-time combinations. Unlike prior 4D approaches,
e.g., optimization-based, geometry-based, or generative, that struggle with
efficiency, generalization, or faithfulness, 4D-LRM learns a unified space-time
representation and directly predicts per-pixel 4D Gaussian primitives from
posed image tokens across time, enabling fast, high-quality rendering at, in
principle, infinite frame rate. Our results demonstrate that scaling
spatiotemporal pretraining enables accurate and efficient 4D reconstruction. We
show that 4D-LRM generalizes to novel objects, interpolates across time, and
handles diverse camera setups. It reconstructs 24-frame sequences in one
forward pass with less than 1.5 seconds on a single A100 GPU.

</details>


### [306] [FilMaster: Bridging Cinematic Principles and Generative AI for Automated Film Generation](https://arxiv.org/abs/2506.18899)
*Kaiyi Huang,Yukun Huang,Xintao Wang,Zinan Lin,Xuefei Ning,Pengfei Wan,Di Zhang,Yu Wang,Xihui Liu*

Main category: cs.CV

TL;DR: FilMaster是一个端到端AI系统，通过整合真实世界的电影原则生成专业级电影，解决了现有系统在电影语言和节奏上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有电影生成系统缺乏多样化的镜头语言和电影节奏，导致视觉效果模板化和叙事不吸引人。

Method: FilMaster基于两个关键原则：从大量真实电影数据学习摄影技术，并模拟以观众为中心的后期制作流程。系统分为参考引导生成阶段和生成后期制作阶段。

Result: FilMaster在镜头语言设计和电影节奏控制方面表现优异，并通过FilmEval基准验证其性能。

Conclusion: FilMaster通过整合专业电影原则和生成AI模型，推动了专业电影制作中生成AI的进步。

Abstract: AI-driven content creation has shown potential in film production. However,
existing film generation systems struggle to implement cinematic principles and
thus fail to generate professional-quality films, particularly lacking diverse
camera language and cinematic rhythm. This results in templated visuals and
unengaging narratives. To address this, we introduce FilMaster, an end-to-end
AI system that integrates real-world cinematic principles for
professional-grade film generation, yielding editable, industry-standard
outputs. FilMaster is built on two key principles: (1) learning cinematography
from extensive real-world film data and (2) emulating professional,
audience-centric post-production workflows. Inspired by these principles,
FilMaster incorporates two stages: a Reference-Guided Generation Stage which
transforms user input to video clips, and a Generative Post-Production Stage
which transforms raw footage into audiovisual outputs by orchestrating visual
and auditory elements for cinematic rhythm. Our generation stage highlights a
Multi-shot Synergized RAG Camera Language Design module to guide the AI in
generating professional camera language by retrieving reference clips from a
vast corpus of 440,000 film clips. Our post-production stage emulates
professional workflows by designing an Audience-Centric Cinematic Rhythm
Control module, including Rough Cut and Fine Cut processes informed by
simulated audience feedback, for effective integration of audiovisual elements
to achieve engaging content. The system is empowered by generative AI models
like (M)LLMs and video generation models. Furthermore, we introduce FilmEval, a
comprehensive benchmark for evaluating AI-generated films. Extensive
experiments show FilMaster's superior performance in camera language design and
cinematic rhythm control, advancing generative AI in professional filmmaking.

</details>


### [307] [Audit & Repair: An Agentic Framework for Consistent Story Visualization in Text-to-Image Diffusion Models](https://arxiv.org/abs/2506.18900)
*Kiymet Akdemir,Tahira Kazimi,Pinar Yanardag*

Main category: cs.CV

TL;DR: 提出了一种多智能体协作框架，用于解决故事可视化中的视觉一致性问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 故事可视化中保持角色和对象的一致性是关键挑战，现有方法常导致不连贯的叙事。

Method: 采用多智能体框架，通过迭代循环自主识别、纠正和优化不一致性，支持多种扩散模型。

Result: 定量和定性实验表明，该方法在多面板一致性上优于现有方法。

Conclusion: 提出的框架灵活且高效，显著提升了故事可视化的视觉一致性。

Abstract: Story visualization has become a popular task where visual scenes are
generated to depict a narrative across multiple panels. A central challenge in
this setting is maintaining visual consistency, particularly in how characters
and objects persist and evolve throughout the story. Despite recent advances in
diffusion models, current approaches often fail to preserve key character
attributes, leading to incoherent narratives. In this work, we propose a
collaborative multi-agent framework that autonomously identifies, corrects, and
refines inconsistencies across multi-panel story visualizations. The agents
operate in an iterative loop, enabling fine-grained, panel-level updates
without re-generating entire sequences. Our framework is model-agnostic and
flexibly integrates with a variety of diffusion models, including rectified
flow transformers such as Flux and latent diffusion models such as Stable
Diffusion. Quantitative and qualitative experiments show that our method
outperforms prior approaches in terms of multi-panel consistency.

</details>


### [308] [From Virtual Games to Real-World Play](https://arxiv.org/abs/2506.18901)
*Wenqiang Sun,Fangyun Wei,Jinjing Zhao,Xi Chen,Zilong Chen,Hongyang Zhang,Jun Zhang,Yan Lu*

Main category: cs.CV

TL;DR: RealPlay是一个基于神经网络的实时游戏引擎，能够通过用户控制信号生成交互式视频，目标是生成逼真且时间一致的视频序列。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有工作局限于游戏风格视觉效果的问题，实现逼真且交互性强的视频生成。

Method: 采用迭代分块预测、时间一致性维护和准确控制响应等技术，结合标记游戏数据和无标记真实视频进行训练。

Result: 实现了控制信号从虚拟到真实场景的迁移，并能泛化控制多种真实世界实体（如自行车、行人）。

Conclusion: RealPlay展示了在无需真实动作标注的情况下，生成逼真交互视频的潜力。

Abstract: We introduce RealPlay, a neural network-based real-world game engine that
enables interactive video generation from user control signals. Unlike prior
works focused on game-style visuals, RealPlay aims to produce photorealistic,
temporally consistent video sequences that resemble real-world footage. It
operates in an interactive loop: users observe a generated scene, issue a
control command, and receive a short video chunk in response. To enable such
realistic and responsive generation, we address key challenges including
iterative chunk-wise prediction for low-latency feedback, temporal consistency
across iterations, and accurate control response. RealPlay is trained on a
combination of labeled game data and unlabeled real-world videos, without
requiring real-world action annotations. Notably, we observe two forms of
generalization: (1) control transfer-RealPlay effectively maps control signals
from virtual to real-world scenarios; and (2) entity transfer-although training
labels originate solely from a car racing game, RealPlay generalizes to control
diverse real-world entities, including bicycles and pedestrians, beyond
vehicles. Project page can be found: https://wenqsun.github.io/RealPlay/

</details>


### [309] [VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory](https://arxiv.org/abs/2506.18903)
*Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab*

Main category: cs.CV

TL;DR: 提出了一种名为Surfel-Indexed View Memory (VMem)的新型记忆机制，用于构建能够交互式探索环境的视频生成器，解决了现有方法在长期场景一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如2D场景外绘和短上下文窗口视频生成器）在长期场景一致性和计算效率上存在局限。

Method: 引入VMem机制，通过3D表面元素（surfels）几何索引过去视图，高效检索相关视图以生成新视图。

Result: 在长期场景合成基准测试中表现优异，显著提升了场景一致性和相机控制能力。

Conclusion: VMem机制在保持场景一致性和降低计算成本方面优于现有方法。

Abstract: We propose a novel memory mechanism to build video generators that can
explore environments interactively. Similar results have previously been
achieved by out-painting 2D views of the scene while incrementally
reconstructing its 3D geometry, which quickly accumulates errors, or by video
generators with a short context window, which struggle to maintain scene
coherence over the long term. To address these limitations, we introduce
Surfel-Indexed View Memory (VMem), a mechanism that remembers past views by
indexing them geometrically based on the 3D surface elements (surfels) they
have observed. VMem enables the efficient retrieval of the most relevant past
views when generating new ones. By focusing only on these relevant views, our
method produces consistent explorations of imagined environments at a fraction
of the computational cost of using all past views as context. We evaluate our
approach on challenging long-term scene synthesis benchmarks and demonstrate
superior performance compared to existing methods in maintaining scene
coherence and camera control.

</details>


### [310] [TC-Light: Temporally Consistent Relighting for Dynamic Long Videos](https://arxiv.org/abs/2506.18904)
*Yang Liu,Chuanchen Luo,Zimo Tang,Yingyan Li,Yuran Yang,Yuanyong Ning,Lue Fan,Junran Peng,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: TC-Light是一种新的视频重光照方法，通过两阶段优化机制实现高效且时间一致的光照编辑。


<details>
  <summary>Details</summary>
Motivation: 现有视频重光照技术主要局限于肖像视频或面临时间一致性和计算效率的瓶颈，需要一种更通用的解决方案。

Method: 提出两阶段后优化机制：第一阶段优化外观嵌入以对齐全局光照，第二阶段优化唯一视频张量（UVT）以对齐细粒度纹理和光照。

Result: 实验表明，TC-Light能够实现物理上合理且时间一致的重光照效果，同时计算成本低。

Conclusion: TC-Light为复杂动态视频的光照编辑提供了一种高效且一致的解决方案。

Abstract: Editing illumination in long videos with complex dynamics has significant
value in various downstream tasks, including visual content creation and
manipulation, as well as data scaling up for embodied AI through sim2real and
real2real transfer. Nevertheless, existing video relighting techniques are
predominantly limited to portrait videos or fall into the bottleneck of
temporal consistency and computation efficiency. In this paper, we propose
TC-Light, a novel paradigm characterized by the proposed two-stage post
optimization mechanism. Starting from the video preliminarily relighted by an
inflated video relighting model, it optimizes appearance embedding in the first
stage to align global illumination. Then it optimizes the proposed canonical
video representation, i.e., Unique Video Tensor (UVT), to align fine-grained
texture and lighting in the second stage. To comprehensively evaluate
performance, we also establish a long and highly dynamic video benchmark.
Extensive experiments show that our method enables physically plausible
relighting results with superior temporal coherence and low computation cost.
The code and video demos are available at
https://dekuliutesla.github.io/tclight/.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [311] [DCMF: A Dynamic Context Monitoring and Caching Framework for Context Management Platforms](https://arxiv.org/abs/2506.17226)
*Ashish Manchanda,Prem Prakash Jayaraman,Abhik Banerjee,Kaneez Fizza,Arkady Zaslavsky*

Main category: cs.DB

TL;DR: 论文提出了一种动态上下文监控框架（DCMF），用于优化物联网（IoT）环境中的上下文缓存，通过动态评估和管理上下文，显著提高了缓存命中率并减少了缓存过期。


<details>
  <summary>Details</summary>
Motivation: 随着上下文感知物联网应用的兴起，对实时且准确的上下文信息的需求增加。传统缓存策略难以应对上下文的高动态性和实时性要求。

Method: DCMF包含上下文评估引擎（CEE）和上下文管理模块（CMM）。CEE基于服务质量（QoS）、上下文质量（QoC）等参数计算访问概率（PoA），CMM采用Dempster-Shafer方法管理上下文新鲜度（CF）。

Result: 在真实智能城市数据（如交通和道路施工场景）的测试中，DCMF的缓存命中率提高了12.5%，缓存过期减少了60%。

Conclusion: DCMF在动态上下文感知物联网环境中表现出良好的可扩展性和适用性，能够确保上下文的及时交付和低延迟。

Abstract: The rise of context-aware IoT applications has increased the demand for
timely and accurate context information. Context is derived by aggregating and
inferring from dynamic IoT data, making it highly volatile and posing
challenges in maintaining freshness and real-time accessibility. Caching is a
potential solution, but traditional policies struggle with the transient nature
of context in IoT (e.g., ensuring real-time access for frequent queries or
handling fast-changing data). To address this, we propose the Dynamic Context
Monitoring Framework (DCMF) to enhance context caching in Context Management
Platforms (CMPs) by dynamically evaluating and managing context. DCMF comprises
two core components: the Context Evaluation Engine (CEE) and the Context
Management Module (CMM). The CEE calculates the Probability of Access (PoA)
using parameters such as Quality of Service (QoS), Quality of Context (QoC),
Cost of Context (CoC), timeliness, and Service Level Agreements (SLAs),
assigning weights to assess access likelihood. Based on this, the CMM applies a
hybrid Dempster-Shafer approach to manage Context Freshness (CF), updating
belief levels and confidence scores to determine whether to cache, evict, or
refresh context items. We implemented DCMF in a Context-as-a-Service (CoaaS)
platform and evaluated it using real-world smart city data, particularly
traffic and roadwork scenarios. Results show DCMF achieves a 12.5% higher cache
hit rate and reduces cache expiry by up to 60% compared to the m-CAC technique,
ensuring timely delivery of relevant context and reduced latency. These results
demonstrate DCMF's scalability and suitability for dynamic context-aware IoT
environments.

</details>


### [312] [Transient Concepts in Streaming Graphs](https://arxiv.org/abs/2506.17451)
*Aida Sheshbolouki,M. Tamer Ozsu*

Main category: cs.DB

TL;DR: 论文提出了两种新框架SGDD和SGDP，用于流图环境下的概念漂移检测和预测，解决了现有方法在动态数据管理中的局限性。


<details>
  <summary>Details</summary>
Motivation: 概念漂移在非静态数据流中普遍存在，现有方法在流图场景下效果不佳，亟需新的解决方案。

Method: 引入SGDD和SGDP框架，分别用于检测和预测流图中的概念漂移，无需访问数据记录的有效载荷。

Result: SGDD能检测生成参数变化导致的概念漂移，但存在显著延迟；SGDP则能在概念漂移发生前7374至0.19毫秒进行预测。

Conclusion: SGDD和SGDP为流图环境下的概念漂移问题提供了有效的检测和预测工具，弥补了现有方法的不足。

Abstract: Concept Drift (CD) occurs when a change in a hidden context can induce
changes in a target concept. CD is a natural phenomenon in non-stationary
settings such as data streams. Understanding, detection, and adaptation to CD
in streaming data is (i) vital for effective and efficient analytics as
reliable output depends on adaptation to fresh input, (ii) challenging as it
requires efficient operations as well as effective performance evaluations, and
(iii) impactful as it applies to a variety of use cases and is a crucial
initial step for data management systems. Current works are mostly focused on
passive CD detection as part of supervised adaptation, on independently
generated data instances or graph snapshots, on target concepts as a function
of data labels, on static data management, and on specific temporal order of
data record. These methods do not always work. We revisit CD for the streaming
graphs setting and introduce two first-of-its-kind frameworks SGDD and SGDP for
streaming graph CD detection and prediction. Both frameworks discern the change
of generative source. SGDD detects the CDs due to the changes of generative
parameters with significant delays such that it is difficult to evaluate the
performance, while SGDP predicts these CDs between 7374 to 0.19 milliseconds
ahead of their occurrence, without accessing the payloads of data records.

</details>


### [313] [Lower Bounds for Conjunctive Query Evaluation](https://arxiv.org/abs/2506.17702)
*Stefan Mengel*

Main category: cs.DB

TL;DR: 综述了不同设置下联合查询评估的复杂性，并探讨了复杂性理论中的假设如何影响查询回答。


<details>
  <summary>Details</summary>
Motivation: 探讨联合查询评估在不同场景下的复杂性，并展示复杂性理论假设如何限制算法的改进空间。

Method: 调查了布尔查询、计数、枚举和直接访问等不同模型中的已知结果。

Result: 展示了复杂性理论假设如何证明某些已知算法在特定情况下无法进一步优化。

Conclusion: 复杂性理论假设为联合查询评估的算法优化提供了理论限制，揭示了进一步改进的难度。

Abstract: In this tutorial, we will survey known results on the complexity of
conjunctive query evaluation in different settings, ranging from Boolean
queries over counting to more complex models like enumeration and direct
access. A particular focus will be on showing how different relatively recent
hypotheses from complexity theory connect to query answering and allow showing
that known algorithms in several cases can likely not be improved.

</details>


### [314] [Dual-Hierarchy Labelling: Scaling Up Distance Queries on Dynamic Road Networks](https://arxiv.org/abs/2506.18013)
*Muhammad Farhan,Henning Koehler,Qing Wang*

Main category: cs.DB

TL;DR: 提出了一种名为Dual-Hierarchy Labelling (DHL)的高效方法，用于动态道路网络中的最短路径查询，通过双层次结构和动态算法显著提升了查询和更新效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态道路网络中表现不佳，查询响应慢或维护效率低，尤其是大规模网络。需要一种更高效的解决方案。

Method: DHL结合了查询层次、更新层次和层次标签三种组件，支持高效查询和动态更新。还提出了并行动态算法。

Result: 在10个大型道路网络上测试，DHL在构建、更新和查询速度上显著优于现有方法，标签空间仅占用10%-20%。

Conclusion: DHL为动态道路网络中的最短路径查询提供了一种高效且节省资源的解决方案。

Abstract: Computing the shortest-path distance between any two given vertices in road
networks is an important problem. A tremendous amount of research has been
conducted to address this problem, most of which are limited to static road
networks. Since road networks undergo various real-time traffic conditions,
there is a pressing need to address this problem for dynamic road networks.
Existing state-of-the-art methods incrementally maintain an indexing structure
to reflect dynamic changes on road networks. However, these methods suffer from
either slow query response time or poor maintenance performance, particularly
when road networks are large. In this work, we propose an efficient solution
\emph{Dual-Hierarchy Labelling (DHL)} for distance querying on dynamic road
networks from a novel perspective, which incorporates two hierarchies with
different but complementary data structures to support efficient query and
update processing. Specifically, our proposed solution is comprised of three
main components: \emph{query hierarchy}, \emph{update hierarchy}, and
\emph{hierarchical labelling}, where \emph{query hierarchy} enables efficient
query answering by exploring only a small subset of vertices in the labels of
two query vertices and \emph{update hierarchy} supports efficient maintenance
of distance labelling under edge weight increase or decrease. We further
develop dynamic algorithms to reflect dynamic changes by efficiently
maintaining the update hierarchy and hierarchical labelling. We also propose a
parallel variant of our dynamic algorithms by exploiting labelling structure.
We evaluate our methods on 10 large road networks and it shows that our methods
significantly outperform the state-of-the-art methods, i.e., achieving
considerably faster construction and update time, while being consistently 2-4
times faster in terms of query processing and consuming only 10\%-20\%
labelling space.

</details>


### [315] [Floating-Point Data Transformation for Lossless Compression](https://arxiv.org/abs/2506.18062)
*Samirasadat Jamalidinan,Kazem Cheshmi*

Main category: cs.DB

TL;DR: 提出了一种名为Typed Data Transformation (DTT)的新方法，通过将相关字节分组以提高浮点数据的压缩效率。


<details>
  <summary>Details</summary>
Motivation: 浮点数据在多个领域广泛应用，且对精度要求高，因此无损压缩至关重要。现有方法未能充分利用数据中的模式。

Method: 提出DTT方法，通过将相关字节分组以利用浮点表示中的固有模式。

Result: 在CPU和GPU上测试，DTT的几何平均压缩比提高了1.16倍，压缩和解压吞吐量提高了1.18-3.79倍。

Conclusion: DTT方法显著提升了浮点数据的压缩效率和性能。

Abstract: Floating-point data is widely used across various domains. Depending on the
required precision, each floating-point value can occupy several bytes.
Lossless storage of this information is crucial due to its critical accuracy,
as seen in applications such as medical imaging and language model weights. In
these cases, data size is often significant, making lossless compression
essential. Previous approaches either treat this data as raw byte streams for
compression or fail to leverage all patterns within the dataset. However,
because multiple bytes represent a single value and due to inherent patterns in
floating-point representations, some of these bytes are correlated. To leverage
this property, we propose a novel data transformation method called Typed Data
Transformation (\DTT{}) that groups related bytes together to improve
compression. We implemented and tested our approach on various datasets across
both CPU and GPU. \DTT{} achieves a geometric mean compression ratio
improvement of 1.16$\times$ over state-of-the-art compression tools such as
zstd, while also improving both compression and decompression throughput by
1.18--3.79$\times$.

</details>


### [316] [Learning Lineage Constraints for Data Science Operations](https://arxiv.org/abs/2506.18252)
*Jinjin Zhao*

Main category: cs.DB

TL;DR: 提出了一种跨库数据血缘的通用参数化表示方法XProv，结合具体血缘图和抽象逻辑模式，支持调试等任务。


<details>
  <summary>Details</summary>
Motivation: 数据科学工作流常涉及多库功能集成，但血缘表示通常与特定数据模型和操作范式绑定，难以跨库追踪。

Method: 借鉴中间表示（IR）思想，提出XProv架构，统一表示逻辑血缘，并设计方法链接具体血缘图和抽象逻辑模式。

Result: 初步探讨了如何从具体血缘图推断逻辑模式。

Conclusion: XProv为跨库数据血缘提供了一种通用解决方案，有望支持复杂工作流的调试与分析。

Abstract: Data science workflows often integrate functionalities from a diverse set of
libraries and frameworks. Tasks such as debugging require data lineage that
crosses library boundaries. The problem is that the way that "lineage" is
represented is often intimately tied to particular data models and data
manipulation paradigms. Inspired by the use of intermediate representations
(IRs) in cross-library performance optimizations, this vision paper proposes a
similar architecture for lineage - how do we specify logical lineage across
libraries in a common parameterized way? In practice, cross-library workflows
will contain both known operations and unknown operations, so a key design of
XProv to link both materialized lineage graphs of data transformations and the
aforementioned abstracted logical patterns. We further discuss early ideas on
how to infer logical patterns when only the materialized graphs are available.

</details>


### [317] [Fast Capture of Cell-Level Provenance in Numpy](https://arxiv.org/abs/2506.18255)
*Jinjin Zhao,Sanjay Krishnan*

Main category: cs.DB

TL;DR: 本文提出了一种用于数组的注释系统原型，旨在解决数组工作流中捕获来源信息的挑战，并通过内存优化显著减少延迟。


<details>
  <summary>Details</summary>
Motivation: 数组工作流中的来源跟踪对可重复性、治理和数据质量至关重要，但面临API快速变化、操作类型多样和大规模数据集的挑战。

Method: 设计了一个针对numpy库的注释系统原型，捕获单元格级别的来源信息，并探索内存优化以减少延迟。

Result: 原型系统通过内存优化显著降低了注释延迟。

Conclusion: 该来源捕获方法可作为结构化数据工作流和多样化数据科学应用的治理系统的一部分。

Abstract: Effective provenance tracking enhances reproducibility, governance, and data
quality in array workflows. However, significant challenges arise in capturing
this provenance, including: (1) rapidly evolving APIs, (2) diverse operation
types, and (3) large-scale datasets. To address these challenges, this paper
presents a prototype annotation system designed for arrays, which captures
cell-level provenance specifically within the numpy library. With this
prototype, we explore straightforward memory optimizations that substantially
reduce annotation latency. We envision this provenance capture approach for
arrays as part of a broader governance system for tracking for structured data
workflows and diverse data science applications.

</details>


### [318] [TableVault: Managing Dynamic Data Collections for LLM-Augmented Workflows](https://arxiv.org/abs/2506.18257)
*Jinjin Zhao,Sanjay Krishnan*

Main category: cs.DB

TL;DR: TableVault是一个为LLM增强环境设计的数据管理系统，支持动态数据集合的管理，包括并发执行、可重现性、数据版本控制和可组合工作流设计。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂数据任务中的应用带来了管理挑战，需要一种系统来支持动态数据集合的高效管理。

Method: TableVault结合了传统数据库方法和LLM驱动的需求，提供透明平台，管理结构化数据和相关数据工件。

Result: TableVault能够高效支持并发执行、确保可重现性、维护数据版本，并实现可组合的工作流设计。

Conclusion: TableVault为LLM增强环境中的数据管理提供了有效的解决方案，满足了动态数据集合的管理需求。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating
and executing complex data tasks. However, their integration into more complex
data workflows introduces significant management challenges. In response, we
present TableVault - a data management system designed to handle dynamic data
collections in LLM-augmented environments. TableVault meets the demands of
these workflows by supporting concurrent execution, ensuring reproducibility,
maintaining robust data versioning, and enabling composable workflow design. By
merging established database methodologies with emerging LLM-driven
requirements, TableVault offers a transparent platform that efficiently manages
both structured data and associated data artifacts.

</details>


### [319] [Patient Journey Ontology: Representing Medical Encounters for Enhanced Patient-Centric Applications](https://arxiv.org/abs/2506.18772)
*Hassan S. Al Khatib,Subash Neupane,Sudip Mittal,Shahram Rahimi,Nina Marhamati,Sean Bozorgzad*

Main category: cs.DB

TL;DR: 本文提出了一种患者旅程本体（PJO），用于整合和管理患者医疗数据，支持语义互操作性和临床推理，提升预测分析和个性化医疗。


<details>
  <summary>Details</summary>
Motivation: 医疗行业正转向以患者为中心的模式，需要先进的方法来管理和表示患者数据。

Method: 利用本体论整合患者数据源（如病史、诊断、治疗路径和结果），捕捉医疗事件的时间、顺序和因果关系。

Result: 定量和定性评估表明，PJO在患者历史检索、症状跟踪和提供者交互表示方面表现优异，具有可靠性和实用性。

Conclusion: PJO为个性化医疗和患者旅程分析提供了可靠工具，并推动了生成式AI在医疗中的应用。

Abstract: The healthcare industry is moving towards a patient-centric paradigm that
requires advanced methods for managing and representing patient data. This
paper presents a Patient Journey Ontology (PJO), a framework that aims to
capture the entirety of a patient's healthcare encounters. Utilizing
ontologies, the PJO integrates different patient data sources like medical
histories, diagnoses, treatment pathways, and outcomes; it enables semantic
interoperability and enhances clinical reasoning. By capturing temporal,
sequential, and causal relationships between medical encounters, the PJO
supports predictive analytics, enabling earlier interventions and optimized
treatment plans. The ontology's structure, including its main classes,
subclasses, properties, and relationships, as detailed in the paper,
demonstrates its ability to provide a holistic view of patient care.
Quantitative and qualitative evaluations by Subject Matter Experts (SMEs)
demonstrate strong capabilities in patient history retrieval, symptom tracking,
and provider interaction representation, while identifying opportunities for
enhanced diagnosis-symptom linking. These evaluations reveal the PJO's
reliability and practical applicability, demonstrating its potential to enhance
patient outcomes and healthcare efficiency. This work contributes to the
ongoing efforts of knowledge representation in healthcare, offering a reliable
tool for personalized medicine, patient journey analysis and advancing the
capabilities of Generative AI in healthcare applications.

</details>


### [320] [LIGHTHOUSE: Fast and precise distance to shoreline calculations from anywhere on earth](https://arxiv.org/abs/2506.18842)
*Patrick Beukema,Henry Herzog,Yawen Zhang,Hunter Pitelka,Favyen Bastani*

Main category: cs.DB

TL;DR: 提出了一种新的全球海岸线数据集和高效算法，分辨率达10米，比现有数据精确100倍以上，并开发了轻量级库Lighthouse，实现毫秒级实时查询。


<details>
  <summary>Details</summary>
Motivation: 现有全球海岸数据集分辨率低（1-4公里），限制了其应用潜力。利用公开卫星图像和计算机视觉技术，可以实现更高精度的海岸距离计算。

Method: 结合卫星图像和计算机视觉技术，生成10米分辨率的全球海岸线数据集。开发了Lighthouse库，采用分层迭代地理空间层次化地形导向统一搜索算法，实现高效计算。

Result: 数据集分辨率提升100倍以上，Lighthouse库仅需1 CPU和2 GB内存即可实现毫秒级在线推理，适用于资源受限环境。

Conclusion: 新数据集和算法显著提升了海岸距离计算的精度和效率，适用于实时应用。

Abstract: We introduce a new dataset and algorithm for fast and efficient coastal
distance calculations from Anywhere on Earth (AoE). Existing global coastal
datasets are only available at coarse resolution (e.g. 1-4 km) which limits
their utility. Publicly available satellite imagery combined with computer
vision enable much higher precision. We provide a global coastline dataset at
10 meter resolution, a 100+ fold improvement in precision over existing data.
To handle the computational challenge of querying at such an increased scale,
we introduce a new library: Layered Iterative Geospatial Hierarchical
Terrain-Oriented Unified Search Engine (Lighthouse). Lighthouse is both
exceptionally fast and resource-efficient, requiring only 1 CPU and 2 GB of RAM
to achieve millisecond online inference, making it well suited for real-time
applications in resource-constrained environments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [321] [PBFT-Backed Semantic Voting for Multi-Agent Memory Pruning](https://arxiv.org/abs/2506.17338)
*Duong Bach*

Main category: cs.DC

TL;DR: 论文提出了一种名为Co-Forgetting Protocol的新框架，用于在多智能体系统中同步修剪记忆，减少过时数据，提高效率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在复杂动态环境中需要管理共享知识，但面临同步、相关性和数据过时的挑战。

Method: 协议包含三个关键组件：上下文感知语义投票、多尺度时间衰减函数和基于PBFT的共识机制。

Result: 实验显示，协议显著减少了内存占用（52%），投票准确率达88%，共识成功率达92%，缓存命中率为82%。

Conclusion: Co-Forgetting Protocol有效解决了多智能体系统中的记忆管理问题，具有高效性和鲁棒性。

Abstract: The proliferation of multi-agent systems (MAS) in complex, dynamic
environments necessitates robust and efficient mechanisms for managing shared
knowledge. A critical challenge is ensuring that distributed memories remain
synchronized, relevant, and free from the accumulation of outdated or
inconsequential data - a process analogous to biological forgetting. This paper
introduces the Co-Forgetting Protocol, a novel, comprehensive framework
designed to address this challenge by enabling synchronized memory pruning in
MAS. The protocol integrates three key components: (1) context-aware semantic
voting, where agents utilize a lightweight DistilBERT model to assess the
relevance of memory items based on their content and the current operational
context; (2) multi-scale temporal decay functions, which assign diminishing
importance to memories based on their age and access frequency across different
time horizons; and (3) a Practical Byzantine Fault Tolerance (PBFT)-based
consensus mechanism, ensuring that decisions to retain or discard memory items
are agreed upon by a qualified and fault-tolerant majority of agents, even in
the presence of up to f Byzantine (malicious or faulty) agents in a system of N
greater than or equal to 3f+1 agents. The protocol leverages gRPC for efficient
inter-agent communication and Pinecone for scalable vector embedding storage
and similarity search, with SQLite managing metadata. Experimental evaluations
in a simulated MAS environment with four agents demonstrate the protocol's
efficacy, achieving a 52% reduction in memory footprint over 500 epochs, 88%
voting accuracy in forgetting decisions against human-annotated benchmarks, a
92% PBFT consensus success rate under simulated Byzantine conditions, and an
82% cache hit rate for memory access.

</details>


### [322] [Speeding up Local Optimization in Vehicle Routing with Tensor-based GPU Acceleration](https://arxiv.org/abs/2506.17357)
*Zhenyu Lei,Jin-Kao Hao,Qinghua Wu*

Main category: cs.DC

TL;DR: 该论文提出了一种基于张量的GPU加速方法，用于优化车辆路径问题（VRP）中的局部搜索操作，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 局部搜索在VRP及其变体中至关重要，但传统方法计算成本高且耗时，尤其是在大规模或复杂约束问题中。

Method: 采用基于属性的表示方法，设计了一种低耦合的GPU加速架构，将密集计算完全卸载到GPU上。

Result: 在三种路由问题的基准实例上，该方法比传统CPU实现具有显著的计算优势。

Conclusion: 该方法不仅提高了计算效率，还提供了性能分析和潜在瓶颈的见解，为未来改进指明了方向。

Abstract: Local search plays a central role in many effective heuristic algorithms for
the vehicle routing problem (VRP) and its variants. However, neighborhood
exploration is known to be computationally expensive and time consuming,
especially for large instances or problems with complex constraints. In this
study, we explore a promising direction to address this challenge by
introducing an original tensor-based GPU acceleration method designed to speed
up the commonly used local search operators in vehicle routing. By using an
attribute-based representation, the method offers broad extensibility, making
it applicable to different VRP variants. Its low-coupling architecture, with
intensive computations completely offloaded to the GPU, ensures seamless
integration in various local search-based algorithms and frameworks, leading to
significant improvements in computational efficiency and potentially improved
solution quality. Through comparative experiments on benchmark instances of
three routing problems, we demonstrate the substantial computational advantages
of the proposed approach over traditional CPU-based implementations. We also
provide a detailed analysis of the strengths and limitations of the method,
providing valuable insights into its performance characteristics and
identifying potential bottlenecks in practical applications. These findings
contribute to a better understanding and suggest directions for future
improvements.

</details>


### [323] [Code Generation for Near-Roofline Finite Element Actions on GPUs from Symbolic Variational Forms](https://arxiv.org/abs/2506.17471)
*Kaushik Kulkarni,Andreas Klöckner*

Main category: cs.DC

TL;DR: 提出了一种基于UFL的FEM变分形式在GPU上的并行化策略，通过代码转换和启发式成本模型优化调度，实现了高性能。


<details>
  <summary>Details</summary>
Motivation: 解决FEM变分形式在GPU上的高效并行化问题，特别是针对UFL可表达的复杂计算负载。

Method: 构建调度候选空间，通过启发式成本模型排序，并结合剪枝策略减少配置数量，平衡延迟隐藏和状态空间。

Result: 在Titan V和Tesla K40c上测试，65%的案例达到50%以上的roofline性能。

Conclusion: 该策略在多种应用中表现优异，为FEM在GPU上的高效计算提供了可行方案。

Abstract: We present a novel parallelization strategy for evaluating Finite Element
Method (FEM) variational forms on GPUs, focusing on those that are expressible
through the Unified Form Language (UFL) on simplex meshes. We base our approach
on code transformations, wherein we construct a space of scheduling candidates
and rank them via a heuristic cost model to effectively handle the large
diversity of computational workloads that can be expressed in this way. We
present a design of a search space to which the cost model is applied, along
with an associated pruning strategy to limit the number of configurations that
need to be empirically evaluated. The goal of our design is to strike a balance
between the device's latency-hiding capabilities and the amount of state space,
a key factor in attaining near-roofline performance.
  To make our work widely available, we have prototyped our parallelization
strategy within the \textsc{Firedrake} framework, a UFL-based FEM solver. We
evaluate the performance of our parallelization scheme on two generations of
Nvidia GPUs, specifically the Titan V (Volta architecture) and Tesla K40c
(Kepler architecture), across a range of operators commonly used in
applications, including fluid dynamics, wave propagation, and structural
mechanics, in 2D and 3D geometries. Our results demonstrate that our proposed
algorithm achieves more than $50\%$ roofline performance in $65\%$ of the test
cases on both devices.

</details>


### [324] [ConsumerBench: Benchmarking Generative AI Applications on End-User Devices](https://arxiv.org/abs/2506.17538)
*Yile Gu,Rohan Kadekodi,Hoang Nguyen,Keisuke Kamahori,Yiyu Liu,Baris Kasikci*

Main category: cs.DC

TL;DR: ConsumerBench是一个用于评估终端设备上GenAI模型系统效率和响应时间的基准测试框架，模拟多应用并发场景，揭示资源分配和调度问题。


<details>
  <summary>Details</summary>
Motivation: 随着GenAI应用从云端转向终端设备，资源管理、系统效率和用户体验面临新挑战，需要新的评估工具。

Method: 开发ConsumerBench框架，模拟多应用并发场景，支持自定义工作流，捕获应用级和系统级指标。

Result: 实验揭示了资源共享低效、贪婪分配下的不公平调度以及静态模型服务器配置的性能缺陷。

Conclusion: 为模型开发者和系统设计者提供实用建议，如定制内核和SLO感知调度策略。

Abstract: The recent shift in Generative AI (GenAI) applications from cloud-only
environments to end-user devices introduces new challenges in resource
management, system efficiency, and user experience. This paper presents
ConsumerBench, a comprehensive benchmarking framework designed to evaluate the
system efficiency and response time of GenAI models running on end-user
devices. Unlike existing benchmarks that assume exclusive model access on
dedicated GPUs, ConsumerBench simulates realistic multi-application scenarios
executing concurrently on constrained hardware. Furthermore, ConsumerBench
supports customizable workflows that simulate complex tasks requiring
coordination among multiple applications. ConsumerBench captures both
application-level metrics, including latency and Service Level Objective (SLO)
attainment, and system-level metrics like CPU/GPU utilization and memory
bandwidth. Through extensive experiments, ConsumerBench reveals inefficiencies
in resource sharing, unfair scheduling under greedy allocation, and performance
pitfalls of static model server configurations. The paper also provides
practical insights for model developers and system designers, highlighting the
benefits of custom kernels tailored to consumer-grade GPU architectures and the
value of implementing SLO-aware scheduling strategies.

</details>


### [325] [Research on Model Parallelism and Data Parallelism Optimization Methods in Large Language Model-Based Recommendation Systems](https://arxiv.org/abs/2506.17551)
*Haowei Yang,Yu Tian,Zhongheng Yang,Zhao Wang,Chengrui Zhou,Dannier Li*

Main category: cs.DC

TL;DR: 本文研究了在推荐系统中使用大语言模型（LLMs）时的分布式训练优化方法，包括模型并行和数据并行，提出了一种混合并行方案，显著提升了训练效率和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在推荐系统中的广泛应用，其庞大的参数规模和数据量导致了计算和通信瓶颈，亟需优化方法。

Method: 采用模型并行（包括张量并行和流水线并行）和数据并行（同步与异步模式），结合梯度压缩、稀疏化和高效通信框架。

Result: 实验表明，混合并行方案比传统单模式并行训练吞吐量提升30%，资源利用率提高20%，同时保持强扩展性和鲁棒性。

Conclusion: 讨论了不同并行策略的权衡，并展望了异构硬件集成和自动调度技术的未来方向。

Abstract: With the rapid adoption of large language models (LLMs) in recommendation
systems, the computational and communication bottlenecks caused by their
massive parameter sizes and large data volumes have become increasingly
prominent. This paper systematically investigates two classes of optimization
methods-model parallelism and data parallelism-for distributed training of LLMs
in recommendation scenarios. For model parallelism, we implement both tensor
parallelism and pipeline parallelism, and introduce an adaptive load-balancing
mechanism to reduce cross-device communication overhead. For data parallelism,
we compare synchronous and asynchronous modes, combining gradient compression
and sparsification techniques with an efficient aggregation communication
framework to significantly improve bandwidth utilization. Experiments conducted
on a real-world recommendation dataset in a simulated service environment
demonstrate that our proposed hybrid parallelism scheme increases training
throughput by over 30% and improves resource utilization by approximately 20%
compared to traditional single-mode parallelism, while maintaining strong
scalability and robustness. Finally, we discuss trade-offs among different
parallel strategies in online deployment and outline future directions
involving heterogeneous hardware integration and automated scheduling
technologies.

</details>


### [326] [Distributed Butterfly Analysis using Mobile Agents](https://arxiv.org/abs/2506.17721)
*Prabhat Kumar Chand,Apurba Das,Anisur Rahaman Molla*

Main category: cs.DC

TL;DR: 提出了一种基于代理的分布式算法，用于在二分图中高效计算蝴蝶（4-循环），无需先验知识，仅需最高代理ID。


<details>
  <summary>Details</summary>
Motivation: 二分图中的蝴蝶结构对识别密集子图至关重要，但基于代理的数据挖掘在此领域的应用尚未充分探索。

Method: 代理首先确定分区并协作构建生成树，通过新颖的相邻代理会面机制提高效率，无需图结构先验知识。

Result: 算法在O(n logλ)轮内完成领导选举和生成树构建，蝴蝶计数在O(Δ)轮内完成，总计数在O(Δ+min{|A|,|B|})轮内完成。

Conclusion: 该方法高效且可扩展至一般图，为分布式环境下的蝴蝶计数提供了实用解决方案。

Abstract: Butterflies, or 4-cycles in bipartite graphs, are crucial for identifying
cohesive structures and dense subgraphs. While agent-based data mining is
gaining prominence, its application to bipartite networks remains relatively
unexplored. We propose distributed, agent-based algorithms for \emph{Butterfly
Counting} in a bipartite graph $G((A,B),E)$. Agents first determine their
respective partitions and collaboratively construct a spanning tree, electing a
leader within $O(n \log \lambda)$ rounds using only $O(\log \lambda)$ bits per
agent. A novel meeting mechanism between adjacent agents improves efficiency
and eliminates the need for prior knowledge of the graph, requiring only the
highest agent ID $\lambda$ among the $n$ agents. Notably, our techniques
naturally extend to general graphs, where leader election and spanning tree
construction maintain the same round and memory complexities. Building on these
foundations, agents count butterflies per node in $O(\Delta)$ rounds and
compute the total butterfly count of $G$ in $O(\Delta+\min\{|A|,|B|\})$ rounds.

</details>


### [327] [Choosing the Right Battery Model for Data Center Simulations](https://arxiv.org/abs/2506.17739)
*Paul Kilian,Philipp Wiesner,Odej Kao*

Main category: cs.DC

TL;DR: 论文探讨了数据中心微电网中电池模型的选择问题，比较了四种模型在仿真速度、真实性和配置难度上的表现。


<details>
  <summary>Details</summary>
Motivation: 随着计算资源需求的增长和碳排放法规的出台，数据中心需要优化电力系统，而选择合适的电池模型是关键挑战。

Method: 在Vessim框架中实现了四种电池模型，并分析其行为。

Result: 线性模型在短期实验中表现接近复杂物理模型，且速度更快；简单无损耗模型则准确性不足。

Conclusion: 线性模型是数据中心仿真的理想选择，平衡了速度与准确性。

Abstract: As demand for computing resources continues to rise, the increasing cost of
electricity and anticipated regulations on carbon emissions are prompting
changes in data center power systems. Many providers are now operating compute
nodes in microgrids, close to renewable power generators and energy storage, to
maintain full control over the cost and origin of consumed electricity.
Recently, new co-simulation testbeds have emerged that integrate
domain-specific simulators to support research, development, and testing of
such systems in a controlled environment. Yet, choosing an appropriate battery
model for data center simulations remains challenging, as it requires balancing
simulation speed, realism, and ease of configuration.
  In this paper, we implement four different battery models for data center
scenarios within the co-simulation framework Vessim and analyze their behavior.
The results show that linear models, which consider inefficiencies and power
limits, closely match the behavior of complex physics-based models in
short-term experiments while offering faster execution, and not requiring
knowledge on electrochemical reactions and circuit-level dynamics. In contrast,
simple, lossless models fail to accurately represent complex behavior and
provide no further runtime advantage.

</details>


### [328] [Maintaining a Bounded Degree Expander in Dynamic Peer-to-Peer Networks](https://arxiv.org/abs/2506.17757)
*Antonio Cruciani*

Main category: cs.DC

TL;DR: 研究在节点动态加入和退出的完全分布式环境中维护鲁棒且稀疏的覆盖网络问题，提出了一种基于随机连接策略的动态扩展器拓扑协议。


<details>
  <summary>Details</summary>
Motivation: 现实世界的非结构化P2P网络需要维护低度数但高连通性的通信图，而现有方法在动态环境中表现不足。

Method: 扩展了Becchetti等人的随机连接策略，结合Augustine等人的框架，设计了一种分布式算法，抵御高频率的节点变动。

Result: 算法在高概率下维护了常数度扩展器图，即使每轮有高达O(n/polylog(n))的节点变动。

Conclusion: 该协议解决了先前工作中的开放问题，提供了一种简单、完全分布式且具有理论保证的解决方案。

Abstract: We study the problem of maintaining robust and sparse overlay networks in
fully distributed settings where nodes continuously join and leave the system.
This scenario closely models real-world unstructured peer-to-peer networks,
where maintaining a well-connected yet low-degree communication graph is
crucial. We generalize a recent protocol by Becchetti et al. [SODA 2020] that
relies on a simple randomized connection strategy to build an expander topology
with high probability to a dynamic networks with churn setting. In this work,
the network dynamism is governed by an oblivious adversary that controls which
nodes join and leave the system in each round. The adversary has full knowledge
of the system and unbounded computational power, but cannot see the random
choices made by the protocol. Our analysis builds on the framework of Augustine
et al. [FOCS 2015], and shows that our distributed algorithm maintains a
constant-degree expander graph with high probability, despite a continuous
adversarial churn with a rate of up to $\mathcal{O}(n/polylog(n))$ per round,
where $n$ is the stable network size. The protocol and proof techniques are not
new, but together they resolve a specific open problem raised in prior work.
The result is a simple, fully distributed, and churn-resilient protocol with
provable guarantees that align with observed empirical behavior.

</details>


### [329] [Implementation and Evaluation of Fast Raft for Hierarchical Consensus](https://arxiv.org/abs/2506.17793)
*Anton Melnychuk,Bryan SebaRaj*

Main category: cs.DC

TL;DR: Fast Raft是一种分层共识协议，通过快速通道机制和减少对领导者的依赖，优化了标准Raft的性能。


<details>
  <summary>Details</summary>
Motivation: 在动态分布式环境中，标准Raft协议的消息轮次较多，影响性能。Fast Raft旨在减少消息轮次，提高效率。

Method: 采用gRPC和基于Kubernetes的部署，在AWS可用区中实现Fast Raft，并引入快速通道机制。

Result: 实验结果显示，在低丢包条件下，吞吐量提升且提交延迟降低，同时保持Raft的安全性和活性保证。

Conclusion: Fast Raft在动态环境中显著优化了性能，为分布式系统提供了更高效的共识解决方案。

Abstract: We present the first open-source implementation and evaluation of Fast Raft,
a hierarchical consensus protocol designed for dynamic, distributed
environments. Fast Raft reduces the number of message rounds needed to commit
log entries compared to standard Raft by introducing a fast-track mechanism and
reducing leader dependence. Our implementation uses gRPC and Kubernetes-based
deployment across AWS availability zones. Experimental results demonstrate a
throughput improvement and reduced commit latency under low packet loss
conditions, while maintaining Raft's safety and liveness guarantees.

</details>


### [330] [CFTel: A Practical Architecture for Robust and Scalable Telerobotics with Cloud-Fog Automation](https://arxiv.org/abs/2506.17991)
*Thien Tran,Jonathan Kua,Minh Tran,Honghao Lyu,Thuong Hoang,Jiong Jin*

Main category: cs.DC

TL;DR: 论文提出了一种基于云-雾计算的远程机器人技术（CFTel），通过分布式架构解决传统云远程机器人的延迟、可靠性和扩展性问题，支持实时控制和AI驱动的自主操作。


<details>
  <summary>Details</summary>
Motivation: 传统云远程机器人存在延迟、可靠性和扩展性问题，无法满足关键应用的实时性能需求。

Method: 采用分布式云-边-机器人计算架构，结合5G超可靠低延迟通信、边缘智能、具身AI和数字孪生等技术。

Result: CFTel能够提升实时控制、扩展性和自主性，支持面向服务的解决方案。

Conclusion: CFTel为未来远程机器人研究提供了基础参考，但仍需解决延迟、网络安全和标准化等挑战。

Abstract: Telerobotics is a key foundation in autonomous Industrial Cyber-Physical
Systems (ICPS), enabling remote operations across various domains. However,
conventional cloud-based telerobotics suffers from latency, reliability,
scalability, and resilience issues, hindering real-time performance in critical
applications. Cloud-Fog Telerobotics (CFTel) builds on the Cloud-Fog Automation
(CFA) paradigm to address these limitations by leveraging a distributed
Cloud-Edge-Robotics computing architecture, enabling deterministic
connectivity, deterministic connected intelligence, and deterministic networked
computing. This paper synthesizes recent advancements in CFTel, aiming to
highlight its role in facilitating scalable, low-latency, autonomous, and
AI-driven telerobotics. We analyze architectural frameworks and technologies
that enable them, including 5G Ultra-Reliable Low-Latency Communication, Edge
Intelligence, Embodied AI, and Digital Twins. The study demonstrates that CFTel
has the potential to enhance real-time control, scalability, and autonomy while
supporting service-oriented solutions. We also discuss practical challenges,
including latency constraints, cybersecurity risks, interoperability issues,
and standardization efforts. This work serves as a foundational reference for
researchers, stakeholders, and industry practitioners in future telerobotics
research.

</details>


### [331] [Leveraging Cloud-Fog Automation for Autonomous Collision Detection and Classification in Intelligent Unmanned Surface Vehicles](https://arxiv.org/abs/2506.18024)
*Thien Tran,Quang Nguyen,Jonathan Kua,Minh Tran,Toan Luu,Thuong Hoang,Jiong Jin*

Main category: cs.DC

TL;DR: 论文提出了一种分布式云-边-物联网架构，以解决海事工业信息物理系统（ICPS）中的计算和通信延迟问题，提升了实时数据处理和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 海事无人水面车辆（USVs）的工业信息物理系统（ICPS）受限于计算能力和通信延迟，影响了实时数据处理和可扩展性。

Method: 采用云-边-物联网三层架构：云层负责数据聚合和高级分析，边缘层执行本地化AI处理，物联网层负责低延迟数据采集。

Result: 实验结果显示分类准确率达86%，延迟性能提升，计算效率和可扩展性显著改善。

Conclusion: 该架构为海事ICPS提供了模块化、可扩展的解决方案，支持智能USVs的自主决策和未来应用。

Abstract: Industrial Cyber-Physical Systems (ICPS) technologies are foundational in
driving maritime autonomy, particularly for Unmanned Surface Vehicles (USVs).
However, onboard computational constraints and communication latency
significantly restrict real-time data processing, analysis, and predictive
modeling, hence limiting the scalability and responsiveness of maritime ICPS.
To overcome these challenges, we propose a distributed Cloud-Edge-IoT
architecture tailored for maritime ICPS by leveraging design principles from
the recently proposed Cloud-Fog Automation paradigm. Our proposed architecture
comprises three hierarchical layers: a Cloud Layer for centralized and
decentralized data aggregation, advanced analytics, and future model
refinement; an Edge Layer that executes localized AI-driven processing and
decision-making; and an IoT Layer responsible for low-latency sensor data
acquisition. Our experimental results demonstrated improvements in
computational efficiency, responsiveness, and scalability. When compared with
our conventional approaches, we achieved a classification accuracy of 86\%,
with an improved latency performance. By adopting Cloud-Fog Automation, we
address the low-latency processing constraints and scalability challenges in
maritime ICPS applications. Our work offers a practical, modular, and scalable
framework to advance robust autonomy and AI-driven decision-making and autonomy
for intelligent USVs in future maritime ICPS.

</details>


### [332] [Edge Association Strategies for Synthetic Data Empowered Hierarchical Federated Learning with Non-IID Data](https://arxiv.org/abs/2506.18259)
*Jer Shyuan Ng,Aditya Pribadi Kalapaaking,Xiaoyu Xia,Dusit Niyato,Ibrahim Khalil,Iqbal Gondal*

Main category: cs.DC

TL;DR: 论文提出了一种基于合成数据的层次联邦学习（HFL）框架，以解决非独立同分布（non-IID）数据和工人参与激励问题。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在分布式边缘网络中的实际应用中，存在工人退出、通信效率低和非IID数据等问题，需要改进。

Method: 引入层次联邦学习（HFL）框架，通过边缘服务器生成和分发合成数据，激励工人参与并缓解非IID数据问题。

Result: 提出的框架提高了模型性能，减少了通信轮次，并激励工人参与。

Conclusion: 合成数据赋能的HFL框架有效解决了FL中的统计和参与问题，适用于实际场景。

Abstract: In recent years, Federated Learning (FL) has emerged as a widely adopted
privacy-preserving distributed training approach, attracting significant
interest from both academia and industry. Research efforts have been dedicated
to improving different aspects of FL, such as algorithm improvement, resource
allocation, and client selection, to enable its deployment in distributed edge
networks for practical applications. One of the reasons for the poor FL model
performance is due to the worker dropout during training as the FL server may
be located far away from the FL workers. To address this issue, an Hierarchical
Federated Learning (HFL) framework has been introduced, incorporating an
additional layer of edge servers to relay communication between the FL server
and workers. While the HFL framework improves the communication between the FL
server and workers, large number of communication rounds may still be required
for model convergence, particularly when FL workers have non-independent and
identically distributed (non-IID) data. Moreover, the FL workers are assumed to
fully cooperate in the FL training process, which may not always be true in
practical situations. To overcome these challenges, we propose a
synthetic-data-empowered HFL framework that mitigates the statistical issues
arising from non-IID local datasets while also incentivizing FL worker
participation. In our proposed framework, the edge servers reward the FL
workers in their clusters for facilitating the FL training process. To improve
the performance of the FL model given the non-IID local datasets of the FL
workers, the edge servers generate and distribute synthetic datasets to FL
workers within their clusters. FL workers determine which edge server to
associate with, considering the computational resources required to train on
both their local datasets and the synthetic datasets.

</details>


### [333] [The Power of Strong Linearizability: the Difficulty of Consistent Refereeing](https://arxiv.org/abs/2506.18401)
*Hagit Attiya,Armando Castañeda,Constantin Enea*

Main category: cs.DC

TL;DR: 本文研究了强线性化实现与一致性协议之间的关系，提出了两种竞争对象以捕捉强线性化的能力，并证明了其在非通用原语中的不可实现性。


<details>
  <summary>Details</summary>
Motivation: 探讨强线性化实现与一致性协议之间的关联，揭示其在并发对象实现中的重要性。

Method: 定义两种竞争对象，分析其在锁自由和无等待实现中的作用，并结合高协调能力进行研究。

Result: 证明了强线性化实现需要高协调能力，且竞争对象在非通用原语中无法实现强线性化。

Conclusion: 强线性化实现需要高协调能力，竞争对象为研究强线性化提供了新工具。

Abstract: This paper studies the relation between agreement and strongly linearizable
implementations of various objects. This leads to new results about
implementations of concurrent objects from various primitives including window
registers and interfering primitives. We consider implementations that provide
both strong linearizability and decisive linearizability.
  We identify that lock-free, respectively, wait-free, strongly linearizable
implementations of several concurrent objects entail a form of agreement that
is weaker than consensus but impossible to strongly-linearizable implement with
combinations of non-universal primitives. In both cases, lock-free and
wait-free, this form of agreement requires a distinguished process to referee a
competition that involves all other processes. Our results show that consistent
refereeing of such competitions (i.e. the outcome of the competition does not
change in extensions of the current execution) requires high coordination
power.
  More specifically, two contest objects are defined and used to capture the
power of strong linearizability in lock-free and wait-free implementations,
respectively. Both objects are strictly weaker than consensus, in the sense
that they have a wait-free linearizable (in fact, decisively linearizable)
implementation from reads and writes. The contest objects capture strong
linearizability since (1) they have strongly linearizable implementations from
several ``high-level'' objects like stacks, queues, snapshots, counters, and
therefore, impossibility results for them carry over to these objects, and (2)
they admit powerful impossibility results for strong linearizability that
involve window registers and interfering primitives, which are non-universal.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [334] [The Case for a Horizontal Federated AI operating System for Telcos](https://arxiv.org/abs/2506.17259)
*Sebastian Barros*

Main category: cs.NI

TL;DR: 本文提出了一种面向电信领域的横向联邦AI操作系统，旨在统一分散的AI应用，支持数据本地化和异构架构。


<details>
  <summary>Details</summary>
Motivation: 电信运营商面临AI应用碎片化的挑战，需统一跨客户体验、网络运营和服务编排的AI能力。

Method: 设计并部署一个横向联邦AI操作系统，提供通用的执行和协调层，支持联邦训练、集成现有系统并符合行业标准。

Result: 该系统能够打破现有孤岛，释放生态系统级智能，为基于代理的自动化提供基础。

Conclusion: 横向联邦AI操作系统在技术和结构上重新定义了分布式网络环境中智能的部署和组合方式。

Abstract: As artificial intelligence capabilities rapidly advance, Telco operators face
a growing need to unify fragmented AI efforts across customer experience,
network operations, and service orchestration. This paper proposes the design
and deployment of a horizontal federated AI operating system tailored for the
telecommunications domain. Unlike vertical vendor-driven platforms, this system
acts as a common execution and coordination layer, enabling Telcos to deploy AI
agents at scale while preserving data locality, regulatory compliance, and
architectural heterogeneity. We argue that such an operating system must expose
tightly scoped abstractions for telemetry ingestion, agent execution, and model
lifecycle management. It should support federated training across sovereign
operators, offer integration hooks into existing OSS and BSS systems, and
comply with TM Forum and O-RAN standards. Importantly, the platform must be
governed through a neutral foundation model to ensure portability,
compatibility, and multi-vendor extensibility. This architecture offers a path
to break the current silos, unlock ecosystem-level intelligence, and provide a
foundation for agent-based automation across the Telco stack. The case for this
horizontal layer is not only technical but structural, redefining how
intelligence is deployed and composed in a distributed network environment.

</details>


### [335] [Solving the Problem of Poor Internet Connectivity in Dhaka: Innovative Solutions Using Advanced WebRTC and Adaptive Streaming Technologies](https://arxiv.org/abs/2506.17343)
*Pavel Malinovskiy*

Main category: cs.NI

TL;DR: 本文提出了一种结合WebRTC技术和自适应流媒体的创新框架，以改善达卡市的高密度网络环境下的移动数据连接问题。


<details>
  <summary>Details</summary>
Motivation: 达卡是世界上人口密度最高的城市之一，网络连接问题严重，亟需解决方案。

Method: 采用动态转码、实时纠错和优化接口选择等技术，结合WebRTC和自适应流媒体，分析网络数据并建立数学模型。

Result: 实验结果显示，该方法显著提高了吞吐量、降低了延迟，并改善了整体服务质量。

Conclusion: 该框架为超密集城市环境下的下一代通信系统提供了可扩展的解决方案。

Abstract: Dhaka, Bangladesh, one of the world's most densely populated cities, faces
severe challenges in maintaining reliable, high-speed internet connectivity.
This paper presents an innovative framework that addresses poor mobile data
connections through the integration of advanced WebRTC technology with adaptive
streaming and server-side recording solutions. Focusing on the unique network
conditions in Dhaka in 2025, our approach combines dynamic transcoding,
real-time error correction, and optimized interface selection to enhance
connectivity. We analyze empirical data on connection speeds, mobile tower
density, district-level population statistics, and social media usage.
Extensive mathematical formulations, including novel models for bitrate
estimation, round-trip time optimization, and reliability analysis, are
provided alongside detailed diagrams and multiple examples of code in both
Python and C++. Experimental results demonstrate significant improvements in
throughput, latency reduction, and overall service quality, offering a scalable
blueprint for next-generation communication systems in hyper-dense urban
environments.

</details>


### [336] [VReaves: Eavesdropping on Virtual Reality App Identity and Activity via Electromagnetic Side Channels](https://arxiv.org/abs/2506.17570)
*Sun Wei,Fang Minghong,Li Mengyuan*

Main category: cs.NI

TL;DR: 论文介绍了VReaves系统，通过分析VR设备的电磁辐射侧信道，实现VR应用识别和活动监测。


<details>
  <summary>Details</summary>
Motivation: VR设备的安全问题，尤其是电磁辐射侧信道的潜在威胁，尚未被充分研究。

Method: 通过信号处理流程分析VR设备中嵌入式IoT传感器的电磁辐射，并利用机器学习模型识别VR应用及其活动。

Result: 实验证明，VReaves能高效识别VR应用及其活动。

Conclusion: 电磁辐射侧信道可用于VR安全研究，未来需进一步探索防护措施。

Abstract: Virtual reality (VR) has recently proliferated significantly, consisting of
headsets or head-mounted displays (HMDs) and hand controllers for an embodied
and immersive experience. The VR device is usually embedded with different
kinds of IoT sensors, such as cameras, microphones, communication sensors, etc.
However, VR security has not been scrutinized from a physical hardware point of
view, especially electromagnetic emanations (EM) that are automatically and
unintentionally emitted from the VR headset. This paper presents VReaves, a
system that can eavesdrop on the electromagnetic emanation side channel of a VR
headset for VR app identification and activity recognition. To do so, we first
characterize the electromagnetic emanations from the embedded IoT sensors
(e.g., cameras and microphones) in the VR headset through a signal processing
pipeline and further propose machine learning models to identify the VR app and
recognize the VR app activities. Our experimental evaluation with commercial
off-the-shelf VR devices demonstrates the efficiency of VR app identification
and activity recognition via electromagnetic emanation side channel.

</details>


### [337] [Non-Intrusive MLOps-Driven Performance Intelligence in Software Data Planes](https://arxiv.org/abs/2506.17658)
*Qiong Liu,Jianke Lin,Tianzhu Zhang,Leonardo Linguaglossa*

Main category: cs.NI

TL;DR: 论文提出了一种轻量级、非侵入式的框架DRST，用于在线性能推断和适应，解决了NFV资源共享导致的性能问题。


<details>
  <summary>Details</summary>
Motivation: NFV资源共享导致性能争用，现有解决方案依赖直接流量分析，但集成开销大且受系统限制。

Method: 利用底层NFV基础设施的硬件特征，避免直接数据平面收集，通过轻量级MLOps管道实现性能推断和自动化适应。

Result: DRST框架在多样化NFV场景中实现了准确的性能推断、运行时瓶颈诊断和自动化适应。

Conclusion: DRST框架以轻量级方式解决了NFV性能问题，无需预定义流量模型或VNF定制。

Abstract: The last decade has witnessed the proliferation of network function
virtualization (NFV) in the telco industry, thanks to its unparalleled
flexibility, scalability, and cost-effectiveness. However, as the NFV
infrastructure is shared by virtual network functions (VNFs), sporadic resource
contentions are inevitable. Such contention makes it extremely challenging to
guarantee the performance of the provisioned network services, especially in
high-speed regimes (e.g., Gigabit Ethernet). Existing solutions typically rely
on direct traffic analysis (e.g., packet- or flow-level measurements) to detect
performance degradation and identify bottlenecks, which is not always
applicable due to significant integration overhead and system-level
constraints.
  This paper complements existing solutions with a lightweight, non-intrusive
framework for online performance inference and adaptation. Instead of direct
data-plane collection, we reuse hardware features in the underlying NFV
infrastructure, introducing negligible interference in the data plane. This
framework can be integrated into existing NFV systems with minimal engineering
effort and operates without the need for predefined traffic models or
VNF-specific customization. Through comprehensive evaluation across diverse NFV
scenarios, our Drift-Resilient and Self-Tuning (DRST) framework delivers
accurate performance inference, runtime bottleneck diagnose, and automated
adaptation under runtime drift, via a lightweight MLOps pipeline.

</details>


### [338] [Location Information Sharing Using Software Defined Radio in Multi-UAV Systems](https://arxiv.org/abs/2506.17678)
*Mehmet Kaan Erol,Eyup Emre Ulku*

Main category: cs.NI

TL;DR: 该研究旨在通过SDR实现FANET中的多通道无线通信，用于共享位置信息，并在真实测试环境中验证。


<details>
  <summary>Details</summary>
Motivation: SDR为军事和民用无线通信提供了灵活、可重复且持久的工具，但现有研究多在仿真环境中测试，缺乏对实际硬件、软件和环境因素的考量。

Method: 采用多通道令牌循环作为信道访问协议，并使用GNU Radio平台进行SDR软件开发。

Result: 研究提出了清晰的块图和代码，并在真实环境中测试了多通道通信系统。

Conclusion: 该研究不仅验证了SDR在多通道通信中的可行性，还通过开源代码和块图提供了可复现的工具。

Abstract: SDR (Software Defined Radio) provides flexible, reproducible, and
longer-lasting radio tools for military and civilian wireless communications
infrastructure. SDR is a radio communication system whose components are
implemented as software. This study aims to establish multi-channel wireless
communication with FANET between two SDRs to share location information and
examine it in a realistic test environment. We used multi-channel token
circulation as a channel access protocol and GNU Radio platform for SDR
software development. The structures of the communication layer, including the
protocols, communication systems, and network structures suggested in the
studies in the literature, are generally tested in the simulation environment.
The simulation environment provides researchers with fast and easy development
and testing, but disadvantages exist. These cause a product to be isolated from
hardware, software, and cost effects encountered while developing and
environmental factors affecting the communication channel while testing.
Another contribution of the study is to present the developed block diagrams
and codes as clear and reproducible. The developed software and block diagrams
are available at github.com/knrl/uav-in-802.11-gnuradio.

</details>


### [339] [The Blind Spot of BGP Anomaly Detection: Why LSTM Autoencoders Fail on Real-World Outages](https://arxiv.org/abs/2506.17821)
*Samuel Oluwafemi Adebayo*

Main category: cs.NI

TL;DR: 论文挑战了现有BGP异常检测模型的假设，发现其无法有效识别真实世界中的低复杂度或信号丢失事件，需多模态混合检测系统。


<details>
  <summary>Details</summary>
Motivation: 现有BGP异常检测模型假设异常表现为高复杂度噪声，但实际安全事件可能表现为低复杂度或信号丢失，需验证其有效性。

Method: 使用LSTM自编码器作为检测模型，对比历史BGP异常（如Slammer蠕虫、莫斯科停电）和模拟BGP风暴。

Result: 模型能识别高复杂度合成异常，但无法检测真实事件中的信号丢失或低偏差签名，误判为极端稳定。

Conclusion: 仅将BGP异常定义为高重构误差事件是危险的简化，需多模态检测系统以全面保障BGP安全。

Abstract: Deep learning has significant potential to make the Internet's Border Gateway
Protocol (BGP) secure by detecting anomalous routing activity. However, all but
a few of these approaches rely on the implicit assumption that anomalies
manifest as noisy, high-complexity outliers from some normal baseline. This
work challenges this assumption by investigating if a best-in-class detection
model built on this assumption can effectively deal with real-world security
events' diverse signatures. We employ an LSTM-based autoencoder, a classical
example of a reconstruction-based anomaly detector, as our test vehicle. We
then contrast this model with a representative sampling of historical BGP
anomalies, including the Slammer worm and the Moscow blackout, and with a
simulated 'BGP storm' designed as a positive control. Our experience unveils a
blind spot of our model: the model easily identifies the synthetic anomaly of
high complexity but invariably fails to identify real-world events that
manifest in the form of a "signal loss" (e.g., Slammer, Moscow Blackout) or
"low-deviation" (e.g., WannaCry) signature. We demonstrate that the model
mistakenly recognizes the abrupt cut-off of BGP updates during catastrophic
failures as a signal of extreme stability, leading to reconstruction errors of
virtually zero and total failure to detect. We conclude that the
characterization of BGP anomalies as high-reconstruction-error events alone is
a weak and dangerous oversimplification. Our research provides the data-driven
case for why hybrid, multi-modal detection systems capable of identifying both
high-complexity and signal-loss signatures are required to enable end-to-end
BGP security.

</details>


### [340] [Supporting Deterministic Traffic on Standard NICs](https://arxiv.org/abs/2506.17877)
*Chuanyu Xue,Tianyu Zhang,Andrew Loveless,Song Han*

Main category: cs.NI

TL;DR: 论文提出了一种名为KeepON的软件驱动模型，用于在标准NIC设备上实现确定性数据包传输，填补了现有硬件方案的不足。


<details>
  <summary>Details</summary>
Motivation: 关键任务应用需要确定性数据传输，但通用计算平台缺乏原生支持，硬件方案兼容性差且成本高。

Method: KeepON通过让NIC持续传输固定大小的数据块作为占位符，实时数据包在指定位置替换占位符以确保精确传输时间。

Result: 实验表明，KeepON在调度精度上比默认驱动高162倍，比硬件方案高2.6倍。

Conclusion: KeepON在标准硬件上实现了精确的时序控制，为关键任务应用提供了低成本解决方案。

Abstract: Networked mission-critical applications (e.g., avionic control and industrial
automation systems) require deterministic packet transmissions to support a
range of sensing and control tasks with stringent timing constraints. While
specialized network infrastructure (e.g., time-sensitive networking (TSN)
switches) provides deterministic data transport across the network, achieving
strict end-to-end timing guarantees requires equally capable end devices to
support deterministic traffic. These end devices, however, often employ
general-purpose computing platforms like standard PCs, which lack native
support for deterministic traffic and suffer from unpredictable delays
introduced by their software stack and system architecture. Although
specialized NICs with hardware scheduling offload can mitigate this problem,
the limited compatibility hinders their widespread adoption, particularly for
cost-sensitive applications or in legacy devices.
  To fill this gap, this paper proposes a novel software-based driver model,
namely KeepON, to enable the support of deterministic packet transmissions on
end devices equipped with standard NICs. The key idea of KeepON is to have the
NIC keep on transmitting fixed-size data chunks as placeholders, thereby
maintaining a predictable temporal transmission pattern. The real-time packets
generated by the mission-critical application(s) will then be precisely
inserted into this stream by replacing placeholders at the designated position
to ensure their accurate transmission time. We implement and evaluate KeepON by
modifying the network driver on a Raspberry Pi using its standard NIC. Our
experiments demonstrate that KeepON can achieve x162 times scheduling accuracy
comparable to its default driver, and x2.6 times compared to hardware-based
solution, thus enabling precise timing control on standard commodity hardware.

</details>


### [341] [LiSec-RTF: Reinforcing RPL Resilience Against Routing Table Falsification Attack in 6LoWPAN](https://arxiv.org/abs/2506.17911)
*Shefali Goel,Vinod Kumar Verma,Abhishek Verma*

Main category: cs.NI

TL;DR: LiSec-RTF是一种轻量级安全解决方案，利用物理不可克隆函数（PUFs）生成独特的认证码，有效抵御RPL中的路由表伪造攻击。


<details>
  <summary>Details</summary>
Motivation: RPL协议在6LoWPAN网络中虽高效，但其未认证的控制消息易受攻击，尤其是路由表伪造（RTF）攻击，导致网络性能下降。目前缺乏有效防御措施。

Method: 提出LiSec-RTF方案，利用PUFs生成认证码（Licenses），在静态和移动场景下保护路由表免受伪造攻击。

Result: 实验表明，LiSec-RTF显著提升了网络性能，减少了RTF攻击对包交付率和延迟的影响。

Conclusion: LiSec-RTF为6LoWPAN设备提供了一种资源友好的安全解决方案，有效抵御RTF攻击，保障网络可靠运行。

Abstract: Routing Protocol for Low-Power and Lossy Networks (RPL) is an
energy-efficient routing solution for IPv6 over Low-Power Wireless Personal
Area Networks (6LoWPAN), recommended for resource-constrained devices. While
RPL offers significant benefits, its security vulnerabilities pose challenges,
particularly due to unauthenticated control messages used to establish and
maintain routing information. These messages are susceptible to manipulation,
enabling malicious nodes to inject false routing data. A notable security
concern is the Routing Table Falsification (RTF) attack, where attackers forge
Destination Advertisement Object (DAO) messages to promote fake routes via a
parent nodes routing table. Experimental results indicate that RTF attacks
significantly reduce packet delivery ratio, increase end-to-end delay, and
leverage power consumption. Currently, no effective countermeasures exist in
the literature, reinforcing the need for a security solution to prevent network
disruption and protect user applications. This paper introduces a Lightweight
Security Solution against Routing Table Falsification Attack (LiSec-RTF),
leveraging Physical Unclonable Functions (PUFs) to generate unique
authentication codes, termed Licenses. LiSec-RTF mitigates RTF attack impact
while considering the resource limitations of 6LoWPAN devices in both static
and mobile scenarios. Our testbed experiments indicate that LiSec-RTF
significantly improves network performance compared to standard RPL under RTF
attacks, thereby ensuring reliable and efficient operation.

</details>


### [342] [Mapping The Invisible Internet: Framework and Dataset](https://arxiv.org/abs/2506.18159)
*Siddique Abubakr Muntaka,Jacques Bou Abdo,Kemi Akanbi,Sunkanmi Oluwadare,Faiza Hussein,Oliver Konyo,Michael Asante*

Main category: cs.NI

TL;DR: 本文介绍了一个专注于I2P网络层的新数据集，填补了以往研究多关注暗网应用层的空白。数据通过SWARM-I2P框架收集，记录了超过50,000个节点及其性能指标，包括带宽、延迟和运行时间。数据集可用于隧道对等选择分析、匿名网络韧性研究和对抗建模。


<details>
  <summary>Details</summary>
Motivation: 以往研究多集中在I2P的应用层（如暗网），而网络层的研究相对缺乏。本文旨在填补这一空白，提供网络层的详细数据集以支持进一步研究。

Method: 使用SWARM-I2P框架部署I2P路由器作为映射代理，通过动态端口映射（30000-50000范围）收集数据。数据收集方法包括路由器控制台查询、netDb分析和被动监控，数据以CSV/TXT格式存储。

Result: 数据集包含50,000多个节点的详细信息，包括2,077个FastSet节点和2,331个高容量节点，记录了带宽、延迟（平均121.21ms ± 48.50）和运行时间等指标。还包括大量流量记录和地理分布数据。

Conclusion: 该数据集为研究I2P网络层提供了宝贵资源，支持隧道对等选择、匿名网络韧性和对抗建模等应用。

Abstract: This article presents a novel dataset focusing on the network layer of the
Invisible Internet Project (I2P), where prior research has predominantly
examined application layers like the dark web. Data was collected through the
SWARM- I2P framework, deploying I2P routers as mapping agents, utilizing
dynamic port mapping (30000-50000 range). The dataset documents over 50,000
nodes, including 2,077 FastSet nodes and 2,331 high-capacity nodes
characterized by bandwidth, latency (mean 121.21ms +- 48.50), and uptime
metrics. It contains 1,997 traffic records (1,003,032 packets/bytes) and
4,222,793 records (2,147,585,625 packets/bytes), with geographic distributions
for 3,444 peers showing capacity metrics (mean 8.57 +- 1.20). Collection
methods included router console queries (127.0.0.1:port/tunnels), netDb
analysis, and passive monitoring, with anonymized identifiers. Data is
structured in CSV/TXT formats (Zenodo) with collection scripts (GitHub).
Potential applications include tunnel peer selection analysis, anonymity
network resilience studies, and adversarial modelling.

</details>


### [343] [Consistent Channel Hopping Algorithms for the Multichannel Rendezvous Problem with Heterogeneous Available Channel Sets](https://arxiv.org/abs/2506.18381)
*Yiwei Liu,Yi-Chia Cheng,Cheng-Shang Chang*

Main category: cs.NI

TL;DR: 提出了一种理论框架，用于解决无线网络中多信道会合问题（MRP），通过一致性信道选择函数和排列序列表示算法，实现了高效的会合概率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决无线网络中异构可用信道集的多信道会合问题，确保信道选择的一致性。

Method: 提出一致性信道选择函数，将其表示为排列序列，并设计模算法以减少实现复杂度。

Result: 证明了ETTR与Jaccard指数的关系，模算法性能接近LSH算法，扩展框架支持多用户场景。

Conclusion: 一致性信道跳频算法在会合概率和性能上表现优越，仿真验证了其有效性和可扩展性。

Abstract: We propose a theoretical framework for consistent channel hopping algorithms
to address the multichannel rendezvous problem (MRP) in wireless networks with
heterogeneous available channel sets. A channel selection function is called
consistent if the selected channel remains unchanged when the available channel
set shrinks, provided the selected channel is still available. We show that all
consistent channel selection functions are equivalent to the function that
always selects the smallest-index channel under appropriate channel relabeling.
This leads to a natural representation of a consistent channel hopping
algorithm as a sequence of permutations. For the two-user MRP, we characterize
rendezvous time slots using a fictitious user and derive tight bounds on the
maximum time-to-rendezvous (MTTR) and expected time-to-rendezvous (ETTR).
Notably, the ETTR is shown to be the inverse of the Jaccard index when
permutations are randomly selected. We also prove that consistent channel
hopping algorithms maximize the rendezvous probability. To reduce
implementation complexity, we propose the modulo algorithm, which uses modular
arithmetic with one-cycle permutations and achieves performance comparable to
locality-sensitive hashing (LSH)-based algorithms. The framework is extended to
multiple users, with novel strategies such as stick-together, spread-out, and a
hybrid method that accelerates rendezvous in both synchronous and asynchronous
settings. Simulation results confirm the effectiveness and scalability of the
proposed algorithms.

</details>


### [344] [XR Offloading Across Multiple Time Scales: The Roles of Power, Temperature, and Energy](https://arxiv.org/abs/2506.18584)
*Francesco Malandrino,Olga Chukhno,Alessandro Catania,Antonella Molinaro,Carla Fabiana Chiasserini*

Main category: cs.NI

TL;DR: 本文提出了一种名为TAO的温度感知卸载策略，旨在优化XR设备的计算卸载成本，同时满足功耗、温度和能量限制。


<details>
  <summary>Details</summary>
Motivation: XR设备需要在低延迟下处理大量计算任务，通常依赖设备端处理和边缘卸载的结合。研究关注卸载策略对瞬时功耗、短期温度波动和长期电池寿命的影响。

Method: 引入了一个综合系统模型，捕捉时间动态，并提出了一种随机且静态的卸载策略TAO。

Result: 通过COMSOL模型验证，TAO比现有方法降低卸载成本超过35%，且不违反设备操作限制。

Conclusion: TAO是一种有效的卸载策略，能够在满足设备限制的同时显著降低成本。

Abstract: Extended reality (XR) devices, commonly known as wearables, must handle
significant computational loads under tight latency constraints. To meet these
demands, they rely on a combination of on-device processing and edge
offloading. This letter focuses on offloading strategies for wearables by
considering their impact across three time scales: instantaneous power
consumption, short-term temperature fluctuations, and long-term battery
duration. We introduce a comprehensive system model that captures these
temporal dynamics, and propose a stochastic and stationary offloading strategy,
called TAO (for temperature-aware offloading), designed to minimize the
offloading cost while adhering to power, thermal, and energy constraints. Our
performance evaluation, leveraging COMSOL models of real-world wearables,
confirms that TAO reduces offloading cost by over 35% compared to
state-of-the-art approaches, without violating the wearable operational limits.

</details>


### [345] [RL-Driven Semantic Compression Model Selection and Resource Allocation in Semantic Communication Systems](https://arxiv.org/abs/2506.18660)
*Xinyi Lin,Peizheng Li,Adnan Aijaz*

Main category: cs.NI

TL;DR: 本文提出了一种基于强化学习的语义压缩模型选择和资源分配框架，用于多用户语义通信系统，以平衡语义准确性、延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信系统常忽略用户间的计算和通信能力差异，需自适应平衡语义准确性、延迟和能耗。

Method: 采用近端策略优化（PPO）的强化学习方法，动态选择语义压缩模型并分配带宽和功率。

Result: 仿真表明，该方法优于多种基线策略，并讨论了框架的泛化能力、计算复杂性和实际应用。

Conclusion: 该框架为现实语义通信系统提供了一种高效的解决方案。

Abstract: Semantic communication (SemCom) is an emerging paradigm that leverages
semantic-level understanding to improve communication efficiency, particularly
in resource-constrained scenarios. However, existing SemCom systems often
overlook diverse computational and communication capabilities and requirements
among different users. Motivated by the need to adaptively balance semantic
accuracy, latency, and energy consumption, this paper presents a reinforcement
learning (RL)-driven framework for semantic compression model (SCM) selection
and resource allocation in multi-user SemCom systems. To address the challenges
of balancing image reconstruction quality and communication performance, a
system-level optimization metric called Rate-Distortion Efficiency (RDE) has
been defined. The framework considers multiple SCMs with varying complexity and
resource requirements. A proximal policy optimization (PPO)-based RL approach
is developed to dynamically select SCMs and allocate bandwidth and power under
non-convex constraints. Simulations demonstrate that the proposed method
outperforms several baseline strategies. This paper also discusses the
generalization ability, computational complexity, scalability, and practical
implications of the framework for real-world SemCom systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [346] [Challenges and Practices in Quantum Software Testing and Debugging: Insights from Practitioners](https://arxiv.org/abs/2506.17306)
*Jake Zappin,Trevor Stalnaker,Oscar Chaparro,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 量子软件工程面临测试和调试的独特挑战，开发者多依赖传统方法而非量子专用工具。调查显示，测试普遍但工具不足，调试策略难以扩展，亟需改进工具和工作流程。


<details>
  <summary>Details</summary>
Motivation: 量子计算从理论转向实践，开发者面临传统开发中不存在的挑战，如概率执行和有限可观测性，需了解当前实践以改进工具。

Method: 调查26位量子软件开发者，并针对测试、调试和常见挑战进行后续访谈。

Result: 测试普遍（如单元测试88%），但量子专用工具使用率低（31%）；调试依赖传统方法，难以扩展；常见错误源于经典问题。

Conclusion: 亟需开发更贴合量子开发者需求的测试和调试工具，并优化工作流程。

Abstract: Quantum software engineering is an emerging discipline with distinct
challenges, particularly in testing and debugging. As quantum computing
transitions from theory to implementation, developers face issues not present
in classical software development, such as probabilistic execution, limited
observability, shallow abstractions, and low awareness of quantum-specific
tools. To better understand current practices, we surveyed 26 quantum software
developers from academia and industry and conducted follow-up interviews
focused on testing, debugging, and recurring challenges. All participants
reported engaging in testing, with unit testing (88%), regression testing
(54%), and acceptance testing (54%) being the most common. However, only 31%
reported using quantum-specific testing tools, relying instead on manual
methods. Debugging practices were similarly grounded in classical strategies,
such as print statements, circuit visualizations, and simulators, which
respondents noted do not scale well. The most frequently cited sources of bugs
were classical in nature-library updates (81%), developer mistakes (68%), and
compatibility issues (62%)-often worsened by limited abstraction in existing
SDKs. These findings highlight the urgent need for better-aligned testing and
debugging tools, integrated more seamlessly into the workflows of quantum
developers. We present these results in detail and offer actionable
recommendations grounded in the real-world needs of practitioners.

</details>


### [347] [An Expert Survey on Models and Digital Twins](https://arxiv.org/abs/2506.17313)
*Jonathan Reif,Daniel Dittler,Milapji Singh Gill,Tamás Farkas,Valentin Stegmaier,Felix Gehlhoff,Tobias Kleinert,Michael Weyrich*

Main category: cs.SE

TL;DR: 研究通过专家调查揭示了数字孪生（DTs）中集成多样化数字模型（DMs）的挑战，包括缺乏标准化接口、高人工适配成本及模型复用支持不足，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 数字孪生在工业应用中日益重要，但集成多样化数字模型的挑战和需求缺乏行业视角的研究。

Method: 通过跨多个应用领域的专家调查，识别和分析多样化数字模型在数字孪生中的集成挑战。

Result: 发现缺乏标准化接口、高人工适配成本及模型复用支持不足等问题，需研究自动化模型组合和基于语义的互操作性。

Conclusion: 研究强调了数字孪生中多样化数字模型集成的挑战，并提出了未来研究方向。

Abstract: Digital Twins (DTs) are becoming increasingly vital for future industrial
applications, enhancing monitoring, control, and optimization of physical
assets. This enhancement is made possible by integrating various Digital Models
(DMs) within DTs, which must interoperate to represent different system aspects
and fulfill diverse application purposes. However, industry perspectives on the
challenges and research needs for integrating these models are rarely obtained.
Thus, this study conducts an expert survey across multiple application domains
to identify and analyze the challenges in utilizing diverse DMs within DTs. The
results reveal missing standardized interfaces, high manual adaptation effort,
and limited support for model reuse across lifecycle phases, highlighting
future research needs in automated model composition and semantics-based
interoperability.

</details>


### [348] [Large Language Models for Spreadsheets: Benchmarking Progress and Evaluating Performance with FLARE](https://arxiv.org/abs/2506.17330)
*Simon Thorne*

Main category: cs.SE

TL;DR: 该研究提出了一个基准框架FLARE，用于评估大型语言模型（LLMs）在电子表格任务中的表现，发现其在复杂任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在电子表格相关任务中的有效性，填补这一领域的研究空白。

Method: 引入FLARE基准框架，涵盖从基础公式生成到复杂数据操作的多样化任务。

Result: LLMs在简单任务中表现良好，但在复杂任务中常产生看似合理但错误的输出。

Conclusion: 当前LLMs在需要精确逻辑推理的电子表格任务中存在局限，需整合符号推理能力。

Abstract: Large Language Models (LLMs) have demonstrated some significant capabilities
across various domains; however, their effectiveness in spreadsheet related
tasks remains underexplored. This study introduces a foundation for a
comprehensive benchmark framework to evaluate the performance of leading LLMs
in executing spreadsheet functions, formula generation and data manipulation
tasks. The benchmark encompasses tasks ranging from basic formula creation to
complex, real world spreadsheet scenarios. Our findings reveal that while LLMs
exhibit proficiency in straightforward tasks, they often falter in complex,
multi step operations, frequently producing plausible yet incorrect outputs.
These results underscore the limitations of current LLMs in handling
spreadsheet tasks that require precise logical reasoning and highlight the need
for integrating symbolic reasoning capabilities into LLM architectures. To
support this, we introduce FLARE (Formula Logic, Auditing, Reasoning and
Evaluation) a new benchmark for evaluating LLM performance on real-world
spreadsheet logic, auditing, and reasoning tasks.

</details>


### [349] [LMR-BENCH: Evaluating LLM Agent's Ability on Reproducing Language Modeling Research](https://arxiv.org/abs/2506.17335)
*Shuo Yan,Ruochen Li,Ziming Luo,Zimu Wang,Daoyang Li,Liqiang Jing,Kaiyu He,Peilin Wu,George Michalopoulos,Yue Zhang,Ziyang Zhang,Mian Zhang,Zhiyu Chen,Xinya Du*

Main category: cs.SE

TL;DR: LMR-BENCH是一个评估LLM代理从语言建模研究中复制代码能力的基准，包含28个任务。实验表明，即使最先进的模型在科学推理和代码合成方面仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 探索LLM代理在从研究论文中复制代码任务中的能力，填补这一领域的空白。

Method: 提出LMR-BENCH基准，包含28个任务，使用标准提示和LLM代理设置进行实验，评估代码正确性。

Result: 实验结果显示，即使最先进的模型在科学推理和代码合成方面仍存在局限性。

Conclusion: LLM代理在自主复制科学研究代码方面仍存在关键能力缺口。

Abstract: Large language model (LLM) agents have demonstrated remarkable potential in
advancing scientific discovery. However, their capability in the fundamental
yet crucial task of reproducing code from research papers, especially in the
NLP domain, remains underexplored. This task includes unique complex reasoning
challenges in the intellectual synthesis of abstract concepts and the
comprehension of code repositories with interdependent files. Motivated by this
gap, we present LMR-BENCH, a benchmark designed to systematically evaluate the
capability of LLM agents on code reproduction from Language Modeling Research.
It consists of 28 code reproduction tasks derived from 23 research papers
published in top-tier NLP venues over the past five years, spanning nine
fundamental categories. Models are provided with a research paper, a code
repository containing one or more masked functions, and instructions for
implementing these functions. We conduct extensive experiments in standard
prompting and LLM agent settings with state-of-the-art LLMs, evaluating the
accuracy of unit tests and performing LLM-based evaluation of code correctness.
Experimental results reveal that even the most advanced models still exhibit
persistent limitations in scientific reasoning and code synthesis, highlighting
critical gaps in LLM agents' ability to autonomously reproduce scientific
research

</details>


### [350] [Re-Evaluating Code LLM Benchmarks Under Semantic Mutation](https://arxiv.org/abs/2506.17369)
*Zhiyuan Pan,Xing Hu,Xin Xia,Xiaohu Yang*

Main category: cs.SE

TL;DR: 论文研究了代码基准测试中提示敏感性对大型语言模型（LLM）性能评估的影响，提出了一种框架并通过实验验证了提示微小变化会导致显著性能波动。


<details>
  <summary>Details</summary>
Motivation: 现有代码基准测试通常依赖单一提示模板，易受提示敏感性影响，导致模型能力评估不可靠。

Method: 提出一个框架，生成语义和结构相似的提示模板，并在8个代码任务和10个LLM上进行实验，分析性能变化。

Result: 实验表明，即使提示微小变化也会导致性能显著波动，并影响模型排名一致性。

Conclusion: 未来设计代码基准测试时需考虑提示敏感性，以提高评估的可靠性和准确性。

Abstract: In the era of large language models (LLMs), code benchmarks have become an
important research area in software engineering and are widely used by
practitioners. These benchmarks evaluate the performance of LLMs on specific
code-related tasks, such as code understanding and generation. A critical step
in constructing code benchmarks is the design of prompts. However, as existing
code benchmarks typically rely on a single prompt template per task, they are
prone to the issue of prompt sensitivity, where minor prompt variations could
result in substantial performance variations, leading to unreliable evaluations
of model capabilities.
  While previous studies have explored prompt sensitivity, their experimental
designs and findings are limited to traditional natural language processing
(NLP) tasks. In this paper, we present an empirical study to investigate prompt
sensitivity in code benchmarks. We first propose a general framework that
modifies prompt templates in a manner that preserves both their semantics and
their structure as much as possible. Based on the framework, we conduct
extensive experiments across eight code benchmark tasks on 10 representative
open-source LLMs, with each task featuring 100 semantically similar prompt
templates. We then analyze the evaluation results using various statistical
metrics, focusing on both absolute and relative model performance. Our findings
suggest that even slight prompt variations can lead to significant shifts in
performance. Additionally, we observe that such variations can introduce
inconsistencies in the performance rankings across different models. These
insights highlight the need for considering prompt sensitivity when designing
future code benchmarks, to ensure more reliable and accurate evaluation of LLM
capabilities.

</details>


### [351] [Breaking Single-Tester Limits: Multi-Agent LLMs for Multi-User Feature Testing](https://arxiv.org/abs/2506.17539)
*Sidong Feng,Changhao Du,Huaxiao Liu,Qingnan Wang,Zhengwei Lv,Mengfei Wang,Chunyang Chen*

Main category: cs.SE

TL;DR: MAdroid利用多智能体和LLM自动化多用户交互测试，效果显著。


<details>
  <summary>Details</summary>
Motivation: 移动应用的多用户交互功能测试自动化面临挑战，现有方法不足。

Method: MAdroid采用多智能体（用户代理和监管代理）协作完成任务。

Result: 在41项任务中，82.9%成功完成，动作相似度达96.8%，并发现11个交互bug。

Conclusion: MAdroid在多用户交互测试中表现出色，具有实际应用价值。

Abstract: The growing dependence on mobile phones and their apps has made multi-user
interactive features, like chat calls, live streaming, and video conferencing,
indispensable for bridging the gaps in social connectivity caused by physical
and situational barriers. However, automating these interactive features for
testing is fraught with challenges, owing to their inherent need for timely,
dynamic, and collaborative user interactions, which current automated testing
methods inadequately address. Inspired by the concept of agents designed to
autonomously and collaboratively tackle problems, we propose MAdroid, a novel
multi-agent approach powered by the Large Language Models (LLMs) to automate
the multi-user interactive task for app feature testing. Specifically, MAdroid
employs two functional types of multi-agents: user agents (Operator) and
supervisor agents (Coordinator and Observer). Each agent takes a specific role:
the Coordinator directs the interactive task; the Operator mimics user
interactions on the device; and the Observer monitors and reviews the task
automation process. Our evaluation, which included 41 multi-user interactive
tasks, demonstrates the effectiveness of our approach, achieving 82.9% of the
tasks with 96.8% action similarity, outperforming the ablation studies and
state-of-the-art baselines. Additionally, a preliminary investigation
underscores MAdroid's practicality by helping identify 11 multi-user
interactive bugs during regression app testing, confirming its potential value
in real-world software development contexts.

</details>


### [352] [CodeMorph: Mitigating Data Leakage in Large Language Model Assessment](https://arxiv.org/abs/2506.17627)
*Hongzhou Rao,Yanjie Zhao,Wenjie Zhu,Ling Xiao,Meizhen Wang,Haoyu Wang*

Main category: cs.SE

TL;DR: CodeMorph是一种支持多编程语言并保持跨文件依赖关系的代码扰动方法，旨在减少数据泄漏，提升LLM评估效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有代码扰动方法在多样性、跨文件依赖和多语言支持上的不足，以更有效地缓解数据泄漏问题。

Method: CodeMorph包含两部分：1）26种语义保持的代码变换方法；2）基于遗传算法的PESO选择算法，优化扰动效果。

Result: 应用CodeMorph后，LLM在代码完成任务上的准确率平均下降24.67%，Python下降最多（45%）；PESO优化的代码相似度平均降低7.01%。

Conclusion: CodeMorph能有效生成多样且复杂的代码扰动，显著降低数据泄漏风险，提升LLM评估的可靠性。

Abstract: Concerns about benchmark leakage in large language models for code (Code
LLMs) have raised issues of data contamination and inflated evaluation metrics.
The diversity and inaccessibility of many training datasets make it difficult
to prevent data leakage entirely, even with time lag strategies. Consequently,
generating new datasets through code perturbation has become essential.
However, existing methods often fail to produce complex and diverse variations,
struggle with complex cross-file dependencies, and lack support for multiple
programming languages, which limits their effectiveness in enhancing LLM
evaluations for coding tasks. To fill this gap, we propose CodeMorph, an
approach designed to support multiple programming languages while preserving
cross-file dependencies to mitigate data leakage. CodeMorph consists of two
main components that work together to enhance the perturbation process. The
first component employs 26 semantic-preserving transformation methods to
iteratively perturb code, generating diverse variations while ensuring that the
modified code remains compilable. The second component introduces a genetic
algorithm-based selection algorithm, PESO, to identify the more effective
perturbation method for each iteration by targeting lower similarity scores
between the perturbed and original code, thereby enhancing overall perturbation
effectiveness. Experimental results demonstrate that after applying CodeMorph,
the accuracy of the LLM on code completion tasks across five programming
languages decreased by an average of 24.67%, with Python showing the most
significant reduction at 45%. The similarity score of code optimized by PESO
is, on average, 7.01% lower than that of randomly perturbed code, peaking at a
reduction of 42.86%.

</details>


### [353] [Deep Learning Framework Testing via Model Mutation: How Far Are We?](https://arxiv.org/abs/2506.17638)
*Yanzhou Mu,Rong Wang,Juan Zhai,Chunrong Fang,Xiang Chen,Zhiyuan Peng,Peiran Yang,Ruixiang Qian,Shaoyu Yang,Zhenyu Chen*

Main category: cs.SE

TL;DR: 本文重新评估了基于突变的深度学习框架测试方法，发现现有方法存在高假阳性率和开发者忽视的问题，并提出优化策略，成功识别并修复了多个重要缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有基于突变的测试方法在检测深度学习框架缺陷时存在高假阳性率和开发者忽视的问题，因此需要研究其有效性并提出改进方案。

Method: 收集三个流行框架的缺陷报告，分类后分析现有突变测试方法的不足，并提出优化策略。

Result: 优化后识别出39个独特缺陷，其中31个被开发者确认，8个已修复。

Conclusion: 通过优化突变测试方法，显著提高了缺陷检测的有效性和开发者认可度。

Abstract: Deep Learning (DL) frameworks are a fundamental component of DL development.
Therefore, the detection of DL framework defects is important and challenging.
As one of the most widely adopted DL testing techniques, model mutation has
recently gained significant attention. In this study, we revisit the defect
detection ability of existing mutation-based testing methods and investigate
the factors that influence their effectiveness. To begin with, we reviewed
existing methods and observed that many of them mutate DL models (e.g.,
changing their parameters) without any customization, ignoring the unique
challenges in framework testing. Another issue with these methods is their
limited effectiveness, characterized by a high rate of false positives caused
by illegal mutations arising from the use of generic, non-customized mutation
operators. Moreover, we tracked the defects identified by these methods and
discovered that most of them were ignored by developers. Motivated by these
observations, we investigate the effectiveness of existing mutation-based
testing methods in detecting important defects that have been authenticated by
framework developers. We begin by collecting defect reports from three popular
frameworks and classifying them based on framework developers' ratings to build
a comprehensive dataset. We then perform an in-depth analysis to uncover
valuable insights. Based on our findings, we propose optimization strategies to
address the shortcomings of existing approaches. Following these optimizations,
we identified seven new defects, four of which were confirmed by developers as
high-priority issues, with three resolved. In summary, we identified 39 unique
defects across just 23 models, of which 31 were confirmed by developers, and
eight have been fixed.

</details>


### [354] [May the Feedback Be with You! Unlocking the Power of Feedback-Driven Deep Learning Framework Fuzzing via LLMs](https://arxiv.org/abs/2506.17642)
*Shaoyu Yang,Chunrong Fang,Haifeng Lin,Xiang Chen,Zhenyu Chen*

Main category: cs.SE

TL;DR: FUEL是一种基于LLM的反馈驱动模糊测试方法，用于检测深度学习框架中的漏洞，已发现并确认多个新漏洞。


<details>
  <summary>Details</summary>
Motivation: 深度学习框架中的漏洞可能导致严重后果，现有模糊测试技术未能充分利用多种反馈信息。

Method: FUEL使用两个LLM代理（分析LLM和生成LLM）分别分析反馈信息和生成测试用例。

Result: FUEL检测到104个PyTorch和TensorFlow漏洞，其中93个为新漏洞，47个已修复，5个获得CVE编号。

Conclusion: 考虑多种反馈类型并利用LLM分析反馈信息是模糊测试的有前景方向。

Abstract: Artificial Intelligence (AI) Infrastructures, represented by Deep Learning
(DL) frameworks, have served as fundamental DL systems over the last decade.
However, the bugs in DL frameworks could lead to catastrophic consequences in
some critical scenarios (e.g., healthcare and autonomous driving). A simple yet
effective way to find bugs in DL frameworks is fuzz testing (Fuzzing).
Unfortunately, existing fuzzing techniques have not comprehensively considered
multiple types of feedback. Additionally, they analyze feedback in a
coarse-grained manner, such as mutating the test cases only according to
whether the coverage increases. Recently, researchers introduced Large Language
Models (LLMs) into fuzzing. However, current LLM-based fuzzing techniques only
focus on using LLMs to generate test cases while overlooking their potential to
analyze feedback information, failing to create more valid and diverse test
cases. To fill this gap, we propose FUEL to break the seal of Feedback-driven
fuzzing for DL frameworks. The backbone of FUEL comprises two LLM-based agents,
namely analysis LLM and generation LLM. Analysis LLM agent infers analysis
summaries from feedback information, while the generation LLM agent creates
tests guided by these analysis summaries. So far, FUEL has detected 104 bugs
for PyTorch and TensorFlow, with 93 confirmed as new bugs, 47 already fixed,
and 5 assigned with CVE IDs. Our work indicates that considering multiple types
of feedback is beneficial to fuzzing performance, and leveraging LLMs to
analyze feedback information is a promising direction. Our artifact is
available at https://github.com/NJU-iSE/FUEL

</details>


### [355] [Improving Compiler Bug Isolation by Leveraging Large Language Models](https://arxiv.org/abs/2506.17647)
*Yixian Qi,Jiajun Jiang,Fengjie Li,Bowen Chen,Hongyu Zhang,Junjie Chen*

Main category: cs.SE

TL;DR: AutoCBI利用大型语言模型（LLMs）总结编译器文件功能，并通过专门提示重新排序可疑文件排名，显著提升了编译器Bug定位效果。


<details>
  <summary>Details</summary>
Motivation: 传统编译器Bug定位技术存在测试程序变异和资源消耗的局限性，而LLMs的进展为解决这一问题提供了新思路。

Method: AutoCBI结合失败测试程序、源文件功能摘要、可疑文件列表和编译配置信息，利用LLMs优化可疑文件排名。

Result: 在GCC和LLVM的120个真实Bug测试中，AutoCBI在Top-1排名中分别比RecBi、DiWi和FuseFL多定位66.67%/69.23%、300%/340%和100%/57.14%的Bug。

Conclusion: AutoCBI通过LLMs显著提升了编译器Bug定位的效率和准确性，各组件均对结果有重要贡献。

Abstract: Compilers play a foundational role in building reliable software systems, and
bugs within them can lead to catastrophic consequences. The compilation process
typically involves hundreds of files, making traditional automated bug
isolation techniques inapplicable due to scalability or effectiveness issues.
Current mainstream compiler bug localization techniques have limitations in
test program mutation and resource consumption. Inspired by the recent advances
of pre-trained Large Language Models (LLMs), we propose an innovative approach
named AutoCBI, which (1) uses LLMs to summarize compiler file functions and (2)
employs specialized prompts to guide LLM in reordering suspicious file
rankings. This approach leverages four types of information: the failing test
program, source file function summaries, lists of suspicious files identified
through analyzing test coverage, as well as compilation configurations with
related output messages, resulting in a refined ranking of suspicious files.
Our evaluation of AutoCBI against state-of-the-art approaches (DiWi, RecBi and
FuseFL) on 120 real-world bugs from the widely-used GCC and LLVM compilers
demonstrates its effectiveness. Specifically, AutoCBI isolates 66.67%/69.23%,
300%/340%, and 100%/57.14% more bugs than RecBi, DiWi, and FuseFL,
respectively, in the Top-1 ranked results for GCC/LLVM. Additionally, the
ablation study underscores the significance of each component in our approach.

</details>


### [356] [PAGENT: Learning to Patch Software Engineering Agents](https://arxiv.org/abs/2506.17772)
*Haoran Xue,Gias Uddin,Song Wang*

Main category: cs.SE

TL;DR: 论文研究了LLM代码代理生成的失败补丁，提出了一个分类法，并设计了PAGENT工具来修复类型相关错误。


<details>
  <summary>Details</summary>
Motivation: 了解LLM代理生成失败补丁的根本原因，并提出解决方案。

Method: 收集114个未解决问题，分析769个失败补丁，提出分类法，并设计PAGENT工具进行类型推断和修复。

Result: PAGENT成功修复了127个类型相关失败补丁中的29个。

Conclusion: PAGENT是解决LLM代理类型相关错误的有效工具，但仍需进一步改进。

Abstract: LLM Agents produce patches automatically to resolve an issue. However, they
can generate inaccurate patches. Little is known about the root causes behind
those failed patches or how those could be fixed. This paper reports an
empirical study of the failed patches generated by seven top LLM code agents.
We collected 114 issues from the SWE-bench Lite dataset that remained
unresolved across the agents. The seven agents produced a total of 769 failed
patches for those issues, which we checked with a combination of GPT-4o and
manual analysis. We present a taxonomy of the failure reasons across the
patches. The taxonomy contains six categories, with several sub-categories
under each category. For example, a frequently observed category is the
inability of an LLM to correctly infer/produce the appropriate variable type in
the produced patch. As a first step towards addressing such type-related
errors, we designed PAGENT (Patch Agent). PAGENT utilizes program analysis
techniques like CFG creation and exploration to infer the type of information
of a patch. PAGENT does this by applying repository-level static code analysis
techniques. Then, PAGENT refines the inferred type by further utilizing an
LLM-based inference technique. We tested PAGENT on all 127 type-related failed
patches from the top three agents in our study. PAGENT could fix 29 of the 127
failed patches.

</details>


### [357] [SAVANT: Vulnerability Detection in Application Dependencies through Semantic-Guided Reachability Analysis](https://arxiv.org/abs/2506.17798)
*Wang Lingxiang,Quanzhi Fu,Wenjia Song,Gelei Deng,Yi Liu,Dan Williams,Ying Zhang*

Main category: cs.SE

TL;DR: SAVANT结合语义预处理和LLM技术，提升Java开发中第三方库漏洞检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有SCA工具因语义理解和计算复杂性限制，难以准确检测第三方库中的API漏洞，导致误报和修复延迟。

Method: SAVANT利用漏洞测试用例和LLM的语义理解能力，通过代码分段和上下文分析实现精准漏洞检测。

Result: 在55个实际应用中，SAVANT的精确率、召回率、准确率和F1分数均优于现有SCA工具。

Conclusion: SAVANT通过语义和上下文分析显著提升了漏洞检测效果，为开发团队提供了更可靠的解决方案。

Abstract: The integration of open-source third-party library dependencies in Java
development introduces significant security risks when these libraries contain
known vulnerabilities. Existing Software Composition Analysis (SCA) tools
struggle to effectively detect vulnerable API usage from these libraries due to
limitations in understanding API usage semantics and computational challenges
in analyzing complex codebases, leading to inaccurate vulnerability alerts that
burden development teams and delay critical security fixes.
  To address these challenges, we proposed SAVANT by leveraging two insights:
proof-of-vulnerability test cases demonstrate how vulnerabilities can be
triggered in specific contexts, and Large Language Models (LLMs) can understand
code semantics. SAVANT combines semantic preprocessing with LLM-powered context
analysis for accurate vulnerability detection. SAVANT first segments source
code into meaningful blocks while preserving semantic relationships, then
leverages LLM-based reflection to analyze API usage context and determine
actual vulnerability impacts. Our evaluation on 55 real-world applications
shows that SAVANT achieves 83.8% precision, 73.8% recall, 69.0% accuracy, and
78.5% F1-score, outperforming state-of-the-art SCA tools.

</details>


### [358] [Is Your Automated Software Engineer Trustworthy?](https://arxiv.org/abs/2506.17812)
*Noble Saji Mathews,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: BouncerBench是一个基准测试，用于评估基于LLM的软件代理是否能拒绝处理模糊输入或不正确输出，以提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具在处理模糊或错误输入时缺乏拒绝机制，导致不可靠行为，如生成错误代码。

Method: 引入BouncerBench，评估模型是否能区分模糊问题和错误补丁，并实现基本输入输出过滤机制。

Result: 大多数模型无法拒绝模糊输入或错误输出，表明LLM在实际应用中仍需改进。

Conclusion: BouncerBench为构建更谨慎、可信的代码代理提供了第一步，但LLM在软件工程中的可靠性仍需提升。

Abstract: Large Language Models (LLMs) are being increasingly used in software
engineering tasks, with an increased focus on bug report resolution over the
past year. However, most proposed systems fail to properly handle uncertain or
incorrect inputs and outputs. Existing LLM-based tools and coding agents
respond to every issue and generate a patch for every case, even when the input
is vague or their own output is incorrect. There are no mechanisms in place to
abstain when confidence is low. This leads to unreliable behaviour, such as
hallucinated code changes or responses based on vague issue reports. We
introduce BouncerBench, a benchmark that evaluates whether LLM-based software
agents can refuse to act when inputs are ill-defined or refuse to respond when
their own outputs are likely to be incorrect. Unlike prior benchmarks that
implicitly incentivize models to generate responses even when uncertain,
BouncerBench aims to improve precision by targeting two overlooked failure
points: (1) vague or underspecified issue descriptions in tickets and (2)
logically or functionally incorrect code patches created by the system. It
measures whether proposed systems can distinguish actionable issues from vague
tickets and valid patches from untrustworthy ones. We also implement a basic
input and output bouncer, evaluating how well current LLMs can abstain when
needed. Our results show that most models fail to abstain from underspecified
inputs or incorrect outputs. Hence, we conclude that there is significant room
for improvement before LLMs can be trusted to make correct decisions and
recommendations in real-world software engineering workflows. BouncerBench
provides a first step toward evaluating and building more cautious, trustworthy
code agents. The replication package, dataset, and leaderboard can be found at
bouncerbench.com

</details>


### [359] [The Impact of AI-Generated Solutions on Software Architecture and Productivity: Results from a Survey Study](https://arxiv.org/abs/2506.17833)
*Giorgio Amasanti,Jasmin Jahic*

Main category: cs.SE

TL;DR: AI工具显著提升软件工程师的生产力，但在复杂项目中效果减弱。AI生成的代码片段对软件质量无显著负面影响，但解决复杂问题时质量下降。


<details>
  <summary>Details</summary>
Motivation: 探讨AI工具对软件工程师生产力的长期影响及其对软件质量的作用。

Method: 通过调查使用AI工具的软件从业者收集数据。

Result: AI工具提高生产力，但在复杂项目中效果减弱；AI生成的代码片段不影响质量，但复杂问题解决方案质量较低。

Conclusion: AI工具需结合问题分解和解决方案集成以应对复杂项目。

Abstract: AI-powered software tools are widely used to assist software engineers.
However, there is still a need to understand the productivity benefits of such
tools for software engineers. In addition to short-term benefits, there is a
question of how adopting AI-generated solutions affects the quality of software
over time (e.g., maintainability and extendability).
  To provide some insight on these questions, we conducted a survey among
software practitioners who use AI tools. Based on the data collected from our
survey, we conclude that AI tools significantly increase the productivity of
software engineers. However, the productivity benefits of using AI tools reduce
as projects become more complex. The results also show that there are no
significant negative influences of adopting AI-generated solutions on software
quality, as long as those solutions are limited to smaller code snippets.
However, when solving larger and more complex problems, AI tools generate
solutions of a lower quality, indicating the need for architects to perform
problem decomposition and solution integration.

</details>


### [360] [Software Reuse in the Generative AI Era: From Cargo Cult Towards AI Native Software Engineering](https://arxiv.org/abs/2506.17937)
*Tommi Mikkonen,Antero Taivalsaari*

Main category: cs.SE

TL;DR: 论文探讨了AI辅助生成式软件重用在“AI原生”软件工程中的影响，提出了相关问题，并定义了初步研究议程。


<details>
  <summary>Details</summary>
Motivation: 随着AI和生成式软件重用的兴起，传统软件重用方法正被AI辅助方法取代，这引发了类似“货物崇拜开发”的新问题。

Method: 通过讨论AI辅助生成式软件重用的影响，提出关键问题并制定研究议程。

Result: 揭示了AI辅助软件重用可能带来的问题，并呼吁采取行动解决这些问题。

Conclusion: 需要进一步研究以应对AI辅助软件重用带来的挑战，推动“AI原生”软件工程的发展。

Abstract: Software development is currently under a paradigm shift in which artificial
intelligence and generative software reuse are taking the center stage in
software creation. Consequently, earlier software reuse practices and methods
are rapidly being replaced by AI-assisted approaches in which developers place
their trust on code that has been generated by artificial intelligence. This is
leading to a new form of software reuse that is conceptually not all that
different from cargo cult development. In this paper we discuss the
implications of AI-assisted generative software reuse in the context of
emerging "AI native" software engineering, bring forth relevant questions, and
define a tentative research agenda and call to action for tackling some of the
central issues associated with this approach.

</details>


### [361] [Build It Clean: Large-Scale Detection of Code Smells in Build Scripts](https://arxiv.org/abs/2506.17948)
*Mahzabin Tamanna,Yash Chandrani,Matthew Burrows,Brandon Wroblewski,Laurie Williams,Dominik Wermke*

Main category: cs.SE

TL;DR: 论文通过混合方法研究构建脚本中的代码异味，识别了13类异味并提出了改进策略。


<details>
  <summary>Details</summary>
Motivation: 构建脚本中的代码异味可能导致构建失败或增加技术债务，研究旨在帮助开发者避免这些问题。

Method: 结合定性分析2000个GitHub问题和定量分析5882个构建脚本，开发了静态分析工具Sniffer。

Result: 发现13类异味，共10895次出现，其中Maven中Insecure URLs最常见，Gradle和CMake中Hardcoded Paths/URLs常见，Makefiles中Wildcard Usage最多。

Conclusion: 建议改进构建脚本的实践以提高效率、可靠性和可维护性。

Abstract: Build scripts are files that automate the process of compiling source code,
managing dependencies, running tests, and packaging software into deployable
artifacts. These scripts are ubiquitous in modern software development
pipelines for streamlining testing and delivery. While developing build
scripts, practitioners may inadvertently introduce code smells. Code smells are
recurring patterns of poor coding practices that may lead to build failures or
increase risk and technical debt. The goal of this study is to aid
practitioners in avoiding code smells in build scripts through an empirical
study of build scripts and issues on GitHub. We employed a mixed-methods
approach, combining qualitative and quantitative analysis. We conducted a
qualitative analysis of 2000 build-script-related GitHub issues. Next, we
developed a static analysis tool, Sniffer, to identify code smells in 5882
build scripts of Maven, Gradle, CMake, and Make files, collected from 4877
open-source GitHub repositories. We identified 13 code smell categories, with a
total of 10,895 smell occurrences, where 3184 were in Maven, 1214 in Gradle,
337 in CMake, and 6160 in Makefiles.
  Our analysis revealed that Insecure URLs were the most prevalent code smell
in Maven build scripts, while Hardcoded Paths/URLs were commonly observed in
both Gradle and CMake scripts. Wildcard Usage emerged as the most frequent
smell in Makefiles. The co-occurrence analysis revealed strong associations
between specific smell pairs of Hardcoded Paths/URLs with Duplicates, and
Inconsistent Dependency Management with Empty or Incomplete Tags, indicating
potential underlying issues in the build script structure and maintenance
practices. Based on our findings, we recommend strategies to mitigate the
existence of code smells in build scripts to improve the efficiency,
reliability, and maintainability of software projects.

</details>


### [362] [VFArchē: A Dual-Mode Framework for Locating Vulnerable Functions in Open-Source Software](https://arxiv.org/abs/2506.18050)
*Lyuye Zhang,Jian Zhang,Kaixuan Li,Chong Wang,Chengwei Liu,Jiahui Wu,Sen Chen,Yaowen Zheng,Yang Liu*

Main category: cs.SE

TL;DR: VFArch=e是一种双模式方法，用于自动定位漏洞函数（VF），适用于有或无补丁的场景，显著提升了SCA工具的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现代漏洞数据库（如NVD）通常缺乏关键信息（如漏洞函数），而直接提取或忽略补丁均存在局限性，需要一种全面解决方案。

Method: 提出VFArch=e，结合补丁存在和补丁缺失两种模式，通过实验验证其有效性。

Result: 在基准数据集上，VFArch=e在补丁存在和缺失模式下分别比最佳基线提升1.3倍和1.9倍的平均倒数排名，并显著减少78-89%的误报。

Conclusion: VFArch=e在实际应用中表现出色，能高效定位漏洞函数，提升SCA工具的实用性。

Abstract: Software Composition Analysis (SCA) has become pivotal in addressing
vulnerabilities inherent in software project dependencies. In particular,
reachability analysis is increasingly used in Open-Source Software (OSS)
projects to identify reachable vulnerabilities (e.g., CVEs) through call
graphs, enabling a focus on exploitable risks. Performing reachability analysis
typically requires the vulnerable function (VF) to track the call chains from
downstream applications. However, such crucial information is usually
unavailable in modern vulnerability databases like NVD. While directly
extracting VF from modified functions in vulnerability patches is intuitive,
patches are not always available. Moreover, our preliminary study shows that
over 26% of VF do not exist in the modified functions. Meanwhile, simply
ignoring patches to search vulnerable functions suffers from overwhelming
noises and lexical gaps between descriptions and source code. Given that almost
half of the vulnerabilities are equipped with patches, a holistic solution that
handles both scenarios with and without patches is required. To meet real-world
needs and automatically localize VF, we present VFArch\=e, a dual-mode approach
designed for disclosed vulnerabilities, applicable in scenarios with or without
available patch links. The experimental results of VFArch\=e on our constructed
benchmark dataset demonstrate significant efficacy regarding three metrics,
achieving 1.3x and 1.9x Mean Reciprocal Rank over the best baselines for
Patch-present and Patch-absent modes, respectively. Moreover, VFArch\=e has
proven its applicability in real-world scenarios by successfully locating VF
for 43 out of 50 latest vulnerabilities with reasonable efforts and
significantly reducing 78-89% false positives of SCA tools.

</details>


### [363] [Call Me Maybe: Enhancing JavaScript Call Graph Construction using Graph Neural Networks](https://arxiv.org/abs/2506.18191)
*Masudul Hasan Masud Bhuiyan,Gianluca De Stefano,Giancarlo Pellegrino,Cristian-Alexandru Staicu*

Main category: cs.SE

TL;DR: GRAPHIA利用图神经网络改进JavaScript调用图构建，通过链接预测提高召回率，减少人工分析需求。


<details>
  <summary>Details</summary>
Motivation: 现有JavaScript调用图构建算法既不健全也不完整，导致误报和遗漏。GRAPHIA旨在通过图神经网络识别遗漏的调用边。

Method: 将问题建模为全程序图上的链接预测，结合句法和语义边表示程序，利用图神经网络学习代码元素间非局部关系。

Result: 在50个流行JavaScript库上评估，GRAPHIA在42%的未解决调用中将正确目标排名第一，72%排名前五。

Conclusion: 学习型方法可显著提升JavaScript调用图构建的召回率，GRAPHIA是首个将GNN应用于多文件程序图进行跨过程分析的工作。

Abstract: Static analysis plays a key role in finding bugs, including security issues.
A critical step in static analysis is building accurate call graphs that model
function calls in a program. However, due to hard-to-analyze language features,
existing call graph construction algorithms for JavaScript are neither sound
nor complete. Prior work shows that even advanced solutions produce false edges
and miss valid ones. In this work, we assist these tools by identifying missed
call edges. Our main idea is to frame the problem as link prediction on full
program graphs, using a rich representation with multiple edge types. Our
approach, GRAPHIA, leverages recent advances in graph neural networks to model
non-local relationships between code elements. Concretely, we propose
representing JavaScript programs using a combination of syntactic- and
semantic-based edges. GRAPHIA can learn from imperfect labels, including static
call edges from existing tools and dynamic edges from tests, either from the
same or different projects. Because call graphs are sparse, standard machine
learning metrics like ROC are not suitable. Instead, we evaluate GRAPHIA by
ranking function definitions for each unresolved call site. We conduct a
large-scale evaluation on 50 popular JavaScript libraries with 163K call edges
(150K static and 13K dynamic). GRAPHIA builds program graphs with 6.6M
structural and 386K semantic edges. It ranks the correct target as the top
candidate in over 42% of unresolved cases and within the top 5 in 72% of cases,
reducing the manual effort needed for analysis. Our results show that
learning-based methods can improve the recall of JavaScript call graph
construction. To our knowledge, this is the first work to apply GNN-based link
prediction to full multi-file program graphs for interprocedural analysis.

</details>


### [364] [Managing Technical Debt in a Multidisciplinary Data Intensive Software Team: an Observational Case Study](https://arxiv.org/abs/2506.18219)
*Ulrike M. Graetsch,Rashina Hoda,Hourieh Khalazjadeh,Mojtaba Shahin,John Grundy*

Main category: cs.SE

TL;DR: 研究探讨了多学科团队在数据密集型系统中管理技术债务的实践，发现数据组件债务和管道债务是主要问题，并提出了适应敏捷开发的债务处理方法。


<details>
  <summary>Details</summary>
Motivation: 随着数据密集型系统投资的增加，技术债务问题日益突出，但多学科团队如何管理这些债务尚不明确。

Method: 采用探索性观察案例研究，结合社会技术扎根理论进行数据分析。

Result: 识别了数据组件债务和管道债务，并分析了团队如何评估和处理这些债务以适应敏捷开发。

Conclusion: 研究结果与现有技术债务分类一致，强调需要新的实施模式和工具支持多学科团队。

Abstract: Context: There is an increase in the investment and development of
data-intensive (DI) solutions, systems that manage large amounts of data.
Without careful management, this growing investment will also grow associated
technical debt (TD). Delivery of DI solutions requires a multidisciplinary
skill set, but there is limited knowledge about how multidisciplinary teams
develop DI systems and manage TD.
  Objective: This research contributes empirical, practice based insights about
multidisciplinary DI team TD management practices.
  Method: This research was conducted as an exploratory observation case study.
We used socio-technical grounded theory (STGT) for data analysis to develop
concepts and categories that articulate TD and TDs debt management practices.
  Results: We identify TD that the DI team deals with, in particular technical
data components debt and pipeline debt. We explain how the team manages the TD,
assesses TD, what TD treatments they consider and how they implement TD
treatments to fit sprint capacity constraints.
  Conclusion: We align our findings to existing TD and TDM taxonomies, discuss
their implications and highlight the need for new implementation patterns and
tool support for multidisciplinary DI teams.

</details>


### [365] [Tu(r)ning AI Green: Exploring Energy Efficiency Cascading with Orthogonal Optimizations](https://arxiv.org/abs/2506.18289)
*Saurabhsingh Rajput,Mootez Saad,Tushar Sharma*

Main category: cs.SE

TL;DR: 论文提出将能源效率作为AI设计核心，通过五个阶段的策略性选择实现显著节能，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: AI计算需求激增带来能源挑战，现有优化方法缺乏系统性。

Method: 在数据、模型、训练、系统和推理五个阶段进行策略性组合优化。

Result: 实验验证组合优化可节能94.6%，同时保持95.95%的F1分数。

Conclusion: 系统性优化框架为可持续AI提供了平衡效率、性能与环保的可行方案。

Abstract: AI's exponential growth intensifies computational demands and energy
challenges. While practitioners employ various optimization techniques, that we
refer as "knobs" in this paper, to tune model efficiency, these are typically
afterthoughts and reactive ad-hoc changes applied in isolation without
understanding their combinatorial effects on energy efficiency. This paper
emphasizes on treating energy efficiency as the first-class citizen and as a
fundamental design consideration for a compute-intensive pipeline. We show that
strategic selection across five AI pipeline phases (data, model, training,
system, inference) creates cascading efficiency. Experimental validation shows
orthogonal combinations reduce energy consumption by up to $94.6$% while
preserving $95.95$% of the original F1 score of non-optimized pipelines. This
curated approach provides actionable frameworks for informed sustainable AI
that balance efficiency, performance, and environmental responsibility.

</details>


### [366] [Use Property-Based Testing to Bridge LLM Code Generation and Validation](https://arxiv.org/abs/2506.18315)
*Lehan He,Zeren Chen,Zhe Zhang,Jing Shao,Xiang Gao,Lu Sheng*

Main category: cs.SE

TL;DR: 论文提出Property-Generated Solver框架，利用基于属性的测试（PBT）验证程序的高层属性，而非依赖具体输入输出示例，显著提升LLM生成代码的正确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统测试驱动开发（TDD）在LLM代码生成中存在高质量测试用例稀缺和自动化测试生成缺陷的问题，导致代码修正过程可能被误导。

Method: 框架包含两个协作的LLM代理：Generator负责代码生成与迭代优化，Tester管理PBT生命周期并提供基于属性违反的语义丰富反馈。

Result: 实验表明，Property-Generated Solver在多个代码生成基准上显著优于传统TDD方法，相对提升23.1%至37.3%。

Conclusion: 通过PBT作为核心验证机制，该框架为LLM生成更正确和泛化的代码提供了稳健的解决方案。

Abstract: Large Language Models (LLMs) excel at code generation, but ensuring their
outputs to be functionally correct, especially in complex programming tasks, is
a persistent challenge. While traditional Test-Driven Development (TDD) offers
a path for code refinement, its efficacy with LLMs is often undermined by the
scarcity of high-quality test cases or the pitfalls of automated test
generation, including biased tests or inaccurate output predictions that can
misdirect the correction process. This paper introduces Property-Generated
Solver, a novel framework that leverages Property-Based Testing (PBT) to
validate high-level program properties or invariants, instead of relying on
specific input-output examples. These properties are often simpler to define
and verify than directly predicting exhaustive test oracles, breaking the
"cycle of self-deception" where tests might share flaws with the code they are
meant to validate. Property-Generated Solver employs two collaborative
LLM-based agents: a Generator dedicated to code generation and iterative
refinement, and a Tester that manages the PBT life-cycle and formulate
semantically rich feedback from property violations. The resulting
comprehensive and actionable feedback then guides the Generator in its
refinement efforts. By establishing PBT as the core validation engine within
this iterative, closed-loop paradigm, Property-Generated Solver provides a
robust mechanism for steering LLMs towards more correct and generalizable code.
Extensive experimental results on multiple code generation benchmarks
demonstrate that Property-Generated Solver achieves substantial pass@1
improvements, ranging from 23.1% to 37.3% relative gains over established TDD
methods.

</details>


### [367] [Predictive Analytics for Collaborators Answers, Code Quality, and Dropout on Stack Overflow](https://arxiv.org/abs/2506.18329)
*Elijah Zolduoarrati,Sherlock A. Licorish,Nigel Stanger*

Main category: cs.SE

TL;DR: 本研究评估了21种算法在三个任务上的表现，发现不同模型在不同任务中表现最佳，并验证了CodeBERT在用户流失预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 以往研究使用的模型数量有限或选择方法随意，可能导致遗漏未测试算法，因此需要更广泛的基准测试。

Method: 采用了标准化、对数变换等方法，结合贝叶斯超参数优化和遗传算法，并微调了CodeBERT模型。

Result: Bagging模型在预测用户回答数量时表现最佳（R2=0.821），SGD在代码质量预测中表现优异，XGBoost在用户流失预测中F1-score最高（0.825）。CodeBERT的F1-score为0.809。

Conclusion: 研究提供了针对不同任务的最佳模型选择建议，并帮助减少超参数调优的初始搜索空间。

Abstract: Previous studies that used data from Stack Overflow to develop predictive
models often employed limited benchmarks of 3-5 models or adopted arbitrary
selection methods. Despite being insightful, their limited scope suggests the
need to benchmark more models to avoid overlooking untested algorithms. Our
study evaluates 21 algorithms across three tasks: predicting the number of
question a user is likely to answer, their code quality violations, and their
dropout status. We employed normalisation, standardisation, as well as
logarithmic and power transformations paired with Bayesian hyperparameter
optimisation and genetic algorithms. CodeBERT, a pre-trained language model for
both natural and programming languages, was fine-tuned to classify user dropout
given their posts (questions and answers) and code snippets. We found Bagging
ensemble models combined with standardisation achieved the highest R2 value
(0.821) in predicting user answers. The Stochastic Gradient Descent regressor,
followed by Bagging and Epsilon Support Vector Machine models, consistently
demonstrated superior performance to other benchmarked algorithms in predicting
user code quality across multiple quality dimensions and languages. Extreme
Gradient Boosting paired with log-transformation exhibited the highest F1-score
(0.825) in predicting user dropout. CodeBERT was able to classify user dropout
with a final F1-score of 0.809, validating the performance of Extreme Gradient
Boosting that was solely based on numerical data. Overall, our benchmarking of
21 algorithms provides multiple insights. Researchers can leverage findings
regarding the most suitable models for specific target variables, and
practitioners can utilise the identified optimal hyperparameters to reduce the
initial search space during their own hyperparameter tuning processes.

</details>


### [368] [Recipe for Discovery: A Framework for Systematic Open Source Project Identification](https://arxiv.org/abs/2506.18359)
*Juanita Gomez,Emily Lovell,Stephanie Lieggi,Alvaro A. Cardenas,James Davis*

Main category: cs.SE

TL;DR: 论文提出了一种框架，用于发现和分类大学和研究实验室开发的分散开源软件项目，以加州大学系统为例，通过GitHub API和机器学习模型实现高效识别和分析。


<details>
  <summary>Details</summary>
Motivation: 开源软件开发在学术机构中分散且难以追踪，导致许多高影响力工具未被认可。本文旨在解决这一挑战，提升开源项目的可见性和机构意识。

Method: 利用GitHub REST API构建管道发现相关仓库，提取元数据，并评估多种分类策略（传统机器学习和大型语言模型）以区分机构关联项目。

Result: 框架在规模上表现高效，发现了超过52,000个仓库，并以高准确率预测了机构关联性。

Conclusion: 该框架为学术开源项目的系统化发现和分析提供了有效工具，有助于提升开源贡献的认可度。

Abstract: Open source software development, particularly within institutions such as
universities and research laboratories, is often decentralized and difficult to
track. Despite producing highly impactful tools in science, these efforts often
go unrecognized due to a lack of visibility and institutional awareness. This
paper addresses the challenge of discovering, classifying, and analyzing open
source software projects developed across distributed institutional systems. We
present a framework for systematically identifying institutional affiliated
repositories, using the University of California (UC) system as a case study.
  Using GitHub's REST API, we build a pipeline to discover relevant
repositories and extract meaningful metadata. We then propose and evaluate
multiple classification strategies, including both traditional machine learning
models and large language models (LLMs), to distinguish affiliated projects
from unrelated repositories and generate accurate insights into the academic
open source landscape. Our results show that the framework is effective at
scale, discovering over 52,000 repositories and predicting institutional
affiliation with high accuracy.

</details>


### [369] [Tracing Errors, Constructing Fixes: Repository-Level Memory Error Repair via Typestate-Guided Context Retrieval](https://arxiv.org/abs/2506.18394)
*Xiao Cheng,Zhihao Guo,Huan Huo,Yulei Sui*

Main category: cs.SE

TL;DR: LTFix利用大型语言模型（LLM）和有限类型状态自动机，解决C语言内存错误修复中的跨过程模式理解和上下文窗口限制问题。


<details>
  <summary>Details</summary>
Motivation: C语言中手动内存管理导致的内存错误修复复杂且易引发漏洞，传统APR方法依赖人工设计策略，深度学习方法则需大量数据且缺乏可解释性。

Method: 结合LLM和有限类型状态自动机，跟踪错误传播路径和上下文痕迹，捕捉内存状态和执行历史的时空维度。

Result: LTFix能有效处理跨函数和文件的复杂内存错误，克服LLM的上下文窗口限制。

Conclusion: LTFix为自动化内存错误修复提供了高效且可解释的新方法。

Abstract: Memory-related errors in C programming continue to pose significant
challenges in software development, primarily due to the complexities of manual
memory management inherent in the language. These errors frequently serve as
vectors for severe vulnerabilities, while their repair requires extensive
knowledge of program logic and C's memory model. Automated Program Repair (APR)
has emerged as a critical research area to address these challenges.
Traditional APR approaches rely on expert-designed strategies and predefined
templates, which are labor-intensive and constrained by the effectiveness of
manual specifications. Deep learning techniques offer a promising alternative
by automatically extracting repair patterns, but they require substantial
training datasets and often lack interpretability.
  This paper introduces LTFix, a novel approach that harnesses the potential of
Large Language Models (LLMs) for automated memory error repair, especially for
complex repository-level errors that span multiple functions and files. We
address two fundamental challenges in LLM-based memory error repair: a limited
understanding of interprocedural memory management patterns and context window
limitations for repository-wide analysis. Our approach utilizes a finite
typestate automaton to guide the tracking of error-propagation paths and
context trace, capturing both spatial (memory states) and temporal (execution
history) dimensions of error behavior. This typestate-guided context retrieval
strategy provides the LLM with concise yet semantically rich information
relevant to erroneous memory management, effectively addressing the token
limitation of LLMs.

</details>


### [370] [Your Token Becomes Worthless: Unveiling Rug Pull Schemes in Crypto Token via Code-and-Transaction Fusion Analysis](https://arxiv.org/abs/2506.18398)
*Hao Wu,Haijun Wang,Shangwang Li,Yin Wu,Ming Fan,Wuxia Jin,Yitao Zhao,Ting Liu*

Main category: cs.SE

TL;DR: RPhunter 是一种结合代码和交易数据的新型 Rug Pull 检测技术，通过构建语义风险代码图和代币流动行为图，利用图神经网络和注意力融合模型提升检测效果，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Rug Pull 骗局对加密货币构成严重威胁，现有方法仅关注代码或交易单一方面，无法有效检测复杂骗局。

Method: RPhunter 结合代码风险分析和交易行为建模，构建语义风险代码图（SRCG）和代币流动行为图（TFBG），利用图神经网络和注意力融合模型进行检测。

Result: 在 645 个 Rug Pull 事件的数据集上，RPhunter 的精确率为 95.3%，召回率为 93.8%，F1 分数为 94.5%。在实际应用中，检测到 4801 个 Rug Pull 代币，精确率为 91%。

Conclusion: RPhunter 通过整合代码和交易信息，显著提升了 Rug Pull 检测的准确性和实用性。

Abstract: Rug pull scams have emerged as a persistent threat to cryptocurrency, causing
significant financial losses. A typical scenario involves scammers deploying
honeypot contracts to attract investments, restricting token sales, and
draining the funds, which leaves investors with worthless tokens. Current
methods either rely on predefined patterns to detect code risks or utilize
statistical transaction data to train detection models. However, real-world Rug
Pull schemes often involve a complex interplay between malicious code and
suspicious transaction behaviors. These methods, which solely focus on one
aspect, fall short in detecting such schemes effectively.
  In this paper, we propose RPhunter, a novel technique that integrates code
and transaction for Rug Pull detection. First, RPhunter establishes declarative
rules and performs flow analysis to extract code risk information, further
constructing a semantic risk code graph (SRCG). Meanwhile, to leverage
transaction information, RPhunter formulates dynamic token transaction
activities as a token flow behavior graph (TFBG) in which nodes and edges are
characterized from network structure and market manipulation perspectives.
Finally, RPhunter employs graph neural networks to extract complementary
features from SRCG and TFBG, integrating them through an attention fusion model
to enhance the detection of Rug Pull. We manually analyzed 645 Rug Pull
incidents from code and transaction aspects and constructed a ground-truth
dataset. We evaluated RPhunter on our dataset, achieving a precision of 95.3%,
a recall of 93.8% and an F1 score of 94.5%, which highlights superior
performance compared to existing state-of-the-art methods. Furthermore, when
applied to the real-world scenarios, RPhunter has identified 4801 Rug Pull
tokens, achieving a precision of 91%.

</details>


### [371] [The Debugging Decay Index: Rethinking Debugging Strategies for Code LLMs](https://arxiv.org/abs/2506.18403)
*Muntasir Adnan,Carlos C. N. Kuhn*

Main category: cs.SE

TL;DR: 论文提出Debugging Decay Index (DDI)框架，量化AI调试能力衰减，并通过适时干预提升调试效果。


<details>
  <summary>Details</summary>
Motivation: 当前AI调试能力在2-3次尝试后显著衰减，影响代码生成系统的实用性。

Method: 引入DDI框架，量化调试失效点，并提出战略性重启策略。

Result: 适时干预可挽救调试效果，DDI揭示了当前AI调试的根本限制。

Conclusion: DDI为优化迭代代码生成策略提供了首个量化框架。

Abstract: The effectiveness of AI debugging follows a predictable exponential decay
pattern; most models lose 60-80% of their debugging capability within just 2-3
attempts, despite iterative debugging being a critical capability for practical
code generation systems. We introduce the Debugging Decay Index (DDI), a
mathematical framework that quantifies when debugging becomes ineffective and
predicts intervention points. Our strategic fresh start approach shifts from
exploitation to exploration at strategic points in the debugging process,
demonstrating that well-timed interventions can rescue the effectiveness of
debugging. DDI reveals a fundamental limitation in current AI debugging and
provides the first quantitative framework for optimising iterative code
generation strategies.

</details>


### [372] [ModeliHub: A Web-based, Federated Analytics Platform for Modelica-centric, Model-based Systems Engineering](https://arxiv.org/abs/2506.18790)
*Mohamad Omar Nachawati*

Main category: cs.SE

TL;DR: ModeliHub是一个基于Web的联邦分析平台，专为基于Modelica的模型系统工程设计，提供统一的系统模型和实时仿真环境。


<details>
  <summary>Details</summary>
Motivation: 为系统工程提供一种基于Modelica的统一模型，支持异构工程工件的集成与分析，平衡严谨性与灵活性。

Method: 采用Modelica为中心的联邦架构，结合可扩展的Modelica编译器前端（基于Isomorphic TypeScript），实现跨浏览器、桌面和服务器的无缝运行。

Result: ModeliHub提供了一个实时交互的仿真环境，支持数字孪生模型的部署，适用于系统工程生命周期的迭代开发。

Conclusion: ModeliHub通过其创新的架构和实现，为系统工程提供了高效、灵活的模型分析和仿真工具。

Abstract: This paper introduces ModeliHub, a Web-based, federated analytics platform
designed specifically for model-based systems engineering with Modelica.
ModeliHub's key innovation lies in its Modelica-centric, hub-and-spoke
federation architecture that provides systems engineers with a Modelica-based,
unified system model of repositories containing heterogeneous engineering
artifacts. From this unified system model, ModeliHub's Virtual Twin engine
provides a real-time, interactive simulation environment for deploying Modelica
simulation models that represent digital twins of the virtual prototype of the
system under development at a particular iteration of the iterative systems
engineering life cycle. The implementation of ModeliHub is centered around its
extensible, Modelica compiler frontend developed in Isomorphic TypeScript that
can run seamlessly across browser, desktop and server environments. This
architecture aims to strike a balance between rigor and agility, enabling
seamless integration and analysis across various engineering domains.

</details>


### [373] [Context-Aware CodeLLM Eviction for AI-assisted Coding](https://arxiv.org/abs/2506.18796)
*Kishanthan Thangarajah,Boyuan Chen,Shi Chang,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: CACE是一种针对自托管CodeLLM服务优化的上下文感知模型驱逐策略，通过多因素决策提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决自托管CodeLLM在资源受限下的模型管理和服务效率问题。

Method: 提出CACE策略，结合模型加载时间、任务延迟敏感性、输出长度预测、近期使用和未来需求等多因素。

Result: CACE显著降低TTFT和E2E延迟，减少模型驱逐次数。

Conclusion: CACE为实际软件工程环境中的低延迟AI编码助手部署提供了实用策略。

Abstract: AI-assisted coding tools powered by Code Large Language Models (CodeLLMs) are
increasingly integrated into modern software development workflows. To address
concerns around privacy, latency, and model customization, many enterprises opt
to self-host these models. However, the diversity and growing number of
CodeLLMs, coupled with limited accelerator memory, introduce practical
challenges in model management and serving efficiency. This paper presents
CACE, a novel context-aware model eviction strategy designed specifically to
optimize self-hosted CodeLLM serving under resource constraints. Unlike
traditional eviction strategies based solely on recency (e.g., Least Recently
Used), CACE leverages multiple context-aware factors, including model load
time, task-specific latency sensitivity, expected output length, and recent
usage and future demand tracked through a sliding window. We evaluate CACE
using realistic workloads that include both latency-sensitive code completion
and throughput-intensive code reasoning tasks. Our experiments show that CACE
reduces Time-to-First-Token (TTFT) and end-to-end (E2E) latency, while
significantly lowering the number of model evictions compared to
state-of-the-art systems. Ablation studies further demonstrate the importance
of multi-factor eviction in balancing responsiveness and resource efficiency.
This work contributes practical strategies for deploying scalable, low-latency
AI coding assistants in real-world software engineering environments.

</details>


### [374] [Understanding Software Engineering Agents: A Study of Thought-Action-Result Trajectories](https://arxiv.org/abs/2506.18824)
*Islem Bouzenia,Michael Pradel*

Main category: cs.SE

TL;DR: 本文对三种基于大语言模型（LLM）的代理（RepairAgent、AutoCodeRover、OpenHands）进行了大规模实证研究，分析了其决策过程和行为模式，揭示了成功与失败执行的关键特征。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM代理在软件工程任务中广泛应用，但其内部决策过程尚不明确，限制了对其动态和失败模式的理解。

Method: 通过统一交互日志格式，捕获120条轨迹和2822次LLM交互，结合定量分析和定性评估，研究其结构特性、行为模式和语义连贯性。

Result: 研究发现成功与失败执行的行为模式和反模式，为改进代理设计提供了实用建议。

Conclusion: 研究为透明和鲁棒的自助软件工程代理设计提供了数据支持和框架，促进进一步研究。

Abstract: Large Language Model (LLM)-based agents are increasingly employed to automate
complex software engineering tasks such as program repair and issue resolution.
These agents operate by autonomously generating natural language thoughts,
invoking external tools, and iteratively refining their solutions. Despite
their widespread adoption, the internal decision-making processes of these
agents remain largely unexplored, limiting our understanding of their
operational dynamics and failure modes. In this paper, we present a large-scale
empirical study of the thought-action-result trajectories of three
state-of-the-art LLM-based agents: \textsc{RepairAgent},
\textsc{AutoCodeRover}, and \textsc{OpenHands}. We unify their interaction logs
into a common format, capturing 120 trajectories and 2822 LLM interactions
focused on program repair and issue resolution. Our study combines quantitative
analyses of structural properties, action patterns, and token usage with
qualitative assessments of reasoning coherence and feedback integration. We
identify key trajectory characteristics such as iteration counts and token
consumption, recurring action sequences, and the semantic coherence linking
thoughts, actions, and their results. Our findings reveal behavioral motifs and
anti-patterns that distinguish successful from failed executions, providing
actionable insights for improving agent design, including prompting strategies,
failure diagnosis, and anti-pattern detection. We release our dataset and
annotation framework to support further research on transparent and robust
autonomous software engineering agents.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [375] [Efficient Difference-in-Differences and Event Study Estimators](https://arxiv.org/abs/2506.17729)
*Xiaohong Chen,Pedro H. C. Sant'Anna,Haitian Xie*

Main category: econ.EM

TL;DR: 本文研究了在异质性处理效应框架下，利用短面板数据进行高效的差分法（DiD）和事件研究（ES）估计，无需参数化假设且允许处理时间变化。


<details>
  <summary>Details</summary>
Motivation: 传统DiD和ES方法在处理异质性效应和不同处理时间时存在效率不足的问题，本文旨在提供更高效的估计方法。

Method: 通过序列条件矩限制对DiD潜在结果模型进行等价表征，推导半参数高效影响函数（EIF），并基于EIF提出简单高效估计器。

Result: EIF具有最小方差性质，模拟和实证应用显示新方法在有限样本中显著提高估计精度。

Conclusion: 本文为现代DiD和ES应用提供了高效推断工具，优化了预处理期和对照组选择以缩小置信区间。

Abstract: This paper investigates efficient Difference-in-Differences (DiD) and Event
Study (ES) estimation using short panel data sets within the heterogeneous
treatment effect framework, free from parametric functional form assumptions
and allowing for variation in treatment timing. We provide an equivalent
characterization of the DiD potential outcome model using sequential
conditional moment restrictions on observables, which shows that the DiD
identification assumptions typically imply nonparametric overidentification
restrictions. We derive the semiparametric efficient influence function (EIF)
in closed form for DiD and ES causal parameters under commonly imposed parallel
trends assumptions. The EIF is automatically Neyman orthogonal and yields the
smallest variance among all asymptotically normal, regular estimators of the
DiD and ES parameters. Leveraging the EIF, we propose simple-to-compute
efficient estimators. Our results highlight how to optimally explore different
pre-treatment periods and comparison groups to obtain the tightest (asymptotic)
confidence intervals, offering practical tools for improving inference in
modern DiD and ES applications even in small samples. Calibrated simulations
and an empirical application demonstrate substantial precision gains of our
efficient estimators in finite samples.

</details>


### [376] [An Empirical Comparison of Weak-IV-Robust Procedures in Just-Identified Models](https://arxiv.org/abs/2506.18001)
*Wenze Li*

Main category: econ.EM

TL;DR: 比较了两种弱识别条件下的工具变量（IV）模型方法：经典的Anderson-Rubin（AR）方法和新的tF方法，发现AR方法在统计显著性和置信区间长度上表现更好，但tF方法在理论上有优势。


<details>
  <summary>Details</summary>
Motivation: 工具变量回归是因果推断的核心方法之一，本文旨在比较两种在弱识别条件下表现不同的方法，以指导实证应用。

Method: 使用美国经济评论（AER）的复制数据和蒙特卡洛模拟实验，评估AR和tF方法在统计显著性测试和置信区间长度上的表现。

Result: AR方法通常具有更高的统计功效和更短的置信区间，但tF方法在理论上有更优的期望置信区间长度。

Conclusion: AR和tF方法可以视为互补工具，适用于涉及潜在弱工具的实证应用。

Abstract: Instrumental variable (IV) regression is recognized as one of the five core
methods for causal inference, as identified by Angrist and Pischke (2008). This
paper compares two leading approaches to inference under weak identification
for just-identified IV models: the classical Anderson-Rubin (AR) procedure and
the recently popular tF method proposed by Lee et al. (2022). Using replication
data from the American Economic Review (AER) and Monte Carlo simulation
experiments, we evaluate the two procedures in terms of statistical
significance testing and confidence interval (CI) length. Empirically, we find
that the AR procedure typically offers higher power and yields shorter CIs than
the tF method. Nonetheless, as noted by Lee et al. (2022), tF has a theoretical
advantage in terms of expected CI length. Our findings suggest that the two
procedures may be viewed as complementary tools in empirical applications
involving potentially weak instruments.

</details>


### [377] [Beyond utility: incorporating eye-tracking, skin conductance and heart rate data into cognitive and econometric travel behaviour models](https://arxiv.org/abs/2506.18068)
*Thomas O. Hancock,Stephane Hess,Charisma F. Choudhury*

Main category: econ.EM

TL;DR: 论文探讨了将生理数据整合到经济计量和认知心理学驱动的选择模型中，以改进决策理解，结果显示眼动追踪和压力数据显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统选择模型基于经济理论或心理学理论，但未充分探索生理数据对模型改进的潜力。本文旨在填补这一研究空白。

Method: 结合生理数据（如眼动追踪和压力测量）到经济计量和决策场理论（DFT）模型中，分别用于静态（住宿选择）和动态（驾驶模拟器实验）场景。

Result: 静态场景中，眼动追踪数据显著提升模型性能；动态场景中，压力数据和眼动追踪与DFT结合效果更佳。

Conclusion: 生理数据为选择模型提供了新价值，DFT框架在整合此类数据时表现更优。

Abstract: Choice models for large-scale applications have historically relied on
economic theories (e.g. utility maximisation) that establish relationships
between the choices of individuals, their characteristics, and the attributes
of the alternatives. In a parallel stream, choice models in cognitive
psychology have focused on modelling the decision-making process, but typically
in controlled scenarios. Recent research developments have attempted to bridge
the modelling paradigms, with choice models that are based on psychological
foundations, such as decision field theory (DFT), outperforming traditional
econometric choice models for travel mode and route choice behaviour. The use
of physiological data, which can provide indications about the choice-making
process and mental states, opens up the opportunity to further advance the
models. In particular, the use of such data to enrich 'process' parameters
within a cognitive theory-driven choice model has not yet been explored. This
research gap is addressed by incorporating physiological data into both
econometric and DFT models for understanding decision-making in two different
contexts: stated-preference responses (static) of accomodation choice and
gap-acceptance decisions within a driving simulator experiment (dynamic).
Results from models for the static scenarios demonstrate that both models can
improve substantially through the incorporation of eye-tracking information.
Results from models for the dynamic scenarios suggest that stress measurement
and eye-tracking data can be linked with process parameters in DFT, resulting
in larger improvements in comparison to simpler methods for incorporating this
data in either DFT or econometric models. The findings provide insights into
the value added by physiological data as well as the performance of different
candidate modelling frameworks for integrating such data.

</details>


### [378] [Poverty Targeting with Imperfect Information](https://arxiv.org/abs/2506.18188)
*Juan C. Yamin*

Main category: econ.EM

TL;DR: 论文提出了一种基于统计决策框架的EB目标规则，用于在发展中国家分配现金转移支付，优于传统的点估计方法。


<details>
  <summary>Details</summary>
Motivation: 发展中国家反贫困计划的关键挑战是依赖估计而非实际收入，导致目标错误。

Method: 提出统计决策框架和EB目标规则，通过收缩方法优化分配。

Result: EB规则在理想和实际应用中均优于传统方法，收敛速度与后验均值估计器相同。

Conclusion: EB规则显著改善目标准确性，适用于发展中国家反贫困计划。

Abstract: A key challenge for targeted antipoverty programs in developing countries is
that policymakers must rely on estimated rather than observed income, which
leads to substantial targeting errors. I propose a statistical decision
framework in which a benevolent planner, subject to a budget constraint and
equipped only with noisy income estimates, allocates cash transfers to the
poorest individuals. In this setting, the commonly used plug-in rule, which
allocates transfers based on point estimates, is inadmissible and uniformly
dominated by a shrinkage-based alternative. Building on this result, I propose
an empirical Bayes (EB) targeting rule. I show that the regret of the empirical
Bayes rule converges at the same rate as that of the posterior mean estimator,
despite applying a nonsmooth transformation to it. Simulations show that the EB
rule delivers large improvements over the plug-in approach in an idealized
setting and modest but consistent gains in a more realistic application.

</details>


### [379] [100-Day Analysis of USD/IDR Exchange Rate Dynamics Around the 2025 U.S. Presidential Inauguration](https://arxiv.org/abs/2506.18738)
*Sandy H. S. Herho,Siti N. Kaban,Cahya Nugraha*

Main category: econ.EM

TL;DR: 论文研究了2025年美国总统就职典礼对印尼盾汇率的影响，发现典礼后印尼盾显著贬值3.61%，但波动性稳定。


<details>
  <summary>Details</summary>
Motivation: 探讨政治过渡对新兴市场货币的潜在影响，为货币政策和风险管理提供依据。

Method: 采用100天对称窗口和非参数统计方法（10,000次自助抽样）分析分布特性和异常。

Result: 印尼盾贬值显著（效应量大），中心趋势明显变化，但波动性未变；检测到四个时间聚集的异常点。

Conclusion: 政治过渡对新兴市场货币有显著影响，对货币政策和风险管理具有重要启示。

Abstract: Using a 100-day symmetric window around the January 2025 U.S. presidential
inauguration, non-parametric statistical methods with bootstrap resampling
(10,000 iterations) analyze distributional properties and anomalies. Results
indicate a statistically significant 3.61\% Indonesian rupiah depreciation
post-inauguration, with a large effect size (Cliff's Delta $= -0.9224$, CI:
$[-0.9727, -0.8571]$). Central tendency shifted markedly, yet volatility
remained stable (variance ratio $= 0.9061$, $p = 0.504$). Four significant
anomalies exhibiting temporal clustering are detected. These findings provide
quantitative evidence of political transition effects on emerging market
currencies, highlighting implications for monetary policy and currency risk
management.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [380] [Social Group Bias in AI Finance](https://arxiv.org/abs/2506.17490)
*Thomas R. Cook,Sophia Kazinnik*

Main category: econ.GN

TL;DR: 论文研究了大型语言模型在金融信贷决策中的种族偏见，提出了一个可重复的反事实测试框架，揭示了显著的种族差异，并通过干预措施减少了70%的偏见。


<details>
  <summary>Details</summary>
Motivation: 金融领域依赖大型语言模型进行高风险决策，但模型可能存在有害偏见，需谨慎监管。本文聚焦信贷决策中的种族偏见，认为其反映了更广泛的金融应用问题。

Method: 采用可重复的反事实测试框架，模拟除种族外其他属性相同的抵押贷款申请人，评估模型响应。通过层次分析追踪敏感属性传播，并实施控制向量干预。

Result: 结果显示显著的种族差异，干预措施平均减少33%的偏见，最高达70%，且不影响模型整体性能。

Conclusion: 研究提供了一个透明、实用的工具包，用于识别和缓解金融领域大型语言模型的偏见。

Abstract: Financial institutions increasingly rely on large language models (LLMs) for
high-stakes decision-making. However, these models risk perpetuating harmful
biases if deployed without careful oversight. This paper investigates racial
bias in LLMs specifically through the lens of credit decision-making tasks,
operating on the premise that biases identified here are indicative of broader
concerns across financial applications. We introduce a reproducible,
counterfactual testing framework that evaluates how models respond to simulated
mortgage applicants identical in all attributes except race. Our results reveal
significant race-based discrepancies, exceeding historically observed bias
levels. Leveraging layer-wise analysis, we track the propagation of sensitive
attributes through internal model representations. Building on this, we deploy
a control-vector intervention that effectively reduces racial disparities by up
to 70% (33% on average) without impairing overall model performance. Our
approach provides a transparent and practical toolkit for the identification
and mitigation of bias in financial LLM deployments.

</details>


### [381] [An AI-powered Tool for Central Bank Business Liaisons: Quantitative Indicators and On-demand Insights from Firms](https://arxiv.org/abs/2506.18505)
*Nicholas Gray,Finn Lattimore,Kate McLoughlin,Callan Windsor*

Main category: econ.GN

TL;DR: 论文介绍了一种新的文本分析工具，用于处理和分析央行联络项目中的软信息，结合传统和现代自然语言处理技术，显著提升了工资增长预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 在政策不确定性增加的背景下，央行需要更多软信息来补充传统经济数据和模型预测。

Method: 开发了一种文本分析工具，结合传统技术和语言模型，支持快速查询、主题分析和数值提取。

Result: 将文本特征加入预测模型后，工资增长的即时预测性能显著提升，信号稀疏但有效。

Conclusion: 该工具为经济条件评估提供了新方法，文本特征在预测中具有独特价值。

Abstract: In a world of increasing policy uncertainty, central banks are relying more
on soft information sources to complement traditional economic statistics and
model-based forecasts. One valuable source of soft information comes from
intelligence gathered through central bank liaison programs -- structured
programs in which central bank staff regularly talk with firms to gather
insights. This paper introduces a new text analytics and retrieval tool that
efficiently processes, organises, and analyses liaison intelligence gathered
from firms using modern natural language processing techniques. The textual
dataset spans 25 years, integrates new information as soon as it becomes
available, and covers a wide range of business sizes and industries. The tool
uses both traditional text analysis techniques and powerful language models to
provide analysts and researchers with three key capabilities: (1) quickly
querying the entire history of business liaison meeting notes; (2) zooming in
on particular topics to examine their frequency (topic exposure) and analysing
the associated tone and uncertainty of the discussion; and (3) extracting
precise numerical values from the text, such as firms' reported figures for
wages and prices growth. We demonstrate how these capabilities are useful for
assessing economic conditions by generating text-based indicators of wages
growth and incorporating them into a nowcasting model. We find that adding
these text-based features to current best-in-class predictive models, combined
with the use of machine learning methods designed to handle many predictors,
significantly improves the performance of nowcasts for wages growth. Predictive
gains are driven by a small number of features, indicating a sparse signal in
contrast to other predictive problems in macroeconomics, where the signal is
typically dense.

</details>


### [382] [The Theory of Economic Complexity](https://arxiv.org/abs/2506.18829)
*César A. Hidalgo,Viktor Stojkoski*

Main category: econ.GN

TL;DR: 论文通过解析经济复杂性指数的特征向量，提出了一种基于经济活动的概率模型，验证了经济复杂性指标与多因素禀赋的关系。


<details>
  <summary>Details</summary>
Motivation: 尽管经济复杂性指数广泛用于解释经济增长、不平等和可持续性，但缺乏从第一性原理推导这些特征向量并将其置于机制模型中的理论。

Method: 通过解析计算特征向量，构建经济活动概率模型，并推广到其他生产函数和短期均衡框架。

Result: 经济复杂性指数（ECI）是经济禀赋概率的单调函数，且在多因素模型中估计了所有因素的平均禀赋。工资函数与复杂性相似经济体的收敛一致。

Conclusion: 研究解决了经济复杂性文献中的理论难题，验证了复杂性指标作为多因素禀赋估计的有效性。

Abstract: Economic complexity estimates rely on eigenvectors derived from matrices of
specialization to explain differences in economic growth, inequality, and
sustainability. Yet, despite their widespread use, we still lack a principled
theory that can deduce these eigenvectors from first principles and place them
in the context of a mechanistic model. Here, we calculate these eigenvectors
analytically for a model where the output of an economy in an activity
increases with the probability the economy is endowed with the factors required
by the activity. We show that the eigenvector known as the Economic Complexity
Index or ECI is a monotonic function of the probability that an economy is
endowed with a factor, and that in a multi-factor model, it is an estimate of
the average endowment across all factors. We then generalize this result to
other production functions and to a short-run equilibrium framework with
prices, wages, and consumption. We find that our main result does not depend on
the introduction of prices or wages, and that the derived wage function is
consistent with the convergence of economies with a similar level of
complexity. Finally, we use this model to explain the shape of networks of
related activities, such as the product space and the research space. These
findings solve long standing theoretical puzzles in the economic complexity
literature and validate the idea that metrics of economic complexity are
estimates of an economy being endowed with multiple factors.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [383] [Network Heterogeneity and Value of Information](https://arxiv.org/abs/2506.17660)
*Kota Murayama*

Main category: econ.TH

TL;DR: 研究支付异质性如何影响信息在选美比赛游戏中的价值，发现公共信息提供对福利有害的条件，并探讨信息共享的均衡效率问题。


<details>
  <summary>Details</summary>
Motivation: 探讨支付异质性对信息价值的影响，特别是在选美比赛游戏中公共信息对福利的作用。

Method: 分析Katz-Bonacich中心性的异质性形式及其对信息价值的影响，研究信息共享的均衡状态。

Result: 公共信息提供在某些条件下会损害福利，且信息共享的均衡可能效率低下。

Conclusion: 支付异质性和网络结构共同影响信息价值，信息共享的均衡可能非最优。

Abstract: This paper studies how payoff heterogeneity affects the value of information
in beauty contest games. I show that public information provision is
detrimental to welfare if and only if agents' Katz-Bonacich centralities
exhibit specific forms of heterogeneity, stemming from the network of
coordination motives. A key insight is that agents may value the commonality of
information so differently that some are harmed by their neighbors knowing what
others know. Leveraging this insight, I also show that when the commonality of
information is endogenously determined through information sharing, the
equilibrium degree of information sharing can be inefficiently low, even
without sharing costs.

</details>


### [384] [An Axiomatization of the Random Priority Rule](https://arxiv.org/abs/2506.17997)
*Christian Basteck*

Main category: econ.TH

TL;DR: 研究不可分割物品的公平随机分配问题，提出Random Priority方法满足平等、效率和单调性。


<details>
  <summary>Details</summary>
Motivation: 在无货币补偿情况下，确保公平分配不可分割物品。

Method: 采用Random Priority（随机优先）方法，满足平等对待、事后效率和概率单调性。

Result: 该方法在严格偏好域下等价于策略证明性，且与确定性规则的Maskin单调性一致。

Conclusion: Random Priority是一种公平且高效的随机分配机制。

Abstract: We study the problem of assigning indivisible objects to agents where each is
to receive at most one. To ensure fairness in the absence of monetary
compensation, we consider random assignments. Random Priority, also known as
Random Serial Dictatorship, is characterized by equal-treatment-of-equals,
ex-post efficiency and probabilistic (Maskin) monotonicity -- whenever
preferences change so that a given deterministic assignment is ranked weakly
higher by all agents, the probability of that assignment arising should be
weakly larger. Probabilistic monotonicity implies strategy-proofness (in a
stochastic dominance sense) for random assignment problems and is equivalent to
it on the universal domain of strict preferences; for deterministic rules it
coincides with Maskin monotonicity.

</details>


### [385] [Interim correlated rationalizability in large games](https://arxiv.org/abs/2506.18426)
*Lukasz Balbus,Michael Greinecker,Kevin Reffett,Lukasz Wozny*

Main category: econ.TH

TL;DR: 论文为大规模分布贝叶斯博弈中的战略不确定性提供了理论基础，使用了一种临时相关理性化方法，并在超模收益函数情况下与临时贝叶斯纳什均衡极值解对应。


<details>
  <summary>Details</summary>
Motivation: 研究大规模分布贝叶斯博弈中战略不确定性的建模问题，填补理论空白。

Method: 采用临时相关理性化方法，分析超模收益函数情况下的博弈结构。

Result: 在超模收益函数情况下，临时相关理性化解与临时贝叶斯纳什均衡极值解一致。

Conclusion: 论文框架和结果通过电子邮件博弈和全球博弈的大规模版本进行了验证。

Abstract: We provide general theoretical foundations for modeling strategic uncertainty
in large distributional Bayesian games with general type spaces, using a
version of interim correlated rationalizability. We then focus on the case in
which payoff functions are supermodular in actions, as is common in the
literature on global games. This structure allows us to identify extremal
interim correlated rationalizable solutions with extremal interim Bayes-Nash
equilibria. Notably, no order structure on types is assumed. We illustrate our
framework and results using the large versions of the electronic mail game and
a global game.

</details>


### [386] [Broad Validity of the First-Order Approach in Moral Hazard](https://arxiv.org/abs/2506.18873)
*Eduardo Azevedo,Ilan Wolff*

Main category: econ.TH

TL;DR: 研究表明，一阶方法（FOA）在代理人保留效用较高时有效，但在保留效用较低时可能失效。主定理证明了在有限责任模型中，当代理人保留效用足够高时，FOA有效，并推导了最优合约的存在性和唯一性。


<details>
  <summary>Details</summary>
Motivation: 探讨一阶方法（FOA）在道德风险委托-代理问题中的有效性，特别是在不同代理人保留效用条件下的适用性。

Method: 通过示例和主定理分析FOA的有效性，并在有限责任模型中验证其适用条件。

Result: FOA在代理人保留效用较高时普遍有效，而在保留效用较低时可能失效。最优合约在特定条件下存在且唯一。

Conclusion: FOA的适用性取决于代理人保留效用的高低，研究结果为多种常见输出分布下的最优合约设计提供了理论支持。

Abstract: The first-order approach (FOA) is the main tool for the moral hazard
principal-agent problem. Although many existing results rely on the FOA, its
validity has been established only under relatively restrictive assumptions. We
demonstrate in examples that the FOA frequently fails when the agent's
reservation utility is low (such as in principal-optimal contracts). However,
the FOA broadly holds when the agent's reservation utility is at least
moderately high (such as in competitive settings where agents receive high
rents). Our main theorem formalizes this point. The theorem shows that the FOA
is valid in a standard limited liability model when the agent's reservation
utility is sufficiently high. The theorem also establishes existence and
uniqueness of the optimal contract. We use the theorem to derive tractable
optimal contracts across several settings. Under log utility, option contracts
are optimal for numerous common output distributions (including Gaussian,
exponential, binomial, Gamma, and Laplace).

</details>


### [387] [Disaster Risk Financing through Taxation: A Framework for Regional Participation in Collective Risk-Sharing](https://arxiv.org/abs/2506.18895)
*Fallou Niakh,Arthur Charpentier,Caroline Hillairet,Philipp Ratz*

Main category: econ.TH

TL;DR: 研究提出了一种公私合作的多区域灾难保险框架，通过税收分摊剩余索赔以应对保险公司破产风险。


<details>
  <summary>Details</summary>
Motivation: 多区域灾难保险中，保险公司可能因系统性风险破产，需保护区域免受保险公司违约风险。

Method: 引入政府与保险公司的公私合作机制，政府通过税收分摊超出保险公司资本的剩余索赔。

Result: 提出了一个理论框架，考虑区域灾难风险和经济状况，实现集体风险分担。

Conclusion: 公私合作和税收分摊机制能有效应对多区域灾难保险中的系统性风险。

Abstract: We consider an economy composed of different risk profile regions wishing to
be hedged against a disaster risk using multi-region catastrophe insurance.
Such catastrophic events inherently have a systemic component; we consider
situations where the insurer faces a non-zero probability of insolvency. To
protect the regions against the risk of the insurer's default, we introduce a
public-private partnership between the government and the insurer. When a
disaster generates losses exceeding the total capital of the insurer, the
central government intervenes by implementing a taxation system to share the
residual claims. In this study, we propose a theoretical framework for regional
participation in collective risk-sharing through tax revenues by accounting for
their disaster risk profiles and their economic status.

</details>
