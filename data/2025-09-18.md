<div id=toc></div>

# Table of Contents

- [cs.AI](#cs.AI) [Total: 25]
- [cs.CL](#cs.CL) [Total: 39]
- [cs.CV](#cs.CV) [Total: 83]
- [cs.DB](#cs.DB) [Total: 4]
- [cs.DC](#cs.DC) [Total: 5]
- [cs.NI](#cs.NI) [Total: 9]
- [cs.PL](#cs.PL) [Total: 4]
- [cs.SE](#cs.SE) [Total: 16]
- [econ.EM](#econ.EM) [Total: 2]
- [econ.GN](#econ.GN) [Total: 6]
- [econ.TH](#econ.TH) [Total: 1]


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [1] [Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness](https://arxiv.org/abs/2509.13332)
*Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi*

Main category: cs.AI

TL;DR: 本研究系统比较了思考型和非思考型LLM在作为评判者时的表现，发现思考型模型在准确率、计算效率和鲁棒性方面均优于非思考型模型，即使经过多种增强策略改进后


<details>
  <summary>Details</summary>
Motivation: 随着LLM越来越多地被用作自动评判工具，确保其可靠性、效率和鲁棒性变得至关重要，需要系统评估思考型和非思考型LLM在评判任务中的表现差异

Method: 使用开源Qwen 3模型（0.6B、1.7B和4B参数），在RewardBench任务上评估准确性和计算效率（FLOPs），并测试了多种增强策略包括上下文学习、规则引导评判、基于参考的评估和n-best聚合

Result: 思考型模型准确率高出约10个百分点，计算开销仅增加不到2倍，而增强策略如少样本学习虽然带来适度提升但成本更高（>8倍）。在多种偏见条件下，思考型模型保持显著更高的一致性（平均高6%）

Conclusion: 显式推理在LLM作为评判者的范式中具有明显优势，不仅在准确性和效率方面，在鲁棒性方面也是如此，这一优势在多语言环境中也得到了验证

Abstract: As Large Language Models (LLMs) are increasingly adopted as automated judges
in benchmarking and reward modeling, ensuring their reliability, efficiency,
and robustness has become critical. In this work, we present a systematic
comparison of "thinking" and "non-thinking" LLMs in the LLM-as-a-judge paradigm
using open-source Qwen 3 models of relatively small sizes (0.6B, 1.7B, and 4B
parameters). We evaluate both accuracy and computational efficiency (FLOPs) on
RewardBench tasks, and further examine augmentation strategies for non-thinking
models, including in-context learning, rubric-guided judging, reference-based
evaluation, and n-best aggregation. Our results show that despite these
enhancements, non-thinking models generally fall short of their thinking
counterparts. Our results show that thinking models achieve approximately 10%
points higher accuracy with little overhead (under 2x), in contrast to
augmentation strategies like few-shot learning, which deliver modest gains at a
higher cost (>8x). Bias and robustness analyses further demonstrate that
thinking models maintain significantly greater consistency under a variety of
bias conditions such as positional, bandwagon, identity, diversity, and random
biases (6% higher on average). We further extend our experiments to the
multilingual setting and our results confirm that explicit reasoning extends
its benefits beyond English. Overall, our work results in several important
findings that provide systematic evidence that explicit reasoning offers clear
advantages in the LLM-as-a-judge paradigm not only in accuracy and efficiency
but also in robustness.

</details>


### [2] [Evaluation Awareness Scales Predictably in Open-Weights Large Language Models](https://arxiv.org/abs/2509.13333)
*Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma*

Main category: cs.AI

TL;DR: 研究发现大型语言模型存在评估意识行为，即模型能够区分评估和部署环境，这种能力随模型规模呈幂律增长，可用于预测未来更大模型的欺骗行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在评估时可能隐藏危险能力，破坏AI安全评估的有效性。先前研究仅在单个70B模型中发现此现象，但不同规模模型间的评估意识缩放关系尚不清楚。

Method: 使用线性探测方法分析15个不同规模模型（0.27B到70B参数）的转向向量激活，研究评估意识的缩放规律。

Result: 发现评估意识随模型规模呈清晰的幂律增长关系，这种缩放规律具有可预测性。

Conclusion: 该缩放定律可用于预测未来更大模型的欺骗行为，并为设计规模感知的AI安全评估策略提供指导。

Abstract: Large language models (LLMs) can internally distinguish between evaluation
and deployment contexts, a behaviour known as \emph{evaluation awareness}. This
undermines AI safety evaluations, as models may conceal dangerous capabilities
during testing. Prior work demonstrated this in a single $70$B model, but the
scaling relationship across model sizes remains unknown. We investigate
evaluation awareness across $15$ models scaling from $0.27$B to $70$B
parameters from four families using linear probing on steering vector
activations. Our results reveal a clear power-law scaling: evaluation awareness
increases predictably with model size. This scaling law enables forecasting
deceptive behavior in future larger models and guides the design of scale-aware
evaluation strategies for AI safety. A link to the implementation of this paper
can be found at
https://anonymous.4open.science/r/evaluation-awareness-scaling-laws/README.md.

</details>


### [3] [FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness](https://arxiv.org/abs/2509.13334)
*Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary*

Main category: cs.AI

TL;DR: 这篇论文提出了FRIT方法，通过干预训练教育语言模型产生因果一致的思维链，解决了以往思维链推理中经常出现的证据与结论无关的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的思维链推理方法在复杂任务上显著提升了大语言模型性能，但研究发现这些推理步骤经常无法因果性影响最终答案，导致输出弱弱且不可信，而现有方法主要集中于测量忠实性，缺乏系统改善的方法。

Method: 提出Faithful Reasoning via Intervention Training (FRIT)方法，通过在模型生成的思维链中对单个推理步骤进行干预来生成合成训练数据，创建忠实/非忠实的对比样本，然后使用直接偏好优化(DPO)教育模型偏好因果一致的推理路径。

Result: 在Qwen3-8B和Mistral-7B-v0.1模型上评测，在事实性和符号推理任务中都取得显著改善。Mistral模型在GSM8K任务上忠实推理提升3.4个百分点，准确性提升7.6个百分点。

Conclusion: FRIT方法提供了第一个可扩展、无监督的方法来训练语言模型产生更可靠和可解释的推理，解决了推理性能与可信过度之间的关键间隔。

Abstract: Chain-of-thought (CoT) reasoning has emerged as a powerful tool for improving
large language model performance on complex tasks, but recent work shows that
reasoning steps often fail to causally influence the final answer, creating
brittle and untrustworthy outputs. Prior approaches focus primarily on
measuring faithfulness, while methods for systematically improving it remain
limited. We introduce Faithful Reasoning via Intervention Training (FRIT), a
scalable alignment method that trains models to produce causally consistent
reasoning by learning from systematically corrupted examples. FRIT generates
synthetic training data by intervening on individual reasoning steps in
model-generated CoTs, creating faithful/unfaithful pairs that highlight when
reasoning breaks down. We then apply Direct Preference Optimization to teach
models to prefer causally consistent reasoning paths. Evaluating on Qwen3-8B
and Mistral-7B-v0.1 across factual and symbolic reasoning tasks, FRIT increases
faithful reasoning by $3.4$ percentage points for Mistral on GSM8K while
improving accuracy by $7.6$ percentage points. Our approach provides the first
scalable, supervision-free method for training language models to produce more
reliable and interpretable reasoning, addressing a critical gap between
reasoning performance and trustworthiness. We release our code at
\href{https://github.com/Anut-py/frit}.

</details>


### [4] [Position: AI Safety Must Embrace an Antifragile Perspective](https://arxiv.org/abs/2509.13339)
*Ming Jin,Hyunin Lee*

Main category: cs.AI

TL;DR: 本文主张AI安全研究应采用抗脆弱性视角，通过利用不确定性来增强系统处理罕见事件和长期安全的能力，而非仅仅追求静态测试和即时鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统静态基准测试和一次性鲁棒性测试无法应对环境演变和模型漂移问题（如奖励黑客攻击、过度优化等），需要建立能够随时间扩展安全保证能力的系统。

Method: 提出抗脆弱性方法框架，强调利用当前不确定性来为未来更大不确定性做准备，包括重新校准AI安全测量、基准测试和持续改进的方法论。

Result: 识别了静态测试的关键局限性（场景多样性不足、奖励黑客、过度对齐等），并探讨了抗脆弱性解决方案管理罕见事件的潜力。

Conclusion: 抗脆弱性方法对于开放式机器学习系统的长期可靠性至关重要，需要建立相应的伦理和实践指南来培育抗脆弱性AI安全社区。

Abstract: This position paper contends that modern AI research must adopt an
antifragile perspective on safety -- one in which the system's capacity to
guarantee long-term AI safety such as handling rare or out-of-distribution
(OOD) events expands over time. Conventional static benchmarks and single-shot
robustness tests overlook the reality that environments evolve and that models,
if left unchallenged, can drift into maladaptation (e.g., reward hacking,
over-optimization, or atrophy of broader capabilities). We argue that an
antifragile approach -- Rather than striving to rapidly reduce current
uncertainties, the emphasis is on leveraging those uncertainties to better
prepare for potentially greater, more unpredictable uncertainties in the future
-- is pivotal for the long-term reliability of open-ended ML systems. In this
position paper, we first identify key limitations of static testing, including
scenario diversity, reward hacking, and over-alignment. We then explore the
potential of antifragile solutions to manage rare events. Crucially, we
advocate for a fundamental recalibration of the methods used to measure,
benchmark, and continually improve AI safety over the long term, complementing
existing robustness approaches by providing ethical and practical guidelines
towards fostering an antifragile AI safety community.

</details>


### [5] [Imagined Autocurricula](https://arxiv.org/abs/2509.13341)
*Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder*

Main category: cs.AI

TL;DR: 利用世界模型生成想象环境训练智能体，通过IMAC方法实现自动课程学习，在有限数据下实现强泛化性能


<details>
  <summary>Details</summary>
Motivation: 解决在真实世界中缺乏大量训练数据和准确仿真的问题，利用离线被动收集的数据通过世界模型生成多样化的训练环境

Method: 提出IMAC（Imagined Autocurricula）方法，结合无监督环境设计（UED）技术，在世界模型生成的想象环境中实现自动课程学习

Result: 在具有挑战性的程序生成环境中，仅使用较窄数据集学习的世界模型进行训练，就能在保留环境中实现强大的迁移性能

Conclusion: 该方法为利用更大规模的基础世界模型训练通用智能体开辟了新路径

Abstract: Training agents to act in embodied environments typically requires vast
training data or access to accurate simulation, neither of which exists for
many cases in the real world. Instead, world models are emerging as an
alternative leveraging offline, passively collected data, they make it possible
to generate diverse worlds for training agents in simulation. In this work, we
harness world models to generate imagined environments to train robust agents
capable of generalizing to novel task variations. One of the challenges in
doing this is ensuring the agent trains on useful generated data. We thus
propose a novel approach, IMAC (Imagined Autocurricula), leveraging
Unsupervised Environment Design (UED), which induces an automatic curriculum
over generated worlds. In a series of challenging, procedurally generated
environments, we show it is possible to achieve strong transfer performance on
held-out environments, having trained only inside a world model learned from a
narrower dataset. We believe this opens the path to utilizing larger-scale,
foundation world models for generally capable agents.

</details>


### [6] [OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft](https://arxiv.org/abs/2509.13347)
*Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang*

Main category: cs.AI

TL;DR: 这篇论文提出了Chain of Action (CoA)框架，通过将高级规划与低级控制统一在单个视觉-语言-动作模型中，解决了动作空间选择的困境。该方法在Minecraft环境中创造了新的最高水平成绩。


<details>
  <summary>Details</summary>
Motivation: 现有抽象动作空间没有通用最优解，效果依赖于具体任务，这给构建通用人工智能代理带来困难。

Method: 提出Chain of Action (CoA)框架，将抽象动作视为类似思维链的中间推理步骤，指导生成最终可执行动作。训练了在多样化动作空间混合上的All-in-One代理。

Result: CoA框架在800个不同任务的综合测试中，超越了所有专门化的基线模型，创造了新的最高水平成绩。

Conclusion: CoA框架能够有效解决动作空间选择困境，学习到更稳健和可推广的策略，为构建通用人工智能代理提供了新的解决方案。

Abstract: The choice of action spaces is a critical yet unresolved challenge in
developing capable, end-to-end trainable agents. This paper first presents a
large-scale, systematic comparison of prominent abstracted action spaces and
tokenizers for Vision-Language-Action (VLA) or hierarchical agent models in the
open-ended Minecraft. Our analysis reveals that no single action space is
universally optimal; instead, the most effective abstraction is highly
task-dependent, creating a dilemma for building generalist agents. To resolve
this, we introduce Chain of Action (CoA), a novel framework that unifies
high-level planning and low-level control within a single, monolithic VLA
model. CoA treats an abstracted action not as a command for a separate policy,
but as an intermediate reasoning step--akin to a chain of thought--that guides
the generation of the final, executable action. Furthermore, we demonstrate
that an All-in-One agent trained on a diverse mixture of action spaces using
the CoA paradigm learns a more robust and generalizable policy. This unified
agent achieves a new state-of-the-art, improving the overall task success rate
over strong, specialized baselines. To foster reproducible research, we release
the OpenHA (Open Hierarchical Agents) suite, which includes our comprehensive
benchmark of over 800 distinct tasks, curated datasets, source code, and all
pretrained model checkpoints at https://github.com/CraftJarvis/OpenHA

</details>


### [7] [Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning](https://arxiv.org/abs/2509.13351)
*Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah*

Main category: cs.AI

TL;DR: 提出了PDDL-Instruct指令微调框架，通过逻辑思维链推理增强大语言模型在符号规划任务中的能力，在标准基准测试中达到94%的规划准确率，相比基线模型提升66%


<details>
  <summary>Details</summary>
Motivation: 大语言模型在多样化任务中表现出色，但在需要形式化表示（如PDDL）的结构化符号规划方面能力有限，需要弥合通用推理能力与自动规划所需逻辑精度之间的差距

Method: 开发指令提示引导模型通过精确的逻辑推理步骤，严格推理动作适用性、状态转换和计划有效性，将规划过程分解为关于前提条件满足、效果应用和不变性保持的显式推理链

Result: 在多个规划领域的实验结果表明，基于思维链推理的指令微调模型在规划方面显著更好，在标准基准测试中达到94%的规划准确率

Conclusion: 该工作为开发更好的AI规划系统提供了有前景的方向，成功弥合了大语言模型的通用推理能力与自动规划所需逻辑精度之间的差距

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across
diverse tasks, yet their ability to perform structured symbolic planning
remains limited, particularly in domains requiring formal representations like
the Planning Domain Definition Language (PDDL). In this paper, we present a
novel instruction tuning framework, PDDL-Instruct, designed to enhance LLMs'
symbolic planning capabilities through logical chain-of-thought reasoning. Our
approach focuses on teaching models to rigorously reason about action
applicability, state transitions, and plan validity using explicit logical
inference steps. By developing instruction prompts that guide models through
the precise logical reasoning required to determine when actions can be applied
in a given state, we enable LLMs to self-correct their planning processes
through structured reflection. The framework systematically builds verification
skills by decomposing the planning process into explicit reasoning chains about
precondition satisfaction, effect application, and invariant preservation.
Experimental results on multiple planning domains show that our
chain-of-thought reasoning based instruction-tuned models are significantly
better at planning, achieving planning accuracy of up to 94% on standard
benchmarks, representing a 66% absolute improvement over baseline models. This
work bridges the gap between the general reasoning capabilities of LLMs and the
logical precision required for automated planning, offering a promising
direction for developing better AI planning systems.

</details>


### [8] [Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning](https://arxiv.org/abs/2509.13352)
*Anis Koubaa,Khaled Gabr*

Main category: cs.AI

TL;DR: 提出了Agentic UAVs框架，通过五层架构（感知、推理、行动、集成、学习）将大型语言模型与无人机系统集成，显著提升了自主决策能力和任务执行效果。


<details>
  <summary>Details</summary>
Motivation: 现有无人机系统主要依赖基于规则的控制和窄AI，在动态不确定任务中适应性差，缺乏情境感知推理和生态系统级集成能力，特别是没有利用LLM进行实时知识访问。

Method: 开发了五层架构框架（感知、推理、行动、集成、学习），集成ROS2和Gazebo原型系统，结合YOLOv11目标检测与GPT-4推理，并部署本地Gemma-3模型。

Result: 在模拟搜救场景中，检测置信度从0.72提升到0.79，人员检测率从75%提高到91%，行动推荐率从4.5%大幅提升至92%。

Conclusion: 适度的计算开销能够实现质的自主性提升和生态系统集成，证明了LLM驱动的无人机系统在复杂任务中的有效性。

Abstract: Unmanned Aerial Vehicles (UAVs) are increasingly deployed in defense,
surveillance, and disaster response, yet most systems remain confined to SAE
Level 2--3 autonomy. Their reliance on rule-based control and narrow AI
restricts adaptability in dynamic, uncertain missions. Existing UAV frameworks
lack context-aware reasoning, autonomous decision-making, and ecosystem-level
integration; critically, none leverage Large Language Model (LLM) agents with
tool-calling for real-time knowledge access. This paper introduces the Agentic
UAVs framework, a five-layer architecture (Perception, Reasoning, Action,
Integration, Learning) that augments UAVs with LLM-driven reasoning, database
querying, and third-party system interaction. A ROS2 and Gazebo-based prototype
integrates YOLOv11 object detection with GPT-4 reasoning and local Gemma-3
deployment. In simulated search-and-rescue scenarios, agentic UAVs achieved
higher detection confidence (0.79 vs. 0.72), improved person detection rates
(91% vs. 75%), and markedly increased action recommendation (92% vs. 4.5%).
These results confirm that modest computational overhead enables qualitatively
new levels of autonomy and ecosystem integration.

</details>


### [9] [Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling](https://arxiv.org/abs/2509.13357)
*Yongchao Huang,Hassan Raza*

Main category: cs.AI

TL;DR: 语义融合：一种轻量级方案，通过并行模糊成员特征通道增强Transformer语言模型，提升语义理解能力


<details>
  <summary>Details</summary>
Motivation: 为了解决传统语言模型在语义理解和可控生成方面的局限性，需要一种能够编码可解释语义特征并保持模型简洁性的方法

Method: 使用并行模糊成员特征通道，为每个token生成包含词性、浅层角色、边界标志、情感极性等可解释特征的向量，通过门控适配器融合到语言模型中，结合标准下一词预测、语义特征重构辅助损失和形容词分布正则化进行训练

Result: 在合成双子句语料库上，语义融合降低了困惑度，实现了精确的用户可控极性标点生成，同时保持模型简洁性，仅增加少量计算开销

Conclusion: 语义融合为条件自然语言生成提供了可解释的途径，完全兼容输入输出嵌入绑定，是一种有效的轻量级语义增强方案

Abstract: We propose semantic fusion, a lightweight scheme that augments a Transformer
language model (LM) with a parallel, fuzzy-membership feature channel that
encodes token-level semantics. Each token is represented by a vector of
interpretable features (e.g. part-of-speech cues, shallow roles, boundary
flags, sentiment polarity and strength) whose values are graded degrees from
differentiable membership functions (e.g. power kernels). These per-token
vectors form a sentence-level semantic matrix fused via a gated adapter into
the LM. Training uses standard next-token prediction, an auxiliary loss that
reconstructs the semantic features from hidden states, and a lightweight
uniformizer that regularizes adjective-class distributions. On a synthetic
two-clause corpus with held-out adjectives for out-of-distribution (OOD)
control, semantic fusion improves perplexity and enables precise,
user-controllable generation of polarity and punctuation while maintaining
model simplicity. This approach adds only small overhead, remains fully
compatible with tied input-output embeddings, and provides an interpretable
pathway for conditioned natural language generation.

</details>


### [10] [Asterisk Operator](https://arxiv.org/abs/2509.13364)
*Zixi Li*

Main category: cs.AI

TL;DR: 提出了星号操作符（∗-operator）这一新颖的统一框架，基于邻接结构并行传播（ASPP）进行抽象推理。该操作符将结构化推理任务形式化为由隐式关系图引导的局部并行状态演化过程。


<details>
  <summary>Details</summary>
Motivation: 为了解决抽象推理问题，需要一种既能保持局部计算约束又能实现全局推理能力的统一框架，以提供高效且收敛的计算范式。

Method: 基于邻接结构并行传播（ASPP）的星号操作符，将推理任务形式化为局部并行状态演化过程，并提出了Embedding-Asterisk蒸馏方法。

Result: 在ARC2挑战和康威生命游戏中验证了操作符的通用性、收敛性和优越性能，仅用600万参数就在ARC2验证集上达到100%准确率。

Conclusion: 星号操作符为神经符号推理提供了重大突破，证明了其在保持局部计算约束的同时实现全局推理能力的有效性。

Abstract: We propose the \textbf{Asterisk Operator} ($\ast$-operator), a novel unified
framework for abstract reasoning based on Adjacency-Structured Parallel
Propagation (ASPP). The operator formalizes structured reasoning tasks as
local, parallel state evolution processes guided by implicit relational graphs.
We prove that the $\ast$-operator maintains local computational constraints
while achieving global reasoning capabilities, providing an efficient and
convergent computational paradigm for abstract reasoning problems. Through
rigorous mathematical analysis and comprehensive experiments on ARC2 challenges
and Conway's Game of Life, we demonstrate the operator's universality,
convergence properties, and superior performance. Our innovative
Embedding-Asterisk distillation method achieves 100\% accuracy on ARC2
validation with only 6M parameters, representing a significant breakthrough in
neural-symbolic reasoning.
  \textbf{Keywords:} Abstract Reasoning, Adjacency Structure, Parallel
Propagation, Asterisk Operator, Convergence, Universal Approximation

</details>


### [11] [$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation](https://arxiv.org/abs/2509.13368)
*Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li*

Main category: cs.AI

TL;DR: Agent²是一个完全自动化的强化学习代理生成框架，通过LLM驱动将自然语言任务描述转换为高性能RL解决方案，无需人工干预


<details>
  <summary>Details</summary>
Motivation: 传统RL代理开发需要大量专业知识和迭代，失败率高且可访问性有限，需要实现完全自动化的RL代理设计

Method: 采用双代理架构：生成器代理分析任务并生成可执行RL代理，目标代理是自动生成的RL代理。框架将RL开发分解为MDP建模和算法优化两个阶段

Result: 在MuJoCo、MetaDrive、MPE和SMAC等多个基准测试中，Agent²始终优于手动设计的解决方案，性能提升高达55%

Conclusion: 这项工作建立了智能代理设计和优化其他代理的新范式，实现了真正的端到端闭环自动化，是自动化AI系统的根本性突破

Abstract: Reinforcement learning agent development traditionally requires extensive
expertise and lengthy iterations, often resulting in high failure rates and
limited accessibility. This paper introduces $Agent^2$, a novel
agent-generates-agent framework that achieves fully automated RL agent design
through intelligent LLM-driven generation. The system autonomously transforms
natural language task descriptions and environment code into comprehensive,
high-performance reinforcement learning solutions without human intervention.
$Agent^2$ features a revolutionary dual-agent architecture. The Generator Agent
serves as an autonomous AI designer that analyzes tasks and generates
executable RL agents, while the Target Agent is the resulting automatically
generated RL agent. The framework decomposes RL development into two distinct
stages: MDP modeling and algorithmic optimization, enabling more targeted and
effective agent generation. Built on the Model Context Protocol, $Agent^2$
provides a unified framework that standardizes intelligent agent creation
across diverse environments and algorithms, while incorporating adaptive
training management and intelligent feedback analysis for continuous
improvement. Extensive experiments on a wide range of benchmarks, including
MuJoCo, MetaDrive, MPE, and SMAC, demonstrate that $Agent^2$ consistently
outperforms manually designed solutions across all tasks, achieving up to 55%
performance improvement and substantial gains on average. By enabling truly
end-to-end, closed-loop automation, this work establishes a new paradigm in
which intelligent agents design and optimize other agents, marking a
fundamental breakthrough for automated AI systems.

</details>


### [12] [The Art of Saying "Maybe": A Conformal Lens for Uncertainty Benchmarking in VLMs](https://arxiv.org/abs/2509.13379)
*Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez*

Main category: cs.AI

TL;DR: 对16个最先进的视觉语言模型在6个多模态数据集上进行全面的不确定性基准测试，发现更大模型具有更好的不确定性量化能力，数学和推理任务的不确定性表现较差


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在复杂视觉理解方面取得显著进展，但不确定性量化这一关键维度未得到足够关注，需要超越有限的共形预测研究进行综合评估

Method: 评估16个开源和闭源的最先进VLM，使用6个多模态数据集和3种不同的评分函数进行不确定性基准测试

Result: 更大模型展现更好的不确定性量化能力；确定性更高的模型准确率更高；数学和推理任务在所有模型中表现出较差的不确定性性能

Conclusion: 这项工作为多模态系统中可靠的不确定性评估奠定了基础

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in complex
visual understanding across scientific and reasoning tasks. While performance
benchmarking has advanced our understanding of these capabilities, the critical
dimension of uncertainty quantification has received insufficient attention.
Therefore, unlike prior conformal prediction studies that focused on limited
settings, we conduct a comprehensive uncertainty benchmarking study, evaluating
16 state-of-the-art VLMs (open and closed-source) across 6 multimodal datasets
with 3 distinct scoring functions. Our findings demonstrate that larger models
consistently exhibit better uncertainty quantification; models that know more
also know better what they don't know. More certain models achieve higher
accuracy, while mathematical and reasoning tasks elicit poorer uncertainty
performance across all models compared to other domains. This work establishes
a foundation for reliable uncertainty evaluation in multimodal systems.

</details>


### [13] [From Next Token Prediction to (STRIPS) World Models -- Preliminary Results](https://arxiv.org/abs/2509.13389)
*Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner*

Main category: cs.AI

TL;DR: 使用转换器模型通过动作序列预测学习STRIPS世界模型，可以从正负例动作序列中学习并准确表示命题逻辑STRIPS模型。


<details>
  <summary>Details</summary>
Motivation: 从动作踪迹中学习命题逻辑STRIPS世界模型，无需人工标注，通过深度学习方法自动推断动作前提和效果。

Method: 将任务派生为监督下一个标记预测问题，使用转换器模型学习动作序列。通过正确和错误的动作序列进行训练，让模型自动学习动作前提条件和隐藏效果。

Result: 转换器模型能够实现对命题逻辑STRIPS世界模型的忠实表示，并从随机生成的有效和无效动作序列中成功学习到模型。实验结果验证了方法的有效性。

Conclusion: 深度学习方法可以从纯动作踪迹中有效学习STRIPS世界模型，为自动化规划和人工智能领域提供了新的模型学习途径。

Abstract: We consider the problem of learning propositional STRIPS world models from
action traces alone, using a deep learning architecture (transformers) and
gradient descent. The task is cast as a supervised next token prediction
problem where the tokens are the actions, and an action $a$ may follow an
action sequence if the hidden effects of the previous actions do not make an
action precondition of $a$ false. We show that a suitable transformer
architecture can faithfully represent propositional STRIPS world models, and
that the models can be learned from sets of random valid (positive) and invalid
(negative) action sequences alone. A number of experiments are reported.

</details>


### [14] [SteeringControl: Holistic Evaluation of Alignment Steering in LLMs](https://arxiv.org/abs/2509.13450)
*Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang*

Main category: cs.AI

TL;DR: SteeringControl是一个评估表示引导方法的基准，用于测试偏见、有害生成和幻觉等核心对齐目标及其对次要行为的影响。研究发现引导效果取决于方法、模型和目标的特定组合，不良组合会导致严重的概念纠缠。


<details>
  <summary>Details</summary>
Motivation: 现有对齐工作主要关注真实性或推理能力，但对表示引导方法的副作用和权衡缺乏系统性理解，需要全面评估引导方法在不同行为上的效果。

Method: 构建包含安全相关主要和次要行为的数据集，基于五个流行引导方法创建模块化引导框架，在Qwen-2.5-7B和Llama-3.1-8B模型上进行评估。

Result: 强引导性能取决于引导方法、模型和目标行为的特定组合，不良组合会导致严重的概念纠缠问题。

Conclusion: 需要仔细选择引导方法、模型和目标行为的组合，以避免概念纠缠并获得最佳引导效果，为表示引导方法的系统性评估提供了基准框架。

Abstract: We introduce SteeringControl, a benchmark for evaluating representation
steering methods across core alignment objectives--bias, harmful generation,
and hallucination--and their effects on secondary behaviors such as sycophancy
and commonsense morality. While prior alignment work often highlights
truthfulness or reasoning ability to demonstrate the side effects of
representation steering, we find there are many unexplored tradeoffs not yet
understood in a systematic way. We collect a dataset of safety-relevant primary
and secondary behaviors to evaluate steering effectiveness and behavioral
entanglement centered around five popular steering methods. To enable this, we
craft a modular steering framework based on unique components that serve as the
building blocks of many existing methods. Our results on Qwen-2.5-7B and
Llama-3.1-8B find that strong steering performance is dependent on the specific
combination of steering method, model, and targeted behavior, and that severe
concept entanglement can result from poor combinations of these three as well.
We release our code here:
https://github.com/wang-research-lab/SteeringControl.git.

</details>


### [15] [AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving](https://arxiv.org/abs/2509.13547)
*Harper Reed,Michael Sugimura,Angelo Zangari*

Main category: cs.AI

TL;DR: 为LLM智能体提供类似人类的协作工具和自主性可以显著提升其在最困难编程问题上的表现，成本降低15-40%，交互轮次减少12-27%，完成速度提高12-38%。


<details>
  <summary>Details</summary>
Motivation: 研究是否通过赋予LLM智能体人类自然使用的协作工具和自主性，能够改善其问题解决性能。

Method: 为Claude Code智能体配备基于MCP的社交媒体和日志记录工具，允许它们自主使用这些工具来解决34个Aider多语言Python编程挑战。

Result: 协作工具在最具挑战性的问题上显著提升性能，不同模型自然采用不同的协作策略，智能体表现出2-9倍的写作偏好而非阅读。

Conclusion: AI智能体在其能力边缘可以系统性地受益于人类启发的协作工具，这表明自适应协作界面可以作为推理增强器而非通用效率提升手段。

Abstract: We investigate whether giving LLM agents the collaborative tools and autonomy
that humans naturally use for problem solving can improve their performance. We
equip Claude Code agents with MCP-based social media and journaling tools and
allow them to use these tools as they see fit. Across 34 Aider Polyglot Python
programming challenges, collaborative tools substantially improve performance
on the hardest problems, delivering 15-40% lower cost, 12-27% fewer turns, and
12-38% faster completion than baseline agents. Effects on the full challenge
set are mixed, suggesting these tools act as performance enhancers when
additional reasoning scaffolding is most needed. Surprisingly, Different models
naturally adopted distinct collaborative strategies without explicit
instruction. Sonnet 3.7 engaged broadly across tools and benefited from
articulation-based cognitive scaffolding. Sonnet 4 showed selective adoption,
leaning on journal-based semantic search when problems were genuinely
difficult. This mirrors how human developers adjust collaboration based on
expertise and task complexity. Behavioral analysis shows agents prefer writing
over reading by about 2-9x, indicating that structured articulation drives much
of the improvement rather than information access alone. Overall, AI agents can
systematically benefit from human-inspired collaboration tools at the edge of
their capabilities, pointing to adaptive collaborative interfaces as reasoning
enhancers rather than universal efficiency boosts.

</details>


### [16] [Gen AI in Proof-based Math Courses: A Pilot Study](https://arxiv.org/abs/2509.13570)
*Hannah Klawa,Shraddha Rajpal,Cigole Thomas*

Main category: cs.AI

TL;DR: 这篇论文研究了在高等教育中生成式AI的应用，重点分析了数学证明课程中学生对AI工具的使用情况和认知，为数学教学中AI的整合提供了建议。


<details>
  <summary>Details</summary>
Motivation: 由于生成式AI在高等教育中的快速兴起和当前AI检测工具的不可靠性，需要开发能够鼓励学生学习和批判性思维的政策。

Method: 研究在三门证明基础的数学课程中进行：一学期抽象代数、拓扑学和二学期抽象代数。课程政策允许某些AI使用。通过调查响应和学生访谎，分析学生如何使用AI工具、对生成式AI有用性和限制的看法，以及这些认知对教学的含义。

Result: 研究分析了学生使用AI工具的方式、对生成式AI有用性和限制的认知，以及这些认知对证明基础数学教学的含义。

Conclusion: 研究讨论了将生成式AI整合到证明基础数学教学中的未来考虑因素，为数学教育领域的AI应用提供了有价值的建议。

Abstract: With the rapid rise of generative AI in higher education and the
unreliability of current AI detection tools, developing policies that encourage
student learning and critical thinking has become increasingly important. This
study examines student use and perceptions of generative AI across three
proof-based undergraduate mathematics courses: a first-semester abstract
algebra course, a topology course and a second-semester abstract algebra
course. In each case, course policy permitted some use of generative AI.
Drawing on survey responses and student interviews, we analyze how students
engaged with AI tools, their perceptions of generative AI's usefulness and
limitations, and what implications these perceptions hold for teaching
proof-based mathematics. We conclude by discussing future considerations for
integrating generative AI into proof-based mathematics instruction.

</details>


### [17] [Programmable Cognitive Bias in Social Agents](https://arxiv.org/abs/2509.13588)
*Xuan Liu,Haoyang Shang,Haojian Jin*

Main category: cs.AI

TL;DR: CoBRA是一个用于在基于LLM的社会模拟中系统化指定智能体行为的新工具包，通过显式编程认知偏见来解决传统自然语言描述方法的一致性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过隐式自然语言描述指定智能体行为存在两个问题：无法在不同模型间产生一致行为，且生成的行为无法捕捉描述的细微差别。

Method: CoBRA包含两个组件：1) 认知偏见指数 - 通过量化智能体在一组验证过的经典社会科学实验中的反应来测量其认知偏见；2) 行为调节引擎 - 调整智能体行为以展示受控的认知偏见。

Result: 评估显示CoBRA能够以模型无关的方式精确编程社会智能体中展示的认知偏见。

Conclusion: CoBRA提供了一种新的方法来显式编程智能体的认知偏见，通过基于经典社会科学实验来锚定预期行为，解决了传统方法的局限性。

Abstract: This paper introduces CoBRA, a novel toolkit for systematically specifying
agent behavior in LLM-based social simulation. We found that conventional
approaches that specify agent behaviors through implicit natural language
descriptions cannot yield consistent behaviors across models, and the produced
agent behaviors do not capture the nuances of the descriptions. In contrast,
CoBRA presents a new approach to program agents' cognitive biases explicitly,
by grounding agents' expected behaviors using classic social science
experiments. CoBRA has two components: (1) Cognitive Bias Index that measures
the cognitive bias of a social agent, by quantifying the agent's reactions in a
set of validated classical social science experiments; (2) Behavioral
Regulation Engine that aligns the agent's behavior to demonstrate controlled
cognitive bias. We evaluated CoBRA as an HCI toolkit through demonstration and
technical benchmarks. Our results suggest that CoBRA can precisely program the
cognitive bias demonstrated in a social agent in a model-agnostic manner.

</details>


### [18] [InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management](https://arxiv.org/abs/2509.13704)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: InfraMind是一个专门为工业管理系统设计的基于探索的GUI代理框架，通过五个创新模块解决LLM-based GUI代理在工业管理中的五大挑战，在DCIM平台上显著优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 工业基础设施管理软件面临系统复杂性增加、多供应商集成和专家操作员短缺的挑战。传统RPA自动化灵活性有限且维护成本高，而通用LLM-based GUI代理在工业管理中存在元素理解、精度效率、状态定位、部署约束和安全要求等五大挑战。

Method: 提出InfraMind框架，包含五个创新模块：1）基于系统搜索探索和虚拟机快照的自主GUI理解；2）内存驱动规划确保高精度高效任务执行；3）高级状态识别用于分层界面中的鲁棒定位；4）结构化知识蒸馏实现轻量模型高效部署；5）多层安全机制保护敏感操作。

Result: 在开源和商业DCIM平台上的广泛实验表明，该方法在任务成功率和操作效率方面持续优于现有框架。

Conclusion: InfraMind为工业管理自动化提供了一个严格且可扩展的解决方案，有效解决了LLM-based GUI代理在工业环境中的关键挑战。

Abstract: Mission-critical industrial infrastructure, such as data centers,
increasingly depends on complex management software. Its operations, however,
pose significant challenges due to the escalating system complexity,
multi-vendor integration, and a shortage of expert operators. While Robotic
Process Automation (RPA) offers partial automation through handcrafted scripts,
it suffers from limited flexibility and high maintenance costs. Recent advances
in Large Language Model (LLM)-based graphical user interface (GUI) agents have
enabled more flexible automation, yet these general-purpose agents face five
critical challenges when applied to industrial management, including unfamiliar
element understanding, precision and efficiency, state localization, deployment
constraints, and safety requirements. To address these issues, we propose
InfraMind, a novel exploration-based GUI agentic framework specifically
tailored for industrial management systems. InfraMind integrates five
innovative modules to systematically resolve different challenges in industrial
management: (1) systematic search-based exploration with virtual machine
snapshots for autonomous understanding of complex GUIs; (2) memory-driven
planning to ensure high-precision and efficient task execution; (3) advanced
state identification for robust localization in hierarchical interfaces; (4)
structured knowledge distillation for efficient deployment with lightweight
models; and (5) comprehensive, multi-layered safety mechanisms to safeguard
sensitive operations. Extensive experiments on both open-source and commercial
DCIM platforms demonstrate that our approach consistently outperforms existing
frameworks in terms of task success rate and operational efficiency, providing
a rigorous and scalable solution for industrial management automation.

</details>


### [19] [See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles](https://arxiv.org/abs/2509.13615)
*Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu*

Main category: cs.AI

TL;DR: 提出了State-aware Reasoning (StaR)训练方法，解决多模态代理在GUI切换控制中的可靠性问题，通过感知当前状态和分析指令需求状态来提升执行准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态代理在执行GUI切换控制指令时不可靠，特别是在当前状态已符合目标状态时表现不佳，这成为GUI控制的关键瓶颈。

Method: 构建状态控制基准测试集，提出StaR训练方法，教导代理感知当前切换状态、分析指令期望状态，并相应执行操作。

Result: 在三个多模态代理上实验显示，StaR能将切换指令执行准确率提升30%以上，在三个公共基准测试中也提升了通用任务性能。

Conclusion: StaR方法有效解决了GUI切换控制问题，在动态环境评估中显示出实际应用潜力，为多模态代理的可靠GUI交互提供了解决方案。

Abstract: The advent of multimodal agents facilitates effective interaction within
graphical user interface (GUI), especially in ubiquitous GUI control. However,
their inability to reliably execute toggle control instructions remains a key
bottleneck. To investigate this, we construct a state control benchmark with
binary toggle instructions from public datasets. Evaluations of existing agents
demonstrate their unreliability, particularly when the current toggle state
already matches the desired state. To address the challenge, we propose
State-aware Reasoning (StaR), a training method that teaches agents to perceive
the current toggle state, analyze the desired state from the instruction, and
act accordingly. Experiments on three multimodal agents demonstrate that StaR
can improve toggle instruction execution accuracy by over 30\%. Further
evaluations on three public benchmarks show that StaR also enhances general
task performance. Finally, evaluations on a dynamic environment highlight the
potential of StaR for real-world applications. Code, benchmark, and
StaR-enhanced agents are available at https://github.com/ZrW00/StaR.

</details>


### [20] [THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning](https://arxiv.org/abs/2509.13761)
*Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao*

Main category: cs.AI

TL;DR: THOR是一个通过强化学习实现工具集成和分层优化的框架，用于提升LLM在数学推理和代码生成任务中的性能，解决了数据构建、细粒度优化和推理增强三个关键挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面取得显著进展，但在高精度任务（如数值计算和符号操作）上仍存在困难。现有工具集成方法在数据构建、细粒度优化和推理增强方面面临挑战。

Method: 1. TIRGen：基于多智能体actor-critic的流水线，构建高质量工具集成推理路径数据集；2. 分层强化学习策略：联合优化轨迹级问题解决和步骤级代码生成；3. 自校正机制：利用工具反馈动态修正推理错误。

Result: 该方法在不同模型上表现出强泛化能力，在数学基准测试中达到同规模模型的最先进性能，同时在代码基准测试上实现一致改进。

Conclusion: THOR框架通过工具集成和分层优化有效提升了LLM在高精度数学推理任务中的性能，为解决工具集成中的关键挑战提供了有效解决方案。

Abstract: Large Language Models (LLMs) have made remarkable progress in mathematical
reasoning, but still continue to struggle with high-precision tasks like
numerical computation and formal symbolic manipulation. Integrating external
tools has emerged as a promising approach to bridge this gap. Despite recent
advances, existing methods struggle with three key challenges: constructing
tool-integrated reasoning data, performing fine-grained optimization, and
enhancing inference. To overcome these limitations, we propose THOR
(Tool-Integrated Hierarchical Optimization via RL). First, we introduce TIRGen,
a multi-agent actor-critic-based pipeline for constructing high-quality
datasets of tool-integrated reasoning paths, aligning with the policy and
generalizing well across diverse models. Second, to perform fine-grained
hierarchical optimization, we introduce an RL strategy that jointly optimizes
for both trajectory-level problem solving and step-level code generation. This
is motivated by our key insight that the success of an intermediate tool call
is a strong predictor of the final answer's correctness. Finally, THOR
incorporates a self-correction mechanism that leverages immediate tool feedback
to dynamically revise erroneous reasoning paths during inference. Our approach
demonstrates strong generalization across diverse models, performing
effectively in both reasoning and non-reasoning models. It further achieves
state-of-the-art performance for models of a similar scale on multiple
mathematical benchmarks, while also delivering consistent improvements on code
benchmarks. Our code will be publicly available at
https://github.com/JingMog/THOR.

</details>


### [21] [MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation](https://arxiv.org/abs/2509.13773)
*Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong*

Main category: cs.AI

TL;DR: MIRA是一个智能手机AI任务指令推荐框架，通过长按图像或文本来提供上下文相关的AI任务指令建议，使用多模态大语言模型和结构化推理来提升推荐准确性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的快速发展，智能手机需要更直观的方式来访问预定义的AI服务，简化用户与设备的交互。

Method: 采用多模态大语言模型(MLLM)的推荐管道进行结构化推理，结合模板增强推理机制和前缀树约束解码策略，确保指令建议的准确性和一致性。

Result: 在真实标注数据集和用户研究中，MIRA在指令推荐准确性方面表现出显著提升。

Conclusion: MIRA有潜力彻底改变用户在智能手机上与AI服务的交互方式，提供更无缝和高效的体验。

Abstract: The rapid advancement of generative AI technologies is driving the
integration of diverse AI-powered services into smartphones, transforming how
users interact with their devices. To simplify access to predefined AI
services, this paper introduces MIRA, a pioneering framework for task
instruction recommendation that enables intuitive one-touch AI tasking on
smartphones. With MIRA, users can long-press on images or text objects to
receive contextually relevant instruction recommendations for executing AI
tasks. Our work introduces three key innovations: 1) A multimodal large
language model (MLLM)-based recommendation pipeline with structured reasoning
to extract key entities, infer user intent, and generate precise instructions;
2) A template-augmented reasoning mechanism that integrates high-level
reasoning templates, enhancing task inference accuracy; 3) A prefix-tree-based
constrained decoding strategy that restricts outputs to predefined instruction
candidates, ensuring coherent and intent-aligned suggestions. Through
evaluation using a real-world annotated datasets and a user study, MIRA has
demonstrated substantial improvements in the accuracy of instruction
recommendation. The encouraging results highlight MIRA's potential to
revolutionize the way users engage with AI services on their smartphones,
offering a more seamless and efficient experience.

</details>


### [22] [An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques](https://arxiv.org/abs/2509.13880)
*Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan*

Main category: cs.AI

TL;DR: 本文提出了一种基于DPLL架构的精确方法来解决整数线性约束的模型计数问题，通过集成混合整数规划中的简化技术显著提升了效率，在随机和应用基准测试中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 线性约束是计算机科学、运筹学和优化领域中最基本的约束之一，许多应用问题都可归结为整数线性约束的模型计数问题(MCILC)，需要高效的解决方案。

Method: 基于详尽的DPLL架构设计精确方法，并集成混合整数规划中的多种有效简化技术来提升效率。

Result: 在2840个随机基准和4131个应用基准测试中，该方法在随机基准上解决了1718个实例（最先进方法仅解决1470个），并且是唯一能解决所有4131个应用实例的方法。

Conclusion: 所提出的方法在整数线性约束模型计数问题上显著优于所有现有精确方法，特别是在应用实例上表现出色，证明了集成混合整数规划简化技术的有效性。

Abstract: Linear constraints are one of the most fundamental constraints in fields such
as computer science, operations research and optimization. Many applications
reduce to the task of model counting over integer linear constraints (MCILC).
In this paper, we design an exact approach to MCILC based on an exhaustive DPLL
architecture. To improve the efficiency, we integrate several effective
simplification techniques from mixed integer programming into the architecture.
We compare our approach to state-of-the-art MCILC counters and propositional
model counters on 2840 random and 4131 application benchmarks. Experimental
results show that our approach significantly outperforms all exact methods in
random benchmarks solving 1718 instances while the state-of-the-art approach
only computes 1470 instances. In addition, our approach is the only approach to
solve all 4131 application instances.

</details>


### [23] [Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks](https://arxiv.org/abs/2509.13968)
*Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel*

Main category: cs.AI

TL;DR: 该研究使用人工神经网络模型探讨信息流结构变化是否能带来认知性能的过渡性转变，发现循环网络相比前馈网络在处理复杂语法时表现出质的性能提升，并观察到训练难度形成的过渡障碍特征。


<details>
  <summary>Details</summary>
Motivation: 探索认知进化是否通过主要转变实现，特别是生物神经网络信息流结构的根本性变化如何影响认知性能的过渡性改变。

Method: 使用理想化信息流模型和人工神经网络，比较前馈、循环和分层拓扑结构，在控制网络大小和资源的情况下测试它们学习不同复杂度人工语法的性能。

Result: 循环网络相比前馈网络能够处理更广泛的输入类型，在最复杂语法学习上表现出质的性能提升；循环网络的训练难度形成了过渡障碍和偶然不可逆性；分层网络在语法学习任务中并未表现出优势。

Conclusion: 某些信息流结构的变化确实能够导致认知性能的过渡性转变，这支持了认知进化可能通过主要转变实现的假设，同时揭示了网络拓扑变化并非都能带来性能优势。

Abstract: Transitional accounts of evolution emphasise a few changes that shape what is
evolvable, with dramatic consequences for derived lineages. More recently it
has been proposed that cognition might also have evolved via a series of major
transitions that manipulate the structure of biological neural networks,
fundamentally changing the flow of information. We used idealised models of
information flow, artificial neural networks (ANNs), to evaluate whether
changes in information flow in a network can yield a transitional change in
cognitive performance. We compared networks with feed-forward, recurrent and
laminated topologies, and tested their performance learning artificial grammars
that differed in complexity, controlling for network size and resources. We
documented a qualitative expansion in the types of input that recurrent
networks can process compared to feed-forward networks, and a related
qualitative increase in performance for learning the most complex grammars. We
also noted how the difficulty in training recurrent networks poses a form of
transition barrier and contingent irreversibility -- other key features of
evolutionary transitions. Not all changes in network topology confer a
performance advantage in this task set. Laminated networks did not outperform
non-laminated networks in grammar learning. Overall, our findings show how some
changes in information flow can yield transitions in cognitive performance.

</details>


### [24] [CrowdAgent: Multi-Agent Managed Multi-Source Annotation System](https://arxiv.org/abs/2509.14030)
*Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang*

Main category: cs.AI

TL;DR: CrowdAgent是一个多智能体系统，通过整合任务分配、数据标注和质量/成本管理，为LLM、SLM和人类专家提供端到端的协同标注流程控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注标注步骤本身，缺乏对多样化标注源（LLM、SLM、人类专家）的动态管理和质量-成本权衡的统一控制。

Method: 采用多智能体系统架构，实现任务分配、数据标注和质量/成本管理的端到端流程控制，使不同标注源能够协同工作。

Result: 在六个多模态分类任务上的广泛实验证明了CrowdAgent的有效性。

Conclusion: CrowdAgent提供了一种新颖的端到端流程控制方法，能够有效管理多样化标注源，实现协同标注工作流。

Abstract: High-quality annotated data is a cornerstone of modern Natural Language
Processing (NLP). While recent methods begin to leverage diverse annotation
sources-including Large Language Models (LLMs), Small Language Models (SLMs),
and human experts-they often focus narrowly on the labeling step itself. A
critical gap remains in the holistic process control required to manage these
sources dynamically, addressing complex scheduling and quality-cost trade-offs
in a unified manner. Inspired by real-world crowdsourcing companies, we
introduce CrowdAgent, a multi-agent system that provides end-to-end process
control by integrating task assignment, data annotation, and quality/cost
management. It implements a novel methodology that rationally assigns tasks,
enabling LLMs, SLMs, and human experts to advance synergistically in a
collaborative annotation workflow. We demonstrate the effectiveness of
CrowdAgent through extensive experiments on six diverse multimodal
classification tasks. The source code and video demo are available at
https://github.com/QMMMS/CrowdAgent.

</details>


### [25] [Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning](https://arxiv.org/abs/2509.14195)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 本文通过层次架构验证二阶学习促进环境-认知同构性的假设，GCN作为一阶学习器预测最优路径，MLP控制器作为二阶学习器动态调整参数，在迷宫任务中展现显著性能提升和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 验证现有理论假设：二阶学习（调整一阶学习机制的学习）能够促进结构化内部心理表征的形成，使其与外部环境同构，这是高级认知的基础但难以实证研究。

Method: 提出分层架构：使用图卷积网络(GCN)作为一阶学习器直接映射节点特征到最优路径预测，使用MLP控制器作为二阶学习器在遇到结构新颖的迷宫环境时动态调整GCN参数。

Result: 当认知系统发展出与环境结构同构的内部心理地图时，二阶学习特别有效。定量和定性结果显示了在未见迷宫任务上的显著性能改进和强大泛化能力。

Conclusion: 研究为结构化心理表征在最大化二阶学习效果中的关键作用提供了实证支持，证实了环境-认知同构性对高级认知功能的重要性。

Abstract: Mental representation, characterized by structured internal models mirroring
external environments, is fundamental to advanced cognition but remains
challenging to investigate empirically. Existing theory hypothesizes that
second-order learning -- learning mechanisms that adapt first-order learning
(i.e., learning about the task/domain) -- promotes the emergence of such
environment-cognition isomorphism. In this paper, we empirically validate this
hypothesis by proposing a hierarchical architecture comprising a Graph
Convolutional Network (GCN) as a first-order learner and an MLP controller as a
second-order learner. The GCN directly maps node-level features to predictions
of optimal navigation paths, while the MLP dynamically adapts the GCN's
parameters when confronting structurally novel maze environments. We
demonstrate that second-order learning is particularly effective when the
cognitive system develops an internal mental map structurally isomorphic to the
environment. Quantitative and qualitative results highlight significant
performance improvements and robust generalization on unseen maze tasks,
providing empirical support for the pivotal role of structured mental
representations in maximizing the effectiveness of second-order learning.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [26] [Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs](https://arxiv.org/abs/2509.13480)
*Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli*

Main category: cs.CL

TL;DR: 首次系统评估LLM在意大利语性别中性改写任务中的表现，开放源LLM超越专门模型，细调模型在小规模下达到相当性能


<details>
  <summary>Details</summary>
Motivation: 意大利语作为语法性别语言，性别中性改写面临特别挑战，需要系统评估现有LLM的表现

Method: 提出两维评估框架（中性性和语义保真度），比较少样本提示、细调选择模型并应用目标清理提升任务相关性

Result: 开放权重LLM表现超过专门模型，细调模型在小规模下使用少量计算资源即可达到相当性能

Conclusion: 评估框架有效、细调方案高效，但需在中性性和语义保真间找到平衡

Abstract: Gender-neutral rewriting (GNR) aims to reformulate text to eliminate
unnecessary gender specifications while preserving meaning, a particularly
challenging task in grammatical-gender languages like Italian. In this work, we
conduct the first systematic evaluation of state-of-the-art large language
models (LLMs) for Italian GNR, introducing a two-dimensional framework that
measures both neutrality and semantic fidelity to the input. We compare
few-shot prompting across multiple LLMs, fine-tune selected models, and apply
targeted cleaning to boost task relevance. Our findings show that open-weight
LLMs outperform the only existing model dedicated to GNR in Italian, whereas
our fine-tuned models match or exceed the best open-weight LLM's performance at
a fraction of its size. Finally, we discuss the trade-off between optimizing
the training data for neutrality and meaning preservation.

</details>


### [27] [Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning](https://arxiv.org/abs/2509.13539)
*Alisa Kanganis,Katherine A. Keith*

Main category: cs.CL

TL;DR: 美联储FOMC会议纪录数据集Op-Fed的构建和分析，包含1044个人工标注句子，重点解决类别不平衡和语境依赖问题


<details>
  <summary>Details</summary>
Motivation: 美联储FOMC议息对货币政策和公众借贷消费决策有重大影响，需要构建一个高质量的语料库来分析其中的观点和立场

Method: 采用五步分层标注框架来分离观点、货币政策和立场等方面，并通过主动学习选择标注实例，大幅提高正样本数量

Result: 最佳闭源LLM在观点分类中达到0.80的零样本准确率，但在货币政策立场分类中仅有0.61（人类基准0.89）

Conclusion: Op-Fed数据集可用于未来模型训练、信心检验和作为后续标注工作的基础数据，显示了货币政策立场分析的复杂性

Abstract: The U.S. Federal Open Market Committee (FOMC) regularly discusses and sets
monetary policy, affecting the borrowing and spending decisions of millions of
people. In this work, we release Op-Fed, a dataset of 1044 human-annotated
sentences and their contexts from FOMC transcripts. We faced two major
technical challenges in dataset creation: imbalanced classes -- we estimate
fewer than 8% of sentences express a non-neutral stance towards monetary policy
-- and inter-sentence dependence -- 65% of instances require context beyond the
sentence-level. To address these challenges, we developed a five-stage
hierarchical schema to isolate aspects of opinion, monetary policy, and stance
towards monetary policy as well as the level of context needed. Second, we
selected instances to annotate using active learning, roughly doubling the
number of positive instances across all schema aspects. Using Op-Fed, we found
a top-performing, closed-weight LLM achieves 0.80 zero-shot accuracy in opinion
classification but only 0.61 zero-shot accuracy classifying stance towards
monetary policy -- below our human baseline of 0.89. We expect Op-Fed to be
useful for future model training, confidence calibration, and as a seed dataset
for future annotation efforts.

</details>


### [28] [Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12](https://arxiv.org/abs/2509.13569)
*John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc*

Main category: cs.CL

TL;DR: DSTC12 Track 1针对对话系统评估提出两个子任务：多维度自动评估和多语言文化安全检测，基线模型表现显示在文化安全方面仍有很大改进空间


<details>
  <summary>Details</summary>
Motivation: 大型语言模型快速发展需要更强大的对话系统评估方法，传统指标不足且安全考虑常存在文化偏见

Method: 设置两个子任务：1）对话级多维度自动评估指标（10个维度）；2）多语言多文化安全检测，提供数据集和基线模型（Llama-3-8B和Llama-Guard-3-1B）

Result: 任务1中Llama-3-8B基线平均Spearman相关系数0.1681；任务2中多语言安全检测团队表现优异（最高ROC-AUC 0.9648），但文化安全检测基线表现更好（0.5126 ROC-AUC）

Conclusion: 对话系统评估在多维度自动评估和文化安全意识方面仍需显著改进，特别是在文化敏感的安全检测领域存在重要需求

Abstract: The rapid advancement of Large Language Models (LLMs) has intensified the
need for robust dialogue system evaluation, yet comprehensive assessment
remains challenging. Traditional metrics often prove insufficient, and safety
considerations are frequently narrowly defined or culturally biased. The DSTC12
Track 1, "Dialog System Evaluation: Dimensionality, Language, Culture and
Safety," is part of the ongoing effort to address these critical gaps. The
track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic
Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection.
For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved
the highest average Spearman's correlation (0.1681), indicating substantial
room for improvement. In Task 2, while participating teams significantly
outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top
ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126
ROC-AUC), highlighting critical needs in culturally-aware safety. This paper
describes the datasets and baselines provided to participants, as well as
submission evaluation results for each of the two proposed subtasks.

</details>


### [29] [Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning](https://arxiv.org/abs/2509.13624)
*Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang*

Main category: cs.CL

TL;DR: 这篇论文提出了一种分析框架，通过转移学习矩阵和降维技术来探索语言模型在任务间的跨任务交互作用，发现隐藏的统计因素比表面数据相似性更能影响转移学习效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型的普遍部署，实际应用中常遇到模型训练未要覆盖的任务，而枚举所有任务的高质量训练数据是不可行的，因此需要研究转移学习在不同特征数据集上的效果和预期外分布请求的处理能力。

Method: 构建转移学习矩阵和使用降维技术，训练分析10个模型来识别潜在能力（如逻辑推理、情感分类、自然语言理解、算术运算等）和发现转移学习的副作用。

Result: 研究发现性能收益常常无法通过表面数据相似性或源数据质量来解释，而是源数据集的隐藏统计因素（如类别分布、生成长度偏好）以及特定语言特征更具影响力。

Conclusion: 这项工作揭示了转移学习的复杂动态机制，为更可预测和有效的大语言模型适配掌平了道路。

Abstract: Large language models are increasingly deployed across diverse applications.
This often includes tasks LLMs have not encountered during training. This
implies that enumerating and obtaining the high-quality training data for all
tasks is infeasible. Thus, we often need to rely on transfer learning using
datasets with different characteristics, and anticipate out-of-distribution
requests. Motivated by this practical need, we propose an analysis framework,
building a transfer learning matrix and dimensionality reduction, to dissect
these cross-task interactions. We train and analyze 10 models to identify
latent abilities (e.g., Reasoning, Sentiment Classification, NLU, Arithmetic)
and discover the side effects of the transfer learning. Our findings reveal
that performance improvements often defy explanations based on surface-level
dataset similarity or source data quality. Instead, hidden statistical factors
of the source dataset, such as class distribution and generation length
proclivities, alongside specific linguistic features, are actually more
influential. This work offers insights into the complex dynamics of transfer
learning, paving the way for more predictable and effective LLM adaptation.

</details>


### [30] [Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs](https://arxiv.org/abs/2509.13664)
*Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu*

Main category: cs.CL

TL;DR: 研究发现LLMs在内部神经元层面线性编码问题歧义性，通过操纵少量歧义编码神经元可以控制模型从直接回答转为弃权


<details>
  <summary>Details</summary>
Motivation: 现实问题普遍存在歧义性，但大语言模型往往自信回答而非寻求澄清，需要理解模型如何内部表示歧义信息

Method: 在模型预填充阶段识别歧义编码神经元(AENs)，训练探针进行歧义检测，并通过神经元操纵控制模型行为

Result: 仅需1个神经元即可编码歧义信息，AENs探针在歧义检测上表现优异且具有跨数据集泛化能力，浅层神经元早期编码歧义信号

Conclusion: LLMs形成紧凑的内部歧义表示，支持可解释和可控的行为，为模型歧义处理机制提供了新见解

Abstract: Ambiguity is pervasive in real-world questions, yet large language models
(LLMs) often respond with confident answers rather than seeking clarification.
In this work, we show that question ambiguity is linearly encoded in the
internal representations of LLMs and can be both detected and controlled at the
neuron level. During the model's pre-filling stage, we identify that a small
number of neurons, as few as one, encode question ambiguity information. Probes
trained on these Ambiguity-Encoding Neurons (AENs) achieve strong performance
on ambiguity detection and generalize across datasets, outperforming
prompting-based and representation-based baselines. Layerwise analysis reveals
that AENs emerge from shallow layers, suggesting early encoding of ambiguity
signals in the model's processing pipeline. Finally, we show that through
manipulating AENs, we can control LLM's behavior from direct answering to
abstention. Our findings reveal that LLMs form compact internal representations
of question ambiguity, enabling interpretable and controllable behavior.

</details>


### [31] [CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction](https://arxiv.org/abs/2509.13672)
*Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim*

Main category: cs.CL

TL;DR: 提出了首个中文文献语法纠错持续学习基准CL²GEC，包含10个学科的1万条标注句子，评估LLM在跨学科语法纠错中的持续学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有中文语法纠错研究缺乏多学科学术写作的专门基准，忽视了持续学习在处理领域特定语言变异和防止灾难性遗忘方面的潜力。

Method: 构建包含10个学科1万句标注数据的CL²GEC基准，评估大语言模型在顺序调优、参数高效适应和4种代表性持续学习算法下的表现。

Result: 实验结果表明，基于正则化的方法比基于回放或简单顺序方法更能有效缓解遗忘问题。

Conclusion: 该基准为跨学科学术领域的自适应语法纠错研究提供了严谨的基础。

Abstract: The growing demand for automated writing assistance in diverse academic
domains highlights the need for robust Chinese Grammatical Error Correction
(CGEC) systems that can adapt across disciplines. However, existing CGEC
research largely lacks dedicated benchmarks for multi-disciplinary academic
writing, overlooking continual learning (CL) as a promising solution to handle
domain-specific linguistic variation and prevent catastrophic forgetting. To
fill this crucial gap, we introduce CL$^2$GEC, the first Continual Learning
benchmark for Chinese Literature Grammatical Error Correction, designed to
evaluate adaptive CGEC across multiple academic fields. Our benchmark includes
10,000 human-annotated sentences spanning 10 disciplines, each exhibiting
distinct linguistic styles and error patterns. CL$^2$GEC focuses on evaluating
grammatical error correction in a continual learning setting, simulating
sequential exposure to diverse academic disciplines to reflect real-world
editorial dynamics. We evaluate large language models under sequential tuning,
parameter-efficient adaptation, and four representative CL algorithms, using
both standard GEC metrics and continual learning metrics adapted to task-level
variation. Experimental results reveal that regularization-based methods
mitigate forgetting more effectively than replay-based or naive sequential
approaches. Our benchmark provides a rigorous foundation for future research in
adaptive grammatical error correction across diverse academic domains.

</details>


### [32] [AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation](https://arxiv.org/abs/2509.13677)
*Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu*

Main category: cs.CL

TL;DR: AgentCTG是一个新颖的可扩展框架，通过模拟多智能体工作流中的控制和调节机制，实现了对文本生成的精确复杂控制，在多个公开数据集上达到最先进效果。


<details>
  <summary>Details</summary>
Motivation: 自然语言处理中的受控文本生成面临细粒度条件控制的挑战，实际应用中还需要考虑成本、可扩展性、领域知识学习和更精确控制等需求。

Method: 提出AgentCTG框架，模拟多智能体工作流机制，探索不同智能体间的协作方法，并引入自动提示模块来增强生成效果。

Result: 在多个公开数据集上达到最先进结果，在角色驱动重写任务中有效转换文本以符合特定角色特征并保留领域知识，在在线导航角色扮演中显著提升驾驶体验。

Conclusion: AgentCTG通过优化上下文相关文本的生成，实现了更沉浸式的在线社区交互，促进了更高的个性化和用户参与度。

Abstract: Although significant progress has been made in many tasks within the field of
Natural Language Processing (NLP), Controlled Text Generation (CTG) continues
to face numerous challenges, particularly in achieving fine-grained conditional
control over generation. Additionally, in real scenario and online
applications, cost considerations, scalability, domain knowledge learning and
more precise control are required, presenting more challenge for CTG. This
paper introduces a novel and scalable framework, AgentCTG, which aims to
enhance precise and complex control over the text generation by simulating the
control and regulation mechanisms in multi-agent workflows. We explore various
collaboration methods among different agents and introduce an auto-prompt
module to further enhance the generation effectiveness. AgentCTG achieves
state-of-the-art results on multiple public datasets. To validate its
effectiveness in practical applications, we propose a new challenging
Character-Driven Rewriting task, which aims to convert the original text into
new text that conform to specific character profiles and simultaneously
preserve the domain knowledge. When applied to online navigation with
role-playing, our approach significantly enhances the driving experience
through improved content delivery. By optimizing the generation of contextually
relevant text, we enable a more immersive interaction within online
communities, fostering greater personalization and user engagement.

</details>


### [33] [Improving Context Fidelity via Native Retrieval-Augmented Reasoning](https://arxiv.org/abs/2509.13683)
*Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu*

Main category: cs.CL

TL;DR: CARE框架通过教导LLM在推理过程中显式整合上下文证据，显著提升了检索准确性和答案生成性能，无需昂贵的监督微调


<details>
  <summary>Details</summary>
Motivation: 解决LLM在基于给定信息回答问题时存在上下文保真度不足、答案不一致的问题，现有方法要么依赖昂贵的监督微调，要么无法有效利用给定上下文

Method: 提出CARE框架，教导LLM利用自身检索能力在推理过程中显式整合上下文证据，使用有限的标注证据数据，通过策略性检索的上下文token增强推理链

Result: 在多个真实世界和反事实QA基准测试中，该方法显著优于监督微调、传统检索增强生成方法和外部检索解决方案

Conclusion: 这项工作是使LLM在知识密集型任务中更加准确、可靠和高效的根本性进展

Abstract: Large language models (LLMs) often struggle with context fidelity, producing
inconsistent answers when responding to questions based on provided
information. Existing approaches either rely on expensive supervised
fine-tuning to generate evidence post-answer or train models to perform web
searches without necessarily improving utilization of the given context. We
propose CARE, a novel native retrieval-augmented reasoning framework that
teaches LLMs to explicitly integrate in-context evidence within their reasoning
process with the model's own retrieval capabilities. Our method requires
limited labeled evidence data while significantly enhancing both retrieval
accuracy and answer generation performance through strategically retrieved
in-context tokens in the reasoning chain. Extensive experiments on multiple
real-world and counterfactual QA benchmarks demonstrate that our approach
substantially outperforms supervised fine-tuning, traditional
retrieval-augmented generation methods, and external retrieval solutions. This
work represents a fundamental advancement in making LLMs more accurate,
reliable, and efficient for knowledge-intensive tasks.

</details>


### [34] [Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?](https://arxiv.org/abs/2509.13695)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 构建日语比较级NLI数据集评估LLM性能，发现模型对提示格式敏感，在日语特有语言现象上表现不佳，但逻辑语义表示能提升推理能力


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数值和逻辑推理方面仍有挑战，特别是在非主导语言如日语中的比较级推理能力尚未充分探索

Method: 构建日语比较级NLI数据集，在零样本和少样本设置下评估多种LLM，分析提示格式和标注示例的影响

Result: 模型性能对零样本提示格式敏感，受少样本示例标注影响；在日语特有语言现象上表现困难；包含逻辑语义表示的提示能帮助解决推理问题

Conclusion: LLM在日语比较级推理中存在局限性，但逻辑语义表示可以提升模型性能，需要针对非主导语言开发更好的推理方法

Abstract: Large Language Models (LLMs) perform remarkably well in Natural Language
Inference (NLI). However, NLI involving numerical and logical expressions
remains challenging. Comparatives are a key linguistic phenomenon related to
such inference, but the robustness of LLMs in handling them, especially in
languages that are not dominant in the models' training data, such as Japanese,
has not been sufficiently explored. To address this gap, we construct a
Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in
zero-shot and few-shot settings. Our results show that the performance of the
models is sensitive to the prompt formats in the zero-shot setting and
influenced by the gold labels in the few-shot examples. The LLMs also struggle
to handle linguistic phenomena unique to Japanese. Furthermore, we observe that
prompts containing logical semantic representations help the models predict the
correct labels for inference problems that they struggle to solve even with
few-shot examples.

</details>


### [35] [Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes](https://arxiv.org/abs/2509.13696)
*Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller*

Main category: cs.CL

TL;DR: 使用DSPy提示优化技术将指令调优的LLM应用于临床笔记和结构化EHR数据的联合处理，在临床分类任务上达到与专业多模态系统相当的性能


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成方面表现出色，但在处理涉及结构化数据（如时间序列）的临床分类任务方面的能力尚未得到充分探索

Method: 采用基于DSPy的提示优化技术来适配指令调优的LLM，使其能够联合处理临床笔记和结构化EHR输入

Result: 该方法在性能上与专业多模态系统相当，同时需要更少的复杂性，并在不同任务间具有更好的适应性

Conclusion: 基于提示优化的LLM适配方法为临床分类任务提供了一种有效且灵活的解决方案，能够处理多模态临床数据

Abstract: Large language models (LLMs) excel at text generation, but their ability to
handle clinical classification tasks involving structured data, such as time
series, remains underexplored. In this work, we adapt instruction-tuned LLMs
using DSPy-based prompt optimization to process clinical notes and structured
EHR inputs jointly. Our results show that this approach achieves performance on
par with specialized multimodal systems while requiring less complexity and
offering greater adaptability across tasks.

</details>


### [36] [DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models](https://arxiv.org/abs/2509.13702)
*Xiao Zheng*

Main category: cs.CL

TL;DR: DSCC-HS是一个主动式框架，通过在自回归解码过程中注入实时引导向量来抑制LLM幻觉，无需修改目标模型，在TruthfulQA和BioGEN基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法如RAG通常是反应式的，LLM幻觉问题严重阻碍了其可靠部署，需要一种主动干预的解决方案。

Method: 基于双过程认知理论，使用紧凑代理模型分别作为事实对齐代理(FAP)和幻觉检测代理(HDP)，在推理时动态计算并注入FAP和HDP对数概率差异作为引导向量。

Result: 在TruthfulQA上达到99.2%的事实一致性率，在BioGEN基准上获得最高的FActScore 46.50，验证了方法的有效性。

Conclusion: DSCC-HS提供了一个原则性且高效的解决方案，能够显著提升LLM的事实准确性，具有即插即用的优势。

Abstract: Large Language Model (LLM) hallucination is a significant barrier to their
reliable deployment. Current methods like Retrieval-Augmented Generation (RAG)
are often reactive. We introduce **Dynamic Self-reinforcing Calibration for
Hallucination Suppression (DSCC-HS)**, a novel, proactive framework that
intervenes during autoregressive decoding. Inspired by dual-process cognitive
theory, DSCC-HS uses a compact proxy model, trained in adversarial roles as a
Factual Alignment Proxy (FAP) and a Hallucination Detection Proxy (HDP). During
inference, these proxies dynamically steer a large target model by injecting a
real-time steering vector, which is the difference between FAP and HDP logits,
at each decoding step. This plug-and-play approach requires no modification to
the target model. Our experiments on TruthfulQA and BioGEN show DSCC-HS
achieves state-of-the-art performance. On TruthfulQA, it reached a 99.2%
Factual Consistency Rate (FCR). On the long-form BioGEN benchmark, it attained
the highest FActScore of 46.50. These results validate DSCC-HS as a principled
and efficient solution for enhancing LLM factuality.

</details>


### [37] [Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models](https://arxiv.org/abs/2509.13706)
*Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang*

Main category: cs.CL

TL;DR: 使用NLP技术开发能够识别高严重性事故报告的跨机构模型，在精细编辑的数据集上达到了类似于人类的表现


<details>
  <summary>Details</summary>
Motivation: 医疗事故报告手工审查耗时耗力，需要专业知识，需要自动化工具来识别高严重性事故

Method: 使用政府机构(7,094份)和IAEA SAFRON(571份)两个数据集，训练SVM和BlueBERT模型，采用跨机构转移学习技术

Result: 在本机构测试集上AUROC达0.81-0.82，跨机构测试无转移学习时性能下降(0.42-0.56)，使用转移学习后提升到0.78，在精细编辑数据集上模型性能类似人类(AUROC 0.74-0.85 vs 0.81)

Conclusion: 成功开发了能够跨机构识别高严重性事故报告的NLP模型，在精细数据上达到了与人类相似的性能

Abstract: PURPOSE: Incident reports are an important tool for safety and quality
improvement in healthcare, but manual review is time-consuming and requires
subject matter expertise. Here we present a natural language processing (NLP)
screening tool to detect high-severity incident reports in radiation oncology
across two institutions.
  METHODS AND MATERIALS: We used two text datasets to train and evaluate our
NLP models: 7,094 reports from our institution (Inst.), and 571 from IAEA
SAFRON (SF), all of which had severity scores labeled by clinical content
experts. We trained and evaluated two types of models: baseline support vector
machines (SVM) and BlueBERT which is a large language model pretrained on
PubMed abstracts and hospitalized patient data. We assessed for
generalizability of our model in two ways. First, we evaluated models trained
using Inst.-train on SF-test. Second, we trained a BlueBERT_TRANSFER model that
was first fine-tuned on Inst.-train then on SF-train before testing on SF-test
set. To further analyze model performance, we also examined a subset of 59
reports from our Inst. dataset, which were manually edited for clarity.
  RESULTS Classification performance on the Inst. test achieved AUROC 0.82
using SVM and 0.81 using BlueBERT. Without cross-institution transfer learning,
performance on the SF test was limited to an AUROC of 0.42 using SVM and 0.56
using BlueBERT. BlueBERT_TRANSFER, which was fine-tuned on both datasets,
improved the performance on SF test to AUROC 0.78. Performance of SVM, and
BlueBERT_TRANSFER models on the manually curated Inst. reports (AUROC 0.85 and
0.74) was similar to human performance (AUROC 0.81).
  CONCLUSION: In summary, we successfully developed cross-institution NLP
models on incident report text from radiation oncology centers. These models
were able to detect high-severity reports similarly to humans on a curated
dataset.

</details>


### [38] [DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning](https://arxiv.org/abs/2509.13723)
*Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan*

Main category: cs.CL

TL;DR: 这篇论文提出了一种双阶段无训练提示压缩方法DSPC，通过语义相关句子筛选和关键词洗净，在保持语义的同时大幅减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决LLM提示越来越长导致计算成本高的问题，现有压缩方法需要训练辅助模型，计算成本大。

Method: 双阶段无训练方法DSPC：粗粒度阶段用TF-IDF筛选语义相关句子，细粒度阶段用注意力贡献、交叉模型损失差和位置重要性评估关键词并优化。

Result: 在LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo上验证，在仅使用3倍更少词汇的情况下，在Longbench数据集的FewShot任务中达到49.17性能，超过最佳基线LongLLMLingua 7.76。

Conclusion: DSPC方法能够在不需要训练的情况下高效压缩提示，显著降低计算成本同时保持性能。

Abstract: Large language models (LLMs) have achieved remarkable success in many natural
language processing (NLP) tasks. To achieve more accurate output, the prompts
used to drive LLMs have become increasingly longer, which incurs higher
computational costs. To address this prompt inflation problem, prompt
compression has been proposed. However, most existing methods require training
a small auxiliary model for compression, incurring a significant amount of
additional computation. To avoid this, we propose a two-stage, training-free
approach, called Dual-Stage Progressive Compression (DSPC). In the
coarse-grained stage, semantic-related sentence filtering removes sentences
with low semantic value based on TF-IDF. In the fine-grained stage, token
importance is assessed using attention contribution, cross-model loss
difference, and positional importance, enabling the pruning of low-utility
tokens while preserving semantics. We validate DSPC on LLaMA-3.1-8B-Instruct
and GPT-3.5-Turbo under a constrained token budget and observe consistent
improvements. For instance, in the FewShot task of the Longbench dataset, DSPC
achieves a performance of 49.17 by using only 3x fewer tokens, outperforming
the best state-of-the-art baseline LongLLMLingua by 7.76.

</details>


### [39] [Implementing a Logical Inference System for Japanese Comparatives](https://arxiv.org/abs/2509.13734)
*Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka*

Main category: cs.CL

TL;DR: 本研究提出ccg-jcomp系统，一种基于组合语义学的日语比较句逻辑推理系统，以解决日语比较句的语法和语义特性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 日语比较句在形态和语义上与英语存在显著差异，使得现有的逻辑推理系统无法直接应用于日语。需要专门的系统来处理日语比较句的自然语言推理问题。

Method: 基于组合语义学的逻辑推理方法，构建了ccg-jcomp系统。该系统采用逻辑基础来处理数量和比较关系的表达。

Result: 在日语比较句NLI数据集上评估，并与现有大语言模型进行了准确率比较。结果显示ccg-jcomp系统具有有效性。

Conclusion: 本研究成功开发了一种专门处理日语比较句的逻辑推理系统，为日语自然语言推理领域提供了可靠的解决方案。

Abstract: Natural Language Inference (NLI) involving comparatives is challenging
because it requires understanding quantities and comparative relations
expressed by sentences. While some approaches leverage Large Language Models
(LLMs), we focus on logic-based approaches grounded in compositional semantics,
which are promising for robust handling of numerical and logical expressions.
Previous studies along these lines have proposed logical inference systems for
English comparatives. However, it has been pointed out that there are several
morphological and semantic differences between Japanese and English
comparatives. These differences make it difficult to apply such systems
directly to Japanese comparatives. To address this gap, this study proposes
ccg-jcomp, a logical inference system for Japanese comparatives based on
compositional semantics. We evaluate the proposed system on a Japanese NLI
dataset containing comparative expressions. We demonstrate the effectiveness of
our system by comparing its accuracy with that of existing LLMs.

</details>


### [40] [Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications](https://arxiv.org/abs/2509.13775)
*Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi*

Main category: cs.CL

TL;DR: 本文探索了阿拉伯方言识别的数据效率和参数效率方法，包括软提示策略和LoRA重参数化，发现LoRA微调模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究阿拉伯方言识别的效率方法，分析大语言模型在少样本或零样本情况下的方言区分能力。

Method: 使用软提示策略（前缀调整、提示调整、P调整等）和LoRA重参数化，在多个阿拉伯数据集上进行实验，并分析了解码器模型的n-shot推理。

Result: 大语言模型在少样本/零样本设置下区分方言细微差异困难，软提示编码器模型表现更好，LoRA微调模型表现最佳且超越全微调。

Conclusion: 对于阿拉伯方言识别任务，参数效率的PEFT方法（特别是LoRA）比数据效率方法更有效，能够在保持高性能的同时减少计算资源需求。

Abstract: This paper discusses our exploration of different data-efficient and
parameter-efficient approaches to Arabic Dialect Identification (ADI). In
particular, we investigate various soft-prompting strategies, including
prefix-tuning, prompt-tuning, P-tuning, and P-tuning V2, as well as LoRA
reparameterizations. For the data-efficient strategy, we analyze hard prompting
with zero-shot and few-shot inferences to analyze the dialect identification
capabilities of Large Language Models (LLMs). For the parameter-efficient PEFT
approaches, we conducted our experiments using Arabic-specific encoder models
on several major datasets. We also analyzed the n-shot inferences on
open-source decoder-only models, a general multilingual model (Phi-3.5), and an
Arabic-specific one(SILMA). We observed that the LLMs generally struggle to
differentiate the dialectal nuances in the few-shot or zero-shot setups. The
soft-prompted encoder variants perform better, while the LoRA-based fine-tuned
models perform best, even surpassing full fine-tuning.

</details>


### [41] [Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning](https://arxiv.org/abs/2509.13790)
*Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S. Yu*

Main category: cs.CL

TL;DR: CAMPUS框架通过动态选择和能力感知调整来解决传统课程学习中课程僵化问题，在指令调优中实现了更好的性能


<details>
  <summary>Details</summary>
Motivation: 传统课程学习方法依赖静态启发式难度指标，无法适应模型在训练过程中的能力变化，导致固定的、可能次优的学习轨迹

Method: 提出CAMPUS框架，包含动态子课程选择、能力感知的课程进度调整以及基于多种难度的调度策略

Result: 大量实验证明CAMPUS在高效指令调优方面优于其他最先进的基线方法

Conclusion: CAMPUS通过动态和适应性课程学习策略有效解决了课程僵化问题，提升了指令调优的最终性能

Abstract: Efficient instruction tuning aims to enhance the ultimate performance of
large language models (LLMs) trained on a given instruction dataset. Curriculum
learning as a typical data organization strategy has shown preliminary
effectiveness in instruction tuning. However, current curriculum tuning methods
suffer from the curriculum rigidity, since they rely solely on static heuristic
difficulty metrics. These methods fail to adapt to the evolving capabilities of
models during training, resulting in a fixed and potentially sub-optimal
learning trajectory. To address the issue, Competence-Aware Multi-Perspective
cUrriculum inStruction tuning framework termed CAMPUS is proposed. CAMPUS
offers several advantages: (1) Dynamic selection for sub-curriculum. (2)
Competency-aware adjustment to the curriculum schedule. (3) Multiple
difficulty-based scheduling. Extensive experiments prove the superior
performance of CAMPUS, compared to other state-of-the-art baselines for
efficient instruction tuning.

</details>


### [42] [Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages](https://arxiv.org/abs/2509.13803)
*Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib*

Main category: cs.CL

TL;DR: 本文研究了语法性别对自动职位排名系统的影响，提出了基于RBO指标的性别偏见评估方法，并在四种语法性别语言中创建了测试集来评估多语言模型的性别偏见程度。


<details>
  <summary>Details</summary>
Motivation: 研究语法性别在职位名称中的显式分配如何影响自动职位排名系统的结果，需要开发评估性别偏见的方法论和测试数据集。

Method: 提出使用RBO（Rank-Biased Overlap）指标来评估职位排名系统中的性别偏见，创建了四种语法性别语言的测试集，包含男性和女性形式的职位名称，并标注了性别和匹配相关性。

Result: 使用新测试集和方法论评估了多个现成的多语言模型，发现所有模型都表现出不同程度的性别偏见。

Conclusion: 该研究为评估职位排名系统中的性别偏见提供了基础框架和测试工具，揭示了当前多语言模型普遍存在的性别偏见问题。

Abstract: This work sets the ground for studying how explicit grammatical gender
assignment in job titles can affect the results of automatic job ranking
systems. We propose the usage of metrics for ranking comparison controlling for
gender to evaluate gender bias in job title ranking systems, in particular RBO
(Rank-Biased Overlap). We generate and share test sets for a job title matching
task in four grammatical gender languages, including occupations in masculine
and feminine form and annotated by gender and matching relevance. We use the
new test sets and the proposed methodology to evaluate the gender bias of
several out-of-the-box multilingual models to set as baselines, showing that
all of them exhibit varying degrees of gender bias.

</details>


### [43] [Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs](https://arxiv.org/abs/2509.13813)
*Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton*

Main category: cs.CL

TL;DR: 通过几何框架提出黑盒方法来量化大语言模型的全局和局部不确定性，用于检测幻觉现象


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒方法只能提供全局不确定性估计，而能够进行局部评估的方法需要白盒访问模型内部状态，需要一种新的黑盒方法来解决这个问题

Method: 基于原型分析的几何框架，通过响应嵌入的凸包体积（Geometric Volume）来量化全局不确定性，通过凸包边界点来评估局部不确定性（Geometric Suspicion）

Result: 在短文问答数据集上表现类似或更好于现有方法，在医疗数据集上表现更优，并且从理论上证明了凸包体积与信息熵之间的联系

Conclusion: 该几何框架提供了一种无需白盒访问的黑盒方法，能够同时评估全局和局部不确定性，有效检测幻觉现象，尤其在高风险场景中具有重要价值

Abstract: Large language models demonstrate impressive results across diverse tasks but
are still known to hallucinate, generating linguistically plausible but
incorrect answers to questions. Uncertainty quantification has been proposed as
a strategy for hallucination detection, but no existing black-box approach
provides estimates for both global and local uncertainty. The former attributes
uncertainty to a batch of responses, while the latter attributes uncertainty to
individual responses. Current local methods typically rely on white-box access
to internal model states, whilst black-box methods only provide global
uncertainty estimates. We introduce a geometric framework to address this,
based on archetypal analysis of batches of responses sampled with only
black-box model access. At the global level, we propose Geometric Volume, which
measures the convex hull volume of archetypes derived from response embeddings.
At the local level, we propose Geometric Suspicion, which ranks responses by
reliability and enables hallucination reduction through preferential response
selection. Unlike prior dispersion methods which yield only a single global
score, our approach provides semantic boundary points which have utility for
attributing reliability to individual responses. Experiments show that our
framework performs comparably to or better than prior methods on short form
question-answering datasets, and achieves superior results on medical datasets
where hallucinations carry particularly critical risks. We also provide
theoretical justification by proving a link between convex hull volume and
entropy.

</details>


### [44] [Findings of the Third Automatic Minuting (AutoMin) Challenge](https://arxiv.org/abs/2509.13814)
*Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal*

Main category: cs.CL

TL;DR: AutoMin 2025共享任务，包含会议纪要自动生成和问答两个任务，覆盖英语和捷克语，参与团队较少但包含多个基线系统评估。


<details>
  <summary>Details</summary>
Motivation: 推动自动会议纪要生成技术发展，探索多语言和跨语言场景下的会议内容理解与处理能力。

Method: 设置结构化会议纪要生成任务（英语和捷克语）和问答任务（单语和跨语言），使用大型语言模型作为基线系统进行评估。

Result: 2025年参与度较低（纪要任务1个团队，问答任务2个团队），但通过基线系统全面评估了当前LLM在相关任务上的表现。

Conclusion: 尽管参与团队有限，但通过基线系统的引入，为自动会议纪要和相关问答任务的技术评估提供了有价值的基准。

Abstract: This paper presents the third edition of AutoMin, a shared task on automatic
meeting summarization into minutes. In 2025, AutoMin featured the main task of
minuting, the creation of structured meeting minutes, as well as a new task:
question answering (QA) based on meeting transcripts.
  The minuting task covered two languages, English and Czech, and two domains:
project meetings and European Parliament sessions. The QA task focused solely
on project meetings and was available in two settings: monolingual QA in
English, and cross-lingual QA, where questions were asked and answered in Czech
based on English meetings.
  Participation in 2025 was more limited compared to previous years, with only
one team joining the minuting task and two teams participating in QA. However,
as organizers, we included multiple baseline systems to enable a comprehensive
evaluation of current (2025) large language models (LLMs) on both tasks.

</details>


### [45] [Large Language Models Discriminate Against Speakers of German Dialects](https://arxiv.org/abs/2509.13835)
*Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense*

Main category: cs.CL

TL;DR: 这篇论文研究大语言模型对德语方言语者的偏见，发现LLMs在联想任务和决策任务中都显示出对方言语者的负面偏见，而明确标注语言人口统计属性会更大程度放大这种偏见。


<details>
  <summary>Details</summary>
Motivation: 方言作为人类文化的重要组成部分，在德国有40%以上人口使用地区方言。然而方言语者经常面临负面社会定型，研究者想要了解这种定型是否体现在大语言模型中。

Method: 采用社会语言学文献中的方言感知特征，通过联想任务和决策任务来评估LLMs的方言命名偏见和方言使用偏见。构建了一个新的评估语料库，包含七种德语地区方言（如阿勒曼语和巴伍利亚语）与标准德语的对应句子。

Result: 所有评估的LLMs都显示出对德语方言语者的显著偏见，体现在负面形容词联想中；所有模型都在决策中复现了这些偏见；明确标注语言人口统计属性比隐含线索更大程度地放大了偏见。

Conclusion: 大语言模型存在对方言语者的系统性偏见，这种偏见与社会中存在的负面定型相一致，而明确的人口统计标注反而会增强模型的偏见表现。

Abstract: Dialects represent a significant component of human culture and are found
across all regions of the world. In Germany, more than 40% of the population
speaks a regional dialect (Adler and Hansen, 2022). However, despite cultural
importance, individuals speaking dialects often face negative societal
stereotypes. We examine whether such stereotypes are mirrored by large language
models (LLMs). We draw on the sociolinguistic literature on dialect perception
to analyze traits commonly associated with dialect speakers. Based on these
traits, we assess the dialect naming bias and dialect usage bias expressed by
LLMs in two tasks: an association task and a decision task. To assess a model's
dialect usage bias, we construct a novel evaluation corpus that pairs sentences
from seven regional German dialects (e.g., Alemannic and Bavarian) with their
standard German counterparts. We find that: (1) in the association task, all
evaluated LLMs exhibit significant dialect naming and dialect usage bias
against German dialect speakers, reflected in negative adjective associations;
(2) all models reproduce these dialect naming and dialect usage biases in their
decision making; and (3) contrary to prior work showing minimal bias with
explicit demographic mentions, we find that explicitly labeling linguistic
demographics--German dialect speakers--amplifies bias more than implicit cues
like dialect usage.

</details>


### [46] [Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs](https://arxiv.org/abs/2509.13869)
*Yang Liu,Chenhui Chu*

Main category: cs.CL

TL;DR: 研究发现大型语言模型在社交偏见场景中与人类价值观存在错位，模型规模大小与错位率无关，不同模型家族对特定场景类型有偏好，且小模型通过微调可以生成可读性更强的解释。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在复杂敏感的社交偏见场景中与人类价值观的对齐情况，探索不同场景类型下模型的对齐差异，以及模型对社交偏见人类价值观的理解能力。

Method: 通过分析12个来自4个模型家族的大型语言模型和4个数据集，评估模型在不同类型偏见场景中的对齐表现，并研究模型对社交偏见人类价值观的解释能力，同时通过微调小模型赋予其解释能力。

Result: 发现大参数规模的LLM不一定具有更低的错位率和攻击成功率；模型对特定场景类型有对齐偏好；同一模型家族的模型判断一致性更高；不同LLM对HVSB的理解无显著差异；模型偏好自己生成的解释；微调后的小模型生成更可读但模型认同度较低的解释。

Conclusion: LLM在社交偏见场景中的价值观对齐存在复杂性，模型规模不是决定性因素，场景类型和模型家族特性影响对齐表现，小模型可以通过微调获得解释能力但需要平衡可读性和模型认同度。

Abstract: Large language models (LLMs) can lead to undesired consequences when
misaligned with human values, especially in scenarios involving complex and
sensitive social biases. Previous studies have revealed the misalignment of
LLMs with human values using expert-designed or agent-based emulated bias
scenarios. However, it remains unclear whether the alignment of LLMs with human
values differs across different types of scenarios (e.g., scenarios containing
negative vs. non-negative questions). In this study, we investigate the
alignment of LLMs with human values regarding social biases (HVSB) in different
types of bias scenarios. Through extensive analysis of 12 LLMs from four model
families and four datasets, we demonstrate that LLMs with large model parameter
scales do not necessarily have lower misalignment rate and attack success rate.
Moreover, LLMs show a certain degree of alignment preference for specific types
of scenarios and the LLMs from the same model family tend to have higher
judgment consistency. In addition, we study the understanding capacity of LLMs
with their explanations of HVSB. We find no significant differences in the
understanding of HVSB across LLMs. We also find LLMs prefer their own generated
explanations. Additionally, we endow smaller language models (LMs) with the
ability to explain HVSB. The generation results show that the explanations
generated by the fine-tuned smaller LMs are more readable, but have a
relatively lower model agreeability.

</details>


### [47] [Combining Evidence and Reasoning for Biomedical Fact-Checking](https://arxiv.org/abs/2509.13879)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个结合科学证据检索、大语言模型推理和监督真实性预测的生物医学事实核查框架，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成威胁，而生物医学事实核查由于复杂术语、领域专业知识和科学证据基础的需求而具有独特挑战。

Method: 提出CER框架，整合科学证据检索、大语言模型推理和监督真实性预测，通过结合大语言模型的文本生成能力和高质量生物医学科学证据检索技术来减少幻觉风险。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上展示了最先进的性能和良好的跨数据集泛化能力。

Conclusion: CER框架通过证据和推理的结合，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https: //github.com/PRAISELab-PicusLab/CER.

</details>


### [48] [Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification](https://arxiv.org/abs/2509.13888)
*Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato*

Main category: cs.CL

TL;DR: CER是一个结合科学证据检索、大语言模型推理和监督真实性预测的生物医学事实核查框架，在多个专业标注数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的错误信息（如疫苗犹豫和未经证实的治疗方法）对公共卫生和医疗系统信任构成威胁，而生物医学事实核查因专业术语复杂、需要领域专业知识和对科学证据的严格要求而具有独特挑战。

Method: 提出CER框架，整合科学证据检索、大语言模型推理和监督真实性预测，通过结合大语言模型的文本生成能力和高质量生物医学科学证据的检索技术，有效减少幻觉风险。

Result: 在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示达到了最先进的性能，并展现出良好的跨数据集泛化能力。

Conclusion: CER框架通过结合证据检索和推理，为生物医学事实核查提供了有效的解决方案，代码和数据已开源以确保透明度和可重复性。

Abstract: Misinformation in healthcare, from vaccine hesitancy to unproven treatments,
poses risks to public health and trust in medical systems. While machine
learning and natural language processing have advanced automated fact-checking,
validating biomedical claims remains uniquely challenging due to complex
terminology, the need for domain expertise, and the critical importance of
grounding in scientific evidence. We introduce CER (Combining Evidence and
Reasoning), a novel framework for biomedical fact-checking that integrates
scientific evidence retrieval, reasoning via large language models, and
supervised veracity prediction. By integrating the text-generation capabilities
of large language models with advanced retrieval techniques for high-quality
biomedical scientific evidence, CER effectively mitigates the risk of
hallucinations, ensuring that generated outputs are grounded in verifiable,
evidence-based sources. Evaluations on expert-annotated datasets (HealthFC,
BioASQ-7b, SciFact) demonstrate state-of-the-art performance and promising
cross-dataset generalization. Code and data are released for transparency and
reproducibility: https://github.com/PRAISELab-PicusLab/CER

</details>


### [49] [Do Large Language Models Understand Word Senses?](https://arxiv.org/abs/2509.13905)
*Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli*

Main category: cs.CL

TL;DR: 本文评估了大语言模型在词义消歧和理解方面的能力，发现GPT-4o和DeepSeek-V3等领先模型在词义消歧任务上与专门系统表现相当，在生成任务中准确率高达98%


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量评估工作，但大语言模型是否真正理解词义仍未被充分探索，本文旨在填补这一空白

Method: 评估指令调优LLMs的词义消歧能力，并与专门系统比较；评估两个顶级开源和闭源LLMs在三种生成设置下的词义理解能力：定义生成、自由形式解释和示例生成

Result: 在词义消歧任务中，领先模型与专门系统表现相当且更具鲁棒性；在生成任务中，LLMs解释词义的准确率高达98%，自由形式解释任务表现最佳

Conclusion: 大语言模型在词义理解和消歧方面表现出色，能够与专门设计的系统相媲美，特别是在生成性任务中展现强大能力

Abstract: Understanding the meaning of words in context is a fundamental capability for
Large Language Models (LLMs). Despite extensive evaluation efforts, the extent
to which LLMs show evidence that they truly grasp word senses remains
underexplored. In this paper, we address this gap by evaluating both i) the
Word Sense Disambiguation (WSD) capabilities of instruction-tuned LLMs,
comparing their performance to state-of-the-art systems specifically designed
for the task, and ii) the ability of two top-performing open- and closed-source
LLMs to understand word senses in three generative settings: definition
generation, free-form explanation, and example generation. Notably, we find
that, in the WSD task, leading models such as GPT-4o and DeepSeek-V3 achieve
performance on par with specialized WSD systems, while also demonstrating
greater robustness across domains and levels of difficulty. In the generation
tasks, results reveal that LLMs can explain the meaning of words in context up
to 98\% accuracy, with the highest performance observed in the free-form
explanation task, which best aligns with their generative capabilities.

</details>


### [50] [Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG](https://arxiv.org/abs/2509.13930)
*Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh*

Main category: cs.CL

TL;DR: 研究发现多语言RAG系统中存在英语偏好偏见，模型会优先引用英语文档而非更相关的其他语言文档，这种偏见在低资源语言和上下文中间位置文档中更加明显。


<details>
  <summary>Details</summary>
Motivation: 研究多语言检索增强生成系统中不同语言文档混合是否会对生成和引用产生意外影响，特别是语言偏好是否会影响引用选择。

Method: 采用受控方法，利用模型内部机制来衡量语言偏好，同时保持文档相关性等其他因素不变，在8种语言和6个开源模型上进行测试。

Result: 发现模型在英语查询时优先引用英语来源，这种偏见在低资源语言和上下文中间位置的文档中被放大。模型有时会牺牲文档相关性来满足语言偏好。

Conclusion: 引用选择并非总是由信息量驱动，语言偏好显著影响多语言RAG系统的引用行为，这对理解语言模型如何利用多语言上下文具有重要意义。

Abstract: Multilingual Retrieval-Augmented Generation (mRAG) systems enable language
models to answer knowledge-intensive queries with citation-supported responses
across languages. While such systems have been proposed, an open questions is
whether the mixture of different document languages impacts generation and
citation in unintended ways. To investigate, we introduce a controlled
methodology using model internals to measure language preference while holding
other factors such as document relevance constant. Across eight languages and
six open-weight models, we find that models preferentially cite English sources
when queries are in English, with this bias amplified for lower-resource
languages and for documents positioned mid-context. Crucially, we find that
models sometimes trade-off document relevance for language preference,
indicating that citation choices are not always driven by informativeness
alone. Our findings shed light on how language models leverage multilingual
context and influence citation behavior.

</details>


### [51] [Long-context Reference-based MT Quality Estimation](https://arxiv.org/abs/2509.13980)
*Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis*

Main category: cs.CL

TL;DR: 基于COMET框架构建的翻译质量评估系统，通过长上下文数据增强训练来预测错误跨度标注分数，整合多种人工标注数据集，实验表明长上下文信息能提升与人工评估的相关性


<details>
  <summary>Details</summary>
Motivation: 解决传统翻译质量评估模型在短片段训练上的局限性，通过利用长上下文信息来更好地预测翻译质量，提升与人类判断的相关性

Method: 使用COMET框架，通过拼接领域内人工标注句子构建长上下文训练数据，计算加权平均分数，整合MQM、SQM和DA多种人工判断数据集，训练多语言回归模型

Result: 实验结果显示，相比仅使用短片段训练的模型，融入长上下文信息的模型与人工判断具有更高的相关性

Conclusion: 长上下文信息的整合能有效提升翻译质量评估系统的性能，为自动化翻译质量评估提供了新的改进方向

Abstract: In this paper, we present our submission to the Tenth Conference on Machine
Translation (WMT25) Shared Task on Automated Translation Quality Evaluation.
  Our systems are built upon the COMET framework and trained to predict
segment-level Error Span Annotation (ESA) scores using augmented long-context
data.
  To construct long-context training data, we concatenate in-domain,
human-annotated sentences and compute a weighted average of their scores.
  We integrate multiple human judgment datasets (MQM, SQM, and DA) by
normalising their scales and train multilingual regression models to predict
quality scores from the source, hypothesis, and reference translations.
  Experimental results show that incorporating long-context information
improves correlations with human judgments compared to models trained only on
short segments.

</details>


### [52] [Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency](https://arxiv.org/abs/2509.13990)
*Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov*

Main category: cs.CL

TL;DR: Slim-SC是一种基于思维层面链间相似性的逐步剪枝策略，可在保持或提高准确性的同时，将Self-Consistency的推理延迟降低45%，KVC使用量减少26%。


<details>
  <summary>Details</summary>
Motivation: Self-Consistency虽然能提升LLM推理性能，但其数量级的计算开销限制了广泛应用。现有加速方法主要依赖模型置信度或缺乏实证支持的启发式方法。

Method: 通过理论和实证分析SC的低效性，提出Slim-SC：在思维层面利用链间相似性识别并移除冗余链的逐步剪枝策略。

Result: 在三个STEM推理数据集和两种LLM架构上的实验表明，Slim-SC在保持或提高准确性的同时，推理延迟降低45%，KVC使用量减少26%。

Conclusion: Slim-SC为Self-Consistency提供了一种简单而高效的测试时缩放替代方案，显著降低了计算开销。

Abstract: Recently, Test-Time Scaling (TTS) has gained increasing attention for
improving LLM reasoning performance at test time without retraining the model.
A notable TTS technique is Self-Consistency (SC), which generates multiple
reasoning chains in parallel and selects the final answer via majority voting.
While effective, the order-of-magnitude computational overhead limits its broad
deployment. Prior attempts to accelerate SC mainly rely on model-based
confidence scores or heuristics with limited empirical support. For the first
time, we theoretically and empirically analyze the inefficiencies of SC and
reveal actionable opportunities for improvement. Building on these insights, we
propose Slim-SC, a step-wise pruning strategy that identifies and removes
redundant chains using inter-chain similarity at the thought level. Experiments
on three STEM reasoning datasets and two recent LLM architectures show that
Slim-SC reduces inference latency and KVC usage by up to 45% and 26%,
respectively, with R1-Distill, while maintaining or improving accuracy, thus
offering a simple yet efficient TTS alternative for SC.

</details>


### [53] [Early Stopping Chain-of-thoughts in Large Language Models](https://arxiv.org/abs/2509.14004)
*Minjia Mao,Bowen Yin,Yu Zhu,Xiao Fang*

Main category: cs.CL

TL;DR: ES-CoT是一种推理时方法，通过检测答案收敛性来提前停止思维链生成，减少约41%的推理token，同时保持与标准CoT相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决复杂问题时需要生成长思维链，但冗长的CoT会产生高昂的推理成本，需要一种方法来缩短CoT生成而不损失性能。

Method: 在每个推理步骤结束时提示LLM输出当前最终答案（步骤答案），跟踪连续相同步骤答案的运行长度作为收敛度量，当运行长度出现急剧增加并超过阈值时终止生成。

Result: 在五个推理数据集和三个LLM上的实验表明，ES-CoT平均减少约41%的推理token，同时保持与标准CoT相当的准确性，并能无缝集成自一致性提示。

Conclusion: ES-CoT是一种实用有效的推理效率提升方法，通过检测答案收敛性实现早期停止，在保持性能的同时显著降低推理成本。

Abstract: Reasoning large language models (LLMs) have demonstrated superior capacities
in solving complicated problems by generating long chain-of-thoughts (CoT), but
such a lengthy CoT incurs high inference costs. In this study, we introduce
ES-CoT, an inference-time method that shortens CoT generation by detecting
answer convergence and stopping early with minimal performance loss. At the end
of each reasoning step, we prompt the LLM to output its current final answer,
denoted as a step answer. We then track the run length of consecutive identical
step answers as a measure of answer convergence. Once the run length exhibits a
sharp increase and exceeds a minimum threshold, the generation is terminated.
We provide both empirical and theoretical support for this heuristic: step
answers steadily converge to the final answer, and large run-length jumps
reliably mark this convergence. Experiments on five reasoning datasets across
three LLMs show that ES-CoT reduces the number of inference tokens by about
41\% on average while maintaining accuracy comparable to standard CoT. Further,
ES-CoT integrates seamlessly with self-consistency prompting and remains robust
across hyperparameter choices, highlighting it as a practical and effective
approach for efficient reasoning.

</details>


### [54] [Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale](https://arxiv.org/abs/2509.14008)
*Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem*

Main category: cs.CL

TL;DR: Hala是一个阿拉伯语为中心的指令和翻译模型家族，通过翻译调优流程构建，在阿拉伯语基准测试中取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯语NLP中高质量指令数据和专业模型的缺乏问题，推动阿拉伯语NLP研究发展。

Method: 使用FP8压缩的AR-EN教师模型生成高质量双语监督数据，训练轻量级语言模型翻译英文指令集为阿拉伯语，采用slerp合并平衡阿拉伯语专业化和基础模型优势。

Result: 在阿拉伯语基准测试中，Hala在"nano"(≤2B)和"small"(7-9B)类别中都取得了最先进的结果，性能超越其基础模型。

Conclusion: Hala模型系列为阿拉伯语NLP提供了有效的解决方案，发布的模型、数据、评估和配方将加速阿拉伯语NLP研究发展。

Abstract: We present Hala, a family of Arabic-centric instruction and translation
models built with our translate-and-tune pipeline. We first compress a strong
AR$\leftrightarrow$EN teacher to FP8 (yielding $\sim$2$\times$ higher
throughput with no quality loss) and use it to create high-fidelity bilingual
supervision. A lightweight language model LFM2-1.2B is then fine-tuned on this
data and used to translate high-quality English instruction sets into Arabic,
producing a million-scale corpus tailored to instruction following. We train
Hala models at 350M, 700M, 1.2B, and 9B parameters, and apply slerp merging to
balance Arabic specialization with base-model strengths. On Arabic-centric
benchmarks, Hala achieves state-of-the-art results within both the "nano"
($\leq$2B) and "small" (7-9B) categories, outperforming their bases. We release
models, data, evaluation, and recipes to accelerate research in Arabic NLP.

</details>


### [55] [Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality](https://arxiv.org/abs/2509.14023)
*Sami Ul Haq,Sheila Castilho,Yvette Graham*

Main category: cs.CL

TL;DR: 这篇论文比较了文本和音频两种方式对机器翻译质量的评估效果，发现音频评估能够更自然地识别翻译系统间的差异


<details>
  <summary>Details</summary>
Motivation: 虽然机器翻译取得了显著进步，但质量评估仍以文本为主，而实际应用中翻译经常是通过语音传达的，需要更自然的评估方式

Method: 使用Amazon Mechanical Turk群众聚集对10个WMT机器翻译系统的评估，比较文本和音频两种评估方式，进行统计显著性测试和自我复制实验

Result: 音频评估得出的排名与文本评估基本一致，但在某些情况下能识别出翻译系统间的显著差异

Conclusion: 音频评估通过更丰富自然的语态提供了更好的评估方式，建议未来机器翻译评估框架结合语音评估

Abstract: Machine Translation (MT) has achieved remarkable performance, with growing
interest in speech translation and multimodal approaches. However, despite
these advancements, MT quality assessment remains largely text centric,
typically relying on human experts who read and compare texts. Since many
real-world MT applications (e.g Google Translate Voice Mode, iFLYTEK
Translator) involve translation being spoken rather printed or read, a more
natural way to assess translation quality would be through speech as opposed
text-only evaluations. This study compares text-only and audio-based
evaluations of 10 MT systems from the WMT General MT Shared Task, using
crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally,
performed statistical significance testing and self-replication experiments to
test reliability and consistency of audio-based approach. Crowd-sourced
assessments based on audio yield rankings largely consistent with text only
evaluations but, in some cases, identify significant differences between
translation systems. We attribute this to speech richer, more natural modality
and propose incorporating speech-based assessments into future MT evaluation
frameworks.

</details>


### [56] [You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models](https://arxiv.org/abs/2509.14031)
*Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis*

Main category: cs.CL

TL;DR: 论文验证了训练数据中上下文丰富样本的稀疏性是机器翻译模型难以有效利用上下文的主要原因，并提出了两种训练策略来改善上下文利用效果


<details>
  <summary>Details</summary>
Motivation: 标准训练数据中上下文丰富样本的稀疏性被认为是机器翻译难以利用上下文确保连贯性和处理复杂现象（如代词消歧）的原因，需要系统验证这一假设

Method: 通过构建具有受控比例上下文相关示例的训练数据集，在单语和多语设置下系统验证数据稀疏性与模型性能的关系，并提出和评估两种训练策略

Result: 证实了训练数据稀疏性是关键瓶颈，上下文改进不能泛化到其他现象，跨语言迁移有限，提出的训练策略在单语和多语设置下分别带来6%和8%的准确率提升

Conclusion: 数据稀疏性是上下文利用的主要障碍，需要针对性的训练策略来有效利用可用数据，不同上下文现象需要不同的处理方法

Abstract: Achieving human-level translations requires leveraging context to ensure
coherence and handle complex phenomena like pronoun disambiguation. Sparsity of
contextually rich examples in the standard training data has been hypothesized
as the reason for the difficulty of context utilization. In this work, we
systematically validate this claim in both single- and multilingual settings by
constructing training datasets with a controlled proportions of contextually
relevant examples. We demonstrate a strong association between training data
sparsity and model performance confirming sparsity as a key bottleneck.
Importantly, we reveal that improvements in one contextual phenomenon do no
generalize to others. While we observe some cross-lingual transfer, it is not
significantly higher between languages within the same sub-family. Finally, we
propose and empirically evaluate two training strategies designed to leverage
the available data. These strategies improve context utilization, resulting in
accuracy gains of up to 6 and 8 percentage points on the ctxPro evaluation in
single- and multilingual settings respectively.

</details>


### [57] [Enhancing Multi-Agent Debate System Performance via Confidence Expression](https://arxiv.org/abs/2509.14034)
*Zijie Lin,Bryan Hooi*

Main category: cs.CL

TL;DR: 该论文提出了ConfMAD框架，在多智能体辩论系统中引入置信度表达机制，以解决LLMs在辩论中难以有效沟通知识优势和避免过早收敛的问题。


<details>
  <summary>Details</summary>
Motivation: 现有MAD系统中，即使某些LLMs对特定任务具有更优的知识或推理能力，但由于缺乏置信度表达，难以在辩论中清晰传达这种优势。不恰当的置信度表达会导致智能体固执坚持错误信念或过早收敛于次优答案。

Method: 提出ConfMAD框架，在多智能体辩论过程中集成置信度表达机制，让LLMs能够明确传达其置信度水平。

Result: 实验结果表明该方法有效，并进一步分析了置信度如何影响辩论动态。

Conclusion: 置信度感知的MAD系统设计能够提升辩论效果和整体系统性能，为多智能体协作提供了新的洞察。

Abstract: Generative Large Language Models (LLMs) have demonstrated remarkable
performance across a wide range of tasks. Recent research has introduced
Multi-Agent Debate (MAD) systems, which leverage multiple LLMs to simulate
human debate and thereby improve task performance. However, while some LLMs may
possess superior knowledge or reasoning capabilities for specific tasks, they
often struggle to clearly communicate this advantage during debates, in part
due to a lack of confidence expression. Moreover, inappropriate confidence
expression can cause agents in MAD systems to either stubbornly maintain
incorrect beliefs or converge prematurely on suboptimal answers, ultimately
reducing debate effectiveness and overall system performance. To address these
challenges, we propose incorporating confidence expression into MAD systems to
allow LLMs to explicitly communicate their confidence levels. To validate this
approach, we develop ConfMAD, a MAD framework that integrates confidence
expression throughout the debate process. Experimental results demonstrate the
effectiveness of our method, and we further analyze how confidence influences
debate dynamics, offering insights into the design of confidence-aware MAD
systems.

</details>


### [58] [SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation](https://arxiv.org/abs/2509.14036)
*Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao*

Main category: cs.CL

TL;DR: 提出基于问答的手语翻译任务(QB-SLT)，通过自监督学习和Sigmoid自注意力加权融合方法，利用对话上下文提升手语翻译质量，在新建数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 对话在手语翻译中提供重要上下文线索，相比传统gloss标注，对话更自然且易于标注，探索如何有效整合对话信息来改善手语翻译。

Method: 提出跨模态自监督学习与Sigmoid自注意力加权(SSL-SSAW)融合方法，使用对比学习对齐多模态特征，SSAW模块自适应提取问题和手语序列特征，利用自监督学习增强表示能力。

Result: 在CSL-Daily-QA和PHOENIX-2014T-QA数据集上达到SOTA性能，易获取的问题辅助可以达到甚至超越gloss辅助的性能，可视化结果证明对话整合能有效提升翻译质量。

Conclusion: QB-SLT任务和SSL-SSAW方法有效利用了对话上下文，证明了问题辅助在手语翻译中的实用价值，为手语翻译提供了新的研究方向和解决方案。

Abstract: Sign Language Translation (SLT) bridges the communication gap between deaf
people and hearing people, where dialogue provides crucial contextual cues to
aid in translation. Building on this foundational concept, this paper proposes
Question-based Sign Language Translation (QB-SLT), a novel task that explores
the efficient integration of dialogue. Unlike gloss (sign language
transcription) annotations, dialogue naturally occurs in communication and is
easier to annotate. The key challenge lies in aligning multimodality features
while leveraging the context of the question to improve translation. To address
this issue, we propose a cross-modality Self-supervised Learning with Sigmoid
Self-attention Weighting (SSL-SSAW) fusion method for sign language
translation. Specifically, we employ contrastive learning to align
multimodality features in QB-SLT, then introduce a Sigmoid Self-attention
Weighting (SSAW) module for adaptive feature extraction from question and sign
language sequences. Additionally, we leverage available question text through
self-supervised learning to enhance representation and translation
capabilities. We evaluated our approach on newly constructed CSL-Daily-QA and
PHOENIX-2014T-QA datasets, where SSL-SSAW achieved SOTA performance. Notably,
easily accessible question assistance can achieve or even surpass the
performance of gloss assistance. Furthermore, visualization results demonstrate
the effectiveness of incorporating dialogue in improving translation quality.

</details>


### [59] [Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST](https://arxiv.org/abs/2509.14128)
*Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg*

Main category: cs.CL

TL;DR: Canary-1B-v2是一个快速、鲁棒的多语言语音识别和语音翻译模型，支持25种欧洲语言，比Whisper-large-v3快10倍且性能更好。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言语音处理模型，能够在保持高性能的同时显著提升处理速度，并减少语音识别和翻译中的幻觉问题。

Method: 采用FastConformer编码器和Transformer解码器架构，使用170万小时数据训练，包括Granary和NeMo ASR Set 3.0数据集，添加非语音音频减少幻觉，采用两阶段预训练和微调过程。

Result: 在英语ASR上超越Whisper-large-v3且速度快10倍，在多语言ASR和AST任务上与Seamless-M4T-v2-large等更大模型竞争，同时发布了更小的Parakeet-TDT-0.6B-v3模型。

Conclusion: Canary-1B-v2展示了在语音识别和翻译任务上的优异性能与效率平衡，nGPT编码器在大规模数据下表现良好，FastConformer在微调后表现卓越。

Abstract: This report introduces Canary-1B-v2, a fast, robust multilingual model for
Automatic Speech Recognition (ASR) and Speech-to-Text Translation (AST). Built
with a FastConformer encoder and Transformer decoder, it supports 25 languages
primarily European. The model was trained on 1.7M hours of total data samples,
including Granary and NeMo ASR Set 3.0, with non-speech audio added to reduce
hallucinations for ASR and AST. We describe its two-stage pre-training and
fine-tuning process with dynamic data balancing, as well as experiments with an
nGPT encoder. Results show nGPT scales well with massive data, while
FastConformer excels after fine-tuning. For timestamps, Canary-1B-v2 uses the
NeMo Forced Aligner (NFA) with an auxiliary CTC model, providing reliable
segment-level timestamps for ASR and AST. Evaluations show Canary-1B-v2
outperforms Whisper-large-v3 on English ASR while being 10x faster, and
delivers competitive multilingual ASR and AST performance against larger models
like Seamless-M4T-v2-large and LLM-based systems. We also release
Parakeet-TDT-0.6B-v3, a successor to v2, offering multilingual ASR across the
same 25 languages with just 600M parameters.

</details>


### [60] [CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset](https://arxiv.org/abs/2509.14161)
*Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero*

Main category: cs.CL

TL;DR: CS-FLEURS是一个新的代码转换语音识别和翻译数据集，包含4个测试集，覆盖113种语言对的52种语言，旨在扩展代码转换语音研究范围。


<details>
  <summary>Details</summary>
Motivation: 为了开发和评估超越高资源语言的代码转换语音识别和翻译系统，需要更广泛的语言覆盖和多样化的数据集。

Method: 构建包含4个测试集的数据集：1)14种X-英语语言对的真实语音合成代码转换句子；2)16种X-英语语言对的生成式文本转语音；3)60种{阿拉伯语、普通话、印地语、西班牙语}-X语言对的生成式文本转语音；4)45种X-英语低资源语言对的拼接式文本转语音。还提供128小时的训练数据。

Result: 成功创建了CS-FLEURS数据集，覆盖113种独特代码转换语言对，跨越52种语言，为代码转换语音研究提供了全面的基准测试资源。

Conclusion: CS-FLEURS数据集将有助于拓宽未来代码转换语音研究的范围，特别是在低资源语言和多样化语言对方面的研究。

Abstract: We present CS-FLEURS, a new dataset for developing and evaluating
code-switched speech recognition and translation systems beyond high-resourced
languages. CS-FLEURS consists of 4 test sets which cover in total 113 unique
code-switched language pairs across 52 languages: 1) a 14 X-English language
pair set with real voices reading synthetically generated code-switched
sentences, 2) a 16 X-English language pair set with generative text-to-speech
3) a 60 {Arabic, Mandarin, Hindi, Spanish}-X language pair set with the
generative text-to-speech, and 4) a 45 X-English lower-resourced language pair
test set with concatenative text-to-speech. Besides the four test sets,
CS-FLEURS also provides a training set with 128 hours of generative
text-to-speech data across 16 X-English language pairs. Our hope is that
CS-FLEURS helps to broaden the scope of future code-switched speech research.
Dataset link: https://huggingface.co/datasets/byan/cs-fleurs.

</details>


### [61] [AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity](https://arxiv.org/abs/2509.14171)
*Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen*

Main category: cs.CL

TL;DR: 提出了AssoCiAm基准，通过混合计算方法解决多模态大语言模型关联能力评估中的模糊性问题，发现认知与关联能力呈正相关，模糊性会使模型行为更随机


<details>
  <summary>Details</summary>
Motivation: 现有MLLM关联能力评估框架忽略了关联任务固有的模糊性，这种模糊性源于关联的发散性，会降低评估的可靠性

Method: 将模糊性分解为内部模糊性和外部模糊性，设计AssoCiAm基准，采用混合计算方法来规避模糊性问题

Result: 实验显示认知与关联能力存在强正相关关系，评估过程中的模糊性会导致MLLM行为更趋随机化

Conclusion: 提出的方法能确保更准确可靠的评估，验证了AssoCiAm基准在解决关联评估模糊性问题上的有效性

Abstract: Recent advancements in multimodal large language models (MLLMs) have garnered
significant attention, offering a promising pathway toward artificial general
intelligence (AGI). Among the essential capabilities required for AGI,
creativity has emerged as a critical trait for MLLMs, with association serving
as its foundation. Association reflects a model' s ability to think creatively,
making it vital to evaluate and understand. While several frameworks have been
proposed to assess associative ability, they often overlook the inherent
ambiguity in association tasks, which arises from the divergent nature of
associations and undermines the reliability of evaluations. To address this
issue, we decompose ambiguity into two types-internal ambiguity and external
ambiguity-and introduce AssoCiAm, a benchmark designed to evaluate associative
ability while circumventing the ambiguity through a hybrid computational
method. We then conduct extensive experiments on MLLMs, revealing a strong
positive correlation between cognition and association. Additionally, we
observe that the presence of ambiguity in the evaluation process causes MLLMs'
behavior to become more random-like. Finally, we validate the effectiveness of
our method in ensuring more accurate and reliable evaluations. See Project Page
for the data and codes.

</details>


### [62] [Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs](https://arxiv.org/abs/2509.14180)
*Akhil Theerthala*

Main category: cs.CL

TL;DR: 提出了一个集成金融背景和行为金融学的新框架，通过精心策划的数据集微调8B模型，在保持性能的同时显著降低成本


<details>
  <summary>Details</summary>
Motivation: 个性化金融建议需要考虑多方面因素，现有方法维护成本高且收益有限，需要更高效的端到端解决方案

Method: 构建包含金融背景和行为金融学的监督数据集，使用19k样本对Qwen-3-8B模型进行微调

Result: 8B模型在事实准确性、流畅性和个性化指标上达到与更大模型(14-32B)相当的性能，同时成本降低80%

Conclusion: 通过精心数据策划和行为金融学整合，较小模型也能在金融咨询任务中实现高性能，显著降低部署成本

Abstract: Personalized financial advice requires consideration of user goals,
constraints, risk tolerance, and jurisdiction. Prior LLM work has focused on
support systems for investors and financial planners. Simultaneously, numerous
recent studies examine broader personal finance tasks, including budgeting,
debt management, retirement, and estate planning, through agentic pipelines
that incur high maintenance costs, yielding less than 25% of their expected
financial returns. In this study, we introduce a novel and reproducible
framework that integrates relevant financial context with behavioral finance
studies to construct supervision data for end-to-end advisors. Using this
framework, we create a 19k sample reasoning dataset and conduct a comprehensive
fine-tuning of the Qwen-3-8B model on the dataset. Through a held-out test
split and a blind LLM-jury study, we demonstrate that through careful data
curation and behavioral integration, our 8B model achieves performance
comparable to significantly larger baselines (14-32B parameters) across factual
accuracy, fluency, and personalization metrics while incurring 80% lower costs
than the larger counterparts.

</details>


### [63] [Framing Migration: A Computational Analysis of UK Parliamentary Discourse](https://arxiv.org/abs/2509.14197)
*Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi*

Main category: cs.CL

TL;DR: 使用大规模语言模型分析英美议会过去75年移民议题谈利涉发现英国政党间态度相对一致而美国趋于两极化，英国议会讨论从长期整合转向边境控制等安全化叙事框架


<details>
  <summary>Details</summary>
Motivation: 通过大规模语言模型进行可扩展的细粒度话语分析，探索英美两国议会在移民问题上的话语演变和政治对立

Method: 使用开源大规模语言模型对英国议会辩论进行高级别态度标注，并通过半自动化框架提取细粒度叙事框架以抓取话语细节

Result: 美国议会话语日益两极化，英国政党间态度相对一致但工党与保守党存在持久意识形态差距，预计2025年达到最负面水平；英国议会讨论向边境控制等安全化叙事转移，长期整合性叙事减少，国内法律讨论被国际法和人权替代

Conclusion: 大规模语言模型能够支持可扩展的细粒度话语分析，在政治和历史背景下揭示了移民话语的演变趋势和细节差异

Abstract: We present a large-scale computational analysis of migration-related
discourse in UK parliamentary debates spanning over 75 years and compare it
with US congressional discourse. Using open-weight LLMs, we annotate each
statement with high-level stances toward migrants and track the net tone toward
migrants across time and political parties. For the UK, we extend this with a
semi-automated framework for extracting fine-grained narrative frames to
capture nuances of migration discourse. Our findings show that, while US
discourse has grown increasingly polarised, UK parliamentary attitudes remain
relatively aligned across parties, with a persistent ideological gap between
Labour and the Conservatives, reaching its most negative level in 2025. The
analysis of narrative frames in the UK parliamentary statements reveals a shift
toward securitised narratives such as border control and illegal immigration,
while longer-term integration-oriented frames such as social integration have
declined. Moreover, discussions of national law about immigration have been
replaced over time by international law and human rights, revealing nuances in
discourse trends. Taken together broadly, our findings demonstrate how LLMs can
support scalable, fine-grained discourse analysis in political and historical
contexts.

</details>


### [64] [Apertus: Democratizing Open and Compliant LLMs for Global Language Environments](https://arxiv.org/abs/2509.14233)
*Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag*

Main category: cs.CL

TL;DR: Apertus是一套完全开源的大语言模型套件，专注于数据合规性和多语言表示，使用完全开放可用的数据进行预训练，支持1800多种语言，在8B和70B规模上达到接近最先进水平的性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前开源模型生态系统中两个系统性缺陷：数据合规性（许多模型发布权重但缺乏可复现的数据管道且不尊重内容所有者权利）和多语言表示不足的问题。

Method: 使用完全开放可用数据进行预训练，尊重robots.txt排除规则，过滤非许可、有毒和个人身份信息内容；采用Goldfish目标函数抑制数据记忆同时保持下游任务性能；在15T tokens上训练，覆盖1800多种语言，40%数据为非英语内容。

Result: Apertus模型在多语言基准测试中接近完全开源模型的最先进结果，与开源权重对应模型相当或超越；发布了8B和70B两种规模的模型。

Conclusion: Apertus不仅提供模型权重，还发布了所有科学成果（数据准备脚本、检查点、评估套件和训练代码），采用宽松许可证，实现了透明审计和扩展的可能性，为开源LLM生态树立了新的合规性和多语言标准。

Abstract: We present Apertus, a fully open suite of large language models (LLMs)
designed to address two systemic shortcomings in today's open model ecosystem:
data compliance and multilingual representation. Unlike many prior models that
release weights without reproducible data pipelines or regard for content-owner
rights, Apertus models are pretrained exclusively on openly available data,
retroactively respecting robots.txt exclusions and filtering for
non-permissive, toxic, and personally identifiable content. To mitigate risks
of memorization, we adopt the Goldfish objective during pretraining, strongly
suppressing verbatim recall of data while retaining downstream task
performance. The Apertus models also expand multilingual coverage, training on
15T tokens from over 1800 languages, with ~40% of pretraining data allocated to
non-English content. Released at 8B and 70B scales, Apertus approaches
state-of-the-art results among fully open models on multilingual benchmarks,
rivalling or surpassing open-weight counterparts. Beyond model weights, we
release all scientific artifacts from our development cycle with a permissive
license, including data preparation scripts, checkpoints, evaluation suites,
and training code, enabling transparent audit and extension.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [65] [Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks](https://arxiv.org/abs/2509.13338)
*Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi*

Main category: cs.CV

TL;DR: 这篇论文提出了一种基于证据检索的不确定性感知决策机制，通过查找近似示例并结合Dempster-Shafer理论融合预测分布，实现了每个实例自适应的阈值决策，提高了决策的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决传统全局固定阈值方法在不确定性感知决策中存在的问题，包括自适应性差、可解释性低等，需要一种更可靠和可审计的方法。

Method: 使用嵌入空间检索每个测试实例的近似示例，通过Dempster-Shafer理论融合这些示例的预测分布，形成融合信念作为每个实例的自适应阈值机制。

Result: 在CIFAR-10/100数据集上使用BiT和ViT背锁进行实验，显示了更高或相当的不确定性感知性能，大幅减少了自信错误的结果，并保持了可持续的审查负荷。仅需少量证据即可实现这些收益。

Conclusion: 证据条件化标签提供了比固定预测熵阈值更可靠和可解释的替代方案，适用于操作性的不确定性感知决策。

Abstract: This work proposes an evidence-retrieval mechanism for uncertainty-aware
decision-making that replaces a single global cutoff with an
evidence-conditioned, instance-adaptive criterion. For each test instance,
proximal exemplars are retrieved in an embedding space; their predictive
distributions are fused via Dempster-Shafer theory. The resulting fused belief
acts as a per-instance thresholding mechanism. Because the supporting evidences
are explicit, decisions are transparent and auditable. Experiments on
CIFAR-10/100 with BiT and ViT backbones show higher or comparable
uncertainty-aware performance with materially fewer confidently incorrect
outcomes and a sustainable review load compared with applying threshold on
prediction entropy. Notably, only a few evidences are sufficient to realize
these gains; increasing the evidence set yields only modest changes. These
results indicate that evidence-conditioned tagging provides a more reliable and
interpretable alternative to fixed prediction entropy thresholds for
operational uncertainty-aware decision-making.

</details>


### [66] [Hybrid Quantum-Classical Model for Image Classification](https://arxiv.org/abs/2509.13353)
*Muhammad Adnan Shahzad*

Main category: cs.CV

TL;DR: 混合量子-经典神经网络在三个基准数据集上相比纯经典模型展现出更高的准确率、更快的训练速度、更少的参数使用以及更好的对抗鲁棒性，特别是在复杂视觉任务中优势明显


<details>
  <summary>Details</summary>
Motivation: 系统比较混合量子-经典神经网络与纯经典模型在性能、效率和鲁棒性方面的差异，评估量子计算在深度学习中的实际价值

Method: 在MNIST、CIFAR100和STL10数据集上，将参数化量子电路与经典深度学习架构结合的混合模型与传统的卷积神经网络进行对比实验，训练50个epoch，评估验证准确率、测试准确率、训练时间、计算资源使用和对抗鲁棒性

Result: 混合模型在所有数据集上准确率均优于经典模型（MNIST: 99.38% vs 98.21%；CIFAR100: 41.69% vs 32.25%；STL10: 74.05% vs 63.76%），训练速度快5-12倍，参数减少6-32%，内存使用更少（4-5GB vs 5-6GB），CPU利用率更低（9.5% vs 23.2%），在简单数据集上对抗鲁棒性显著更好

Conclusion: 混合量子-经典架构在准确率、训练效率和参数可扩展性方面具有显著优势，特别适合复杂视觉任务，为量子计算在深度学习中的应用提供了有力证据

Abstract: This study presents a systematic comparison between hybrid quantum-classical
neural networks and purely classical models across three benchmark datasets
(MNIST, CIFAR100, and STL10) to evaluate their performance, efficiency, and
robustness. The hybrid models integrate parameterized quantum circuits with
classical deep learning architectures, while the classical counterparts use
conventional convolutional neural networks (CNNs). Experiments were conducted
over 50 training epochs for each dataset, with evaluations on validation
accuracy, test accuracy, training time, computational resource usage, and
adversarial robustness (tested with $\epsilon=0.1$ perturbations).Key findings
demonstrate that hybrid models consistently outperform classical models in
final accuracy, achieving {99.38\% (MNIST), 41.69\% (CIFAR100), and 74.05\%
(STL10) validation accuracy, compared to classical benchmarks of 98.21\%,
32.25\%, and 63.76\%, respectively. Notably, the hybrid advantage scales with
dataset complexity, showing the most significant gains on CIFAR100 (+9.44\%)
and STL10 (+10.29\%). Hybrid models also train 5--12$\times$ faster (e.g.,
21.23s vs. 108.44s per epoch on MNIST) and use 6--32\% fewer parameters} while
maintaining superior generalization to unseen test data.Adversarial robustness
tests reveal that hybrid models are significantly more resilient on simpler
datasets (e.g., 45.27\% robust accuracy on MNIST vs. 10.80\% for classical) but
show comparable fragility on complex datasets like CIFAR100 ($\sim$1\%
robustness for both). Resource efficiency analyses indicate that hybrid models
consume less memory (4--5GB vs. 5--6GB for classical) and lower CPU utilization
(9.5\% vs. 23.2\% on average).These results suggest that hybrid
quantum-classical architectures offer compelling advantages in accuracy,
training efficiency, and parameter scalability, particularly for complex vision
tasks.

</details>


### [67] [Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention](https://arxiv.org/abs/2509.13361)
*Tong Yulin,Liang Xuechen*

Main category: cs.CV

TL;DR: 这篇论文提出了一种集成框架，通过优化YOLOv11-DIoU检测算法和改进DeepSort跟踪算法提高了遮挡情况下的车辆感知准确性，并使用GRU-Attention模型实现了高准确度的拒道报警预测。


<details>
  <summary>Details</summary>
Motivation: 现有的"检测-预测"系统在遮挡情况下车辆感知准确性低，而且在拒塞预测中丢失长序列依赖关系，影响了高速公路拒塞管控的效果。

Method: 1) 将YOLOv11优化为YOLOv11-DIoU（使用DIoU Loss替换GIoU Loss）
2) 改进DeepSort算法（融合马氏距离咄余弦距离）
3) 使用Greenberg模型分析流量密度关系
4) 构建GRU-Attention模型进行拒塞预警

Result: 1) YOLOv11-DIoU达到95.7% mAP（比基准提高6.5%），遮挡漏检率5.3%
2) DeepSort达到93.8% MOTA（比SORT提高11.3%），仅4次ID切换
3) GRU-Attention模型测试准确率99.7%（比传统GRU提高7-9%）
4) 10分钟预警30分钟拒塞，时间误差≤1分钟，警告准确率95%

Conclusion: 该集成框架有效解决了遮挡情况下车辆感知和长序列拒塞预测的问题，为高速公路拒塞控制提供了量化支持，具有良好的智能交通应用前景。

Abstract: Expressway traffic congestion severely reduces travel efficiency and hinders
regional connectivity. Existing "detection-prediction" systems have critical
flaws: low vehicle perception accuracy under occlusion and loss of
long-sequence dependencies in congestion forecasting. This study proposes an
integrated technical framework to resolve these issues.For traffic flow
perception, two baseline algorithms were optimized. Traditional YOLOv11 was
upgraded to YOLOv11-DIoU by replacing GIoU Loss with DIoU Loss, and DeepSort
was improved by fusing Mahalanobis (motion) and cosine (appearance) distances.
Experiments on Chang-Shen Expressway videos showed YOLOv11-DIoU achieved 95.7\%
mAP (6.5 percentage points higher than baseline) with 5.3\% occlusion miss
rate. DeepSort reached 93.8\% MOTA (11.3 percentage points higher than SORT)
with only 4 ID switches. Using the Greenberg model (for 10-15 vehicles/km
high-density scenarios), speed and density showed a strong negative correlation
(r=-0.97), conforming to traffic flow theory. For congestion warning, a
GRU-Attention model was built to capture congestion precursors. Trained 300
epochs with flow, density, and speed, it achieved 99.7\% test accuracy (7-9
percentage points higher than traditional GRU). In 10-minute advance warnings
for 30-minute congestion, time error was $\leq$ 1 minute. Validation with an
independent video showed 95\% warning accuracy, over 90\% spatial overlap of
congestion points, and stable performance in high-flow ($>$5 vehicles/second)
scenarios.This framework provides quantitative support for expressway
congestion control, with promising intelligent transportation applications.

</details>


### [68] [Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks](https://arxiv.org/abs/2509.13366)
*Tony Rohe,Martin Margreiter,Markus Moertl*

Main category: cs.CV

TL;DR: 通过深度学习和卷积神经网络自动化地面真实测试过程，将人力芯片时间减少99.58%，优化了基于群智数据的实时路边停车服务质量


<details>
  <summary>Details</summary>
Motivation: 优化现有的地面真实测试过程，减少人工工作量，提高基于群智数据的实时路边停车服务质量

Method: 采用机器学习和图像模式识别技术，应用卷积神经网络，自动化地面真实数据测试分析过程

Result: 实现了高度自动化，人力资源时间减少达523倍（减少99.58%），大大提高了测试效率

Conclusion: 机器学习技术成功应用于停车服务质量优化，自动化工具在数据分析过程中发挥了重要作用，具有广阔的未来应用前景

Abstract: This research is part of a study of a real-time, cloud-based on-street
parking service using crowd-sourced in-vehicle fleet data. The service provides
real-time information about available parking spots by classifying
crowd-sourced detections observed via ultrasonic sensors. The goal of this
research is to optimize the current parking service quality by analyzing the
automation of the existing test process for ground truth tests. Therefore,
methods from the field of machine learning, especially image pattern
recognition, are applied to enrich the database and substitute human
engineering work in major areas of the analysis process. After an introduction
into the related areas of machine learning, this paper explains the methods and
implementations made to achieve a high level of automation, applying
convolutional neural networks. Finally, predefined metrics present the
performance level achieved, showing a time reduction of human resources up to
99.58 %. The overall improvements are discussed, summarized, and followed by an
outlook for future development and potential application of the analysis
automation tool.

</details>


### [69] [An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity](https://arxiv.org/abs/2509.13375)
*Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen*

Main category: cs.CV

TL;DR: 本文系统分析了基于视觉语言模型(VLM)的零样本分布外检测机制，揭示了VLM相比单模态方法的优势在于利用丰富的语义新颖性，同时发现其对提示词措辞高度敏感的关键脆弱性。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP等视觉语言模型在零样本分布外检测方面表现出色，但研究界对其工作机制、相对于单模态方法的优势以及行为鲁棒性仍缺乏全面理解。

Method: 使用分布内和分布外提示词对VLM进行系统性实证分析，包括：1)在嵌入空间中形式化关键操作特性；2)量化比较VLM与单模态方法；3)测试对图像噪声和提示词措辞的敏感性。

Result: VLM在零样本OOD检测中优于单模态方法，主要优势在于利用语义新颖性；同时发现VLM对常见图像噪声具有鲁棒性，但对提示词措辞高度敏感的不对称鲁棒性特征。

Conclusion: 研究提供了对VLM基于OOD检测优势和关键脆弱性的结构化理解，为开发更鲁棒可靠的未来设计提供了实证指导。

Abstract: Vision-Language Models (VLMs), such as CLIP, have demonstrated remarkable
zero-shot out-of-distribution (OOD) detection capabilities, vital for reliable
AI systems. Despite this promising capability, a comprehensive understanding of
(1) why they work so effectively, (2) what advantages do they have over
single-modal methods, and (3) how is their behavioral robustness -- remains
notably incomplete within the research community. This paper presents a
systematic empirical analysis of VLM-based OOD detection using in-distribution
(ID) and OOD prompts. (1) Mechanisms: We systematically characterize and
formalize key operational properties within the VLM embedding space that
facilitate zero-shot OOD detection. (2) Advantages: We empirically quantify the
superiority of these models over established single-modal approaches,
attributing this distinct advantage to the VLM's capacity to leverage rich
semantic novelty. (3) Sensitivity: We uncovers a significant and previously
under-explored asymmetry in their robustness profile: while exhibiting
resilience to common image noise, these VLM-based methods are highly sensitive
to prompt phrasing. Our findings contribute a more structured understanding of
the strengths and critical vulnerabilities inherent in VLM-based OOD detection,
offering crucial, empirically-grounded guidance for developing more robust and
reliable future designs.

</details>


### [70] [Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery](https://arxiv.org/abs/2509.13631)
*Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit*

Main category: cs.CV

TL;DR: 本文提出了一种基于联邦学习的分布式方法，用于从卫星图像中识别和定位森林砍伐，在保护数据隐私的同时实现多客户端协作训练。


<details>
  <summary>Details</summary>
Motivation: 准确的森林砍伐识别对地理状况分析至关重要，但传统集中式训练需要合并数据，会危及客户端数据安全。联邦学习能够在分布式网络中协作训练模型，同时保持用户数据隐私和安全。

Method: 使用FLOWER框架和RAY框架构建分布式学习系统，采用YOLOS-small（Vision Transformer变体）、基于ResNet50的Faster R-CNN和基于MobileNetV3的Faster R-CNN模型，在公开数据集上进行训练和测试。

Result: 该方法为卫星图像分割任务提供了新的视角，能够有效识别和定位森林砍伐，同时确保数据安全和隐私保护。

Conclusion: 基于联邦学习的分布式框架为卫星图像分析提供了一种安全高效的解决方案，在保护数据隐私的前提下实现了准确的森林砍伐检测。

Abstract: Accurate identification of deforestation from satellite images is essential
in order to understand the geographical situation of an area. This paper
introduces a new distributed approach to identify as well as locate
deforestation across different clients using Federated Learning (FL). Federated
Learning enables distributed network clients to collaboratively train a model
while maintaining data privacy and security of the active users. In our
framework, a client corresponds to an edge satellite center responsible for
local data processing. Moreover, FL provides an advantage over centralized
training method which requires combining data, thereby compromising with data
security of the clients. Our framework leverages the FLOWER framework with RAY
framework to execute the distributed learning workload. Furthermore, efficient
client spawning is ensured by RAY as it can select definite amount of users to
create an emulation environment. Our FL framework uses YOLOS-small (a Vision
Transformer variant), Faster R-CNN with a ResNet50 backbone, and Faster R-CNN
with a MobileNetV3 backbone models trained and tested on publicly available
datasets. Our approach provides us a different view for image
segmentation-based tasks on satellite imagery.

</details>


### [71] [Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension](https://arxiv.org/abs/2509.13385)
*Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati*

Main category: cs.CV

TL;DR: 基于新的弯曲概念构建离散度量空间的几何交形并提出数据表示效果评估方法，可用于估计数据本质维度和评估降维技术效果


<details>
  <summary>Details</summary>
Motivation: 为了构建离散度量空间的弯曲基几何交形，并提供一种量化方法来评估数据表示的有效性，特别是对于降维技术的评估

Method: 利用最近发展的截面弯曲概念，通过捕捉点三元组与其他点之间的度量关系来构建弯曲基几何交形

Result: 实验证明该弯曲基分析方法可用于估计数据集的本质维度，探索经验网络的大规模几何特征，并评估降维技术的有效性

Conclusion: 该弯曲基几何交形方法为数据表示评估提供了一种量化工具，在本质维度估计和降维技术效果评估方面具有应用价值

Abstract: Utilizing recently developed abstract notions of sectional curvature, we
introduce a method for constructing a curvature-based geometric profile of
discrete metric spaces. The curvature concept that we use here captures the
metric relations between triples of points and other points. More
significantly, based on this curvature profile, we introduce a quantitative
measure to evaluate the effectiveness of data representations, such as those
produced by dimensionality reduction techniques. Furthermore, Our experiments
demonstrate that this curvature-based analysis can be employed to estimate the
intrinsic dimensionality of datasets. We use this to explore the large-scale
geometry of empirical networks and to evaluate the effectiveness of
dimensionality reduction techniques.

</details>


### [72] [Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji](https://arxiv.org/abs/2509.13388)
*Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra*

Main category: cs.CV

TL;DR: 使用机器学习和遥感技术分析斐济Nadi地区2013-2024年土地利用变化，重点关注城市化进程


<details>
  <summary>Details</summary>
Motivation: 斐济作为发展中国家正经历快速城市化，需要技术支持来监测土地利用/覆盖变化和建模

Method: 使用Landsat-8卫星影像，结合Google Earth Engine和k-means聚类进行无监督机器学习，采用卷积神经网络进行土地覆盖分类

Result: 生成了土地覆盖图并提供了变化检测可视化，突出显示城市区域随时间的变化

Conclusion: 该研究为土地覆盖/土地利用建模和变化检测提供了有效的技术支撑框架

Abstract: As a developing country, Fiji is facing rapid urbanisation, which is visible
in the massive development projects that include housing, roads, and civil
works. In this study, we present machine learning and remote sensing frameworks
to compare land use and land cover change from 2013 to 2024 in Nadi, Fiji. The
ultimate goal of this study is to provide technical support in land cover/land
use modelling and change detection. We used Landsat-8 satellite image for the
study region and created our training dataset with labels for supervised
machine learning. We used Google Earth Engine and unsupervised machine learning
via k-means clustering to generate the land cover map. We used convolutional
neural networks to classify the selected regions' land cover types. We present
a visualisation of change detection, highlighting urban area changes over time
to monitor changes in the map.

</details>


### [73] [Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence](https://arxiv.org/abs/2509.13396)
*Xinan Wang,Di Shi,Fengyu Wang*

Main category: cs.CV

TL;DR: 一种基于YOLOv7分割和ConvNeXt特征提取的三阶段框架，用于电力传输系统中的实时异物入侵检测与跟踪，支持边缘设备部署和增量更新。


<details>
  <summary>Details</summary>
Motivation: 解决电力传输系统中异物入侵相关安全问题，需要高准确性、强冒逆性和实时性的检测跟踪方案，并适合边缘设备部署。

Method: 三阶段框架：YOLOv7分割模型进行对象定位，ConvNeXt特征提取器使用三元组损失生成区分性嵌入，特征辅助IoU跟踪器处理遮挡和运动。支持混合精度推理和增量更新。

Result: 在真实监控和无人机视频数据集上高准确性和冒逆性，NVIDIA Jetson边缘设备上实时性能良好。

Conclusion: 该框架能够高效、准确地检测和跟踪异物入侵，适合实际边缘应用部署，且支持无需重新训练的增量学习。

Abstract: This paper presents a novel three-stage framework for real-time foreign
object intrusion (FOI) detection and tracking in power transmission systems.
The framework integrates: (1) a YOLOv7 segmentation model for fast and robust
object localization, (2) a ConvNeXt-based feature extractor trained with
triplet loss to generate discriminative embeddings, and (3) a feature-assisted
IoU tracker that ensures resilient multi-object tracking under occlusion and
motion. To enable scalable field deployment, the pipeline is optimized for
deployment on low-cost edge hardware using mixed-precision inference. The
system supports incremental updates by adding embeddings from previously unseen
objects into a reference database without requiring model retraining. Extensive
experiments on real-world surveillance and drone video datasets demonstrate the
framework's high accuracy and robustness across diverse FOI scenarios. In
addition, hardware benchmarks on NVIDIA Jetson devices confirm the framework's
practicality and scalability for real-world edge applications.

</details>


### [74] [EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing](https://arxiv.org/abs/2509.13399)
*Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou*

Main category: cs.CV

TL;DR: 提出了EdiVal-Agent框架，通过对象中心视角和多专家工具集成，为多轮指令图像编辑提供自动化、可扩展的细粒度评估，解决了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前指令图像编辑评估存在两个问题：(i)依赖配对参考图像导致覆盖有限且继承生成模型偏见；(ii)仅依赖零样本VLM评估不够精确。需要更可靠、可解释的评估方法。

Method: EdiVal-Agent首先将图像分解为语义对象，然后合成多样化的上下文感知编辑指令。评估时集成VLM与开放词汇对象检测器评估指令遵循，使用语义级特征提取器评估内容一致性，利用人类偏好模型判断视觉质量。

Result: 实验表明，VLM与对象检测器结合比单独使用VLM和CLIP指标在指令遵循评估中与人类判断有更强一致性。模块化设计支持未来工具集成以持续提升评估准确性。

Conclusion: 构建了EdiVal-Bench基准，涵盖9种指令类型和11种最先进编辑模型。EdiVal-Agent能够识别现有失败模式，为下一代编辑模型开发提供指导。

Abstract: Instruction-based image editing has advanced rapidly, yet reliable and
interpretable evaluation remains a bottleneck. Current protocols either (i)
depend on paired reference images -- resulting in limited coverage and
inheriting biases from prior generative models -- or (ii) rely solely on
zero-shot vision-language models (VLMs), whose prompt-based assessments of
instruction following, content consistency, and visual quality are often
imprecise.
  To address this, we introduce EdiVal-Agent, an automated, scalable, and
fine-grained evaluation framework for multi-turn instruction-based editing from
an object-centric perspective, supported by a suite of expert tools. Given an
image, EdiVal-Agent first decomposes it into semantically meaningful objects,
then synthesizes diverse, context-aware editing instructions. For evaluation,
it integrates VLMs with open-vocabulary object detectors to assess instruction
following, uses semantic-level feature extractors to evaluate content
consistency, and leverages human preference models to judge visual quality. We
show that combining VLMs with object detectors yields stronger agreement with
human judgments in instruction-following evaluation compared to using VLMs
alone and CLIP-based metrics. Furthermore, the pipeline's modular design allows
future tools to be seamlessly integrated, enhancing evaluation accuracy over
time.
  Instantiating this pipeline, we build EdiVal-Bench, a multi-turn editing
benchmark covering 9 instruction types and 11 state-of-the-art editing models
spanning autoregressive (AR) (including Nano Banana, GPT-Image-1),
flow-matching, and diffusion paradigms. We demonstrate that EdiVal-Agent can be
used to identify existing failure modes, thereby informing the development of
the next generation of editing models. Project page:
https://tianyucodings.github.io/EdiVAL-page/.

</details>


### [75] [MapAnything: Universal Feed-Forward Metric 3D Reconstruction](https://arxiv.org/abs/2509.13414)
*Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder*

Main category: cs.CV

TL;DR: MapAnything是一个统一的基于transformer的前馈模型，能够处理单张或多张图像以及可选的几何输入，直接回归出度量3D场景几何和相机参数，在多种3D视觉任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决多种3D视觉任务需要专门模型的问题，研究者希望开发一个统一的模型来处理包括未标定运动恢复结构、多视图立体视觉、单目深度估计等在内的多种任务。

Method: 采用基于transformer的前馈架构，输入图像和可选几何信息，使用分解的多视图场景几何表示（深度图、局部射线图、相机位姿和度量尺度因子），通过标准化监督和灵活输入增强进行训练。

Result: 实验表明MapAnything在多个3D视觉任务中优于或匹配专门的专家模型，同时提供更高效的联合训练性能。

Conclusion: MapAnything为通用3D重建骨干网络开辟了道路，展示了统一模型在多样化3D视觉任务中的强大潜力。

Abstract: We introduce MapAnything, a unified transformer-based feed-forward model that
ingests one or more images along with optional geometric inputs such as camera
intrinsics, poses, depth, or partial reconstructions, and then directly
regresses the metric 3D scene geometry and cameras. MapAnything leverages a
factored representation of multi-view scene geometry, i.e., a collection of
depth maps, local ray maps, camera poses, and a metric scale factor that
effectively upgrades local reconstructions into a globally consistent metric
frame. Standardizing the supervision and training across diverse datasets,
along with flexible input augmentation, enables MapAnything to address a broad
range of 3D vision tasks in a single feed-forward pass, including uncalibrated
structure-from-motion, calibrated multi-view stereo, monocular depth
estimation, camera localization, depth completion, and more. We provide
extensive experimental analyses and model ablations demonstrating that
MapAnything outperforms or matches specialist feed-forward models while
offering more efficient joint training behavior, thus paving the way toward a
universal 3D reconstruction backbone.

</details>


### [76] [Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization](https://arxiv.org/abs/2509.13474)
*Yujia Lin,Nicholas Evans*

Main category: cs.CV

TL;DR: 提出SCM-PR框架，结合RGB图像的高级语义信息，在LiDAR地图中实现鲁棒定位，解决现有跨模态定位方法在复杂场景中的挑战


<details>
  <summary>Details</summary>
Motivation: 解决无GPS环境下机器人精确定位问题，现有RGB方法对光照、天气和季节变化敏感，而现有跨模态方法在复杂场景、细粒度匹配和视角变化情况下表现不佳

Method: 使用VMamba骨干网络进行RGB特征提取；语义感知特征融合模块；结合语义和几何的LiDAR描述符；NetVLAD中的跨模态语义注意力机制；多视角语义几何匹配和语义一致性损失

Result: 在KITTI和KITTI-360数据集上实现了最先进的性能，优于其他跨模态地点识别方法

Conclusion: SCM-PR框架通过有效整合语义信息，显著提升了跨模态地点识别的鲁棒性和准确性，特别是在复杂环境和视角变化条件下

Abstract: Ensuring accurate localization of robots in environments without GPS
capability is a challenging task. Visual Place Recognition (VPR) techniques can
potentially achieve this goal, but existing RGB-based methods are sensitive to
changes in illumination, weather, and other seasonal changes. Existing
cross-modal localization methods leverage the geometric properties of RGB
images and 3D LiDAR maps to reduce the sensitivity issues highlighted above.
Currently, state-of-the-art methods struggle in complex scenes, fine-grained or
high-resolution matching, and situations where changes can occur in viewpoint.
In this work, we introduce a framework we call Semantic-Enhanced Cross-Modal
Place Recognition (SCM-PR) that combines high-level semantics utilizing RGB
images for robust localization in LiDAR maps. Our proposed method introduces: a
VMamba backbone for feature extraction of RGB images; a Semantic-Aware Feature
Fusion (SAFF) module for using both place descriptors and segmentation masks;
LiDAR descriptors that incorporate both semantics and geometry; and a
cross-modal semantic attention mechanism in NetVLAD to improve matching.
Incorporating the semantic information also was instrumental in designing a
Multi-View Semantic-Geometric Matching and a Semantic Consistency Loss, both in
a contrastive learning framework. Our experimental work on the KITTI and
KITTI-360 datasets show that SCM-PR achieves state-of-the-art performance
compared to other cross-modal place recognition methods.

</details>


### [77] [Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization](https://arxiv.org/abs/2509.13482)
*Hao Xu,Xiaolin Wu,Xi Zhang*

Main category: cs.CV

TL;DR: 提出SALVQ方法，用场景自适应的格点向量量化替代均匀标量量化，提升3DGS压缩的率失真性能，支持多码率且无需重新训练


<details>
  <summary>Details</summary>
Motivation: 现有3DGS压缩方法都使用简单的均匀标量量化(USQ)，但更复杂的量化器可能以极小开销显著提升压缩性能

Method: 采用格点向量量化(LVQ)替代USQ，并为每个场景优化格点基向量，实现场景自适应LVQ(SALVQ)，通过缩放基向量动态调整格点密度

Result: SALVQ在保持低复杂度的同时提升了率失真效率，可无缝集成现有架构，支持多码率目标且无需单独训练模型

Conclusion: SALVQ方法有效平衡了向量量化的率失真效率和USQ的低复杂度，为3DGS压缩提供了灵活高效的解决方案

Abstract: 3D Gaussian Splatting (3DGS) is rapidly gaining popularity for its
photorealistic rendering quality and real-time performance, but it generates
massive amounts of data. Hence compressing 3DGS data is necessary for the cost
effectiveness of 3DGS models. Recently, several anchor-based neural compression
methods have been proposed, achieving good 3DGS compression performance.
However, they all rely on uniform scalar quantization (USQ) due to its
simplicity. A tantalizing question is whether more sophisticated quantizers can
improve the current 3DGS compression methods with very little extra overhead
and minimal change to the system. The answer is yes by replacing USQ with
lattice vector quantization (LVQ). To better capture scene-specific
characteristics, we optimize the lattice basis for each scene, improving LVQ's
adaptability and R-D efficiency. This scene-adaptive LVQ (SALVQ) strikes a
balance between the R-D efficiency of vector quantization and the low
complexity of USQ. SALVQ can be seamlessly integrated into existing 3DGS
compression architectures, enhancing their R-D performance with minimal
modifications and computational overhead. Moreover, by scaling the lattice
basis vectors, SALVQ can dynamically adjust lattice density, enabling a single
model to accommodate multiple bit rate targets. This flexibility eliminates the
need to train separate models for different compression levels, significantly
reducing training time and memory consumption.

</details>


### [78] [MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes](https://arxiv.org/abs/2509.13484)
*Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk*

Main category: cs.CV

TL;DR: 提出了MINGLE方法，用于从街景图像中检测社交群体区域，通过三阶段流程结合目标检测、深度估计和VLM推理来识别和定位社交互动群体。


<details>
  <summary>Details</summary>
Motivation: 理解公共场所的群体社交互动对城市规划至关重要，但传统目标检测方法难以捕捉复杂的社交关系信号。

Method: 三阶段模块化流程：1) 使用现成的人体检测和深度估计；2) 基于VLM的成对社交关系分类；3) 轻量级空间聚合算法定位社交连接群体。

Result: 构建了包含10万张街景图像的新数据集，标注了个人和社交群体的边界框和标签，结合人工标注和MINGLE输出。

Conclusion: MINGLE方法能够有效检测和定位社交群体区域，为城市社交环境分析提供了新的技术手段和数据集支持。

Abstract: Understanding group-level social interactions in public spaces is crucial for
urban planning, informing the design of socially vibrant and inclusive
environments. Detecting such interactions from images involves interpreting
subtle visual cues such as relations, proximity, and co-movement - semantically
complex signals that go beyond traditional object detection. To address this
challenge, we introduce a social group region detection task, which requires
inferring and spatially grounding visual regions defined by abstract
interpersonal relations. We propose MINGLE (Modeling INterpersonal Group-Level
Engagement), a modular three-stage pipeline that integrates: (1) off-the-shelf
human detection and depth estimation, (2) VLM-based reasoning to classify
pairwise social affiliation, and (3) a lightweight spatial aggregation
algorithm to localize socially connected groups. To support this task and
encourage future research, we present a new dataset of 100K urban street-view
images annotated with bounding boxes and labels for both individuals and
socially interacting groups. The annotations combine human-created labels and
outputs from the MINGLE pipeline, ensuring semantic richness and broad coverage
of real-world scenarios.

</details>


### [79] [BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation](https://arxiv.org/abs/2509.13496)
*Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan*

Main category: cs.CV

TL;DR: BiasMap是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念级表征偏见，通过交叉注意力归因图揭示人口统计学与语义概念的结构性纠缠，并提出基于能量引导扩散采样的偏见缓解方法。


<details>
  <summary>Details</summary>
Motivation: 现有偏见发现方法主要关注输出层面的人口分布，无法保证缓解后的概念表征解耦，需要更深入地探索生成过程中的表征偏见。

Method: 利用交叉注意力归因图量化人口统计学与语义概念的空间纠缠（IoU），并通过能量引导扩散采样在去噪过程中最小化SoftIoU来缓解偏见。

Result: 发现现有公平性干预措施可能减少输出分布差距，但往往无法解耦概念级耦合，而BiasMap方法能够在图像生成中缓解概念纠缠并补充分布偏见缓解。

Conclusion: BiasMap提供了一个发现和缓解潜在概念级表征偏见的新框架，能够揭示传统方法无法发现的隐藏偏见，并通过直接修改潜在噪声空间实现有效的偏见缓解。

Abstract: Bias discovery is critical for black-box generative models, especiall
text-to-image (TTI) models. Existing works predominantly focus on output-level
demographic distributions, which do not necessarily guarantee concept
representations to be disentangled post-mitigation. We propose BiasMap, a
model-agnostic framework for uncovering latent concept-level representational
biases in stable diffusion models. BiasMap leverages cross-attention
attribution maps to reveal structural entanglements between demographics (e.g.,
gender, race) and semantics (e.g., professions), going deeper into
representational bias during the image generation. Using attribution maps of
these concepts, we quantify the spatial demographics-semantics concept
entanglement via Intersection over Union (IoU), offering a lens into bias that
remains hidden in existing fairness discovery approaches. In addition, we
further utilize BiasMap for bias mitigation through energy-guided diffusion
sampling that directly modifies latent noise space and minimizes the expected
SoftIoU during the denoising process. Our findings show that existing fairness
interventions may reduce the output distributional gap but often fail to
disentangle concept-level coupling, whereas our mitigation method can mitigate
concept entanglement in image generation while complementing distributional
bias mitigation.

</details>


### [80] [LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming](https://arxiv.org/abs/2509.13504)
*Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández*

Main category: cs.CV

TL;DR: LivePyxel是一个基于Python的实时图像标注工具，可直接连接成像设备进行实时标注，支持贝塞尔曲线和二进制掩码等专业标注工具


<details>
  <summary>Details</summary>
Motivation: 现有图像标注软件需要先上传预收集的数据集，不支持实时数据采集，这在实验室实时仪器数据采集场景中造成限制

Method: 开发基于Python的图形用户界面，集成OpenCV和Numpy高性能库，支持多种视频设备连接，提供类似商业图形软件的标注工具

Result: 实现了实时图像标注功能，支持贝塞尔曲线、二进制掩码和非破坏性图层等专业编辑功能

Conclusion: LivePyxel简化了数据收集和标注流程，加速了实验工作流中AI模型的开发

Abstract: The lack of flexible annotation tools has hindered the deployment of AI
models in some scientific areas. Most existing image annotation software
requires users to upload a precollected dataset, which limits support for
on-demand pipelines and introduces unnecessary steps to acquire images. This
constraint is particularly problematic in laboratory environments, where
real-time data acquisition from instruments such as microscopes is increasingly
common. In this work, we introduce \texttt{LivePixel}, a Python-based graphical
user interface that integrates with imaging systems, such as webcams,
microscopes, and others, to enable real-time image annotation. LivePyxel is
designed to be easy to use through a simple interface that allows users to
precisely delimit areas for annotation using tools commonly found in commercial
graphics editing software. Of particular interest is the availability of
B\'ezier splines and binary masks, and the software's capacity to work with
non-destructive layers that enable high-performance editing. LivePyxel also
integrates a wide compatibility across video devices, and it's optimized for
object detection operations via the use of OpenCV in combination with
high-performance libraries designed to handle matrix and linear algebra
operations via Numpy effectively. LivePyxel facilitates seamless data
collection and labeling, accelerating the development of AI models in
experimental workflows. LivePyxel freely available at
https://github.com/UGarCil/LivePyxel

</details>


### [81] [DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform](https://arxiv.org/abs/2509.13506)
*Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane*

Main category: cs.CV

TL;DR: 提出DEFT-VTON方法，使用Doob's h-transform高效微调技术，仅训练1.42%的冻结参数实现虚拟试穿，并通过自适应一致性损失减少推理时间至15步。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试穿方法需要大量端到端训练，但实际应用需要有限的训练和推理预算，因此需要高效的微调方法。

Method: 采用DEFT冻结预训练模型参数，训练小型h-transform网络学习条件变换；结合自适应一致性损失和去噪分数匹配损失进行低成本微调。

Result: 在虚拟试穿任务上达到最先进性能，仅需15步去噪步骤，同时保持竞争力结果。

Conclusion: DEFT-VTON方法实现了高效参数利用和快速推理，为实际虚拟试穿应用提供了可行的解决方案。

Abstract: Diffusion models enable high-quality virtual try-on (VTO) with their
established image synthesis abilities. Despite the extensive end-to-end
training of large pre-trained models involved in current VTO methods,
real-world applications often prioritize limited training and inference,
serving, and deployment budgets for VTO. To solve this obstacle, we apply
Doob's h-transform efficient fine-tuning (DEFT) for adapting large pre-trained
unconditional models for downstream image-conditioned VTO abilities. DEFT
freezes the pre-trained model's parameters and trains a small h-transform
network to learn a conditional h-transform. The h-transform network allows
training only 1.42 percent of the frozen parameters, compared to a baseline of
5.52 percent in traditional parameter-efficient fine-tuning (PEFT).
  To further improve DEFT's performance and decrease existing models' inference
time, we additionally propose an adaptive consistency loss. Consistency
training distills slow but high-performing diffusion models into a fast one
while retaining performance by enforcing consistencies along the inference
path. Inspired by constrained optimization, instead of distillation, we combine
the consistency loss and the denoising score matching loss in a data-adaptive
manner for fine-tuning existing VTO models at a low cost. Empirical results
show the proposed DEFT-VTON method achieves state-of-the-art performance on VTO
tasks, with as few as 15 denoising steps, while maintaining competitive
results.

</details>


### [82] [Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving](https://arxiv.org/abs/2509.13507)
*Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari*

Main category: cs.CV

TL;DR: 提出了一种基于数据增强的合成数据生成方法，通过对抗学习光照条件来改善虚拟行人生成质量，提升自动驾驶中行人识别性能


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要合成数据来覆盖特定交通场景，但合成数据与真实数据之间存在领域差距，影响行人识别效果

Method: 开发了数据增强流水线，在Cityscapes数据集中添加虚拟行人，并提出了新颖的生成对抗网络架构来学习数据集的光照条件以提高真实感

Result: 在语义分割和实例分割任务上评估了该方法的效果

Conclusion: 该方法能够有效生成逼真的合成交通场景数据，改善自动驾驶系统中的行人识别性能

Abstract: In the autonomous driving area synthetic data is crucial for cover specific
traffic scenarios which autonomous vehicle must handle. This data commonly
introduces domain gap between synthetic and real domains. In this paper we
deploy data augmentation to generate custom traffic scenarios with VRUs in
order to improve pedestrian recognition. We provide a pipeline for augmentation
of the Cityscapes dataset with virtual pedestrians. In order to improve
augmentation realism of the pipeline we reveal a novel generative network
architecture for adversarial learning of the data-set lighting conditions. We
also evaluate our approach on the tasks of semantic and instance segmentation.

</details>


### [83] [FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation](https://arxiv.org/abs/2509.13508)
*Maksim Penkin,Andrey Krylov*

Main category: cs.CV

TL;DR: 提出了FunKAN网络，一种专门为医学图像处理设计的可解释神经网络框架，在图像增强和分割任务中优于其他KAN方法


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法可解释性差，以及Kolmogorov-Arnold网络破坏图像空间结构的问题

Method: 基于函数空间的Kolmogorov-Arnold表示定理，使用傅里叶分解和Hermite函数基学习内部函数

Result: 在多个医学数据集上（IXI、BUSI、GlaS、CVC-ClinicDB）的增强和分割任务中，PSNR、TV、IoU、F1指标均优于其他KAN方法

Conclusion: FunKAN架起了理论函数逼近与医学图像分析之间的桥梁，为临床应用提供了鲁棒且可解释的解决方案

Abstract: Medical image enhancement and segmentation are critical yet challenging tasks
in modern clinical practice, constrained by artifacts and complex anatomical
variations. Traditional deep learning approaches often rely on complex
architectures with limited interpretability. While Kolmogorov-Arnold networks
offer interpretable solutions, their reliance on flattened feature
representations fundamentally disrupts the intrinsic spatial structure of
imaging data. To address this issue we propose a Functional Kolmogorov-Arnold
Network (FunKAN) -- a novel interpretable neural framework, designed
specifically for image processing, that formally generalizes the
Kolmogorov-Arnold representation theorem onto functional spaces and learns
inner functions using Fourier decomposition over the basis Hermite functions.
We explore FunKAN on several medical image processing tasks, including Gibbs
ringing suppression in magnetic resonance images, benchmarking on IXI dataset.
We also propose U-FunKAN as state-of-the-art binary medical segmentation model
with benchmarks on three medical datasets: BUSI (ultrasound images), GlaS
(histological structures) and CVC-ClinicDB (colonoscopy videos), detecting
breast cancer, glands and polyps, respectively. Experiments on those diverse
datasets demonstrate that our approach outperforms other KAN-based backbones in
both medical image enhancement (PSNR, TV) and segmentation (IoU, F1). Our work
bridges the gap between theoretical function approximation and medical image
analysis, offering a robust, interpretable solution for clinical applications.

</details>


### [84] [Multimodal Hate Detection Using Dual-Stream Graph Neural Networks](https://arxiv.org/abs/2509.13515)
*Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出了一种新的多模态双流图神经网络模型，通过实例图和互补权重图来突出仇恨内容，在仇恨视频分类任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态方法通常对所有内容一视同仁，未能强调仇恨成分，且无法系统捕获视频中的结构化信息，限制了多模态融合效果。

Method: 构建实例图将视频分割为多个实例提取特征，通过互补权重图为特征分配重要性权重以突出仇恨实例，结合权重和特征生成视频标签。

Result: 在公共数据集上的广泛实验表明，该模型在仇恨视频分类方面达到最先进水平，并具有很强的可解释性。

Conclusion: 提出的多模态双流图神经网络模型有效解决了现有方法的局限性，在仇恨视频检测任务上表现出色且具有良好解释性。

Abstract: Hateful videos present serious risks to online safety and real-world
well-being, necessitating effective detection methods. Although multimodal
classification approaches integrating information from several modalities
outperform unimodal ones, they typically neglect that even minimal hateful
content defines a video's category. Specifically, they generally treat all
content uniformly, instead of emphasizing the hateful components. Additionally,
existing multimodal methods cannot systematically capture structured
information in videos, limiting the effectiveness of multimodal fusion. To
address these limitations, we propose a novel multimodal dual-stream graph
neural network model. It constructs an instance graph by separating the given
video into several instances to extract instance-level features. Then, a
complementary weight graph assigns importance weights to these features,
highlighting hateful instances. Importance weights and instance features are
combined to generate video labels. Our model employs a graph-based framework to
systematically model structured relationships within and across modalities.
Extensive experiments on public datasets show that our model is
state-of-the-art in hateful video classification and has strong explainability.
Code is available:
https://github.com/Multimodal-Intelligence-Lab-MIL/MultiHateGNN.

</details>


### [85] [ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors](https://arxiv.org/abs/2509.13525)
*Romain Hardy,Tyler Berzin,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: ColonCrafter是一个基于扩散模型的深度估计方法，能够从单目结肠镜视频生成时间一致的深度图，在C3VD数据集上实现了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 结肠镜中的3D场景理解面临重大挑战，需要自动化方法进行精确深度估计。现有的内窥镜深度估计模型在视频序列的时间一致性方面存在困难，限制了其在3D重建中的应用。

Method: 使用基于扩散模型的深度估计方法，从合成结肠镜序列学习鲁棒的几何先验来生成时间一致的深度图，并引入风格迁移技术将真实临床视频适配到合成训练域。

Result: 在C3VD数据集上实现了最先进的零样本性能，优于通用和特定于内窥镜的方法，能够生成3D点云和进行表面覆盖评估。

Conclusion: 虽然完整的轨迹3D重建仍然具有挑战性，但ColonCrafter展示了临床相关的应用价值，包括3D点云生成和表面覆盖评估。

Abstract: Three-dimensional (3D) scene understanding in colonoscopy presents
significant challenges that necessitate automated methods for accurate depth
estimation. However, existing depth estimation models for endoscopy struggle
with temporal consistency across video sequences, limiting their applicability
for 3D reconstruction. We present ColonCrafter, a diffusion-based depth
estimation model that generates temporally consistent depth maps from monocular
colonoscopy videos. Our approach learns robust geometric priors from synthetic
colonoscopy sequences to generate temporally consistent depth maps. We also
introduce a style transfer technique that preserves geometric structure while
adapting real clinical videos to match our synthetic training domain.
ColonCrafter achieves state-of-the-art zero-shot performance on the C3VD
dataset, outperforming both general-purpose and endoscopy-specific approaches.
Although full trajectory 3D reconstruction remains a challenge, we demonstrate
clinically relevant applications of ColonCrafter, including 3D point cloud
generation and surface coverage assessment.

</details>


### [86] [MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM](https://arxiv.org/abs/2509.13536)
*Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou*

Main category: cs.CV

TL;DR: 通过基于几何相似性的汇聚算法和PG点采样初始化，在不影响渲染性能的前提下，降低了3DGS的GPU内存占用并提升了渲染质量


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式平台（如微空中运输工具）在3D重建中计算资源和内存有限的问题，当前研究太过依赖高性能桌面GPU

Method: 1. 在voxel空间中基于几何相似性合并冗余的3D高斯原语 2. 通过Patch-Grid(PG)点采样初始化3D高斯原语以更准确建模整个场景

Result: 在公开数据集上的定量和定性评估证明了方法的有效性，减少了GPU内存使用量同时提升了渲染质量

Conclusion: 该方法为嵌入式平台提供了更高效的3D重建解决方案，在保持系统性能的同时优化了内存使用和渲染质量

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have made a significant
impact on rendering and reconstruction techniques. Current research
predominantly focuses on improving rendering performance and reconstruction
quality using high-performance desktop GPUs, largely overlooking applications
for embedded platforms like micro air vehicles (MAVs). These devices, with
their limited computational resources and memory, often face a trade-off
between system performance and reconstruction quality. In this paper, we
improve existing methods in terms of GPU memory usage while enhancing rendering
quality. Specifically, to address redundant 3D Gaussian primitives in SLAM, we
propose merging them in voxel space based on geometric similarity. This reduces
GPU memory usage without impacting system runtime performance. Furthermore,
rendering quality is improved by initializing 3D Gaussian primitives via
Patch-Grid (PG) point sampling, enabling more accurate modeling of the entire
scene. Quantitative and qualitative evaluations on publicly available datasets
demonstrate the effectiveness of our improvements.

</details>


### [87] [Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles](https://arxiv.org/abs/2509.13577)
*Tongfei Guo,Lili Su*

Main category: cs.CV

TL;DR: 本文提出了一种自适应框架用于自动驾驶车辆轨迹预测中的分布外检测，通过显式建模预测误差模式，在检测延迟和误报率方面显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在部署时面临训练数据与真实世界条件之间的分布偏移问题，现有研究主要集中在计算机视觉任务的OOD检测，而轨迹级别的OOD检测研究相对不足。

Method: 基于快速变化检测(QCD)任务，引入自适应机制来建模预测误差的模式依赖性分布，这些分布会随时间演变并具有数据集特定的动态特性。

Result: 在多个真实世界数据集上的实验表明，该方法在检测延迟和误报率方面都有显著改进，在准确性和计算效率上都明显优于现有的不确定度量化和基于视觉的OOD方法。

Conclusion: 该框架为可靠的、驾驶感知的自主性提供了一条实用路径，能够有效处理复杂驾驶环境中的分布外检测问题。

Abstract: Trajectory prediction is central to the safe and seamless operation of
autonomous vehicles (AVs). In deployment, however, prediction models inevitably
face distribution shifts between training data and real-world conditions, where
rare or underrepresented traffic scenarios induce out-of-distribution (OOD)
cases. While most prior OOD detection research in AVs has concentrated on
computer vision tasks such as object detection and segmentation,
trajectory-level OOD detection remains largely underexplored. A recent study
formulated this problem as a quickest change detection (QCD) task, providing
formal guarantees on the trade-off between detection delay and false alarms
[1]. Building on this foundation, we propose a new framework that introduces
adaptive mechanisms to achieve robust detection in complex driving
environments. Empirical analysis across multiple real-world datasets reveals
that prediction errors -- even on in-distribution samples -- exhibit
mode-dependent distributions that evolve over time with dataset-specific
dynamics. By explicitly modeling these error modes, our method achieves
substantial improvements in both detection delay and false alarm rates.
Comprehensive experiments on established trajectory prediction benchmarks show
that our framework significantly outperforms prior UQ- and vision-based OOD
approaches in both accuracy and computational efficiency, offering a practical
path toward reliable, driving-aware autonomy.

</details>


### [88] [Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection](https://arxiv.org/abs/2509.13586)
*Nathalie Neptune,Josiane Mothe*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的亚马逊雨林砍伐检测方法，通过卫星图像对比较和视觉语义模型自动标注变化区域。


<details>
  <summary>Details</summary>
Motivation: 亚马逊雨林砍伐对全球碳排放和生物多样性有重大影响，需要有效的监测工具来检测和研究砍伐活动。

Method: 利用地球观测卫星图像对，采用深度学习技术比较不同时期的同一区域图像，识别森林覆盖变化，并结合科学文献提取关键词进行自动标注。

Result: 在亚马逊图像对数据集上验证了方法的有效性，能够准确检测砍伐并生成相关标注。

Conclusion: 该方法为监测和研究亚马逊雨林砍伐影响提供了有用工具，且具有通用性可应用于其他领域。

Abstract: The Amazon rain forest is a vital ecosystem that plays a crucial role in
regulating the Earth's climate and providing habitat for countless species.
Deforestation in the Amazon is a major concern as it has a significant impact
on global carbon emissions and biodiversity. In this paper, we present a method
for detecting deforestation in the Amazon using image pairs from Earth
observation satellites. Our method leverages deep learning techniques to
compare the images of the same area at different dates and identify changes in
the forest cover. We also propose a visual semantic model that automatically
annotates the detected changes with relevant keywords. The candidate annotation
for images are extracted from scientific documents related to the Amazon
region. We evaluate our approach on a dataset of Amazon image pairs and
demonstrate its effectiveness in detecting deforestation and generating
relevant annotations. Our method provides a useful tool for monitoring and
studying the impact of deforestation in the Amazon. While we focus on
environment applications of our work by using images of deforestation in the
Amazon rain forest to demonstrate the effectiveness of our proposed approach,
it is generic enough to be applied to other domains.

</details>


### [89] [Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation](https://arxiv.org/abs/2509.13590)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 基于Google Gemini 2.5 Flash的多模态医疗影像分析框架，整合视觉和语言处理技术，实现肿瘤自动检测和临床报告生成，支持CT、MRI、X-ray和超声等多种影像模态。


<details>
  <summary>Details</summary>
Motivation: 医疗影像AI的快速发展需要更智能的多模态分析框架，以提升诊断准确性和临床决策效率，同时减少对大型数据集的依赖。

Method: 采用Vision-Language Models (VLMs)，结合坐标验证机制和概率高斯建模进行异常分布分析，使用多层可视化技术和精确的提示工程进行结果处理。

Result: 在多模态异常检测中表现优异，位置测量平均偏差80像素，具备零样本学习能力，可通过用户友好的Gradio界面集成到临床工作流中。

Conclusion: 该框架在自动化诊断支持和放射工作流效率方面取得显著进展，但需要进一步的临床验证和多中心评估才能广泛应用。

Abstract: The rapid advancement of artificial intelligence (AI) in healthcare imaging
has revolutionized diagnostic medicine and clinical decision-making processes.
This work presents an intelligent multimodal framework for medical image
analysis that leverages Vision-Language Models (VLMs) in healthcare
diagnostics. The framework integrates Google Gemini 2.5 Flash for automated
tumor detection and clinical report generation across multiple imaging
modalities including CT, MRI, X-ray, and Ultrasound. The system combines visual
feature extraction with natural language processing to enable contextual image
interpretation, incorporating coordinate verification mechanisms and
probabilistic Gaussian modeling for anomaly distribution. Multi-layered
visualization techniques generate detailed medical illustrations, overlay
comparisons, and statistical representations to enhance clinical confidence,
with location measurement achieving 80 pixels average deviation. Result
processing utilizes precise prompt engineering and textual analysis to extract
structured clinical information while maintaining interpretability.
Experimental evaluations demonstrated high performance in anomaly detection
across multiple modalities. The system features a user-friendly Gradio
interface for clinical workflow integration and demonstrates zero-shot learning
capabilities to reduce dependence on large datasets. This framework represents
a significant advancement in automated diagnostic support and radiological
workflow efficiency, though clinical validation and multi-center evaluation are
necessary prior to widespread adoption.

</details>


### [90] [A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms](https://arxiv.org/abs/2509.13605)
*Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong*

Main category: cs.CV

TL;DR: CLAP算法从2D定位扩展到3D定位和图像拼接的通用框架，通过聚类方法处理噪声和异常值，比传统RANSAC方法更鲁棒


<details>
  <summary>Details</summary>
Motivation: 扩展CLAP算法到更通用的框架，超越2D定位应用，为处理噪声和不确定性提供更广泛适用的工具

Method: 采用聚类方法来抑制噪声和错误特征匹配，替代传统的RANSAC异常值拒绝方案

Result: 成功将CLAP扩展到3D定位和图像拼接领域，并建立了CLAP、RANSAC和Hough变换之间的关系

Conclusion: CLAP的泛化框架适用于多个不同领域，是处理噪声和不确定性的有效工具

Abstract: In previous work, we introduced a 2D localization algorithm called CLAP,
Clustering to Localize Across $n$ Possibilities, which was used during our
championship win in RoboCup 2024, an international autonomous humanoid soccer
competition. CLAP is particularly recognized for its robustness against
outliers, where clustering is employed to suppress noise and mitigate against
erroneous feature matches. This clustering-based strategy provides an
alternative to traditional outlier rejection schemes such as RANSAC, in which
candidates are validated by reprojection error across all data points. In this
paper, CLAP is extended to a more general framework beyond 2D localization,
specifically to 3D localization and image stitching. We also show how CLAP,
RANSAC, and Hough transforms are related. The generalization of CLAP is widely
applicable to many different fields and can be a useful tool to deal with noise
and uncertainty.

</details>


### [91] [SAMIR, an efficient registration framework via robust feature learning from SAM](https://arxiv.org/abs/2509.13629)
*Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen*

Main category: cs.CV

TL;DR: SAMIR是一个基于Segment Anything Model的医学图像配准框架，通过SAM提取结构感知特征嵌入，结合轻量级3D头部和分层特征一致性损失，在心脏和腹部CT图像配准任务上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督医学图像配准方法需要分割掩码或地标等解剖先验信息，但这些弱标签通常不易获得，限制了实际应用。受视觉基础模型强大表示学习能力的启发，本文利用Segment Anything Model来增强特征提取。

Method: 设计任务特定的适配管道，使用SAM的图像编码器提取结构感知特征嵌入；构建轻量级3D头部在嵌入空间内细化特征；引入分层特征一致性损失指导从粗到细的特征匹配。

Result: 在基准数据集上，SAMIR在心脏图像配准任务上性能提升2.68%（ACDC数据集），在腹部CT图像配准任务上提升6.44%，显著优于最先进方法。

Conclusion: SAMIR框架通过利用预训练的Segment Anything Model提取鲁棒的特征表示，有效解决了医学图像配准中对解剖先验信息的依赖问题，为医学图像分析提供了新的解决方案。

Abstract: Image registration is a fundamental task in medical image analysis.
Deformations are often closely related to the morphological characteristics of
tissues, making accurate feature extraction crucial. Recent weakly supervised
methods improve registration by incorporating anatomical priors such as
segmentation masks or landmarks, either as inputs or in the loss function.
However, such weak labels are often not readily available, limiting their
practical use. Motivated by the strong representation learning ability of
visual foundation models, this paper introduces SAMIR, an efficient medical
image registration framework that utilizes the Segment Anything Model (SAM) to
enhance feature extraction. SAM is pretrained on large-scale natural image
datasets and can learn robust, general-purpose visual representations. Rather
than using raw input images, we design a task-specific adaptation pipeline
using SAM's image encoder to extract structure-aware feature embeddings,
enabling more accurate modeling of anatomical consistency and deformation
patterns. We further design a lightweight 3D head to refine features within the
embedding space, adapting to local deformations in medical images.
Additionally, we introduce a Hierarchical Feature Consistency Loss to guide
coarse-to-fine feature matching and improve anatomical alignment. Extensive
experiments demonstrate that SAMIR significantly outperforms state-of-the-art
methods on benchmark datasets for both intra-subject cardiac image registration
and inter-subject abdomen CT image registration, achieving performance
improvements of 2.68% on ACDC and 6.44% on the abdomen dataset. The source code
will be publicly available on GitHub following the acceptance of this paper.

</details>


### [92] [Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction](https://arxiv.org/abs/2509.13652)
*Yumin Li,Dylan Campbell*

Main category: cs.CV

TL;DR: GARPS是一种无需训练的相对相机位姿估计框架，通过直接对齐两个独立重建的3D高斯混合模型来实现度量尺度的位姿估计，在Real-Estate10K数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的双目位姿估计方法无法恢复度量尺度（相机平移只有尺度未知），且在宽基线和纹理贫乏区域表现不佳。需要一种能够实现度量尺度估计且对纹理贫乏区域鲁棒的方法。

Method: 使用度量单目深度估计器和高斯场景重建器为每张图像构建度量3D高斯混合模型(GMM)，然后通过优化可微分的GMM对齐目标来精化初始位姿，该目标综合考虑几何结构、视角无关颜色、各向异性协方差和语义特征一致性。

Result: 在Real-Estate10K数据集上的大量实验表明，GARPS超越了经典方法和最先进的学习方法，包括MASt3R。

Conclusion: 将单视角感知与多视角几何相结合，可以实现鲁棒且具有度量尺度的相对位姿估计，展现了这一方向的巨大潜力。

Abstract: Estimating metric relative camera pose from a pair of images is of great
importance for 3D reconstruction and localisation. However, conventional
two-view pose estimation methods are not metric, with camera translation known
only up to a scale, and struggle with wide baselines and textureless or
reflective surfaces. This paper introduces GARPS, a training-free framework
that casts this problem as the direct alignment of two independently
reconstructed 3D scenes. GARPS leverages a metric monocular depth estimator and
a Gaussian scene reconstructor to obtain a metric 3D Gaussian Mixture Model
(GMM) for each image. It then refines an initial pose from a feed-forward
two-view pose estimator by optimising a differentiable GMM alignment objective.
This objective jointly considers geometric structure, view-independent colour,
anisotropic covariance, and semantic feature consistency, and is robust to
occlusions and texture-poor regions without requiring explicit 2D
correspondences. Extensive experiments on the Real\-Estate10K dataset
demonstrate that GARPS outperforms both classical and state-of-the-art
learning-based methods, including MASt3R. These results highlight the potential
of bridging single-view perception with multi-view geometry to achieve robust
and metric relative pose estimation.

</details>


### [93] [Deep Lookup Network](https://arxiv.org/abs/2509.13662)
*Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An*

Main category: cs.CV

TL;DR: 该论文提出用查找表操作替代卷积神经网络中的乘法操作，以降低计算复杂度和能耗，提高移动设备部署效率。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络中的乘法操作计算复杂度高、能耗大，阻碍了在移动设备上的部署。受资源受限设备使用查找表简化计算的启发，作者希望用查找操作替代乘法操作。

Method: 提出可微分查找表操作作为神经网络基础构件，用查找操作替代权重和激活值的乘法计算，并设计了多种训练策略来促进收敛。

Result: 在图像分类、超分辨率和点云分类任务中，查找网络在能耗和推理速度方面效率更高，同时保持了与原始卷积网络相当的性能。

Conclusion: 查找网络在不同任务（分类和回归）和数据类型（图像和点云）上都取得了最先进的性能，证明了查找操作在提高神经网络效率方面的有效性。

Abstract: Convolutional neural networks are constructed with massive operations with
different types and are highly computationally intensive. Among these
operations, multiplication operation is higher in computational complexity and
usually requires {more} energy consumption with longer inference time than
other operations, which hinders the deployment of convolutional neural networks
on mobile devices. In many resource-limited edge devices, complicated
operations can be calculated via lookup tables to reduce computational cost.
Motivated by this, in this paper, we introduce a generic and efficient lookup
operation which can be used as a basic operation for the construction of neural
networks. Instead of calculating the multiplication of weights and activation
values, simple yet efficient lookup operations are adopted to compute their
responses. To enable end-to-end optimization of the lookup operation, we
construct the lookup tables in a differentiable manner and propose several
training strategies to promote their convergence. By replacing computationally
expensive multiplication operations with our lookup operations, we develop
lookup networks for the image classification, image super-resolution, and point
cloud classification tasks. It is demonstrated that our lookup networks can
benefit from the lookup operations to achieve higher efficiency in terms of
energy consumption and inference speed while maintaining competitive
performance to vanilla convolutional networks. Extensive experiments show that
our lookup networks produce state-of-the-art performance on different tasks
(both classification and regression tasks) and different data types (both
images and point clouds).

</details>


### [94] [Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation](https://arxiv.org/abs/2509.13676)
*Xiaobo Yang,Xiaojin Gong*

Main category: cs.CV

TL;DR: 通过使用SAM生成语义超像素来压缩视觉标记，减少93%的视觉标记数量同时保持性能，提升RIS模型的训练和推理速度


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在指代图像分割中遇到的视觉标记冗余问题，传统的补丁视觉投影器无法在减少标记数量和保持语义清晰性之间取得平衡

Method: 提出一种新的语义视觉投影器，利用SAM生成的语义超像素识别"视觉单词"，通过压缩和投影语义超像素作为视觉标记，同时使用语义超像素位置嵌入和语义超像素聚合器来减少信息损失

Result: 方法减少93%的视觉标记数量但性能不受影响，显著提升了MLLM的训练和推理速度，在RIS任务上超过现有的压缩视觉投影器

Conclusion: 该方法通过语义超像素的方式有效解决了视觉标记冗余问题，在大幅减少计算量的同时保持了分割性能，为高效的多模态图像分割提供了新的解决方案

Abstract: Recently, Referring Image Segmentation (RIS) frameworks that pair the
Multimodal Large Language Model (MLLM) with the Segment Anything Model (SAM)
have achieved impressive results. However, adapting MLLM to segmentation is
computationally intensive, primarily due to visual token redundancy. We observe
that traditional patch-wise visual projectors struggle to strike a balance
between reducing the number of visual tokens and preserving semantic clarity,
often retaining overly long token sequences to avoid performance drops.
Inspired by text tokenizers, we propose a novel semantic visual projector that
leverages semantic superpixels generated by SAM to identify "visual words" in
an image. By compressing and projecting semantic superpixels as visual tokens,
our approach adaptively shortens the token sequence according to scene
complexity while minimizing semantic loss in compression. To mitigate loss of
information, we propose a semantic superpixel positional embedding to
strengthen MLLM's awareness of superpixel geometry and position, alongside a
semantic superpixel aggregator to preserve both fine-grained details inside
superpixels and global context outside. Experiments show that our method cuts
visual tokens by 93% without compromising performance, notably speeding up MLLM
training and inference, and outperforming existing compressive visual
projectors on RIS.

</details>


### [95] [FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras](https://arxiv.org/abs/2509.13681)
*Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li*

Main category: cs.CV

TL;DR: FishBEV是一个专门为鱼眼相机设计的BEV分割框架，通过三个创新模块解决了鱼眼相机在BEV分割中的几何畸变、多视角对应模糊和时间动态不稳定等问题，在Synwoodscapes数据集上超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有的BEV分割方法主要针对针孔相机设计，难以直接应用于存在严重几何畸变、多视角对应关系模糊和时间动态不稳定的鱼眼相机，这些因素显著降低了BEV分割性能。

Method: 提出了FishBEV框架，包含三个核心模块：1) 抗畸变多尺度提取(DRME)主干网络，在畸变下学习鲁棒特征并保持尺度一致性；2) 不确定性感知空间交叉注意力(U-SCA)机制，利用不确定性估计实现可靠的跨视角对齐；3) 距离感知时间自注意力(D-TSA)模块，自适应平衡近场细节和远场上下文以确保时间一致性。

Result: 在Synwoodscapes数据集上的大量实验表明，FishBEV在环视鱼眼BEV分割任务上持续优于现有的最先进基线方法。

Conclusion: FishBEV通过专门针对鱼眼相机特性设计的三个互补创新模块，有效解决了鱼眼相机BEV分割中的关键挑战，显著提升了分割性能。

Abstract: As a cornerstone technique for autonomous driving, Bird's Eye View (BEV)
segmentation has recently achieved remarkable progress with pinhole cameras.
However, it is non-trivial to extend the existing methods to fisheye cameras
with severe geometric distortion, ambiguous multi-view correspondences and
unstable temporal dynamics, all of which significantly degrade BEV performance.
To address these challenges, we propose FishBEV, a novel BEV segmentation
framework specifically tailored for fisheye cameras. This framework introduces
three complementary innovations, including a Distortion-Resilient Multi-scale
Extraction (DRME) backbone that learns robust features under distortion while
preserving scale consistency, an Uncertainty-aware Spatial Cross-Attention
(U-SCA) mechanism that leverages uncertainty estimation for reliable cross-view
alignment, a Distance-aware Temporal Self-Attention (D-TSA) module that
adaptively balances near field details and far field context to ensure temporal
coherence. Extensive experiments on the Synwoodscapes dataset demonstrate that
FishBEV consistently outperforms SOTA baselines, regarding the performance
evaluation of FishBEV on the surround-view fisheye BEV segmentation tasks.

</details>


### [96] [Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification](https://arxiv.org/abs/2509.13687)
*Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra*

Main category: cs.CV

TL;DR: 本文提出了三种基于械条的Kolmogorov-Arnold网络(KANs)方案，用于医学图像分类，在数据限制环境下实现了高准确率和良好的可解释性。SBTAYLOR-KAN在仅使用30%训练数据的情况下仍能保持过86%以上的准确率，且参数量仅为2872个，远少于传统CNN模型。


<details>
  <summary>Details</summary>
Motivation: 解决资源限制临床环境下医学图像分类的挑战，特别是面对有限、多样化数据集时的准确分类和模型解释性问题。

Method: 提出三种械条基KANs模型：SBTAYLOR-KAN（B械条+泰勒级数）、SBRBF-KAN（B械条+径向基函数）、SBWAVELET-KAN（B械条+Morlet小波变换）。利用械条基函数近似捕捉局部和全局非线性。在脑部MRI、胸部X光片等四个医学图像数据集上进行评估，使用Grad-CAM实现可解释性。

Result: SBTAYLOR-KAN达到了98.93%的最高准确率，在仅使用30%训练数据时仍能保持超过86%的准确率。在皮肤癌数据集上达到68.22%准确率，表现超过其他模型。模型仅需2872个可训练参数，远少于ResNet50的24.18M参数。

Conclusion: 该框架提供了一种轻量级、可解释、具有良好普适性的医学图像分类解决方案，有效应对临床AI应用中的数据限制和数据稀缺挑战。

Abstract: Effective and interpretable classification of medical images is a challenge
in computer-aided diagnosis, especially in resource-limited clinical settings.
This study introduces spline-based Kolmogorov-Arnold Networks (KANs) for
accurate medical image classification with limited, diverse datasets. The
models include SBTAYLOR-KAN, integrating B-splines with Taylor series;
SBRBF-KAN, combining B-splines with Radial Basis Functions; and SBWAVELET-KAN,
embedding B-splines in Morlet wavelet transforms. These approaches leverage
spline-based function approximation to capture both local and global
nonlinearities. The models were evaluated on brain MRI, chest X-rays,
tuberculosis X-rays, and skin lesion images without preprocessing,
demonstrating the ability to learn directly from raw data. Extensive
experiments, including cross-dataset validation and data reduction analysis,
showed strong generalization and stability. SBTAYLOR-KAN achieved up to 98.93%
accuracy, with a balanced F1-score, maintaining over 86% accuracy using only
30% of the training data across three datasets. Despite class imbalance in the
skin cancer dataset, experiments on both imbalanced and balanced versions
showed SBTAYLOR-KAN outperforming other models, achieving 68.22% accuracy.
Unlike traditional CNNs, which require millions of parameters (e.g., ResNet50
with 24.18M), SBTAYLOR-KAN achieves comparable performance with just 2,872
trainable parameters, making it more suitable for constrained medical
environments. Gradient-weighted Class Activation Mapping (Grad-CAM) was used
for interpretability, highlighting relevant regions in medical images. This
framework provides a lightweight, interpretable, and generalizable solution for
medical image classification, addressing the challenges of limited datasets and
data-scarce scenarios in clinical AI applications.

</details>


### [97] [StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models](https://arxiv.org/abs/2509.13711)
*Qiuyu Tang,Joshua Krinsky,Aparna Bharati*

Main category: cs.CV

TL;DR: 本文提出StyleProtect方法，通过选择性更新交叉注意力层来有效防御针对艺术风格的微调扩散模型模仿攻击。


<details>
  <summary>Details</summary>
Motivation: 生成模型特别是扩散模型的快速发展使得恶意使用者能够廉价复制艺术家的独特风格，这需要开发有效的艺术风格保护方法来防止风格模仿。

Method: 研究发现某些交叉注意力层对艺术风格特别敏感，基于此提出了StyleProtect方法，仅更新选定的交叉注意力层来实现轻量级风格保护。

Result: 实验使用基于WikiArt的30位艺术家作品数据集和Anita动画数据集，证明该方法能有效保护艺术作品和动漫的独特风格，同时保持较好的不可感知性。

Conclusion: StyleProtect提供了一种高效轻量的解决方案，能够有效防御微调扩散模型的风格模仿攻击，为艺术创作提供了实用的保护机制。

Abstract: The rapid advancement of generative models, particularly diffusion-based
approaches, has inadvertently facilitated their potential for misuse. Such
models enable malicious exploiters to replicate artistic styles that capture an
artist's creative labor, personal vision, and years of dedication in an
inexpensive manner. This has led to a rise in the need and exploration of
methods for protecting artworks against style mimicry. Although generic
diffusion models can easily mimic an artistic style, finetuning amplifies this
capability, enabling the model to internalize and reproduce the style with
higher fidelity and control. We hypothesize that certain cross-attention layers
exhibit heightened sensitivity to artistic styles. Sensitivity is measured
through activation strengths of attention layers in response to style and
content representations, and assessing their correlations with features
extracted from external models. Based on our findings, we introduce an
efficient and lightweight protection strategy, StyleProtect, that achieves
effective style defense against fine-tuned diffusion models by updating only
selected cross-attention layers. Our experiments utilize a carefully curated
artwork dataset based on WikiArt, comprising representative works from 30
artists known for their distinctive and influential styles and cartoon
animations from the Anita dataset. The proposed method demonstrates promising
performance in safeguarding unique styles of artworks and anime from malicious
diffusion customization, while maintaining competitive imperceptibility.

</details>


### [98] [UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry](https://arxiv.org/abs/2509.13713)
*Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn*

Main category: cs.CV

TL;DR: UM-Depth是一个自监督单目深度估计框架，通过运动感知和不确定性感知的细化方法，在动态物体边界和纹理缺失区域提高深度估计精度，无需额外标签或推理时开销。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督单目深度估计方法在低纹理或动态区域存在不确定性，导致深度精度下降，需要一种能够有效处理这些挑战的方法。

Method: 采用师生训练策略，将不确定性估计嵌入训练流程和网络架构，仅在教师网络训练时使用光流，避免额外标签需求和运行时成本。

Result: 在KITTI和Cityscapes数据集上的广泛实验表明，该方法在自监督深度和姿态估计方面达到了最先进的性能。

Conclusion: UM-Depth通过不确定性感知的细化有效提升了深度估计精度，特别是在具有挑战性的场景区域，且无需推理时额外开销。

Abstract: Monocular depth estimation has been increasingly adopted in robotics and
autonomous driving for its ability to infer scene geometry from a single
camera. In self-supervised monocular depth estimation frameworks, the network
jointly generates and exploits depth and pose estimates during training,
thereby eliminating the need for depth labels. However, these methods remain
challenged by uncertainty in the input data, such as low-texture or dynamic
regions, which can cause reduced depth accuracy. To address this, we introduce
UM-Depth, a framework that combines motion- and uncertainty-aware refinement to
enhance depth accuracy at dynamic object boundaries and in textureless regions.
Specifically, we develop a teacherstudent training strategy that embeds
uncertainty estimation into both the training pipeline and network
architecture, thereby strengthening supervision where photometric signals are
weak. Unlike prior motion-aware approaches that incur inference-time overhead
and rely on additional labels or auxiliary networks for real-time generation,
our method uses optical flow exclusively within the teacher network during
training, which eliminating extra labeling demands and any runtime cost.
Extensive experiments on the KITTI and Cityscapes datasets demonstrate the
effectiveness of our uncertainty-aware refinement. Overall, UM-Depth achieves
state-of-the-art results in both self-supervised depth and pose estimation on
the KITTI datasets.

</details>


### [99] [Mitigating Query Selection Bias in Referring Video Object Segmentation](https://arxiv.org/abs/2509.13722)
*Dingwei Zhang,Dong Zhang,Jinhui Tang*

Main category: cs.CV

TL;DR: TQF通过将引用查询分解为外观、帧内交互和帧间运动三个专门化组件，结合语言线索和视觉引导动态构建查询，解决了RVOS中静态查询容易被相似干扰物误导的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查询的RVOS方法使用静态文本查询进行跨模态对齐，但容易被外观或运动相似的干扰物误导，导致查询选择偏差问题。

Method: 提出Triple Query Former (TQF)，将引用查询分解为三个专门组件：外观查询（静态属性）、帧内交互查询（空间关系）和帧间运动查询（时间关联）。查询通过整合语言线索和视觉引导动态构建，并引入两个运动感知聚合模块增强对象标记表示。

Result: 在多个RVOS基准测试上的广泛实验证明了TQF的优势以及结构化查询设计和运动感知聚合模块的有效性。

Conclusion: TQF通过分解查询和引入运动感知机制，有效解决了RVOS中的查询选择偏差问题，提升了跨模态对齐的性能。

Abstract: Recently, query-based methods have achieved remarkable performance in
Referring Video Object Segmentation (RVOS) by using textual static object
queries to drive cross-modal alignment. However, these static queries are
easily misled by distractors with similar appearance or motion, resulting in
\emph{query selection bias}. To address this issue, we propose Triple Query
Former (TQF), which factorizes the referring query into three specialized
components: an appearance query for static attributes, an intra-frame
interaction query for spatial relations, and an inter-frame motion query for
temporal association. Instead of relying solely on textual embeddings, our
queries are dynamically constructed by integrating both linguistic cues and
visual guidance. Furthermore, we introduce two motion-aware aggregation modules
that enhance object token representations: Intra-frame Interaction Aggregation
incorporates position-aware interactions among objects within a single frame,
while Inter-frame Motion Aggregation leverages trajectory-guided alignment
across frames to ensure temporal coherence. Extensive experiments on multiple
RVOS benchmarks demonstrate the advantages of TQF and the effectiveness of our
structured query design and motion-aware aggregation modules.

</details>


### [100] [Improving Generalized Visual Grounding with Instance-aware Joint Learning](https://arxiv.org/abs/2509.13747)
*Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang*

Main category: cs.CV

TL;DR: InstanceVG是一个多任务通用视觉定位框架，首次同时处理GREC和GRES任务，通过实例查询统一实例级边界框和掩码的联合一致性预测，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将GREC和GRES任务独立处理，忽视了联合训练的优势，且将GRES视为语义分割任务，忽略了实例感知能力和实例级边界框与掩码一致性预测的重要性。

Method: 提出InstanceVG框架，使用实例查询统一实例级边界框和掩码的联合一致性预测，为每个实例查询分配先验参考点，促进同一实例的点、边界框和掩码的一致性预测。

Result: 在10个数据集上的4个任务实验表明，InstanceVG在各项评估指标上显著超越现有方法，达到最先进性能。

Conclusion: InstanceVG是第一个同时处理GREC和GRES任务并融入实例感知能力的通用视觉定位框架，通过统一的多粒度一致性预测取得了优异性能。

Abstract: Generalized visual grounding tasks, including Generalized Referring
Expression Comprehension (GREC) and Segmentation (GRES), extend the classical
visual grounding paradigm by accommodating multi-target and non-target
scenarios. Specifically, GREC focuses on accurately identifying all referential
objects at the coarse bounding box level, while GRES aims for achieve
fine-grained pixel-level perception. However, existing approaches typically
treat these tasks independently, overlooking the benefits of jointly training
GREC and GRES to ensure consistent multi-granularity predictions and streamline
the overall process. Moreover, current methods often treat GRES as a semantic
segmentation task, neglecting the crucial role of instance-aware capabilities
and the necessity of ensuring consistent predictions between instance-level
boxes and masks. To address these limitations, we propose InstanceVG, a
multi-task generalized visual grounding framework equipped with instance-aware
capabilities, which leverages instance queries to unify the joint and
consistency predictions of instance-level boxes and masks. To the best of our
knowledge, InstanceVG is the first framework to simultaneously tackle both GREC
and GRES while incorporating instance-aware capabilities into generalized
visual grounding. To instantiate the framework, we assign each instance query a
prior reference point, which also serves as an additional basis for target
matching. This design facilitates consistent predictions of points, boxes, and
masks for the same instance. Extensive experiments obtained on ten datasets
across four tasks demonstrate that InstanceVG achieves state-of-the-art
performance, significantly surpassing the existing methods in various
evaluation metrics. The code and model will be publicly available at
https://github.com/Dmmm1997/InstanceVG.

</details>


### [101] [Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval](https://arxiv.org/abs/2509.13754)
*Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen*

Main category: cs.CV

TL;DR: FMFA框架通过显式细粒度对齐和自适应相似度分布匹配，解决了文本-图像行人检索中的跨模态对齐问题，在三个公开数据集上达到了最先进的性能


<details>
  <summary>Details</summary>
Motivation: 解决现有方法缺乏验证局部特征是否正确对齐的能力，以及主要关注困难负样本而忽视错误匹配正样本对的问题

Method: 提出全模式细粒度对齐框架(FMFA)，包含自适应相似度分布匹配(A-SDM)模块来修正未匹配正样本对，以及显式细粒度对齐(EFA)模块通过稀疏化相似度矩阵和硬编码方法加强局部对齐

Result: 在三个公开数据集上实现了所有全局匹配方法中的最先进性能

Conclusion: FMFA框架通过显式和隐式对齐相结合的方式，有效提升了跨模态行人检索的性能，无需额外监督

Abstract: Text-to-Image Person Retrieval (TIPR) is a cross-modal matching task that
aims to retrieve the most relevant person images based on a given text query.
The key challenge in TIPR lies in achieving effective alignment between textual
and visual modalities within a common latent space. To address this challenge,
prior approaches incorporate attention mechanisms for implicit cross-modal
local alignment. However, they lack the ability to verify whether all local
features are correctly aligned. Moreover, existing methods primarily focus on
hard negative samples during model updates, with the goal of refining
distinctions between positive and negative pairs, often neglecting incorrectly
matched positive pairs. To alleviate these issues, we propose FMFA, a
cross-modal Full-Mode Fine-grained Alignment framework, which enhances global
matching through explicit fine-grained alignment and existing implicit
relational reasoning -- hence the term ``full-mode" -- without requiring
additional supervision. Specifically, we design an Adaptive Similarity
Distribution Matching (A-SDM) module to rectify unmatched positive sample
pairs. A-SDM adaptively pulls the unmatched positive pairs closer in the joint
embedding space, thereby achieving more precise global alignment. Additionally,
we introduce an Explicit Fine-grained Alignment (EFA) module, which makes up
for the lack of verification capability of implicit relational reasoning. EFA
strengthens explicit cross-modal fine-grained interactions by sparsifying the
similarity matrix and employs a hard coding method for local alignment. Our
proposed method is evaluated on three public datasets, achieving
state-of-the-art performance among all global matching methods. Our code is
available at https://github.com/yinhao1102/FMFA.

</details>


### [102] [Controllable-Continuous Color Editing in Diffusion Model via Color Mapping](https://arxiv.org/abs/2509.13756)
*Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo*

Main category: cs.CV

TL;DR: 通过颜色映射模块建立文本嵌入空间与图像RGB值的明确对应关系，实现了精确、连续可控的文本驱动图像颜色编辑


<details>
  <summary>Details</summary>
Motivation: 解决文本驱动图像编辑中因自然语言模糊性导致的颜色控制精度不足、连续性差的问题，以及嵌入向量插值方法中颜色变化范围与控制关系不明确的缺陷

Method: 设计了颜色映射模块，明确建模文本嵌入空间与图像RGB值之间的对应关系，能够根据指定的RGB值预测对应的嵌入向量，从而实现精确的颜色控制

Result: 实验结果表明方法在颜色连续性和可控制性方面表现良好，能够在保持语义一致性的同时实现细粒度的连续颜色编辑

Conclusion: 该方法有效解决了文本驱动图像颜色编辑的精确性和连续性问题，通过明确的颜色映射模型实现了更精细的可控颜色编辑能力

Abstract: In recent years, text-driven image editing has made significant progress.
However, due to the inherent ambiguity and discreteness of natural language,
color editing still faces challenges such as insufficient precision and
difficulty in achieving continuous control. Although linearly interpolating the
embedding vectors of different textual descriptions can guide the model to
generate a sequence of images with varying colors, this approach lacks precise
control over the range of color changes in the output images. Moreover, the
relationship between the interpolation coefficient and the resulting image
color is unknown and uncontrollable. To address these issues, we introduce a
color mapping module that explicitly models the correspondence between the text
embedding space and image RGB values. This module predicts the corresponding
embedding vector based on a given RGB value, enabling precise color control of
the generated images while maintaining semantic consistency. Users can specify
a target RGB range to generate images with continuous color variations within
the desired range, thereby achieving finer-grained, continuous, and
controllable color editing. Experimental results demonstrate that our method
performs well in terms of color continuity and controllability.

</details>


### [103] [Iterative Prompt Refinement for Safer Text-to-Image Generation](https://arxiv.org/abs/2509.13760)
*Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 通过视觉语言模型迭代精炼提示，在保持用户意图的同时提高文本到图像生成的安全性


<details>
  <summary>Details</summary>
Motivation: 现有的安全方法仅依靠大语言模型精炼提示，忽视了生成图像的安全性，导致不安全输出或对安全提示的不必要修改

Method: 提出迭代提示精炼算法，利用视觉语言模型分析输入提示和生成图像，通过视觉反馈有效精炼提示

Result: 实验结果显示该方法能够生成更安全的输出，同时保持与用户意图的对齐性

Conclusion: 提供了一种生成更安全文本到图像内容的实用解决方案，并开源了代码

Abstract: Text-to-Image (T2I) models have made remarkable progress in generating images
from text prompts, but their output quality and safety still depend heavily on
how prompts are phrased. Existing safety methods typically refine prompts using
large language models (LLMs), but they overlook the images produced, which can
result in unsafe outputs or unnecessary changes to already safe prompts. To
address this, we propose an iterative prompt refinement algorithm that uses
Vision Language Models (VLMs) to analyze both the input prompts and the
generated images. By leveraging visual feedback, our method refines prompts
more effectively, improving safety while maintaining user intent and
reliability comparable to existing LLM-based approaches. Additionally, we
introduce a new dataset labeled with both textual and visual safety signals
using off-the-shelf multi-modal LLM, enabling supervised fine-tuning.
Experimental results demonstrate that our approach produces safer outputs
without compromising alignment with user intent, offering a practical solution
for generating safer T2I content. Our code is available at
https://github.com/ku-dmlab/IPR. \textbf{\textcolor{red}WARNING: This paper
contains examples of harmful or inappropriate images generated by models.

</details>


### [104] [Task-Aware Image Signal Processor for Advanced Visual Perception](https://arxiv.org/abs/2509.13762)
*Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu*

Main category: cs.CV

TL;DR: 提出TA-ISP框架，通过轻量级多尺度调制算子替代传统密集卷积ISP网络，在减少计算开销的同时提升RAW数据视觉感知任务的性能


<details>
  <summary>Details</summary>
Motivation: 现有RAW数据处理方法存在两大局限：大规模ISP网络计算开销大，传统ISP调优方法表示能力有限，需要一种既能保持计算效率又能提升感知任务性能的新方法

Method: 设计Task-Aware ISP框架，预测一组轻量级多尺度调制算子，在全局、区域和像素尺度上重塑图像统计信息，实现空间变化的变换表示

Result: 在多个RAW域检测和分割基准测试中，TA-ISP在白天和夜间条件下均能持续提升下游任务精度，同时显著减少参数数量和推理时间

Conclusion: TA-ISP适合在资源受限设备上部署，通过因子化控制扩展了空间变换表示范围，同时严格控制内存使用、计算量和延迟

Abstract: In recent years, there has been a growing trend in computer vision towards
exploiting RAW sensor data, which preserves richer information compared to
conventional low-bit RGB images. Early studies mainly focused on enhancing
visual quality, while more recent efforts aim to leverage the abundant
information in RAW data to improve the performance of visual perception tasks
such as object detection and segmentation. However, existing approaches still
face two key limitations: large-scale ISP networks impose heavy computational
overhead, while methods based on tuning traditional ISP pipelines are
restricted by limited representational capacity.To address these issues, we
propose Task-Aware Image Signal Processing (TA-ISP), a compact RAW-to-RGB
framework that produces task-oriented representations for pretrained vision
models. Instead of heavy dense convolutional pipelines, TA-ISP predicts a small
set of lightweight, multi-scale modulation operators that act at global,
regional, and pixel scales to reshape image statistics across different spatial
extents. This factorized control significantly expands the range of spatially
varying transforms that can be represented while keeping memory usage,
computation, and latency tightly constrained. Evaluated on several RAW-domain
detection and segmentation benchmarks under both daytime and nighttime
conditions, TA-ISP consistently improves downstream accuracy while markedly
reducing parameter count and inference time, making it well suited for
deployment on resource-constrained devices.

</details>


### [105] [NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset](https://arxiv.org/abs/2509.13766)
*Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan*

Main category: cs.CV

TL;DR: 提出NDLPNet网络，通过位置感知模块有效处理夜间低光条件下的雨纹去除问题，在保持背景信息的同时显著提升去雨效果


<details>
  <summary>Details</summary>
Motivation: 现有图像去雨技术主要针对白天条件设计，在夜间光照下表现不佳，因为雨纹分布的空间异质性和光线依赖的条纹可见性影响

Method: 提出夜间去雨位置增强感知网络(NDLPNet)，包含位置感知模块(PPM)来捕获空间上下文信息，识别并重新校准不同特征通道的重要性

Result: 在现有数据集和新构建的NSR数据集上，定性和定量实验均表明该方法在夜间去雨任务中优于最先进方法

Conclusion: NDLPNet能有效去除夜间雨纹并保留关键背景信息，新构建的NSR数据集为夜间去雨研究提供了新基准

Abstract: Visual degradation caused by rain streak artifacts in low-light conditions
significantly hampers the performance of nighttime surveillance and autonomous
navigation. Existing image deraining techniques are primarily designed for
daytime conditions and perform poorly under nighttime illumination due to the
spatial heterogeneity of rain distribution and the impact of light-dependent
stripe visibility. In this paper, we propose a novel Nighttime Deraining
Location-enhanced Perceptual Network(NDLPNet) that effectively captures the
spatial positional information and density distribution of rain streaks in
low-light environments. Specifically, we introduce a Position Perception Module
(PPM) to capture and leverage spatial contextual information from input data,
enhancing the model's capability to identify and recalibrate the importance of
different feature channels. The proposed nighttime deraining network can
effectively remove the rain streaks as well as preserve the crucial background
information. Furthermore, We construct a night scene rainy (NSR) dataset
comprising 900 image pairs, all based on real-world nighttime scenes, providing
a new benchmark for nighttime deraining task research. Extensive qualitative
and quantitative experimental evaluations on both existing datasets and the NSR
dataset consistently demonstrate our method outperform the state-of-the-art
(SOTA) methods in nighttime deraining tasks. The source code and dataset is
available at https://github.com/Feecuin/NDLPNet.

</details>


### [106] [VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI](https://arxiv.org/abs/2509.13767)
*Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro*

Main category: cs.CV

TL;DR: VocSegMRI是一个多模态框架，整合视频、音频和语音学输入，通过跨注意力融合和对比学习提升实时MRI中发音结构分割的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，但同步的声学和语音学信号能提供互补上下文信息，丰富视觉信息并提高分割精度。

Method: 提出VocSegMRI多模态框架，通过跨注意力融合实现动态特征对齐，并引入对比学习目标来增强跨模态表示，即使在推理时音频模态不可用也能提升性能。

Result: 在USC-75 rtMRI数据集子集上达到最先进性能：Dice分数0.95，95% Hausdorff距离4.20mm，优于单模态和多模态基线。消融研究证实了跨注意力和对比学习的贡献。

Conclusion: 集成多模态建模对准确声道分析具有重要价值，跨模态融合和对比学习能显著提升分割精度和鲁棒性。

Abstract: Accurately segmenting articulatory structures in real-time magnetic resonance
imaging (rtMRI) remains challenging, as most existing methods rely almost
entirely on visual cues. Yet synchronized acoustic and phonological signals
provide complementary context that can enrich visual information and improve
precision. In this paper, we introduce VocSegMRI, a multimodal framework that
integrates video, audio, and phonological inputs through cross-attention fusion
for dynamic feature alignment. To further enhance cross-modal representation,
we incorporate a contrastive learning objective that improves segmentation
performance even when the audio modality is unavailable at inference. Evaluated
on a sub-set of USC-75 rtMRI dataset, our approach achieves state-of-the-art
performance, with a Dice score of 0.95 and a 95th percentile Hausdorff Distance
(HD_95) of 4.20 mm, outperforming both unimodal and multimodal baselines.
Ablation studies confirm the contributions of cross-attention and contrastive
learning to segmentation precision and robustness. These results highlight the
value of integrative multimodal modeling for accurate vocal tract analysis.

</details>


### [107] [Generative Image Coding with Diffusion Prior](https://arxiv.org/abs/2509.13768)
*Jianhui Chang*

Main category: cs.CV

TL;DR: 一种基于沉积模型的生成式图像压缩框架，通过利用预训练模型和轻量化适配器，在低码率下显著提升视觉质量和压缩效果


<details>
  <summary>Details</summary>
Motivation: 随着生成式技术发展，视觉内容混合了自然和AI生成图像，需要更高效的编码技术来优先保证感知质量，而传统方法在高压缩比下难以维持主观质量

Method: 使用预优化编码器生成广义压缩域表示，通过轻量适配器和注意力融合模块与预训练模型内部特征集成，采用分布重新归一化方法提升重建保真度

Result: 在低码率下超过现有方法的视觉保真度，比H.266/VVC提高压缩性能至79%，为AI生成内容提供高效解决方案且适应更广泛内容类型

Conclusion: 该框架有效利用现有预训练沉积模型，通过最小的重新训练成本即可适应不同的预训练模型，为低码率图像压缩提供了高效且可扩展的解决方案

Abstract: As generative technologies advance, visual content has evolved into a complex
mix of natural and AI-generated images, driving the need for more efficient
coding techniques that prioritize perceptual quality. Traditional codecs and
learned methods struggle to maintain subjective quality at high compression
ratios, while existing generative approaches face challenges in visual fidelity
and generalization. To this end, we propose a novel generative coding framework
leveraging diffusion priors to enhance compression performance at low bitrates.
Our approach employs a pre-optimized encoder to generate generalized
compressed-domain representations, integrated with the pretrained model's
internal features via a lightweight adapter and an attentive fusion module.
This framework effectively leverages existing pretrained diffusion models and
enables efficient adaptation to different pretrained models for new
requirements with minimal retraining costs. We also introduce a distribution
renormalization method to further enhance reconstruction fidelity. Extensive
experiments show that our method (1) outperforms existing methods in visual
fidelity across low bitrates, (2) improves compression performance by up to 79%
over H.266/VVC, and (3) offers an efficient solution for AI-generated content
while being adaptable to broader content types.

</details>


### [108] [AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2509.13769)
*Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang*

Main category: cs.CV

TL;DR: AdaThinkDrive是一个创新的视觉语言动作框架，采用双模式推理机制（快速回答和慢速思考），通过自适应推理在自动驾驶中平衡准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain of Thought推理技术在简单场景中表现不佳，引入不必要的计算开销而无法提升决策质量，需要一种能够区分场景并自适应选择推理模式的方法。

Method: 1) 在大规模自动驾驶场景上进行预训练，获取世界知识和驾驶常识；2) 监督微调时引入双模式数据集（无CoT的快速回答和有CoT的慢速思考）；3) 提出自适应思考奖励策略结合GRPO，通过比较不同推理模式的轨迹质量来奖励模型选择性应用CoT。

Result: 在Navsim基准测试中达到90.3的PDMS分数，比最佳纯视觉基线高1.7分；相比始终思考基线减少14%推理时间；比从不思考和始终思考基线分别提升2.0和1.4个PDMS分数。

Conclusion: AdaThinkDrive通过自适应推理机制成功平衡了自动驾驶中的准确性和效率，证明了双模式推理在VLA模型中的有效性。

Abstract: While reasoning technology like Chain of Thought (CoT) has been widely
adopted in Vision Language Action (VLA) models, it demonstrates promising
capabilities in end to end autonomous driving. However, recent efforts to
integrate CoT reasoning often fall short in simple scenarios, introducing
unnecessary computational overhead without improving decision quality. To
address this, we propose AdaThinkDrive, a novel VLA framework with a dual mode
reasoning mechanism inspired by fast and slow thinking. First, our framework is
pretrained on large scale autonomous driving (AD) scenarios using both question
answering (QA) and trajectory datasets to acquire world knowledge and driving
commonsense. During supervised fine tuning (SFT), we introduce a two mode
dataset, fast answering (w/o CoT) and slow thinking (with CoT), enabling the
model to distinguish between scenarios that require reasoning. Furthermore, an
Adaptive Think Reward strategy is proposed in conjunction with the Group
Relative Policy Optimization (GRPO), which rewards the model for selectively
applying CoT by comparing trajectory quality across different reasoning modes.
Extensive experiments on the Navsim benchmark show that AdaThinkDrive achieves
a PDMS of 90.3, surpassing the best vision only baseline by 1.7 points.
Moreover, ablations show that AdaThinkDrive surpasses both the never Think and
always Think baselines, improving PDMS by 2.0 and 1.4, respectively. It also
reduces inference time by 14% compared to the always Think baseline,
demonstrating its ability to balance accuracy and efficiency through adaptive
reasoning.

</details>


### [109] [Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization](https://arxiv.org/abs/2509.13776)
*Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren*

Main category: cs.CV

TL;DR: 通过局部和全局双视角独立预测伪造区域，采用形态学操作融合预测结果，提高伪造区域定位的准确性和稳健性


<details>
  <summary>Details</summary>
Motivation: 虽然深度伪造检测的准确性不断提升，但准确定位伪造区域仍是重大挑战。现有方法忽视了局部细节与全局语义上下文的互补性，且融合策略有在强化噪声和错误的问题

Method: 提出一种新方法，独立使用局部和全局视角预测伪造区域，然后采用形态学操作融合两者输出，有效压制噪声并增强空间一致性

Result: 大量实验证明了每个模块在提高伪造定位准确性和稳健性方面的有效性

Conclusion: 该方法通过双视角独立预测和形态学融合策略，有效解决了伪造区域定位中的噪声和不一致性问题，显著提升了定位性能

Abstract: While the pursuit of higher accuracy in deepfake detection remains a central
goal, there is an increasing demand for precise localization of manipulated
regions. Despite the remarkable progress made in classification-based
detection, accurately localizing forged areas remains a significant challenge.
A common strategy is to incorporate forged region annotations during model
training alongside manipulated images. However, such approaches often neglect
the complementary nature of local detail and global semantic context, resulting
in suboptimal localization performance. Moreover, an often-overlooked aspect is
the fusion strategy between local and global predictions. Naively combining the
outputs from both branches can amplify noise and errors, thereby undermining
the effectiveness of the localization.
  To address these issues, we propose a novel approach that independently
predicts manipulated regions using both local and global perspectives. We
employ morphological operations to fuse the outputs, effectively suppressing
noise while enhancing spatial coherence. Extensive experiments reveal the
effectiveness of each module in improving the accuracy and robustness of
forgery localization.

</details>


### [110] [Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models](https://arxiv.org/abs/2509.13836)
*Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao*

Main category: cs.CV

TL;DR: 本文提出了VHBench-10基准测试和VisionWeaver方法，系统分析不同视觉编码器的幻觉特性，并通过动态路由机制显著减少大视觉语言模型的物体幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型中的物体幻觉问题严重阻碍了其实际应用，不同视觉编码器由于训练范式不同而具有不同的归纳偏置，导致幻觉表现差异，但现有基准测试无法捕捉这种细粒度差异。

Method: 提出VHBench-10基准测试（约10,000样本，10个细粒度幻觉类别）系统评估不同编码器；设计VisionWeaver - 基于全局视觉特征生成路由信号的上下文感知路由网络，动态聚合多个专家视觉特征。

Result: 评估证实不同编码器具有独特的幻觉特征；VisionWeaver能显著减少幻觉并提升整体模型性能。

Conclusion: 视觉编码器的选择对减少物体幻觉至关重要，VisionWeaver通过动态特征聚合有效解决了简单特征融合的次优问题，为LVLMs的实际应用提供了重要改进。

Abstract: Object hallucination in Large Vision-Language Models (LVLMs) significantly
impedes their real-world applicability. As the primary component for accurately
interpreting visual information, the choice of visual encoder is pivotal. We
hypothesize that the diverse training paradigms employed by different visual
encoders instill them with distinct inductive biases, which leads to their
diverse hallucination performances. Existing benchmarks typically focus on
coarse-grained hallucination detection and fail to capture the diverse
hallucinations elaborated in our hypothesis. To systematically analyze these
effects, we introduce VHBench-10, a comprehensive benchmark with approximately
10,000 samples for evaluating LVLMs across ten fine-grained hallucination
categories. Our evaluations confirm encoders exhibit unique hallucination
characteristics. Building on these insights and the suboptimality of simple
feature fusion, we propose VisionWeaver, a novel Context-Aware Routing Network.
It employs global visual features to generate routing signals, dynamically
aggregating visual features from multiple specialized experts. Comprehensive
experiments confirm the effectiveness of VisionWeaver in significantly reducing
hallucinations and improving overall model performance.

</details>


### [111] [CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling](https://arxiv.org/abs/2509.13784)
*Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan*

Main category: cs.CV

TL;DR: 基于Mamba状态空间模型的变速率空间事件处理方法，直接处理原始事件流，避免中间表示引入的窗口延迟，实现低延迟高效的实时事件处理。


<details>
  <summary>Details</summary>
Motivation: 现有事件监控方法需要将事件流转换为帧、立方体网格或点云等中间表示，这会引入预定义时间窗口延迟；而点级检测方法计算成本高，无法实现实时效率。

Method: 提出Variable-Rate Spatial Event Mamba架构，直接处理原始事件流；使用轻量级因果空间邻域编码器捐捕局部几何关系；基于Mamba状态空间模型进行线性复杂度的可扩展时间建模；通过控制器根据事件率自适应调整处理速度。

Result: 方法能够在避免窗口延迟的同时，实现低计算成本和高效率的事件处理，达到窗口延迟与推理延迟之间的最佳平衡。

Conclusion: 该方法为高速视觉任务提供了一种无窗口延迟、计算高效的新型事件处理方案，充分利用事件监控器的微秒级时间分辨率优势。

Abstract: Event cameras capture asynchronous pixel-level brightness changes with
microsecond temporal resolution, offering unique advantages for high-speed
vision tasks. Existing methods often convert event streams into intermediate
representations such as frames, voxel grids, or point clouds, which inevitably
require predefined time windows and thus introduce window latency. Meanwhile,
pointwise detection methods face computational challenges that prevent
real-time efficiency due to their high computational cost. To overcome these
limitations, we propose the Variable-Rate Spatial Event Mamba, a novel
architecture that directly processes raw event streams without intermediate
representations. Our method introduces a lightweight causal spatial
neighborhood encoder to efficiently capture local geometric relations, followed
by Mamba-based state space models for scalable temporal modeling with linear
complexity. During inference, a controller adaptively adjusts the processing
speed according to the event rate, achieving an optimal balance between window
latency and inference latency.

</details>


### [112] [BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching](https://arxiv.org/abs/2509.13789)
*Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia*

Main category: cs.CV

TL;DR: BWCache是一种无需训练的加速方法，通过动态缓存和重用DiT块特征来减少扩散变换器视频生成的计算冗余，实现2.24倍加速且保持视觉质量


<details>
  <summary>Details</summary>
Motivation: 现有扩散变换器(DiT)的顺序去噪过程导致不可避免的延迟，限制了实际应用。现有加速方法要么因架构修改而损害视觉质量，要么无法在适当粒度上重用中间特征

Method: 提出Block-Wise Caching (BWCache)方法：1) 分析发现DiT块是推理延迟的主要贡献者，特征变化呈U形模式；2) 在扩散时间步间动态缓存和重用DiT块特征；3) 引入相似性指示器，仅在相邻时间步块特征差异低于阈值时触发特征重用

Result: 在多个视频扩散模型上的广泛实验表明，BWCache实现了高达2.24倍的加速，同时保持可比的视觉质量

Conclusion: BWCache是一种有效的训练免费加速方法，通过智能特征重用显著减少DiT视频生成的计算冗余，在保持视觉保真度的同时大幅提升推理速度

Abstract: Recent advancements in Diffusion Transformers (DiTs) have established them as
the state-of-the-art method for video generation. However, their inherently
sequential denoising process results in inevitable latency, limiting real-world
applicability. Existing acceleration methods either compromise visual quality
due to architectural modifications or fail to reuse intermediate features at
proper granularity. Our analysis reveals that DiT blocks are the primary
contributors to inference latency. Across diffusion timesteps, the feature
variations of DiT blocks exhibit a U-shaped pattern with high similarity during
intermediate timesteps, which suggests substantial computational redundancy. In
this paper, we propose Block-Wise Caching (BWCache), a training-free method to
accelerate DiT-based video generation. BWCache dynamically caches and reuses
features from DiT blocks across diffusion timesteps. Furthermore, we introduce
a similarity indicator that triggers feature reuse only when the differences
between block features at adjacent timesteps fall below a threshold, thereby
minimizing redundant computations while maintaining visual fidelity. Extensive
experiments on several video diffusion models demonstrate that BWCache achieves
up to 2.24$\times$ speedup with comparable visual quality.

</details>


### [113] [Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation](https://arxiv.org/abs/2509.13792)
*Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 首个专门为宇航器姿态估计关键点回归设计的监督域适应框架，通过联合优化域不变表征和任务风险，在少量标签真实数据下就能达到比较大量标签数据更好的性能


<details>
  <summary>Details</summary>
Motivation: 解决宇航器姿态估计中合成数据到真实数据的域差距问题，尤其是当有限量标签真实数据可用时，现有无监督域适应方法表现不佳

Method: 基于LIRR范式，联合优化域不变表征和任务特定风险，同时利用标签合成数据和限量标签真实数据

Result: 在SPEED+基准测试中持续超过了源基线、微调和oracle基线。仅用5%标签目标数据就能达到或超过使用更大比例标签数据的oracle性能

Conclusion: 该框架轻量、不依赖于特定网络构造、计算高效，为实际部署提供了可行路径，能够实现稳健可靠的宇航器姿态估计

Abstract: Spacecraft Pose Estimation (SPE) is a fundamental capability for autonomous
space operations such as rendezvous, docking, and in-orbit servicing. Hybrid
pipelines that combine object detection, keypoint regression, and
Perspective-n-Point (PnP) solvers have recently achieved strong results on
synthetic datasets, yet their performance deteriorates sharply on real or
lab-generated imagery due to the persistent synthetic-to-real domain gap.
Existing unsupervised domain adaptation approaches aim to mitigate this issue
but often underperform when a modest number of labeled target samples are
available. In this work, we propose the first Supervised Domain Adaptation
(SDA) framework tailored for SPE keypoint regression. Building on the Learning
Invariant Representation and Risk (LIRR) paradigm, our method jointly optimizes
domain-invariant representations and task-specific risk using both labeled
synthetic and limited labeled real data, thereby reducing generalization error
under domain shift. Extensive experiments on the SPEED+ benchmark demonstrate
that our approach consistently outperforms source-only, fine-tuning, and oracle
baselines. Notably, with only 5% labeled target data, our method matches or
surpasses oracle performance trained on larger fractions of labeled data. The
framework is lightweight, backbone-agnostic, and computationally efficient,
offering a practical pathway toward robust and deployable spacecraft pose
estimation in real-world space environments.

</details>


### [114] [SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments](https://arxiv.org/abs/2509.13795)
*Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao*

Main category: cs.CV

TL;DR: 提出SWA-PF方法，结合语义加权和粒子滤波，在GNSS拒止环境下实现无人机快速定位，定位误差低于10米，计算效率提升10倍


<details>
  <summary>Details</summary>
Motivation: 现有基于检索的无人机视觉定位方法存在数据集不足、实时性能不佳、环境敏感性强和泛化能力有限等问题，特别是在动态或时变环境中

Method: 提出大规模多高度飞行段数据集(MAFS)和语义加权自适应粒子滤波(SWA-PF)方法，整合无人机图像和卫星图像的语义特征，包含语义加权机制和优化的粒子滤波架构

Result: 在自建数据集上评估，计算效率比特征提取方法提升10倍，全局定位误差低于10米，可在数秒内使用低分辨率卫星地图快速完成4自由度位姿估计

Conclusion: SWA-PF方法有效解决了无人机在GNSS拒止环境下的定位挑战，具有高效率和强鲁棒性，代码和数据集将开源

Abstract: Vision-based Unmanned Aerial Vehicle (UAV) localization systems have been
extensively investigated for Global Navigation Satellite System (GNSS)-denied
environments. However, existing retrieval-based approaches face limitations in
dataset availability and persistent challenges including suboptimal real-time
performance, environmental sensitivity, and limited generalization capability,
particularly in dynamic or temporally varying environments. To overcome these
limitations, we present a large-scale Multi-Altitude Flight Segments dataset
(MAFS) for variable altitude scenarios and propose a novel Semantic-Weighted
Adaptive Particle Filter (SWA-PF) method. This approach integrates robust
semantic features from both UAV-captured images and satellite imagery through
two key innovations: a semantic weighting mechanism and an optimized particle
filtering architecture. Evaluated using our dataset, the proposed method
achieves 10x computational efficiency gain over feature extraction methods,
maintains global positioning errors below 10 meters, and enables rapid 4 degree
of freedom (4-DoF) pose estimation within seconds using accessible
low-resolution satellite maps. Code and dataset will be available at
https://github.com/YuanJiayuuu/SWA-PF.

</details>


### [115] [Dense Video Understanding with Gated Residual Tokenization](https://arxiv.org/abs/2509.14199)
*Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu*

Main category: cs.CV

TL;DR: 该论文提出了Dense Video Understanding (DVU)方案，通过Gated Residual Tokenization (GRT)框架解决高帧率视频理解中的计算和令牌成本问题，并创建了DIVE评测标准。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型多采用低帧率采样，丢失了密集的时间信息，对于需要精确时间对齐的任务（如讲座理解）效果差。直接令牌每帧导致计算成本高和令牌冗余。

Method: 提出Gated Residual Tokenization (GRT)两阶段框架：1) 运动补偿间间隔令牌化：利用像素级运动估计跳过静态区域，实现次线性令牌增长和计算。 2) 语义场景内令牌合并：融合同一场景内静态区域的令牌，减少冗余保留动态语义。

Result: 在DIVE标准上，GRT表现超过更大的VLLM基线模型，并且随着FPS增加而继续提升性能。

Conclusion: 密集时间信息对视频理解至关重要，GRT框架能够高效地支持高帧率视频理解，为密集时间推理任务提供了可扩展的解决方案。

Abstract: High temporal resolution is essential for capturing fine-grained details in
video understanding. However, current video large language models (VLLMs) and
benchmarks mostly rely on low-frame-rate sampling, such as uniform sampling or
keyframe selection, discarding dense temporal information. This compromise
avoids the high cost of tokenizing every frame, which otherwise leads to
redundant computation and linear token growth as video length increases. While
this trade-off works for slowly changing content, it fails for tasks like
lecture comprehension, where information appears in nearly every frame and
requires precise temporal alignment. To address this gap, we introduce Dense
Video Understanding (DVU), which enables high-FPS video comprehension by
reducing both tokenization time and token overhead. Existing benchmarks are
also limited, as their QA pairs focus on coarse content changes. We therefore
propose DIVE (Dense Information Video Evaluation), the first benchmark designed
for dense temporal reasoning. To make DVU practical, we present Gated Residual
Tokenization (GRT), a two-stage framework: (1) Motion-Compensated Inter-Gated
Tokenization uses pixel-level motion estimation to skip static regions during
tokenization, achieving sub-linear growth in token count and compute. (2)
Semantic-Scene Intra-Tokenization Merging fuses tokens across static regions
within a scene, further reducing redundancy while preserving dynamic semantics.
Experiments on DIVE show that GRT outperforms larger VLLM baselines and scales
positively with FPS. These results highlight the importance of dense temporal
information and demonstrate that GRT enables efficient, scalable high-FPS video
understanding.

</details>


### [116] [Masked Feature Modeling Enhances Adaptive Segmentation](https://arxiv.org/abs/2509.13801)
*Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma*

Main category: cs.CV

TL;DR: 提出Masked Feature Modeling (MFM)作为语义分割无监督域适应的辅助任务，通过在特征空间进行掩码和重建，与分割任务目标对齐，无需修改推理架构且零测试开销。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码建模方法在无监督域适应语义分割中未被充分探索，主要由于架构不兼容和优化目标不一致。需要一种与分割任务目标对齐的辅助任务来提升特征判别性。

Method: 提出MFM方法，在特征空间进行特征掩码和重建，使用轻量级Rebuilder模块进行联合训练（推理时丢弃），利用分割解码器对重建特征进行分类，确保辅助目标与像素级预测任务紧密耦合。

Result: 在各种架构和UDA基准测试上的广泛实验表明，MFM能持续提升分割性能。

Conclusion: MFM为无监督域适应语义分割提供了一种简单、高效且可泛化的策略，通过特征空间掩码建模有效提升了模型性能。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to
transfer models from a labeled source domain to an unlabeled target domain.
While auxiliary self-supervised tasks-particularly contrastive learning-have
improved feature discriminability, masked modeling approaches remain
underexplored in this setting, largely due to architectural incompatibility and
misaligned optimization objectives. We propose Masked Feature Modeling (MFM), a
novel auxiliary task that performs feature masking and reconstruction directly
in the feature space. Unlike existing masked modeling methods that reconstruct
low-level inputs or perceptual features (e.g., HOG or visual tokens), MFM
aligns its learning target with the main segmentation task, ensuring
compatibility with standard architectures like DeepLab and DAFormer without
modifying the inference pipeline. To facilitate effective reconstruction, we
introduce a lightweight auxiliary module, Rebuilder, which is trained jointly
but discarded during inference, adding zero computational overhead at test
time. Crucially, MFM leverages the segmentation decoder to classify the
reconstructed features, tightly coupling the auxiliary objective with the
pixel-wise prediction task to avoid interference with the primary task.
Extensive experiments across various architectures and UDA benchmarks
demonstrate that MFM consistently enhances segmentation performance, offering a
simple, efficient, and generalizable strategy for unsupervised domain-adaptive
semantic segmentation.

</details>


### [117] [Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET](https://arxiv.org/abs/2509.13809)
*Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert*

Main category: cs.CV

TL;DR: 本文研究了高光谱图像像素光谱分类问题，提出使用MiniROCKET和HDC-MiniROCKET方法在训练数据有限的情况下优于当前最先进的1D-Justo-LiuNet模型。


<details>
  <summary>Details</summary>
Motivation: 虽然当前最佳方法利用空间-光谱信息，但仅基于光谱信息的分类具有模型小、训练数据需求少的优势。现有最优模型1D-Justo-LiuNet在训练数据有限时性能下降，需要寻找更稳健的解决方案。

Method: 采用MiniROCKET和HDC-MiniROCKET方法进行光谱分类，这些方法在特征提取部分没有可训练参数，通过精心设计的特征提取来应对有限训练数据的问题。

Result: MiniROCKET在有限数据场景下优于1D-Justo-LiuNet，在一般情况下性能相当，尽管参数量更多但对训练数据不足的情况更具鲁棒性。

Conclusion: MiniROCKET系列方法为解决光谱分类中训练数据有限的问题提供了有效解决方案，其无参数特征提取机制使其在数据稀缺情况下表现更佳。

Abstract: The classification of pixel spectra of hyperspectral images, i.e. spectral
classification, is used in many fields ranging from agricultural, over medical
to remote sensing applications and is currently also expanding to areas such as
autonomous driving. Even though for full hyperspectral images the
best-performing methods exploit spatial-spectral information, performing
classification solely on spectral information has its own advantages, e.g.
smaller model size and thus less data required for training. Moreover, spectral
information is complementary to spatial information and improvements on either
part can be used to improve spatial-spectral approaches in the future.
Recently, 1D-Justo-LiuNet was proposed as a particularly efficient model with
very few parameters, which currently defines the state of the art in spectral
classification. However, we show that with limited training data the model
performance deteriorates. Therefore, we investigate MiniROCKET and
HDC-MiniROCKET for spectral classification to mitigate that problem. The model
extracts well-engineered features without trainable parameters in the feature
extraction part and is therefore less vulnerable to limited training data. We
show that even though MiniROCKET has more parameters it outperforms
1D-Justo-LiuNet in limited data scenarios and is mostly on par with it in the
general case

</details>


### [118] [Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2509.13834)
*Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu*

Main category: cs.CV

TL;DR: Semi-MOE是首个用于半监督组织病理学图像分割的多任务专家混合框架，通过三个专家网络和自适应多目标损失，在低标签设置下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法在处理组织病理学图像分割时，由于腺体边界模糊和形态学误分类，难以处理噪声伪标签问题。

Method: 提出三个专家网络：主分割专家、符号距离场回归专家和边界预测专家，通过多门控伪标签模块动态聚合专家特征，并采用自适应多目标损失来平衡多个学习目标。

Result: 在GlaS和CRAG基准测试上的广泛实验表明，该方法在低标签设置下优于最先进的方法。

Conclusion: 基于专家混合的架构在推进半监督分割方面具有巨大潜力。

Abstract: Semi-supervised learning has been employed to alleviate the need for
extensive labeled data for histopathology image segmentation, but existing
methods struggle with noisy pseudo-labels due to ambiguous gland boundaries and
morphological misclassification. This paper introduces Semi-MOE, to the best of
our knowledge, the first multi-task Mixture-of-Experts framework for
semi-supervised histopathology image segmentation. Our approach leverages three
specialized expert networks: A main segmentation expert, a signed distance
field regression expert, and a boundary prediction expert, each dedicated to
capturing distinct morphological features. Subsequently, the Multi-Gating
Pseudo-labeling module dynamically aggregates expert features, enabling a
robust fuse-and-refine pseudo-labeling mechanism. Furthermore, to eliminate
manual tuning while dynamically balancing multiple learning objectives, we
propose an Adaptive Multi-Objective Loss. Extensive experiments on GlaS and
CRAG benchmarks show that our method outperforms state-of-the-art approaches in
low-label settings, highlighting the potential of MoE-based architectures in
advancing semi-supervised segmentation. Our code is available at
https://github.com/vnlvi2k3/Semi-MoE.

</details>


### [119] [Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation](https://arxiv.org/abs/2509.13846)
*Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink*

Main category: cs.CV

TL;DR: 本文挑战了表示学习中无相关视图足以学习有意义的表示这一假设，提出了一种显式对齐不同视图表示的方法，在自监督学习中取得了优异的下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前表示学习方法隐含假设数据点的无关视图足以学习有意义的表示，但研究发现潜在空间中的有意义结构不会自然出现，需要显式诱导。

Method: 提出了一种自监督学习方法，将数据不同视图的表示对齐以整合互补信息，同时避免产生假阳性对齐。

Result: 在MICCAI 2025 SSL3D挑战赛中，使用Primus视觉变换器和ResEnc卷积神经网络分别获得第一名和第二名的成绩。

Conclusion: 结构化视图对齐在学习有效表示中起着关键作用，显式对齐方法能显著提升下游任务性能。

Abstract: Many recent approaches in representation learning implicitly assume that
uncorrelated views of a data point are sufficient to learn meaningful
representations for various downstream tasks. In this work, we challenge this
assumption and demonstrate that meaningful structure in the latent space does
not emerge naturally. Instead, it must be explicitly induced. We propose a
method that aligns representations from different views of the data to align
complementary information without inducing false positives. Our experiments
show that our proposed self-supervised learning method, Consistent View
Alignment, improves performance for downstream tasks, highlighting the critical
role of structured view alignment in learning effective representations. Our
method achieved first and second place in the MICCAI 2025 SSL3D challenge when
using a Primus vision transformer and ResEnc convolutional neural network,
respectively. The code and pretrained model weights are released at
https://github.com/Tenbatsu24/LatentCampus.

</details>


### [120] [SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation](https://arxiv.org/abs/2509.13848)
*Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai*

Main category: cs.CV

TL;DR: SpecDiff是一种基于自推测信息的训练免费多级特征缓存策略，通过引入未来信息来克服传统特征缓存方法仅依赖历史信息的局限性，在扩散模型推理中实现了显著加速和精度保持。


<details>
  <summary>Details</summary>
Motivation: 现有特征缓存方法仅依赖历史信息，导致精度和速度性能受限。需要引入未来信息来突破速度-精度权衡瓶颈。

Method: 提出自推测范式，利用不同迭代次数下相同时步的信息相似性引入未来信息。包含基于自推测信息的缓存特征选择算法和基于特征重要性分数的多级特征分类算法。

Result: 在Stable Diffusion 3、3.5和FLUX上分别实现平均2.80×、2.74×和3.17×的加速，质量损失可忽略。

Conclusion: 通过融合推测信息和历史信息，SpecDiff突破了速度-精度权衡瓶颈，推动了高效扩散模型推理的Pareto前沿。

Abstract: Feature caching has recently emerged as a promising method for diffusion
model acceleration. It effectively alleviates the inefficiency problem caused
by high computational requirements by caching similar features in the inference
process of the diffusion model. In this paper, we analyze existing feature
caching methods from the perspective of information utilization, and point out
that relying solely on historical information will lead to constrained accuracy
and speed performance. And we propose a novel paradigm that introduces future
information via self-speculation based on the information similarity at the
same time step across different iteration times. Based on this paradigm, we
present \textit{SpecDiff}, a training-free multi-level feature caching strategy
including a cached feature selection algorithm and a multi-level feature
classification algorithm. (1) Feature selection algorithm based on
self-speculative information. \textit{SpecDiff} determines a dynamic importance
score for each token based on self-speculative information and historical
information, and performs cached feature selection through the importance
score. (2) Multi-level feature classification algorithm based on feature
importance scores. \textit{SpecDiff} classifies tokens by leveraging the
differences in feature importance scores and introduces a multi-level feature
calculation strategy. Extensive experiments show that \textit{SpecDiff}
achieves average 2.80 \times, 2.74 \times , and 3.17\times speedup with
negligible quality loss in Stable Diffusion 3, 3.5, and FLUX compared to RFlow
on NVIDIA A800-80GB GPU. By merging speculative and historical information,
\textit{SpecDiff} overcomes the speedup-accuracy trade-off bottleneck, pushing
the Pareto frontier of speedup and accuracy in the efficient diffusion model
inference.

</details>


### [121] [EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics](https://arxiv.org/abs/2509.13858)
*Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang*

Main category: cs.CV

TL;DR: EDITS是一个新的数据集蒸馏框架，利用图像中的隐含文本语义信息，通过视觉语言模型和大型语言模型融合图像与文本特征，生成更高质量的合成数据集。


<details>
  <summary>Details</summary>
Motivation: 传统数据集蒸馏方法主要捕获低级视觉特征，忽略了图像中的高级语义和结构信息，导致蒸馏效果受限。

Method: 1. 使用视觉语言模型生成外部文本并与图像特征融合；2. 通过全局语义查询模块形成先验聚类缓冲区；3. 局部语义感知选择代表性样本构建图像和文本原型；4. 使用精心设计的提示词引导大型语言模型；5. 通过扩散模型生成最终合成数据集。

Result: 大量实验证实了该方法的有效性，能够生成更高质量的合成数据集，在保持竞争力的模型性能的同时实现高效学习。

Conclusion: EDITS框架通过利用图像中的文本语义信息，显著提升了数据集蒸馏的效果，为高效机器学习提供了新的解决方案。

Abstract: Dataset distillation aims to synthesize a compact dataset from the original
large-scale one, enabling highly efficient learning while preserving
competitive model performance. However, traditional techniques primarily
capture low-level visual features, neglecting the high-level semantic and
structural information inherent in images. In this paper, we propose EDITS, a
novel framework that exploits the implicit textual semantics within the image
data to achieve enhanced distillation. First, external texts generated by a
Vision Language Model (VLM) are fused with image features through a Global
Semantic Query module, forming the prior clustered buffer. Local Semantic
Awareness then selects representative samples from the buffer to construct
image and text prototypes, with the latter produced by guiding a Large Language
Model (LLM) with meticulously crafted prompt. Ultimately, Dual Prototype
Guidance strategy generates the final synthetic dataset through a diffusion
model. Extensive experiments confirm the effectiveness of our method.Source
code is available in: https://github.com/einsteinxia/EDITS.

</details>


### [122] [LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction](https://arxiv.org/abs/2509.13863)
*Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li*

Main category: cs.CV

TL;DR: LamiGauss是一种结合高斯溅射辐射光栅化和专用探测器-世界变换模型的CL重建算法，能够在极稀疏视图条件下实现高质量重建，仅需3%的完整视图即可超越全数据集优化的迭代方法。


<details>
  <summary>Details</summary>
Motivation: 传统CT在板状结构检测中存在几何约束问题，而CL在稀疏视图条件下的高质量体积重建仍然具有挑战性，特别是在高度稀疏视图采集条件下。

Method: 提出LamiGauss算法，结合高斯溅射辐射光栅化和包含层析倾斜角的专用探测器-世界变换模型，采用初始化策略过滤层析伪影，防止冗余高斯分配到虚假结构。

Result: 在合成和真实数据集上的广泛实验证明了该方法的有效性和优越性，仅使用3%的完整视图就能实现优于全数据集优化迭代方法的性能。

Conclusion: LamiGauss能够直接从稀疏投影进行有效优化，在有限数据条件下实现准确高效的重建，解决了层析成像在稀疏视图条件下的重建挑战。

Abstract: X-ray Computed Laminography (CL) is essential for non-destructive inspection
of plate-like structures in applications such as microchips and composite
battery materials, where traditional computed tomography (CT) struggles due to
geometric constraints. However, reconstructing high-quality volumes from
laminographic projections remains challenging, particularly under highly
sparse-view acquisition conditions. In this paper, we propose a reconstruction
algorithm, namely LamiGauss, that combines Gaussian Splatting radiative
rasterization with a dedicated detector-to-world transformation model
incorporating the laminographic tilt angle. LamiGauss leverages an
initialization strategy that explicitly filters out common laminographic
artifacts from the preliminary reconstruction, preventing redundant Gaussians
from being allocated to false structures and thereby concentrating model
capacity on representing the genuine object. Our approach effectively optimizes
directly from sparse projections, enabling accurate and efficient
reconstruction with limited data. Extensive experiments on both synthetic and
real datasets demonstrate the effectiveness and superiority of the proposed
method over existing techniques. LamiGauss uses only 3$\%$ of full views to
achieve superior performance over the iterative method optimized on a full
dataset.

</details>


### [123] [Distractor-Aware Memory-Based Visual Object Tracking](https://arxiv.org/abs/2509.13864)
*Jovana Videnovic,Matej Kristan,Alan Lukezic*

Main category: cs.CV

TL;DR: 提出了DAM4SAM，一个针对SAM2的干扰物感知内存模块和自省管理方法，有效减少跟踪漂移并提升遮挡后重检测能力，在多个基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于内存的视频分割方法如SAM2在分割任务中表现优异，但在视觉目标跟踪中面对视觉相似干扰物时存在挑战，需要专门针对干扰物的解决方案。

Method: 提出干扰物感知的即插即用内存模块和基于自省的内存管理方法，构建了DiDi干扰物蒸馏数据集用于分析跟踪性能。

Result: DAM4SAM在13个基准测试中超越SAM2.1，在10个测试中达到新的SOTA；集成到实时跟踪器EfficientTAM中提升11%性能，在边缘跟踪器EdgeTAM中提升4%性能。

Conclusion: 所提出的干扰物感知内存模块具有良好的泛化能力，能有效提升各种架构跟踪器在干扰物环境下的性能表现。

Abstract: Recent emergence of memory-based video segmentation methods such as SAM2 has
led to models with excellent performance in segmentation tasks, achieving
leading results on numerous benchmarks. However, these modes are not fully
adjusted for visual object tracking, where distractors (i.e., objects visually
similar to the target) pose a key challenge. In this paper we propose a
distractor-aware drop-in memory module and introspection-based management
method for SAM2, leading to DAM4SAM. Our design effectively reduces the
tracking drift toward distractors and improves redetection capability after
object occlusion. To facilitate the analysis of tracking in the presence of
distractors, we construct DiDi, a Distractor-Distilled dataset. DAM4SAM
outperforms SAM2.1 on thirteen benchmarks and sets new state-of-the-art results
on ten. Furthermore, integrating the proposed distractor-aware memory into a
real-time tracker EfficientTAM leads to 11% improvement and matches tracking
quality of the non-real-time SAM2.1-L on multiple tracking and segmentation
benchmarks, while integration with edge-based tracker EdgeTAM delivers 4%
performance boost, demonstrating a very good generalization across
architectures.

</details>


### [124] [MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment](https://arxiv.org/abs/2509.14001)
*Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli*

Main category: cs.CV

TL;DR: MOCHA是一种知识蒸馏方法，将大型视觉-语言教师模型的区域级多模态语义转移到轻量级纯视觉目标检测学生模型中，通过对象级对齐实现高效语义迁移。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注密集或全局对齐，而MOCHA专注于对象级语义转移，旨在在不修改教师模型或推理时不需要文本输入的情况下，实现高效的多模态知识蒸馏。

Method: 使用翻译模块将学生特征映射到联合空间，通过双目标损失函数（局部对齐和全局关系一致性）指导学生和翻译器的训练，在对象级别进行操作。

Result: 在四个个性化检测基准测试中，few-shot设置下平均得分提升+10.1，紧凑架构性能可与大型多模态模型媲美。

Conclusion: MOCHA证明了在对象级别进行多模态知识蒸馏的有效性，适合实际部署应用。

Abstract: We introduce MOCHA (Multi-modal Objects-aware Cross-arcHitecture Alignment),
a knowledge distillation approach that transfers region-level multimodal
semantics from a large vision-language teacher (e.g., LLaVa) into a lightweight
vision-only object detector student (e.g., YOLO). A translation module maps
student features into a joint space, where the training of the student and
translator is guided by a dual-objective loss that enforces both local
alignment and global relational consistency. Unlike prior approaches focused on
dense or global alignment, MOCHA operates at the object level, enabling
efficient transfer of semantics without modifying the teacher or requiring
textual input at inference. We validate our method across four personalized
detection benchmarks under few-shot regimes. Results show consistent gains over
baselines, with a +10.1 average score improvement. Despite its compact
architecture, MOCHA reaches performance on par with larger multimodal models,
proving its suitability for real-world deployment.

</details>


### [125] [Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis](https://arxiv.org/abs/2509.13873)
*Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam*

Main category: cs.CV

TL;DR: PelFANet是一个双流注意力网络，通过融合原始骨盆X光片和分割骨图像来提高骨折分类性能，在可见和不可见骨折检测中均表现出色


<details>
  <summary>Details</summary>
Motivation: 骨盆骨折在标准X光片中难以诊断，特别是当骨折迹象细微或不可见时，需要更精确的检测方法

Method: 使用双流注意力网络，融合原始X光片和分割骨图像，采用Fused Attention Blocks进行特征交换和精炼，通过两阶段分割引导的管道进行训练

Result: 在AMERI数据集上，可见骨折检测准确率88.68%，AUC 0.9334；不可见骨折检测准确率82.29%，AUC 0.8688，尽管未在不可见骨折数据上训练

Conclusion: 该研究表明解剖感知的双输入架构在骨折检测方面具有临床潜力，特别是在放射学表现细微的情况下

Abstract: Pelvic fractures pose significant diagnostic challenges, particularly in
cases where fracture signs are subtle or invisible on standard radiographs. To
address this, we introduce PelFANet, a dual-stream attention network that fuses
raw pelvic X-rays with segmented bone images to improve fracture
classification. The network em-ploys Fused Attention Blocks (FABlocks) to
iteratively exchange and refine fea-tures from both inputs, capturing global
context and localized anatomical detail. Trained in a two-stage pipeline with a
segmentation-guided approach, PelFANet demonstrates superior performance over
conventional methods. On the AMERI dataset, it achieves 88.68% accuracy and
0.9334 AUC on visible fractures, while generalizing effectively to invisible
fracture cases with 82.29% accuracy and 0.8688 AUC, despite not being trained
on them. These results highlight the clini-cal potential of anatomy-aware
dual-input architectures for robust fracture detec-tion, especially in
scenarios with subtle radiographic presentations.

</details>


### [126] [EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View](https://arxiv.org/abs/2509.13883)
*Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen*

Main category: cs.CV

TL;DR: EvHand-FPV是一个轻量级单事件相机第一人称视角3D手部追踪框架，通过手腕ROI定位、端到端映射和多任务学习策略，在保持高精度的同时大幅降低计算量和参数数量


<details>
  <summary>Details</summary>
Motivation: 传统帧式方法在精度、延迟和能效方面难以满足XR设备的需求，事件相机具有微秒级时间分辨率和毫瓦级功耗优势，但缺乏第一人称视角的基准数据集

Method: 构建合成训练数据和真实评估数据的事件数据集；引入手腕ROI几何定位；端到端映射嵌入ROI偏移减少计算；多任务学习辅助几何特征头提升表征

Result: 在真实测试集上2D-AUCp从0.77提升到0.85，参数量减少89%至1.2M，计算量减少89%至0.185G FLOPs；合成数据上保持0.84的3D-AUCp

Conclusion: 该方法实现了准确高效的自我中心事件手部追踪，适合设备端XR应用，数据集和代码已开源

Abstract: Hand tracking holds great promise for intuitive interaction paradigms, but
frame-based methods often struggle to meet the requirements of accuracy, low
latency, and energy efficiency, especially in resource-constrained settings
such as Extended Reality (XR) devices. Event cameras provide $\mu$s-level
temporal resolution at mW-level power by asynchronously sensing brightness
changes. In this work, we present EvHand-FPV, a lightweight framework for
egocentric First-Person-View 3D hand tracking from a single event camera. We
construct an event-based FPV dataset that couples synthetic training data with
3D labels and real event data with 2D labels for evaluation to address the
scarcity of egocentric benchmarks. EvHand-FPV also introduces a wrist-based
region of interest (ROI) that localizes the hand region via geometric cues,
combined with an end-to-end mapping strategy that embeds ROI offsets into the
network to reduce computation without explicit reconstruction, and a multi-task
learning strategy with an auxiliary geometric feature head that improves
representations without test-time overhead. On our real FPV test set,
EvHand-FPV improves 2D-AUCp from 0.77 to 0.85 while reducing parameters from
11.2M to 1.2M by 89% and FLOPs per inference from 1.648G to 0.185G by 89%. It
also maintains a competitive 3D-AUCp of 0.84 on synthetic data. These results
demonstrate accurate and efficient egocentric event-based hand tracking
suitable for on-device XR applications. The dataset and code are available at
https://github.com/zen5x5/EvHand-FPV.

</details>


### [127] [White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation](https://arxiv.org/abs/2509.13907)
*Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo*

Main category: cs.CV

TL;DR: 提出WARM模块解决少样本3D点云分割中原型生成的分布差异问题，通过白化和染色变换改进注意力机制，在多个基准测试中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法使用传统算法（如最远点采样）构建原型存在初始随机性影响性能的问题，且原型生成过程研究不足。注意力机制虽有效但存在可学习原型标记与支持特征间的分布差异

Method: 提出White Aggregation and Restoration Module (WARM)，在交叉注意力前后分别进行白化和染色变换：白化将支持特征与原型标记对齐，染色将注意力后的标记恢复原始分布

Result: 在多个少样本3D点云分割基准测试中取得了显著优于现有方法的性能，通过大量实验证明了有效性

Conclusion: WARM模块通过简单的白化-注意力-染色设计解决了分布差异问题，能够生成更具代表性的原型，显著提升了少样本3D点云分割的性能

Abstract: Few-Shot 3D Point Cloud Segmentation (FS-PCS) aims to predict per-point
labels for an unlabeled point cloud, given only a few labeled examples. To
extract discriminative representations from the limited support set, existing
methods have constructed prototypes using conventional algorithms such as
farthest point sampling. However, we point out that its initial randomness
significantly affects FS-PCS performance and that the prototype generation
process remains underexplored despite its prevalence. This motivates us to
investigate an advanced prototype generation method based on attention
mechanism. Despite its potential, we found that vanilla module suffers from the
distributional gap between learnable prototypical tokens and support features.
To overcome this, we propose White Aggregation and Restoration Module (WARM),
which resolves the misalignment by sandwiching cross-attention between
whitening and coloring transformations. Specifically, whitening aligns the
support features to prototypical tokens before attention process, and
subsequently coloring restores the original distribution to the attended
tokens. This simple yet effective design enables robust attention, thereby
generating representative prototypes by capturing the semantic relationships
among support features. Our method achieves state-of-the-art performance with a
significant margin on multiple FS-PCS benchmarks, demonstrating its
effectiveness through extensive experiments.

</details>


### [128] [Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration](https://arxiv.org/abs/2509.13919)
*Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li*

Main category: cs.CV

TL;DR: 提出了自校准推理框架SRC，通过轻量级推理微调、候选响应搜索和配对评分策略，迭代校准视觉语言模型中推理过程与答案的对齐，显著提升了模型的感知、推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉问答中表现出色，但推理过程与生成答案之间缺乏对齐，导致推理不一致和错误响应，需要解决这种对齐问题。

Method: SRC框架包含三个步骤：1）轻量级推理微调，修改响应格式要求先给出推理再得出答案；2）搜索多样化候选响应；3）使用定制的R-Scorer评分模型进行配对评分，通过置信度加权的偏好选择过程进行偏好微调。

Result: 在多个基准测试中显著提升了LVLMs的感知、推理和泛化能力，证明了推理导向对齐方法在挖掘LVLMs潜力方面的重要性。

Conclusion: SRC框架通过迭代校准推理与答案的对齐，有效解决了LVLMs中的推理不一致问题，为探索视觉语言模型的潜力提供了重要方向。

Abstract: Large Vision-Language Models (LVLMs) have manifested strong visual question
answering capability. However, they still struggle with aligning the rationale
and the generated answer, leading to inconsistent reasoning and incorrect
responses. To this end, this paper introduces the Self-Rationale Calibration
(SRC) framework to iteratively calibrate the alignment between rationales and
answers. SRC begins by employing a lightweight "rationale fine-tuning"
approach, which modifies the model's response format to require a rationale
before deriving an answer without explicit prompts. Next, SRC searches for a
diverse set of candidate responses from the fine-tuned LVLMs for each sample,
followed by a proposed pairwise scoring strategy using a tailored scoring
model, R-Scorer, to evaluate both rationale quality and factual consistency of
candidates. Based on a confidence-weighted preference curation process, SRC
decouples the alignment calibration into a preference fine-tuning manner,
leading to significant improvements of LVLMs in perception, reasoning, and
generalization across multiple benchmarks. Our results emphasize the
rationale-oriented alignment in exploring the potential of LVLMs.

</details>


### [129] [Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification](https://arxiv.org/abs/2509.13922)
*Wenkui Yang,Jie Cao,Junxian Duan,Ran He*

Main category: cs.CV

TL;DR: 提出了AntiPure方法，通过在扩散模型中引入两种引导机制来抵抗净化攻击，保护图像免受恶意伪造。


<details>
  <summary>Details</summary>
Motivation: 扩散模型如Stable Diffusion的强大定制能力带来了严重的安全风险，包括深度伪造和版权侵权。现有的保护性扰动方法容易被净化技术移除，需要开发抗净化解决方案。

Method: 提出AntiPure方法，包含两种引导机制：1) 块状频率引导 - 减少模型对净化图像高频分量的影响；2) 错误时间步引导 - 扰乱模型在不同时间步的去噪策略。通过额外引导嵌入难以察觉的扰动。

Result: 实验表明AntiPure在净化-定制工作流中实现了最小的感知差异和最大的失真效果，优于其他保护性扰动方法。

Conclusion: AntiPure作为净化的压力测试，能够有效抵抗净化攻击，为图像安全保护提供了有效的解决方案。

Abstract: Diffusion models like Stable Diffusion have become prominent in visual
synthesis tasks due to their powerful customization capabilities, which also
introduce significant security risks, including deepfakes and copyright
infringement. In response, a class of methods known as protective perturbation
emerged, which mitigates image misuse by injecting imperceptible adversarial
noise. However, purification can remove protective perturbations, thereby
exposing images again to the risk of malicious forgery. In this work, we
formalize the anti-purification task, highlighting challenges that hinder
existing approaches, and propose a simple diagnostic protective perturbation
named AntiPure. AntiPure exposes vulnerabilities of purification within the
"purification-customization" workflow, owing to two guidance mechanisms: 1)
Patch-wise Frequency Guidance, which reduces the model's influence over
high-frequency components in the purified image, and 2) Erroneous Timestep
Guidance, which disrupts the model's denoising strategy across different
timesteps. With additional guidance, AntiPure embeds imperceptible
perturbations that persist under representative purification settings,
achieving effective post-customization distortion. Experiments show that, as a
stress test for purification, AntiPure achieves minimal perceptual discrepancy
and maximal distortion, outperforming other protective perturbation methods
within the purification-customization workflow.

</details>


### [130] [Noise-Level Diffusion Guidance: Well Begun is Half Done](https://arxiv.org/abs/2509.13936)
*Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett*

Main category: cs.CV

TL;DR: 提出Noise Level Guidance (NLG)方法，通过优化初始噪声来提高扩散模型生成质量和提示遵循度，无需额外训练数据、辅助网络或反向传播


<details>
  <summary>Details</summary>
Motivation: 扩散模型使用随机高斯噪声开始生成过程会影响最终输出质量，现有噪声优化方法依赖额外数据集、网络或反向传播，实用性受限

Method: NLG方法通过增加初始噪声与通用指导对齐的可能性来优化噪声，提供统一框架适用于条件和无条件扩散模型，支持多种扩散级指导形式

Result: 在五个标准基准测试上的广泛实验表明，该方法提高了输出生成质量和输入条件遵循度

Conclusion: NLG方法在保持计算效率的同时与现有指导方法无缝集成，为扩散模型提供了实用且可扩展的增强方案

Abstract: Diffusion models have achieved state-of-the-art image generation. However,
the random Gaussian noise used to start the diffusion process influences the
final output, causing variations in image quality and prompt adherence.
Existing noise-level optimization approaches generally rely on extra dataset
construction, additional networks, or backpropagation-based optimization,
limiting their practicality. In this paper, we propose Noise Level Guidance
(NLG), a simple, efficient, and general noise-level optimization approach that
refines initial noise by increasing the likelihood of its alignment with
general guidance - requiring no additional training data, auxiliary networks,
or backpropagation. The proposed NLG approach provides a unified framework
generalizable to both conditional and unconditional diffusion models,
accommodating various forms of diffusion-level guidance. Extensive experiments
on five standard benchmarks demonstrate that our approach enhances output
generation quality and input condition adherence. By seamlessly integrating
with existing guidance methods while maintaining computational efficiency, our
method establishes NLG as a practical and scalable enhancement to diffusion
models. Code can be found at
https://github.com/harveymannering/NoiseLevelGuidance.

</details>


### [131] [Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions](https://arxiv.org/abs/2509.14165)
*Michal Szczepanski,Martyna Poreba,Karim Haroun*

Main category: cs.CV

TL;DR: STEP是一种混合式令牌缩减框架，通过动态补丁合并和令牌剪枝提升ViT在语义分割中的效率，计算复杂度降低4倍，速度提升1.7倍，准确度下降不超2%


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在语义分割任务中计算和内存成本过高的问题

Method: 提出STEP混合框架，结合动态补丁合并(dCTS)和早期剪枝，通过轻量CNN策略网络实现灵活合并，并在编码器中集成早期退出机制

Result: 在1024x1024高分辨率图像上，令牌数量减少2.5倍，计算成本降低2.6倍，吞吐量提升3.4倍；完整框架达到4倍计算复杂度降低和1.7倍速度提升，40%令牌可早期停止

Conclusion: STEP框架能够在准确度损失最小的情况下显著提升ViT在语义分割中的效率，为高分辨率形势处理提供了有效解决方案

Abstract: Vision Transformers (ViTs) achieve state-of-the-art performance in semantic
segmentation but are hindered by high computational and memory costs. To
address this, we propose STEP (SuperToken and Early-Pruning), a hybrid
token-reduction framework that combines dynamic patch merging and token pruning
to enhance efficiency without significantly compromising accuracy. At the core
of STEP is dCTS, a lightweight CNN-based policy network that enables flexible
merging into superpatches. Encoder blocks integrate also early-exits to remove
high-confident supertokens, lowering computational load. We evaluate our method
on high-resolution semantic segmentation benchmarks, including images up to
1024 x 1024, and show that when dCTS is applied alone, the token count can be
reduced by a factor of 2.5 compared to the standard 16 x 16 pixel patching
scheme. This yields a 2.6x reduction in computational cost and a 3.4x increase
in throughput when using ViT-Large as the backbone. Applying the full STEP
framework further improves efficiency, reaching up to a 4x reduction in
computational complexity and a 1.7x gain in inference speed, with a maximum
accuracy drop of no more than 2.0%. With the proposed STEP configurations, up
to 40% of tokens can be confidently predicted and halted before reaching the
final encoder layer.

</details>


### [132] [Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation](https://arxiv.org/abs/2509.13939)
*Gia Khanh Nguyen,Yifeng Huang,Minh Hoai*

Main category: cs.CV

TL;DR: PairTally是一个专门评估细粒度视觉计数能力的基准数据集，包含681张高分辨率图像，每张图像包含两个需要区分的物体类别，测试模型基于形状、大小、颜色或语义的细微差异进行选择性计数的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的类无关计数模型和大规模视觉语言模型在细粒度、意图驱动的计数任务上的能力尚不明确，需要专门的评估基准来诊断和改进这些系统。

Method: 构建了包含681张高分辨率图像的PairTally数据集，每张图像包含两个物体类别（跨类别和类别内设置），对多种最先进模型进行基准测试，包括基于示例的方法、语言提示模型和大规模视觉语言模型。

Result: 尽管最近有所进展，但当前模型在可靠地计数用户意图方面仍然存在困难，特别是在细粒度和视觉模糊的情况下。

Conclusion: PairTally为诊断和改进细粒度视觉计数系统提供了新的基础，揭示了当前模型在意图驱动计数任务上的局限性。

Abstract: Visual counting is a fundamental yet challenging task, especially when users
need to count objects of a specific type in complex scenes. While recent
models, including class-agnostic counting models and large vision-language
models (VLMs), show promise in counting tasks, their ability to perform
fine-grained, intent-driven counting remains unclear. In this paper, we
introduce PairTally, a benchmark dataset specifically designed to evaluate
fine-grained visual counting. Each of the 681 high-resolution images in
PairTally contains two object categories, requiring models to distinguish and
count based on subtle differences in shape, size, color, or semantics. The
dataset includes both inter-category (distinct categories) and intra-category
(closely related subcategories) settings, making it suitable for rigorous
evaluation of selective counting capabilities. We benchmark a variety of
state-of-the-art models, including exemplar-based methods, language-prompted
models, and large VLMs. Our results show that despite recent advances, current
models struggle to reliably count what users intend, especially in fine-grained
and visually ambiguous cases. PairTally provides a new foundation for
diagnosing and improving fine-grained visual counting systems.

</details>


### [133] [Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments](https://arxiv.org/abs/2509.14012)
*Tamara R. Lenhard,Andreas Weinmann,Tobias Koch*

Main category: cs.CV

TL;DR: 基于YOLO-FEDER FusionNet的改进版本，通过系统性的训练数据组成、特征融合策略和背锁设计优化，显著提升了复杂视觉环境下的无人机检测性能。


<details>
  <summary>Details</summary>
Motivation: 复杂视觉环境下的无人机检测面临背景杂乱、小物体尺度和谜色效果等挑战，通用检测器在这种环境下性能伞减。

Method: 提出了一种改进的YOLO-FEDER FusionNet框架，结合了通用物体检测和谜色物体检测技术。采用大规模照片实感合成数据和少量真实样本进行训练，系统评估中间多尺度FEDER特征的贡献，并在多个YOLO背锁配置上进行综合性能测评。

Result: 在最优配置(YOLOv8l背锁+DWD模块FEDER特征)下，与基线相比，FNR降低了39.1个百分点，mAP在IoU阈值0.5时提高了62.8个百分点。

Conclusion: 集成中间FEDER特征结合背锁升级，能够带来显著的性能提升，有效解决了复杂视觉环境下无人机检测的挑战。

Abstract: Drone detection in visually complex environments remains challenging due to
background clutter, small object scale, and camouflage effects. While generic
object detectors like YOLO exhibit strong performance in low-texture scenes,
their effectiveness degrades in cluttered environments with low
object-background separability. To address these limitations, this work
presents an enhanced iteration of YOLO-FEDER FusionNet -- a detection framework
that integrates generic object detection with camouflage object detection
techniques. Building upon the original architecture, the proposed iteration
introduces systematic advancements in training data composition, feature fusion
strategies, and backbone design. Specifically, the training process leverages
large-scale, photo-realistic synthetic data, complemented by a small set of
real-world samples, to enhance robustness under visually complex conditions.
The contribution of intermediate multi-scale FEDER features is systematically
evaluated, and detection performance is comprehensively benchmarked across
multiple YOLO-based backbone configurations. Empirical results indicate that
integrating intermediate FEDER features, in combination with backbone upgrades,
contributes to notable performance improvements. In the most promising
configuration -- YOLO-FEDER FusionNet with a YOLOv8l backbone and FEDER
features derived from the DWD module -- these enhancements lead to a FNR
reduction of up to 39.1 percentage points and a mAP increase of up to 62.8
percentage points at an IoU threshold of 0.5, compared to the initial baseline.

</details>


### [134] [SAIL-VL2 Technical Report](https://arxiv.org/abs/2509.14033)
*Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng*

Main category: cs.CV

TL;DR: SAIL-VL2是一个开源的2B和8B参数规模视觉语言基础模型，在106个数据集上表现优异，在MMMU和MathVista等推理基准测试中达到最先进水平，在OpenCompass排行榜中4B参数规模以下开源模型排名第一。


<details>
  <summary>Details</summary>
Motivation: 作为SAIL-VL的继任者，旨在开发一个全面的多模态理解和推理基础模型，通过核心创新提升训练效率和模型能力。

Method: 采用大规模数据筛选管道、渐进式训练框架（从预训练视觉编码器到多模态预训练，再到思维融合SFT-RL混合范式）以及稀疏MoE架构设计。

Result: 在2B和8B参数规模下在多样化图像和视频基准测试中达到最先进性能，在106个数据集上展示竞争优势，在挑战性推理基准测试中表现优异。

Conclusion: SAIL-VL2为开源多模态社区提供了一个高效且可扩展的基础模型，在多个维度上实现了突破性进展。

Abstract: We introduce SAIL-VL2, an open-suite vision-language foundation model (LVM)
for comprehensive multimodal understanding and reasoning. As the successor to
SAIL-VL, SAIL-VL2 achieves state-of-the-art performance at the 2B and 8B
parameter scales across diverse image and video benchmarks, demonstrating
strong capabilities from fine-grained perception to complex reasoning. Three
core innovations drive its effectiveness. First, a large-scale data curation
pipeline with scoring and filtering strategies enhances both quality and
distribution across captioning, OCR, QA, and video data, improving training
efficiency. Second, a progressive training framework begins with a powerful
pre-trained vision encoder (SAIL-ViT), advances through multimodal
pre-training, and culminates in a thinking-fusion SFT-RL hybrid paradigm that
systematically strengthens model capabilities. Third, architectural advances
extend beyond dense LLMs to efficient sparse Mixture-of-Experts (MoE) designs.
With these contributions, SAIL-VL2 demonstrates competitive performance across
106 datasets and achieves state-of-the-art results on challenging reasoning
benchmarks such as MMMU and MathVista. Furthermore, on the OpenCompass
leaderboard, SAIL-VL2-2B ranks first among officially released open-source
models under the 4B parameter scale, while serving as an efficient and
extensible foundation for the open-source multimodal community.

</details>


### [135] [PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings](https://arxiv.org/abs/2509.14051)
*Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas*

Main category: cs.CV

TL;DR: PROFUSEme方法通过融合临床、影像和病理多模态数据，使用Cox比例风险回归器预测前列腺癌根治术后生化复发，性能优于晚期融合方法。


<details>
  <summary>Details</summary>
Motivation: 约30%前列腺癌患者在根治性前列腺切除术后经历生化复发，准确早期预测有助于临床决策和改善患者预后。

Method: 提出PROFUSEme方法，采用中间融合配置学习临床、影像和病理数据的跨模态交互，结合Cox比例风险回归器。

Result: 内部5折嵌套交叉验证平均C-index为0.861，在CHIMERA 2025挑战验证排行榜上C-index为0.7103，性能优于晚期融合配置。

Conclusion: 多模态数据融合方法能有效预测前列腺癌术后生化复发，为临床决策提供支持。

Abstract: Almost 30% of prostate cancer (PCa) patients undergoing radical prostatectomy
(RP) experience biochemical recurrence (BCR), characterized by increased
prostate specific antigen (PSA) and associated with increased mortality.
Accurate early prediction of BCR, at the time of RP, would contribute to prompt
adaptive clinical decision-making and improved patient outcomes. In this work,
we propose prostate cancer BCR prediction via fused multi-modal embeddings
(PROFUSEme), which learns cross-modal interactions of clinical, radiology, and
pathology data, following an intermediate fusion configuration in combination
with Cox Proportional Hazard regressors. Quantitative evaluation of our
proposed approach reveals superior performance, when compared with late fusion
configurations, yielding a mean C-index of 0.861 ($\sigma=0.112$) on the
internal 5-fold nested cross-validation framework, and a C-index of 0.7103 on
the hold out data of CHIMERA 2025 challenge validation leaderboard.

</details>


### [136] [Wan-Animate: Unified Character Animation and Replacement with Holistic Replication](https://arxiv.org/abs/2509.14055)
*Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo*

Main category: cs.CV

TL;DR: Wan-Animate是一个统一的角色动画和替换框架，能够根据参考视频精确复制角色的表情和动作来生成高质量角色视频，或将动画角色无缝集成到参考视频中替换原始角色。


<details>
  <summary>Details</summary>
Motivation: 为了解决角色动画和替换任务中需要高保真度复制表情动作以及实现环境光照无缝集成的问题，开发一个统一的框架来处理这些相关但具有挑战性的计算机视觉任务。

Method: 基于Wan模型构建，采用改进的输入范式区分参考条件和生成区域，使用空间对齐的骨架信号复制身体运动，从源图像提取隐式面部特征重现表情，并开发辅助的Relighting LoRA模块来增强环境集成效果。

Result: 实验结果表明Wan-Animate达到了最先进的性能水平，能够生成具有高度可控性和表现力的角色视频，并实现无缝的环境光照集成。

Conclusion: Wan-Animate是一个有效的统一框架，成功解决了角色动画和替换的关键技术挑战，作者承诺将开源模型权重和源代码以促进相关研究发展。

Abstract: We introduce Wan-Animate, a unified framework for character animation and
replacement. Given a character image and a reference video, Wan-Animate can
animate the character by precisely replicating the expressions and movements of
the character in the video to generate high-fidelity character videos.
Alternatively, it can integrate the animated character into the reference video
to replace the original character, replicating the scene's lighting and color
tone to achieve seamless environmental integration. Wan-Animate is built upon
the Wan model. To adapt it for character animation tasks, we employ a modified
input paradigm to differentiate between reference conditions and regions for
generation. This design unifies multiple tasks into a common symbolic
representation. We use spatially-aligned skeleton signals to replicate body
motion and implicit facial features extracted from source images to reenact
expressions, enabling the generation of character videos with high
controllability and expressiveness. Furthermore, to enhance environmental
integration during character replacement, we develop an auxiliary Relighting
LoRA. This module preserves the character's appearance consistency while
applying the appropriate environmental lighting and color tone. Experimental
results demonstrate that Wan-Animate achieves state-of-the-art performance. We
are committed to open-sourcing the model weights and its source code.

</details>


### [137] [VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement](https://arxiv.org/abs/2509.14060)
*Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu*

Main category: cs.CV

TL;DR: 提出VSE-MOT框架，通过视觉语义增强解决低质量视频中的多目标跟踪问题，在真实低质量场景中性能提升8-20%


<details>
  <summary>Details</summary>
Motivation: 当前多目标跟踪算法在低质量视频中性能显著下降，需要提升在真实世界低质量视频场景中的应用能力

Method: 设计三分支架构，利用视觉语言模型提取全局视觉语义信息并与查询向量融合；引入MOT-Adapter适配多目标跟踪任务，VSFM模块提升特征融合效果

Result: 在真实低质量视频场景中验证有效性和优越性，跟踪性能指标比现有方法提升约8%-20%，在常规场景中保持稳健性能

Conclusion: VSE-MOT框架成功解决了低质量视频中的多目标跟踪挑战，为真实世界应用提供了有效解决方案

Abstract: Current multi-object tracking (MOT) algorithms typically overlook issues
inherent in low-quality videos, leading to significant degradation in tracking
performance when confronted with real-world image deterioration. Therefore,
advancing the application of MOT algorithms in real-world low-quality video
scenarios represents a critical and meaningful endeavor. To address the
challenges posed by low-quality scenarios, inspired by vision-language models,
this paper proposes a Visual Semantic Enhancement-guided Multi-Object Tracking
framework (VSE-MOT). Specifically, we first design a tri-branch architecture
that leverages a vision-language model to extract global visual semantic
information from images and fuse it with query vectors. Subsequently, to
further enhance the utilization of visual semantic information, we introduce
the Multi-Object Tracking Adapter (MOT-Adapter) and the Visual Semantic Fusion
Module (VSFM). The MOT-Adapter adapts the extracted global visual semantic
information to suit multi-object tracking tasks, while the VSFM improves the
efficacy of feature fusion. Through extensive experiments, we validate the
effectiveness and superiority of the proposed method in real-world low-quality
video scenarios. Its tracking performance metrics outperform those of existing
methods by approximately 8% to 20%, while maintaining robust performance in
conventional scenarios.

</details>


### [138] [AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration](https://arxiv.org/abs/2509.14084)
*Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao*

Main category: cs.CV

TL;DR: 首次将DINOv3模型用于零样本异常检测(ZSAD)，提出AD-DINOv3框架，通过多模态对比学习和异常感知检查模块解决域偏置和全局语义偏询问题，在八个工业和医疗数据集上达到最先进水平


<details>
  <summary>Details</summary>
Motivation: 传统的零样本异常检测主要基于CLIP模型，而DINOv3等视觉基础模型显示出强大的可转移表征能力，但直接应用遇到域偏置和全局语义偏询题

Method: 提出AD-DINOv3框架：使用DINOv3作为视觉背骨提取patch tokens和CLS token，CLIP文本编码器提供正常/异常提示的嵌入。通过轻量适配器缩小域间距，设计异常感知检查模块(AACM)明确引导CLS token关注异常区域

Result: 在八个工业和医疗标准数据集上进行了涉广实验，AD-DINOv3一致地匹配或超越了最先进方法

Conclusion: AD-DINOv3作为一个通用的零样本异常检测框架体现了其优越性，通过多模态对比学习和异常感知检查有效解决了DINOv3在异常检测任务中的挑战

Abstract: Zero-Shot Anomaly Detection (ZSAD) seeks to identify anomalies from arbitrary
novel categories, offering a scalable and annotation-efficient solution.
Traditionally, most ZSAD works have been based on the CLIP model, which
performs anomaly detection by calculating the similarity between visual and
text embeddings. Recently, vision foundation models such as DINOv3 have
demonstrated strong transferable representation capabilities. In this work, we
are the first to adapt DINOv3 for ZSAD. However, this adaptation presents two
key challenges: (i) the domain bias between large-scale pretraining data and
anomaly detection tasks leads to feature misalignment; and (ii) the inherent
bias toward global semantics in pretrained representations often leads to
subtle anomalies being misinterpreted as part of the normal foreground objects,
rather than being distinguished as abnormal regions. To overcome these
challenges, we introduce AD-DINOv3, a novel vision-language multimodal
framework designed for ZSAD. Specifically, we formulate anomaly detection as a
multimodal contrastive learning problem, where DINOv3 is employed as the visual
backbone to extract patch tokens and a CLS token, and the CLIP text encoder
provides embeddings for both normal and abnormal prompts. To bridge the domain
gap, lightweight adapters are introduced in both modalities, enabling their
representations to be recalibrated for the anomaly detection task. Beyond this
baseline alignment, we further design an Anomaly-Aware Calibration Module
(AACM), which explicitly guides the CLS token to attend to anomalous regions
rather than generic foreground semantics, thereby enhancing discriminability.
Extensive experiments on eight industrial and medical benchmarks demonstrate
that AD-DINOv3 consistently matches or surpasses state-of-the-art methods,
verifying its superiority as a general zero-shot anomaly detection framework.

</details>


### [139] [Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing](https://arxiv.org/abs/2509.14097)
*Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出EMA引导的伪监督框架和类感知跨模态一致性损失，在弱监督音频-视觉视频解析任务中实现SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注全局预测的细化，但忽略了稳定的片段级监督和类感知的跨模态对齐

Method: 1) EMA引导的伪监督框架，通过自适应阈值或top-k选择生成可靠的片段级掩码；2) 类感知跨模态一致性(CMA)损失，在可靠的片段-类别对上对齐音频和视觉嵌入

Result: 在LLP和UnAV-100数据集上的评估显示，该方法在多个指标上达到了最先进的性能

Conclusion: 提出的两种策略有效解决了弱监督音频-视觉视频解析中的片段级监督和跨模态对齐问题，取得了优异的性能

Abstract: Weakly-supervised audio-visual video parsing (AVVP) seeks to detect audible,
visible, and audio-visual events without temporal annotations. Previous work
has emphasized refining global predictions through contrastive or collaborative
learning, but neglected stable segment-level supervision and class-aware
cross-modal alignment. To address this, we propose two strategies: (1) an
exponential moving average (EMA)-guided pseudo supervision framework that
generates reliable segment-level masks via adaptive thresholds or top-k
selection, offering stable temporal guidance beyond video-level labels; and (2)
a class-aware cross-modal agreement (CMA) loss that aligns audio and visual
embeddings at reliable segment-class pairs, ensuring consistency across
modalities while preserving temporal structure. Evaluations on LLP and UnAV-100
datasets shows that our method achieves state-of-the-art (SOTA) performance
across multiple metrics.

</details>


### [140] [CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts](https://arxiv.org/abs/2509.14104)
*Leonard Hackel,Tom Burgert,Begüm Demir*

Main category: cs.CV

TL;DR: 通过集成软专家混合机制，提出了一种高效远感基础模型CSMoE，在保持表征能力的同时大幅提升计算效率


<details>
  <summary>Details</summary>
Motivation: 现有远感基础模型要么计算复杂度过高，要么表征能力有限，限制了实际应用

Method: 在Cross-Sensor Masked Autoencoder模型中集成Soft mixture-of-experts机制，实现模态特定专家专业化和跨传感器共享表征学习，使用主题-气候描述符驱动的采样策略构建训练集

Result: CSMoE模型在场景分类、语义分割和内容基图像检索任务中表现突出，计算效率提升超过2倍，保持或提升了表征性能

Conclusion: 该方法能够有效创建计算效率高的远感基础模型，在表征能力、准确性和计算效率之间实现优称的平衡

Abstract: Self-supervised learning through masked autoencoders has attracted great
attention for remote sensing (RS) foundation model (FM) development, enabling
improved representation learning across diverse sensors and downstream tasks.
However, existing RS FMs often either suffer from substantial computational
complexity during both training and inference or exhibit limited
representational capacity. These issues restrict their practical applicability
in RS. To address this limitation, we propose an adaptation for enhancing the
efficiency of RS FMs by integrating the Soft mixture-of-experts (MoE) mechanism
into the FM. The integration of Soft MoEs into the FM allows modality-specific
expert specialization alongside shared cross-sensor representation learning. To
demonstrate the effectiveness of our adaptation, we apply it on the
Cross-Sensor Masked Autoencoder (CSMAE) model, resulting in the Cross-Sensor
Mixture-of-Experts (CSMoE) model. In addition, we introduce a thematic-climatic
descriptor-driven sampling strategy for the construction of a representative
and diverse training set to train our CSMoE model. Extensive experiments on
scene classification, semantic segmentation, and content-based image retrieval
demonstrate that our adaptation yields a reduction in computational
requirements while maintaining or improving representational performance.
Compared to state-of-the-art RS FMs, CSMoE achieves a superior trade-off
between representational capacity, accuracy, and computational efficiency. On
average, CSMoE achieves more than twice the computational efficiency of
existing RS FMs, while maintaining competitive performance across all
experiments. These results show the effectiveness of the proposed adaptation
for creating computationally efficient RS FMs. The code for the model, the
training set creation, and the model weights will be available at
https://git.tu-berlin.de/rsim/csmoe.

</details>


### [141] [Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows](https://arxiv.org/abs/2509.14119)
*Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T. W. Wong,Hao Chen*

Main category: cs.CV

TL;DR: 提出了一种带有级联配准机制的鲁棒虚拟染色框架，解决了生成输出与真实标注之间的空间不匹配问题，在多个数据集上显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 传统组织病理学诊断需要多种化学染色，过程耗时费力且对环境不友好。现有虚拟染色方法依赖对齐良好的配对数据，但获取这种数据困难，因为化学染色过程会导致组织结构变形，且单一切片无法进行多次染色

Method: 提出了包含级联配准机制的虚拟染色框架，通过配准机制解决生成输出与真实标注之间的空间不匹配问题

Result: 在五个数据集上显著优于最先进模型，内部数据集平均提升3.2%，外部数据集平均提升10.1%。在严重不对齐的数据集上，PSNR比基线模型提升23.8%

Conclusion: 该方法在不同数据集上表现出卓越的鲁棒性，简化了虚拟染色的数据采集过程，为推进其发展提供了新思路

Abstract: Accurate histopathological diagnosis often requires multiple differently
stained tissue sections, a process that is time-consuming, labor-intensive, and
environmentally taxing due to the use of multiple chemical stains. Recently,
virtual staining has emerged as a promising alternative that is faster,
tissue-conserving, and environmentally friendly. However, existing virtual
staining methods face significant challenges in clinical applications,
primarily due to their reliance on well-aligned paired data. Obtaining such
data is inherently difficult because chemical staining processes can distort
tissue structures, and a single tissue section cannot undergo multiple staining
procedures without damage or loss of information. As a result, most available
virtual staining datasets are either unpaired or roughly paired, making it
difficult for existing methods to achieve accurate pixel-level supervision. To
address this challenge, we propose a robust virtual staining framework
featuring cascaded registration mechanisms to resolve spatial mismatches
between generated outputs and their corresponding ground truth. Experimental
results demonstrate that our method significantly outperforms state-of-the-art
models across five datasets, achieving an average improvement of 3.2% on
internal datasets and 10.1% on external datasets. Moreover, in datasets with
substantial misalignment, our approach achieves a remarkable 23.8% improvement
in peak signal-to-noise ratio compared to baseline models. The exceptional
robustness of the proposed method across diverse datasets simplifies the data
acquisition process for virtual staining and offers new insights for advancing
its development.

</details>


### [142] [Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection](https://arxiv.org/abs/2509.14120)
*Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis*

Main category: cs.CV

TL;DR: 美颜滤镜会降低深度伪造和换脸攻击检测器的性能，导致检测准确率下降


<details>
  <summary>Details</summary>
Motivation: 社交媒体美颜滤镜的普及引发了对面部图像视频可靠性和自动人脸分析有效性的担忧，特别是对于旨在区分真实和伪造数据的数字操纵检测器

Method: 对多个最先进的检测器在基准数据集上进行全面分析，评估应用各种平滑滤镜前后的性能表现

Result: 研究发现性能下降，揭示了面部美化引入的脆弱性

Conclusion: 需要开发能够抵抗此类美颜滤镜影响的鲁棒检测模型

Abstract: Digital beautification through social media filters has become increasingly
popular, raising concerns about the reliability of facial images and videos and
the effectiveness of automated face analysis. This issue is particularly
critical for digital manipulation detectors, systems aiming at distinguishing
between genuine and manipulated data, especially in cases involving deepfakes
and morphing attacks designed to deceive humans and automated facial
recognition. This study examines whether beauty filters impact the performance
of deepfake and morphing attack detectors. We perform a comprehensive analysis,
evaluating multiple state-of-the-art detectors on benchmark datasets before and
after applying various smoothing filters. Our findings reveal performance
degradation, highlighting vulnerabilities introduced by facial enhancements and
underscoring the need for robust detection models resilient to such
alterations.

</details>


### [143] [MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook](https://arxiv.org/abs/2509.14142)
*Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen,Yicen Tian,Yilin Tao,Yin Tang,Yipeng Lin,Yiqing Wang,Yiting Xi,Yongkang Yu,Yumei Li,Yuxin Qin,Yuying Chen,Yuzhe Cen,Zhaofan Zou,Zhaohong Liu,Zhehao Shen,Zhenglin Du,Zhengyang Li,Zhenni Huang,Zhenwei Shao,Zhilong Song,Zhiyong Feng,Zhiyu Wang,Zhou Yu,Ziang Li,Zihan Zhai,Zijian Zhang,Ziyang Peng,Ziyun Xiao,Zongshu Li*

Main category: cs.CV

TL;DR: MARS2 2025挑战赛综述，聚焦多模态推理，发布Lens和AdsQA数据集，评估40+基线模型，设立三个竞赛赛道，吸引76个团队参与。


<details>
  <summary>Details</summary>
Motivation: 整合多模态机器学习和LLM的不同方法，通过大型基准测试推动该动态领域的发展，并扩展MLLM在多模态推理中的实际应用场景。

Method: 发布两个定制数据集（Lens和AdsQA），评估40+基线模型（包括通用MLLM和任务特定模型），设立三个竞赛赛道：VG-RS、VQA-SA和VR-Ads。

Result: 76个知名学术和工业机构团队注册，40+有效提交（从1200+中筛选），数据集、代码集和排名结果公开可用。

Conclusion: MARS2挑战赛成功建立了多模态推理的基准测试平台，为研究者提供了跟踪最新技术进展的资源，并促进了该领域的发展。

Abstract: This paper reviews the MARS2 2025 Challenge on Multimodal Reasoning. We aim
to bring together different approaches in multimodal machine learning and LLMs
via a large benchmark. We hope it better allows researchers to follow the
state-of-the-art in this very dynamic area. Meanwhile, a growing number of
testbeds have boosted the evolution of general-purpose large language models.
Thus, this year's MARS2 focuses on real-world and specialized scenarios to
broaden the multimodal reasoning applications of MLLMs. Our organizing team
released two tailored datasets Lens and AdsQA as test sets, which support
general reasoning in 12 daily scenarios and domain-specific reasoning in
advertisement videos, respectively. We evaluated 40+ baselines that include
both generalist MLLMs and task-specific models, and opened up three competition
tracks, i.e., Visual Grounding in Real-world Scenarios (VG-RS), Visual Question
Answering with Spatial Awareness (VQA-SA), and Visual Reasoning in Creative
Advertisement Videos (VR-Ads). Finally, 76 teams from the renowned academic and
industrial institutions have registered and 40+ valid submissions (out of
1200+) have been included in our ranking lists. Our datasets, code sets (40+
baselines and 15+ participants' methods), and rankings are publicly available
on the MARS2 workshop website and our GitHub organization page
https://github.com/mars2workshop/, where our updates and announcements of
upcoming events will be continuously provided.

</details>


### [144] [An Exploratory Study on Abstract Images and Visual Representations Learned from Them](https://arxiv.org/abs/2509.14149)
*Haotian Li,Jianbo Jiao*

Main category: cs.CV

TL;DR: 本文研究了原始形状构成的抽象图像能否有效传递视觉语义信息，通过构建分层抽象图像数据集HAID，在不同抽象层次上评估视觉系统的性能表现。


<details>
  <summary>Details</summary>
Motivation: 探索抽象图像（由原始形状构成）与传统栅格图像在传递视觉语义信息方面的性能差距原因，研究不同抽象层次能捕获多少高级语义内容。

Method: 引入分层抽象图像数据集HAID，包含从正常栅格图像生成的多层次抽象图像，在分类、分割和目标检测等任务上训练和评估传统视觉系统。

Result: 提供了栅格化图像与抽象图像表示之间的全面比较研究，分析了抽象图像作为视觉语义信息传递格式的有效性。

Conclusion: 讨论了抽象图像是否可以作为传递视觉语义信息的潜在有效格式，以及其对视觉任务的贡献潜力。

Abstract: Imagine living in a world composed solely of primitive shapes, could you
still recognise familiar objects? Recent studies have shown that abstract
images-constructed by primitive shapes-can indeed convey visual semantic
information to deep learning models. However, representations obtained from
such images often fall short compared to those derived from traditional raster
images. In this paper, we study the reasons behind this performance gap and
investigate how much high-level semantic content can be captured at different
abstraction levels. To this end, we introduce the Hierarchical Abstraction
Image Dataset (HAID), a novel data collection that comprises abstract images
generated from normal raster images at multiple levels of abstraction. We then
train and evaluate conventional vision systems on HAID across various tasks
including classification, segmentation, and object detection, providing a
comprehensive study between rasterised and abstract image representations. We
also discuss if the abstract image can be considered as a potentially effective
format for conveying visual semantic information and contributing to vision
tasks.

</details>


### [145] [BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection](https://arxiv.org/abs/2509.14151)
*Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang*

Main category: cs.CV

TL;DR: BEVUDA++是一个几何感知的师生框架，用于解决鸟瞰图感知中的域适应问题，通过可靠深度教师和几何一致性学生模型来减少多几何空间中的域偏移积累。


<details>
  <summary>Details</summary>
Motivation: 鸟瞰图感知在自动驾驶中很重要，但现有研究忽视了域偏移问题，导致跨域场景下性能显著下降。多几何空间中的域偏移积累是主要挑战。

Method: 提出BEVUDA++框架，包含可靠深度教师(RDT)和几何一致性学生(GCS)模型。RDT融合LiDAR和深度预测生成深度感知信息，GCS将多空间特征映射到统一几何嵌入空间。还引入不确定性引导指数移动平均(UEMA)减少误差积累。

Result: 在四个跨域场景中进行了全面实验，在BEV 3D目标检测任务中达到了最先进性能，日夜间适应任务上NDS提升12.9%，mAP提升9.5%。

Conclusion: 该方法有效解决了BEV感知中的域适应挑战，通过几何感知框架显著提升了跨域场景下的检测性能。

Abstract: Vision-centric Bird's Eye View (BEV) perception holds considerable promise
for autonomous driving. Recent studies have prioritized efficiency or accuracy
enhancements, yet the issue of domain shift has been overlooked, leading to
substantial performance degradation upon transfer. We identify major domain
gaps in real-world cross-domain scenarios and initiate the first effort to
address the Domain Adaptation (DA) challenge in multi-view 3D object detection
for BEV perception. Given the complexity of BEV perception approaches with
their multiple components, domain shift accumulation across multi-geometric
spaces (e.g., 2D, 3D Voxel, BEV) poses a significant challenge for BEV domain
adaptation. In this paper, we introduce an innovative geometric-aware
teacher-student framework, BEVUDA++, to diminish this issue, comprising a
Reliable Depth Teacher (RDT) and a Geometric Consistent Student (GCS) model.
Specifically, RDT effectively blends target LiDAR with dependable depth
predictions to generate depth-aware information based on uncertainty
estimation, enhancing the extraction of Voxel and BEV features that are
essential for understanding the target domain. To collaboratively reduce the
domain shift, GCS maps features from multiple spaces into a unified geometric
embedding space, thereby narrowing the gap in data distribution between the two
domains. Additionally, we introduce a novel Uncertainty-guided Exponential
Moving Average (UEMA) to further reduce error accumulation due to domain shifts
informed by previously obtained uncertainty guidance. To demonstrate the
superiority of our proposed method, we execute comprehensive experiments in
four cross-domain scenarios, securing state-of-the-art performance in BEV 3D
object detection tasks, e.g., 12.9\% NDS and 9.5\% mAP enhancement on Day-Night
adaptation.

</details>


### [146] [Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark](https://arxiv.org/abs/2509.14227)
*Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel*

Main category: cs.CV

TL;DR: Cinéaste是一个用于长视频电影理解的综合基准测试，包含3,119个多选题，涵盖5种细粒度推理类别，现有MLLM模型表现不佳（最高仅63.15%准确率），长时序推理是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注短视频识别或模板化问题，缺乏对长叙事内容的细粒度推理能力评估，需要填补这一空白。

Method: 使用GPT-4o生成多样化、上下文丰富的问题，整合视觉描述、字幕、场景标题和摘要；采用两阶段过滤流程确保问题质量（上下文独立性和事实一致性验证）。

Result: 现有多模态大语言模型在Cinéaste基准上表现困难，最佳开源模型准确率仅为63.15%，长时序推理是主要挑战。

Conclusion: 该研究揭示了细粒度上下文理解和长视频电影理解方面存在的重大挑战，强调了该领域需要进一步技术发展。

Abstract: While recent advancements in vision-language models have improved video
understanding, diagnosing their capacity for deep, narrative comprehension
remains a challenge. Existing benchmarks often test short-clip recognition or
use template-based questions, leaving a critical gap in evaluating fine-grained
reasoning over long-form narrative content. To address these gaps, we introduce
$\mathsf{Cin\acute{e}aste}$, a comprehensive benchmark for long-form movie
understanding. Our dataset comprises 3,119 multiple-choice question-answer
pairs derived from 1,805 scenes across 200 diverse movies, spanning five novel
fine-grained contextual reasoning categories. We use GPT-4o to generate
diverse, context-rich questions by integrating visual descriptions, captions,
scene titles, and summaries, which require deep narrative understanding. To
ensure high-quality evaluation, our pipeline incorporates a two-stage filtering
process: Context-Independence filtering ensures questions require video
context, while Contextual Veracity filtering validates factual consistency
against the movie content, mitigating hallucinations. Experiments show that
existing MLLMs struggle on $\mathsf{Cin\acute{e}aste}$; our analysis reveals
that long-range temporal reasoning is a primary bottleneck, with the top
open-source model achieving only 63.15\% accuracy. This underscores significant
challenges in fine-grained contextual understanding and the need for
advancements in long-form movie comprehension.

</details>


### [147] [GenExam: A Multidisciplinary Text-to-Image Exam](https://arxiv.org/abs/2509.14232)
*Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo*

Main category: cs.CV

TL;DR: GenExam是首个多学科文本到图像考试基准，包含10个学科的1000个样本，采用四级分类的考试风格提示，用于严格评估图像生成模型的知识整合、推理和生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有考试基准主要关注理解和推理任务，而生成基准强调世界知识和视觉概念的展示，缺乏对严格绘图考试的评估。需要一个新的基准来全面评估模型在图像生成考试中的综合能力。

Method: 构建包含1000个样本的多学科文本到图像考试基准，涵盖10个学科，采用考试风格提示和四级分类法。每个问题都配备真实图像和细粒度评分点，用于精确评估语义正确性和视觉合理性。

Result: 实验显示，即使是GPT-Image-1和Gemini-2.5-Flash-Image等最先进模型，严格得分也低于15%，大多数模型得分接近0%，表明该基准具有极大挑战性。

Conclusion: GenExam通过将图像生成框架为考试，提供了对模型知识整合、推理和生成能力的严格评估，为通往通用AGI的道路提供了重要见解。

Abstract: Exams are a fundamental test of expert-level intelligence and require
integrated understanding, reasoning, and generation. Existing exam-style
benchmarks mainly focus on understanding and reasoning tasks, and current
generation benchmarks emphasize the illustration of world knowledge and visual
concepts, neglecting the evaluation of rigorous drawing exams. We introduce
GenExam, the first benchmark for multidisciplinary text-to-image exams,
featuring 1,000 samples across 10 subjects with exam-style prompts organized
under a four-level taxonomy. Each problem is equipped with ground-truth images
and fine-grained scoring points to enable a precise evaluation of semantic
correctness and visual plausibility. Experiments show that even
state-of-the-art models such as GPT-Image-1 and Gemini-2.5-Flash-Image achieve
less than 15% strict scores, and most models yield almost 0%, suggesting the
great challenge of our benchmark. By framing image generation as an exam,
GenExam offers a rigorous assessment of models' ability to integrate knowledge,
reasoning, and generation, providing insights on the path to general AGI.

</details>


<div id='cs.DB'></div>

# cs.DB [[Back]](#toc)

### [148] [The NIAID Discovery Portal: A Unified Search Engine for Infectious and Immune-Mediated Disease Datasets](https://arxiv.org/abs/2509.13524)
*Ginger Tsueng,Emily Bullen,Candice Czech,Dylan Welzel,Leandro Collares,Jason Lin,Everaldo Rodolpho,Zubair Qazi,Nichollette Acosta,Lisa M. Mayer,Sudha Venkatachari,Zorana Mitrović Vučičević,Poromendro N. Burman,Deepti Jain,Jack DiGiovanna,Maria Giovanni,Asiyah Lin,Wilbert Van Panhuis,Laura D. Hughes,Andrew I. Su,Chunlei Wu*

Main category: cs.DB

TL;DR: NIAID数据生态系统发现门户是一个统一的搜索平台，整合了400多万个传染病和免疫介导疾病研究相关数据集，提供用户友好的搜索界面和程序化API访问。


<details>
  <summary>Details</summary>
Motivation: 解决有价值生物医学数据集难以发现和访问的问题，降低数据获取技术门槛，促进数据重用和二次利用。

Method: 整合领域特定和通用存储库的元数据，通过标准化关键元数据字段和协调异构格式，提供过滤器和预构建查询功能。

Result: 建立了集中式可搜索接口，支持不同技术水平的用户发现和重用数据，提高了数据的可发现性、可访问性和可重用性。

Conclusion: 该门户作为IID研究的重要入口点，通过降低数据访问障碍，支持假设生成、比较分析和公共数据的二次使用，最大化公共研究数据的科学影响力。

Abstract: The NIAID Data Ecosystem Discovery Portal (https://data.niaid.nih.gov)
provides a unified search interface for over 4 million datasets relevant to
infectious and immune-mediated disease (IID) research. Integrating metadata
from domain-specific and generalist repositories, the Portal enables
researchers to identify and access datasets using user-friendly filters or
advanced queries, without requiring technical expertise. The Portal supports
discovery of a wide range of resources, including epidemiological, clinical,
and multi-omic datasets, and is designed to accommodate exploratory browsing
and precise searches. The Portal provides filters, prebuilt queries, and
dataset collections to simplify the discovery process for users. The Portal
additionally provides documentation and an API for programmatic access to
harmonized metadata. By easing access barriers to important biomedical
datasets, the NIAID Data Ecosystem Discovery Portal serves as an entry point
for researchers working to understand, diagnose, or treat IID.
  Valuable datasets are often overlooked because they are difficult to locate.
The NIAID Data Ecosystem Discovery Portal fills this gap by providing a
centralized, searchable interface that empowers users with varying levels of
technical expertise to find and reuse data. By standardizing key metadata
fields and harmonizing heterogeneous formats, the Portal improves data
findability, accessibility, and reusability. This resource supports hypothesis
generation, comparative analysis, and secondary use of public data by the IID
research community, including those funded by NIAID. The Portal supports data
sharing by standardizing metadata and linking to source repositories, and
maximizes the impact of public investment in research data by supporting
scientific advancement via secondary use.

</details>


### [149] [Tractability Frontiers of the Shapley Value for Aggregate Conjunctive Queries](https://arxiv.org/abs/2509.13565)
*Christoph Standke,Benny Kimelfeld*

Main category: cs.DB

TL;DR: 本文研究了在聚合合取查询中计算元组Shapley值的复杂度，针对不同聚合函数（min、max、count-distinct、average、quantile）确定了可处理的层次化查询类，并证明了这些类的极大性。


<details>
  <summary>Details</summary>
Motivation: Shapley值作为衡量数据库查询中元组贡献的重要指标，其计算复杂度问题尚未完全解决。之前的研究只解决了sum和count聚合函数的情况，其他常见聚合函数的复杂度仍是开放问题。

Method: 通过识别每个聚合函数对应的层次化查询类，分析在这些类中Shapley值的可计算性，并证明这些类的极大性（即超出这些类的查询在特定值函数下是#P-难的）。

Result: 发现不同聚合函数对应不同的层次化查询类：max、min、count-distinct对应all-hierarchical类，average和quantile对应更严格的q-hierarchical类。每个类都是可处理性的极大类。

Conclusion: 研究为不同聚合函数的Shapley值计算提供了完整的复杂度分类，揭示了从布尔查询到非布尔查询时层次化概念的不同泛化方式，解决了之前提出的开放问题。

Abstract: In recent years, the Shapley value has emerged as a general game-theoretic
measure for assessing the contribution of a tuple to the result of a database
query. We study the complexity of calculating the Shapley value of a tuple for
an aggregate conjunctive query, which applies an aggregation function to the
result of a conjunctive query (CQ) based on a value function that assigns a
number to each query answer. Prior work by Livshits, Bertossi, Kimelfeld, and
Sebag (2020) established that this task is #P-hard for every nontrivial
aggregation function when the query is non-hierarchical with respect to its
existential variables, assuming the absence of self-joins. They further showed
that this condition precisely characterizes the class of intractable CQs when
the aggregate function is sum or count. In addition, they posed as open
problems the complexity of other common aggregate functions such as min, max,
count-distinct, average, and quantile (including median). Towards the
resolution of these problems, we identify for each aggregate function a class
of hierarchical CQs where the Shapley value is tractable with every value
function, as long as it is local (i.e., determined by the tuples of one
relation). We further show that each such class is maximal: for every CQ
outside of this class, there is a local (easy-to-compute) value function that
makes the Shapley value #P-hard. Interestingly, our results reveal that each
aggregate function corresponds to a different generalization of the class of
hierarchical CQs from Boolean to non-Boolean queries. In particular, max, min,
and count-distinct match the class of CQs that are all-hierarchical (i.e.,
hierarchical with respect to all variables), and average and quantile match the
narrower class of q-hierarchical CQs introduced by Berkholz, Keppeler, and
Schweikardt (2017) in the context of the fine-grained complexity of query
answering.

</details>


### [150] [XASDB -- Design and Implementation of an Open-Access Spectral Database](https://arxiv.org/abs/2509.13566)
*Denis Spasyuk*

Main category: cs.DB

TL;DR: XASDB是一个基于网络的X射线吸收光谱数据库平台，提供1000多个参考光谱，支持浏览器端数据处理和可视化，促进FAIR数据原则和协作研究。


<details>
  <summary>Details</summary>
Motivation: 随着同步辐射设施产生的XAS数据量和复杂性不断增加，需要强大的数据管理、共享和分析基础设施来处理多样化的数据格式和促进协作研究。

Method: 采用Node.js/MongoDB架构开发网络平台，集成XASproc JavaScript库进行浏览器端数据处理（归一化、背景扣除、EXAFS提取等），并通过XASVue光谱查看器提供跨设备可视化。

Result: 平台包含40种元素和324种化合物的1000多个参考光谱，支持标准化数据输出、完整元数据和集成分析功能，为线性组合拟合、机器学习和教育提供资源。

Conclusion: XASDB展示了以网络为中心的方法在XAS数据分析中的潜力，加速材料科学、环境研究、化学和生物学领域的进展，同时促进FAIR数据原则的实施。

Abstract: The increasing volume and complexity of X-ray absorption spectroscopy (XAS)
data generated at synchrotron facilities worldwide require robust
infrastructure for data management, sharing, and analysis. This paper
introduces the XAS Database (XASDB), a comprehensive web-based platform
developed and hosted by the Canadian Light Source (CLS). The database houses
more than 1000 reference spectra spanning 40 elements and 324 chemical
compounds. The platform employs a Node.js/MongoDB architecture designed to
handle diverse data formats from multiple beamlines and synchrotron facilities.
A key innovation is the XASproc JavaScript library, which enables browser-based
XAS data processing including normalization, background sub- traction, extended
X-ray absorption fine structure (EXAFS) extraction, and preliminary analysis
traditionally limited to desktop applications. The integrated XASVue spectral
viewer provides installation-free data visualization and analysis with broad
accessibility across devices and operating systems. By offering standardized
data output, comprehensive metadata, and integrated analytical ca- pabilities,
XASDB facilitates collaborative research and promotes FAIR (Findable,
Accessible, In- teroperable, and Reusable) data principles. The platform serves
as a valuable resource for linear combination fitting (LCF) analysis, machine
learning applications, and educational purposes. This initiative demonstrates
the potential for web-centric approaches in XAS data analysis, accelerating
advances in materials science, environmental research, chemistry, and biology.

</details>


### [151] [Algorithms for Optimizing Acyclic Queries](https://arxiv.org/abs/2509.14144)
*Zheng Luo,Wim Van den Broeck,Guy Van den Broeck,Yisu Remy Wang*

Main category: cs.DB

TL;DR: 提出了三种构建无环查询连接树的方法：枚举所有连接树、构建最浅连接树实现并行执行、将左深线性计划转换为连接树以重用二元连接优化基础设施


<details>
  <summary>Details</summary>
Motivation: 传统查询优化主要关注二元连接算法，而理论上最优算法（如Yannakakis算法）需要连接树，这需要新的优化技术

Method: 1. 枚举α-无环查询的所有连接树；2. 使用最大基数搜索算法构建Berge-无环查询的最浅连接树；3. 将γ-无环查询的左深线性计划转换为连接树

Result: 开发了基于成本的优化器基础、实现了大连接查询的并行执行、允许重用现有二元连接优化基础设施

Conclusion: 三种方法为不同类别的无环查询提供了有效的连接树构建方案，推动了理论上最优连接算法在实际查询优化中的应用

Abstract: Most research on query optimization has centered on binary join algorithms
like hash join and sort-merge join. However, recent years have seen growing
interest in theoretically optimal algorithms, notably Yannakakis' algorithm.
These algorithms rely on join trees, which differ from the operator trees for
binary joins and require new optimization techniques. We propose three
approaches to constructing join trees for acyclic queries. First, we give an
algorithm to enumerate all join trees of an alpha-acyclic query by edits with
amortized constant delay, which forms the basis of a cost-based optimizer for
acyclic joins. Second, we show that the Maximum Cardinality Search algorithm by
Tarjan and Yannakakis constructs a unique shallowest join tree, rooted at any
relation, for a Berge-acyclic query; this tree enables parallel execution of
large join queries. Finally, we prove that any connected left-deep linear plan
for a gamma-acyclic query can be converted into a join tree by a simple
algorithm, allowing reuse of optimization infrastructure developed for binary
joins.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [152] [A User-centric Kubernetes-based Architecture for Green Cloud Computing](https://arxiv.org/abs/2509.13325)
*Matteo Zanotto,Leonardo Vicentini,Redi Vreto,Francesco Lumpp,Diego Braga,Sandro Fiore*

Main category: cs.DC

TL;DR: 提出基于Kubernetes的用户中心绿色云计算架构，通过碳强度预测和绿色能源调度，在严格资源限制下可实现13%的排放减少


<details>
  <summary>Details</summary>
Motivation: 数据中心规模增长导致电力消耗和CO2排放增加，云提供商虽接近最优能效但缺乏精确的可持续性报告，需要在用户侧进一步改进

Method: 实现碳强度预测器，利用区域和时间变化调度工作负载，基于绿色能源可用性最小化排放，使用Kubernetes架构

Result: 使用真实云工作负载执行轨迹评估，与轮询调度基线相比，在严格资源限制场景下可实现高达13%的排放减少

Conclusion: 用户中心的绿色云计算架构能有效利用绿色能源变化实现排放优化，为云计算的可持续发展提供了可行方案

Abstract: To meet the increasing demand for cloud computing services, the scale and
number of data centers keeps increasing worldwide. This growth comes at the
cost of increased electricity consumption, which directly correlates to CO2
emissions, the main driver of climate change. As such, researching ways to
reduce cloud computing emissions is more relevant than ever. However, although
cloud providers are reportedly already working near optimal power efficiency,
they fail in providing precise sustainability reporting. This calls for further
improvements on the cloud computing consumer's side. To this end, in this paper
we propose a user-centric, Kubernetes-based architecture for green cloud
computing. We implement a carbon intensity forecaster and we use it to schedule
workloads based on the availability of green energy, exploiting both regional
and temporal variations to minimize emissions. We evaluate our system using
real-world traces of cloud workloads execution comparing the achieved carbon
emission savings against a baseline round-robin scheduler. Our findings
indicate that our system can achieve up to a 13% reduction in emissions in a
strict scenario with heavy limitations on the available resources.

</details>


### [153] [LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology](https://arxiv.org/abs/2509.13978)
*Renan Souza,Timothy Poteet,Brian Etz,Daniel Rosendo,Amal Gueroudji,Woong Shin,Prasanna Balaprakash,Rafael Ferreira da Silva*

Main category: cs.DC

TL;DR: 使用LLM代理进行交互式资源数据分析，通过自然语言转换为结构化查询，解决大规模工作流跟踪数据分析难题


<details>
  <summary>Details</summary>
Motivation: 现代科学发现依赖于跨边缘-云-HPC连续体的工作流，但大规模跟踪数据复杂难以分析，现有系统依赖自定义脚本和静态仪表板，限制了数据交互

Method: 提出评估方法、参考架构和开源实现，采用轻量级元数据驱动设计，将自然语言翻译为结构化跟踪查询，测试LLaMA、GPT、Gemini、Claude等多种LLM

Result: 模块化设计、提示调整和RAG技术能够实现准确且有深度的LLM代理响应，超越了记录的跟踪数据范围

Conclusion: 交互式LLM代理为大规模工作流跟踪数据分析提供了有效解决方案，通过自然语言接口提升了数据交互能力和分析效果

Abstract: Modern scientific discovery increasingly relies on workflows that process
data across the Edge, Cloud, and High Performance Computing (HPC) continuum.
Comprehensive and in-depth analyses of these data are critical for hypothesis
validation, anomaly detection, reproducibility, and impactful findings.
Although workflow provenance techniques support such analyses, at large scale,
the provenance data become complex and difficult to analyze. Existing systems
depend on custom scripts, structured queries, or static dashboards, limiting
data interaction. In this work, we introduce an evaluation methodology,
reference architecture, and open-source implementation that leverages
interactive Large Language Model (LLM) agents for runtime data analysis. Our
approach uses a lightweight, metadata-driven design that translates natural
language into structured provenance queries. Evaluations across LLaMA, GPT,
Gemini, and Claude, covering diverse query classes and a real-world chemistry
workflow, show that modular design, prompt tuning, and Retrieval-Augmented
Generation (RAG) enable accurate and insightful LLM agent responses beyond
recorded provenance.

</details>


### [154] [Testing and benchmarking emerging supercomputers via the MFC flow solver](https://arxiv.org/abs/2509.13575)
*Benjamin Wilfong,Anand Radhakrishnan,Henry A. Le Berre,Tanush Prathi,Stephen Abbott,Spencer H. Bryngelson*

Main category: cs.DC

TL;DR: MFC是一个计算流体动力学代码，配备了自动化工具链，用于评估不同编译器-硬件组合的正确性和性能，已在约50个计算设备和5个旗舰超级计算机上进行基准测试。


<details>
  <summary>Details</summary>
Motivation: 部署新超级计算机需要通过应用程序代码进行测试和评估，需要便携、用户友好的工具来简化这一过程。

Method: 使用MFC代码及其自动化工具链，包括输入生成、编译、批处理作业提交、回归测试和基准测试功能，评估不同GPU和CPU架构的性能。

Result: 测试了五代NVIDIA GPU、三代AMD GPU和各种CPU架构，发现了Frontier和El Capitan等新机器上的编译器错误和回归问题。

Conclusion: MFC及其工具链为评估编译器-硬件组合提供了有效的解决方案，即使对于软件工程经验有限的用户也能进行正确性和性能评估。

Abstract: Deploying new supercomputers requires testing and evaluation via application
codes. Portable, user-friendly tools enable evaluation, and the Multicomponent
Flow Code (MFC), a computational fluid dynamics (CFD) code, addresses this
need. MFC is adorned with a toolchain that automates input generation,
compilation, batch job submission, regression testing, and benchmarking. The
toolchain design enables users to evaluate compiler-hardware combinations for
correctness and performance with limited software engineering experience. As
with other PDE solvers, wall time per spatially discretized grid point serves
as a figure of merit. We present MFC benchmarking results for five generations
of NVIDIA GPUs, three generations of AMD GPUs, and various CPU architectures,
utilizing Intel, Cray, NVIDIA, AMD, and GNU compilers. These tests have
revealed compiler bugs and regressions on recent machines such as Frontier and
El Capitan. MFC has benchmarked approximately 50 compute devices and 5 flagship
supercomputers.

</details>


### [155] [Modeling the Carbon Footprint of HPC: The Top 500 and EasyC](https://arxiv.org/abs/2509.13583)
*Varsha Rao,Andrew A. Chien*

Main category: cs.DC

TL;DR: 这篇论文使用EasyC工具对Top500超算系统进行碳踹计算，估算出运营碳排放为13.937亿吨CO2e，体现碳排放为18.818亿吨CO2e，并预测了2030年的增长趋势。


<details>
  <summary>Details</summary>
Motivation: HPC系统的碳踹计算面临数据不足的挑战，现有GHG协议方法难以应用于单个或集群系统，导致缺乏HPC行业广泛的碳排放报告。

Method: 利用Top500.org公开数据，通过新开发的EasyC工具建立碳踹模型，对391个系统进行运营碳排放分析和283个系统进行体现碳排放分析，并通过插值法推算整个Top500的碳踹。

Result: 成功建模并估算Top500系统的碳踹：运营碳13.937亿吨CO2e/年，体现碳18.818亿吨CO2e。通过数据增强技术可将覆盖率提升到运营碳98%和体现碳80.8%。

Conclusion: 这是首次对Top500超算系统进行全面的碳踹估算，EasyC工具以最少的数据要求实现了高覆盖率的碳踹模型，为HPC行业的碳踹管理和减排提供了重要基础。

Abstract: Climate change is a critical concern for HPC systems, but GHG protocol
carbon-emission accounting methodologies are difficult for a single system, and
effectively infeasible for a collection of systems. As a result, there is no
HPC-wide carbon reporting, and even the largest HPC sites do not do GHG
protocol reporting.
  We assess the carbon footprint of HPC, focusing on the Top 500 systems. The
key challenge lies in modeling the carbon footprint with limited data
availability.
  With the disclosed Top500.org data, and using a new tool, EasyC, we were able
to model the operational carbon of 391 HPC systems and the embodied carbon of
283 HPC systems. We further show how this coverage can be enhanced by
exploiting additional public information. With improved coverage, then
interpolation is used to produce the first carbon footprint estimates of the
Top 500 HPC systems. They are 1,393.7 million MT CO2e operational carbon (1
Year) and 1,881.8 million MT CO2e embodied carbon. We also project how the Top
500's carbon footprint will increase through 2030.
  A key enabler is the EasyC tool which models carbon footprint with only a few
data metrics. We explore availability of data and enhancement, showing that
coverage can be increased to 98% of Top 500 systems for operational and 80.8%
of the systems for embodied emissions.

</details>


### [156] [GPU Programming for AI Workflow Development on AWS SageMaker: An Instructional Approach](https://arxiv.org/abs/2509.13703)
*Sriram Srinivasan,Hamdan Alabsi,Rand Obeidat,Nithisha Ponnala,Azene Zenebe*

Main category: cs.DC

TL;DR: 这是一个关于GPU架构和编程专业课程的教学研究，通过AWS平台进行实践教学，培养学生GPU编程和AI应用能力


<details>
  <summary>Details</summary>
Motivation: 为了准备STEM学生满足现代计算密集领域的需求，整合并行计算到教育中，提升学生的技术技能和解决问题能力

Method: 开设GPU架构和编程专业课程，从基础GPU/CPU硬件和并行计算开始，进行RAG开发和GPU优化，让学生实践云端GPU实例配置、并行算法实现和AI解决方案部署

Result: 评估结果显示：(1)AWS是高效经济的GPU编程实践平台；(2)实践学习显著提升技术技能和学习参与度；(3)通过TensorBoard和HPC分析工具增强了学生的问题解决能力

Conclusion: 并行计算整合到STEM教育具有重要教育价值，应在更广泛的STEM课程中推广类似选修课程，以满足现代计算密集领域的人才需求

Abstract: We present the design, implementation, and comprehensive evaluation of a
specialized course on GPU architecture, GPU programming, and how these are used
for developing AI agents. This course is offered to undergraduate and graduate
students during Fall 2024 and Spring 2025. The course began with foundational
concepts in GPU/CPU hardware and parallel computing and progressed to develop
RAG and optimizing them using GPUs. Students gained experience provisioning and
configuring cloud-based GPU instances, implementing parallel algorithms, and
deploying scalable AI solutions. We evaluated learning outcomes through
assessments, course evaluations, and anonymous surveys. The results reveal that
(1) AWS served as an effective and economical platform for practical GPU
programming, (2) experiential learning significantly enhanced technical
proficiency and engagement, and (3) the course strengthened students'
problem-solving and critical thinking skills through tools such as TensorBoard
and HPC profilers, which exposed performance bottlenecks and scaling issues.
Our findings underscore the pedagogical value of integrating parallel computing
into STEM education. We advocate for broader adoption of similar electives
across STEM curricula to prepare students for the demands of modern,
compute-intensive fields.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [157] [GRU-Based Learning for the Identification of Congestion Protocols in TCP Traffic](https://arxiv.org/abs/2509.13490)
*Paul Bergeron,Sandhya Aneja*

Main category: cs.NI

TL;DR: 使用GRU神经网络模型在Marist大学校园网络中识别TCP Reno、TCP Cubic、TCP Vegas和BBR拥塞控制协议，准确率达到97.04%


<details>
  <summary>Details</summary>
Motivation: 在更复杂和竞争性的网络环境中，使用更快的神经网络架构来准确识别不同的拥塞控制协议

Method: 采用基于GRU（门控循环单元）的学习模型，构建了更快的神经网络架构

Result: 在Marist大学校园网络中实现了97.04%的识别准确率，与现有工作相比获得了相当高的准确性

Conclusion: GRU-based模型在复杂网络环境下能够有效识别多种TCP拥塞控制协议，具有很高的准确性和实用性

Abstract: This paper presents the identification of congestion control protocols TCP
Reno, TCP Cubic, TCP Vegas, and BBR on the Marist University campus, with an
accuracy of 97.04% using a GRU-based learning model. We used a faster neural
network architecture on a more complex and competitive network in comparison to
existing work and achieved comparably high accuracy.

</details>


### [158] [Odin: Effective End-to-End SLA Decomposition for 5G/6G Network Slicing via Online Learning](https://arxiv.org/abs/2509.13511)
*Duo Cheng,Ramanujan K Sheshadri,Ahan Kak,Nakjung Choi,Xingyu Zhou,Bo Ji*

Main category: cs.NI

TL;DR: Odin是一个基于贝叶斯优化的SLA分解方案，通过各域的在线反馈实现高效的端到端SLA分解，在SLA满足率上比基线方法提升45%，同时降低资源成本。


<details>
  <summary>Details</summary>
Motivation: 5G/6G网络切片需要满足端到端SLA要求，但由于域间异构性、动态网络条件以及SLA编排器不了解域内资源优化，SLA分解面临重大挑战。

Method: 提出基于贝叶斯优化的Odin解决方案，利用各域的在线反馈进行可证明高效的SLA分解。

Result: 理论分析和严格评估表明，Odin的端到端编排器在SLA满足率上比基线解决方案提升高达45%，同时降低总体资源成本，即使在存在域间噪声反馈的情况下也能保持性能。

Conclusion: Odin通过贝叶斯优化方法有效解决了跨域SLA分解的挑战，显著提升了SLA满足率和资源利用效率。

Abstract: Network slicing plays a crucial role in realizing 5G/6G advances, enabling
diverse Service Level Agreement (SLA) requirements related to latency,
throughput, and reliability. Since network slices are deployed end-to-end
(E2E), across multiple domains including access, transport, and core networks,
it is essential to efficiently decompose an E2E SLA into domain-level targets,
so that each domain can provision adequate resources for the slice. However,
decomposing SLAs is highly challenging due to the heterogeneity of domains,
dynamic network conditions, and the fact that the SLA orchestrator is oblivious
to the domain's resource optimization. In this work, we propose Odin, a
Bayesian Optimization-based solution that leverages each domain's online
feedback for provably-efficient SLA decomposition. Through theoretical analyses
and rigorous evaluations, we demonstrate that Odin's E2E orchestrator can
achieve up to 45% performance improvement in SLA satisfaction when compared
with baseline solutions whilst reducing overall resource costs even in the
presence of noisy feedback from the individual domains.

</details>


### [159] [A Framework for Multi-source Prefetching Through Adaptive Weight](https://arxiv.org/abs/2509.13604)
*Yoseph Berhanu Alebachew,Mulugeta Libsie*

Main category: cs.NI

TL;DR: 这篇论文提出了一种新的预取框架，能够集成基于访问历史和语义信息的两种预取策略，通过适应性权重管理来提高预测准确性并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决网页访问延迟问题，现有预取技术对应用层级文档关系的利用有限，且无法有效结合基于访问历史和语义信息的两种方法。

Method: 设计了一种可扩展框架，允许任何预取算法作为生成待访问对象列表的组件集成。框架通过适应性权重管理技术，根据每个算法的实际表现动态调整其在整体预测中的影响程度。

Result: 该框架比现有方案更为节制（less aggressive），特别适合资源受限的移动设备使用。

Conclusion: 这种新型预取框架能够有效结合不同预取策略的优势，提高了预测准确性的同时减少资源消耗，尤其适用于移动设备环境。

Abstract: The World Wide Web has come to be a great part of our daily life, yet user
observed latency is still a problem that needs a proper means of handling. Even
though earlier attempts focused on caching as the chief solution to tackling
this issue, its success was extremely limited. Prefetching has come to be the
primary technique in supplementing caching towards soothing the latency problem
associated with the contemporary Internet. However, existing approaches in
prefetching are extremely limited in their ability to employ application level
web document relationship which is often visible only to the content developer.
This is because most approaches are access history based schemes that make
future users' access prediction only based on past user access. Attempts to
incorporate prefetching schemes that utilize semantic information with those
that use users past access history are extremely limited in their
extensibility. In this work we present a novel framework that enables
integration of schemes from both worlds of prefetching without the need for a
major modification to the algorithms. When there is a need/possibility to
capture new application level context, a new algorithm could be developed to do
so and then it can be integrated into the framework. Since each participating
scheme is merely viewed as an algorithm that produces a list of candidate
objects that are likely to be accessed in the near future, the framework can
entertain any one of the existing prefetching schemes. With its adaptive weight
management technique the framework adjusts the effect of each algorithm in the
overall prediction to parallel with its observed performance so far. We have
found this formwork to be less aggressive than its contemporary counterparts
which is extremely important for resource constrained mobile devices that have
come to be the major means of access by users of the current web.

</details>


### [160] [LINC: An In-Network Coding Approach to Tame Packet Loss in Hybrid Wireless-Fiber Backbones](https://arxiv.org/abs/2509.13714)
*Benoit Pit-Claudel,Muriel Médard,Manya Ghobadi*

Main category: cs.NI

TL;DR: LINC是一个在混合骨干网络中提供网络内网络编码能力的系统，无需终端主机配合即可缓解环境丢包问题，通过逐链路系统块编码减少不必要的重传，降低端到端延迟达18%。


<details>
  <summary>Details</summary>
Motivation: 混合骨干网络（光纤、卫星、微波）虽然提供低延迟，但存在环境丢包问题（恶劣天气、施工、视线阻挡）。传统传输协议将丢包误判为网络拥塞，而现有网络编码方案需要终端主机完全配合。

Method: LINC采用逐链路的系统块编码方法，在网络内部进行数据包编码和解码操作。建立了端到端重传与冗余数据包之间的吞吐量权衡模型，并提出优化公式来确定最佳编码参数。

Result: 在真实骨干网络拓扑上的模拟显示，LINC通过消除不必要的重传，将端到端延迟降低了高达18%。

Conclusion: LINC系统成功解决了混合骨干网络中的环境丢包问题，无需终端主机修改即可提供有效的网络内编码解决方案，显著提升了网络性能。

Abstract: The emergence of ultra-low latency applications, such as financial
transactions, has driven the development of hybrid backbone networks that rely
on fiber, satellite, and microwave links. Despite providing low latencies,
these hybrid networks suffer from occasional environmental packet loss caused
by poor weather, construction, and line of sight blockage. Paradoxically,
today's hybrid backbones rely on conventional transport protocols that take
packet loss to signal network congestion, as opposed to transient environmental
obstacles. A common approach to address this challenge is to use network coding
(NC) between the end hosts to recover from these occasional packet loss events.
However, current NC proposals assume full access to the end-hosts' stack to
perform end-to-end encoding/decoding operations. In this paper, we introduce
LINC, a novel system that provides in-network NC capabilities to mitigate
environmental packet loss events without requiring cooperation from the end
hosts. LINC uses a systematic block coding approach on a link-by-link basis,
encoding and decoding packets inside the network. We model the tradeoff in
goodput between end-to-end retransmissions and redundant packets introduced by
LINC, and propose an optimization formulation to determine the optimal choice
of coding parameters. Our simulations on real-world backbone topologies
demonstrate that LINC reduces the end-to-end latency by up to 18% by
eliminating unnecessary retransmissions.

</details>


### [161] [Conducting Mission-Critical Voice Experiments with Automated Speech Recognition and Crowdsourcing](https://arxiv.org/abs/2509.13724)
*Jan Janak,Kahlil Dozier,Lauren Berny,Liang Hu,Dan Rubenstein,Charles Jennings,Henning Schulzrinne*

Main category: cs.NI

TL;DR: 本文研究为公共安全聚焦的关键语音通信系统开发了在模拟真实环境中进行人体实验的方法论和工具，通过Levenshtein距离指标评估用户体验质量，并比较了人类与自动语音识别系统的性能差异。


<details>
  <summary>Details</summary>
Motivation: 公共安全用户需要关键语音通信系统在挑战性条件下供可靠服务，但现有研究在模拟真实环境和批准用户体验质量指标方面遇到挑战。

Method: 开发了包括模拟真实环境的关键语音通信测试床和自动语音识别机器人的工具，通过Amazon MTurk引擎进行人体实验研究，使用Levenshtein距离作为用户体验质量的代理指标。

Result: 发现人类在关键语音任务中的准确性通常超过自动语音识别系统，编码器对用户体验质量和自动语音识别性能有显著影响。

Conclusion: 研究为关键语音通信系统的用户体验质量评估提供了有效的方法论和工具，Levenshtein距离是衡量理解度和用户体验的合适指标，且人类在关键语音任务中仍然保持优势。

Abstract: Mission-critical voice (MCV) communications systems have been a critical tool
for the public safety community for over eight decades. Public safety users
expect MCV systems to operate reliably and consistently, particularly in
challenging conditions. Because of these expectations, the Public Safety
Communications Research (PSCR) Division of the National Institute of Standards
and Technology (NIST) has been interested in correlating impairments in MCV
communication systems and public safety user quality of experience (QoE).
Previous research has studied MCV voice quality and intelligibility in a
controlled environment. However, such research has been limited by the
challenges inherent in emulating real-world environmental conditions.
Additionally, there is the question of the best metric to use to reflect QoE
accurately.
  This paper describes our efforts to develop the methodology and tools for
human-subject experiments with MCV. We illustrate their use in human-subject
experiments in emulated real-world environments. The tools include a testbed
for emulating real-world MCV systems and an automated speech recognition (ASR)
robot approximating human subjects in transcription tasks. We evaluate QoE
through a Levenshtein Distance-based metric, arguing it is a suitable proxy for
measuring comprehension and the QoE. We conducted human-subject studies with
Amazon MTurk volunteers to understand the influence of selected system
parameters and impairments on human subject performance and end-user QoE. We
also compare the performance of several ASR system configurations with
human-subject performance. We find that humans generally perform better than
ASR in accuracy-related MCV tasks and that the codec significantly influences
the end-user QoE and ASR performance.

</details>


### [162] [Performance Evaluation of Intent-Based Networking Scenarios: A GitOps and Nephio Approach](https://arxiv.org/abs/2509.13901)
*Saptarshi Ghosh,Ioannis Mavromatis,Konstantinos Antonakoglou,Konstantinos Katsaros*

Main category: cs.NI

TL;DR: 本文通过可复现的指标化测试，评估了Argo CD、Flux CD和ConfigSync三种GitOps运算器在意图网络场景下的性能表现和资源开销，为自主网络系统的工具选型提供价值见解。


<details>
  <summary>Details</summary>
Motivation: GitOps在云原生基础设施管理中广泛采用，但其工具在意图基础网络(IBN)场景下的性能和可扩展性评估不足，需要系统性能测试来指导工具选型和优化。

Method: 进行可复现的指标化测试，在单意图和多意图场景下测诙三种GitOps运算器的延迟和资源消耗，并使用Nephio作为系统调度器进行实际组织场景测试。

Result: 结果显示了各工具在确定性、资源效率和响应能力方面的特性和交易特性，量化了声明式端到端部署流程中的处理延迟和开销。

Conclusion: 研究结果为未来自主网络组织系统的工具选型和优化提供了有价值的见解和指导。

Abstract: GitOps has emerged as a foundational paradigm for managing cloud-native
infrastructures by enabling declarative configuration, version-controlled
state, and automated reconciliation between intents and runtime deployments.
Despite its widespread adoption, the performance and scalability of GitOps
tools in Intent-Based Networking (IBN) scenarios are insufficiently evaluated.
This paper presents a reproducible, metric-driven benchmarking, assessing the
latency and resource overheads of three widely used GitOps operators: Argo CD,
Flux CD, and ConfigSync. We conduct controlled experiments under both single-
and multi-intent scenarios, capturing key performance indicators such as
latency and resource consumption. Our results highlight trade-offs between the
tools in terms of determinism, resource efficiency, and responsiveness. We
further investigate a realistic orchestration scenario, using Nephio as our
orchestrator, to quantify the processing latency and overhead in declarative
end-to-end deployment pipelines. Our findings can offer valuable insights for
tool selection and optimisation in future autonomous network orchestration
systems.

</details>


### [163] [Low-cost Highly-interoperable Multiplatform Campus Network: Experience of YARSI University](https://arxiv.org/abs/2509.13954)
*Surya Agustian,Sandra Permana,Salman Teguh Pratista,Syarifu Adam,Iswandi*

Main category: cs.NI

TL;DR: 基于开源系统和Cisco交换技术的低成本校园网设计方案，通过广推网关和无线访问分享，为预算有限的组织提供经济的网络解决方案


<details>
  <summary>Details</summary>
Motivation: 解决组织建设校园网络成本高、缺乏IT知识导致外包费用过高的问题，为预算有限的机构提供可行的网络解决方案

Method: 组建CMIS中心，结合开源操作系统和本地组装PC作为网关/路由器，采用Cisco交换技术设计UTP基础校园网，通过广推网关系统分享广带连接和专用无线访问

Result: 成功为100多名同时用户提供网络访问，显著降低了网络基础设施的购买、维护和运营成本，同时降低了互联网访问成本

Conclusion: 该低成本校园网设计模型可以在农村社区或预算有限的组织中推广应用，为类似的组织提供经济的互联网访问解决方案

Abstract: To some organizations, building campus network is sometimes considered to be
very expensive; and this has made the project uneasy to perform. Moreover, if
the organization without sufficient IT knowledge does not have capable IT
engineers, leaving this project to third parties without supervision would lead
to unexpected larger expenses. For this reason, in the year of 2003, YARSI
University formed CMIS (Center for Management Infor-mation System) to perform
tasks in designing, operations and maintenance of campus network and its
services. By combining Open Source operating system run on a local assembled
personal computer as gateway and router, and switching technology from Cisco,
we designed a low-cost UTP-based campus network which covering rooms and
buildings in YARSI environment. Meanwhile the internet access through several
broadband connections and dedicated wireless was shared to more than 100
simultaneous users by a captive portal system. With this strategy, we can
significantly reduce cost for purchasing, maintenance and operations of network
infrastructure and internet access. Our model in designing low-cost campus
network and internet connections could be adopted by rural community or
organizations that have limited budget to have internet access.

</details>


### [164] [Path-Oblivious Entanglement Swapping for the Quantum Internet](https://arxiv.org/abs/2509.13993)
*Vincent Mutolo,Rhea Parekh,Dan Rubenstein*

Main category: cs.NI

TL;DR: 这篇论文提出了路径无知的豫尔对交换协议，让量子网络中的豫尔对交换不再依赖预先预置的路由路径，而是通过线性规划平衡网络中的豫尔对分布。


<details>
  <summary>Details</summary>
Motivation: 传统的豫尔对交换协议需要预先预置特定路由路径，但随着量子状态变得更便宜和稳定，这种偏保守的方法可能不再最优。从经典网络中获得的经验显示，灵活的无预置方案在资源充足的网络中通常表现更好。

Method: 将豫尔对交换过程形式化为线性规划问题，并提出了一个基准协议，通过尽量平衡网络中的豫尔对分布来实现路径无知的交换。

Result: 初步结果显示，虽然简单的平衡策略还有改进空间，但路径无知的豫尔对交换是一个有前景的研究方向。

Conclusion: 随着量子技术的发展，豫尔对交换协议应进化向更灵活的路径无知方案，而不是依赖传统的预先路由预置方式。

Abstract: Proposed Bell pair swapping protocols, an essential component of the Quantum
Internet, are planned-path: specific, structured, routing paths are reserved
prior to the execution of the swapping process. This makes sense when one
assumes the state used in the swapping process is expensive, fragile, and
unstable. However, lessons from classical networking have shown that while
reservations seem promising in concept, flexible, reservation-light or free
approaches often outperform their more restrictive counterparts in
well-provisioned networks. In this paper, we propose that a path-oblivious
approach is more amenable to supporting swapping as quantum state evolves into
a cheaper, more robust form. We formulate the swapping process as a linear
program and present and evaluate a fairly naive baseline swapping protocol that
tries to balance Bell pairs throughout the network. Preliminary results show
that while naive balancing leaves room for improvement, investigating
path-oblivious swapping is a promising direction.

</details>


### [165] [RepCaM++: Exploring Transparent Visual Prompt With Inference-Time Re-Parameterization for Neural Video Delivery](https://arxiv.org/abs/2509.14002)
*Rongyu Zhang,Xize Duan,Jiaming Liu,Li Du,Yuan Du,Dan Wang,Shanghang Zhang,Fangxin Wang*

Main category: cs.NI

TL;DR: RepCaM++是一个基于重参数化内容感知调制模块的创新框架，通过并行级联参数训练和推理时重参数化技术，解决了传统内容感知方法在长视频中参数累积和性能下降的问题，结合透明视觉提示技术，在视频恢复质量和带宽压缩方面达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 传统内容感知方法为每个视频块训练单独的SR模型会导致参数累积，随着视频长度增加会出现适应性问题，导致传输成本增加和性能下降，需要一种更高效的统一调制框架。

Method: 提出RepCaM++框架，基于重参数化内容感知调制模块，在训练时集成并行级联参数适应多个视频块，推理时通过重参数化消除额外参数；同时引入透明视觉提示(TVP)技术，使用极少量零初始化图像级参数捕捉视频块细节。

Result: 在VSD4K数据集（包含6种不同视频场景）上进行广泛实验，在视频恢复质量和传输带宽压缩方面取得了最先进的结果。

Conclusion: RepCaM++框架通过重参数化技术和透明视觉提示，有效解决了长视频内容感知SR中的参数累积问题，实现了更好的性能表现和带宽效率。

Abstract: Recently, content-aware methods have been employed to reduce bandwidth and
enhance the quality of Internet video delivery. These methods involve training
distinct content-aware super-resolution (SR) models for each video chunk on the
server, subsequently streaming the low-resolution (LR) video chunks with the SR
models to the client. Prior research has incorporated additional partial
parameters to customize the models for individual video chunks. However, this
leads to parameter accumulation and can fail to adapt appropriately as video
lengths increase, resulting in increased delivery costs and reduced
performance. In this paper, we introduce RepCaM++, an innovative framework
based on a novel Re-parameterization Content-aware Modulation (RepCaM) module
that uniformly modulates video chunks. The RepCaM framework integrates extra
parallel-cascade parameters during training to accommodate multiple chunks,
subsequently eliminating these additional parameters through
re-parameterization during inference. Furthermore, to enhance RepCaM's
performance, we propose the Transparent Visual Prompt (TVP), which includes a
minimal set of zero-initialized image-level parameters (e.g., less than 0.1%)
to capture fine details within video chunks. We conduct extensive experiments
on the VSD4K dataset, encompassing six different video scenes, and achieve
state-of-the-art results in video restoration quality and delivery bandwidth
compression.

</details>


<div id='cs.PL'></div>

# cs.PL [[Back]](#toc)

### [166] [Catalpa: GC for a Low-Variance Software Stack](https://arxiv.org/abs/2509.13429)
*Anthony Arnold,Mark Marron*

Main category: cs.PL

TL;DR: 提出Catalpa垃圾收集器，为Bosque语言设计，旨在最小化延迟和变异性，同时保持高吞吐量和低内存开销


<details>
  <summary>Details</summary>
Motivation: 实际应用中性能是二元的（快/慢），工业开发者更关注95/99百分位尾延迟而非平均响应时间，需要软件栈支持这种需求

Method: 利用Bosque语言的不变性和无引用循环特性，设计无界收集暂停、固定内存开销、无需屏障或同步的收集器

Result: Catalpa收集器实现了有界收集暂停、固定常数内存开销，且不需要与应用代码进行同步

Conclusion: 通过编程语言和运行时系统设计可以构建支持低延迟需求的软件栈，Catalpa收集器为此提供了有效解决方案

Abstract: The performance of an application/runtime is usually conceptualized as a
continuous function where, the lower the amount of memory/time used on a given
workload, then the better the compiler/runtime is. However, in practice, good
performance of an application is viewed as more of a binary function - either
the application responds in under, say 100 ms, and is fast enough for a user to
barely notice, or it takes a noticeable amount of time, leaving the user
waiting and potentially abandoning the task. Thus, performance really means how
often the application is fast enough to be usable, leading industrial
developers to focus on the 95th and 99th percentile tail-latencies as heavily,
or moreso, than average response time. Our vision is to create a software stack
that actively supports these needs via programming language and runtime system
design. In this paper we present a novel garbage-collector design, the Catalpa
collector, for the Bosque programming language and runtime. This allocator is
designed to minimize latency and variability while maintaining high-throughput
and incurring small memory overheads. To achieve these goals we leverage
various features of the Bosque language, including immutability and
reference-cycle freedom, to construct a collector that has bounded collection
pauses, incurs fixed-constant memory overheads, and does not require any
barriers or synchronization with application code.

</details>


### [167] [Extended Abstract: Towards a Performance Comparison of Syntax and Type-Directed NbE](https://arxiv.org/abs/2509.13489)
*Chester J. F. Gould,William J. Bowman*

Main category: cs.PL

TL;DR: 这是一个进行中的工作，研究两种类型检查方法的性能对比，通过建立直接可比的平台来量化语法指向和类型指向方法的性能差异。


<details>
  <summary>Details</summary>
Motivation: 目前依赖类型检查器中，类型相等性检查的方法存在两种主要方法：语法指向和类型指向。虽然普遍认为语法指向方法性能更好而类型指向方法表达力更强，但由于实现通常只选择其中一种方法，导致无法进行直接的对比。

Method: 开发一个实际的平台，支持同时实现语法指向和类型指向两种类型相等性检查方法，以进行直接的、可比的性能分析。

Result: 这是一个进行中的工作，目前还没有最终的实验结果。预计将量化类型指向方法相比语法指向方法的性能差异，并分析性能差异的原因和改进方法。

Conclusion: 通过建立直接可比的实验平台，这项研究有助于准确评估两种类型相等性检查方法的性能差异，为依赖类型检查器的性能优化提供侦查基础。

Abstract: A key part of any dependent type-checker is the method for checking whether
two types are equal. A common claim is that syntax-directed equality is more
performant, although type-directed equality is more expressive. However, this
claim is difficult to make precise, since implementations choose only one or
the other approach, making a direct comparison impossible. We present some
work-in-progress developing a realistic platform for direct, apples-to-apples,
comparison of the two approaches, quantifying how much slower type-directed
equality checking is, and analyzing why and how it can be improved.

</details>


### [168] [CLMTracing: Black-box User-level Watermarking for Code Language Model Tracing](https://arxiv.org/abs/2509.13982)
*Boyu Zhang,Ping He,Tianyu Du,Xuhong Zhang,Lei Yun,Kingsum Chow,Jianwei Yin*

Main category: cs.PL

TL;DR: CLMTracing是一个黑盒代码语言模型水印框架，通过规则水印和保持实用性的注入方法实现用户级模型追踪，具有强鲁棒性对抗移除攻击。


<details>
  <summary>Details</summary>
Motivation: 随着开源代码语言模型的广泛采用，知识产权保护变得日益重要。现有水印技术在面对更实际复杂的黑盒设置下用户级追踪需求时存在局限性。

Method: 采用基于规则的水印和保持实用性的注入方法，结合对鲁棒水印敏感的参数选择算法和对抗训练来增强对水印移除攻击的鲁棒性。

Result: 综合评估表明CLMTracing在多个最先进代码语言模型上有效，相比现有基线显示出显著的无害改进，并对各种移除攻击具有强鲁棒性。

Conclusion: CLMTracing提供了一个有效的黑盒水印解决方案，能够实现用户级模型追踪，解决了当前代码语言模型知识产权保护的实际需求。

Abstract: With the widespread adoption of open-source code language models (code LMs),
intellectual property (IP) protection has become an increasingly critical
concern. While current watermarking techniques have the potential to identify
the code LM to protect its IP, they have limitations when facing the more
practical and complex demand, i.e., offering the individual user-level tracing
in the black-box setting. This work presents CLMTracing, a black-box code LM
watermarking framework employing the rule-based watermarks and
utility-preserving injection method for user-level model tracing. CLMTracing
further incorporates a parameter selection algorithm sensitive to the robust
watermark and adversarial training to enhance the robustness against watermark
removal attacks. Comprehensive evaluations demonstrate CLMTracing is effective
across multiple state-of-the-art (SOTA) code LMs, showing significant harmless
improvements compared to existing SOTA baselines and strong robustness against
various removal attacks.

</details>


### [169] [Parallelizable Feynman-Kac Models for Universal Probabilistic Programming](https://arxiv.org/abs/2509.14092)
*Michele Boreale,Luisa Collodi*

Main category: cs.PL

TL;DR: 本文为概率程序开发了基于自动机理论的向量化粒子滤波算法VPF，证明了其语义一致性和有限近似定理，实验显示优于现有推理工具


<details>
  <summary>Details</summary>
Motivation: 研究如何在具有任意采样和无界循环的概率程序中实现可证明正确且高效的序列蒙特卡洛推理方法

Method: 首先为概率程序图(PPGs)建立基于无限执行轨迹的期望语义，证明有限近似定理，构建Feynman-Kac模型框架，最终提出向量化粒子滤波算法VPF

Result: 实验证明VPF算法相比最先进的概率程序推理工具表现出非常有前景的结果

Conclusion: 通过形式化语义和理论保证，成功开发了适用于通用概率程序的高效向量化推理算法VPF

Abstract: We study provably correct and efficient instantiations of Sequential Monte
Carlo (SMC) inference in the context of formal operational semantics of
Probabilistic Programs (PPs). We focus on universal PPs featuring sampling from
arbitrary measures and conditioning/reweighting in unbounded loops. We first
equip Probabilistic Program Graphs (PPGs), an automata-theoretic description
format of PPs, with an expectation-based semantics over infinite execution
traces, which also incorporates trace weights. We then prove a finite
approximation theorem that provides bounds to this semantics based on
expectations taken over finite, fixed-length traces. This enables us to frame
our semantics within a Feynman-Kac (FK) model, and ensures the consistency of
the Particle Filtering (PF) algorithm, an instance of SMC, with respect to our
semantics. Building on these results, we introduce VPF, a vectorized version of
the PF algorithm tailored to PPGs and our semantics. Experiments conducted with
a proof-of-concept implementation of VPF show very promising results compared
to state-of-the-art PP inference tools.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [170] [Is Research Software Science a Metascience?](https://arxiv.org/abs/2509.13436)
*Evan Eisinger,Michael A. Heroux*

Main category: cs.SE

TL;DR: 本文探讨研究软件科学(RSS)是否应归类为元科学，分析了RSS与元科学在目标、原则和重叠方面的关系，认为RSS是符合元科学目标的独立跨学科领域。


<details>
  <summary>Details</summary>
Motivation: 随着研究日益依赖计算方法，研究软件的质量、可重现性和透明度对科学结果的可靠性至关重要。需要明确RSS的学科定位以促进其认可度、资金支持和在科研改进中的整合。

Method: 通过定义元科学和RSS，比较两者的原则和目标，分析它们的重叠领域，并从支持和反对两个角度进行论证分析。

Result: 分析发现RSS推进了元科学的核心目标，特别是在计算可重现性方面，并连接了研究的技术、社会和认知维度。其分类取决于采用广义还是狭义的元科学定义。

Conclusion: RSS最好被理解为一个独特的跨学科领域，与元科学相一致并在某些定义下属于元科学。无论分类如何，对研究软件应用科学严谨性至关重要。

Abstract: As research increasingly relies on computational methods, the reliability of
scientific results depends on the quality, reproducibility, and transparency of
research software. Ensuring these qualities is critical for scientific
integrity and discovery. This paper asks whether Research Software Science
(RSS)--the empirical study of how research software is developed and
used--should be considered a form of metascience, the science of science.
Classification matters because it could affect recognition, funding, and
integration of RSS into research improvement. We define metascience and RSS,
compare their principles and objectives, and examine their overlaps. Arguments
for classification highlight shared commitments to reproducibility,
transparency, and empirical study of research processes. Arguments against
portraying RSS as a specialized domain focused on a tool rather than the
broader scientific enterprise. Our analysis finds RSS advances core goals of
metascience, especially in computational reproducibility, and bridges
technical, social, and cognitive aspects of research. Its classification
depends on whether one adopts a broad definition of metascience--any empirical
effort to improve science--or a narrow one focused on systemic and
epistemological structures. We argue RSS is best understood as a distinct
interdisciplinary domain that aligns with, and in some definitions fits within,
metascience. Recognizing it as such can strengthen its role in improving
reliability, justify funding, and elevate software development in research
institutions. Regardless of classification, applying scientific rigor to
research software ensures the tools of discovery meet the standards of the
discoveries themselves.

</details>


### [171] [An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software](https://arxiv.org/abs/2509.13471)
*Sina Gogani-Khiabani,Ashutosh Trivedi,Diptikalyan Saha,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 使用多智能体框架将法律条文转化为可执行软件，通过高阶蜕变测试和LLM驱动的测试生成，在复杂税法任务中表现优于前沿模型


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在法律条文翻译中存在可靠性问题，特别是在法律关键场景下存在模糊性和幻觉问题，需要开发更可靠的法律关键软件方法

Method: 提出基于智能体的方法，使用高阶蜕变关系进行测试用例生成，采用LLM驱动的角色框架自动化测试生成和代码合成，实现多智能体系统

Result: 使用较小模型(GPT-4o-mini)在最坏情况下通过率达到45%，优于前沿模型(GPT-4o和Claude 3.5的9-15%)

Conclusion: 智能体LLM方法为从自然语言规范开发稳健、可信赖的法律关键软件提供了一条可行路径

Abstract: Large language models (LLMs) show promise for translating natural-language
statutes into executable logic, but reliability in legally critical settings
remains challenging due to ambiguity and hallucinations. We present an agentic
approach for developing legal-critical software, using U.S. federal tax
preparation as a case study. The key challenge is test-case generation under
the oracle problem, where correct outputs require interpreting law. Building on
metamorphic testing, we introduce higher-order metamorphic relations that
compare system outputs across structured shifts among similar individuals.
Because authoring such relations is tedious and error-prone, we use an
LLM-driven, role-based framework to automate test generation and code
synthesis. We implement a multi-agent system that translates tax code into
executable software and incorporates a metamorphic-testing agent that searches
for counterexamples. In experiments, our framework using a smaller model
(GPT-4o-mini) achieves a worst-case pass rate of 45%, outperforming frontier
models (GPT-4o and Claude 3.5, 9-15%) on complex tax-code tasks. These results
support agentic LLM methodologies as a path to robust, trustworthy
legal-critical software from natural-language specifications.

</details>


### [172] [Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation](https://arxiv.org/abs/2509.13487)
*Abubakari Alidu,Michele Ciavotta,Flavio DePaoli*

Main category: cs.SE

TL;DR: Prompt2DAG是一个将自然语言描述转换为可执行Apache Airflow DAG的方法论，通过混合方法实现了78.5%的成功率，显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的数据丰富管道需要大量工程专业知识，希望通过自动化方法降低数据管道开发的门槛。

Method: 提出了四种生成方法（直接、纯LLM、混合和基于模板），在260个实验中评估了13个LLM和5个案例研究，使用惩罚性评分框架衡量可靠性、代码质量、结构完整性和可执行性。

Result: 混合方法表现最佳，成功率78.5%，质量评分优异（SAT:6.79, DST:7.67, PCT:7.76），成本效益是直接提示法的两倍以上。

Conclusion: 结构化混合方法对于平衡自动化工作流生成的灵活性和可靠性至关重要，为数据管道开发的民主化提供了可行路径。

Abstract: Developing reliable data enrichment pipelines demands significant engineering
expertise. We present Prompt2DAG, a methodology that transforms natural
language descriptions into executable Apache Airflow DAGs. We evaluate four
generation approaches -- Direct, LLM-only, Hybrid, and Template-based -- across
260 experiments using thirteen LLMs and five case studies to identify optimal
strategies for production-grade automation. Performance is measured using a
penalized scoring framework that combines reliability with code quality (SAT),
structural integrity (DST), and executability (PCT). The Hybrid approach
emerges as the optimal generative method, achieving a 78.5% success rate with
robust quality scores (SAT: 6.79, DST: 7.67, PCT: 7.76). This significantly
outperforms the LLM-only (66.2% success) and Direct (29.2% success) methods.
Our findings show that reliability, not intrinsic code quality, is the primary
differentiator. Cost-effectiveness analysis reveals the Hybrid method is over
twice as efficient as Direct prompting per successful DAG. We conclude that a
structured, hybrid approach is essential for balancing flexibility and
reliability in automated workflow generation, offering a viable path to
democratize data pipeline development.

</details>


### [173] [Crash Report Enhancement with Large Language Models: An Empirical Study](https://arxiv.org/abs/2509.13535)
*S M Farah Al Fahim,Md Nakhla Rafi,Zeyang Ma,Dong Jae Kim,Tse-Hsun,Chen*

Main category: cs.SE

TL;DR: 使用大型语言模型增强崩溃报告，通过添加故障位置、根因解释和修复建议，显著提高调试效率


<details>
  <summary>Details</summary>
Motivation: 崩溃报告缺乏足够的诊断细节，开发者调试效率低下，需要增强报告内容来改善调试过程

Method: 研究两种增强策略：Direct-LLM（单次使用堆栈跟踪上下文）和Agentic-LLM（迭代探索代码库获取额外证据）

Result: 在492个真实崩溃报告上，Top-1问题定位准确率从10.6%提升到40.2-43.1%，修复建议与开发者补丁相似度达56-57%

Conclusion: 为LLM提供堆栈跟踪和代码库信息可以生成显著更有用的增强崩溃报告，特别是Agentic-LLM在根因解释和修复指导方面表现更佳

Abstract: Crash reports are central to software maintenance, yet many lack the
diagnostic detail developers need to debug efficiently. We examine whether
large language models can enhance crash reports by adding fault locations,
root-cause explanations, and repair suggestions. We study two enhancement
strategies: Direct-LLM, a single-shot approach that uses stack-trace context,
and Agentic-LLM, an iterative approach that explores the repository for
additional evidence. On a dataset of 492 real-world crash reports, LLM-enhanced
reports improve Top-1 problem-localization accuracy from 10.6% (original
reports) to 40.2-43.1%, and produce suggested fixes that closely resemble
developer patches (CodeBLEU around 56-57%). Both our manual evaluations and
LLM-as-a-judge assessment show that Agentic-LLM delivers stronger root-cause
explanations and more actionable repair guidance. A user study with 16
participants further confirms that enhanced reports make crashes easier to
understand and resolve, with the largest improvement in repair guidance. These
results indicate that supplying LLMs with stack traces and repository code
yields enhanced crash reports that are substantially more useful for debugging.

</details>


### [174] [GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?](https://arxiv.org/abs/2509.13650)
*Amena Amro,Manar H. Alalfi*

Main category: cs.SE

TL;DR: GitHub Copilot代码审查功能在检测安全漏洞方面效果不佳，主要关注低严重性问题而非关键安全漏洞


<details>
  <summary>Details</summary>
Motivation: 随着软件开发越来越多采用AI工具，确保这些工具能够支持安全编码变得至关重要，需要评估GitHub Copilot代码审查功能的安全漏洞检测能力

Method: 使用来自多个编程语言和应用领域的开源项目中精选的标记漏洞代码样本，系统评估Copilot识别常见安全缺陷的能力

Result: Copilot代码审查经常无法检测SQL注入、XSS和不安全反序列化等关键漏洞，反馈主要针对编码风格和拼写错误等低严重性问题

Conclusion: AI辅助代码审查的实际效果与预期能力存在显著差距，仍需专用安全工具和人工代码审计来确保软件安全

Abstract: As software development practices increasingly adopt AI-powered tools,
ensuring that such tools can support secure coding has become critical. This
study evaluates the effectiveness of GitHub Copilot's recently introduced code
review feature in detecting security vulnerabilities. Using a curated set of
labeled vulnerable code samples drawn from diverse open-source projects
spanning multiple programming languages and application domains, we
systematically assessed Copilot's ability to identify and provide feedback on
common security flaws. Contrary to expectations, our results reveal that
Copilot's code review frequently fails to detect critical vulnerabilities such
as SQL injection, cross-site scripting (XSS), and insecure deserialization.
Instead, its feedback primarily addresses low-severity issues, such as coding
style and typographical errors. These findings expose a significant gap between
the perceived capabilities of AI-assisted code review and its actual
effectiveness in supporting secure development practices. Our results highlight
the continued necessity of dedicated security tools and manual code audits to
ensure robust software security.

</details>


### [175] [A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks](https://arxiv.org/abs/2509.13656)
*Yingao Elaine Yao,Vedant Nimje,Varun Viswanath,Saikat Dutta*

Main category: cs.SE

TL;DR: NBTest是首个针对Jupyter Notebook的回归测试框架，支持单元格级断言，可自动生成ML管道关键组件的断言，提高笔记本的可靠性和可维护性。


<details>
  <summary>Details</summary>
Motivation: 解决Jupyter Notebook在机器学习开发中测试支持有限的问题，防止因缺乏测试导致的性能回归和静默错误。

Method: 开发NBTest框架，提供断言API库和JupyterLab插件，支持在pytest和CI管道中运行测试，并开发自动化方法生成数据预处理、模型构建和评估等关键组件的单元格级断言。

Result: 在592个Kaggle笔记本上评估，平均每个笔记本生成35.75个断言，突变得分为0.57。用户研究显示NBTest直观易用（评分4.3/5），对编写断言和测试笔记本很有用（评分4.24/5）。

Conclusion: NBTest能有效检测回归错误，通过统计技术最小化非确定性计算导致的测试不稳定性，已被主流ML库的CI采用，显著提升笔记本测试的可靠性和效率。

Abstract: Notebooks have become the de-facto choice for data scientists and machine
learning engineers for prototyping and experimenting with machine learning (ML)
pipelines. Notebooks provide an interactive interface for code, data, and
visualization. However, notebooks provide very limited support for testing.
Thus, during continuous development, many subtle bugs that do not lead to
crashes often go unnoticed and cause silent errors that manifest as performance
regressions.
  To address this, we introduce NBTest - the first regression testing framework
that allows developers to write cell-level assertions in notebooks and run such
notebooks in pytest or in continuous integration (CI) pipelines. NBTest offers
a library of assertion APIs, and a JupyterLab plugin that enables executing
assertions. We also develop the first automated approach for generating
cell-level assertions for key components in ML notebooks, such as data
processing, model building, and model evaluation. NBTest aims to improve the
reliability and maintainability of ML notebooks without adding developer
burden.
  We evaluate NBTest on 592 Kaggle notebooks. Overall, NBTest generates 21163
assertions (35.75 on average per notebook). The generated assertions obtain a
mutation score of 0.57 in killing ML-specific mutations. NBTest can catch
regression bugs in previous versions of the Kaggle notebooks using assertions
generated for the latest versions. Because ML pipelines involve non
deterministic computations, the assertions can be flaky. Hence, we also show
how NBTest leverages statistical techniques to minimize flakiness while
retaining high fault-detection effectiveness. NBTest has been adopted in the CI
of a popular ML library. Further, we perform a user study with 17 participants
that shows that notebook users find NBTest intuitive (Rating 4.3/5) and useful
in writing assertions and testing notebooks (Rating 4.24/5).

</details>


### [176] [Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations](https://arxiv.org/abs/2509.13680)
*Wei Ma,Yixiao Yang,Jingquan Ge,Xiaofei Xie,Lingxiao Jiang*

Main category: cs.SE

TL;DR: PromptSE框架通过创建语义相同但情感和个性不同的提示变体，评估代码生成模型对提示措辞的敏感性，揭示了性能与稳定性是解耦的优化目标。


<details>
  <summary>Details</summary>
Motivation: 代码生成模型对提示措辞的敏感性未被充分研究，相同需求用不同情感或沟通风格表达会产生不同输出，而现有基准主要关注峰值性能。

Method: 使用情感和个性模板创建语义等价的提示变体，通过概率感知连续评分或二元通过率评估稳定性，并提出了AUC-E曲线下面积指标进行跨模型比较。

Result: 在14个模型（来自Llama、Qwen和DeepSeek三个家族）上的研究表明，性能和稳定性在很大程度上是解耦的优化目标，并揭示了挑战模型鲁棒性常见假设的架构和规模相关模式。

Conclusion: PromptSE框架能够量化性能与稳定性的权衡，将提示稳定性定位为与性能和公平性互补的评估维度，有助于构建更可信的AI辅助软件开发工具。

Abstract: Code generation models are widely used in software development, yet their
sensitivity to prompt phrasing remains under-examined. Identical requirements
expressed with different emotions or communication styles can yield divergent
outputs, while most benchmarks emphasize only peak performance. We present
PromptSE (Prompt Sensitivity Evaluation), a framework that creates semantically
equivalent prompt variants with emotion and personality templates, and that
evaluates stability using probability aware continuous scoring or using binary
pass rates when logits are unavailable. The results are aggregated into a
proposed area under curve metric (AUC-E) for cross model comparison. Across 14
models from three families (Llama, Qwen, and DeepSeek), our study shows that
performance and stability behave as largely decoupled optimization objectives,
and it reveals architectural and scale related patterns that challenge common
assumptions about model robustness. The framework supports rapid screening for
closed-source models as well as detailed stability analysis in research
settings. PromptSE enables practitioners to quantify performance stability
trade offs for deployment and model selection, positioning prompt stability as
a complementary evaluation dimension alongside performance and fairness, and
contributing to more trustworthy AI-assisted software development tools.

</details>


### [177] [Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning](https://arxiv.org/abs/2509.13755)
*Zhaoyang Chu,Yao Wan,Zhikun Zhang,Di Wang,Zhou Yang,Hongyu Zhang,Pan Zhou,Xuanhua Shi,Hai Jin,David Lo*

Main category: cs.SE

TL;DR: 代码语言模型存在敏感数据记忆泄漏风险，本文提出CodeEraser方法通过机器忘学技术高效删除特定敏感信息而无需全模型重训


<details>
  <summary>Details</summary>
Motivation: 当前代码语言模型存在敏感训练数据被记忆和泄漏的风险，而现有解决方案需要全模型重训，计算成本高

Method: 采用机器忘学技术，首先量化敏感数据记忆风险并精选50,000个高风险样本，研究梯度上升基础的忘学方法，提出CodeEraser方法选择性删除敏感代码段而保持周围代码结构完整性

Result: 在CodeParrot、CodeGen-Mono和Qwen2.5-Coder三种代码模型上验证了CodeEraser的有效性和高效性，能够成功删除目标敏感记忆同时保持模型功能

Conclusion: 机器忘学技术可以高效解决代码语言模型的敏感数据泄漏问题，CodeEraser方法为部署模型提供了一种不需全模型重训的安全修复方案

Abstract: While Code Language Models (CLMs) have demonstrated superior performance in
software engineering tasks such as code generation and summarization, recent
empirical studies reveal a critical privacy vulnerability: these models exhibit
unintended memorization of sensitive training data, enabling verbatim
reproduction of confidential information when specifically prompted. To address
this issue, several approaches, including training data de-duplication and
differential privacy augmentation, have been proposed. However, these methods
require full-model retraining for deployed CLMs, which incurs substantial
computational costs. In this paper, we aim to answer the following research
question: Can sensitive information memorized by CLMs be erased effectively and
efficiently?
  We conduct a pioneering investigation into erasing sensitive memorization in
CLMs through machine unlearning - a post-hoc modification method that removes
specific information from trained models without requiring full retraining.
Specifically, we first quantify the memorization risks of sensitive data within
CLM training datasets and curate a high-risk dataset of 50,000 sensitive
memorized samples as unlearning targets. We study two widely used gradient
ascent-based unlearning approaches: the vanilla and constraint-based methods,
and introduce CodeEraser, an advanced variant that selectively unlearns
sensitive memorized segments in code while preserving the structural integrity
and functional correctness of the surrounding code. Extensive experiments on
three families of CLMs, i.e., CodeParrot, CodeGen-Mono, and Qwen2.5-Coder,
validate the effectiveness and efficiency of CodeEraser in erasing targeted
sensitive memorization while maintaining model utility.

</details>


### [178] [A Study on Thinking Patterns of Large Reasoning Models in Code Generation](https://arxiv.org/abs/2509.13758)
*Kevin Halim,Sin G. Teo,Ruitao Feng,Zhenpeng Chen,Yang Gu,Chong Wang,Yang Liu*

Main category: cs.SE

TL;DR: 本文系统分析了大型推理模型(LRMs)在代码生成中的推理行为模式，通过手动标注推理轨迹建立了包含15种推理行为的分类法，揭示了不同模型的推理特点及其与代码正确性的关系。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型(LRMs)在代码生成方面表现出色，但缺乏对其推理模式的系统性分析，需要研究这些模型的推理行为如何影响生成的代码质量。

Method: 使用代码生成任务提示多个先进LRMs，应用开放式编码手动标注推理轨迹，建立LRM推理行为分类法，包含15种推理动作和四个阶段。

Result: 发现LRMs遵循类似人类的编码工作流程，复杂任务引发额外动作；不同模型推理风格各异；单元测试创建和脚手架生成等动作显著支持功能正确性；基于上下文的轻量级提示策略可改善代码质量。

Conclusion: 研究为理解LRMs的推理行为提供了系统框架，揭示了推理模式与代码质量的关系，为改进自动代码生成提供了实用见解和策略。

Abstract: Currently, many large language models (LLMs) are utilized for software
engineering tasks such as code generation. The emergence of more advanced
models known as large reasoning models (LRMs), such as OpenAI's o3, DeepSeek
R1, and Qwen3. They have demonstrated the capability of performing multi-step
reasoning. Despite the advancement in LRMs, little attention has been paid to
systematically analyzing the reasoning patterns these models exhibit and how
such patterns influence the generated code. This paper presents a comprehensive
study aimed at investigating and uncovering the reasoning behavior of LRMs
during code generation. We prompted several state-of-the-art LRMs of varying
sizes with code generation tasks and applied open coding to manually annotate
the reasoning traces. From this analysis, we derive a taxonomy of LRM reasoning
behaviors, encompassing 15 reasoning actions across four phases.
  Our empirical study based on the taxonomy reveals a series of findings.
First, we identify common reasoning patterns, showing that LRMs generally
follow a human-like coding workflow, with more complex tasks eliciting
additional actions such as scaffolding, flaw detection, and style checks.
Second, we compare reasoning across models, finding that Qwen3 exhibits
iterative reasoning while DeepSeek-R1-7B follows a more linear, waterfall-like
approach. Third, we analyze the relationship between reasoning and code
correctness, showing that actions such as unit test creation and scaffold
generation strongly support functional outcomes, with LRMs adapting strategies
based on task context. Finally, we evaluate lightweight prompting strategies
informed by these findings, demonstrating the potential of context- and
reasoning-oriented prompts to improve LRM-generated code. Our results offer
insights and practical implications for advancing automatic code generation.

</details>


### [179] [Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis](https://arxiv.org/abs/2509.13782)
*Yu Ge,Linna Xie,Zhong Li,Yu Pei,Tian Zhang*

Main category: cs.SE

TL;DR: FAMAS是首个基于频谱的多智能体系统故障归因方法，通过轨迹重放和频谱分析来识别导致故障的具体智能体行为


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在自动化复杂任务时存在故障，但故障归因困难且耗时，阻碍了系统调试和改进

Method: 通过系统化的轨迹重放和抽象，结合专门设计的可疑度公式，分析智能体行为模式和动作激活模式来估计每个动作导致故障的可能性

Result: 在Who and When基准测试中，FAMAS优于12个基线方法，表现出卓越的性能

Conclusion: FAMAS为多智能体系统提供了一种有效的故障归因解决方案，有助于系统调试和性能提升

Abstract: Large Language Model Powered Multi-Agent Systems (MASs) are increasingly
employed to automate complex real-world problems, such as programming and
scientific discovery. Despite their promising, MASs are not without their
flaws. However, failure attribution in MASs - pinpointing the specific agent
actions responsible for failures - remains underexplored and labor-intensive,
posing significant challenges for debugging and system improvement. To bridge
this gap, we propose FAMAS, the first spectrum-based failure attribution
approach for MASs, which operates through systematic trajectory replay and
abstraction, followed by spectrum analysis.The core idea of FAMAS is to
estimate, from variations across repeated MAS executions, the likelihood that
each agent action is responsible for the failure. In particular, we propose a
novel suspiciousness formula tailored to MASs, which integrates two key factor
groups, namely the agent behavior group and the action behavior group, to
account for the agent activation patterns and the action activation patterns
within the execution trajectories of MASs. Through expensive evaluations
against 12 baselines on the Who and When benchmark, FAMAS demonstrates superior
performance by outperforming all the methods in comparison.

</details>


### [180] [Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing](https://arxiv.org/abs/2509.13852)
*Yulun Wu,Guangba Yu,Zhihan Jiang,Yichen Li,Michael R. Lyu*

Main category: cs.SE

TL;DR: 提出了Trace Sampling 2.0方法Autoscope，通过span级别采样在保持trace结构完整性的同时减少81.2%的存储开销，并提高故障诊断效果。


<details>
  <summary>Details</summary>
Motivation: 传统trace采样方法通常只保留异常trace，丢弃了大量有价值的正常trace信息，无法进行有效的对比分析，且给后端存储带来巨大负担。

Method: 设计实现了Autoscope span级别采样方法，利用静态分析提取执行逻辑，在保持trace结构一致性的同时选择性保留关键span。

Result: 在两个开源微服务上评估显示：trace大小减少81.2%，故障span覆盖率达到98.1%，根因分析效果平均提升8.3%。

Conclusion: Autoscope能够显著提升微服务系统的可观测性和存储效率，为性能监控提供了强有力的解决方案。

Abstract: Distributed tracing is an essential diagnostic tool in microservice systems,
but the sheer volume of traces places a significant burden on backend storage.
A common approach to mitigating this issue is trace sampling, which selectively
retains traces based on specific criteria, often preserving only anomalous
ones. However, this method frequently discards valuable information, including
normal traces that are essential for comparative analysis. To address this
limitation, we introduce Trace Sampling 2.0, which operates at the span level
while maintaining trace structure consistency. This approach allows for the
retention of all traces while significantly reducing storage overhead. Based on
this concept, we design and implement Autoscope, a span-level sampling method
that leverages static analysis to extract execution logic, ensuring that
critical spans are preserved without compromising structural integrity. We
evaluated Autoscope on two open-source microservices. Our results show that it
reduces trace size by 81.2% while maintaining 98.1% faulty span coverage,
outperforming existing trace-level sampling methods. Furthermore, we
demonstrate its effectiveness in root cause analysis, achieving an average
improvement of 8.3%. These findings indicate that Autoscope can significantly
enhance observability and storage efficiency in microservices, offering a
robust solution for performance monitoring.

</details>


### [181] [Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification](https://arxiv.org/abs/2509.13868)
*Manal Binkhonain,Reem Alfayaz*

Main category: cs.SE

TL;DR: 基于提示的大型语言模型在需求分类任务中表现出色，能够减少对大量标注数据的依赖，在少样本提示下性能可匹配或超越微调transformer基线。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法需要大量标注数据，成本高、速度慢、领域依赖性强且泛化能力差。本研究旨在测试基于提示的大型语言模型是否能减少数据需求。

Method: 在PROMISE和SecReq两个英文数据集上，对多个模型和提示风格（零样本、少样本、角色扮演和思维链）进行基准测试，并与微调transformer基线进行比较。

Result: 基于提示的LLM，特别是少样本提示，能够匹配或超越基线性能。添加角色扮演或角色扮演加思维链提示可以带来进一步的性能提升。

Conclusion: 基于提示的LLM是实用且可扩展的选择，减少了对大规模标注的依赖，并能提高跨任务的泛化能力。

Abstract: Requirements classification assigns natural language requirements to
predefined classes, such as functional and non functional. Accurate
classification reduces risk and improves software quality. Most existing models
rely on supervised learning, which needs large labeled data that are costly,
slow to create, and domain dependent; they also generalize poorly and often
require retraining for each task. This study tests whether prompt based large
language models can reduce data needs. We benchmark several models and
prompting styles (zero shot, few shot, persona, and chain of thought) across
multiple tasks on two English datasets, PROMISE and SecReq. For each task we
compare model prompt configurations and then compare the best LLM setups with a
strong fine tuned transformer baseline. Results show that prompt based LLMs,
especially with few shot prompts, can match or exceed the baseline. Adding a
persona, or persona plus chain of thought, can yield further gains. We conclude
that prompt based LLMs are a practical and scalable option that reduces
dependence on large annotations and can improve generalizability across tasks.

</details>


### [182] [Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education](https://arxiv.org/abs/2509.13896)
*Shalini Chakraborty,Lola Burgueño,Nathalie Moreno,Javier Troya,Paula Muñoz*

Main category: cs.SE

TL;DR: 这篇系统性文献综述发现生成式AI在软件建模教育中的伦理问题很少被研究，仅找到3篇相关论文，告诉了该领域伦理框架的紧急需求。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在软件建模教育中快速普及，影响核心学习成果，但其伦理含义待探索。研究动机是识别并分析该领域的伦理问题。

Method: 通过系统性文献综述方法，搜索6大计算机科学数字图书馆（ACM、IEEE、Scopus等）中关于生成式AI在软件建模教育中伦理问题的研究。

Result: 从1386篇论文中仅找到3篇明确讨论伦理问题的研究，显示该领域伦理讨论的严重缺失。

Conclusion: 研究呈现了生成式AI在软件建模教育中负责任集成的紧急需求，并指出了该领域的研究机遇和挑战，强调需要结构化的伦理框架。

Abstract: Generative Artificial Intelligence (GenAI) is rapidly gaining momentum in
software modeling education, embraced by both students and educators. As GenAI
assists with interpreting requirements, formalizing models, and translating
students' mental models into structured notations, it increasingly shapes core
learning outcomes such as domain comprehension, diagrammatic thinking, and
modeling fluency without clear ethical oversight or pedagogical guidelines.
Yet, the ethical implications of this integration remain underexplored.
  In this paper, we conduct a systematic literature review across six major
digital libraries in computer science (ACM Digital Library, IEEE Xplore,
Scopus, ScienceDirect, SpringerLink, and Web of Science). Our aim is to
identify studies discussing the ethical aspects of GenAI in software modeling
education, including responsibility, fairness, transparency, diversity, and
inclusion among others.
  Out of 1,386 unique papers initially retrieved, only three explicitly
addressed ethical considerations. This scarcity highlights the critical absence
of ethical discourse surrounding GenAI in modeling education and raises urgent
questions about the responsible integration of AI in modeling curricula, as
well as it evinces the pressing need for structured ethical frameworks in this
emerging educational landscape. We examine these three studies and explore the
emerging research opportunities as well as the challenges that have arisen in
this field.

</details>


### [183] [An Empirical Study on Failures in Automated Issue Solving](https://arxiv.org/abs/2509.13941)
*Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: 本文分析了自动化问题解决中LLM代理工具的失败模式，提出了包含3阶段、9大类、25子类的失败分类法，并设计了专家-执行者协作框架来解决推理缺陷和认知死锁问题，在SWE-Bench基准上解决了22.2%之前无法解决的问题。


<details>
  <summary>Details</summary>
Motivation: 当前自动化问题解决评估主要报告总体解决率，掩盖了成功和失败的根本原因，难以诊断模型弱点或指导针对性改进。需要从高层次性能指标转向底层原因分析。

Method: 首先分析三种SOTA工具在SWE-Bench-Verified上的性能和效率，然后对150个失败实例进行系统手动分析，建立失败模式分类法，最后提出专家-执行者协作框架，其中专家代理提供战略监督和纠偏。

Result: 建立了全面的失败模式分类法，发现两种架构范式具有不同的失败特征，代理式失败主要源于有缺陷的推理和认知死锁。提出的协作框架为领先单代理解决了22.2%之前无法解决的问题。

Conclusion: 通过诊断性评估和协作设计，为构建更强大的代理工具铺平了道路，专家-执行者框架能有效纠正推理缺陷和打破认知死锁。

Abstract: Automated issue solving seeks to autonomously identify and repair defective
code snippets across an entire codebase. SWE-Bench has emerged as the most
widely adopted benchmark for evaluating progress in this area. While LLM-based
agentic tools show great promise, they still fail on a substantial portion of
tasks. Moreover, current evaluations primarily report aggregate issue-solving
rates, which obscure the underlying causes of success and failure, making it
challenging to diagnose model weaknesses or guide targeted improvements. To
bridge this gap, we first analyze the performance and efficiency of three SOTA
tools, spanning both pipeline-based and agentic architectures, in automated
issue solving tasks of SWE-Bench-Verified under varying task characteristics.
Furthermore, to move from high-level performance metrics to underlying cause
analysis, we conducted a systematic manual analysis of 150 failed instances.
From this analysis, we developed a comprehensive taxonomy of failure modes
comprising 3 primary phases, 9 main categories, and 25 fine-grained
subcategories. Then we systematically analyze the distribution of the
identified failure modes, the results reveal distinct failure fingerprints
between the two architectural paradigms, with the majority of agentic failures
stemming from flawed reasoning and cognitive deadlocks. Motivated by these
insights, we propose a collaborative Expert-Executor framework. It introduces a
supervisory Expert agent tasked with providing strategic oversight and
course-correction for a primary Executor agent. This architecture is designed
to correct flawed reasoning and break the cognitive deadlocks that frequently
lead to failure. Experiments show that our framework solves 22.2% of previously
intractable issues for a leading single agent. These findings pave the way for
building more robust agents through diagnostic evaluation and collaborative
design.

</details>


### [184] [Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation](https://arxiv.org/abs/2509.13942)
*Duc Minh Ha,Phu Trac Kien,Tho Quan,Anh Nguyen-Duc*

Main category: cs.SE

TL;DR: 这篇论文研究了如何将传统软件开发流程作为协调架构应用于LLM多代理系统，通过对比研究发现不同流程模型在代码质量、成本和效率方面的特点和交换价


<details>
  <summary>Details</summary>
Motivation: 利用传统软件开发流程（如Waterfall、V-Model、Agile）的结构化协调模式来指导LLM多代理系统的自主协作，提高软件开发的质量和效率

Method: 执行11个多样化软件项目，在3种流程模型和4种GPT变体下进行实验（共132次运行），使用标准化指标评估代码规模、成本和质量

Result: 流程模型和LLM选择都显著影响系统性能。Waterfall最高效，V-Model产生最冗长代码，Agile质量最高但计算成本也最高

Conclusion: 传统软件流程可有效应用于LLM多代理系统，但各有交换价，应根据项目优先级选择合适的流程模型

Abstract: [Background] Large Language Model (LLM)-based multi-agent systems (MAS) are
transforming software development by enabling autonomous collaboration.
Classical software processes such asWaterfall, V-Model, and Agile offer
structured coordination patterns that can be repurposed to guide these agent
interactions. [Aims] This study explores how traditional software development
processes can be adapted as coordination scaffolds for LLM based MAS and
examines their impact on code quality, cost, and productivity. [Method] We
executed 11 diverse software projects under three process models and four GPT
variants, totaling 132 runs. Each output was evaluated using standardized
metrics for size (files, LOC), cost (execution time, token usage), and quality
(code smells, AI- and human detected bugs). [Results] Both process model and
LLM choice significantly affected system performance. Waterfall was most
efficient, V-Model produced the most verbose code, and Agile achieved the
highest code quality, albeit at higher computational cost. [Conclusions]
Classical software processes can be effectively instantiated in LLM-based MAS,
but each entails trade-offs across quality, cost, and adaptability. Process
selection should reflect project goals, whether prioritizing efficiency,
robustness, or structured validation.

</details>


### [185] [Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework](https://arxiv.org/abs/2509.14093)
*Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia*

Main category: cs.SE

TL;DR: 思维链推理虽能提升大语言模型性能，但带来高昂计算成本。研究发现过长推理反而降低准确率并增加延迟。为此提出SEER自适应框架，通过压缩思维链在保持准确性的同时减少42.1%的输出长度。


<details>
  <summary>Details</summary>
Motivation: 思维链推理虽然能提高LLM在算术、逻辑和常识任务中的准确性和鲁棒性，但会导致计算成本显著增加（延迟、内存使用和KV缓存需求），特别是在需要简洁确定性输出的软件工程任务中。需要研究这种权衡关系并找到优化方案。

Method: 提出SEER（Self-Enhancing Efficient Reasoning）自适应框架，结合Best-of-N采样和任务感知自适应过滤，根据推理前输出动态调整阈值来压缩思维链，减少冗余和计算开销。

Result: 在三个软件工程任务和一个数学任务上的评估显示：SEER平均缩短思维链42.1%，通过减少截断提高准确性，并消除了大多数无限循环问题。

Conclusion: SEER是一种实用方法，能使思维链增强的LLM更加高效和鲁棒，即使在资源受限环境下也能保持性能，挑战了"推理越长越好"的假设。

Abstract: Chain-of-Thought (CoT) reasoning enhances Large Language Models (LLMs) by
prompting intermediate steps, improving accuracy and robustness in arithmetic,
logic, and commonsense tasks. However, this benefit comes with high
computational costs: longer outputs increase latency, memory usage, and
KV-cache demands. These issues are especially critical in software engineering
tasks where concise and deterministic outputs are required. To investigate
these trade-offs, we conduct an empirical study based on code generation
benchmarks. The results reveal that longer CoT does not always help. Excessive
reasoning often causes truncation, accuracy drops, and latency up to five times
higher, with failed outputs consistently longer than successful ones. These
findings challenge the assumption that longer reasoning is inherently better
and highlight the need for adaptive CoT control. Motivated by this, we propose
SEER (Self-Enhancing Efficient Reasoning), an adaptive framework that
compresses CoT while preserving accuracy. SEER combines Best-of-N sampling with
task-aware adaptive filtering, dynamically adjusting thresholds based on
pre-inference outputs to reduce verbosity and computational overhead. We then
evaluate SEER on three software engineering tasks and one math task. On
average, SEER shortens CoT by 42.1%, improves accuracy by reducing truncation,
and eliminates most infinite loops. These results demonstrate SEER as a
practical method to make CoT-enhanced LLMs more efficient and robust, even
under resource constraints.

</details>


<div id='econ.EM'></div>

# econ.EM [[Back]](#toc)

### [186] [Generalized Covariance Estimator under Misspecification and Constraints](https://arxiv.org/abs/2509.13492)
*Aryan Manafi Neyazi*

Main category: econ.EM

TL;DR: 本文研究了广义协方差(GCov)估计器在错误设定和约束条件下的性质，应用于具有局部爆炸模式的过程，如因果-非因果和双自回归(DAR)过程。证明了GCov在错误设定下的一致性和渐近正态性，构建了基于GCov的Wald型和得分型检验，并提出了约束GCov(CGCov)估计器扩展应用范围。


<details>
  <summary>Details</summary>
Motivation: 研究GCov估计器在模型错误设定和参数约束条件下的统计性质，特别是在处理具有局部爆炸特征的时间序列过程时的表现，以扩展该估计器的应用范围。

Method: 开发了GCov-based Wald型和得分型检验方法，提出了约束GCov(CGCov)估计器，分析了参数在边界和远离边界时的渐近分布，并在因果-非因果和DAR模型中验证有限样本性能。

Result: GCov在错误设定下保持一致性且具有渐近正态分布，提出的检验统计量服从χ²分布，CGCov估计器成功扩展了GCov的应用范围。实证应用展示了方法在能源需求商品指数和美国3个月国债利率分析中的有效性。

Conclusion: GCov估计器在模型错误设定和约束条件下仍具有良好的统计性质，CGCov扩展了其适用性，为分析具有局部爆炸模式的时间序列过程提供了有效的工具。

Abstract: This paper investigates the properties of the Generalized Covariance (GCov)
estimator under misspecification and constraints with application to processes
with local explosive patterns, such as causal-noncausal and double
autoregressive (DAR) processes. We show that GCov is consistent and has an
asymptotically Normal distribution under misspecification. Then, we construct
GCov-based Wald-type and score-type tests to test one specification against the
other, all of which follow a $\chi^2$ distribution. Furthermore, we propose the
constrained GCov (CGCov) estimator, which extends the use of the GCov estimator
to a broader range of models with constraints on their parameters. We
investigate the asymptotic distribution of the CGCov estimator when the true
parameters are far from the boundary and on the boundary of the parameter
space. We validate the finite sample performance of the proposed estimators and
tests in the context of causal-noncausal and DAR models. Finally, we provide
two empirical applications by applying the noncausal model to the final energy
demand commodity index and also the DAR model to the US 3-month treasury bill.

</details>


### [187] [Time-Varying Heterogeneous Treatment Effects in Event Studies](https://arxiv.org/abs/2509.13698)
*Irene Botosaru,Laura Liu*

Main category: econ.EM

TL;DR: 本文研究了事件研究中异质性处理效应的识别与估计，强调了滞后因变量和处理效应异质性的重要性。开发了一种基于短T动态线性面板模型的半参数方法，构建了两步估计器，并提供了对事件研究文献中常见假设的见解。


<details>
  <summary>Details</summary>
Motivation: 传统事件研究在估计时变处理效应时，忽略滞后因变量可能导致遗漏变量偏差，且需要同时考虑处理效应的异质性。

Method: 提出基于短T动态线性面板模型（具有相关随机系数）的半参数方法，使用时序过程建模时变异质性处理效应以降低维度。构建了两步估计器：第一步用准最大似然估计共同参数，第二步用经验贝叶斯估计异质性处理效应。

Result: 该方法灵活易实施，在渐近意义上达到比率最优性。研究结果还为事件研究文献中的常见假设（如无预期效应、跨处理时间队列的处理效应同质性、状态依赖结构等）提供了新的见解。

Conclusion: 本文提出的半参数方法能有效解决事件研究中滞后因变量遗漏和处理效应异质性问题，为相关实证研究提供了更可靠的估计框架。

Abstract: This paper examines the identification and estimation of heterogeneous
treatment effects in event studies, emphasizing the importance of both lagged
dependent variables and treatment effect heterogeneity. We show that omitting
lagged dependent variables can induce omitted variable bias in the estimated
time-varying treatment effects. We develop a novel semiparametric approach
based on a short-T dynamic linear panel model with correlated random
coefficients, where the time-varying heterogeneous treatment effects can be
modeled by a time-series process to reduce dimensionality. We construct a
two-step estimator employing quasi-maximum likelihood for common parameters and
empirical Bayes for the heterogeneous treatment effects. The procedure is
flexible, easy to implement, and achieves ratio optimality asymptotically. Our
results also provide insights into common assumptions in the event study
literature, such as no anticipation, homogeneous treatment effects across
treatment timing cohorts, and state dependence structure.

</details>


<div id='econ.GN'></div>

# econ.GN [[Back]](#toc)

### [188] [In-between Transatlantic (Monetary) Disturbances](https://arxiv.org/abs/2509.13578)
*Santiago Camara,Jeanne Aublin*

Main category: econ.GN

TL;DR: 本文研究欧洲央行利率冲击对加拿大经济的溢出效应，并与美联储冲击进行比较，发现ECB加息导致加元贬值和经济活动收缩，主要通过贸易渠道传导，而Fed冲击主要通过金融条件收紧影响加拿大经济。


<details>
  <summary>Details</summary>
Motivation: 研究加拿大经济如何受到外国货币政策冲击的影响，特别是比较欧洲央行和美联储利率政策的不同传导机制，以了解加拿大在全球金融和贸易市场中的脆弱性。

Method: 结合VAR模型和局部投影回归，采用识别策略来消除政策公告周围的信息效应，分析ECB和Fed利率冲击对加拿大经济的影响。

Result: ECB利率加息导致加元贬值和经济活动显著收缩，主要通过降低油价和出口的贸易渠道传导，对国内金融条件影响有限；而Fed冲击显著收紧加拿大金融条件，对贸易流动影响较小。

Conclusion: 加拿大通过全球金融和贸易市场的一体化，直接和间接地暴露于外国货币政策冲击，ECB和Fed冲击通过不同渠道影响加拿大经济，凸显了其对外部冲击的脆弱性。

Abstract: This paper studies the spillovers of European Central Bank (ECB) interest
rate shocks into the Canadian economy and compares them with those of the U.S.
Federal Reserve (Fed). We combine a VAR model and local projection regressions
with identification strategies that explicitly purge information effects around
policy announcements. We find that an ECB rate hike leads to a depreciation of
the Canadian dollar and a sharp contraction in economic activity. The main
transmission channel is international trade: ECB shocks trigger a decline in
oil prices and exports, while leaving domestic financial conditions largely
unaffected. By contrast, Fed shocks tighten Canadian financial conditions
significantly, with more limited effects on trade flows. These findings show
that Canada is exposed to foreign monetary policy both directly and indirectly,
through its integration in global financial and trade markets.

</details>


### [189] [Deep Learning in the Sequence Space](https://arxiv.org/abs/2509.13623)
*Marlon Azinovic-Yang,Jan Žemlička*

Main category: econ.GN

TL;DR: 使用深度神经网络近似动态随机经济的力子期望均衡解，通过模拟路径训练网络满足所有均衡条件，并在三个逐渐复杂的经济模型中验证性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态随机经济中力子期望均衡的计算问题，特别是当经济包含多种风险来源和复杂结构时，传统数值方法面临计算复杂性挑战。

Method: 使用深度神经网络参数化均衡对象作为外生冲击历史的函数，通过模拟经济路径训练网络满足所有均衡条件，并设计保证单调性的策略函数网络架构。

Result: 成功解决了三个逐渐复杂的经济模型：随机增长模型、高维度代际交叠经济以及包含微观和宏观风险的经济。方法能够处理多种风险来源和复杂结构。

Conclusion: 深度学习算法提供了一种有效的方法来近似复杂动态经济的力子期望均衡，特别是在传统数值方法遇到计算困难的情况下。方法具有强大的扩展性和实践应用价值。

Abstract: We develop a deep learning algorithm for approximating functional rational
expectations equilibria of dynamic stochastic economies in the sequence space.
We use deep neural networks to parameterize equilibrium objects of the economy
as a function of truncated histories of exogenous shocks. We train the neural
networks to fulfill all equilibrium conditions along simulated paths of the
economy. To illustrate the performance of our method, we solve three economies
of increasing complexity: the stochastic growth model, a high-dimensional
overlapping generations economy with multiple sources of aggregate risk, and
finally an economy where households and firms face uninsurable idiosyncratic
risk, shocks to aggregate productivity, and shocks to idiosyncratic and
aggregate volatility. Furthermore, we show how to design practical neural
policy function architectures that guarantee monotonicity of the predicted
policies, facilitating the use of the endogenous grid method to simplify parts
of our algorithm.

</details>


### [190] [Can the decoy effect increase cooperation in networks? An experiment](https://arxiv.org/abs/2509.13887)
*Claudia Cerrone,Francesco Feri,Anita Gantner,Paolo Pin*

Main category: econ.GN

TL;DR: 研究表明诱饵效应（吸引效应）能够促进社交网络中的合作行为，实验显示引入被支配选项可增加目标选择，特别是在早期决策中


<details>
  <summary>Details</summary>
Motivation: 探究诱饵效应是否能够在社交网络中促进合作行为，特别是在存在搭便车激励的网络环境中

Method: 通过实验室实验，在社交网络环境中引入被支配选项（诱饵），观察其对目标选择行为的影响

Result: 引入被支配选项显著增加了目标选择，特别是在早期决策中；效应在个体设置中更强，但在网络中仍然存在，且效果因决策者的战略位置而异

Conclusion: 诱饵效应能够有效促进社交网络中的合作，即使在存在搭便车激励的情况下，这为设计促进合作的机制提供了新思路

Abstract: This paper investigates whether the decoy effect - specifically the
attraction effect - can foster cooperation in social networks. In a lab
experiment, we show that introducing a dominated option increases the selection
of the target choice, especially in early decisions. The effect is stronger in
individual settings but persists in networks despite free-riding incentives,
with variation depending on the decision-maker's strategic position.

</details>


### [191] [Machines are more productive than humans until they aren't, and vice versa](https://arxiv.org/abs/2509.14057)
*Riccardo Zanardelli*

Main category: econ.GN

TL;DR: 通过蒙特卡洛模拟分析人机技能组合的经济效益，发现真正的增强效应是人机协同成功的关键，简单分配人和机器技能反而可能造成价值损失


<details>
  <summary>Details</summary>
Motivation: 解决在人工智能发展背景下，组织如何根据经济原则优化技能政策决策的复杂问题

Method: 基于实证现实主义的蒙特卡洛模拟方法，建立了一个计算机模拟框架，分析不同复杂度任务中人类和机器技能单独或联合部署的经济影响

Result: 自动化在中低复杂度任务中最经济高效，而在高复杂场景中人类技能更优；人机组合在需要高法划性的情况下可能最有效，但只有实现真正增强时才能成功，否则会因双重技能结构成本而造成价值损失

Conclusion: 人机技能政策不是银弹解决方案或低风险投机，而是需要组织坚定承诺才能实现的竞争力提升机会；提高机器技能成本效益不能取代对实现增强效应的核心关注

Abstract: With the growth of artificial skills, organizations may increasingly confront
with the problem of optimizing skill policy decisions guided by economic
principles. This paper addresses the underlying complexity of this challenge by
developing an in-silico framework based on Monte Carlo simulations grounded in
empirical realism to analyze the economic impact of human and machine skills,
individually or jointly deployed, in the execution of tasks presenting varying
levels of complexity. Our results provide quantitative support for the
established notions that automation tends to be the most economically-effective
strategy for tasks characterized by low-to-medium generalization difficulty,
while automation struggles to match the economic utility of human skills in
more complex scenarios. Critically, our simulations highlight that combining
human and machine skills can be the most effective strategy when a high level
of generalization is required, but only if genuine augmentation is achieved. In
contrast, when failing to realize this synergy, the human-machine policy is
severely penalized by the inherent costs of its dual skill structure, causing
it to destroy value and becoming the worst choice from an economic perspective.
The takeaway for decision-makers is unambiguous: simply allocating human and
machine skills to a task is insufficient, and a human-machine skill policy is
neither a silver-bullet solution nor a low-risk compromise. Rather, it is a
critical opportunity to boost competitiveness that demands a strong
organizational commitment to enabling augmentation. Also, our findings show
that improving the cost-effectiveness of machine skills over time, while
useful, does not replace the fundamental need to focus on achieving
augmentation.

</details>


### [192] [Incentivizing High Quality Entrants When Creators Are Strategic](https://arxiv.org/abs/2509.14102)
*Felicia Nguyen*

Main category: econ.GN

TL;DR: 平台通过设计早期曝光和奖励机制来激励创作者在发布前选择高质量内容，提出了可实现性奖励、前载保证曝光和等边际价值规则等优化策略


<details>
  <summary>Details</summary>
Motivation: 解决创作者冷启动问题，激励创作者在内容发布前选择高质量创作，以提升平台内容质量和供给

Method: 建立理论模型分析创作者策略性质量选择行为，推导出可实现性奖励公式，提出前载曝光策略和等边际价值分配规则，并将现实排名算法映射到模型参数

Result: 得到了完美对齐创作者和平台目标的闭式解，发现前载保证曝光是最有效的激励方式，并提供了基于遥测的估计方法

Conclusion: 该框架简单易操作，为平台提供了直接且易于管理解释的解决方案，能有效解决创作者冷启动问题并培育高质量内容供给

Abstract: We study how a platform should design early exposure and rewards when
creators strategically choose quality before release. A short testing window
with a pass/fail bar induces a pass probability, the slope of which is the key
sufficient statistic for incentives. We derive three main results. First, a
closed-form ``implementability bounty'' can perfectly align creator and
platform objectives, correcting for incomplete revenue sharing. Second,
front-loading guaranteed impressions is the most effective way to strengthen
incentives for a given attention budget. Third, when impression and cash
budgets are constrained, the optimal policy follows an equal-marginal-value
rule based on the prize spread and certain exposure. We map realistic ranking
engines (e.g., Thompson sampling) into the model's parameters and provide
telemetry-based estimators. The framework is simple to operationalize and
offers a direct, managerially interpretable solution for platforms to solve the
creator cold-start problem and cultivate high-quality supply.

</details>


### [193] [Minimum pricing or volumetric taxation? Quantity, quality and competition effects of price regulations in alcohol markets](https://arxiv.org/abs/2509.14116)
*Celine Bonnet,Fabrice Etile,Sebastien Lecocq*

Main category: econ.GN

TL;DR: 这篇论文研究了法国酒精价格政策改革，发现最低单位价格(MUP)政策比以酒精为基础的税改更能有效减少酒精购买量，特别是重度饮酒家庭，同时有助于小型咖酒企业增益。


<details>
  <summary>Details</summary>
Motivation: 酒精价格规制改革在酒籿产国面临挑战，因为现行价格规制反映了文化偏好与经济利益的结合，而非公共健康考虑。需要评估不同酒精定价政策对消费者行为、企业和市场的影响。

Method: 开发了一个微观基础的部分均衡模型，考虑了消费者在不同酒精类别购买量和产品质量上的偏好，以及企业的战略定价行为。并使用家庭扫描仪数据进行模型检验。

Result: 最低单位价格(MUP)政策在减少酒精购买方面表现更优(-15% vs -10%)，特别是重度饮酒家庭(-17%)。MUP增加了中小型咖酒企业利润(+39%)，减少了大型制造商和零售商利润(-39%)，同时保持税收稳定。

Conclusion: 最低单位价格(MUP)是一种目标明确的策略，能够有效减少有害消费，同时有利于中小型咖酒生产商。这为酒籿产国的酒精定价政策提供了重要的事前证据。

Abstract: Reforming alcohol price regulations in wine-producing countries is
challenging, as current price regulations reflect the alignment of cultural
preferences with economic interests rather than public health concerns. We
evaluate and compare the impact of counterfactual alcohol pricing policies on
consumer behaviors, firms, and markets in France. We develop a micro-founded
partial equilibrium model that accounts for consumer preferences over purchase
volumes across alcohol categories and over product quality within categories,
and for firms' strategic price-setting. After calibration on household scanner
data, we compare the impacts of replacing current taxes by ethanol-based
volumetric taxes with a minimum unit price (MUP) policy of 0.50 Euro per
standard drink. The results show that the MUP in addition to the current tax
outperforms a tax reform in reducing ethanol purchases (-15% vs. -10% for
progressive taxation), especially among heavy drinking households (-17%). The
MUP increases the profits of small and medium wine firms (+39%) while
decreasing the profits of large manufacturers and retailers (-39%) and
maintaining tax revenues stable. The results support the MUP as a targeted
strategy to reduce harmful consumption while benefiting small and medium wine
producers. This study provides ex-ante evidence that is crucial for alcohol
pricing policies in wine-producing countries.

</details>


<div id='econ.TH'></div>

# econ.TH [[Back]](#toc)

### [194] [Strategic Pricing and Ranking in Recommendation Systems with Seller Competition](https://arxiv.org/abs/2509.13462)
*Tushar Shankar Walunj,Veeraruna Kavitha,Jayakrishnan Nair,Priyank Agarwal*

Main category: econ.TH

TL;DR: 本文研究推荐系统中卖家通过佣金竞争平台可见度的博弈问题，提出了新的μ-连接均衡循环(μ-EC)解概念来处理传统纳什均衡不存在的情况。


<details>
  <summary>Details</summary>
Motivation: 研究推荐系统中卖家与平台的战略互动，传统纳什均衡由于效用不连续性而无法存在，需要寻找新的均衡概念来刻画这种竞争环境。

Method: 采用Stackelberg博弈模型，卖家作为领导者，平台作为跟随者。考虑两种定价模式：平台定价和卖家预设定价。在渐近状态下分析极限博弈的均衡结构。

Result: 证明了当卖家实力不同时标准纳什均衡不存在，提出了μ-连接均衡循环(μ-EC)这一新的集合值解概念，具有稳定性、无外部链、内部不稳定性和最小性四个重要性质。

Conclusion: μ-EC概念成功解决了推荐系统竞争环境中传统均衡概念失效的问题，为理解平台经济中的战略互动提供了新的分析框架。

Abstract: We study a recommendation system where sellers compete for visibility by
strategically offering commissions to a platform that optimally curates a
ranked menu of items and their respective prices for each customer. Customers
interact sequentially with the menu following a cascade click model, and their
purchase decisions are influenced by price sensitivity and positions of various
items in the menu. We model the seller-platform interaction as a Stackelberg
game with sellers as leaders and consider two different games depending on
whether the prices are set by the platform or prefixed by the sellers. It is
complicated to find the optimal policy of the platform in complete generality;
hence, we solve the problem in an important asymptotic regime.
  The core contribution of this paper lies in characterizing the equilibrium
structure of the limit game. We show that when sellers are of different
strengths, the standard Nash equilibrium does not exist due to discontinuities
in utilities. We instead establish the existence of a novel equilibrium
solution, namely `$\mu$-connected equilibrium cycle' ($\mu$-EC), which captures
oscillatory strategic responses at the equilibrium. Unlike the (pure) Nash
equilibrium, which defines a fixed point of mutual best responses, this is a
set-valued solution concept of connected components. This novel equilibrium
concept identifies a Cartesian product set of connected action profiles in the
continuous action space that satisfies four important properties: stability
against external deviations, no external chains, instability against internal
deviations, and minimality. We extend a recently introduced solution concept
equilibrium cycle to include stability against measure-zero violations and, by
avoiding topological difficulties to propose $\mu$-EC.

</details>
